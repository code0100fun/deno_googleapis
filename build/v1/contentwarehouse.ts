// Copyright 2022 Luca Casonato. All rights reserved. MIT license.
/**
 * Document AI Warehouse API Client for Deno
 * =========================================
 * 
 * 
 * 
 * Docs: https://cloud.google.com/document-warehouse
 * Source: https://github.com/code0100fun/deno_googleapis
 */

import { auth, CredentialsClient, GoogleAuth, request } from "../../base/mod.ts";
export { auth, GoogleAuth };
export type { CredentialsClient };

export class contentWarehouse {
  #client: CredentialsClient | undefined;
  #baseUrl: string;

  constructor(client?: CredentialsClient, baseUrl: string = "https://contentwarehouse.googleapis.com/") {
    this.#client = client;
    this.#baseUrl = baseUrl;
  }

  /**
   * Gets the access control policy for a resource. Returns NOT_FOUND error if
   * the resource does not exist. Returns an empty policy if the resource exists
   * but does not have a policy set.
   *
   * @param resource Required. REQUIRED: The resource for which the policy is being requested. Format for document: projects/{project_number}/locations/{location}/documents/{document_id}. Format for project: projects/{project_number}.
   */
  async projectsFetchAcl(resource: string, req: GoogleCloudContentwarehouseV1FetchAclRequest): Promise<GoogleCloudContentwarehouseV1FetchAclResponse> {
    const url = new URL(`${this.#baseUrl}v1/${ resource }:fetchAcl`);
    const body = JSON.stringify(req);
    const data = await request(url.href, {
      client: this.#client,
      method: "POST",
      body,
    });
    return deserializeGoogleCloudContentwarehouseV1FetchAclResponse(data);
  }

  /**
   * Creates a document schema.
   *
   * @param parent Required. The parent name.
   */
  async projectsLocationsDocumentSchemasCreate(parent: string, req: GoogleCloudContentwarehouseV1DocumentSchema): Promise<GoogleCloudContentwarehouseV1DocumentSchema> {
    const url = new URL(`${this.#baseUrl}v1/${ parent }/documentSchemas`);
    const body = JSON.stringify(req);
    const data = await request(url.href, {
      client: this.#client,
      method: "POST",
      body,
    });
    return data as GoogleCloudContentwarehouseV1DocumentSchema;
  }

  /**
   * Deletes a document schema. Returns NOT_FOUND if the document schema does
   * not exist. Returns BAD_REQUEST if the document schema has documents
   * depending on it.
   *
   * @param name Required. The name of the document schema to delete.
   */
  async projectsLocationsDocumentSchemasDelete(name: string): Promise<GoogleProtobufEmpty> {
    const url = new URL(`${this.#baseUrl}v1/${ name }`);
    const data = await request(url.href, {
      client: this.#client,
      method: "DELETE",
    });
    return data as GoogleProtobufEmpty;
  }

  /**
   * Gets a document schema. Returns NOT_FOUND if the document schema does not
   * exist.
   *
   * @param name Required. The name of the document schema to retrieve.
   */
  async projectsLocationsDocumentSchemasGet(name: string): Promise<GoogleCloudContentwarehouseV1DocumentSchema> {
    const url = new URL(`${this.#baseUrl}v1/${ name }`);
    const data = await request(url.href, {
      client: this.#client,
      method: "GET",
    });
    return data as GoogleCloudContentwarehouseV1DocumentSchema;
  }

  /**
   * Lists document schemas.
   *
   * @param parent Required. The parent, which owns this collection of document schemas. Format: projects/{project_number}/locations/{location}.
   */
  async projectsLocationsDocumentSchemasList(parent: string, opts: ProjectsLocationsDocumentSchemasListOptions = {}): Promise<GoogleCloudContentwarehouseV1ListDocumentSchemasResponse> {
    const url = new URL(`${this.#baseUrl}v1/${ parent }/documentSchemas`);
    if (opts.pageSize !== undefined) {
      url.searchParams.append("pageSize", String(opts.pageSize));
    }
    if (opts.pageToken !== undefined) {
      url.searchParams.append("pageToken", String(opts.pageToken));
    }
    const data = await request(url.href, {
      client: this.#client,
      method: "GET",
    });
    return data as GoogleCloudContentwarehouseV1ListDocumentSchemasResponse;
  }

  /**
   * Updates a Document Schema. Returns INVALID_ARGUMENT if the name of the
   * Document Schema is non-empty and does not equal the existing name. Supports
   * only appending new properties, adding new ENUM possible values, and
   * updating the EnumTypeOptions.validation_check_disabled flag for ENUM
   * possible values. Updating existing properties will result into
   * INVALID_ARGUMENT.
   *
   * @param name Required. The name of the document schema to update. Format: projects/{project_number}/locations/{location}/documentSchemas/{document_schema_id}.
   */
  async projectsLocationsDocumentSchemasPatch(name: string, req: GoogleCloudContentwarehouseV1UpdateDocumentSchemaRequest): Promise<GoogleCloudContentwarehouseV1DocumentSchema> {
    const url = new URL(`${this.#baseUrl}v1/${ name }`);
    const body = JSON.stringify(req);
    const data = await request(url.href, {
      client: this.#client,
      method: "PATCH",
      body,
    });
    return data as GoogleCloudContentwarehouseV1DocumentSchema;
  }

  /**
   * Creates a document.
   *
   * @param parent Required. The parent name. Format: projects/{project_number}/locations/{location}.
   */
  async projectsLocationsDocumentsCreate(parent: string, req: GoogleCloudContentwarehouseV1CreateDocumentRequest): Promise<GoogleCloudContentwarehouseV1CreateDocumentResponse> {
    req = serializeGoogleCloudContentwarehouseV1CreateDocumentRequest(req);
    const url = new URL(`${this.#baseUrl}v1/${ parent }/documents`);
    const body = JSON.stringify(req);
    const data = await request(url.href, {
      client: this.#client,
      method: "POST",
      body,
    });
    return deserializeGoogleCloudContentwarehouseV1CreateDocumentResponse(data);
  }

  /**
   * Deletes a document. Returns NOT_FOUND if the document does not exist.
   *
   * @param name Required. The name of the document to delete. Format: projects/{project_number}/locations/{location}/documents/{document_id} or projects/{project_number}/locations/{location}/documents/referenceId/{reference_id}.
   */
  async projectsLocationsDocumentsDelete(name: string, req: GoogleCloudContentwarehouseV1DeleteDocumentRequest): Promise<GoogleProtobufEmpty> {
    const url = new URL(`${this.#baseUrl}v1/${ name }:delete`);
    const body = JSON.stringify(req);
    const data = await request(url.href, {
      client: this.#client,
      method: "POST",
      body,
    });
    return data as GoogleProtobufEmpty;
  }

  /**
   * Create a link between a source document and a target document.
   *
   * @param parent Required. Parent of the document-link to be created. parent of document-link should be a document. Format: projects/{project_number}/locations/{location}/documents/{source_document_id}.
   */
  async projectsLocationsDocumentsDocumentLinksCreate(parent: string, req: GoogleCloudContentwarehouseV1CreateDocumentLinkRequest): Promise<GoogleCloudContentwarehouseV1DocumentLink> {
    const url = new URL(`${this.#baseUrl}v1/${ parent }/documentLinks`);
    const body = JSON.stringify(req);
    const data = await request(url.href, {
      client: this.#client,
      method: "POST",
      body,
    });
    return data as GoogleCloudContentwarehouseV1DocumentLink;
  }

  /**
   * Remove the link between the source and target documents.
   *
   * @param name Required. The name of the document-link to be deleted. Format: projects/{project_number}/locations/{location}/documents/{source_document_id}/documentLinks/{document_link_id}.
   */
  async projectsLocationsDocumentsDocumentLinksDelete(name: string, req: GoogleCloudContentwarehouseV1DeleteDocumentLinkRequest): Promise<GoogleProtobufEmpty> {
    const url = new URL(`${this.#baseUrl}v1/${ name }:delete`);
    const body = JSON.stringify(req);
    const data = await request(url.href, {
      client: this.#client,
      method: "POST",
      body,
    });
    return data as GoogleProtobufEmpty;
  }

  /**
   * Gets the access control policy for a resource. Returns NOT_FOUND error if
   * the resource does not exist. Returns an empty policy if the resource exists
   * but does not have a policy set.
   *
   * @param resource Required. REQUIRED: The resource for which the policy is being requested. Format for document: projects/{project_number}/locations/{location}/documents/{document_id}. Format for project: projects/{project_number}.
   */
  async projectsLocationsDocumentsFetchAcl(resource: string, req: GoogleCloudContentwarehouseV1FetchAclRequest): Promise<GoogleCloudContentwarehouseV1FetchAclResponse> {
    const url = new URL(`${this.#baseUrl}v1/${ resource }:fetchAcl`);
    const body = JSON.stringify(req);
    const data = await request(url.href, {
      client: this.#client,
      method: "POST",
      body,
    });
    return deserializeGoogleCloudContentwarehouseV1FetchAclResponse(data);
  }

  /**
   * Gets a document. Returns NOT_FOUND if the document does not exist.
   *
   * @param name Required. The name of the document to retrieve. Format: projects/{project_number}/locations/{location}/documents/{document_id} or projects/{project_number}/locations/{location}/documents/referenceId/{reference_id}.
   */
  async projectsLocationsDocumentsGet(name: string, req: GoogleCloudContentwarehouseV1GetDocumentRequest): Promise<GoogleCloudContentwarehouseV1Document> {
    const url = new URL(`${this.#baseUrl}v1/${ name }:get`);
    const body = JSON.stringify(req);
    const data = await request(url.href, {
      client: this.#client,
      method: "POST",
      body,
    });
    return deserializeGoogleCloudContentwarehouseV1Document(data);
  }

  /**
   * Return all source document-links from the document.
   *
   * @param parent Required. The name of the document, for which all source links are returned. Format: projects/{project_number}/locations/{location}/documents/{source_document_id}.
   */
  async projectsLocationsDocumentsLinkedSources(parent: string, req: GoogleCloudContentwarehouseV1ListLinkedSourcesRequest): Promise<GoogleCloudContentwarehouseV1ListLinkedSourcesResponse> {
    const url = new URL(`${this.#baseUrl}v1/${ parent }/linkedSources`);
    const body = JSON.stringify(req);
    const data = await request(url.href, {
      client: this.#client,
      method: "POST",
      body,
    });
    return data as GoogleCloudContentwarehouseV1ListLinkedSourcesResponse;
  }

  /**
   * Return all target document-links from the document.
   *
   * @param parent Required. The name of the document, for which all target links are returned. Format: projects/{project_number}/locations/{location}/documents/{target_document_id}.
   */
  async projectsLocationsDocumentsLinkedTargets(parent: string, req: GoogleCloudContentwarehouseV1ListLinkedTargetsRequest): Promise<GoogleCloudContentwarehouseV1ListLinkedTargetsResponse> {
    const url = new URL(`${this.#baseUrl}v1/${ parent }/linkedTargets`);
    const body = JSON.stringify(req);
    const data = await request(url.href, {
      client: this.#client,
      method: "POST",
      body,
    });
    return data as GoogleCloudContentwarehouseV1ListLinkedTargetsResponse;
  }

  /**
   * Updates a document. Returns INVALID_ARGUMENT if the name of the document
   * is non-empty and does not equal the existing name.
   *
   * @param name Required. The name of the document to update. Format: projects/{project_number}/locations/{location}/documents/{document_id} or projects/{project_number}/locations/{location}/documents/referenceId/{reference_id}.
   */
  async projectsLocationsDocumentsPatch(name: string, req: GoogleCloudContentwarehouseV1UpdateDocumentRequest): Promise<GoogleCloudContentwarehouseV1UpdateDocumentResponse> {
    req = serializeGoogleCloudContentwarehouseV1UpdateDocumentRequest(req);
    const url = new URL(`${this.#baseUrl}v1/${ name }`);
    const body = JSON.stringify(req);
    const data = await request(url.href, {
      client: this.#client,
      method: "PATCH",
      body,
    });
    return deserializeGoogleCloudContentwarehouseV1UpdateDocumentResponse(data);
  }

  /**
   * Deletes a document. Returns NOT_FOUND if the document does not exist.
   *
   * @param name Required. The name of the document to delete. Format: projects/{project_number}/locations/{location}/documents/{document_id} or projects/{project_number}/locations/{location}/documents/referenceId/{reference_id}.
   */
  async projectsLocationsDocumentsReferenceIdDelete(name: string, req: GoogleCloudContentwarehouseV1DeleteDocumentRequest): Promise<GoogleProtobufEmpty> {
    const url = new URL(`${this.#baseUrl}v1/${ name }:delete`);
    const body = JSON.stringify(req);
    const data = await request(url.href, {
      client: this.#client,
      method: "POST",
      body,
    });
    return data as GoogleProtobufEmpty;
  }

  /**
   * Gets a document. Returns NOT_FOUND if the document does not exist.
   *
   * @param name Required. The name of the document to retrieve. Format: projects/{project_number}/locations/{location}/documents/{document_id} or projects/{project_number}/locations/{location}/documents/referenceId/{reference_id}.
   */
  async projectsLocationsDocumentsReferenceIdGet(name: string, req: GoogleCloudContentwarehouseV1GetDocumentRequest): Promise<GoogleCloudContentwarehouseV1Document> {
    const url = new URL(`${this.#baseUrl}v1/${ name }:get`);
    const body = JSON.stringify(req);
    const data = await request(url.href, {
      client: this.#client,
      method: "POST",
      body,
    });
    return deserializeGoogleCloudContentwarehouseV1Document(data);
  }

  /**
   * Updates a document. Returns INVALID_ARGUMENT if the name of the document
   * is non-empty and does not equal the existing name.
   *
   * @param name Required. The name of the document to update. Format: projects/{project_number}/locations/{location}/documents/{document_id} or projects/{project_number}/locations/{location}/documents/referenceId/{reference_id}.
   */
  async projectsLocationsDocumentsReferenceIdPatch(name: string, req: GoogleCloudContentwarehouseV1UpdateDocumentRequest): Promise<GoogleCloudContentwarehouseV1UpdateDocumentResponse> {
    req = serializeGoogleCloudContentwarehouseV1UpdateDocumentRequest(req);
    const url = new URL(`${this.#baseUrl}v1/${ name }`);
    const body = JSON.stringify(req);
    const data = await request(url.href, {
      client: this.#client,
      method: "PATCH",
      body,
    });
    return deserializeGoogleCloudContentwarehouseV1UpdateDocumentResponse(data);
  }

  /**
   * Searches for documents using provided SearchDocumentsRequest. This call
   * only returns documents that the caller has permission to search against.
   *
   * @param parent Required. The parent, which owns this collection of documents. Format: projects/{project_number}/locations/{location}.
   */
  async projectsLocationsDocumentsSearch(parent: string, req: GoogleCloudContentwarehouseV1SearchDocumentsRequest): Promise<GoogleCloudContentwarehouseV1SearchDocumentsResponse> {
    req = serializeGoogleCloudContentwarehouseV1SearchDocumentsRequest(req);
    const url = new URL(`${this.#baseUrl}v1/${ parent }/documents:search`);
    const body = JSON.stringify(req);
    const data = await request(url.href, {
      client: this.#client,
      method: "POST",
      body,
    });
    return deserializeGoogleCloudContentwarehouseV1SearchDocumentsResponse(data);
  }

  /**
   * Sets the access control policy for a resource. Replaces any existing
   * policy.
   *
   * @param resource Required. REQUIRED: The resource for which the policy is being requested. Format for document: projects/{project_number}/locations/{location}/documents/{document_id}. Format for project: projects/{project_number}.
   */
  async projectsLocationsDocumentsSetAcl(resource: string, req: GoogleCloudContentwarehouseV1SetAclRequest): Promise<GoogleCloudContentwarehouseV1SetAclResponse> {
    req = serializeGoogleCloudContentwarehouseV1SetAclRequest(req);
    const url = new URL(`${this.#baseUrl}v1/${ resource }:setAcl`);
    const body = JSON.stringify(req);
    const data = await request(url.href, {
      client: this.#client,
      method: "POST",
      body,
    });
    return deserializeGoogleCloudContentwarehouseV1SetAclResponse(data);
  }

  /**
   * Provisions resources for given tenant project. Returns a long running
   * operation.
   *
   * @param location Required. The location to be initialized Format: projects/{project_number}/locations/{location}.
   */
  async projectsLocationsInitialize(location: string, req: GoogleCloudContentwarehouseV1InitializeProjectRequest): Promise<GoogleLongrunningOperation> {
    const url = new URL(`${this.#baseUrl}v1/${ location }:initialize`);
    const body = JSON.stringify(req);
    const data = await request(url.href, {
      client: this.#client,
      method: "POST",
      body,
    });
    return data as GoogleLongrunningOperation;
  }

  /**
   * Gets the latest state of a long-running operation. Clients can use this
   * method to poll the operation result at intervals as recommended by the API
   * service.
   *
   * @param name The name of the operation resource.
   */
  async projectsLocationsOperationsGet(name: string): Promise<GoogleLongrunningOperation> {
    const url = new URL(`${this.#baseUrl}v1/${ name }`);
    const data = await request(url.href, {
      client: this.#client,
      method: "GET",
    });
    return data as GoogleLongrunningOperation;
  }

  /**
   * Creates a ruleset.
   *
   * @param parent Required. The parent name. Format: projects/{project_number}/locations/{location}.
   */
  async projectsLocationsRuleSetsCreate(parent: string, req: GoogleCloudContentwarehouseV1RuleSet): Promise<GoogleCloudContentwarehouseV1RuleSet> {
    req = serializeGoogleCloudContentwarehouseV1RuleSet(req);
    const url = new URL(`${this.#baseUrl}v1/${ parent }/ruleSets`);
    const body = JSON.stringify(req);
    const data = await request(url.href, {
      client: this.#client,
      method: "POST",
      body,
    });
    return deserializeGoogleCloudContentwarehouseV1RuleSet(data);
  }

  /**
   * Deletes a ruleset. Returns NOT_FOUND if the document does not exist.
   *
   * @param name Required. The name of the rule set to delete. Format: projects/{project_number}/locations/{location}/ruleSets/{rule_set_id}.
   */
  async projectsLocationsRuleSetsDelete(name: string): Promise<GoogleProtobufEmpty> {
    const url = new URL(`${this.#baseUrl}v1/${ name }`);
    const data = await request(url.href, {
      client: this.#client,
      method: "DELETE",
    });
    return data as GoogleProtobufEmpty;
  }

  /**
   * Gets a ruleset. Returns NOT_FOUND if the ruleset does not exist.
   *
   * @param name Required. The name of the rule set to retrieve. Format: projects/{project_number}/locations/{location}/ruleSets/{rule_set_id}.
   */
  async projectsLocationsRuleSetsGet(name: string): Promise<GoogleCloudContentwarehouseV1RuleSet> {
    const url = new URL(`${this.#baseUrl}v1/${ name }`);
    const data = await request(url.href, {
      client: this.#client,
      method: "GET",
    });
    return deserializeGoogleCloudContentwarehouseV1RuleSet(data);
  }

  /**
   * Lists rulesets.
   *
   * @param parent Required. The parent, which owns this collection of document. Format: projects/{project_number}/locations/{location}.
   */
  async projectsLocationsRuleSetsList(parent: string, opts: ProjectsLocationsRuleSetsListOptions = {}): Promise<GoogleCloudContentwarehouseV1ListRuleSetsResponse> {
    const url = new URL(`${this.#baseUrl}v1/${ parent }/ruleSets`);
    if (opts.pageSize !== undefined) {
      url.searchParams.append("pageSize", String(opts.pageSize));
    }
    if (opts.pageToken !== undefined) {
      url.searchParams.append("pageToken", String(opts.pageToken));
    }
    const data = await request(url.href, {
      client: this.#client,
      method: "GET",
    });
    return deserializeGoogleCloudContentwarehouseV1ListRuleSetsResponse(data);
  }

  /**
   * Updates a ruleset. Returns INVALID_ARGUMENT if the name of the ruleset is
   * non-empty and does not equal the existing name.
   *
   * @param name Required. The name of the rule set to update. Format: projects/{project_number}/locations/{location}/ruleSets/{rule_set_id}.
   */
  async projectsLocationsRuleSetsPatch(name: string, req: GoogleCloudContentwarehouseV1UpdateRuleSetRequest): Promise<GoogleCloudContentwarehouseV1RuleSet> {
    req = serializeGoogleCloudContentwarehouseV1UpdateRuleSetRequest(req);
    const url = new URL(`${this.#baseUrl}v1/${ name }`);
    const body = JSON.stringify(req);
    const data = await request(url.href, {
      client: this.#client,
      method: "PATCH",
      body,
    });
    return deserializeGoogleCloudContentwarehouseV1RuleSet(data);
  }

  /**
   * Run a predefined pipeline.
   *
   * @param name Required. The resource name which owns the resources of the pipeline. Format: projects/{project_number}/locations/{location}.
   */
  async projectsLocationsRunPipeline(name: string, req: GoogleCloudContentwarehouseV1RunPipelineRequest): Promise<GoogleLongrunningOperation> {
    const url = new URL(`${this.#baseUrl}v1/${ name }:runPipeline`);
    const body = JSON.stringify(req);
    const data = await request(url.href, {
      client: this.#client,
      method: "POST",
      body,
    });
    return data as GoogleLongrunningOperation;
  }

  /**
   * Creates a SynonymSet for a single context. Throws an ALREADY_EXISTS
   * exception if a synonymset already exists for the context.
   *
   * @param parent Required. The parent name. Format: projects/{project_number}/locations/{location}.
   */
  async projectsLocationsSynonymSetsCreate(parent: string, req: GoogleCloudContentwarehouseV1SynonymSet): Promise<GoogleCloudContentwarehouseV1SynonymSet> {
    const url = new URL(`${this.#baseUrl}v1/${ parent }/synonymSets`);
    const body = JSON.stringify(req);
    const data = await request(url.href, {
      client: this.#client,
      method: "POST",
      body,
    });
    return data as GoogleCloudContentwarehouseV1SynonymSet;
  }

  /**
   * Deletes a SynonymSet for a given context. Throws a NOT_FOUND exception if
   * the SynonymSet is not found.
   *
   * @param name Required. The name of the synonymSet to delete Format: projects/{project_number}/locations/{location}/synonymSets/{context}.
   */
  async projectsLocationsSynonymSetsDelete(name: string): Promise<GoogleProtobufEmpty> {
    const url = new URL(`${this.#baseUrl}v1/${ name }`);
    const data = await request(url.href, {
      client: this.#client,
      method: "DELETE",
    });
    return data as GoogleProtobufEmpty;
  }

  /**
   * Gets a SynonymSet for a particular context. Throws a NOT_FOUND exception
   * if the Synonymset does not exist
   *
   * @param name Required. The name of the synonymSet to retrieve Format: projects/{project_number}/locations/{location}/synonymSets/{context}.
   */
  async projectsLocationsSynonymSetsGet(name: string): Promise<GoogleCloudContentwarehouseV1SynonymSet> {
    const url = new URL(`${this.#baseUrl}v1/${ name }`);
    const data = await request(url.href, {
      client: this.#client,
      method: "GET",
    });
    return data as GoogleCloudContentwarehouseV1SynonymSet;
  }

  /**
   * Returns all SynonymSets (for all contexts) for the specified location.
   *
   * @param parent Required. The parent name. Format: projects/{project_number}/locations/{location}.
   */
  async projectsLocationsSynonymSetsList(parent: string, opts: ProjectsLocationsSynonymSetsListOptions = {}): Promise<GoogleCloudContentwarehouseV1ListSynonymSetsResponse> {
    const url = new URL(`${this.#baseUrl}v1/${ parent }/synonymSets`);
    if (opts.pageSize !== undefined) {
      url.searchParams.append("pageSize", String(opts.pageSize));
    }
    if (opts.pageToken !== undefined) {
      url.searchParams.append("pageToken", String(opts.pageToken));
    }
    const data = await request(url.href, {
      client: this.#client,
      method: "GET",
    });
    return data as GoogleCloudContentwarehouseV1ListSynonymSetsResponse;
  }

  /**
   * Remove the existing SynonymSet for the context and replaces it with a new
   * one. Throws a NOT_FOUND exception if the SynonymSet is not found.
   *
   * @param name Required. The name of the synonymSet to update Format: projects/{project_number}/locations/{location}/synonymSets/{context}.
   */
  async projectsLocationsSynonymSetsPatch(name: string, req: GoogleCloudContentwarehouseV1SynonymSet): Promise<GoogleCloudContentwarehouseV1SynonymSet> {
    const url = new URL(`${this.#baseUrl}v1/${ name }`);
    const body = JSON.stringify(req);
    const data = await request(url.href, {
      client: this.#client,
      method: "PATCH",
      body,
    });
    return data as GoogleCloudContentwarehouseV1SynonymSet;
  }

  /**
   * Sets the access control policy for a resource. Replaces any existing
   * policy.
   *
   * @param resource Required. REQUIRED: The resource for which the policy is being requested. Format for document: projects/{project_number}/locations/{location}/documents/{document_id}. Format for project: projects/{project_number}.
   */
  async projectsSetAcl(resource: string, req: GoogleCloudContentwarehouseV1SetAclRequest): Promise<GoogleCloudContentwarehouseV1SetAclResponse> {
    req = serializeGoogleCloudContentwarehouseV1SetAclRequest(req);
    const url = new URL(`${this.#baseUrl}v1/${ resource }:setAcl`);
    const body = JSON.stringify(req);
    const data = await request(url.href, {
      client: this.#client,
      method: "POST",
      body,
    });
    return deserializeGoogleCloudContentwarehouseV1SetAclResponse(data);
  }
}

export interface AbuseiamAbuseType {
  id?:  | "NONE" | "OTHER_ABUSE" | "CHILD_PORN" | "PORNOGRAPHY" | "SPAM" | "PHISHING" | "HATE" | "TOS_OTHER" | "MALWARE" | "MALICIOUS_JAVASCRIPT" | "NOT_FAMILY_SAFE" | "IMPERSONATION" | "PEDOPHILIA" | "PERSONAL_INFO" | "COPYRIGHT" | "HIGH_RISK" | "VIOLENCE" | "UNSAFE_RACY" | "UNSAFE_OTHER" | "FAKE_USER" | "NAME_VIOLATION" | "PLUSONE_VIOLATION" | "DEFAMATION" | "TRADEMARK" | "COURT_ORDER" | "GOVERNMENT_ORDER" | "LOCAL_LAWS" | "PRIVACY" | "ES_BLACKLIST" | "ES_COMMENTS_BLACKLIST" | "HARASSMENT" | "COMPROMISED" | "LOW_QUALITY" | "API_VIOLATION" | "REGULATED" | "CAROUSEL_FRAME_BLACKLIST" | "QUOTA_EXCEEDED" | "FOUNTAIN_BLACKLIST" | "COPPA_REGULATED" | "DOXXING" | "SOFT_HATE" | "SOFT_HARASSMENT" | "OBNOXIOUS" | "UNWANTED" | "NOT_UNICORN_SAFE" | "FAKE_ENGAGEMENT" | "COUNTERFEIT" | "CTM";
  /**
   * Optional client specific subtype of abuse that is too specific to belong
   * in the above enumeration. For example, some client may want to
   * differentiate nudity from graphic sex, but both are PORNOGRAPHY.
   */
  subtype?: string;
}

export interface AbuseiamAgeRestriction {
  /**
   * This restriction applies if the user is between [min_age_years, age_years)
   * years old.
   */
  ageYears?: number;
  minAgeYears?: number;
}

export interface AbuseiamAndRestriction {
  /**
   * This restriction applies if all of the children apply.
   */
  child?: AbuseiamUserRestriction[];
}

/**
 * A client is be a Google product, or subproduct that provides content for
 * AbuseIAm to classify.
 */
export interface AbuseiamClient {
  id?:  | "ABUSE_TEAM" | "SQE" | "SEARCH" | "POSTINI" | "BLOGGER" | "ORKUT" | "ZIPIT" | "GROUPS" | "RIPTIDE" | "GADGETS" | "SITES" | "READER" | "DOCS" | "U2U" | "YOUTUBE" | "POPTART" | "COSMO" | "PROFILES" | "KNOL" | "SKETCHUP" | "CALENDAR" | "HOTSHOTS" | "TRIKI" | "MAPS" | "COMMUNITY_TRANSLATION" | "WRITELY" | "SPREADSHEET_FORM" | "SPREADSHEET" | "EXPLORER" | "FINANCE" | "GMR" | "LAIBA" | "CONFUCIUS" | "PRESENTATION" | "CHROME_EXTENSION" | "WENDA" | "TACOTOWN" | "KRAKEN" | "URL_SHORTENER" | "WAREHOUSE" | "ANDROID_VM" | "CODESITE" | "FRIEND_CONNECT" | "GEOWIKI" | "GOOGLE_LABS" | "HELP_CENTER" | "SEARCHWIKI" | "SIDEWIKI" | "TOPIC_SEARCH" | "VIDEO" | "GOOGLEBASE" | "FEEDBURNER" | "PUBLISHER_QUALITY" | "NOTEBOOK" | "SMARTLISTS" | "ENTERPRISE_MARKETPLACE" | "BOOKS" | "IGOOGLE" | "USENET" | "TRANSLATE" | "PERFECT_STREAM" | "PHOTOS" | "AFMA" | "LIKES" | "QUESTIONS" | "SKYJAM" | "MIC" | "ANDROID_MARKET" | "CHROME_WEBSTORE" | "FINSKY" | "BARNOWL" | "STREET_VIEW" | "ADCONNECT" | "ES" | "HELLO" | "TRADER" | "SCHEMER" | "ANDROID" | "MINE" | "GAIA" | "GOGGLES" | "SIGNUP" | "BABEL" | "CHECKOUT" | "TASTEMAKER" | "STRATUS" | "DRAGONFLY" | "APIARY" | "CAROUSEL" | "FOUNTAIN" | "GEOPIX" | "VILLAGE" | "KIX" | "AMARNA" | "GINKGO" | "TEE" | "SHOPPING" | "SLAM" | "APPENGINE" | "GUNS" | "CULTURAL" | "COMPUTEENGINE" | "BIGSTORE" | "COPACABANA" | "ANALYTICS" | "GRANDCENTRAL" | "GMAIL" | "GLASS" | "CRISIS_RESPONSE" | "GJOBS" | "HAZMAT" | "SAFE_BROWSING" | "CLOUD" | "PANTHEON" | "CLUSTER" | "KEEP" | "APP_HISTORY" | "COMMERCIAL_ENTITY" | "ARES_DATA_PROVIDER" | "ARES_DATA_WRITER" | "BIZBUILDER" | "RITZ" | "POLLS" | "APPINVITE";
  /**
   * The name of the subservice within a client. This subservice can be used to
   * affect the flow of decision script, or selection of backend classifiers.
   * For example, StreetView may want to specify a panel is insufficiently
   * blurred (maybe there is a lisense plate or public sex, etc), which requires
   * manual review then the subservice might be "blurring".
   */
  subservice?: string;
}

/**
 * Extra information regarding evaluations received through cluster review.
 */
export interface AbuseiamClusterEvaluationContext {
  /**
   * The family of the cluster where the case received the evaluation.
   */
  clusterFamily?: string;
  /**
   * The AbuseIAm rowkey of the cluster where the case received an evaluation.
   */
  clusterRowkey?: string;
  /**
   * The gaia id of a mail box that ops can send inquiries to for appeals. Used
   * only by user clusters to fill a required gatekeeper param. See
   * gaia_disableserver.DisableSpec.escalate_to field.
   */
  gaiaIdToEscalate?: bigint;
}

function serializeAbuseiamClusterEvaluationContext(data: any): AbuseiamClusterEvaluationContext {
  return {
    ...data,
    gaiaIdToEscalate: data["gaiaIdToEscalate"] !== undefined ? String(data["gaiaIdToEscalate"]) : undefined,
  };
}

function deserializeAbuseiamClusterEvaluationContext(data: any): AbuseiamClusterEvaluationContext {
  return {
    ...data,
    gaiaIdToEscalate: data["gaiaIdToEscalate"] !== undefined ? BigInt(data["gaiaIdToEscalate"]) : undefined,
  };
}

export interface AbuseiamConstantRestriction {
  /**
   * A constant of type TRUE always applies, and of type FALSE never applies.
   */
  type?:  | "ALWAYS_TRUE" | "ALWAYS_FALSE";
}

/**
 * Pair of Verdicts used for ProjectR age/geo gating. See http://go/projectr
 * for more information.
 */
export interface AbuseiamContentRestriction {
  /**
   * Takedowns specified by admins via AbuseIAm
   */
  adminVerdict?: AbuseiamVerdict[];
  /**
   * User-specified takedowns
   */
  userVerdict?: AbuseiamVerdict[];
}

function serializeAbuseiamContentRestriction(data: any): AbuseiamContentRestriction {
  return {
    ...data,
    adminVerdict: data["adminVerdict"] !== undefined ? data["adminVerdict"].map((item: any) => (serializeAbuseiamVerdict(item))) : undefined,
    userVerdict: data["userVerdict"] !== undefined ? data["userVerdict"].map((item: any) => (serializeAbuseiamVerdict(item))) : undefined,
  };
}

function deserializeAbuseiamContentRestriction(data: any): AbuseiamContentRestriction {
  return {
    ...data,
    adminVerdict: data["adminVerdict"] !== undefined ? data["adminVerdict"].map((item: any) => (deserializeAbuseiamVerdict(item))) : undefined,
    userVerdict: data["userVerdict"] !== undefined ? data["userVerdict"].map((item: any) => (deserializeAbuseiamVerdict(item))) : undefined,
  };
}

/**
 * Backends return Evaluations to AbuseIAm. One of the things Evaluations are
 * used for is to explain Verdicts.
 */
export interface AbuseiamEvaluation {
  abuseType?: AbuseiamAbuseType;
  /**
   * Who creates this Evaluation. This field is required.
   */
  backend?:  | "UNKNOWN" | "ADMIN" | "GRADS" | "OCELOT" | "SPAMIAM" | "MANUAL_REVIEW" | "MAWLER" | "SNEAKY_JS" | "DOWNLOADER" | "PORN_CLASSIFIER" | "GIBBERISH_DETECTOR" | "ANTIVIRUS" | "GAUSS" | "REALUSERS" | "USERRANK" | "GRADS_AGGRESSIVE" | "BULK_ACTION" | "BADWORD" | "GAIA" | "LINKS_COUNT" | "RE_RULE" | "SLAM" | "AUTHORRANK" | "USERRANK_BADNESS" | "GAUSS_EXPLICIT" | "GAUSS_IMPLICIT" | "RETRIEVE_MESSAGE" | "SPAM_REPORT" | "SQUEAL" | "BLOGGER_LOGS" | "TRUSTRANK_PHISHING" | "CATFOOD" | "IMAGE_PORN_CLASSIFIER" | "OCELOT_IMPORT" | "FIFE_IMAGE_FETCHER" | "FAST_RISING_FEATURES" | "BOTGUARD" | "NAME_CHECKER" | "CHEETAH" | "GALLIFREY" | "OCELOT_DELETE" | "RULE" | "FOCUS" | "VIDEO_THUMBNAILER" | "PATTERNLIST" | "METADATA" | "METADATA_IMPORT" | "NAME_DETECTOR" | "SHINGLE_COMPUTER" | "WIGGUM" | "BINARY_EXPLORATION" | "REVNET" | "FURS" | "YOUTUBE_CLASSIFIER" | "IDV" | "CLUSTERCAT" | "CHEETAH_IMPORT" | "CHEETAH_READ" | "BOTGUARD_DECODE" | "QUOTASERVER" | "YOUTUBE" | "BLOGGER" | "SOCIAL_GRAPH" | "WEB_SIGNALS" | "TRAWLER" | "NOTIFICATIONS" | "CASES" | "BADURLS" | "LINK_IMPORT" | "SHINGLE_DEDUPER" | "DEV_CONSOLE" | "METADATA_QUERY" | "PLUS_PAGE" | "YOUTUBE_VIDEO_INFO" | "GOOGLE_ADMIN" | "RESPAY" | "COOKBOOK" | "EASY_LEARN" | "QUALITY_SAMPLER" | "BLOBSTORE" | "OWNER" | "POLICY" | "EXTERNAL" | "ABUSEIAM_FEEDBACK" | "BIGSTORE" | "PHOTO_SERVICE" | "GRADS_RELATED" | "REAPER" | "GATEKEEPER" | "VIPER" | "MSISDN" | "VIDEO_REVIEW" | "CSAI_MATCH" | "REDQUEEN" | "STREAMER_INDEXER" | "DREMEL" | "VISUAL_SEARCH_SERVICE_PORN" | "VISUAL_SEARCH_SERVICE_OCR" | "IMPLICIT_SOCIAL_GRAPH" | "EASY_LEARN_BLEND" | "USER_AURA" | "GOOPS" | "ANDROID_CHECKIN" | "ARES_DATA_PROVIDER" | "DROIDGUARD_VERDICT" | "ARES_DATA_WRITER" | "ADAPTIVE_QUOTA" | "AIAPLX" | "INFAME" | "ARES" | "VISUAL_SEARCH_SERVICE_ICA" | "VISUAL_SEARCH_SERVICE_BUTTON_DETECTION" | "VISUAL_SEARCH_SERVICE_LOGO_DETECTION";
  /**
   * Extra information regarding the cluster review context where the case
   * received the evaluation.
   */
  clusterEvaluationContext?: AbuseiamClusterEvaluationContext;
  /**
   * Backends can choose to put some debug info in addition to abuse_type,
   * score, and status.
   */
  comment?: string;
  /**
   * A set of repeated features to allow adapters to return semi structured
   * data. Please, prefer using feature instead of the old misc_data field since
   * it supports richer and more structured data to be passed back.
   */
  feature?: AbuseiamFeature[];
  /**
   * Information about the manual review, for manual review evaluations. Do NOT
   * expect this field to be set if `backend != MANUAL_REVIEW`.
   */
  manualReviewInfo?: AbuseiamManualReviewEvaluationInfo;
  /**
   * This field is used to store miscellaneous information that Backend might
   * provide. If you find youself here considering to use this field, please
   * prefer using the repeated feature field below instead. It supports a richer
   * structure for passing complex data back from the backend.
   */
  miscData?: AbuseiamNameValuePair[];
  /**
   * When the evaluation was processed by the decision script.
   */
  processedMicros?: bigint;
  /**
   * Time in milliseconds when the Backend processed this Evaluation.
   */
  processTimeMillisecs?: bigint;
  /**
   * The list of regions where the evaluation applies.
   */
  region?: AbuseiamRegion[];
  score?: number;
  status?:  | "OK" | "ERROR";
  target?: AbuseiamTarget;
  /**
   * When the Evaluation was generated.
   */
  timestampMicros?: bigint;
  /**
   * A boolean expression tree used to define the restrictions where the
   * verdict applies. Please use
   * java/com/google/ccc/abuse/abuseiam/client/TakedownManager.java to evaluate
   * this proto.
   */
  userRestriction?: AbuseiamUserRestriction;
  /**
   * Version of Backend. For rules, this string is the only way to
   * differentiate between them.
   */
  version?: string;
  /**
   * Information about the video review, for video review evaluations. Do NOT
   * expect this field to be set if `backend != VIDEO_REVIEW`.
   */
  videoReviewData?: AbuseiamVideoReviewData;
}

function serializeAbuseiamEvaluation(data: any): AbuseiamEvaluation {
  return {
    ...data,
    clusterEvaluationContext: data["clusterEvaluationContext"] !== undefined ? serializeAbuseiamClusterEvaluationContext(data["clusterEvaluationContext"]) : undefined,
    feature: data["feature"] !== undefined ? data["feature"].map((item: any) => (serializeAbuseiamFeature(item))) : undefined,
    miscData: data["miscData"] !== undefined ? data["miscData"].map((item: any) => (serializeAbuseiamNameValuePair(item))) : undefined,
    processedMicros: data["processedMicros"] !== undefined ? String(data["processedMicros"]) : undefined,
    processTimeMillisecs: data["processTimeMillisecs"] !== undefined ? String(data["processTimeMillisecs"]) : undefined,
    timestampMicros: data["timestampMicros"] !== undefined ? String(data["timestampMicros"]) : undefined,
    videoReviewData: data["videoReviewData"] !== undefined ? serializeAbuseiamVideoReviewData(data["videoReviewData"]) : undefined,
  };
}

function deserializeAbuseiamEvaluation(data: any): AbuseiamEvaluation {
  return {
    ...data,
    clusterEvaluationContext: data["clusterEvaluationContext"] !== undefined ? deserializeAbuseiamClusterEvaluationContext(data["clusterEvaluationContext"]) : undefined,
    feature: data["feature"] !== undefined ? data["feature"].map((item: any) => (deserializeAbuseiamFeature(item))) : undefined,
    miscData: data["miscData"] !== undefined ? data["miscData"].map((item: any) => (deserializeAbuseiamNameValuePair(item))) : undefined,
    processedMicros: data["processedMicros"] !== undefined ? BigInt(data["processedMicros"]) : undefined,
    processTimeMillisecs: data["processTimeMillisecs"] !== undefined ? BigInt(data["processTimeMillisecs"]) : undefined,
    timestampMicros: data["timestampMicros"] !== undefined ? BigInt(data["timestampMicros"]) : undefined,
    videoReviewData: data["videoReviewData"] !== undefined ? deserializeAbuseiamVideoReviewData(data["videoReviewData"]) : undefined,
  };
}

export interface AbuseiamFeature {
  /**
   * Exactly one of the following should be filled in.
   */
  booleanValue?: boolean;
  doubleValue?: number;
  /**
   * Useful for applications that need to know how many times a specific
   * feature occurs
   */
  featureCount?: bigint;
  /**
   * Useful for timestamps, or for numerical features where it is helpful for
   * decision scripts to have exact values.
   */
  int64Value?: bigint;
  /**
   * integer value field is deprecated and shall only be used for passing the
   * following features hardcoded in spamiam::SpamIAmMessage:
   * spamiam::OrkutSenderId spamiam::OrkutPostnumReports
   * spamiam::BloggerNumComments spamiam::BloggerNumCommentsByOthers Another
   * hard-coded spamiam feature is spamiam::BlogName, which can be specified via
   * string value.
   */
  integerValue?: number;
  name?: string;
  stringValue?: string[];
  /**
   * This field should only be used to store a sequence of timestamps
   * associated with the feature.
   */
  timestampSequence?: bigint[];
}

function serializeAbuseiamFeature(data: any): AbuseiamFeature {
  return {
    ...data,
    featureCount: data["featureCount"] !== undefined ? String(data["featureCount"]) : undefined,
    int64Value: data["int64Value"] !== undefined ? String(data["int64Value"]) : undefined,
    timestampSequence: data["timestampSequence"] !== undefined ? data["timestampSequence"].map((item: any) => (String(item))) : undefined,
  };
}

function deserializeAbuseiamFeature(data: any): AbuseiamFeature {
  return {
    ...data,
    featureCount: data["featureCount"] !== undefined ? BigInt(data["featureCount"]) : undefined,
    int64Value: data["int64Value"] !== undefined ? BigInt(data["int64Value"]) : undefined,
    timestampSequence: data["timestampSequence"] !== undefined ? data["timestampSequence"].map((item: any) => (BigInt(item))) : undefined,
  };
}

/**
 * A node representing a table of regions and restrictions that apply to those
 * regions. This table understands region inclusion and knows to apply the most
 * specific rule, for example, a rule for France would override a rule for the
 * EU for a user in France.
 */
export interface AbuseiamGeoRestriction {
  locale?: AbuseiamGeoRestrictionLocale[];
}

export interface AbuseiamGeoRestrictionLocale {
  /**
   * The location where the restriction applies. Defaults to the "The world".
   * See go/iii.
   */
  location?: string;
  /**
   * The UserRestriction that applies to this location. If not specified
   * evaluates to true.
   */
  restriction?: AbuseiamUserRestriction;
}

/**
 * Information about various hashes that can be computed on a message ex:
 * simhash, attachment hash, etc
 */
export interface AbuseiamHash {
  /**
   * 64 bit hash in the hex form.
   */
  hash?: string;
  type?: string;
}

export interface AbuseiamManualReviewerInfo {
  credential?:  | "UNKNOWN" | "LEGAL" | "POLICY" | "ANALYST" | "LEGAL_PANEL"[];
  username?: string;
}

/**
 * Relevant information for manual review evaluations.
 */
export interface AbuseiamManualReviewEvaluationInfo {
  /**
   * Reviewer performing the manual review.
   */
  reviewer?: AbuseiamManualReviewerInfo;
  /**
   * Tool used to perform the manual review.
   */
  tool?: AbuseiamManualReviewTool;
}

export interface AbuseiamManualReviewTool {
  experimentId?: string;
  name?:  | "UNKNOWN" | "NUFF" | "GOOGLE_ADMIN" | "YOUTUBE";
}

export interface AbuseiamNameValuePair {
  name?: string;
  nonUtf8Value?: Uint8Array;
  value?: string;
}

function serializeAbuseiamNameValuePair(data: any): AbuseiamNameValuePair {
  return {
    ...data,
    nonUtf8Value: data["nonUtf8Value"] !== undefined ? encodeBase64(data["nonUtf8Value"]) : undefined,
  };
}

function deserializeAbuseiamNameValuePair(data: any): AbuseiamNameValuePair {
  return {
    ...data,
    nonUtf8Value: data["nonUtf8Value"] !== undefined ? decodeBase64(data["nonUtf8Value"] as string) : undefined,
  };
}

export interface AbuseiamNotRestriction {
  /**
   * This restriction applies if the child does not apply. Only one is allowed.
   * "repeated" is used to avoid breaking Sawzall (See b/6758277).
   */
  child?: AbuseiamUserRestriction[];
}

export interface AbuseiamOrRestriction {
  /**
   * This restriction applies if any of the children apply.
   */
  child?: AbuseiamUserRestriction[];
}

export interface AbuseiamRegion {
  /**
   * This is a CLDR Region Code: http://wiki/Main/IIIHowTo#using_region It is
   * used to denote the region affected by a verdict.
   */
  region?: string;
}

/**
 * A SpecialRestriction is a standardized UserRestriction which lives in a
 * table maintained via CDD.
 */
export interface AbuseiamSpecialRestriction {
  type?:  | "ALCOHOL";
}

export interface AbuseiamTarget {
  id?: string;
  type?:  | "MESSAGE_ID" | "CHUNK_ID" | "IMAGE_URL" | "URL" | "USER_ID" | "IP" | "SITE" | "SITEDOMAIN" | "ENTITY_ID" | "PERFECT_STREAM_ID" | "ACTIVITY_ID" | "COMMENT_ID" | "AD_ID" | "TEXT" | "TEXT_FRAGMENT" | "CLUSTER_MEMBER_ID" | "EMBED_ID" | "ANDROID_ID";
}

/**
 * A structure used to configure a notification to a user.
 */
export interface AbuseiamUserNotification {
  channel?:  | "UNKNOWN" | "BUILT_IN" | "EMAIL" | "GAIA";
}

/**
 * Describes restrictions on where the verdict applies. Please use {@code
 * TakedownManager} to evaluate this proto.
 */
export interface AbuseiamUserRestriction {
  ageRestriction?: AbuseiamAgeRestriction;
  /**
   * Operators
   */
  andRestriction?: AbuseiamAndRestriction;
  /**
   * Constant
   */
  constantRestriction?: AbuseiamConstantRestriction;
  /**
   * Leaf Nodes
   */
  geoRestriction?: AbuseiamGeoRestriction;
  notRestriction?: AbuseiamNotRestriction;
  orRestriction?: AbuseiamOrRestriction;
  specialRestriction?: AbuseiamSpecialRestriction;
}

/**
 * Verdict against a target. AbuseIAm generates a verdict based on evaluations.
 * AbuseIAm can send such verdicts to clients for enforcement.
 */
export interface AbuseiamVerdict {
  /**
   * Target client of the verdict. It can be used to differentiate verdicts
   * from multiple clients when such verdicts are processed in one common place.
   */
  client?: AbuseiamClient;
  /**
   * Additional info regarding the verdict.
   */
  comment?: string;
  decision?:  | "ERROR" | "NO_ACTION" | "GOOD" | "DELETE" | "INTERSTITIAL" | "HIDE" | "BLACK_LIST" | "MARK_AS_SPAM" | "REWRITE_LINKS" | "HIDE_AND_NOTIFY" | "FREEZE_SERVICE" | "SUSPEND_SERVICE" | "SMS_DISABLE" | "NOTIFY";
  /**
   * Time duration (in minutes) of the verdict.
   */
  durationMins?: number;
  /**
   * Evaluations relevant to this verdict. Every Verdict should contain at
   * least one Evaluation.
   */
  evaluation?: AbuseiamEvaluation[];
  /**
   * Details of all the hashes that can be computed on a message, such as
   * simhash and attachment hash
   */
  hashes?: AbuseiamHash[];
  /**
   * Is this verdict issued by legal?
   */
  isLegalIssued?: boolean;
  /**
   * This field is used to pass relevant / necessary scores to our clients. For
   * eg: ASBE propogates these scores to moonshine.
   */
  miscScores?: AbuseiamNameValuePair[];
  /**
   * A short description of the reason why the verdict decision is made.
   */
  reasonCode?: string;
  /**
   * The regions in which this verdict should be enforced. Absence of this
   * field indicates that the verdict is applicable everywhere.
   */
  region?: AbuseiamRegion[];
  /**
   * Restrictions on where this verdict applies. If any restriction is met, the
   * verdict is applied there. If no restrictions are present, the verdict is
   * considered global.
   */
  restriction?: AbuseiamVerdictRestriction[];
  /**
   * Category of the strike if this is a strike verdict.
   */
  strikeCategory?:  | "ES" | "CP" | "COPYRIGHT" | "BLOGGER" | "GRANDCENTRAL" | "DRIVE" | "CLOUD" | "SITES";
  target?: AbuseiamTarget;
  /**
   * The timestamp of the target. E.g., the time when the target was updated.
   */
  targetTimestampMicros?: bigint;
  /**
   * When the verdict is generated
   */
  timestampMicros?: bigint;
  /**
   * Extra notification(s) to be delivered to target user or message owner
   * about the verdict.
   */
  userNotification?: AbuseiamUserNotification[];
  /**
   * version of decision script
   */
  version?: string;
}

function serializeAbuseiamVerdict(data: any): AbuseiamVerdict {
  return {
    ...data,
    evaluation: data["evaluation"] !== undefined ? data["evaluation"].map((item: any) => (serializeAbuseiamEvaluation(item))) : undefined,
    miscScores: data["miscScores"] !== undefined ? data["miscScores"].map((item: any) => (serializeAbuseiamNameValuePair(item))) : undefined,
    targetTimestampMicros: data["targetTimestampMicros"] !== undefined ? String(data["targetTimestampMicros"]) : undefined,
    timestampMicros: data["timestampMicros"] !== undefined ? String(data["timestampMicros"]) : undefined,
  };
}

function deserializeAbuseiamVerdict(data: any): AbuseiamVerdict {
  return {
    ...data,
    evaluation: data["evaluation"] !== undefined ? data["evaluation"].map((item: any) => (deserializeAbuseiamEvaluation(item))) : undefined,
    miscScores: data["miscScores"] !== undefined ? data["miscScores"].map((item: any) => (deserializeAbuseiamNameValuePair(item))) : undefined,
    targetTimestampMicros: data["targetTimestampMicros"] !== undefined ? BigInt(data["targetTimestampMicros"]) : undefined,
    timestampMicros: data["timestampMicros"] !== undefined ? BigInt(data["timestampMicros"]) : undefined,
  };
}

/**
 * Describes restrictions on where the verdict applies.
 */
export interface AbuseiamVerdictRestriction {
  /**
   * For a restriction to apply, all contexts must be satisfied. For example,
   * if context[0] is COUNTRY/'GERMANY' and context[1] is
   * DESTINATION_STREAM/'gplus:SQUARE:knitting_discussion', then the verdict
   * applies only when the 'knitting discussion' square is viewed from inside
   * Germany. Please note that this is present for legacy reasons and users of
   * this field would be migrated to use the user_restriction field defined
   * below.
   */
  context?: AbuseiamVerdictRestrictionContext[];
  /**
   * A boolean expression tree used to define the restrictions where the
   * verdict applies. Please use
   * java/com/google/ccc/abuse/abuseiam/client/TakedownManager.java to evaluate
   * this proto.
   */
  userRestriction?: AbuseiamUserRestriction;
}

/**
 * Describes a dimension of a context where a verdict applies.
 */
export interface AbuseiamVerdictRestrictionContext {
  /**
   * String identifying the context.
   */
  id?: string;
  type?:  | "UNKNOWN" | "DESTINATION_STREAM";
}

/**
 * Information about a video review.
 */
export interface AbuseiamVideoReviewData {
  /**
   * Serialized repeated youtube_admin.adminmatch.csai.ReferenceFragment
   */
  referenceFragment?: Uint8Array[];
  /**
   * Information about the video reviewer.
   */
  reviewer?: AbuseiamVideoReviewer;
  /**
   * The Viper id of the video.
   */
  videoId?: string;
}

function serializeAbuseiamVideoReviewData(data: any): AbuseiamVideoReviewData {
  return {
    ...data,
    referenceFragment: data["referenceFragment"] !== undefined ? data["referenceFragment"].map((item: any) => (encodeBase64(item))) : undefined,
  };
}

function deserializeAbuseiamVideoReviewData(data: any): AbuseiamVideoReviewData {
  return {
    ...data,
    referenceFragment: data["referenceFragment"] !== undefined ? data["referenceFragment"].map((item: any) => (decodeBase64(item as string))) : undefined,
  };
}

/**
 * Information about video reviewers.
 */
export interface AbuseiamVideoReviewer {
  type?:  | "UNKNOWN" | "CRT" | "TIERED_CRT" | "POLICY" | "ANALYSTS" | "LEGAL" | "LEGAL_CSAI" | "LEGAL_REMOVALS" | "HIJACKING_TEAM" | "CRT_CSAI" | "LEGAL_CSAI_LOW_PRIORITY";
  /**
   * The username of the person doing the video review.
   */
  username?: string;
}

/**
 * The serialized form of a SORI id. NOTE that this proto is stored in V4/O4
 * index and that new fields should not be added without getting an agreement
 * from the serving team as well.
 */
export interface AdsShoppingReportingOffersSerializedSoriId {
  highId?: bigint;
  lowId1?: bigint;
  lowId2?: bigint;
}

function serializeAdsShoppingReportingOffersSerializedSoriId(data: any): AdsShoppingReportingOffersSerializedSoriId {
  return {
    ...data,
    highId: data["highId"] !== undefined ? String(data["highId"]) : undefined,
    lowId1: data["lowId1"] !== undefined ? String(data["lowId1"]) : undefined,
    lowId2: data["lowId2"] !== undefined ? String(data["lowId2"]) : undefined,
  };
}

function deserializeAdsShoppingReportingOffersSerializedSoriId(data: any): AdsShoppingReportingOffersSerializedSoriId {
  return {
    ...data,
    highId: data["highId"] !== undefined ? BigInt(data["highId"]) : undefined,
    lowId1: data["lowId1"] !== undefined ? BigInt(data["lowId1"]) : undefined,
    lowId2: data["lowId2"] !== undefined ? BigInt(data["lowId2"]) : undefined,
  };
}

export interface Anchors {
  anchor?: AnchorsAnchor[];
  /**
   * The total # of local homepage anchors dropped in AnchorAccumulator.
   */
  homepageAnchorsDropped?: bigint;
  /**
   * The index tier from which the anchors were extracted. Note that this is
   * only valid in the anchor record written by linkextractor. The value can be
   * one of the enum values defined in segindexer/types.h.
   */
  indexTier?: number;
  /**
   * The total # of local non-homepage anchors dropped in AnchorAccumulator.
   */
  localAnchorsDropped?: bigint;
  /**
   * The total # of non-local anchors dropped in AnchorAccumulator.
   */
  nonlocalAnchorsDropped?: bigint;
  redundantanchorinfo?: AnchorsRedundantAnchorInfo[];
  /**
   * The *_anchors_dropped fields below are not populated by Alexandria, which
   * uses cdoc.anchor_stats instead. The total # of redundant anchors dropped in
   * linkextractor.
   */
  redundantAnchorsDropped?: bigint;
  /**
   * The total # of supplemental anchors dropped in AnchorAccumulator. ##
   * DEPRECATED.
   */
  supplementalAnchorsDropped?: bigint;
  /**
   * may be implicit
   */
  targetDocid?: bigint;
  /**
   * HOST_LEVEL site chunking.
   */
  targetSite?: string;
  /**
   * This is produced during link extraction but not written out in the
   * linklogs in order to save space.
   */
  targetUrl?: string;
}

function serializeAnchors(data: any): Anchors {
  return {
    ...data,
    anchor: data["anchor"] !== undefined ? data["anchor"].map((item: any) => (serializeAnchorsAnchor(item))) : undefined,
    homepageAnchorsDropped: data["homepageAnchorsDropped"] !== undefined ? String(data["homepageAnchorsDropped"]) : undefined,
    localAnchorsDropped: data["localAnchorsDropped"] !== undefined ? String(data["localAnchorsDropped"]) : undefined,
    nonlocalAnchorsDropped: data["nonlocalAnchorsDropped"] !== undefined ? String(data["nonlocalAnchorsDropped"]) : undefined,
    redundantanchorinfo: data["redundantanchorinfo"] !== undefined ? data["redundantanchorinfo"].map((item: any) => (serializeAnchorsRedundantAnchorInfo(item))) : undefined,
    redundantAnchorsDropped: data["redundantAnchorsDropped"] !== undefined ? String(data["redundantAnchorsDropped"]) : undefined,
    supplementalAnchorsDropped: data["supplementalAnchorsDropped"] !== undefined ? String(data["supplementalAnchorsDropped"]) : undefined,
    targetDocid: data["targetDocid"] !== undefined ? String(data["targetDocid"]) : undefined,
  };
}

function deserializeAnchors(data: any): Anchors {
  return {
    ...data,
    anchor: data["anchor"] !== undefined ? data["anchor"].map((item: any) => (deserializeAnchorsAnchor(item))) : undefined,
    homepageAnchorsDropped: data["homepageAnchorsDropped"] !== undefined ? BigInt(data["homepageAnchorsDropped"]) : undefined,
    localAnchorsDropped: data["localAnchorsDropped"] !== undefined ? BigInt(data["localAnchorsDropped"]) : undefined,
    nonlocalAnchorsDropped: data["nonlocalAnchorsDropped"] !== undefined ? BigInt(data["nonlocalAnchorsDropped"]) : undefined,
    redundantanchorinfo: data["redundantanchorinfo"] !== undefined ? data["redundantanchorinfo"].map((item: any) => (deserializeAnchorsRedundantAnchorInfo(item))) : undefined,
    redundantAnchorsDropped: data["redundantAnchorsDropped"] !== undefined ? BigInt(data["redundantAnchorsDropped"]) : undefined,
    supplementalAnchorsDropped: data["supplementalAnchorsDropped"] !== undefined ? BigInt(data["supplementalAnchorsDropped"]) : undefined,
    targetDocid: data["targetDocid"] !== undefined ? BigInt(data["targetDocid"]) : undefined,
  };
}

export interface AnchorsAnchor {
  bucket?: number;
  /**
   * CATfish tags attached to a link. These are similar to link tags, except
   * the values are created on the fly within Cookbook. See:
   * http://sites/cookbook/exporting/indexing
   */
  catfishTags?: number[];
  /**
   * If the anchor contained images, these image urls are stored here in
   * compressed form.
   */
  compressedImageUrls?: Uint8Array[];
  /**
   * The anchor's original target url, compressed. Available only in Alexandria
   * docjoins when the anchor is forwarded.
   */
  compressedOriginalTargetUrl?: Uint8Array;
  context?: number;
  /**
   * This is a hash of terms near the anchor. (This is a second-generation hash
   * replacing the value stored in the 'context' field.)
   */
  context2?: number;
  /**
   * used for history - the first and last time we have seen this anchor.
   * creation_date also used for Freshdocs Twitter indexing, a retweet is an
   * anchor of the original tweet. This field records the time when a retweet is
   * created.
   */
  creationDate?: number;
  deleted?: boolean;
  deletionDate?: number;
  /**
   * DEPRECATED
   */
  demotionreason?: number;
  /**
   * Encoded data containing information about newsiness of anchor. Populated
   * only if anchor is classified as coming from a newsy, high quality site.
   * Encoded data for anchor sources are being stored in
   * googledata/quality/freshness/news_anchors/encoded_news_anchors_data.txt
   * Scores are being computed with quality/freshness/news_anchors/ routines.
   */
  encodedNewsAnchorData?: number;
  /**
   * If true, the anchor is for experimental purposes and should not be used in
   * serving.
   */
  experimental?: boolean;
  /**
   * true iff exp domain
   */
  expired?: boolean;
  /**
   * # days past Dec 31, 1994, 23:00:00 UTC (Unix time @788914800) that this
   * link was first seen. Should never occupy more than 15 bits. NOTE: this is
   * NOT the same as creation_date; firstseen_date is filled during link
   * extraction
   */
  firstseenDate?: number;
  /**
   * true if we think 'firstseen_date' is an accurate estimate of when the link
   * was actually added to the source page. false if it may have existed for
   * some time before we saw it.
   */
  firstseenNearCreation?: boolean;
  fontsize?: number;
  /**
   * How the anchor is forwarded to the canonical, available only for forwarded
   * anchors (i.e., the field is set). The forwarding types are defined in
   * URLForwardingUtil (segindexer/segment-indexer-util.h). Always use
   * URLForwardingUtil to access this field and use
   * URLForwardingUtil::GetAnchorForwardingReason to get the explanation how the
   * anchor is forwarded to the canonical. NOTE: Use with caution as it is only
   * set for docjoins generated using the urlmap from repository/updater.
   */
  forwardingTypes?: number;
  /**
   * The URL fragment for this anchor (the foo in http://www.google.com#foo)
   */
  fragment?: string;
  /**
   * The full context. These are not written out in the linklogs.
   */
  fullLeftContext?: bigint[];
  fullRightContext?: bigint[];
  /**
   * The bit ~roughly~ indicates whether an anchor's source and target pages
   * are on the same domain. Note: this plays no role in determining whether an
   * anchor is onsite, ondomain, or offdomain in mustang (i.e., the bit above).
   */
  isLocal?: boolean;
  /**
   * Used for history and freshness tracking - the timestamp this anchor is
   * updated in indexing.
   */
  lastUpdateTimestamp?: number;
  /**
   * Additional information related to the anchor, such as additional anchor
   * text or scores.
   */
  linkAdditionalInfo?: Proto2BridgeMessageSet;
  /**
   * Contains info on link type, source page, etc.
   */
  linkTags?: number[];
  /**
   * For ranking purposes, the quality of an anchor is measured by its
   * "locality" and "bucket". See quality/anchors/definitions.h for more
   * information.
   */
  locality?: number;
  /**
   * This is the offset for the first term in the anchor - it can be used as a
   * unique ID for the anchor within the document and compared against all
   * per-tag data. This is measured in bytes from the start of the document. We
   * write this out to the linklogs to recover the original order of links after
   * source/target forwarding. This is necessary for computing the global
   * related data.
   */
  offset?: number;
  /**
   * The docid of the anchor's original target. This field is available if and
   * only if the anchor is forwarded.
   */
  originalTargetDocid?: bigint;
  /**
   * Original text, including capitalization and punctuation. Runs of
   * whitespace are collapsed into a single space.
   */
  origText?: string;
  /**
   * Weight to be stored in linkmaps for pageranker
   */
  pagerankWeight?: number;
  /**
   * The number of additional links from the same source page to the same
   * target domain. Not populated if is_local is true.
   */
  parallelLinks?: number;
  /**
   * DEPRECATED. It used to be set if firstseen_date is not set. It's to
   * indicate that the anchor is possibly old, but we don't have enough
   * information to tell until the linkage map is updated. TODO(hxu) rename it
   * to possibly_old_firstseen_date_DEPRECATED after clean up other
   * dependencies.
   */
  possiblyOldFirstseenDate?: boolean;
  /**
   * TEMPORARY
   */
  setiPagerankWeight?: number;
  source?: AnchorsAnchorSource;
  /**
   * is to record the quality of the anchor's source page and is correlated
   * with but not identical to the index tier of the source page. In the
   * docjoins built by the indexing pipeline (Alexandria), - Anchors marked
   * TYPE_HIGH_QUALITY are from base documents. - Anchors marked
   * TYPE_MEDIUM_QUALITY are from documents of medium quality (roughly but not
   * exactly supplemental tier documents). - Anchors marked TYPE_LOW_QUALITY are
   * from documents of low quality (roughly but not exactly blackhole
   * documents). Note that the source_type can also be used as an importance
   * indicator of an anchor (a lower source_type value indicates a more
   * important anchor), so it is important to enforce that TYPE_HIGH_QUALITY <
   * TYPE_MEDIUM_QUALITY < TYPE_LOW_QUALITY To add a new source type in future,
   * please maintain the proper relationship among the types as well.
   * TYPE_FRESHDOCS, only available in freshdocs indexing, is a special case and
   * is considered the same type as TYPE_HIGH_QUALITY for the purpose of anchor
   * importance in duplicate anchor removal.
   */
  sourceType?: number;
  /**
   * A given target URL may be found in different encodings in different
   * documents. We store the URL encoding with each source anchor so that we can
   * count them later to find the encoding most likely to be expected by the Web
   * site. Around 0.7% of target URLs are expected to require a non-default
   * value here. The default value 0 is referenced in C++ as
   * webutil::kDefaultUrlEncoding. See also webutil/urlencoding.
   */
  targetUrlEncoding?: number;
  /**
   * Space-delimited anchor words. Text that needs segmentation (like CJK or
   * Thai) is unsegmented, since we set FLAGS_segment_during_lexing to false in
   * mr-linkextractor.cc .
   */
  text?: string;
  /**
   * This field is DEPRECATED and no longer filled. For source page crawl
   * timestamp, use Source.crawl_timestamp. Next tag id should be 62.
   */
  timestamp?: bigint;
  /**
   * DEPRECATED: Now in link_tags
   */
  type?: number;
  /**
   * weights are 0-127
   */
  weight?: number;
}

function serializeAnchorsAnchor(data: any): AnchorsAnchor {
  return {
    ...data,
    compressedImageUrls: data["compressedImageUrls"] !== undefined ? data["compressedImageUrls"].map((item: any) => (encodeBase64(item))) : undefined,
    compressedOriginalTargetUrl: data["compressedOriginalTargetUrl"] !== undefined ? encodeBase64(data["compressedOriginalTargetUrl"]) : undefined,
    fullLeftContext: data["fullLeftContext"] !== undefined ? data["fullLeftContext"].map((item: any) => (String(item))) : undefined,
    fullRightContext: data["fullRightContext"] !== undefined ? data["fullRightContext"].map((item: any) => (String(item))) : undefined,
    originalTargetDocid: data["originalTargetDocid"] !== undefined ? String(data["originalTargetDocid"]) : undefined,
    source: data["source"] !== undefined ? serializeAnchorsAnchorSource(data["source"]) : undefined,
    timestamp: data["timestamp"] !== undefined ? String(data["timestamp"]) : undefined,
  };
}

function deserializeAnchorsAnchor(data: any): AnchorsAnchor {
  return {
    ...data,
    compressedImageUrls: data["compressedImageUrls"] !== undefined ? data["compressedImageUrls"].map((item: any) => (decodeBase64(item as string))) : undefined,
    compressedOriginalTargetUrl: data["compressedOriginalTargetUrl"] !== undefined ? decodeBase64(data["compressedOriginalTargetUrl"] as string) : undefined,
    fullLeftContext: data["fullLeftContext"] !== undefined ? data["fullLeftContext"].map((item: any) => (BigInt(item))) : undefined,
    fullRightContext: data["fullRightContext"] !== undefined ? data["fullRightContext"].map((item: any) => (BigInt(item))) : undefined,
    originalTargetDocid: data["originalTargetDocid"] !== undefined ? BigInt(data["originalTargetDocid"]) : undefined,
    source: data["source"] !== undefined ? deserializeAnchorsAnchorSource(data["source"]) : undefined,
    timestamp: data["timestamp"] !== undefined ? BigInt(data["timestamp"]) : undefined,
  };
}

/**
 * attributes of the source document for the link
 */
export interface AnchorsAnchorSource {
  /**
   * Additional information related to the source, such as news hub info.
   */
  additionalInfo?: Proto2BridgeMessageSet;
  /**
   * anchor++ cluster id
   */
  cluster?: number;
  /**
   * compressed source url
   */
  compressedUrl?: Uint8Array;
  /**
   * Source page crawl timestamp.
   */
  crawlTimestamp?: bigint;
  /**
   * The docid field used to be "required", but it is now "optional" because it
   * is not present when anchors are stored in webtable. When anchors are stored
   * as part of docjoin files in the segment indexer, however, docid should be
   * considered required.
   */
  docid?: bigint;
  /**
   * necessary for anything?
   */
  doclength?: number;
  /**
   * Information about if the source page is a home page. It can be one of the
   * enum values defined in PerDocData::HomePageInfo (NOT_HOMEPAGE, NOT_TRUSTED,
   * PARTIALLY_TRUSTED, and FULLY_TRUSTED).
   */
  homePageInfo?: number;
  /**
   * uint16 scale
   */
  indyrank?: number;
  /**
   * DEPRECATED, use packed_ipaddress
   */
  ipaddr?: number;
  /**
   * default -> English
   */
  language?: number;
  /**
   * 0 -> no hash
   */
  linkhash?: bigint;
  /**
   * Countries to which the source page is local/most relevant; stored as III
   * identifiers for country/region codes (see http://go/iii).
   */
  localCountryCodes?: number[];
  /**
   * This NSR value has range [0,1000] and is the original value [0.0,1.0]
   * multiplied by 1000 rounded to an integer.
   */
  nsr?: number;
  outdegree?: number;
  /**
   * approx num of pointed-to sites
   */
  outsites?: number;
  /**
   * string in IPAddress::ToPackedString() format.
   */
  packedIpaddress?: Uint8Array;
  /**
   * uint16 scale
   */
  pagerank?: number;
  /**
   * unit16 scale
   */
  pagerankNs?: number;
  /**
   * Page tags are described by enum PageTag in PerDocData. Page tags are used
   * in anchors to identify properties of the linking page. These are
   * DEPRECATED: in the future, use link_tags instead. DEPRECATED
   */
  pageTags?: number[];
  /**
   * DEPRECATED
   */
  seglanguage?: number;
  site?: string;
  /**
   * uint16 scale
   */
  spamrank?: number;
  /**
   * deprecated, to be removed after October 20. 0-127 scale
   */
  spamscore1?: number;
  /**
   * 0-127 scale
   */
  spamscore2?: number;
  /**
   * Webtable key of source
   */
  webtableKey?: string;
}

function serializeAnchorsAnchorSource(data: any): AnchorsAnchorSource {
  return {
    ...data,
    compressedUrl: data["compressedUrl"] !== undefined ? encodeBase64(data["compressedUrl"]) : undefined,
    crawlTimestamp: data["crawlTimestamp"] !== undefined ? String(data["crawlTimestamp"]) : undefined,
    docid: data["docid"] !== undefined ? String(data["docid"]) : undefined,
    linkhash: data["linkhash"] !== undefined ? String(data["linkhash"]) : undefined,
    packedIpaddress: data["packedIpaddress"] !== undefined ? encodeBase64(data["packedIpaddress"]) : undefined,
  };
}

function deserializeAnchorsAnchorSource(data: any): AnchorsAnchorSource {
  return {
    ...data,
    compressedUrl: data["compressedUrl"] !== undefined ? decodeBase64(data["compressedUrl"] as string) : undefined,
    crawlTimestamp: data["crawlTimestamp"] !== undefined ? BigInt(data["crawlTimestamp"]) : undefined,
    docid: data["docid"] !== undefined ? BigInt(data["docid"]) : undefined,
    linkhash: data["linkhash"] !== undefined ? BigInt(data["linkhash"]) : undefined,
    packedIpaddress: data["packedIpaddress"] !== undefined ? decodeBase64(data["packedIpaddress"] as string) : undefined,
  };
}

/**
 * NOTE: in docjoins, the following anchor sampling information is only ##
 * available in the first record of a document (under the same docid). The total
 * number of redundant anchors dropped per (domain, text) in linkextractor. If
 * we receive a large number of anchors from a particular domain, then we'll
 * throw out all but a sampling of them from that domain. The data is sorted by
 * the (domain,text) pairs. This field is not populated by Alexandria, which
 * uses cdoc.anchor_stats instead.
 */
export interface AnchorsRedundantAnchorInfo {
  anchorsDropped?: bigint;
  domain?: string;
  text?: string;
}

function serializeAnchorsRedundantAnchorInfo(data: any): AnchorsRedundantAnchorInfo {
  return {
    ...data,
    anchorsDropped: data["anchorsDropped"] !== undefined ? String(data["anchorsDropped"]) : undefined,
  };
}

function deserializeAnchorsRedundantAnchorInfo(data: any): AnchorsRedundantAnchorInfo {
  return {
    ...data,
    anchorsDropped: data["anchorsDropped"] !== undefined ? BigInt(data["anchorsDropped"]) : undefined,
  };
}

/**
 * Represents a GSuite customer ID. Obfuscated with CustomerIdObfuscator.
 */
export interface AppsDynamiteCustomerId {
  customerId?: string;
}

/**
 * Contains info about the entity that something is, or is owned by.
 */
export interface AppsDynamiteSharedOrganizationInfo {
  consumerInfo?: AppsDynamiteSharedOrganizationInfoConsumerInfo;
  customerInfo?: AppsDynamiteSharedOrganizationInfoCustomerInfo;
}

/**
 * Intentionally empty. Used to disambiguate consumer and customer use cases in
 * oneof below.
 */
export interface AppsDynamiteSharedOrganizationInfoConsumerInfo {
}

export interface AppsDynamiteSharedOrganizationInfoCustomerInfo {
  customerId?: AppsDynamiteCustomerId;
}

/**
 * A DestinationStream is a /namespace/id[0]/id[1]/.../id[n] that represents a
 * collection of Activities. Example destinations: -The Profile Stream on
 * http://plus.google.com/+JohnDoe/posts -A Square Stream on
 * http://plus.google.com/squares/123 -A "comment Stream" (Fountain) on
 * http://www.youtube.com/watch?id=123 It's possible for a single Activity to
 * show in each of these destinations - and it might behave/look slightly
 * differently for each one. Destinations can have their own business logic
 * associated with them at both write-time and read-time server-side (these are
 * documented below). Each DestinationStream is indexed and can be retrieved
 * using the GetDestinationStreamRequest. For the repeated ID space indexing
 * happens at all levels, e.g. if you have: /square/123/abc /square/123/efd
 * /square/456 You can fetch /square/123/abc directly or /square/123 (which
 * includes all Activities in both /square/123/abc and /square/123/efd), or even
 * /square which retrieves all Activities in the Square namespace (visible for
 * that user). On the storage layer, we represent DestinationStream as Channel
 * (http://cs/#google3/social/common/channel/channel.proto), since the storage
 * does not have the concept of a Stream. Both terms are used interchangeably
 * within the service layer, but client of Social Infrastructure should use the
 * term DestinationStream. Next ID: 3
 */
export interface AppsPeopleActivityBackendDestinationStream {
  /**
   * The hierarchy of IDs. Each individual ID is "flat" and the repeated list
   * defines the hierarchy. Namespaces define the "validity" of this hierachy
   * (depth, naming convention, etc) and the server will reject invalid IDs.
   */
  id?: string[];
  namespace?:  | "UNKNOWN_DESTINATION_NAMESPACE" | "SQUARES" | "FOUNTAIN" | "PROFILE" | "COLLEXIONS" | "TEST" | "HIGHLIGHT" | "SOCIETY" | "MEMEGEN" | "PHOTOS" | "SUPPLY_CHAIN_CENTRAL" | "PAISA" | "SOCIETY_CHAT" | "PLUS_ENTERPRISE_LOG" | "SEARCH_UGC" | "LOUPE" | "MINDSEARCH" | "SOS_LIVE_COMMENTS" | "SBE_LOADTEST" | "SYSTEM1" | "G_PLUS" | "YOUTUBE" | "EVENTS" | "DEPRECATED_COLLECTIONS" | "REVIEWS" | "BACKSTAGE" | "SPACES";
}

/**
 * Stores the number of different kind of user engagement actions. Abuse Report
 * is also consider an engagement. Currently we only have abuse report
 * engagements but in future we might add other types of engagements as well.
 */
export interface AppsPeopleActivityStreamqualityDistillerEngagements {
  /**
   * Corresponds on "This account might be compromised or hacked" reporting
   * action.
   */
  reportCompromised?: bigint;
  /**
   * Corresponds on "Harassment or bullying" reporting action.
   */
  reportHarassment?: bigint;
  /**
   * Corresponds on "Hate speach or graphic violence" reporting action.
   */
  reportHate?: bigint;
  /**
   * Corresponds on "Pornography or sexually explicit material" reporting
   * action.
   */
  reportPorn?: bigint;
  /**
   * Corresponds on "Unwanted commercial content or spam" reporting action.
   */
  reportSpam?: bigint;
  /**
   * Number of times this activity was served out of asbe/stanza.
   */
  serveCount?: bigint;
  /**
   * Timestamp in seconds for which time this record is valid.
   */
  timeSec?: bigint;
  /**
   * Corresponds on Distiller comment thumbs down action.
   */
  ytThumbsDown?: bigint;
}

function serializeAppsPeopleActivityStreamqualityDistillerEngagements(data: any): AppsPeopleActivityStreamqualityDistillerEngagements {
  return {
    ...data,
    reportCompromised: data["reportCompromised"] !== undefined ? String(data["reportCompromised"]) : undefined,
    reportHarassment: data["reportHarassment"] !== undefined ? String(data["reportHarassment"]) : undefined,
    reportHate: data["reportHate"] !== undefined ? String(data["reportHate"]) : undefined,
    reportPorn: data["reportPorn"] !== undefined ? String(data["reportPorn"]) : undefined,
    reportSpam: data["reportSpam"] !== undefined ? String(data["reportSpam"]) : undefined,
    serveCount: data["serveCount"] !== undefined ? String(data["serveCount"]) : undefined,
    timeSec: data["timeSec"] !== undefined ? String(data["timeSec"]) : undefined,
    ytThumbsDown: data["ytThumbsDown"] !== undefined ? String(data["ytThumbsDown"]) : undefined,
  };
}

function deserializeAppsPeopleActivityStreamqualityDistillerEngagements(data: any): AppsPeopleActivityStreamqualityDistillerEngagements {
  return {
    ...data,
    reportCompromised: data["reportCompromised"] !== undefined ? BigInt(data["reportCompromised"]) : undefined,
    reportHarassment: data["reportHarassment"] !== undefined ? BigInt(data["reportHarassment"]) : undefined,
    reportHate: data["reportHate"] !== undefined ? BigInt(data["reportHate"]) : undefined,
    reportPorn: data["reportPorn"] !== undefined ? BigInt(data["reportPorn"]) : undefined,
    reportSpam: data["reportSpam"] !== undefined ? BigInt(data["reportSpam"]) : undefined,
    serveCount: data["serveCount"] !== undefined ? BigInt(data["serveCount"]) : undefined,
    timeSec: data["timeSec"] !== undefined ? BigInt(data["timeSec"]) : undefined,
    ytThumbsDown: data["ytThumbsDown"] !== undefined ? BigInt(data["ytThumbsDown"]) : undefined,
  };
}

export interface AppsPeopleOzExternalMergedpeopleapiAbout {
  contentType?:  | "TEXT_PLAIN" | "TEXT_HTML";
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
  /**
   * Sanitized HTML value that is only populated when the SANITIZE_ABOUT_HTML
   * extension is requested.
   */
  safeHtmlValue?: WebutilHtmlTypesSafeHtmlProto;
  value?: string;
}

function serializeAppsPeopleOzExternalMergedpeopleapiAbout(data: any): AppsPeopleOzExternalMergedpeopleapiAbout {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiAbout(data: any): AppsPeopleOzExternalMergedpeopleapiAbout {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

/**
 * Extension data for use in AboutMe.
 */
export interface AppsPeopleOzExternalMergedpeopleapiAboutMeExtendedData {
  nameDisplayOptions?: AppsPeopleOzExternalMergedpeopleapiAboutMeExtendedDataNameDisplayOptions;
  photosCompareData?: AppsPeopleOzExternalMergedpeopleapiAboutMeExtendedDataPhotosCompareData;
  profileEditability?: AppsPeopleOzExternalMergedpeopleapiAboutMeExtendedDataProfileEditability;
  profileNameModificationHistory?: AppsPeopleOzExternalMergedpeopleapiAboutMeExtendedDataProfileNameModificationHistory;
}

function serializeAppsPeopleOzExternalMergedpeopleapiAboutMeExtendedData(data: any): AppsPeopleOzExternalMergedpeopleapiAboutMeExtendedData {
  return {
    ...data,
    photosCompareData: data["photosCompareData"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiAboutMeExtendedDataPhotosCompareData(data["photosCompareData"]) : undefined,
    profileNameModificationHistory: data["profileNameModificationHistory"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiAboutMeExtendedDataProfileNameModificationHistory(data["profileNameModificationHistory"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiAboutMeExtendedData(data: any): AppsPeopleOzExternalMergedpeopleapiAboutMeExtendedData {
  return {
    ...data,
    photosCompareData: data["photosCompareData"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiAboutMeExtendedDataPhotosCompareData(data["photosCompareData"]) : undefined,
    profileNameModificationHistory: data["profileNameModificationHistory"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiAboutMeExtendedDataProfileNameModificationHistory(data["profileNameModificationHistory"]) : undefined,
  };
}

/**
 * See NameDisplayOptions in //depot/google3/focus/backend/proto/backend.proto.
 * See also go/nickname-mess.
 */
export interface AppsPeopleOzExternalMergedpeopleapiAboutMeExtendedDataNameDisplayOptions {
  nicknameOption?:  | "UNKNOWN_NICKNAME_OPTION" | "QUOTED_NICKNAME" | "PAREN_NICKNAME";
}

export interface AppsPeopleOzExternalMergedpeopleapiAboutMeExtendedDataPhotosCompareData {
  diffData?: AppsPeopleOzExternalMergedpeopleapiAboutMeExtendedDataPhotosCompareDataDiffData;
  highResUrl?: string;
  /**
   * True if photo diff is greater than 0.01 on any color band, or if the user
   * has a low res photo but no high res photo. This field is primarily for use
   * in About Me and for other uses it's recommended to use the DiffData values
   * directly instead. The cutoff is based on a heuristic determined in
   * go/comparing-profile-photos
   */
  inconsistentPhoto?: boolean;
  /**
   * Only present if the photo diff is greater than 0.01 on any color band.
   */
  lowResData?: Uint8Array;
  lowResUrl?: string;
  monogramUrl?: string;
  /**
   * True if the low-res photo has a private ACL set.
   */
  privateLowResAcl?: boolean;
}

function serializeAppsPeopleOzExternalMergedpeopleapiAboutMeExtendedDataPhotosCompareData(data: any): AppsPeopleOzExternalMergedpeopleapiAboutMeExtendedDataPhotosCompareData {
  return {
    ...data,
    lowResData: data["lowResData"] !== undefined ? encodeBase64(data["lowResData"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiAboutMeExtendedDataPhotosCompareData(data: any): AppsPeopleOzExternalMergedpeopleapiAboutMeExtendedDataPhotosCompareData {
  return {
    ...data,
    lowResData: data["lowResData"] !== undefined ? decodeBase64(data["lowResData"] as string) : undefined,
  };
}

export interface AppsPeopleOzExternalMergedpeopleapiAboutMeExtendedDataPhotosCompareDataDiffData {
  blueDiff?: number;
  greenDiff?: number;
  redDiff?: number;
}

/**
 * See UserEditedLockedMask in
 * //depot/google3/focus/backend/proto/backend.proto.
 */
export interface AppsPeopleOzExternalMergedpeopleapiAboutMeExtendedDataProfileEditability {
  /**
   * Read-only set of zero or more field paths that are locked for update on
   * this person, such as "person.name", "person.email", etc. The set of fields
   * is only populated for the requester's profile. Fields in the set cannot be
   * edited, added, or deleted from the profile. Attempting to update any of
   * these fields will result in an exception.
   */
  lockedField?: string[];
}

/**
 * See ABUSE_NAME_LAST_MODIFIED in
 * //depot/google3/focus/backend/proto/backend.proto which maps to
 * //depot/google3/focus/proto/profileattribute.proto
 */
export interface AppsPeopleOzExternalMergedpeopleapiAboutMeExtendedDataProfileNameModificationHistory {
  /**
   * The number of name changes remaining at RPC request time. This can be more
   * than name_changes_remaining, if user hasn't changed name for some time and
   * accrued quota since last change.
   */
  computedNameChangesRemaining?: number;
  /**
   * The number of nickname changes remaining at RPC request time. This can be
   * more than nickname_changes_remaining, if user hasn't changed nickname for
   * some time and accrued quota since last change.
   */
  computedNicknameChangesRemaining?: number;
  /**
   * The number of name changes remaining at the time the name was last
   * modified.
   */
  nameChangesRemaining?: number;
  /**
   * The last time the profile name was modified in milliseconds UTC.
   */
  nameLastModified?: bigint;
  /**
   * The number of nickname changes remaining at the time the nickname was last
   * modified.
   */
  nicknameChangesRemaining?: number;
  /**
   * The last time the profile nickname was modified in milliseconds UTC.
   */
  nicknameLastModified?: bigint;
  quotaEnforcementStatus?:  | "UNKNOWN_QUOTA_ENFORCEMENT_STATUS" | "ENFORCED" | "NOT_ENFORCED" | "NOT_APPLICABLE";
}

function serializeAppsPeopleOzExternalMergedpeopleapiAboutMeExtendedDataProfileNameModificationHistory(data: any): AppsPeopleOzExternalMergedpeopleapiAboutMeExtendedDataProfileNameModificationHistory {
  return {
    ...data,
    nameLastModified: data["nameLastModified"] !== undefined ? String(data["nameLastModified"]) : undefined,
    nicknameLastModified: data["nicknameLastModified"] !== undefined ? String(data["nicknameLastModified"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiAboutMeExtendedDataProfileNameModificationHistory(data: any): AppsPeopleOzExternalMergedpeopleapiAboutMeExtendedDataProfileNameModificationHistory {
  return {
    ...data,
    nameLastModified: data["nameLastModified"] !== undefined ? BigInt(data["nameLastModified"]) : undefined,
    nicknameLastModified: data["nicknameLastModified"] !== undefined ? BigInt(data["nicknameLastModified"]) : undefined,
  };
}

export interface AppsPeopleOzExternalMergedpeopleapiAccountEmail {
  email?: string;
}

/**
 * Additional information about a container. TO BE DELETED: replaced by
 * DeviceContactInfo.
 */
export interface AppsPeopleOzExternalMergedpeopleapiAdditionalContainerInfo {
  /**
   * When the container is a DEVICE_CONTACT, this list provides account
   * information from the raw contact which is the source of this field.
   */
  rawDeviceContactInfo?: AppsPeopleOzExternalMergedpeopleapiRawDeviceContactInfo[];
}

function serializeAppsPeopleOzExternalMergedpeopleapiAdditionalContainerInfo(data: any): AppsPeopleOzExternalMergedpeopleapiAdditionalContainerInfo {
  return {
    ...data,
    rawDeviceContactInfo: data["rawDeviceContactInfo"] !== undefined ? data["rawDeviceContactInfo"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiRawDeviceContactInfo(item))) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiAdditionalContainerInfo(data: any): AppsPeopleOzExternalMergedpeopleapiAdditionalContainerInfo {
  return {
    ...data,
    rawDeviceContactInfo: data["rawDeviceContactInfo"] !== undefined ? data["rawDeviceContactInfo"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiRawDeviceContactInfo(item))) : undefined,
  };
}

export interface AppsPeopleOzExternalMergedpeopleapiAddress {
  country?: string;
  countryCode?: string;
  /**
   * FeatureId associated with the address. The format is the same as that used
   * for ids in PLACE containers in SourceIdentity.
   */
  encodedPlaceId?: string;
  extendedAddress?: string;
  formatted?: string;
  /**
   * The `type` translated and formatted in the request locale. See
   * go/people-api-howto/localization for details on how to usage.
   */
  formattedType?: string;
  locality?: string;
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
  poBox?: string;
  pointSpec?: AppsPeopleOzExternalMergedpeopleapiPointSpec;
  postalCode?: string;
  region?: string;
  streetAddress?: string;
  /**
   * The type of the address. The type can be free form or one of these
   * predefined values: * `home` * `work` * `other`
   */
  type?: string;
}

function serializeAppsPeopleOzExternalMergedpeopleapiAddress(data: any): AppsPeopleOzExternalMergedpeopleapiAddress {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiAddress(data: any): AppsPeopleOzExternalMergedpeopleapiAddress {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

/**
 * Similar to social.graph.storage.Affinity, but pared down to what the clients
 * of the People API are interested in.
 */
export interface AppsPeopleOzExternalMergedpeopleapiAffinity {
  /**
   * Contains extra ranking information returned by DAS.
   */
  affinityMetadata?: SocialGraphWireProtoPeopleapiAffinityMetadata;
  affinityType?:  | "AFFINITY_TYPE_UNKNOWN" | "EMAIL_AUTOCOMPLETE" | "CONTACTS_PLUS_FREQUENTLY_CONTACTED" | "CHAT_AUTOCOMPLETE" | "GPLUS_AUTOCOMPLETE" | "GLASS_AFFINITY" | "PEOPLE_AUTOCOMPLETE_SOCIAL" | "FIELD_AUTOCOMPLETE_SOCIAL" | "CONTACTS_PLUS_EMAIL" | "PHOTOS_PEOPLE_TO_SHARE_WITH_SUGGESTIONS" | "PHOTOS_FIELDS_TO_SHARE_WITH_SUGGESTIONS" | "INBOX_AFFINITY" | "DYNAMITE_AFFINITY" | "PHOTOS_SUGGESTIONS_AFFINITY" | "PHOTOS_SUGGESTED_TARGETS" | "PHOTOS_ASSISTANT_SUGGESTIONS_AFFINITY" | "DRIVE_AUTOCOMPLETE" | "WALLET_PEOPLE_TO_PAY_SUGGESTIONS" | "CONTACTS_PLUS_CONTACT_CENTRIC" | "POMEROY_AFFINITY" | "CALENDAR_AFFINITY" | "SPACES_APP_PEOPLE_AFFINITY" | "HOMEROOM_AFFINITY" | "PEOPLE_PLAYGROUND_AFFINITY" | "FAMILY_AFFINITY" | "CONTACTS_ASSISTANT_SUGGESTED_CONTACTS" | "TRIPS_AFFINITY" | "GOOGLE_VOICE_AFFINITY" | "PHOTOS_FACE_AFFINITY" | "G3DOC_AUTOCOMPLETE" | "LOUPE_SUGGESTIONS_AFFINITY" | "MAPS_SHARING_AFFINITY" | "CLOUD_SEARCH_AFFINITY" | "YOUTUBE_UNPLUGGED" | "JAM_AFFINITY" | "ITEM_SUGGEST_AFFINITY" | "ISSUE_TRACKER_AFFINITY" | "APPS_ASSISTANT_AFFINITY" | "APDL_CONTACT_CENTRIC_DEFAULT_AFFINITY" | "APDL_PROFILE_CENTRIC_DEFAULT_AFFINITY" | "SOCIAL_RECOVERY" | "TEZ_AFFINITY" | "NEWS_AFFINITY" | "ALLO_AFFINITY" | "GPLUS_PEOPLE_RECOMMENDATIONS" | "GPLUS_PEOPLE_RECOMMENDATIONS_SAME_DOMAIN" | "DRIVE_AFFINITY" | "PODIUM_AFFINITY" | "ZOOM_SIGHTS_EMAIL_AFFINITY" | "AIRDROME_AFFINITY" | "HANGOUTS_MEET_AFFINITY" | "GALLERY_AFFINITY" | "AGSA_AFFINITY" | "PAY_AFFINITY" | "SAVES_AFFINITY" | "JASPER_AFFINITY" | "GOOGLE_HOME_APP_AFFINITY" | "TOPAZ_TEAMS_AFFINITY" | "DYNAMITE_OUT_OF_DOMAIN_AFFINITY" | "GOOGLE_VOICE_SIRI_EXTENSION_AFFINITY" | "COURSE_KIT_AFFINITY" | "FORMS_AFFINITY" | "NOVITAS_AFFINITY" | "GTI_PEER_INTERACTIONS_AFFINITY" | "ANDROID_EMERGENCY_AFFINITY" | "DATA_STUDIO_AFFINITY" | "SPUR_AFFINITY" | "PLAY_GAMES_SERVICES_AFFINITY" | "GROUPS_ADD_MEMBER_AFFINITY" | "DUO_AFFINITY" | "MY_BUSINESS_AFFINITY" | "GMAIL_COMPOSE" | "NON_GPLUS_AFFINITY" | "ABUSE_AFFINITY" | "ABUSE_AFFINITY_LITE" | "CALENDAR_PEEK_AFFINITY" | "HUB_CALL_AFFINITY" | "GSUITE_WORKFLOW_AFFINITY" | "VR_POLY_PRO_AFFINITY" | "TASKS_AFFINITY" | "GOOGLE_ONE_AFFINITY" | "TRAVEL_AFFINITY" | "GEO_DISCOVERY_FOLLOW_AFFINITY" | "GMAIL_WEB_AFFINITY" | "ASSISTANT_SETTINGS_WEB_UI_AFFINITY" | "ARTIFEX_AFFINITY" | "CONTACT_STORE_DEFAULT_AFFINITY" | "CONTACT_STORE_SELF_EXCLUSIVE" | "PHOTOS_FACE_STALE_AFFINITY" | "LANDSPEEDER_AFFINITY" | "GOOGLE_FI_AFFINITY" | "CONTACTS_PLUS_DOMAIN_ONLY" | "PHOTOS_SUGGESTED_TARGETS_IN_APP_ONLY" | "SOCIETY_AFFINITY" | "NANDHI_TEST_SCHEDULER_AFFINITY" | "HIJACKING_HIGH_RISK_AFFINITY" | "TRUECOLOURS_AFFINITY" | "ESPRESSO_AFFINITY" | "TAG_AFFINITY" | "CORPBOT_AFFINITY" | "SHOPPING_LIST_AFFINITY" | "INTEGRATION_PLATFORM_AFFINITY" | "HOT_ORDERS_UI_AFFINITY" | "TELLY_MOBILE_APP_AFFINITY" | "NGA_SUGGESTION_RESOLUTION_AFFINITY" | "DUC_COMPANION_AFFINITY" | "TOG_AFFINITY" | "ANDROID_SYSTEM_INTELLIGENCE_AFFINITY" | "EARTH_AFFINITY" | "SHORTCUT_AFFINITY" | "CHROME_OS_SCALING_AFFINITY" | "SHOWTIME_AFFINITY" | "PLAY_GAMES_SERVICES_EXPERIMENTAL" | "GUPPEEPS_AFFINITY" | "NEST_AFFINITY" | "BLOGGER_AFFINITY" | "INDIVIDUAL_OUTGOING_INTERACTIONS_RECENCY_RANK" | "ASSISTANT_TOOLCHAIN_AFFINITY" | "CHAT_CONSERVER_FAVORITE_CONTACTS_AFFINITY" | "CHAT_CONSERVER_INVITEE_AFFINITY" | "GANTRY_AFFINITY" | "KINTARO_AFFINITY" | "KEEP_AFFINITY" | "INCIDENTFLOW_AFFINITY" | "DRIVE_MENTION_AFFINITY" | "DRIVE_LOOKUP_AFFINITY" | "PODCASTS_MANAGER_AFFINITY" | "EMAIL_AUTOCOMPLETE_GG" | "ONE_REVIEWER_TOOL_AFFINITY" | "ASSISTANT_FAMILY_VERTICAL_AFFINITY" | "STADIA_AFFINITY" | "ATLAS_AFFINITY" | "CONSTELLATION_AFFINITY" | "CORONADO_AFFINITY" | "WALLET_GOLDEN_GATE_AFFINITY" | "PUMICE_AFFINITY" | "DEMO_AFFINITY_DEFAULT_ALGO" | "DEMO_AFFINITY_DEFAULT_ALGO_DOMAIN_ONLY" | "DEMO_AFFINITY_EMAIL_ALGO" | "DEMO_AFFINITY_EMAIL_ALGO_DOMAIN_ONLY" | "BACKLIGHT_AFFINITY" | "DYNAMITE_GROUPS_AFFINITY" | "DYNAMITE_OUT_OF_DOMAIN_GROUPS_AFFINITY" | "GLOSSARY_MANAGER_AFFINITY" | "ONEDEV_WORKFLOW_AFFINITY" | "GSUITE_HUB_CALL_AFFINITY" | "AVALANCHE_AFFINITY" | "SANDTROUT_DEVICE_CONTACTS_AFFINITY" | "DYNAMITE_ROOM_AFFINITY" | "DESKBOOKING_AFFINITY" | "TEZ_EXTENDED_AFFINITY" | "DRIVE_PROFILE_ONLY_AFFINITY" | "OFFSEC_AFFINITY" | "GOOGLE_HOME_FAMILY_AFFINITY" | "ONEMARKET_CALENDAR_AFFINITY" | "GPAY_MERCHANT_CONSOLE_AFFINITY" | "WORDFLOW_AFFINITY" | "YOUTUBE_CREATOR_STUDIO_AFFINITY" | "BRICKS_AFFINITY" | "BUG_OBSERVER_AFFINITY" | "ALPHASCHEDULE_AFFINITY" | "BURROW_AFFINITY" | "TEAMSPACES_AFFINITY" | "GMAIL_SMARTADDRESS_REPLACE_AFFINITY" | "GMAIL_SMARTADDRESS_EXPAND_AFFINITY" | "ASSISTANT_OPA_AFFINITY" | "POLYGLOT_AFFINITY" | "TRANSLATION_MEMORY_MANAGER_AFFINITY" | "THREADIT_AFFINITY" | "RESOURCE_SYMPHONY_AFFINITY" | "HOUSEHOLD_CONTACTS_PICKER_AFFINITY" | "L10N_INFRA_SHARED_AFFINITY" | "WORK_TRACKER_AFFINITY" | "ARIANE_AFFINITY" | "DRIVE_ROOM_AFFINITY" | "MOMA_SEARCH_AFFINITY" | "COLAB_INTERNAL_AFFINITY" | "COLAB_EXTERNAL_AFFINITY" | "TALENT_GROW_AFFINITY" | "SOCIAL_CONNECTION_CHECKER_AFFINITY" | "GMS_PEOPLE_AFFINITY" | "ROCKET_LABS_AFFINITY" | "DYNAMITE_ROOM_AND_INDIVIDUAL_ONLY_AFFINITY" | "TEZ_PHONE_SEARCH_AFFINITY" | "MY_GOOGLE_FAMILIES_AFFINITY" | "DYNAMITE_UNIFIED_AFFINITY" | "SHORTCUT_SERVER_AFFINITY" | "LEGAL_CONTRACTS_AFFINITY" | "CALENDAR_WEB_AFFINITY" | "DATA_CATALOG_AFFINITY" | "BRIEF_API_AFFINITY" | "HARDWARE_MFG_DATA_VENUS_AFFINITY" | "BETTERBUG_AFFINITY" | "DCMS_AFFINITY" | "PLAY_BOOKS_PUBENG_AFFINITY" | "YAQS_AFFINITY" | "RESPONSIBLE_FEATURE_ACCESS_AFFINITY" | "PROSPER_AFFINITY" | "PEOPLE_TO_ADD_BIRTHDAY_FOR_AFFINITY" | "FLOURISH_AFFINITY" | "CAMPAIGN_MANAGEMENT_TOOL_AFFINITY" | "RECORDER_AFFINITY" | "CLASSROOM_SEARCH_AFFINITY" | "HIRING_AFFINITY" | "DATACENTER_SOFTWARE_AFFINITY" | "PHOTOS_INVITE_AFFINITY" | "PHOTOS_PARTNER_SHARING_AFFINITY" | "MARKETING_WORKFLOWS_AFFINITY" | "INTROSPECT_AFFINITY" | "YOUTUBE_PARENT_TOOLS_AFFINITY" | "RELIABILITY_INSIGHTS_PST_AFFINITY" | "GMAIL_ANDROID_AFFINITY" | "CUSTOMER_CARE_PORTAL_AFFINITY" | "MOMAHOME_3C_AFFINITY" | "DIGITAL_CAR_KEY_AFFINITY" | "PLAY_BOOKS_DISTRIBUTION_AFFINITY" | "GOOGLE_ASSIGNMENTS_AFFINITY" | "TEST_FUSION_AFFINITY" | "PRODUCTION2020_UIE_AFFINITY" | "SPEAKEASY_AFFINITY" | "DOCS_TASKS_AFFINITY" | "DYNAMITE_SEARCH_AFFINITY" | "GPAY_RELEASE_OPS_AFFINITY" | "VOICE_PBX_AFFINITY" | "VOICE_WEB_AFFINITY" | "SKILLSSTACK_AFFINITY" | "WHOSTORY_AFFINITY" | "PHOTOS_PARTNER_SHARING_EMAIL_ONLY" | "MEMORIZE_AFFINITY" | "BETTANY_AFFINITY" | "BASECAMP_AFFINITY" | "DRIVE_SEARCH_FILTER_AFFINITY" | "CULTURE_EVENTS_CALENDAR_AFFINITY" | "DATABRIDGE_CONSOLE_AFFINITY" | "COMMSTAR_AFFINITY" | "CDDB_AFFINITY" | "DATA_STUDIO_SPACES_AFFINITY" | "SOJI_AFFINITY" | "PLAY_MOVIES_ANDROID_AFFINITY" | "DATA_STUDIO_DOMAIN_ONLY_AFFINITY" | "MONOSPACE_AFFINITY" | "MY_ACCOUNT_AFFINITY" | "NUDGEIT_CAMPAIGN_MANAGER_AFFINITY" | "LEGAL_CONTRACTS_EXTERNAL_AFFINITY" | "CONTACTS_TO_STAR_AFFINITY";
  /**
   * The ID of the container
   */
  containerId?: string;
  /**
   * The type of container to which this affinity applies
   */
  containerType?:  | "UNKNOWN_CONTAINER" | "PROFILE" | "CONTACT" | "CIRCLE" | "PLACE" | "ACCOUNT" | "EXTERNAL_ACCOUNT" | "DOMAIN_PROFILE" | "DOMAIN_CONTACT" | "DEVICE_CONTACT" | "GOOGLE_GROUP" | "NAMED_CHAT_ROOM" | "UNNAMED_CHAT_ROOM" | "AFFINITY" | "RAW_DEVICE_CONTACT" | "CONTACT_ANNOTATION" | "DELEGATED_CONTACT";
  /**
   * Used to log events for this affinity value, for disco diagnostic-purposes.
   * See go/disco-diagnostics.
   */
  loggingId?: string;
  /**
   * Affinity value. Frequently represented as an inverse ranking, sometimes
   * with additional data encoded. If data_formats.affinity_formats.score_format
   * is set to RAW_SCORE then the value will be the score returned by DAS.
   */
  value?: number;
}

/**
 * Please read go/people-api-howto:age on how to get age data. Message for the
 * `Person.age_range_repeated` field. Replaces the existing `Person.age_range`
 * field.
 */
export interface AppsPeopleOzExternalMergedpeopleapiAgeRangeType {
  /**
   * Please read go/people-api-howto:age on how to get age data. Age of the
   * user. The field is set based on profile storage fields such as account
   * birthday. If the source fields are not present, `age_in_years` will be left
   * unset.
   */
  ageInYears?: number;
  /**
   * Deprecated. Use go/supervised-accounts#capabilities-for-child-accounts
   * instead. Denotes whether the user is under the region based Age of Consent.
   * The user's region is based on ClientUserInfo.GlobalTos.AgreedLocation The
   * age is inferred from Birthday field or CertifiedBornBefore field. The
   * region based AoC is specified at go/aoc.
   */
  ageOfConsentStatus?:  | "AOC_STATUS_UNKNOWN" | "UNDER_AOC" | "AT_OR_ABOVE_AOC";
  /**
   * Deprecated. Please read go/people-api-howto:age on how to get age data.
   * Age range is populated based on `account_birthday` and
   * `certified_born_before`, which may not be set for dasher users.
   */
  ageRange?:  | "UNKNOWN" | "LESS_THAN_EIGHTEEN" | "TWENTY_ONE_OR_OLDER" | "EIGHTEEN_TO_TWENTY";
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
}

function serializeAppsPeopleOzExternalMergedpeopleapiAgeRangeType(data: any): AppsPeopleOzExternalMergedpeopleapiAgeRangeType {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiAgeRangeType(data: any): AppsPeopleOzExternalMergedpeopleapiAgeRangeType {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

/**
 * Store all app unique info that are needed for app action fulfillment.
 */
export interface AppsPeopleOzExternalMergedpeopleapiAppUniqueInfo {
  /**
   * Store the app unique id endpoint. This will be passed over to app to
   * fulfill the action. For example, app_unique_id for Whatsapp will be
   * "11234567890@s.whatsapp.net"
   */
  appUniqueId?: string;
  /**
   * Store third party endpoint that is displayed to users. For example,
   * display_app_unique_id for Whatsapp will be "Message +11234567890".
   */
  displayAppUniqueId?: string;
  /**
   * Store third party endpoint label. For example, "HOME", "WORK"
   */
  label?: string;
  /**
   * Store mimetype of this endpoint. We will use this as the differentiator
   * for Assistant to know whether to use the RawContact for messaging, call or
   * video call. For example, send message mimetype for whatsapp:
   * "vnd.android.cursor.item/vnd.com.whatsapp.profile" voice call mimetype for
   * whatsapp: "vnd.android.cursor.item/vnd.com.whatsapp.voip.call"
   */
  mimetype?: string;
}

/**
 * The best suggested name to use for the Person from the available source
 * fields, which may include FileAs, Name, Org, Email, IM, Phone, ... Rough
 * source container priority order is Contact, then Profile, then Place.
 */
export interface AppsPeopleOzExternalMergedpeopleapiBestDisplayName {
  /**
   * The container the suggested name was sourced from
   */
  containerType?:  | "UNKNOWN_CONTAINER" | "PROFILE" | "CONTACT" | "CIRCLE" | "PLACE" | "ACCOUNT" | "EXTERNAL_ACCOUNT" | "DOMAIN_PROFILE" | "DOMAIN_CONTACT" | "DEVICE_CONTACT" | "GOOGLE_GROUP" | "NAMED_CHAT_ROOM" | "UNNAMED_CHAT_ROOM" | "AFFINITY" | "RAW_DEVICE_CONTACT" | "CONTACT_ANNOTATION" | "DELEGATED_CONTACT";
  /**
   * The display name. This name is intended to be the best name to display for
   * this Person. It may be built from a variety of fields, even if those fields
   * are not explicitly requested in the request mask. Generally, the display
   * name is formatted in 'first last' format. If the name appears to be a CJK
   * name (as determined by a heuristic), the 'last first' format will be used.
   * There may be other cases that the 'last first' format is used which are not
   * documented here. See the code at:
   * http://google3/java/com/google/focus/backend/client/DisplayNameFormatter.java?l=659&rcl=351360938
   */
  displayName?: string;
  /**
   * The display name, always in 'last first' format. This field does not
   * depend on the format of `display_name` and will always be in 'last first'
   * format.
   */
  displayNameLastFirst?: string;
}

/**
 * IMPORTANT NOTES: - Requesting person.birthday requires membership in the
 * purpose limited data ACL group sgbe-ac-d-birthday-(read|mutate). Contact
 * people-api-eng@ for assistance with initial setup. - The birthday field
 * should not be used to calculate the requester's age! To determine the
 * requester's age, use person.age_range_repeated. - For more details about age
 * see go/peopleapi-howto/age Birthday value may not be present: - Consumer
 * users generally required to have account birthday set (required at account
 * creation), though some users created via legacy flows may not have birthday
 * present. - Dasher users generally don't require birthday, but could
 * optionally have it set by users. - Any other types of accounts (e.g. robot,
 * service) do not have birthdays. - Account Birthday field may be present but
 * without birthday value set for grace period birthday (provisional new
 * birthday). For users that do have birthday data: - "Profile Birthday"
 * (person.birthday.metadata.container is PROFILE) may not have a year set if
 * user "hides" the year. - "Account Birthday" (see api-specific notes below)
 * will only be returned for the requester's own profile. - People API
 * (go/peopleapi): * Account birthday is only supported in GetPeople for
 * PeopleAPI. * If account birthday is needed, use a request mask with:
 * `include_field { paths: "person.birthday" }` `include_container: ACCOUNT` -
 * People API++ (go/peopleapi++): * Account birthday is supported for most apis
 * in PeopleAPI++. * If account birthday is needed, use a request mask with:
 * `include_field { paths: "person.account_birthday" }` `include_container:
 * PROFILE` (note: it will also need `include_container: DOMAIN_PROFILE` because
 * they must be requested together: go/people-api-masks#profile-domain_profile)
 * - See go/papi-vs-papi++#birthday for more details.
 */
export interface AppsPeopleOzExternalMergedpeopleapiBirthday {
  /**
   * Only supported for PROFILE/DOMAIN_PROFILE/ACCOUNT container.
   */
  ageDisableGracePeriod?: AppsPeopleOzExternalMergedpeopleapiBirthdayAgeDisableGracePeriod;
  /**
   * Whether the user has opted in to display their birthday via photo
   * decorations. Only supported for PROFILE/DOMAIN_PROFILE container.
   */
  birthdayDecoration?: SocialGraphApiProtoBirthdayDecoration;
  /**
   * Only supported for PROFILE/DOMAIN_PROFILE/ACCOUNT container.
   */
  birthdayResolution?:  | "FULL" | "MONTH_AND_APPROXIMATED_YEAR" | "APPROXIMATED_YEAR";
  /**
   * Birthdays are more accurately represented as a calendar day that does not
   * depend on a timestamp representation at all. When given a timestamp, there
   * are lots of opportunities to make mistakes, so a CalendarDay proto is
   * replacing timestamps. Currently this is always returned by PeopleApi on
   * reads that include birthday fields. New clients should write using
   * calendar_day. Clients that were already writing via date_ms are allowlisted
   * such that writes use that field. Old callers should migrate to writing BOTH
   * date_ms and calendar_day values. If those are consistent, they may be
   * removed from the 'legacy_timestamp_event_write_behavior_enabled'
   * capability.
   */
  calendarDay?: GoogleTypeDate;
  /**
   * Birthdays are currently represented as timestamp values, although the
   * interpretation of these timestamp values is a calendar date. Clients are
   * recommended to read the calendar_day field, which is easier to work with
   * than date_ms. New clients writing to PeopleApi must set calendar_day
   * instead of date_ms. There are a few important details about how this value
   * should be mapped to a calendar date that should be consistent among all
   * clients. 1. Epoch - The epoch or calendar date equivalent to 0 ms is chosen
   * to be 1970-01-01 UTC. 2. Timezone - All of the conversions to calendars
   * should occur in the UTC timezone. We don't typically think of someones
   * birthday changing when they travel, so clients should not use local times.
   * 3. Calendar - The calendar used for the dates should be a Gregorian
   * proleptic calendar. Proleptic means that the rules of the Gregorian
   * calendar are retrofitted to before its adoption. It is easy to get this
   * wrong, particularly with the java GregorianCalendar class, which by default
   * is a mixed Gregorian/Julian calendar. Joda Time makes this easy, but if
   * it's not an option, look into GregorianCalendar.setGregorianChange(). 4.
   * Omitted years - Clients have chosen to represent birthdays or events
   * without years as timestamps within the year zero. When the computed date
   * has a year of 0, it means the client did not specify a year. Note that a
   * year 0 does not exist in a chronology like the familiar Anno Domini (A.D.
   * and B.C.); clients must agree on year numbering. 5. Year Numbering - The
   * chronology used to map dates to the calendar should use Astronomical Year
   * Numbering so that the year 0 is defined and dates before it have a negative
   * year. If libraries only provide Anno Domini, then the year of 1 BC
   * corresponds to year zero and an omitted user provided year. Other BC values
   * are presumed rare, but clients should still not ignore the era and
   * interpret the year as an A.D. value, especially if writing values back to
   * PeopleApi.
   */
  dateMs?: bigint;
  /**
   * date_ms_as_number contains the same data as date_ms, but has a different
   * type in generated javascript bindings. Non javascript clients can ignore
   * it.
   */
  dateMsAsNumber?: bigint;
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
  /**
   * People Prompts settings for contact birthday data. Only supported for
   * CONTACT container.
   */
  prompt?: SocialGraphApiProtoPrompt;
  /**
   * Actual value entered. Allows unstructured values.
   */
  value?: string;
}

function serializeAppsPeopleOzExternalMergedpeopleapiBirthday(data: any): AppsPeopleOzExternalMergedpeopleapiBirthday {
  return {
    ...data,
    ageDisableGracePeriod: data["ageDisableGracePeriod"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiBirthdayAgeDisableGracePeriod(data["ageDisableGracePeriod"]) : undefined,
    dateMs: data["dateMs"] !== undefined ? String(data["dateMs"]) : undefined,
    dateMsAsNumber: data["dateMsAsNumber"] !== undefined ? String(data["dateMsAsNumber"]) : undefined,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
    prompt: data["prompt"] !== undefined ? serializeSocialGraphApiProtoPrompt(data["prompt"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiBirthday(data: any): AppsPeopleOzExternalMergedpeopleapiBirthday {
  return {
    ...data,
    ageDisableGracePeriod: data["ageDisableGracePeriod"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiBirthdayAgeDisableGracePeriod(data["ageDisableGracePeriod"]) : undefined,
    dateMs: data["dateMs"] !== undefined ? BigInt(data["dateMs"]) : undefined,
    dateMsAsNumber: data["dateMsAsNumber"] !== undefined ? BigInt(data["dateMsAsNumber"]) : undefined,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
    prompt: data["prompt"] !== undefined ? deserializeSocialGraphApiProtoPrompt(data["prompt"]) : undefined,
  };
}

/**
 * Whether this field is set or not determines whether an account is in the
 * grace period. While in the grace period, the user is unable to change their
 * birthday on their own, and will be age-disabled if they don't act in a
 * limited amount of time. Applies only to ServiceData Birthday. Users enter the
 * grace period if they choose a birthday below the Age of Consent (go/aoc).
 * After the grace period ends, the account will be age disabled. See
 * go/age-disable-grace-period-dd.
 */
export interface AppsPeopleOzExternalMergedpeopleapiBirthdayAgeDisableGracePeriod {
  /**
   * Provisional birthday <AoC the user provided, which made them enter the
   * grace period. The main birthday fields were not altered yet while in the
   * grace period.
   */
  calendarDay?: GoogleTypeDate;
  /**
   * Timestamp which signifies the end of the grace period for this account.
   */
  gracePeriodEnd?: Date;
  /**
   * Timestamp which signifies the start of the grace period for this account.
   */
  gracePeriodStart?: Date;
  gracePeriodType?:  | "UNKNOWN" | "USER_SPECIFIED_BIRTHDAY" | "UNDERAGE_SUSPECTED";
  manualGracePeriodInfo?: AppsPeopleOzExternalMergedpeopleapiBirthdayAgeDisableGracePeriodManualGracePeriodInfo;
}

function serializeAppsPeopleOzExternalMergedpeopleapiBirthdayAgeDisableGracePeriod(data: any): AppsPeopleOzExternalMergedpeopleapiBirthdayAgeDisableGracePeriod {
  return {
    ...data,
    gracePeriodEnd: data["gracePeriodEnd"] !== undefined ? data["gracePeriodEnd"].toISOString() : undefined,
    gracePeriodStart: data["gracePeriodStart"] !== undefined ? data["gracePeriodStart"].toISOString() : undefined,
    manualGracePeriodInfo: data["manualGracePeriodInfo"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiBirthdayAgeDisableGracePeriodManualGracePeriodInfo(data["manualGracePeriodInfo"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiBirthdayAgeDisableGracePeriod(data: any): AppsPeopleOzExternalMergedpeopleapiBirthdayAgeDisableGracePeriod {
  return {
    ...data,
    gracePeriodEnd: data["gracePeriodEnd"] !== undefined ? new Date(data["gracePeriodEnd"]) : undefined,
    gracePeriodStart: data["gracePeriodStart"] !== undefined ? new Date(data["gracePeriodStart"]) : undefined,
    manualGracePeriodInfo: data["manualGracePeriodInfo"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiBirthdayAgeDisableGracePeriodManualGracePeriodInfo(data["manualGracePeriodInfo"]) : undefined,
  };
}

/**
 * Information provided within MutateDataRequest when setting a user into
 * AgeDisableGracePeriod manually. When the grace period expires, this info will
 * be forwarded to Gaia when disabling the user.
 * cs//symbol:InitiateAgeDisableGracePeriodArguments
 */
export interface AppsPeopleOzExternalMergedpeopleapiBirthdayAgeDisableGracePeriodManualGracePeriodInfo {
  /**
   * The Gaia ID of an email that ops can send inquiries to for appeals.
   */
  escalateTo?: bigint;
  /**
   * The Gaia ID of a Googler who initiated this disable.
   */
  executedBy?: bigint;
  /**
   * When setting a user into age grace period manually, the requester can
   * additionally supply a short human-readable reason of why the account is put
   * into manual grace period. The description will be forwarded to Gaia when we
   * disable the account when the grace period expires.
   */
  reason?: string;
}

function serializeAppsPeopleOzExternalMergedpeopleapiBirthdayAgeDisableGracePeriodManualGracePeriodInfo(data: any): AppsPeopleOzExternalMergedpeopleapiBirthdayAgeDisableGracePeriodManualGracePeriodInfo {
  return {
    ...data,
    escalateTo: data["escalateTo"] !== undefined ? String(data["escalateTo"]) : undefined,
    executedBy: data["executedBy"] !== undefined ? String(data["executedBy"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiBirthdayAgeDisableGracePeriodManualGracePeriodInfo(data: any): AppsPeopleOzExternalMergedpeopleapiBirthdayAgeDisableGracePeriodManualGracePeriodInfo {
  return {
    ...data,
    escalateTo: data["escalateTo"] !== undefined ? BigInt(data["escalateTo"]) : undefined,
    executedBy: data["executedBy"] !== undefined ? BigInt(data["executedBy"]) : undefined,
  };
}

export interface AppsPeopleOzExternalMergedpeopleapiBraggingRights {
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
  value?: string;
}

function serializeAppsPeopleOzExternalMergedpeopleapiBraggingRights(data: any): AppsPeopleOzExternalMergedpeopleapiBraggingRights {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiBraggingRights(data: any): AppsPeopleOzExternalMergedpeopleapiBraggingRights {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

/**
 * A url to the person's calendar. As of 03/2018 is not supported for user
 * Profile.
 */
export interface AppsPeopleOzExternalMergedpeopleapiCalendar {
  /**
   * The `type` translated and formatted in the request locale. See
   * go/people-api-howto/localization for details on how to usage.
   */
  formattedType?: string;
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
  /**
   * The type of the calendar URL. The type can be free form or one of these
   * predefined values: * `home` * `freeBusy` * `work`
   */
  type?: string;
  url?: string;
}

function serializeAppsPeopleOzExternalMergedpeopleapiCalendar(data: any): AppsPeopleOzExternalMergedpeopleapiCalendar {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiCalendar(data: any): AppsPeopleOzExternalMergedpeopleapiCalendar {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

export interface AppsPeopleOzExternalMergedpeopleapiCallerIdExtendedData {
  /**
   * Indicates which data source was used to populate the caller ID result
   */
  callerIdSource?: AppsPeopleOzExternalMergedpeopleapiCallerIdExtendedDataCallerIdSource;
}

export interface AppsPeopleOzExternalMergedpeopleapiCallerIdExtendedDataCallerIdSource {
  sourceType?:  | "UNKNOWN_SOURCE_TYPE" | "PLACE" | "SCOOBY_MANUAL" | "SCOOBY_GOOGLE_VOICE" | "SCOOBY_CSA" | "SCOOBY_KNOWLEDGE_GRAPH";
}

/**
 * Information related to domain administrator (or authority) certification of
 * a users age.
 */
export interface AppsPeopleOzExternalMergedpeopleapiCertifiedBornBefore {
  /**
   * Indicates that the user was born at or before this time.
   */
  bornBefore?: Date;
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
}

function serializeAppsPeopleOzExternalMergedpeopleapiCertifiedBornBefore(data: any): AppsPeopleOzExternalMergedpeopleapiCertifiedBornBefore {
  return {
    ...data,
    bornBefore: data["bornBefore"] !== undefined ? data["bornBefore"].toISOString() : undefined,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiCertifiedBornBefore(data: any): AppsPeopleOzExternalMergedpeopleapiCertifiedBornBefore {
  return {
    ...data,
    bornBefore: data["bornBefore"] !== undefined ? new Date(data["bornBefore"]) : undefined,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

export interface AppsPeopleOzExternalMergedpeopleapiChannelData {
  /**
   * Unique ID that corresponds to a Youtube channel.
   */
  channelId?: string;
  /**
   * Number of comments for a given Youtube channel.
   */
  commentCount?: bigint;
  /**
   * Description of the channel.
   */
  description?: string;
  playlistCount?: bigint;
  /**
   * A FIFE URL pointing to the channel's profile image (go/avatar-fife-urls)
   * with default fife url options. Also refer to go/people-api-concepts:photos
   * for People API's FIFE best practices. The image could be up to a couple of
   * days stale, though it is much fresher in practice. If a fresh image is
   * required, contact the YouTubeAccountProfileService. The URL itself expires
   * ~30 days after generation.
   */
  profilePictureUrl?: string;
  /**
   * URL of user's Youtube channel profile.
   */
  profileUrl?: string;
  /**
   * Number of subscribers for a given Youtube channel.
   */
  subscriberCount?: bigint;
  /**
   * Title of the YouTube channel
   */
  title?: string;
  /**
   * Whether or not the channel's profile has a title/avatar that is canonical
   * in YouTube. Used to determine if the product profile card should be part of
   * the core persona or have their own persona.
   */
  usesYoutubeNames?: boolean;
  /**
   * Number of videos uploaded in a given Youtube channel.
   */
  videoCount?: bigint;
}

function serializeAppsPeopleOzExternalMergedpeopleapiChannelData(data: any): AppsPeopleOzExternalMergedpeopleapiChannelData {
  return {
    ...data,
    commentCount: data["commentCount"] !== undefined ? String(data["commentCount"]) : undefined,
    playlistCount: data["playlistCount"] !== undefined ? String(data["playlistCount"]) : undefined,
    subscriberCount: data["subscriberCount"] !== undefined ? String(data["subscriberCount"]) : undefined,
    videoCount: data["videoCount"] !== undefined ? String(data["videoCount"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiChannelData(data: any): AppsPeopleOzExternalMergedpeopleapiChannelData {
  return {
    ...data,
    commentCount: data["commentCount"] !== undefined ? BigInt(data["commentCount"]) : undefined,
    playlistCount: data["playlistCount"] !== undefined ? BigInt(data["playlistCount"]) : undefined,
    subscriberCount: data["subscriberCount"] !== undefined ? BigInt(data["subscriberCount"]) : undefined,
    videoCount: data["videoCount"] !== undefined ? BigInt(data["videoCount"]) : undefined,
  };
}

/**
 * A circle membership that the person has. A circle membership is created by
 * adding a person to a circle by person-id or by email.
 */
export interface AppsPeopleOzExternalMergedpeopleapiCircleMembership {
  /**
   * The circle that the person belongs to.
   */
  circleId?: string;
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
}

function serializeAppsPeopleOzExternalMergedpeopleapiCircleMembership(data: any): AppsPeopleOzExternalMergedpeopleapiCircleMembership {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiCircleMembership(data: any): AppsPeopleOzExternalMergedpeopleapiCircleMembership {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

/**
 * Arbitrary client data that is populated based on the client
 */
export interface AppsPeopleOzExternalMergedpeopleapiClientData {
  key?: string;
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
  namespace?: string;
  value?: string;
}

function serializeAppsPeopleOzExternalMergedpeopleapiClientData(data: any): AppsPeopleOzExternalMergedpeopleapiClientData {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiClientData(data: any): AppsPeopleOzExternalMergedpeopleapiClientData {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

/**
 * Email for Google product communication with the user. This is only allowed
 * in ServiceData. It is purely synthesized and read-only, and contains at most
 * one field. It proxies from RawCommunicationEmail and only includes the
 * primary field if exists. Otherwise if RawCommunicationEmail does not have
 * primary, this includes a field synthesized from valid Gaia primary account
 * email. Otherwise if Gaia primary account email is invalid, this field is
 * empty. See go/comm-email-use for more details.
 */
export interface AppsPeopleOzExternalMergedpeopleapiCommunicationEmail {
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
  value?: string;
}

function serializeAppsPeopleOzExternalMergedpeopleapiCommunicationEmail(data: any): AppsPeopleOzExternalMergedpeopleapiCommunicationEmail {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiCommunicationEmail(data: any): AppsPeopleOzExternalMergedpeopleapiCommunicationEmail {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

/**
 * Contact-level people-prompts settings and contact-level connection
 * reminders. Part of go/people-prompts.
 */
export interface AppsPeopleOzExternalMergedpeopleapiConnectionReminder {
  /**
   * Contains the Contact level settings that will affect all reminders.
   */
  contactPromptSettings?: SocialGraphApiProtoContactPromptSettings;
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
  /**
   * Contact-level "reminder to connect" prompts for this contact.
   */
  prompt?: SocialGraphApiProtoPrompt[];
}

function serializeAppsPeopleOzExternalMergedpeopleapiConnectionReminder(data: any): AppsPeopleOzExternalMergedpeopleapiConnectionReminder {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
    prompt: data["prompt"] !== undefined ? data["prompt"].map((item: any) => (serializeSocialGraphApiProtoPrompt(item))) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiConnectionReminder(data: any): AppsPeopleOzExternalMergedpeopleapiConnectionReminder {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
    prompt: data["prompt"] !== undefined ? data["prompt"].map((item: any) => (deserializeSocialGraphApiProtoPrompt(item))) : undefined,
  };
}

/**
 * Contact creation timestamps and related metadata. See
 * go/contact-edit-history. This message is a pure wrapper of the shared
 * ContactCreactionContext message so that it can be a top-level person field.
 * No other fields should be added to the message.
 */
export interface AppsPeopleOzExternalMergedpeopleapiContactCreateContextInfo {
  contactCreateContext?: SocialGraphApiProtoContactCreateContext;
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
}

function serializeAppsPeopleOzExternalMergedpeopleapiContactCreateContextInfo(data: any): AppsPeopleOzExternalMergedpeopleapiContactCreateContextInfo {
  return {
    ...data,
    contactCreateContext: data["contactCreateContext"] !== undefined ? serializeSocialGraphApiProtoContactCreateContext(data["contactCreateContext"]) : undefined,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiContactCreateContextInfo(data: any): AppsPeopleOzExternalMergedpeopleapiContactCreateContextInfo {
  return {
    ...data,
    contactCreateContext: data["contactCreateContext"] !== undefined ? deserializeSocialGraphApiProtoContactCreateContext(data["contactCreateContext"]) : undefined,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

/**
 * Contact edit timestamps and related metadata. See go/contact-edit-history.
 * This message is a pure wrapper of the shared ContactCreactionContext message
 * so that it can be a top-level person field. No other fields should be added
 * to the message.
 */
export interface AppsPeopleOzExternalMergedpeopleapiContactEditContextInfo {
  contactEditContext?: SocialGraphApiProtoContactEditContext;
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
}

function serializeAppsPeopleOzExternalMergedpeopleapiContactEditContextInfo(data: any): AppsPeopleOzExternalMergedpeopleapiContactEditContextInfo {
  return {
    ...data,
    contactEditContext: data["contactEditContext"] !== undefined ? serializeSocialGraphApiProtoContactEditContext(data["contactEditContext"]) : undefined,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiContactEditContextInfo(data: any): AppsPeopleOzExternalMergedpeopleapiContactEditContextInfo {
  return {
    ...data,
    contactEditContext: data["contactEditContext"] !== undefined ? deserializeSocialGraphApiProtoContactEditContext(data["contactEditContext"]) : undefined,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

/**
 * A membership that the person has. The person can be a member of multiple
 * circles and multiple contact-groups. A circle membership is created by adding
 * a person to a circle by person-id or by email. A contact-group membership is
 * created by adding a contact to a contact-group.
 */
export interface AppsPeopleOzExternalMergedpeopleapiContactGroupMembership {
  /**
   * The contact-group that the person belong to. The id can be either a
   * hex-formatted id or a camel-cased SystemContactGroup predefined group name.
   * The id will be predefined group name iff the system_contact_group_id has a
   * value.
   */
  contactGroupId?: string;
  /**
   * Information related to delegated group that this contact belongs to.
   */
  delegatedGroupInfo?: AppsPeopleOzExternalMergedpeopleapiDelegatedGroupInfo;
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
  /**
   * This field will be populated when the membership is in a system-reserved
   * contact-group.
   */
  systemContactGroupId?:  | "UNKNOWN" | "MY_CONTACTS" | "STARRED" | "FRIENDS" | "FAMILY" | "COWORKERS";
}

function serializeAppsPeopleOzExternalMergedpeopleapiContactGroupMembership(data: any): AppsPeopleOzExternalMergedpeopleapiContactGroupMembership {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiContactGroupMembership(data: any): AppsPeopleOzExternalMergedpeopleapiContactGroupMembership {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

/**
 * Contact state and related metadata. See go/fbs-contacts-trash. This message
 * is a pure wrapper of the shared ContactState message so that it can be a
 * top-level person field. No other fields should be added to the message.
 */
export interface AppsPeopleOzExternalMergedpeopleapiContactStateInfo {
  contactState?: SocialGraphApiProtoContactState;
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
}

function serializeAppsPeopleOzExternalMergedpeopleapiContactStateInfo(data: any): AppsPeopleOzExternalMergedpeopleapiContactStateInfo {
  return {
    ...data,
    contactState: data["contactState"] !== undefined ? serializeSocialGraphApiProtoContactState(data["contactState"]) : undefined,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiContactStateInfo(data: any): AppsPeopleOzExternalMergedpeopleapiContactStateInfo {
  return {
    ...data,
    contactState: data["contactState"] !== undefined ? deserializeSocialGraphApiProtoContactState(data["contactState"]) : undefined,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

/**
 * CoverPhoto is the long banner photo (also called full bleed photo) at the
 * top of G+ profile page.
 */
export interface AppsPeopleOzExternalMergedpeopleapiCoverPhoto {
  imageHeight?: number;
  imageId?: string;
  imageUrl?: string;
  imageWidth?: number;
  isAnimated?: boolean;
  isDefault?: boolean;
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
}

function serializeAppsPeopleOzExternalMergedpeopleapiCoverPhoto(data: any): AppsPeopleOzExternalMergedpeopleapiCoverPhoto {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiCoverPhoto(data: any): AppsPeopleOzExternalMergedpeopleapiCoverPhoto {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

/**
 * Contains customer data for profile owner proxied from D3.
 */
export interface AppsPeopleOzExternalMergedpeopleapiCustomerInfo {
  /**
   * DEPRECATED. Use obfuscated_customer_id instead. If result has a GSuite
   * Customer ID, this field will continue to be populated with -1 to indicate
   * the presence of a value for backwards compatibility with clients in the
   * wild. See b/144596193.
   */
  customerId?: bigint;
  /**
   * Customer organization name for dasher user.
   */
  customerName?: string;
  /**
   * Obfuscated FlexOrgs customer ID for Dasher user. See
   * cs/symbol:CustomerIdObfuscator.
   */
  obfuscatedCustomerId?: string;
}

function serializeAppsPeopleOzExternalMergedpeopleapiCustomerInfo(data: any): AppsPeopleOzExternalMergedpeopleapiCustomerInfo {
  return {
    ...data,
    customerId: data["customerId"] !== undefined ? String(data["customerId"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiCustomerInfo(data: any): AppsPeopleOzExternalMergedpeopleapiCustomerInfo {
  return {
    ...data,
    customerId: data["customerId"] !== undefined ? BigInt(data["customerId"]) : undefined,
  };
}

/**
 * Custom fields associated with a person, from the custom schema defined on
 * the domain. See go/custompeopleapi and go/customfocus. NOTE: these are only
 * updatable via Cloud Directory (go/cd).
 */
export interface AppsPeopleOzExternalMergedpeopleapiCustomSchemaField {
  fieldDisplayName?: string;
  fieldId?: string;
  fieldType?:  | "CUSTOM_FIELD_TYPE_UNKNOWN" | "STRING" | "INT64" | "BOOL" | "DOUBLE" | "EMAIL" | "PHONE" | "DATE";
  /**
   * The `type` translated and formatted in the request locale. See
   * go/people-api-howto/localization for details on how to usage.
   */
  formattedType?: string;
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
  multiValued?: boolean;
  schemaDisplayName?: string;
  schemaId?: string;
  /**
   * The type of the custom schema field. The type can be free form or one of
   * these predefined values: * `home` * `other` * `work`
   */
  type?: string;
  /**
   * String representation of the value, based on FieldType
   */
  value?: string;
}

function serializeAppsPeopleOzExternalMergedpeopleapiCustomSchemaField(data: any): AppsPeopleOzExternalMergedpeopleapiCustomSchemaField {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiCustomSchemaField(data: any): AppsPeopleOzExternalMergedpeopleapiCustomSchemaField {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

/**
 * Container information for deduping. When two fields have the same value and
 * only differ by field.metadata a service implementation can choose to avoid
 * duplicating the fields and instead set
 * field.metadata.other_deduped_containers This type can include information on
 * the dedupe type (for example, strict value match vs. lenient value match)
 */
export interface AppsPeopleOzExternalMergedpeopleapiDedupedContainerInfo {
  /**
   * See SourceIdentity.container_type
   */
  containerType?:  | "UNKNOWN_CONTAINER" | "PROFILE" | "CONTACT" | "CIRCLE" | "PLACE" | "ACCOUNT" | "EXTERNAL_ACCOUNT" | "DOMAIN_PROFILE" | "DOMAIN_CONTACT" | "DEVICE_CONTACT" | "GOOGLE_GROUP" | "NAMED_CHAT_ROOM" | "UNNAMED_CHAT_ROOM" | "AFFINITY" | "RAW_DEVICE_CONTACT" | "CONTACT_ANNOTATION" | "DELEGATED_CONTACT";
  /**
   * See SourceIdentity.id
   */
  id?: string;
}

/**
 * Information related to delegated group that this contact belongs to.
 */
export interface AppsPeopleOzExternalMergedpeopleapiDelegatedGroupInfo {
  /**
   * Required. The additional id specifically for a delegated group.
   */
  delegatedGroupId?: SocialGraphApiProtoDelegatedGroupId;
}

/**
 * Extra metadata for an aggregated or raw device contact.
 */
export interface AppsPeopleOzExternalMergedpeopleapiDeviceContactExtraMetadata {
  /**
   * Attributes for this device contact.
   */
  attributes?:  | "ATTRIBUTE_UNKNOWN" | "STARRED"[];
  /**
   * Usage info for this device contact.
   */
  usageInfo?: SocialGraphApiProtoUsageInfo[];
}

function serializeAppsPeopleOzExternalMergedpeopleapiDeviceContactExtraMetadata(data: any): AppsPeopleOzExternalMergedpeopleapiDeviceContactExtraMetadata {
  return {
    ...data,
    usageInfo: data["usageInfo"] !== undefined ? data["usageInfo"].map((item: any) => (serializeSocialGraphApiProtoUsageInfo(item))) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiDeviceContactExtraMetadata(data: any): AppsPeopleOzExternalMergedpeopleapiDeviceContactExtraMetadata {
  return {
    ...data,
    usageInfo: data["usageInfo"] !== undefined ? data["usageInfo"].map((item: any) => (deserializeSocialGraphApiProtoUsageInfo(item))) : undefined,
  };
}

/**
 * Unique id for an aggregated device contact.
 */
export interface AppsPeopleOzExternalMergedpeopleapiDeviceContactId {
  /**
   * Aggregated device contact id on the source device.
   */
  contactId?: bigint;
  /**
   * Source device id (go/client-instance-id) of this device contact.
   */
  deviceId?: string;
}

function serializeAppsPeopleOzExternalMergedpeopleapiDeviceContactId(data: any): AppsPeopleOzExternalMergedpeopleapiDeviceContactId {
  return {
    ...data,
    contactId: data["contactId"] !== undefined ? String(data["contactId"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiDeviceContactId(data: any): AppsPeopleOzExternalMergedpeopleapiDeviceContactId {
  return {
    ...data,
    contactId: data["contactId"] !== undefined ? BigInt(data["contactId"]) : undefined,
  };
}

/**
 * Device contact information.
 */
export interface AppsPeopleOzExternalMergedpeopleapiDeviceContactInfo {
  /**
   * Metadata for this device contact.
   */
  deviceContactMetadata?: AppsPeopleOzExternalMergedpeopleapiDeviceContactExtraMetadata;
  /**
   * Output only. True if any of the contact's phone, email or address fields
   * can be used on devices other than the one it originated from. Note that
   * there can be other fields, typically name, and metadata such as some of the
   * raw_contact_infos that can be used on other devices. Assigned by the
   * server.
   */
  hasCrossDeviceData?: boolean;
  /**
   * Id of the device contact.
   */
  id?: AppsPeopleOzExternalMergedpeopleapiDeviceContactId;
  /**
   * Last time a device contact was updated on device.
   */
  lastClientUpdateTime?: Date;
  /**
   * An opaque value used by the device to look up this contact if its row id
   * changed as a result of a sync or aggregation. See:
   * https://developer.android.com/reference/android/provider/ContactsContract.ContactsColumns.html#LOOKUP_KEY
   */
  lookupKey?: string;
  /**
   * Info about the raw device contacts that make up this device contact.
   */
  rawContactInfo?: AppsPeopleOzExternalMergedpeopleapiRawDeviceContactInfo[];
}

function serializeAppsPeopleOzExternalMergedpeopleapiDeviceContactInfo(data: any): AppsPeopleOzExternalMergedpeopleapiDeviceContactInfo {
  return {
    ...data,
    deviceContactMetadata: data["deviceContactMetadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiDeviceContactExtraMetadata(data["deviceContactMetadata"]) : undefined,
    id: data["id"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiDeviceContactId(data["id"]) : undefined,
    lastClientUpdateTime: data["lastClientUpdateTime"] !== undefined ? data["lastClientUpdateTime"].toISOString() : undefined,
    rawContactInfo: data["rawContactInfo"] !== undefined ? data["rawContactInfo"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiRawDeviceContactInfo(item))) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiDeviceContactInfo(data: any): AppsPeopleOzExternalMergedpeopleapiDeviceContactInfo {
  return {
    ...data,
    deviceContactMetadata: data["deviceContactMetadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiDeviceContactExtraMetadata(data["deviceContactMetadata"]) : undefined,
    id: data["id"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiDeviceContactId(data["id"]) : undefined,
    lastClientUpdateTime: data["lastClientUpdateTime"] !== undefined ? new Date(data["lastClientUpdateTime"]) : undefined,
    rawContactInfo: data["rawContactInfo"] !== undefined ? data["rawContactInfo"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiRawDeviceContactInfo(item))) : undefined,
  };
}

export interface AppsPeopleOzExternalMergedpeopleapiEdgeKeyInfo {
  /**
   * The container ID of the entity this field creates a join to. See
   * `SourceIdentity.id`.
   */
  containerId?: string;
  /**
   * The type of container that this edge points to. See
   * `SourceIdentity.container_type`.
   */
  containerType?:  | "UNKNOWN_CONTAINER" | "PROFILE" | "CONTACT" | "CIRCLE" | "PLACE" | "ACCOUNT" | "EXTERNAL_ACCOUNT" | "DOMAIN_PROFILE" | "DOMAIN_CONTACT" | "DEVICE_CONTACT" | "GOOGLE_GROUP" | "NAMED_CHAT_ROOM" | "UNNAMED_CHAT_ROOM" | "AFFINITY" | "RAW_DEVICE_CONTACT" | "CONTACT_ANNOTATION" | "DELEGATED_CONTACT";
  /**
   * Data that is added to the proto by peopleapi read extensions.
   */
  extendedData?: AppsPeopleOzExternalMergedpeopleapiEdgeKeyInfoExtensionData;
  /**
   * True indicates this edge links this source to a container represented by
   * this person object. Note: Except for certain legacy clients, EdgeKeyInfo is
   * only created for for edges to an entity in this person and this will always
   * be true.
   */
  materialized?: boolean;
}

export interface AppsPeopleOzExternalMergedpeopleapiEdgeKeyInfoExtensionData {
  /**
   * The GDataCompatibilityExtension will (temporarily) return mobile_owner_id
   * for profile containers.
   */
  gdataCompatibilityExtensionId?: string;
}

export interface AppsPeopleOzExternalMergedpeopleapiEmail {
  certificate?: AppsPeopleOzExternalMergedpeopleapiEmailCertificate[];
  classification?:  | "EMAIL_CLASSIFICATION_UNKNOWN" | "SIGNUP_EMAIL";
  /**
   * To read or update, use the CONTACT_GROUP_PREFERENCE mask field.
   */
  contactGroupPreference?: AppsPeopleOzExternalMergedpeopleapiEmailContactGroupPreference[];
  displayName?: string;
  extendedData?: AppsPeopleOzExternalMergedpeopleapiEmailExtendedData;
  /**
   * The `type` translated and formatted in the request locale. See
   * go/people-api-howto/localization for details on how to usage.
   */
  formattedType?: string;
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
  signupEmailMetadata?: AppsPeopleOzExternalMergedpeopleapiEmailSignupEmailMetadata;
  /**
   * The type of the email address. The type can be free form or one of these
   * predefined values: * `home` * `work` * `other`
   */
  type?: string;
  value?: string;
}

function serializeAppsPeopleOzExternalMergedpeopleapiEmail(data: any): AppsPeopleOzExternalMergedpeopleapiEmail {
  return {
    ...data,
    certificate: data["certificate"] !== undefined ? data["certificate"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiEmailCertificate(item))) : undefined,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiEmail(data: any): AppsPeopleOzExternalMergedpeopleapiEmail {
  return {
    ...data,
    certificate: data["certificate"] !== undefined ? data["certificate"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiEmailCertificate(item))) : undefined,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

/**
 * Represents a S/MIME certificate config for use with Gmail. See
 * //caribou/smime/proto/certificate_status.proto. There can be zero or more
 * certificates associated with an email address, be it profile email or contact
 * email.
 */
export interface AppsPeopleOzExternalMergedpeopleapiEmailCertificate {
  /**
   * The name of this certificate configuration. Examples could be "High
   * security level" or "For domain emails only".
   */
  configurationName?: string;
  /**
   * It is conceivable that certificates could be ACLed. We also need to
   * indicate which certificate is the default. The PersonFieldMetadata can
   * accomplish both of these.
   */
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
  status?: AppsPeopleOzExternalMergedpeopleapiEmailCertificateCertificateStatus;
}

function serializeAppsPeopleOzExternalMergedpeopleapiEmailCertificate(data: any): AppsPeopleOzExternalMergedpeopleapiEmailCertificate {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
    status: data["status"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiEmailCertificateCertificateStatus(data["status"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiEmailCertificate(data: any): AppsPeopleOzExternalMergedpeopleapiEmailCertificate {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
    status: data["status"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiEmailCertificateCertificateStatus(data["status"]) : undefined,
  };
}

/**
 * Minimal S/MIME certificate status i.e. two fields per email address.
 */
export interface AppsPeopleOzExternalMergedpeopleapiEmailCertificateCertificateStatus {
  /**
   * The certificate expiration timestamp in seconds.
   */
  notAfterSec?: bigint;
  /**
   * Current status of the email's certificate chain.
   */
  statusCode?:  | "UNKNOWN" | "CERTIFICATE_VALID" | "CERTIFICATE_MISSING" | "CERTIFICATE_EXPIRED" | "CERTIFICATE_REVOKED";
}

function serializeAppsPeopleOzExternalMergedpeopleapiEmailCertificateCertificateStatus(data: any): AppsPeopleOzExternalMergedpeopleapiEmailCertificateCertificateStatus {
  return {
    ...data,
    notAfterSec: data["notAfterSec"] !== undefined ? String(data["notAfterSec"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiEmailCertificateCertificateStatus(data: any): AppsPeopleOzExternalMergedpeopleapiEmailCertificateCertificateStatus {
  return {
    ...data,
    notAfterSec: data["notAfterSec"] !== undefined ? BigInt(data["notAfterSec"]) : undefined,
  };
}

/**
 * Preferred email addresses for contact groups.
 */
export interface AppsPeopleOzExternalMergedpeopleapiEmailContactGroupPreference {
  contactGroupId?: string;
  /**
   * If the Preference was implicitly set by PeopleApi. A preference with this
   * bit will not be saved. See go/contact-group-email-preference-papi-problem
   * for more info.
   */
  isSynthetic?: boolean;
  type?:  | "UNKNOWN" | "GMAIL";
}

/**
 * Extension data for a person email.
 */
export interface AppsPeopleOzExternalMergedpeopleapiEmailExtendedData {
  /**
   * For use with the CUSTOMER_INFO_ADDITIONAL_DATA extension. This includes
   * information on whether the given email is internal to or external to the
   * requesting user's domain.
   */
  internalExternal?: PeoplestackFlexorgsProtoInternalExternal;
  /**
   * For ListPeoplebyKnownId to indicate an email is sythesized from a lookup
   * email.
   */
  isPlaceholder?: boolean;
  /**
   * For use with the TLS extension. Whether the SMTP server that handles
   * delivery for this email address supports TLS encryption.
   */
  smtpServerSupportsTls?: boolean;
  /**
   * For use with the Gmail Homograph Warning extension. Whether the email
   * contains mixed character sets that could be used to decieve users. This
   * field is populated by the GMAIL_SECURITY_DATA extension.
   */
  usesConfusingCharacters?: boolean;
}

/**
 * Additional metadata for a signup email. This will only be set if the email's
 * classification is SIGNUP_EMAIL.
 */
export interface AppsPeopleOzExternalMergedpeopleapiEmailSignupEmailMetadata {
  /**
   * This is considered to be the primary signup email. At most 1 signup email
   * will have this set.
   */
  primary?: boolean;
}

/**
 * Emergency info for Person. See go/emergency-trusted-contacts-papi.
 */
export interface AppsPeopleOzExternalMergedpeopleapiEmergencyInfo {
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
  /**
   * Opaque id from Pomeroy (go/pomeroy). Non-empty pomeroy_id means that this
   * contact has the potential to become trusted contact or it's already trusted
   * contact. Trust is eventually gaia<->gaia link, but when the trust link is
   * initiated gaia might not be known. Until gaia is discovered, pomeroy_id is
   * used to identify the contact uniquely. If trust_level is missing or set to
   * TRUST_LEVEL_UNSPECIFIED pomeroy_id must be empty.
   */
  pomeroyId?: string;
  trustLevel?:  | "TRUST_LEVEL_UNSPECIFIED" | "TRUST_LEVEL_EMERGENCY_CONTACT";
}

function serializeAppsPeopleOzExternalMergedpeopleapiEmergencyInfo(data: any): AppsPeopleOzExternalMergedpeopleapiEmergencyInfo {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiEmergencyInfo(data: any): AppsPeopleOzExternalMergedpeopleapiEmergencyInfo {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

export interface AppsPeopleOzExternalMergedpeopleapiEvent {
  /**
   * Event are more accurately represented as a calendar day that does not
   * depend on a timestamp representation at all. When given a timestamp, there
   * are lots of opportunities to make mistakes, so a CalendarDay proto is
   * replacing timestamps. PeopleApi will return these values on reads, and
   * unless the client is a legacy caller in the
   * legacy_timestamp_event_write_behavior_enabled capability allowlist, this
   * value is what is used for Person writes.
   */
  calendarDay?: GoogleTypeDate;
  /**
   * The `type` translated and formatted in the request locale. See
   * go/people-api-howto/localization for details on how to usage.
   */
  formattedType?: string;
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
  /**
   * People Prompts settings for contact event data.
   */
  prompt?: SocialGraphApiProtoPrompt;
  /**
   * Clients are recommended to read the calendar_day field instead of
   * timestamp_millis. When writing events, new clients must set calendar_day
   * instead of timestamp_millis. Events are currently represented as timestamp
   * values, although the interpretation of these timestamp values is a calendar
   * date. There are a few important details about how this value should be
   * mapped to a calendar date that should be consistent among all clients. For
   * detailed information, see Birthday.date_ms.
   */
  timestampMillis?: bigint;
  /**
   * The type of the event. The type can be free form or one of these
   * predefined values: * `anniversary` * `other`
   */
  type?: string;
}

function serializeAppsPeopleOzExternalMergedpeopleapiEvent(data: any): AppsPeopleOzExternalMergedpeopleapiEvent {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
    prompt: data["prompt"] !== undefined ? serializeSocialGraphApiProtoPrompt(data["prompt"]) : undefined,
    timestampMillis: data["timestampMillis"] !== undefined ? String(data["timestampMillis"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiEvent(data: any): AppsPeopleOzExternalMergedpeopleapiEvent {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
    prompt: data["prompt"] !== undefined ? deserializeSocialGraphApiProtoPrompt(data["prompt"]) : undefined,
    timestampMillis: data["timestampMillis"] !== undefined ? BigInt(data["timestampMillis"]) : undefined,
  };
}

/**
 * External identifier associated with the person.
 */
export interface AppsPeopleOzExternalMergedpeopleapiExternalId {
  /**
   * The `type` translated and formatted in the request locale. See
   * go/people-api-howto/localization for details on how to usage.
   */
  formattedType?: string;
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
  /**
   * The type of the external ID. The type can be free form or one of these
   * predefined values: * `account` * `customer` * `loginId` * `network` *
   * `organization`
   */
  type?: string;
  value?: string;
}

function serializeAppsPeopleOzExternalMergedpeopleapiExternalId(data: any): AppsPeopleOzExternalMergedpeopleapiExternalId {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiExternalId(data: any): AppsPeopleOzExternalMergedpeopleapiExternalId {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

/**
 * The field ACL. Currently only populated on profile fields for the profile
 * owner. A Person field ACL; see http://go/peopleapi-acl
 */
export interface AppsPeopleOzExternalMergedpeopleapiFieldAcl {
  /**
   * A custom type of field ACL entry. The set of all ACL entries includes
   * those listed in acl_entry as well as predefined_acl_entry.
   */
  aclEntry?: AppsPeopleOzExternalMergedpeopleapiFieldAclAclEntry[];
  /**
   * Set of users that will be authorized to view the field by this field ACL.
   * If the ACL is public, this will only contain ALL_USERS. This field is
   * synthesized, read-only, and currently only used for profile photos. It's
   * populated under "person.photo.metadata.field_acl" for the current photo ACL
   * and "person.photo.metadata.acl_choices" for available photo ACL choices.
   * Note: The set of authorized viewers for a given FieldAcl may depend on the
   * user's account type and domain configuration. For example, a PRIVATE_READ
   * FieldAcl could have any of the following authorized viewers: Consumer user:
   * [IDENTITY_ACL_ESTABLISHED] Dasher user without domain contact sharing:
   * [IDENTITY_ACL_ESTABLISHED] Unicorn user: [SAME_UNICORN_FAMILY] Hafez user:
   * []
   */
  authorizedViewers?:  | "AUTHORIZED_VIEWER_UNSPECIFIED" | "IDENTITY_ACL_ESTABLISHED" | "SAME_ORGANIZATION" | "SAME_UNICORN_FAMILY" | "ALL_USERS"[];
  /**
   * A common type of field ACL entry. A predefined ACL entry is a shortcut for
   * a commonly occurring case of role and scope. For example, PUBLIC_READ is
   * the same as an AclEntry with role = READER and scope.all_users = true. The
   * set of all ACL entries includes those listed in acl_entry as well as
   * predefined_acl_entry.
   */
  predefinedAclEntry?:  | "UNKNOWN" | "OWNER" | "PUBLIC_READ" | "DOMAIN_READ" | "YOUR_CIRCLES_READ" | "EXTENDED_CIRCLES_READ" | "PRIVATE_READ"[];
}

export interface AppsPeopleOzExternalMergedpeopleapiFieldAclAclEntry {
  role?:  | "UNKNOWN" | "READER" | "WRITER" | "OWNER";
  scope?: AppsPeopleOzExternalMergedpeopleapiFieldAclAclEntryScope;
}

export interface AppsPeopleOzExternalMergedpeopleapiFieldAclAclEntryScope {
  /**
   * Indicates that the field is accessible to all users including
   * unauthenticated users. For some fields this means "to everyone except
   * blocked users".
   */
  allUsers?: boolean;
  /**
   * This is a "synthetic" field. In reality domains are treated as gaia-
   * groups. This field will be 'true' when the field is ACLed to the gaia-group
   * of the requester's domain.
   */
  domainUsers?: boolean;
  membership?: AppsPeopleOzExternalMergedpeopleapiFieldAclAclEntryScopeMembershipAcl;
  /**
   * Indicates that the field is accessible to a person.
   */
  person?: AppsPeopleOzExternalMergedpeopleapiFieldAclAclEntryScopePersonAcl;
}

/**
 * Used when the field is accessible to a membership that the person has.
 */
export interface AppsPeopleOzExternalMergedpeopleapiFieldAclAclEntryScopeMembershipAcl {
  circle?: AppsPeopleOzExternalMergedpeopleapiFieldAclAclEntryScopeMembershipAclCircleAcl;
  contactGroup?: AppsPeopleOzExternalMergedpeopleapiFieldAclAclEntryScopeMembershipAclContactGroupAcl;
}

/**
 * Used when a field is accessible to a circle.
 */
export interface AppsPeopleOzExternalMergedpeopleapiFieldAclAclEntryScopeMembershipAclCircleAcl {
  circleId?: string;
  circleSet?:  | "UNKNOWN" | "YOUR_CIRCLES" | "EXTENDED_CIRCLES";
  /**
   * Equivalent to Circle.display_name for the circle_id. Included when
   * FieldAclOption.FULL_ACL_WITH_DETAILS is requested. This field is read-only
   * and ignored on update.
   */
  displayName?: string;
}

/**
 * Used when a field is accessible to a legacy contact group. Contact groups
 * are discouraged and may be deprecated soon. ContactGroupAcls are read-only.
 * If they are included as part of an ACL on an Update, an exception is thrown.
 */
export interface AppsPeopleOzExternalMergedpeopleapiFieldAclAclEntryScopeMembershipAclContactGroupAcl {
  /**
   * A contact group ID. This is either a user-defined contact group hex ID, or
   * it is the string name of the enum constant in Group.PredefinedId in FBS
   * backend.proto for predefined groups. Common values for the predefined name
   * include, but are not limited to: all, myContacts, starred, chatBuddies,
   * friends, family, coworkers, and blocked.
   */
  contactGroupId?: string;
  /**
   * The localized display name for the predefined group, if known; or, the
   * display name for the user-defined contact group. Included when
   * FieldAclOption.FULL_ACL_WITH_DETAILS is requested.
   */
  displayName?: string;
}

/**
 * Used when a field is accessible to a person. NOTE: ACLs to a circle or to a
 * non-self person are no longer supported, so this can only be applied to the
 * requester self.
 */
export interface AppsPeopleOzExternalMergedpeopleapiFieldAclAclEntryScopePersonAcl {
  /**
   * DEPRECATED. This is not different than reading from person.name for a
   * self-read; ACLs to a circle or to a non-self person are no longer
   * supported. Equivalent to Name.display_name for the person_id profile.
   * Included when the profile Name is ACLed to the requester and
   * FieldAclOption.FULL_ACL_WITH_DETAILS is requested. This field is read-only
   * and ignored on update.
   */
  displayName?: string;
  personId?: string;
  /**
   * DEPRECATED. This is not different than reading from person.photo for a
   * self-read; ACLs to a circle or to a non-self person are no longer
   * supported. Equivalent to Photo.url for the person_id profile. Included when
   * the profile Photo is ACLed to the requester and
   * FieldAclOption.FULL_ACL_WITH_DETAILS is requested. This field is read-only
   * and ignored on update.
   */
  photoUrl?: string;
}

/**
 * Emergency information for Person field, such as Phone or Email. See
 * go/emergency-trusted-contacts-papi.
 */
export interface AppsPeopleOzExternalMergedpeopleapiFieldEmergencyInfo {
  emergencyLevel?:  | "EMERGENCY_LEVEL_UNSPECIFIED" | "EMERGENCY_LEVEL_PRIMARY";
}

/**
 * The FileAs field in Contacts is used to override the DisplayName of a
 * Contact for that User.
 */
export interface AppsPeopleOzExternalMergedpeopleapiFileAs {
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
  value?: string;
}

function serializeAppsPeopleOzExternalMergedpeopleapiFileAs(data: any): AppsPeopleOzExternalMergedpeopleapiFileAs {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiFileAs(data: any): AppsPeopleOzExternalMergedpeopleapiFileAs {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

/**
 * Gender in PeopleApi has some odd semantics about writing and reading that
 * are not obvious from the proto definition. First, the `type` string, when
 * read, always maps to the constrained domain of "male", "female", and "other",
 * aside from a pathological case that PeopleApi would like to fix. There are
 * two typical patterns: 1. `type` is either "male" or "female" and
 * `custom_type` and `address_me_as` are exactly as specified by an update to
 * PeopleApi, although they are most often absent for "male" and "female"
 * writes. 2. `type` is "other" and `custom_type` is set to a freeform string
 * from the request. `address_me_as` is equal to whatever was provided at write
 * time. When writing, the free-form string for `custom_type` can come from
 * either `custom_type` if the field is present on the request, or if
 * `custom_type` is absent, the string value of `type` will be copied into it.
 * Any value in `type` will be coerced to "other" and the free-form value will
 * be copied into `custom_type`, even if `type` is exactly "other". Prefer to
 * explicitly set `custom_type` and set type to "other" instead of setting type
 * to a free-form value. There are weird edge cases when the value is "unknown".
 * Consider the behavior for `type` == "unknown" unspecified. Clients reading
 * the gender should use the value from `formatted_type` if `type` is "male" or
 * "female". If `type` is "other", `formatted_type` will be "Other" (or some
 * translation) and clients should read `custom_type` for more specificity.
 */
export interface AppsPeopleOzExternalMergedpeopleapiGender {
  /**
   * Preferred pronoun choice. It's unclear whether this value is constrained
   * to a finite domain by UIs. `address_me_as` may be populated regardless of
   * whether `type` is "male", "female", or "other", although most writers only
   * set it if `type` is "other".
   */
  addressMeAs?: string;
  /**
   * A free-form string indicating what the user entered as their gender.
   * `custom_type` may exist even if the type is "male" or "female", although
   * most writers do not set it unless `type` is "other".
   */
  customType?: string;
  /**
   * The `type` translated and formatted in the request locale. See
   * go/people-api-howto/localization for details on how to usage.
   */
  formattedType?: string;
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
  /**
   * The gender. "male", "female", or "other". If "other", typically,
   * additional fields will have additional information.
   */
  type?: string;
}

function serializeAppsPeopleOzExternalMergedpeopleapiGender(data: any): AppsPeopleOzExternalMergedpeopleapiGender {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiGender(data: any): AppsPeopleOzExternalMergedpeopleapiGender {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

/**
 * Extension data for use in GPay Product Profile.
 * go/gpay-product-profile-1-pager Contact: profiles-eng-fe@google.com
 */
export interface AppsPeopleOzExternalMergedpeopleapiGPayExtendedData {
  /**
   * Failure type if there is an error when fetching product profile data.
   */
  failure?: AppsPeopleOzExternalMergedpeopleapiProductProfileFailure;
  /**
   * A number in international format including the country code that is made
   * user readable by including formatting such as spaces. Example: "+41 44 668
   * 1800" DEPRECATED: A user's phone number should be masked and not in an
   * international format
   */
  internationalNumber?: string;
  /**
   * The masked string of a user's phone number The number will be obfucsated
   * with * except the last 4 digits. Refer to:
   * //java/com/google/nbu/paisa/common/PhoneNumberMasker.java
   */
  maskedNumber?: string;
}

export interface AppsPeopleOzExternalMergedpeopleapiGplusExtendedData {
  contentRestriction?:  | "UNKNOWN" | "PUBLIC" | "DISCOVERY" | "WALLED_GARDEN";
  /**
   * Equivalent to having the DASHER_POLICY bit in the REGISTERED state.
   */
  isEnterpriseUser?: boolean;
}

/**
 * Extension data for use in Hangouts.
 */
export interface AppsPeopleOzExternalMergedpeopleapiHangoutsExtendedData {
  hadPastHangoutState?:  | "UNKNOWN_PAST_HANGOUT_STATE" | "HAD_PAST_HANGOUT" | "NO_PAST_HANGOUT";
  /**
   * Populated for all contacts. Only set if had_past_hangout_state ==
   * HAD_PAST_HANGOUT. INVITATION_NEEDED is not a valid value because there
   * already is a past hangout, which means either the invitation is still
   * pending or its been accepted.
   */
  invitationStatus?:  | "UNKNOWN_INVITATION_STATUS" | "PENDING_INVITATION" | "ACCEPTED_INVITATION" | "INVITATION_NEEDED";
  /**
   * True if this is a Hangouts bot.
   */
  isBot?: boolean;
  isDismissed?: boolean;
  isFavorite?: boolean;
  isPinned?: boolean;
  userType?:  | "UNKNOWN_USER_TYPE" | "INVALID" | "GAIA" | "OFF_NETWORK_PHONE" | "MALFORMED_PHONE_NUMBER" | "UNKNOWN_PHONE_NUMBER" | "ANONYMOUS_PHONE_NUMBER";
}

export interface AppsPeopleOzExternalMergedpeopleapiIdentityInfo {
  /**
   * Original lookup token from the request that resulted in this person or one
   * of its containers.
   */
  originalLookupToken?: string[];
  /**
   * Any former IDs this person may have had, in the case that their ID may
   * have changed. Populated only for sync requests. Examples of such changes
   * include adding an edge to a contact that links to a profile. The ID will
   * change from being contact-oriented to being profile-oriented. To be used to
   * clear out old versions of a person.
   */
  previousPersonId?: string[];
  /**
   * A list of sources contributing to the merged person, including profiles
   * (with gaia-id), contacts and synthetic-contacts.
   */
  sourceIds?: AppsPeopleOzExternalMergedpeopleapiSourceIdentity[];
}

function serializeAppsPeopleOzExternalMergedpeopleapiIdentityInfo(data: any): AppsPeopleOzExternalMergedpeopleapiIdentityInfo {
  return {
    ...data,
    sourceIds: data["sourceIds"] !== undefined ? data["sourceIds"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiSourceIdentity(item))) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiIdentityInfo(data: any): AppsPeopleOzExternalMergedpeopleapiIdentityInfo {
  return {
    ...data,
    sourceIds: data["sourceIds"] !== undefined ? data["sourceIds"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiSourceIdentity(item))) : undefined,
  };
}

export interface AppsPeopleOzExternalMergedpeopleapiIm {
  /**
   * The `protocol` translated and formatted in the request locale. See
   * go/people-api-howto/localization for details on how to usage.
   */
  formattedProtocol?: string;
  /**
   * The `type` translated and formatted in the request locale. See
   * go/people-api-howto/localization for details on how to usage.
   */
  formattedType?: string;
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
  /**
   * The protocol of the IM. The protocol can be free form or one of these
   * predefined values: * `aim` * `msn` * `yahoo` * `skype` * `qq` *
   * `googleTalk` * `icq` * `jabber` * `netMeeting`
   */
  protocol?: string;
  /**
   * The type of the IM. The type can be free form or one of these predefined
   * values: * `home` * `work` * `other`
   */
  type?: string;
  value?: string;
}

function serializeAppsPeopleOzExternalMergedpeopleapiIm(data: any): AppsPeopleOzExternalMergedpeopleapiIm {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiIm(data: any): AppsPeopleOzExternalMergedpeopleapiIm {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

/**
 * How and where to send notifications to this person in other apps, and why
 * the requester can do so. See go/reachability for more info. "How" and "where"
 * identify the recipient in a P2P Bridge (glossary/p2p bridge), and "why" may
 * be helpful in a UI to disambiguate which of several ways may be used to
 * contact the recipient. How: Via a Google profile or a reachable-only phone
 * number that the requester has access to. Specified in the target "type" and
 * "value". Where: Apps in which the profile/phone number owner may receive
 * notifications. Specified in the repeated "app". Why: Which fields in, e.g., a
 * contact associated with this person make the notification target info visible
 * to the requester. Specified in the repeated originating_field param. Example:
 * Alice has a contact Bob, with: Email 0 = bob@gmail.com Phone 0 = +12223334444
 * Phone 1 = +15556667777 Email 0 and Phone 0 let Alice see Bob's public profile
 * (obfuscated gaia ID = 123). Public profiles are visible by email by default,
 * and Bob has explicitly made it visible via Phone 0. Bob says people can send
 * notifications to his public profile in YouTube. Phone 2 is associated with
 * another Google profile that Bob owns, but he doesn't want others to see it.
 * He is okay with people sending notifications to him in Who's Down if they
 * have this phone number, however. There will be separate
 * InAppNotificationTargets: one for Bob's public Google profile, and one for
 * the second phone number, which is in his private profile. IANT #1 - targeting
 * Bob's public profile (visible via Email 0 and Phone 0): app = [YOUTUBE] type
 * = OBFUSCATED_GAIA_ID value = 123 originating_field: [ { field_type = EMAIL,
 * field_index = 0 } // For Email 0 { field_type = PHONE, field_index = 0 } //
 * For Phone 0 ] IANT #2 - targeting Bob's private profile phone number Phone 1:
 * app = [WHOS_DOWN] type = PHONE value = +15556667777 originating_field: [ {
 * field_type = PHONE, field_index = 1 } // For Phone 1 ]
 */
export interface AppsPeopleOzExternalMergedpeopleapiInAppNotificationTarget {
  app?:  | "UNKNOWN" | "BABEL" | "YOUTUBE" | "WHOS_DOWN" | "YOUTUBE_MANGO" | "PHOTOS" | "GOOGLE_ASSISTANT" | "KABOO" | "COMMERCE_PLATFORM" | "SPACES" | "MAPS" | "LOUPE_UNUSED" | "POMEROY" | "LOUPE" | "PEOPLE_PLAYGROUND" | "NEWS_360" | "DUO"[];
  clientData?: AppsPeopleOzExternalMergedpeopleapiInAppNotificationTargetClientData[];
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
  /**
   * There may be more than one field from which this IANT originates, as in
   * the case of Bob's public profile.
   */
  originatingField?: AppsPeopleOzExternalMergedpeopleapiInAppNotificationTargetOriginatingField[];
  type?:  | "UNKNOWN_KEY_TYPE" | "PHONE" | "OBFUSCATED_GAIA_ID" | "EMAIL";
  /**
   * The value of the target, used for delivery. E.g., the obfuscated gaia ID
   * for a visible profile.
   */
  value?: string;
}

function serializeAppsPeopleOzExternalMergedpeopleapiInAppNotificationTarget(data: any): AppsPeopleOzExternalMergedpeopleapiInAppNotificationTarget {
  return {
    ...data,
    clientData: data["clientData"] !== undefined ? data["clientData"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiInAppNotificationTargetClientData(item))) : undefined,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiInAppNotificationTarget(data: any): AppsPeopleOzExternalMergedpeopleapiInAppNotificationTarget {
  return {
    ...data,
    clientData: data["clientData"] !== undefined ? data["clientData"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiInAppNotificationTargetClientData(item))) : undefined,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

/**
 * Client-specific data pertaining to app reachability. No PII data or user
 * content should be stored in this blob.
 */
export interface AppsPeopleOzExternalMergedpeopleapiInAppNotificationTargetClientData {
  /**
   * The app to which this client data applies.
   */
  app?:  | "UNKNOWN" | "BABEL" | "YOUTUBE" | "WHOS_DOWN" | "YOUTUBE_MANGO" | "PHOTOS" | "GOOGLE_ASSISTANT" | "KABOO" | "COMMERCE_PLATFORM" | "SPACES" | "MAPS" | "LOUPE_UNUSED" | "POMEROY" | "LOUPE" | "PEOPLE_PLAYGROUND" | "NEWS_360" | "DUO";
  byteValue?: Uint8Array;
}

function serializeAppsPeopleOzExternalMergedpeopleapiInAppNotificationTargetClientData(data: any): AppsPeopleOzExternalMergedpeopleapiInAppNotificationTargetClientData {
  return {
    ...data,
    byteValue: data["byteValue"] !== undefined ? encodeBase64(data["byteValue"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiInAppNotificationTargetClientData(data: any): AppsPeopleOzExternalMergedpeopleapiInAppNotificationTargetClientData {
  return {
    ...data,
    byteValue: data["byteValue"] !== undefined ? decodeBase64(data["byteValue"] as string) : undefined,
  };
}

/**
 * Info for identifying the specific field in this person that lets the
 * requester send them notifications. These are typically fields added to a
 * contact (e.g., email). There will not always be in originating field,
 * typically in the case that whatever permits the requester to see this target
 * info is not something that can be used on its own for contacting this person.
 */
export interface AppsPeopleOzExternalMergedpeopleapiInAppNotificationTargetOriginatingField {
  /**
   * The index of the relevant field in the merged person
   */
  fieldIndex?: number;
  fieldType?:  | "UNKNOWN_FIELD_TYPE" | "PHONE" | "EMAIL";
  /**
   * The value of the origin field
   */
  value?: string;
}

/**
 * This is deprecated in PEOPLE_API/SHARPEN, and should only be used for
 * PROFILES. Which apps the person has indicated they are reachable at for the
 * requester. See go/d13y and com.google.focus.proto.InAppReachability.
 */
export interface AppsPeopleOzExternalMergedpeopleapiInAppReachability {
  appType?:  | "UNKNOWN" | "BABEL" | "YOUTUBE" | "WHOS_DOWN" | "YOUTUBE_MANGO" | "PHOTOS" | "KABOO" | "COMMERCE_PLATFORM" | "SPACES" | "GOOGLE_ASSISTANT" | "PEOPLE_PLAYGROUND" | "MAPS" | "LOUPE_UNUSED" | "POMEROY" | "LOUPE" | "NEWS_360" | "DUO";
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
  reachabilityKey?: AppsPeopleOzExternalMergedpeopleapiInAppReachabilityReachabilityKey;
  status?:  | "UNKNOWN_REACHABLE_STATUS" | "REACHABLE" | "NOT_REACHABLE";
}

function serializeAppsPeopleOzExternalMergedpeopleapiInAppReachability(data: any): AppsPeopleOzExternalMergedpeopleapiInAppReachability {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiInAppReachability(data: any): AppsPeopleOzExternalMergedpeopleapiInAppReachability {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

/**
 * Information pertaining to how this reachable state was established.
 */
export interface AppsPeopleOzExternalMergedpeopleapiInAppReachabilityReachabilityKey {
  keyType?:  | "UNKNOWN_KEY_TYPE" | "PHONE" | "OBFUSCATED_GAIA_ID";
  /**
   * The value of the key by which the user said they may be reachable. E.g.,
   * the phone number.
   */
  keyValue?: string;
}

/**
 * Defines interactions that are allowed or disallowed with this person.
 */
export interface AppsPeopleOzExternalMergedpeopleapiInteractionSettings {
  allowed?: boolean;
  interaction?:  | "UNKNOWN" | "INCOMING_CIRCLE_MEMBERSHIP" | "INCOMING_SOCIAL_EDGE" | "INVITE_TO_EMAIL";
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
}

function serializeAppsPeopleOzExternalMergedpeopleapiInteractionSettings(data: any): AppsPeopleOzExternalMergedpeopleapiInteractionSettings {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiInteractionSettings(data: any): AppsPeopleOzExternalMergedpeopleapiInteractionSettings {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

export interface AppsPeopleOzExternalMergedpeopleapiInterest {
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
  value?: string;
}

function serializeAppsPeopleOzExternalMergedpeopleapiInterest(data: any): AppsPeopleOzExternalMergedpeopleapiInterest {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiInterest(data: any): AppsPeopleOzExternalMergedpeopleapiInterest {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

/**
 * The value can either by a language code conforming to the IETF BCP 47
 * specification or a custom freeform value. By default the returned value is
 * proxied from FBS Profile.Language. If `include_account_locale` is set on the
 * `MergePersonSourceOptions` the language from go/uls is preferred and returned
 * as primary along with a secondary language from FBS.
 */
export interface AppsPeopleOzExternalMergedpeopleapiLanguage {
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
  value?: string;
}

function serializeAppsPeopleOzExternalMergedpeopleapiLanguage(data: any): AppsPeopleOzExternalMergedpeopleapiLanguage {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiLanguage(data: any): AppsPeopleOzExternalMergedpeopleapiLanguage {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

export interface AppsPeopleOzExternalMergedpeopleapiLatLng {
  lat?: number;
  lng?: number;
}

/**
 * Fields used in legacy applications. Useful for joining legacy and new data
 * streams. Most applications should not care about these fields.
 */
export interface AppsPeopleOzExternalMergedpeopleapiLegacyFields {
  /**
   * Mobile obfuscated gaia id. This is the same gaia id in metadata.owner_id,
   * but obfuscated with the legacy mobile obfuscator.
   */
  mobileOwnerId?: string;
}

export interface AppsPeopleOzExternalMergedpeopleapiLimitedProfileSettingsField {
  limitedProfileSettings?: SocialGraphApiProtoLimitedProfileSettings;
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
}

function serializeAppsPeopleOzExternalMergedpeopleapiLimitedProfileSettingsField(data: any): AppsPeopleOzExternalMergedpeopleapiLimitedProfileSettingsField {
  return {
    ...data,
    limitedProfileSettings: data["limitedProfileSettings"] !== undefined ? serializeSocialGraphApiProtoLimitedProfileSettings(data["limitedProfileSettings"]) : undefined,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiLimitedProfileSettingsField(data: any): AppsPeopleOzExternalMergedpeopleapiLimitedProfileSettingsField {
  return {
    ...data,
    limitedProfileSettings: data["limitedProfileSettings"] !== undefined ? deserializeSocialGraphApiProtoLimitedProfileSettings(data["limitedProfileSettings"]) : undefined,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

export interface AppsPeopleOzExternalMergedpeopleapiLocation {
  buildingId?: string;
  /**
   * The building_name field is only filled if the
   * DESK_LOCATION_ADDITIONAL_DATA extension is active.
   */
  buildingName?: string;
  current?: boolean;
  /**
   * Most specific textual description of individual desk location.
   */
  deskCode?: string;
  floorName?: string;
  floorSection?: string;
  /**
   * Indicates the time this location was added or last edited.
   */
  lastUpdateTime?: Date;
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
  /**
   * Value indicates the origin of this location information.
   */
  source?:  | "UNKNOWN" | "EXPLICIT" | "INFERRED";
  /**
   * Describes the type of location. For e.g. Grew_up, Desk. Corresponds to FBS
   * backend.proto Location.StandardTag
   */
  type?: string;
  value?: string;
}

function serializeAppsPeopleOzExternalMergedpeopleapiLocation(data: any): AppsPeopleOzExternalMergedpeopleapiLocation {
  return {
    ...data,
    lastUpdateTime: data["lastUpdateTime"] !== undefined ? data["lastUpdateTime"].toISOString() : undefined,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiLocation(data: any): AppsPeopleOzExternalMergedpeopleapiLocation {
  return {
    ...data,
    lastUpdateTime: data["lastUpdateTime"] !== undefined ? new Date(data["lastUpdateTime"]) : undefined,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

export interface AppsPeopleOzExternalMergedpeopleapiManagementUpchain {
  /**
   * List of managers in the chain. If user has manager email "abc@google.com"
   * and manager's manager has email "xyz@google.com" then the list will be:
   * [0]: { email: "abc@google.com" } [1]: { email: "xyz@google.com" }
   */
  indirectManager?: AppsPeopleOzExternalMergedpeopleapiManagementUpchainIndirectManager[];
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
  status?:  | "UNKNOWN" | "OK" | "PARTIAL" | "LOOP";
}

function serializeAppsPeopleOzExternalMergedpeopleapiManagementUpchain(data: any): AppsPeopleOzExternalMergedpeopleapiManagementUpchain {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiManagementUpchain(data: any): AppsPeopleOzExternalMergedpeopleapiManagementUpchain {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

export interface AppsPeopleOzExternalMergedpeopleapiManagementUpchainIndirectManager {
  email?: string;
  personId?: string;
}

/**
 * Extension data for use in Maps Product Profile.
 */
export interface AppsPeopleOzExternalMergedpeopleapiMapsExtendedData {
  /**
   * Failure type if there is an error when fetching product profile data.
   */
  failure?: AppsPeopleOzExternalMergedpeopleapiProductProfileFailure;
  /**
   * Number of people the user is following.
   */
  followeeCount?: bigint;
  /**
   * Number of people who are following the user.
   */
  followerCount?: number;
  /**
   * Sum of creators contributions i.e. reviews, rating, questions, etc.
   */
  numContributions?: bigint;
  /**
   * The user's profile photo that might have a badge rendered at the corner if
   * the user is eligible for a badge.
   */
  profilePhotoUrl?: string;
  /**
   * A user's bio, or tagline.
   */
  tagline?: string;
  /**
   * A topic that creator has expertise in. This will be in the format: emoji
   * associated with the topic, display name of the topic, topic score
   */
  topicExpertise?: string[];
  /**
   * A user's caption displayed under the user name on their profile page i.e.
   * 'Local Guide Level 8'
   */
  userCaption?: string;
}

function serializeAppsPeopleOzExternalMergedpeopleapiMapsExtendedData(data: any): AppsPeopleOzExternalMergedpeopleapiMapsExtendedData {
  return {
    ...data,
    followeeCount: data["followeeCount"] !== undefined ? String(data["followeeCount"]) : undefined,
    numContributions: data["numContributions"] !== undefined ? String(data["numContributions"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiMapsExtendedData(data: any): AppsPeopleOzExternalMergedpeopleapiMapsExtendedData {
  return {
    ...data,
    followeeCount: data["followeeCount"] !== undefined ? BigInt(data["followeeCount"]) : undefined,
    numContributions: data["numContributions"] !== undefined ? BigInt(data["numContributions"]) : undefined,
  };
}

/**
 * Maps Profile Data. See go/product-profiles-backend-api.
 */
export interface AppsPeopleOzExternalMergedpeopleapiMapsProfile {
  fieldRestriction?: AppsPeopleOzExternalMergedpeopleapiMapsProfileFieldRestriction[];
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
  tagline?: string;
  /**
   * A link to the profile owner's website to be displayed in profile.
   */
  websiteLink?: AppsPeopleOzExternalMergedpeopleapiMapsProfileUrlLink;
}

function serializeAppsPeopleOzExternalMergedpeopleapiMapsProfile(data: any): AppsPeopleOzExternalMergedpeopleapiMapsProfile {
  return {
    ...data,
    fieldRestriction: data["fieldRestriction"] !== undefined ? data["fieldRestriction"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiMapsProfileFieldRestriction(item))) : undefined,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiMapsProfile(data: any): AppsPeopleOzExternalMergedpeopleapiMapsProfile {
  return {
    ...data,
    fieldRestriction: data["fieldRestriction"] !== undefined ? data["fieldRestriction"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiMapsProfileFieldRestriction(item))) : undefined,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

export interface AppsPeopleOzExternalMergedpeopleapiMapsProfileFieldRestriction {
  /**
   * Opaque data associated with this restriction e.g. abuse status.
   */
  clientData?: Uint8Array;
  type?:  | "TYPE_UNSPECIFIED" | "HIDE_TAGLINE";
}

function serializeAppsPeopleOzExternalMergedpeopleapiMapsProfileFieldRestriction(data: any): AppsPeopleOzExternalMergedpeopleapiMapsProfileFieldRestriction {
  return {
    ...data,
    clientData: data["clientData"] !== undefined ? encodeBase64(data["clientData"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiMapsProfileFieldRestriction(data: any): AppsPeopleOzExternalMergedpeopleapiMapsProfileFieldRestriction {
  return {
    ...data,
    clientData: data["clientData"] !== undefined ? decodeBase64(data["clientData"] as string) : undefined,
  };
}

export interface AppsPeopleOzExternalMergedpeopleapiMapsProfileUrlLink {
  /**
   * Anchor text to be displayed as clickable link. If not present, the URL
   * should be displayed directly.
   */
  anchorText?: string;
  /**
   * The URL to be linked to.
   */
  url?: string;
}

/**
 * Represents the matching information for a field when there is a query.
 */
export interface AppsPeopleOzExternalMergedpeopleapiMatchInfo {
  /**
   * The list of matches ordered by most relevant matching for autocomplete
   * coming first.
   */
  match?: AppsPeopleOzExternalMergedpeopleapiMatchInfoLookupTokenMatch[];
  /**
   * The query token we are matching against.
   */
  query?: string;
}

/**
 * All the substring that were matched for the given query against the current
 * field. Represents a substring of another string.
 */
export interface AppsPeopleOzExternalMergedpeopleapiMatchInfoLookupTokenMatch {
  /**
   * Index right after the last character that matches the query. length =
   * end-start, we have substring = [start, end).
   */
  endIndex?: number;
  /**
   * Index of the first unicode character that matches the query.
   */
  startIndex?: number;
}

/**
 * A membership that the person has. The person can be a member of multiple
 * circles and multiple contact-groups. A circle membership is created by adding
 * a person to a circle by person-id or by email. A contact-group membership is
 * created by adding a contact to a contact-group.
 */
export interface AppsPeopleOzExternalMergedpeopleapiMembership {
  /**
   * A circle that the person belongs to.
   */
  circleId?: string;
  /**
   * A contact-group that the person belong to. The id can be either a
   * hex-formatted id or a camel-cased SystemContactGroup predefined group name.
   * The id will be predefined group name iff the system_contact_group_id has a
   * value.
   */
  contactGroupId?: string;
  /**
   * The metadata field can be used to determine which container generated the
   * membership. For example, when the membership has a contact_group_id, the
   * metadata.container will be CONTACT and the container_id will be the contact
   * Id.
   */
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
  /**
   * The membership has a contact_group_id, this field will be populated when
   * the membership is in a system-reserved contact-group.
   */
  systemContactGroupId?:  | "UNKNOWN" | "MY_CONTACTS" | "STARRED" | "FRIENDS" | "FAMILY" | "COWORKERS";
}

function serializeAppsPeopleOzExternalMergedpeopleapiMembership(data: any): AppsPeopleOzExternalMergedpeopleapiMembership {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiMembership(data: any): AppsPeopleOzExternalMergedpeopleapiMembership {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

export interface AppsPeopleOzExternalMergedpeopleapiMission {
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
  value?: string;
}

function serializeAppsPeopleOzExternalMergedpeopleapiMission(data: any): AppsPeopleOzExternalMergedpeopleapiMission {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiMission(data: any): AppsPeopleOzExternalMergedpeopleapiMission {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

/**
 * See go/people-api-howto:names for an overview of name usage in PeopleAPI.
 * The `unstructured_name` field contains a free form name value. The
 * `given_name`, `middle_name`, `family_name`, etc, fields contain the
 * structured name. For CONTACT mutates, (i.e. when Name.metadata.container is
 * CONTACT), it is recommended for clients to set either the `unstructured_name`
 * or the set of structured name fields, not both. * When only the
 * `unstructured_name` is set, it is parsed to produce a best-guess set of
 * structured name values for the `given_name`, `family_name`, etc. * When only
 * the structured name fields are set, the various values are combined to
 * produce an `unstructured_name`. * When both are set, the `unstructured_name`
 * is saved as-is and the structured name fields are saved as-is. This may be
 * confusing as they might not "match". For PROFILE mutates, (i.e. when
 * Name.metadata.container is PROFILE), it is _required_ for clients to use the
 * structured name fields as the unstructured field value is ignored on write.
 * The unstructured name fields are generated for convenience on read. For
 * DEVICE_CONTACTS, see b/156020778.
 */
export interface AppsPeopleOzExternalMergedpeopleapiName {
  /**
   * Read-only. A name synthesized based on `unstructured_name` and the
   * structured name fields. Example: "John Smith" If a language code is passed
   * in the side channel using
   * http://cs/symbol:framework.rpc.DeprecatedPropagatedLanguageCode.value or
   * http://cs/symbol:google.rpc.context.OriginContext.accept_language and the
   * name does not have `honorific_prefix`, `middle_name`, or `honorific_suffix`
   * set, the language code will be used to format `display_name`. If
   * `include_account_locale` is set on the `MergePersonSourceOptions` and a
   * language code is not passed in the side channel. The language code from
   * go/uls will be used as the language code for formatting `display_name`.
   */
  displayName?: string;
  /**
   * Read-only. A name synthesized based on `unstructured_name` and the
   * structured name fields with the last name first. Example: "Smith, John"
   */
  displayNameLastFirst?: string;
  /**
   * Read-only. The source of the display name.
   */
  displayNameSource?: SocialGraphApiProtoDisplayNameSource;
  familyName?: string;
  /**
   * DEPRECATED(b/70571931). Use `unstructured_name` instead.
   */
  formattedName?: string;
  givenName?: string;
  honorificPrefix?: string;
  honorificSuffix?: string;
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
  middleName?: string;
  /**
   * This field is stored in contact annotations and merged at read-time. It is
   * available with CONTACT_ANNOTATION container type at read time.
   */
  pronunciations?: SocialGraphApiProtoPronunciations;
  /**
   * Read-only. A possibly shorter version of the user's name. - The purpose of
   * this field is to address the needs of UIs where a full display name might
   * be too large to fit. Instead of relying on `first_name`, which might not be
   * present, `short_display_name` is preferred. - This is only available for
   * PROFILE and DOMAIN_PROFILE container types. - About the actual content in
   * this field: will be the first name when it's visible to the requester, or
   * the same as `display_name`, otherwise. A sample scenario where the first
   * name may not be visible is when the limited profile is returned. For more
   * info, see: http://shortn/_9iV7TJ33la
   */
  shortDisplayName?: string;
  /**
   * The free form name value. For contact mutates it is recommended for
   * clients to set either the `unstructured_name` or the set of structured name
   * fields, not both.
   */
  unstructuredName?: string;
  yomiFamilyName?: string;
  yomiFullName?: string;
  yomiGivenName?: string;
  yomiHonorificPrefix?: string;
  yomiHonorificSuffix?: string;
  yomiMiddleName?: string;
}

function serializeAppsPeopleOzExternalMergedpeopleapiName(data: any): AppsPeopleOzExternalMergedpeopleapiName {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiName(data: any): AppsPeopleOzExternalMergedpeopleapiName {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

/**
 * Pronunciation audio metadata info. See go/name-pronunciation-backend. The
 * metadata itself tracks the state of a user's name pronunciation audio.
 */
export interface AppsPeopleOzExternalMergedpeopleapiNamePronunciationAudioMetadataInfo {
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
  /**
   * Actual metadata proto, shared with FBS backends.
   */
  namePronunciationAudioMetadata?: SocialGraphApiProtoNamePronunciationAudioMetadata;
}

function serializeAppsPeopleOzExternalMergedpeopleapiNamePronunciationAudioMetadataInfo(data: any): AppsPeopleOzExternalMergedpeopleapiNamePronunciationAudioMetadataInfo {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiNamePronunciationAudioMetadataInfo(data: any): AppsPeopleOzExternalMergedpeopleapiNamePronunciationAudioMetadataInfo {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

export interface AppsPeopleOzExternalMergedpeopleapiNickname {
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
  type?:  | "NICKNAME_UNKNOWN" | "DEFAULT" | "OTHER_NAME" | "MAIDEN_NAME" | "SHORT_NAME" | "INITIALS" | "ALTERNATE_NAME";
  value?: string;
}

function serializeAppsPeopleOzExternalMergedpeopleapiNickname(data: any): AppsPeopleOzExternalMergedpeopleapiNickname {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiNickname(data: any): AppsPeopleOzExternalMergedpeopleapiNickname {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

export interface AppsPeopleOzExternalMergedpeopleapiOccupation {
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
  value?: string;
}

function serializeAppsPeopleOzExternalMergedpeopleapiOccupation(data: any): AppsPeopleOzExternalMergedpeopleapiOccupation {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiOccupation(data: any): AppsPeopleOzExternalMergedpeopleapiOccupation {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

/**
 * The periods that this place is open during the week. The periods are in
 * chronological order, starting with today in the place-local timezone. An
 * empty (but not absent) value indicates a place that is never open, e.g.
 * because it is closed temporarily for renovations.
 */
export interface AppsPeopleOzExternalMergedpeopleapiOpeningHours {
  /**
   * Is this place open right now? Always present unless we lack time-of-day or
   * timezone data for these opening hours.
   */
  openNow?: boolean;
  periods?: AppsPeopleOzExternalMergedpeopleapiOpeningHoursPeriod[];
  /**
   * Localized strings describing the opening hours of this place, one string
   * for each day of the week. Will be empty if the hours are unknown or could
   * not be converted to localized text. Example: "Sun: 18:00-06:00"
   */
  weekdayTexts?: string[];
}

export interface AppsPeopleOzExternalMergedpeopleapiOpeningHoursEndpoint {
  /**
   * A day of the week, as an integer in the range 0-6. 0 is Sunday, 1 is
   * Monday, etc.
   */
  day?: number;
  /**
   * A time in 24-hour "hhmm" format (i.e. range is 0000 to 2359).
   */
  time?: string;
}

export interface AppsPeopleOzExternalMergedpeopleapiOpeningHoursPeriod {
  close?: AppsPeopleOzExternalMergedpeopleapiOpeningHoursEndpoint;
  open?: AppsPeopleOzExternalMergedpeopleapiOpeningHoursEndpoint;
}

export interface AppsPeopleOzExternalMergedpeopleapiOrganization {
  assignment?: AppsPeopleOzExternalMergedpeopleapiOrganizationAssignment[];
  certification?: string;
  costCenter?: string;
  current?: boolean;
  department?: string;
  description?: string;
  domain?: string;
  /**
   * Start and End Dates are better represented as calendar entities. The
   * intention is to replace timestamps. Not set if no value exists. Clients can
   * choose whether to use has* semantics or default value semantics. For
   * writes, the default proto and an absent message are equivalent. Legacy
   * callers in the legacy_timestamp_event_write_behavior_enabled capability
   * allowlist should write to PeopleApi via end_ms and migrate to setting both
   * so they can be removed from the whitelist.
   */
  endCalendarDay?: GoogleTypeDate;
  /**
   * Clients are encouraged to read the end_calendar_day instead. PeopleApi
   * writes will still use end_ms for legacy callers that are in the
   * legacy_timestamp_event_write_behavior_enabled capability allowlist. New
   * writers must use the calendar_day fields.
   */
  endMs?: bigint;
  endMsAsNumber?: bigint;
  /**
   * The `string_type` translated and formatted in the request locale. See
   * go/people-api-howto/localization for details on how to usage.
   */
  formattedStringType?: string;
  fteMilliPercent?: number;
  importance?: number;
  location?: string;
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
  name?: string;
  project?: AppsPeopleOzExternalMergedpeopleapiOrganizationProject[];
  /**
   * Start and End Dates are better represented as calendar entities. The
   * intention is to replace timestamps. Not set if no value exists. Clients can
   * choose whether to use has* semantics or default value semantics. For
   * writes, the default proto and an absent message are equivalent. Legacy
   * callers in the legacy_timestamp_event_write_behavior_enabled capability
   * allowlist should write to PeopleApi via start_ms and migrate to setting
   * both so they can be removed from the allowlist.
   */
  startCalendarDay?: GoogleTypeDate;
  /**
   * Clients are encouraged to read the start_calendar_day instead. PeopleApi
   * writes will still use start_ms for legacy callers that are in the
   * legacy_timestamp_event_write_behavior_enabled capability allowlist. New
   * writers must use the calendar_day fields.
   */
  startMs?: bigint;
  startMsAsNumber?: bigint;
  /**
   * The type of the organization. The type can be free form or one of these
   * predefined values: * `work` * `school`
   */
  stringType?: string;
  symbol?: string;
  title?: string;
  type?:  | "UNKNOWN" | "WORK" | "SCHOOL" | "DOMAIN_ONLY";
  yomiName?: string;
}

function serializeAppsPeopleOzExternalMergedpeopleapiOrganization(data: any): AppsPeopleOzExternalMergedpeopleapiOrganization {
  return {
    ...data,
    endMs: data["endMs"] !== undefined ? String(data["endMs"]) : undefined,
    endMsAsNumber: data["endMsAsNumber"] !== undefined ? String(data["endMsAsNumber"]) : undefined,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
    startMs: data["startMs"] !== undefined ? String(data["startMs"]) : undefined,
    startMsAsNumber: data["startMsAsNumber"] !== undefined ? String(data["startMsAsNumber"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiOrganization(data: any): AppsPeopleOzExternalMergedpeopleapiOrganization {
  return {
    ...data,
    endMs: data["endMs"] !== undefined ? BigInt(data["endMs"]) : undefined,
    endMsAsNumber: data["endMsAsNumber"] !== undefined ? BigInt(data["endMsAsNumber"]) : undefined,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
    startMs: data["startMs"] !== undefined ? BigInt(data["startMs"]) : undefined,
    startMsAsNumber: data["startMsAsNumber"] !== undefined ? BigInt(data["startMsAsNumber"]) : undefined,
  };
}

export interface AppsPeopleOzExternalMergedpeopleapiOrganizationAssignment {
  name?: string;
  url?: string;
}

export interface AppsPeopleOzExternalMergedpeopleapiOrganizationProject {
  description?: string;
  name?: string;
  role?: string;
  /**
   * Mapped from StandardProjectTag / CustomProjectTag
   */
  type?: string;
  url?: string;
}

export interface AppsPeopleOzExternalMergedpeopleapiOtherKeyword {
  /**
   * The `type` translated and formatted in the request locale. See
   * go/people-api-howto/localization for details on how to usage.
   */
  formattedType?: string;
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
  source?:  | "SOURCE_UNKNOWN" | "OUTLOOK" | "CUSTOM";
  /**
   * The type of the event. The type depends on the `OtherKeyword.source`.
   * `OUTLOOK` source fields must be one of: * `billing_information` *
   * `directory_server` * `keyword` * `mileage` * `sensitivity` * `user` *
   * `subject` All other fields are treated as a `CUSTOM` source field. The
   * value can be free form or one of these predefined values: * `home` *
   * `other` * `work`
   */
  type?: string;
  value?: string;
}

function serializeAppsPeopleOzExternalMergedpeopleapiOtherKeyword(data: any): AppsPeopleOzExternalMergedpeopleapiOtherKeyword {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiOtherKeyword(data: any): AppsPeopleOzExternalMergedpeopleapiOtherKeyword {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

/**
 * Merged-person combines multiple sources of data like contacts and profiles.
 * See go/people-api and go/understanding-merged-person NOTE: Why are all the
 * fields repeated? See go/people-api-concepts#repeated
 */
export interface AppsPeopleOzExternalMergedpeopleapiPerson {
  about?: AppsPeopleOzExternalMergedpeopleapiAbout[];
  address?: AppsPeopleOzExternalMergedpeopleapiAddress[];
  /**
   * Deprecated. If age is needed use `person.age_range_repeated` instead.
   * Please see go/people-api-howto:age on how to correctly get age data.
   */
  ageRange?:  | "UNKNOWN" | "LESS_THAN_EIGHTEEN" | "TWENTY_ONE_OR_OLDER" | "EIGHTEEN_TO_TWENTY";
  /**
   * Data on the person's age range, adult status, and age of consent. NOTE:
   * Please read go/people-api-howto:age on how to correctly get age data.
   */
  ageRangeRepeated?: AppsPeopleOzExternalMergedpeopleapiAgeRangeType[];
  birthday?: AppsPeopleOzExternalMergedpeopleapiBirthday[];
  /**
   * Used only by contacts, no data will be returned for profiles.
   */
  braggingRights?: AppsPeopleOzExternalMergedpeopleapiBraggingRights[];
  /**
   * b/145671020: Deprecated for Profiles, but not for Contacts.
   */
  calendar?: AppsPeopleOzExternalMergedpeopleapiCalendar[];
  certifiedBornBefore?: AppsPeopleOzExternalMergedpeopleapiCertifiedBornBefore[];
  /**
   * Circles that this person is a member of.
   */
  circleMembership?: AppsPeopleOzExternalMergedpeopleapiCircleMembership[];
  clientData?: AppsPeopleOzExternalMergedpeopleapiClientData[];
  communicationEmail?: AppsPeopleOzExternalMergedpeopleapiCommunicationEmail[];
  /**
   * Reminder to connect with a Contact (part of go/people-prompts). Also
   * contains contact-level prompts settings. Each Contact can have a single
   * `connection_reminder` (but can have multiple Prompts inside of it). Field
   * is repeated per PeopleAPI data model go/people-api-concepts#repeated. Only
   * supported for CONTACT container.
   */
  connectionReminder?: AppsPeopleOzExternalMergedpeopleapiConnectionReminder[];
  contactCreateContextInfo?: AppsPeopleOzExternalMergedpeopleapiContactCreateContextInfo[];
  contactEditContextInfo?: AppsPeopleOzExternalMergedpeopleapiContactEditContextInfo[];
  /**
   * Contact groups that this person is a member of.
   */
  contactGroupMembership?: AppsPeopleOzExternalMergedpeopleapiContactGroupMembership[];
  /**
   * Contact state and related metadata. See go/fbs-contacts-trash. If this
   * field was requested but is not set on the Person then the contact is in the
   * DEFAULT contact state. This field is read-only, and should not be set on a
   * mutate (e.g. UpdatePerson) call. Clients must call the explicit APIs (e.g.
   * UntrashPerson) to change contact state.
   */
  contactStateInfo?: AppsPeopleOzExternalMergedpeopleapiContactStateInfo[];
  /**
   * DEPRECATED. Now always returns a default cover photo. See
   * go/sunset-cover-photo.
   */
  coverPhoto?: AppsPeopleOzExternalMergedpeopleapiCoverPhoto[];
  customSchemaField?: AppsPeopleOzExternalMergedpeopleapiCustomSchemaField[];
  email?: AppsPeopleOzExternalMergedpeopleapiEmail[];
  /**
   * Emergency information. See go/emergency-trusted-contacts-papi.
   */
  emergencyInfo?: AppsPeopleOzExternalMergedpeopleapiEmergencyInfo[];
  /**
   * Event is currently in use by contacts.
   */
  event?: AppsPeopleOzExternalMergedpeopleapiEvent[];
  /**
   * Data added by extensions that are not specific to a particular field.
   */
  extendedData?: AppsPeopleOzExternalMergedpeopleapiPersonExtendedData;
  externalId?: AppsPeopleOzExternalMergedpeopleapiExternalId[];
  fileAs?: AppsPeopleOzExternalMergedpeopleapiFileAs[];
  /**
   * A fingerprint that can be used to reliably determine if a resource has
   * changed. Externally it is used as part of the etag.
   */
  fingerprint?: string;
  gender?: AppsPeopleOzExternalMergedpeopleapiGender[];
  im?: AppsPeopleOzExternalMergedpeopleapiIm[];
  /**
   * Ways to send in-app notifications to this person. See go/reachability.
   * This field is read-only and ignored for mutates.
   */
  inAppNotificationTarget?: AppsPeopleOzExternalMergedpeopleapiInAppNotificationTarget[];
  /**
   * Used only by profile service, deprecated for PeopleAPI and Sharpen. If you
   * aren't sure, contact people-api-users@ and profile-service-eng@.
   */
  inAppReachability?: AppsPeopleOzExternalMergedpeopleapiInAppReachability[];
  /**
   * DEPRECATED. This field isn't populated in people.list.
   */
  interactionSettings?: AppsPeopleOzExternalMergedpeopleapiInteractionSettings[];
  interest?: AppsPeopleOzExternalMergedpeopleapiInterest[];
  language?: AppsPeopleOzExternalMergedpeopleapiLanguage[];
  /**
   * DEPRECATED. This field was only for backwards compatibility with legacy
   * GData callers, and should not be used by new clients. Legacy fields used
   * for mobile clients.
   */
  legacyFields?: AppsPeopleOzExternalMergedpeopleapiLegacyFields;
  /**
   * Settings for the limited profile. See go/limited-profiles-api.
   */
  limitedProfileSettings?: AppsPeopleOzExternalMergedpeopleapiLimitedProfileSettingsField[];
  /**
   * Other person resources linked indirectly by an edge. The full person or
   * just the IDs may be populated depending on request parameters. We consider
   * linked people distinct people, but they share information. Example: A
   * contact with two outgoing edges. The two edges are considered separate, but
   * linked people.
   */
  linkedPerson?: AppsPeopleOzExternalMergedpeopleapiPerson[];
  location?: AppsPeopleOzExternalMergedpeopleapiLocation[];
  managementUpchain?: AppsPeopleOzExternalMergedpeopleapiManagementUpchain[];
  /**
   * MapsProfile, see go/product-profiles-backend-api
   */
  mapsProfile?: AppsPeopleOzExternalMergedpeopleapiMapsProfile[];
  /**
   * DEPRECATED. Please use `circle_membership` or `contact_group_membership`
   * instead. Contact-groups and circles that this person is a member of.
   */
  membership?: AppsPeopleOzExternalMergedpeopleapiMembership[];
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonMetadata;
  mission?: AppsPeopleOzExternalMergedpeopleapiMission[];
  /**
   * See go/people-api-howto:names for details about names in PeopleAPI.
   */
  name?: AppsPeopleOzExternalMergedpeopleapiName[];
  /**
   * Metadata info for a user's name pronunciation audio. See
   * go/name-pronunication-backend.
   */
  namePronunciationAudioMetadataInfo?: AppsPeopleOzExternalMergedpeopleapiNamePronunciationAudioMetadataInfo[];
  nickname?: AppsPeopleOzExternalMergedpeopleapiNickname[];
  occupation?: AppsPeopleOzExternalMergedpeopleapiOccupation[];
  organization?: AppsPeopleOzExternalMergedpeopleapiOrganization[];
  /**
   * Legacy arbitrary key value fields
   */
  otherKeyword?: AppsPeopleOzExternalMergedpeopleapiOtherKeyword[];
  /**
   * DEPRECATED. This feature was stubbed, but never implemented. This field
   * will not be populated with any results.
   */
  peopleInCommon?: AppsPeopleOzExternalMergedpeopleapiPerson[];
  /**
   * In order to request this field, the client must set desired
   * PersonAttributeKey in the dedicated RequestMask field `person_attribute`.
   * Unlike other person fields, this field cannot be requested in the
   * `include_field` field mask.
   */
  personAttribute?: AppsPeopleOzExternalMergedpeopleapiPersonAttribute[];
  /**
   * The ID of the person. This is determined by the backend, is unstable, and
   * may not be the same as a user_id. Internally referred as 'personKey' to
   * distinguish from the common PersonId pojo. See
   * go/people-api-concepts#person-id
   */
  personId?: string;
  phone?: AppsPeopleOzExternalMergedpeopleapiPhone[];
  /**
   * See go/people-api-concepts/photos for usage details
   */
  photo?: AppsPeopleOzExternalMergedpeopleapiPhoto[];
  /**
   * Data specific to places. Data which also applies to contacts and profiles
   * such as name, phone, photo, etc. are returned in the corresponding Person
   * fields.
   */
  placeDetails?: AppsPeopleOzExternalMergedpeopleapiPlaceDetails[];
  /**
   * DEPRECATED. Info about plus pages in the person.
   */
  plusPageInfo?: AppsPeopleOzExternalMergedpeopleapiPlusPageInfo[];
  posixAccount?: AppsPeopleOzExternalMergedpeopleapiPosixAccount[];
  /**
   * DEPRECATED. (go/people-api-concepts#repeated): Use
   * person.profile_url_repeated instead. Access to this field is restricted to
   * a set of legacy clients. This is a Google+-only field. See
   * go/fbs-g+-deprecation. NOTE: `Person.profile_url` is only populated for
   * profile-centric person.
   */
  profileUrl?: string;
  /**
   * This is a Google+-only field. See go/fbs-g+-deprecation.
   */
  profileUrlRepeated?: AppsPeopleOzExternalMergedpeopleapiProfileUrl[];
  /**
   * Pronouns are not supported for consumer profiles. See
   * go/pronouns-in-people-system-prd for more details.
   */
  pronoun?: AppsPeopleOzExternalMergedpeopleapiPronoun[];
  /**
   * Information about the profiles that are a part of this Person. This is
   * only applicable to PROFILE and DOMAIN_PROFILE containers.
   */
  readOnlyProfileInfo?: AppsPeopleOzExternalMergedpeopleapiReadOnlyProfileInfo[];
  /**
   * See go/relation-vs-relationship for relation vs relationship explanation.
   */
  relation?: AppsPeopleOzExternalMergedpeopleapiRelation[];
  /**
   * DEPRECATED. No data is returned for this field anymore.
   */
  relationshipInterest?: AppsPeopleOzExternalMergedpeopleapiRelationshipInterest[];
  /**
   * DEPRECATED. No data is returned for this field anymore.
   */
  relationshipStatus?: AppsPeopleOzExternalMergedpeopleapiRelationshipStatus[];
  rightOfPublicityState?: AppsPeopleOzExternalMergedpeopleapiRightOfPublicityState[];
  /**
   * Data specific to rosters (such as Google Groups and Chat Rooms). Data
   * which also applies to contacts and profiles such as name, email, and photo,
   * etc are returned in the corresponding Person fields.
   */
  rosterDetails?: AppsPeopleOzExternalMergedpeopleapiRosterDetails[];
  /**
   * Profile for Janata and Search. go/janata-profile-in-sgbe
   */
  searchProfile?: AppsPeopleOzExternalMergedpeopleapiSearchProfile[];
  /**
   * SipAddress is currently in use by contacts.
   */
  sipAddress?: AppsPeopleOzExternalMergedpeopleapiSipAddress[];
  skills?: AppsPeopleOzExternalMergedpeopleapiSkills[];
  /**
   * NOTE: this is used by go/starlight, but not actually used or returned in
   * PeopleAPI. See b/27281119 for context. Please reach out to people-api-eng@
   * if you have questions.
   */
  socialConnection?: AppsPeopleOzExternalMergedpeopleapiSocialConnection[];
  sortKeys?: AppsPeopleOzExternalMergedpeopleapiSortKeys;
  sshPublicKey?: AppsPeopleOzExternalMergedpeopleapiSshPublicKey[];
  /**
   * Only supported for PLACE container results, no data will be returned for
   * profiles.
   */
  tagline?: AppsPeopleOzExternalMergedpeopleapiTagline[];
  /**
   * DEPRECATED. *UNSUPPORTED*. This field is never populated.
   */
  teamsExtendedData?: AppsPeopleOzExternalMergedpeopleapiTeamsExtendedData;
  /**
   * UserDefined is currently in use by contacts.
   */
  userDefined?: AppsPeopleOzExternalMergedpeopleapiUserDefined[];
  /**
   * Add annotation_id and metadata (product_source) for visible to guests
   * contacts go/visible-to-guests.
   */
  visibleToGuests?: AppsPeopleOzExternalMergedpeopleapiVisibleToGuests[];
  website?: AppsPeopleOzExternalMergedpeopleapiWebsite[];
}

function serializeAppsPeopleOzExternalMergedpeopleapiPerson(data: any): AppsPeopleOzExternalMergedpeopleapiPerson {
  return {
    ...data,
    about: data["about"] !== undefined ? data["about"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiAbout(item))) : undefined,
    address: data["address"] !== undefined ? data["address"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiAddress(item))) : undefined,
    ageRangeRepeated: data["ageRangeRepeated"] !== undefined ? data["ageRangeRepeated"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiAgeRangeType(item))) : undefined,
    birthday: data["birthday"] !== undefined ? data["birthday"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiBirthday(item))) : undefined,
    braggingRights: data["braggingRights"] !== undefined ? data["braggingRights"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiBraggingRights(item))) : undefined,
    calendar: data["calendar"] !== undefined ? data["calendar"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiCalendar(item))) : undefined,
    certifiedBornBefore: data["certifiedBornBefore"] !== undefined ? data["certifiedBornBefore"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiCertifiedBornBefore(item))) : undefined,
    circleMembership: data["circleMembership"] !== undefined ? data["circleMembership"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiCircleMembership(item))) : undefined,
    clientData: data["clientData"] !== undefined ? data["clientData"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiClientData(item))) : undefined,
    communicationEmail: data["communicationEmail"] !== undefined ? data["communicationEmail"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiCommunicationEmail(item))) : undefined,
    connectionReminder: data["connectionReminder"] !== undefined ? data["connectionReminder"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiConnectionReminder(item))) : undefined,
    contactCreateContextInfo: data["contactCreateContextInfo"] !== undefined ? data["contactCreateContextInfo"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiContactCreateContextInfo(item))) : undefined,
    contactEditContextInfo: data["contactEditContextInfo"] !== undefined ? data["contactEditContextInfo"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiContactEditContextInfo(item))) : undefined,
    contactGroupMembership: data["contactGroupMembership"] !== undefined ? data["contactGroupMembership"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiContactGroupMembership(item))) : undefined,
    contactStateInfo: data["contactStateInfo"] !== undefined ? data["contactStateInfo"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiContactStateInfo(item))) : undefined,
    coverPhoto: data["coverPhoto"] !== undefined ? data["coverPhoto"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiCoverPhoto(item))) : undefined,
    customSchemaField: data["customSchemaField"] !== undefined ? data["customSchemaField"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiCustomSchemaField(item))) : undefined,
    email: data["email"] !== undefined ? data["email"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiEmail(item))) : undefined,
    emergencyInfo: data["emergencyInfo"] !== undefined ? data["emergencyInfo"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiEmergencyInfo(item))) : undefined,
    event: data["event"] !== undefined ? data["event"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiEvent(item))) : undefined,
    extendedData: data["extendedData"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonExtendedData(data["extendedData"]) : undefined,
    externalId: data["externalId"] !== undefined ? data["externalId"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiExternalId(item))) : undefined,
    fileAs: data["fileAs"] !== undefined ? data["fileAs"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiFileAs(item))) : undefined,
    gender: data["gender"] !== undefined ? data["gender"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiGender(item))) : undefined,
    im: data["im"] !== undefined ? data["im"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiIm(item))) : undefined,
    inAppNotificationTarget: data["inAppNotificationTarget"] !== undefined ? data["inAppNotificationTarget"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiInAppNotificationTarget(item))) : undefined,
    inAppReachability: data["inAppReachability"] !== undefined ? data["inAppReachability"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiInAppReachability(item))) : undefined,
    interactionSettings: data["interactionSettings"] !== undefined ? data["interactionSettings"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiInteractionSettings(item))) : undefined,
    interest: data["interest"] !== undefined ? data["interest"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiInterest(item))) : undefined,
    language: data["language"] !== undefined ? data["language"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiLanguage(item))) : undefined,
    limitedProfileSettings: data["limitedProfileSettings"] !== undefined ? data["limitedProfileSettings"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiLimitedProfileSettingsField(item))) : undefined,
    linkedPerson: data["linkedPerson"] !== undefined ? data["linkedPerson"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiPerson(item))) : undefined,
    location: data["location"] !== undefined ? data["location"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiLocation(item))) : undefined,
    managementUpchain: data["managementUpchain"] !== undefined ? data["managementUpchain"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiManagementUpchain(item))) : undefined,
    mapsProfile: data["mapsProfile"] !== undefined ? data["mapsProfile"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiMapsProfile(item))) : undefined,
    membership: data["membership"] !== undefined ? data["membership"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiMembership(item))) : undefined,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonMetadata(data["metadata"]) : undefined,
    mission: data["mission"] !== undefined ? data["mission"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiMission(item))) : undefined,
    name: data["name"] !== undefined ? data["name"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiName(item))) : undefined,
    namePronunciationAudioMetadataInfo: data["namePronunciationAudioMetadataInfo"] !== undefined ? data["namePronunciationAudioMetadataInfo"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiNamePronunciationAudioMetadataInfo(item))) : undefined,
    nickname: data["nickname"] !== undefined ? data["nickname"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiNickname(item))) : undefined,
    occupation: data["occupation"] !== undefined ? data["occupation"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiOccupation(item))) : undefined,
    organization: data["organization"] !== undefined ? data["organization"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiOrganization(item))) : undefined,
    otherKeyword: data["otherKeyword"] !== undefined ? data["otherKeyword"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiOtherKeyword(item))) : undefined,
    peopleInCommon: data["peopleInCommon"] !== undefined ? data["peopleInCommon"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiPerson(item))) : undefined,
    personAttribute: data["personAttribute"] !== undefined ? data["personAttribute"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiPersonAttribute(item))) : undefined,
    phone: data["phone"] !== undefined ? data["phone"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiPhone(item))) : undefined,
    photo: data["photo"] !== undefined ? data["photo"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiPhoto(item))) : undefined,
    placeDetails: data["placeDetails"] !== undefined ? data["placeDetails"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiPlaceDetails(item))) : undefined,
    plusPageInfo: data["plusPageInfo"] !== undefined ? data["plusPageInfo"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiPlusPageInfo(item))) : undefined,
    posixAccount: data["posixAccount"] !== undefined ? data["posixAccount"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiPosixAccount(item))) : undefined,
    profileUrlRepeated: data["profileUrlRepeated"] !== undefined ? data["profileUrlRepeated"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiProfileUrl(item))) : undefined,
    pronoun: data["pronoun"] !== undefined ? data["pronoun"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiPronoun(item))) : undefined,
    readOnlyProfileInfo: data["readOnlyProfileInfo"] !== undefined ? data["readOnlyProfileInfo"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiReadOnlyProfileInfo(item))) : undefined,
    relation: data["relation"] !== undefined ? data["relation"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiRelation(item))) : undefined,
    relationshipInterest: data["relationshipInterest"] !== undefined ? data["relationshipInterest"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiRelationshipInterest(item))) : undefined,
    relationshipStatus: data["relationshipStatus"] !== undefined ? data["relationshipStatus"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiRelationshipStatus(item))) : undefined,
    rightOfPublicityState: data["rightOfPublicityState"] !== undefined ? data["rightOfPublicityState"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiRightOfPublicityState(item))) : undefined,
    rosterDetails: data["rosterDetails"] !== undefined ? data["rosterDetails"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiRosterDetails(item))) : undefined,
    searchProfile: data["searchProfile"] !== undefined ? data["searchProfile"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiSearchProfile(item))) : undefined,
    sipAddress: data["sipAddress"] !== undefined ? data["sipAddress"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiSipAddress(item))) : undefined,
    skills: data["skills"] !== undefined ? data["skills"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiSkills(item))) : undefined,
    socialConnection: data["socialConnection"] !== undefined ? data["socialConnection"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiSocialConnection(item))) : undefined,
    sshPublicKey: data["sshPublicKey"] !== undefined ? data["sshPublicKey"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiSshPublicKey(item))) : undefined,
    tagline: data["tagline"] !== undefined ? data["tagline"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiTagline(item))) : undefined,
    teamsExtendedData: data["teamsExtendedData"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiTeamsExtendedData(data["teamsExtendedData"]) : undefined,
    userDefined: data["userDefined"] !== undefined ? data["userDefined"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiUserDefined(item))) : undefined,
    visibleToGuests: data["visibleToGuests"] !== undefined ? data["visibleToGuests"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiVisibleToGuests(item))) : undefined,
    website: data["website"] !== undefined ? data["website"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiWebsite(item))) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiPerson(data: any): AppsPeopleOzExternalMergedpeopleapiPerson {
  return {
    ...data,
    about: data["about"] !== undefined ? data["about"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiAbout(item))) : undefined,
    address: data["address"] !== undefined ? data["address"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiAddress(item))) : undefined,
    ageRangeRepeated: data["ageRangeRepeated"] !== undefined ? data["ageRangeRepeated"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiAgeRangeType(item))) : undefined,
    birthday: data["birthday"] !== undefined ? data["birthday"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiBirthday(item))) : undefined,
    braggingRights: data["braggingRights"] !== undefined ? data["braggingRights"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiBraggingRights(item))) : undefined,
    calendar: data["calendar"] !== undefined ? data["calendar"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiCalendar(item))) : undefined,
    certifiedBornBefore: data["certifiedBornBefore"] !== undefined ? data["certifiedBornBefore"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiCertifiedBornBefore(item))) : undefined,
    circleMembership: data["circleMembership"] !== undefined ? data["circleMembership"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiCircleMembership(item))) : undefined,
    clientData: data["clientData"] !== undefined ? data["clientData"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiClientData(item))) : undefined,
    communicationEmail: data["communicationEmail"] !== undefined ? data["communicationEmail"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiCommunicationEmail(item))) : undefined,
    connectionReminder: data["connectionReminder"] !== undefined ? data["connectionReminder"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiConnectionReminder(item))) : undefined,
    contactCreateContextInfo: data["contactCreateContextInfo"] !== undefined ? data["contactCreateContextInfo"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiContactCreateContextInfo(item))) : undefined,
    contactEditContextInfo: data["contactEditContextInfo"] !== undefined ? data["contactEditContextInfo"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiContactEditContextInfo(item))) : undefined,
    contactGroupMembership: data["contactGroupMembership"] !== undefined ? data["contactGroupMembership"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiContactGroupMembership(item))) : undefined,
    contactStateInfo: data["contactStateInfo"] !== undefined ? data["contactStateInfo"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiContactStateInfo(item))) : undefined,
    coverPhoto: data["coverPhoto"] !== undefined ? data["coverPhoto"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiCoverPhoto(item))) : undefined,
    customSchemaField: data["customSchemaField"] !== undefined ? data["customSchemaField"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiCustomSchemaField(item))) : undefined,
    email: data["email"] !== undefined ? data["email"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiEmail(item))) : undefined,
    emergencyInfo: data["emergencyInfo"] !== undefined ? data["emergencyInfo"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiEmergencyInfo(item))) : undefined,
    event: data["event"] !== undefined ? data["event"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiEvent(item))) : undefined,
    extendedData: data["extendedData"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonExtendedData(data["extendedData"]) : undefined,
    externalId: data["externalId"] !== undefined ? data["externalId"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiExternalId(item))) : undefined,
    fileAs: data["fileAs"] !== undefined ? data["fileAs"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiFileAs(item))) : undefined,
    gender: data["gender"] !== undefined ? data["gender"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiGender(item))) : undefined,
    im: data["im"] !== undefined ? data["im"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiIm(item))) : undefined,
    inAppNotificationTarget: data["inAppNotificationTarget"] !== undefined ? data["inAppNotificationTarget"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiInAppNotificationTarget(item))) : undefined,
    inAppReachability: data["inAppReachability"] !== undefined ? data["inAppReachability"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiInAppReachability(item))) : undefined,
    interactionSettings: data["interactionSettings"] !== undefined ? data["interactionSettings"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiInteractionSettings(item))) : undefined,
    interest: data["interest"] !== undefined ? data["interest"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiInterest(item))) : undefined,
    language: data["language"] !== undefined ? data["language"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiLanguage(item))) : undefined,
    limitedProfileSettings: data["limitedProfileSettings"] !== undefined ? data["limitedProfileSettings"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiLimitedProfileSettingsField(item))) : undefined,
    linkedPerson: data["linkedPerson"] !== undefined ? data["linkedPerson"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiPerson(item))) : undefined,
    location: data["location"] !== undefined ? data["location"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiLocation(item))) : undefined,
    managementUpchain: data["managementUpchain"] !== undefined ? data["managementUpchain"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiManagementUpchain(item))) : undefined,
    mapsProfile: data["mapsProfile"] !== undefined ? data["mapsProfile"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiMapsProfile(item))) : undefined,
    membership: data["membership"] !== undefined ? data["membership"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiMembership(item))) : undefined,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonMetadata(data["metadata"]) : undefined,
    mission: data["mission"] !== undefined ? data["mission"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiMission(item))) : undefined,
    name: data["name"] !== undefined ? data["name"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiName(item))) : undefined,
    namePronunciationAudioMetadataInfo: data["namePronunciationAudioMetadataInfo"] !== undefined ? data["namePronunciationAudioMetadataInfo"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiNamePronunciationAudioMetadataInfo(item))) : undefined,
    nickname: data["nickname"] !== undefined ? data["nickname"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiNickname(item))) : undefined,
    occupation: data["occupation"] !== undefined ? data["occupation"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiOccupation(item))) : undefined,
    organization: data["organization"] !== undefined ? data["organization"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiOrganization(item))) : undefined,
    otherKeyword: data["otherKeyword"] !== undefined ? data["otherKeyword"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiOtherKeyword(item))) : undefined,
    peopleInCommon: data["peopleInCommon"] !== undefined ? data["peopleInCommon"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiPerson(item))) : undefined,
    personAttribute: data["personAttribute"] !== undefined ? data["personAttribute"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiPersonAttribute(item))) : undefined,
    phone: data["phone"] !== undefined ? data["phone"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiPhone(item))) : undefined,
    photo: data["photo"] !== undefined ? data["photo"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiPhoto(item))) : undefined,
    placeDetails: data["placeDetails"] !== undefined ? data["placeDetails"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiPlaceDetails(item))) : undefined,
    plusPageInfo: data["plusPageInfo"] !== undefined ? data["plusPageInfo"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiPlusPageInfo(item))) : undefined,
    posixAccount: data["posixAccount"] !== undefined ? data["posixAccount"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiPosixAccount(item))) : undefined,
    profileUrlRepeated: data["profileUrlRepeated"] !== undefined ? data["profileUrlRepeated"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiProfileUrl(item))) : undefined,
    pronoun: data["pronoun"] !== undefined ? data["pronoun"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiPronoun(item))) : undefined,
    readOnlyProfileInfo: data["readOnlyProfileInfo"] !== undefined ? data["readOnlyProfileInfo"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiReadOnlyProfileInfo(item))) : undefined,
    relation: data["relation"] !== undefined ? data["relation"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiRelation(item))) : undefined,
    relationshipInterest: data["relationshipInterest"] !== undefined ? data["relationshipInterest"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiRelationshipInterest(item))) : undefined,
    relationshipStatus: data["relationshipStatus"] !== undefined ? data["relationshipStatus"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiRelationshipStatus(item))) : undefined,
    rightOfPublicityState: data["rightOfPublicityState"] !== undefined ? data["rightOfPublicityState"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiRightOfPublicityState(item))) : undefined,
    rosterDetails: data["rosterDetails"] !== undefined ? data["rosterDetails"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiRosterDetails(item))) : undefined,
    searchProfile: data["searchProfile"] !== undefined ? data["searchProfile"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiSearchProfile(item))) : undefined,
    sipAddress: data["sipAddress"] !== undefined ? data["sipAddress"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiSipAddress(item))) : undefined,
    skills: data["skills"] !== undefined ? data["skills"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiSkills(item))) : undefined,
    socialConnection: data["socialConnection"] !== undefined ? data["socialConnection"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiSocialConnection(item))) : undefined,
    sshPublicKey: data["sshPublicKey"] !== undefined ? data["sshPublicKey"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiSshPublicKey(item))) : undefined,
    tagline: data["tagline"] !== undefined ? data["tagline"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiTagline(item))) : undefined,
    teamsExtendedData: data["teamsExtendedData"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiTeamsExtendedData(data["teamsExtendedData"]) : undefined,
    userDefined: data["userDefined"] !== undefined ? data["userDefined"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiUserDefined(item))) : undefined,
    visibleToGuests: data["visibleToGuests"] !== undefined ? data["visibleToGuests"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiVisibleToGuests(item))) : undefined,
    website: data["website"] !== undefined ? data["website"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiWebsite(item))) : undefined,
  };
}

/**
 * Client-specific binary blob stored with Person data. This differs from
 * ClientData, which stores structured, key-value pairs.
 */
export interface AppsPeopleOzExternalMergedpeopleapiPersonAttribute {
  attributeKey?:  | "PERSON_ATTRIBUTE_UNKNOWN" | "REJECTED_CLEANUP_CARD_SUGGESTIONS";
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
  value?: string;
}

function serializeAppsPeopleOzExternalMergedpeopleapiPersonAttribute(data: any): AppsPeopleOzExternalMergedpeopleapiPersonAttribute {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiPersonAttribute(data: any): AppsPeopleOzExternalMergedpeopleapiPersonAttribute {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

/**
 * Extension data for the whole person entity.
 */
export interface AppsPeopleOzExternalMergedpeopleapiPersonExtendedData {
  /**
   * For use by AboutMe and SmartProfile clients.
   */
  aboutMeExtendedData?: AppsPeopleOzExternalMergedpeopleapiAboutMeExtendedData;
  /**
   * For use with Apps Waldo Availability Data extension
   */
  appsWaldoExtendedData?: SocialGraphWireProtoPeopleapiExtensionAppsWaldoExtendedData;
  /**
   * For use with caller ID extension
   */
  callerIdExtendedData?: AppsPeopleOzExternalMergedpeopleapiCallerIdExtendedData;
  /**
   * For use with Contacts extension.
   */
  contactsExtendedData?: AppsPeopleOzExternalMergedpeopleapiWebContactsExtendedData;
  /**
   * Hosted domain this person is a member of. The domain_name is also returned
   * as part of the person's ReadOnlyProfileInfo, so requesting it via this
   * extension is no longer necessary.
   */
  domainName?: string[];
  /**
   * For use with Dynamite extension.
   */
  dynamiteExtendedData?: SocialGraphWireProtoPeopleapiExtensionDynamiteExtendedData;
  /**
   * For use with Google Pay extension.
   */
  gpayExtendedData?: AppsPeopleOzExternalMergedpeopleapiGPayExtendedData;
  /**
   * For use with Google+ extension.
   */
  gplusExtendedData?: AppsPeopleOzExternalMergedpeopleapiGplusExtendedData;
  /**
   * For use with Hangouts extension.
   */
  hangoutsExtendedData?: AppsPeopleOzExternalMergedpeopleapiHangoutsExtendedData;
  /**
   * For use with gmail extensions and lookup by email. If true, no person was
   * actually found using the specified email address, but we want to return TLS
   * info about the email address regardless.
   */
  isPlaceholder?: boolean;
  /**
   * For use with Maps extension.
   */
  mapsExtendedData?: AppsPeopleOzExternalMergedpeopleapiMapsExtendedData;
  /**
   * For use with Paisa extension
   */
  paisaExtendedData?: SocialGraphWireProtoPeopleapiExtensionPaisaExtendedData;
  /**
   * DEPRECATED: Use people_stack_person_extended_data instead. For use with
   * PeopleStack extension.
   */
  peopleStackExtendedData?: SocialGraphWireProtoPeopleapiExtensionPeopleStackExtendedData;
  /**
   * For use with PeopleStack extension.
   */
  peopleStackPersonExtendedData?: SocialGraphWireProtoPeopleapiExtensionPeopleStackPersonExtendedData;
  /**
   * For use with Play Games Product Profile extension. See
   * go/jam-games-profile. The play games profile will be returned only for
   * profile-centric requests.
   */
  playGamesExtendedData?: AppsPeopleOzExternalMergedpeopleapiPlayGamesExtendedData;
  /**
   * For use with the TLS extension and lookup by email. If true, no person was
   * actually found using the specified email address, but we want to return TLS
   * info about the email address regardless. DEPRECATED: Use is_placeholder
   * instead.
   */
  tlsIsPlaceholder?: boolean;
  /**
   * For use with Youtube extension.
   */
  youtubeExtendedData?: AppsPeopleOzExternalMergedpeopleapiYoutubeExtendedData;
}

function serializeAppsPeopleOzExternalMergedpeopleapiPersonExtendedData(data: any): AppsPeopleOzExternalMergedpeopleapiPersonExtendedData {
  return {
    ...data,
    aboutMeExtendedData: data["aboutMeExtendedData"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiAboutMeExtendedData(data["aboutMeExtendedData"]) : undefined,
    appsWaldoExtendedData: data["appsWaldoExtendedData"] !== undefined ? serializeSocialGraphWireProtoPeopleapiExtensionAppsWaldoExtendedData(data["appsWaldoExtendedData"]) : undefined,
    dynamiteExtendedData: data["dynamiteExtendedData"] !== undefined ? serializeSocialGraphWireProtoPeopleapiExtensionDynamiteExtendedData(data["dynamiteExtendedData"]) : undefined,
    mapsExtendedData: data["mapsExtendedData"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiMapsExtendedData(data["mapsExtendedData"]) : undefined,
    playGamesExtendedData: data["playGamesExtendedData"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPlayGamesExtendedData(data["playGamesExtendedData"]) : undefined,
    youtubeExtendedData: data["youtubeExtendedData"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiYoutubeExtendedData(data["youtubeExtendedData"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiPersonExtendedData(data: any): AppsPeopleOzExternalMergedpeopleapiPersonExtendedData {
  return {
    ...data,
    aboutMeExtendedData: data["aboutMeExtendedData"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiAboutMeExtendedData(data["aboutMeExtendedData"]) : undefined,
    appsWaldoExtendedData: data["appsWaldoExtendedData"] !== undefined ? deserializeSocialGraphWireProtoPeopleapiExtensionAppsWaldoExtendedData(data["appsWaldoExtendedData"]) : undefined,
    dynamiteExtendedData: data["dynamiteExtendedData"] !== undefined ? deserializeSocialGraphWireProtoPeopleapiExtensionDynamiteExtendedData(data["dynamiteExtendedData"]) : undefined,
    mapsExtendedData: data["mapsExtendedData"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiMapsExtendedData(data["mapsExtendedData"]) : undefined,
    playGamesExtendedData: data["playGamesExtendedData"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPlayGamesExtendedData(data["playGamesExtendedData"]) : undefined,
    youtubeExtendedData: data["youtubeExtendedData"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiYoutubeExtendedData(data["youtubeExtendedData"]) : undefined,
  };
}

/**
 * Metadata for a single Person field. See go/understanding-merged-person
 */
export interface AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata {
  /**
   * When the container is PROFILE/DOMAIN_PROFILE and the profile owner is the
   * requester, this read-only, synthesized field indicates which ACLs the user
   * is allowed to set on the profile field. This is distinct from field_acl,
   * which is the field's currently set ACL. field_acl will always be a valid
   * ACL choice, except for the case of default synthesized profile fields like
   * monogram profile photos. For those, field_acl does not represent a user-set
   * field ACL, so it may or may not be a valid choice. In all cases,
   * default_acl_choice will always be a valid choice. This is currently only
   * populated on the photo field when the "person.photo.metadata.acl_choices"
   * mask is set.
   */
  aclChoices?: AppsPeopleOzExternalMergedpeopleapiFieldAcl[];
  /**
   * Additional information about the container of this field.
   */
  additionalContainerInfo?: AppsPeopleOzExternalMergedpeopleapiAdditionalContainerInfo;
  /**
   * For field-level affinity scores. The affinity between the requester and
   * this particular field in the Person (e.g., frequency of calling a
   * particular phone number).
   */
  affinity?: AppsPeopleOzExternalMergedpeopleapiAffinity[];
  /**
   * Each field can have different visibility settings Only returned when
   * explicitly requested.
   */
  contactVisibility?:  | "CONTACT_VISIBILITY_UNSPECIFIED" | "VISIBLE_TO_GUEST"[];
  /**
   * DEPRECATED. Use container_type instead. Having the Container be an enum at
   * the PFM message level causes circular dependency when other types try to
   * refer to it. It breaks javascript build targets.
   */
  container?:  | "UNKNOWN" | "PROFILE" | "CONTACT" | "CIRCLE" | "PLACE" | "ACCOUNT" | "EXTERNAL_ACCOUNT" | "DOMAIN_PROFILE" | "DOMAIN_CONTACT" | "DEVICE_CONTACT" | "GOOGLE_GROUP" | "AFFINITY" | "RAW_DEVICE_CONTACT" | "CONTACT_ANNOTATION" | "DELEGATED_CONTACT";
  /**
   * DEPRECATED. Use encoded_container_id instead. The numeric id of the data
   * source. The id is only unique within a single container type. This is only
   * set when the id of the container is numeric, e.g. contact id.
   */
  containerId?: bigint;
  /**
   * Indicates if this field is the primary field for the container and
   * container_id.
   */
  containerPrimary?: boolean;
  /**
   * The source for the data in the field.
   */
  containerType?:  | "UNKNOWN_CONTAINER" | "PROFILE" | "CONTACT" | "CIRCLE" | "PLACE" | "ACCOUNT" | "EXTERNAL_ACCOUNT" | "DOMAIN_PROFILE" | "DOMAIN_CONTACT" | "DEVICE_CONTACT" | "GOOGLE_GROUP" | "NAMED_CHAT_ROOM" | "UNNAMED_CHAT_ROOM" | "AFFINITY" | "RAW_DEVICE_CONTACT" | "CONTACT_ANNOTATION" | "DELEGATED_CONTACT";
  /**
   * True if this field can be used on other devices than the one it originated
   * from. Assigned by the server. Currently only used for device contacts.
   */
  crossDeviceAllowed?: boolean;
  /**
   * When the container is PROFILE/DOMAIN_PROFILE and the profile owner is the
   * requester, this read-only, synthesized field contains the default ACL
   * choice. This can be used to select a preferred choice from acl_choices.
   * Generally, default_acl_choice should only be preferred for default
   * synthesized profile fields like monogram profile photos. Otherwise, the
   * existing field_acl should be preferred. This is currently only populated on
   * the photo field when the "person.photo.metadata.acl_choices" mask is set.
   */
  defaultAclChoice?: AppsPeopleOzExternalMergedpeopleapiFieldAcl;
  /**
   * DEPRECATED. Use container_id. Not populated or used at all.
   */
  deprecatedContactContainerId?: bigint;
  /**
   * Field is an edge key for this person. Modifying it breaks the link between
   * data sources. This is equivalent to edge_key_info having at least one entry
   * with materialized = true.
   */
  edgeKey?: boolean;
  /**
   * Edges that this field creates. This includes all edges and not necessarily
   * just the edge relevant to the joined entities.
   */
  edgeKeyInfo?: AppsPeopleOzExternalMergedpeopleapiEdgeKeyInfo[];
  /**
   * The encoded id of the data source. The id is only unique within a single
   * container type. This field correlates to
   * person.metadata.identity_info.source_id.id. This field may not be populated
   * in some special cases, where the id is not visible to the querying user.
   * e.g. ListAutocompletions with full phone number query.
   */
  encodedContainerId?: string;
  /**
   * When the container is PROFILE and the profile owner is the requester, this
   * field indicates how the profile field is accessible.
   */
  fieldAcl?: AppsPeopleOzExternalMergedpeopleapiFieldAcl;
  /**
   * Indicates the time that the field was added or last edited. Currently this
   * is populated for: (1) person.birthday with ContainerType PROFILE,
   * DOMAIN_PROFILE or ACCOUNT. (2) person.name, person.address,
   * person.relation, person.email and person.phone with ContainerType
   * CONTACT_ANNOTATION;
   */
  lastUpdateTime?: Date;
  /**
   * The matching informations if there was a query against this field.
   */
  matchingInfo?: AppsPeopleOzExternalMergedpeopleapiMatchInfo[];
  /**
   * When deduping fields by value, list of containers of the fields that where
   * deduped.
   */
  otherDedupedContainers?: AppsPeopleOzExternalMergedpeopleapiDedupedContainerInfo[];
  /**
   * If true, indicates this field is the Person's primary field eg. Contact,
   * and (Profile) Person could have different Name fields, and the Name
   * represented by the Person is primary. For selecting a primary field from
   * RepeatedFields within a Person, use container_primary.
   */
  primary?: boolean;
  /**
   * The product(s) that generated the data in this field. Empty is equivalent
   * to DEFAULT. ST_USER_METADATA
   */
  productMetadata?: AppsPeopleOzExternalMergedpeopleapiProductMetadata[];
  /**
   * Indicates whether this is a verified field. It is synthesized from
   * verification and is read-only. If there is at least one verification with
   * status PASSED, the field is considered verified. Currently this is
   * applicable to address, email, name, and phone for PROFILE and
   * DOMAIN_PROFILE. Use .metadata.verified in the request mask.
   */
  verified?: boolean;
  /**
   * Currently, only people.get may set this value
   */
  visibility?:  | "VISIBILITY_UNKNOWN" | "PUBLIC" | "USER";
  /**
   * Whether the field is writeable to the requester.
   */
  writeable?: boolean;
}

function serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data: any): AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata {
  return {
    ...data,
    additionalContainerInfo: data["additionalContainerInfo"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiAdditionalContainerInfo(data["additionalContainerInfo"]) : undefined,
    containerId: data["containerId"] !== undefined ? String(data["containerId"]) : undefined,
    deprecatedContactContainerId: data["deprecatedContactContainerId"] !== undefined ? String(data["deprecatedContactContainerId"]) : undefined,
    lastUpdateTime: data["lastUpdateTime"] !== undefined ? data["lastUpdateTime"].toISOString() : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data: any): AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata {
  return {
    ...data,
    additionalContainerInfo: data["additionalContainerInfo"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiAdditionalContainerInfo(data["additionalContainerInfo"]) : undefined,
    containerId: data["containerId"] !== undefined ? BigInt(data["containerId"]) : undefined,
    deprecatedContactContainerId: data["deprecatedContactContainerId"] !== undefined ? BigInt(data["deprecatedContactContainerId"]) : undefined,
    lastUpdateTime: data["lastUpdateTime"] !== undefined ? new Date(data["lastUpdateTime"]) : undefined,
  };
}

/**
 * A person list with total number specified.
 */
export interface AppsPeopleOzExternalMergedpeopleapiPersonListWithTotalNumber {
  people?: AppsPeopleOzExternalMergedpeopleapiPerson[];
  /**
   * The total number of people, which is aways no less than the size of the
   * above list.
   */
  totalNumber?: number;
}

function serializeAppsPeopleOzExternalMergedpeopleapiPersonListWithTotalNumber(data: any): AppsPeopleOzExternalMergedpeopleapiPersonListWithTotalNumber {
  return {
    ...data,
    people: data["people"] !== undefined ? data["people"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiPerson(item))) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiPersonListWithTotalNumber(data: any): AppsPeopleOzExternalMergedpeopleapiPersonListWithTotalNumber {
  return {
    ...data,
    people: data["people"] !== undefined ? data["people"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiPerson(item))) : undefined,
  };
}

/**
 * Metadata for the entire Person resource.
 */
export interface AppsPeopleOzExternalMergedpeopleapiPersonMetadata {
  /**
   * Affinities associated with the person, with respect to the requester.
   */
  affinity?: AppsPeopleOzExternalMergedpeopleapiAffinity[];
  /**
   * Populated when the data for the MergedPerson comes from a 3rd party
   * provider or data source. Clients must display these attributions to the
   * user if they are present. NOTE: This field is only relevant when requesting
   * the following containers: - PLACE (data read from Maps)
   */
  attribution?: string[];
  /**
   * The best name to use for this person for user-facing display. See
   * go/people-api-howto:names for details about how this field is computed. In
   * many cases this will simply be Person.name[0]. However, Person.name returns
   * only explicit Name fields, but other fields maybe usable as a name (for
   * example: nicknames, file_as, ...). `best_display_name` will be calculated
   * from all fields in storage which are usable as a name, even fields which
   * are not explicitly requested in the MergedPerson result. See
   * go/javagoog/apps/tacotown/socialgraph/entity/PersonNameFormatter.java
   */
  bestDisplayName?: AppsPeopleOzExternalMergedpeopleapiBestDisplayName;
  /**
   * DEPRECATED. Indicates whether the profile owner has blocked this person.
   * Please use `person.read_only_profile_info.block_type` instead.
   */
  blockType?:  | "BLOCK_TYPE_UNKNOWN" | "CIRCLE" | "LEGACY"[];
  /**
   * DEPRECATED. The circles the person belongs to.
   */
  circleId?: string[];
  /**
   * DEPRECATED. Please use `person.contact_group_memberships` instead. The
   * contact groups the person belongs to.
   */
  contactGroupId?: string[];
  /**
   * The IDs of all contacts contributing to this person.
   */
  contactId?: bigint[];
  /**
   * DEPRECATED. Customized masking of the response similar to the legacy
   * People2RequestMask People2Params request message. NOTE: This param is
   * inherently client-specific, limited to specific legacy clients, and not
   * open to new usage. NOTE: Effects may be applied to a subset of people in
   * the response.
   */
  customResponseMaskingType?:  | "UNKNOWN" | "NONE" | "MENAGERIE";
  /**
   * For sync requests (i.e., changed since the provided sync_token), indicates
   * the resource is a tombstone for a Person resource that has been entirely
   * deleted.
   */
  deleted?: boolean;
  /**
   * DEPRECATED. Please use `person.read_only_profile_info.block_type` instead.
   */
  deprecatedBlocked?: boolean;
  /**
   * DEPRECATED. This field is no longer populated or read.
   */
  deprecatedMembershipCircleId?: bigint[];
  /**
   * DEPRECATED. This field is no longer populated or read.
   */
  deprecatedMembershipContactGroupId?: bigint[];
  /**
   * Info about the aggregated device contacts. When the person contains
   * RAW_DEVICE_CONTACT containers, each DeviceContactInfo represents a single
   * aggregate device contact made up of one or more raw device contacts.
   */
  deviceContactInfo?: AppsPeopleOzExternalMergedpeopleapiDeviceContactInfo[];
  /**
   * Detailed metadata about the lookup IDs and data sources included in a
   * MergedPerson result.
   */
  identityInfo?: AppsPeopleOzExternalMergedpeopleapiIdentityInfo;
  /**
   * DEPRECATED. Indicates whether this person is blocking the profile owner.
   * Please use `person.read_only_profile_info.incoming_block_type` instead.
   */
  incomingBlockType?:  | "BLOCK_TYPE_UNKNOWN" | "CIRCLE" | "LEGACY"[];
  /**
   * DEPRECATED. Indicates whether this person is in the same domain as the
   * viewer. For proxying trust between two users based on organization
   * membership, see: - go/flex-orgs-platform - go/flex-orgs-compliance-handbook
   * (especially http://shortn/_ChwfAY36Ys)
   */
  inViewerDomain?: boolean;
  /**
   * DEPRECATED. The last update timestamps for the constituent components of
   * this person are available in `identity_info.source_ids`. The time of the
   * most recent change to this person, in !!!NANOS!!! (due to a bug). May be a
   * change to any of the underlying parts of the person (profile, contact,
   * etc.). Not guaranteed to be the timestamp of the most recent change, due to
   * limitations in the backend. This field is not fully deprecated for backend
   * container-specific storage services like ProfileService which lack
   * identity_info. The use is still discouraged in such systems and they should
   * prefer to use the `last_update_time` field of this message instead.
   */
  lastUpdateTimeMicros?: bigint;
  /**
   * The person model that is used to construct this person.
   */
  model?:  | "PERSON_MODEL_UNKNOWN" | "PROFILE_CENTRIC" | "CONTACT_CENTRIC";
  /**
   * DEPRECATED.
   */
  objectType?:  | "OBJECT_TYPE_UNKNOWN" | "PERSON" | "PAGE";
  /**
   * DEPRECATED. Please use `person.read_only_profile_info.owner_id` instead.
   */
  ownerId?: string;
  /**
   * DEPRECATED. See `person.read_only_profile_info.owner_user_type` instead.
   */
  ownerUserType?:  | "OWNER_USER_TYPE_UNKNOWN" | "GOOGLE_USER" | "GPLUS_USER" | "GPLUS_DISABLED_BY_ADMIN" | "GOOGLE_APPS_USER" | "GOOGLE_APPS_SELF_MANAGED_USER" | "GOOGLE_FAMILY_USER" | "GOOGLE_FAMILY_CHILD_USER" | "GOOGLE_APPS_ADMIN_DISABLED" | "GOOGLE_ONE_USER" | "GOOGLE_FAMILY_CONVERTED_CHILD_USER"[];
  /**
   * DEPRECATED. Please use `Person.plus_page_info` instead.
   */
  plusPageType?:  | "PLUS_PAGE_TYPE_UNKNOWN" | "LOCAL" | "COMPANY" | "BRAND" | "CELEBRITY" | "CAUSE" | "ENTERTAINMENT" | "OTHER" | "OBSOLETE_PRIVATE";
  /**
   * DEPRECATED. This field is no longer populated or read.
   */
  previousPersonId?: string[];
  /**
   * DEPRECATED. Stats/counters pertaining to followers and incoming edges.
   * Please use `person.read_only_profile_info.profile_owner_stats` instead.
   */
  profileOwnerStats?: AppsPeopleOzExternalMergedpeopleapiProfileOwnerStats;
  /**
   * Contact people-directory-dev-team@ if you want to use this field.
   */
  scoringInfo?: AppsPeopleOzExternalMergedpeopleapiPersonMetadataScoringInfo;
  /**
   * DEPRECATED. This field is no longer populated or read.
   */
  userVisibleStats?: AppsPeopleOzExternalMergedpeopleapiUserVisibleStats;
}

function serializeAppsPeopleOzExternalMergedpeopleapiPersonMetadata(data: any): AppsPeopleOzExternalMergedpeopleapiPersonMetadata {
  return {
    ...data,
    contactId: data["contactId"] !== undefined ? data["contactId"].map((item: any) => (String(item))) : undefined,
    deprecatedMembershipCircleId: data["deprecatedMembershipCircleId"] !== undefined ? data["deprecatedMembershipCircleId"].map((item: any) => (String(item))) : undefined,
    deprecatedMembershipContactGroupId: data["deprecatedMembershipContactGroupId"] !== undefined ? data["deprecatedMembershipContactGroupId"].map((item: any) => (String(item))) : undefined,
    deviceContactInfo: data["deviceContactInfo"] !== undefined ? data["deviceContactInfo"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiDeviceContactInfo(item))) : undefined,
    identityInfo: data["identityInfo"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiIdentityInfo(data["identityInfo"]) : undefined,
    lastUpdateTimeMicros: data["lastUpdateTimeMicros"] !== undefined ? String(data["lastUpdateTimeMicros"]) : undefined,
    profileOwnerStats: data["profileOwnerStats"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiProfileOwnerStats(data["profileOwnerStats"]) : undefined,
    userVisibleStats: data["userVisibleStats"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiUserVisibleStats(data["userVisibleStats"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiPersonMetadata(data: any): AppsPeopleOzExternalMergedpeopleapiPersonMetadata {
  return {
    ...data,
    contactId: data["contactId"] !== undefined ? data["contactId"].map((item: any) => (BigInt(item))) : undefined,
    deprecatedMembershipCircleId: data["deprecatedMembershipCircleId"] !== undefined ? data["deprecatedMembershipCircleId"].map((item: any) => (BigInt(item))) : undefined,
    deprecatedMembershipContactGroupId: data["deprecatedMembershipContactGroupId"] !== undefined ? data["deprecatedMembershipContactGroupId"].map((item: any) => (BigInt(item))) : undefined,
    deviceContactInfo: data["deviceContactInfo"] !== undefined ? data["deviceContactInfo"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiDeviceContactInfo(item))) : undefined,
    identityInfo: data["identityInfo"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiIdentityInfo(data["identityInfo"]) : undefined,
    lastUpdateTimeMicros: data["lastUpdateTimeMicros"] !== undefined ? BigInt(data["lastUpdateTimeMicros"]) : undefined,
    profileOwnerStats: data["profileOwnerStats"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiProfileOwnerStats(data["profileOwnerStats"]) : undefined,
    userVisibleStats: data["userVisibleStats"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiUserVisibleStats(data["userVisibleStats"]) : undefined,
  };
}

export interface AppsPeopleOzExternalMergedpeopleapiPersonMetadataScoringInfo {
  /**
   * Only populated on a SearchDirectoryPeople call, when results are scored.
   * Contact people-directory-dev-team@ if you want to use this field.
   */
  rawMatchQualityScore?: number;
  /**
   * Only populated on a SearchDirectoryPeople call that sends a request with
   * StFieldSpecExpressions. - Used for linking indexed terms with query terms
   * for go/better-name-matching - Name should be alphanumeric or underscores -
   * Value should be an st expression following the syntax at go/stsyntax
   * Contact people-directory-dev-team@ if you want to use this field.
   */
  stExpressionResults?: AppsPeopleOzExternalMergedpeopleapiPersonMetadataScoringInfoStExpressionResult[];
}

export interface AppsPeopleOzExternalMergedpeopleapiPersonMetadataScoringInfoStExpressionResult {
  name?: string;
  value?: string;
}

export interface AppsPeopleOzExternalMergedpeopleapiPhone {
  /**
   * Canonicalized form that follows ITU-T E.164 international public
   * telecommunication numbering plan.
   */
  canonicalizedForm?: string;
  /**
   * Emergency information. See go/emergency-trusted-contacts-papi.
   */
  emergencyInfo?: AppsPeopleOzExternalMergedpeopleapiFieldEmergencyInfo;
  /**
   * Read-only. Field requested by specifying `HANGOUTS_PHONE_DATA` in
   * `extension_set.extension_names`.
   */
  extendedData?: AppsPeopleOzExternalMergedpeopleapiPhoneExtendedData;
  /**
   * The `type` translated and formatted in the request locale. See
   * go/people-api-howto/localization for details on how to usage.
   */
  formattedType?: string;
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
  /**
   * The type of the phone number. The type can be free form or one of these
   * predefined values: * `home` * `work` * `mobile` * `homeFax` * `workFax` *
   * `otherFax` * `pager` * `workMobile` * `workPager` * `main` * `googleVoice`
   * * `other`
   */
  type?: string;
  uri?: string;
  value?: string;
}

function serializeAppsPeopleOzExternalMergedpeopleapiPhone(data: any): AppsPeopleOzExternalMergedpeopleapiPhone {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiPhone(data: any): AppsPeopleOzExternalMergedpeopleapiPhone {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

export interface AppsPeopleOzExternalMergedpeopleapiPhoneExtendedData {
  /**
   * For use with Hangouts extension.
   */
  structuredPhone?: AppsPeopleOzExternalMergedpeopleapiStructuredPhone;
}

export interface AppsPeopleOzExternalMergedpeopleapiPhoto {
  /**
   * Read-only. Use UpdatePersonPhoto to change photo decorations. If this
   * photo is decorated, this field contains information about its decorations.
   * For now, this will contain at most one entry.
   */
  decoration?: SocialGraphApiProtoDecorationOverlay[];
  /**
   * URL of an emoji avatar as an image. See go/emoji-cdn. PeopleAPI will
   * return the SVG format so that it can be scaled client side and so that the
   * images will not be animated. All clients that use this field must also have
   * fall-back handling for using the `Photo.url` field if this is empty. When
   * we have FIFE-compatible emoji-image URLs we will drop this field and return
   * the Photo.url instead. Clients that have their own go/emoji-rendering
   * integration may prefer to render the emoji-avatar from `Photo.glyph` field
   * using their rendering system so that the emoji version/style match the rest
   * of the application. For further background, see
   * go/chatroom-avatar-as-roster-metadata. This field will only be populated if
   * all of: - The PersonFieldMetadata `container_type` for the Photo is
   * NAMED_CHAT_ROOM - The chat room has an emoji type avatar image set
   */
  emojiAvatarUrl?: string;
  /**
   * Unicode emoji representation of the chat room emoji avatar. This can be
   * used by clients that use go/emoji-rendering directly so that they can
   * present this with the same version/style as the rest of their application.
   * This value may also be useful to clients as alt-text for the image. This
   * field will only be populated if all of: - The PersonFieldMetadata
   * `container_type` for the Photo is NAMED_CHAT_ROOM - The chat room has an
   * emoji type avatar image set
   */
  glyph?: string;
  /**
   * A set of HTML data provider attributions that must be shown with the
   * result. Supported for PLACES photos only. See:
   * go/understanding-places-api-attribution-requirements
   */
  htmlAttribution?: string[];
  /**
   * True when the photo is synthetic or generated (i.e. a monogram or default
   * photo), false when the person has a custom photo.
   */
  isDefault?: boolean;
  /**
   * Indicates if the photo is a monogram avatar. Combined with is_default, the
   * type of photo can be determined by: is_default=true, is_monogram=true:
   * Default monogram avatar. is_default=true, is_monogram=false: Default
   * silhouette avatar. is_default=false: Custom photo. is_monogram is
   * irrelevant in this case.
   */
  isMonogram?: boolean;
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
  /**
   * When is_monogram=true, this is the background color of the monogram photo
   * as a hex RGB formatted string "RRGGBB".
   */
  monogramBackground?: string;
  /**
   * Read-only. A reference to the original, undecorated profile photo in
   * storage. This field is not stored. It is populated by a live read to
   * /SocialGraphImageService.GetActiveProfilePhoto. This field is only returned
   * when "person.photo.original_photo" is specified in the request mask.
   */
  originalPhoto?: SocialGraphApiProtoImageReference;
  /**
   * For writes only. Indicates photo content for person photo-field update.
   * Currently only used for profile-photo updates (not contact photos yet).
   */
  photoId?: AppsPeopleOzExternalMergedpeopleapiPhotoPhotoStorageId;
  /**
   * Most clients don't need to worry about this field and should just use the
   * `url` to fetch the photo. See go/phototoken-migration-plan for some more
   * context about this field. If you think you want to use this please talk
   * with people-api-eng@ first.
   */
  photoToken?: string;
  /**
   * See go/people-api-concepts/photos for info on the different
   * representations of URLs.
   */
  url?: string;
  /**
   * A URL for a UI to view the photo in its original context. For example, for
   * a place photo, this is the url of a Google Maps page displaying the photo.
   * Supported for place photos only.
   */
  viewerUrl?: string;
}

function serializeAppsPeopleOzExternalMergedpeopleapiPhoto(data: any): AppsPeopleOzExternalMergedpeopleapiPhoto {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
    originalPhoto: data["originalPhoto"] !== undefined ? serializeSocialGraphApiProtoImageReference(data["originalPhoto"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiPhoto(data: any): AppsPeopleOzExternalMergedpeopleapiPhoto {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
    originalPhoto: data["originalPhoto"] !== undefined ? deserializeSocialGraphApiProtoImageReference(data["originalPhoto"]) : undefined,
  };
}

/**
 * Info necessary for looking up a photo in storage.
 */
export interface AppsPeopleOzExternalMergedpeopleapiPhotoPhotoStorageId {
  /**
   * For writes only, pass the media key that represents the image in photos
   * backend. Note, this is not populated on reads.
   */
  mediaKey?: string;
}

/**
 * Metadata specific to places.
 */
export interface AppsPeopleOzExternalMergedpeopleapiPlaceDetails {
  /**
   * A URL hosted by Google providing more information about this place This is
   * the URL returned by Places API in the Place.Url.google field
   */
  googleUrl?: string;
  latLng?: AppsPeopleOzExternalMergedpeopleapiLatLng;
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
  openingHours?: AppsPeopleOzExternalMergedpeopleapiOpeningHours;
  /**
   * The name of the primary type. Examples of primary type are: "art_school",
   * "clothing_wholesaler", etc. All primary types can be found at
   * http://shortn/_veqh6UwWdc
   */
  primaryTypeName?: string;
}

function serializeAppsPeopleOzExternalMergedpeopleapiPlaceDetails(data: any): AppsPeopleOzExternalMergedpeopleapiPlaceDetails {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiPlaceDetails(data: any): AppsPeopleOzExternalMergedpeopleapiPlaceDetails {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

/**
 * Extension data for use in Play Games Product Profile. See
 * go/jam-games-profile.
 */
export interface AppsPeopleOzExternalMergedpeopleapiPlayGamesExtendedData {
  /**
   * User's top achievements that are sorted for example by rarity.
   */
  achievements?: AppsPeopleOzExternalMergedpeopleapiPlayGamesExtendedDataAchievement[];
  /**
   * The avatar image to display for the user.
   */
  avatarImageUrl?: string;
  /**
   * Failure type if there is an error when fetching product profile data.
   */
  failure?: AppsPeopleOzExternalMergedpeopleapiProductProfileFailure;
  /**
   * The gamer tag set by the user. Not set if the user hasn't set a gamer tag
   * yet.
   */
  gamerTag?: string;
  /**
   * User's level.
   */
  playerLevel?: number;
  /**
   * Specifies the visibility of the player's profile.
   */
  profileVisibility?:  | "UNKNOWN_CLIENT_PLAYER_PROFILE_VISIBILITY" | "PRIVATE_VISIBILITY" | "PUBLIC_VISIBILITY" | "FRIENDS_VISIBILITY";
  /**
   * Total number of friends.
   */
  totalFriendsCount?: bigint;
  /**
   * How many achievements this player has unlocked.
   */
  totalUnlockedAchievements?: bigint;
}

function serializeAppsPeopleOzExternalMergedpeopleapiPlayGamesExtendedData(data: any): AppsPeopleOzExternalMergedpeopleapiPlayGamesExtendedData {
  return {
    ...data,
    totalFriendsCount: data["totalFriendsCount"] !== undefined ? String(data["totalFriendsCount"]) : undefined,
    totalUnlockedAchievements: data["totalUnlockedAchievements"] !== undefined ? String(data["totalUnlockedAchievements"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiPlayGamesExtendedData(data: any): AppsPeopleOzExternalMergedpeopleapiPlayGamesExtendedData {
  return {
    ...data,
    totalFriendsCount: data["totalFriendsCount"] !== undefined ? BigInt(data["totalFriendsCount"]) : undefined,
    totalUnlockedAchievements: data["totalUnlockedAchievements"] !== undefined ? BigInt(data["totalUnlockedAchievements"]) : undefined,
  };
}

/**
 * Details of an achievement that the user has unlocked.
 */
export interface AppsPeopleOzExternalMergedpeopleapiPlayGamesExtendedDataAchievement {
  /**
   * The name of the achievement.
   */
  achievementName?: string;
  /**
   * The achievement icon url shown to the user if it is unlocked.
   */
  achievementUnlockedIconUrl?: string;
  /**
   * Rarity of unlocking this achievement (3% of players unlocked would be 3)
   */
  rarityPercentage?: number;
}

/**
 * Information about a plus page and the entity it represents.
 */
export interface AppsPeopleOzExternalMergedpeopleapiPlusPageInfo {
  /**
   * Int64 ID of packaging-service entry; if set, the plus page is associated
   * with a third-party application.
   */
  applicationId?: bigint;
  entityType?:  | "ENTITY_TYPE_UNSPECIFIED" | "LOCAL" | "COMPANY" | "BRAND" | "CELEBRITY" | "CAUSE" | "ENTERTAINMENT" | "OTHER" | "OBSOLETE_PRIVATE";
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
}

function serializeAppsPeopleOzExternalMergedpeopleapiPlusPageInfo(data: any): AppsPeopleOzExternalMergedpeopleapiPlusPageInfo {
  return {
    ...data,
    applicationId: data["applicationId"] !== undefined ? String(data["applicationId"]) : undefined,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiPlusPageInfo(data: any): AppsPeopleOzExternalMergedpeopleapiPlusPageInfo {
  return {
    ...data,
    applicationId: data["applicationId"] !== undefined ? BigInt(data["applicationId"]) : undefined,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

/**
 * Map marker location for an address.
 */
export interface AppsPeopleOzExternalMergedpeopleapiPointSpec {
  bounds?: GeostoreRectProto;
  point?: GeostorePointProto;
  pointSource?:  | "UNKNOWN_POINT_SOURCE" | "POINT_SOURCE_UNSPECIFIED" | "USER_PROVIDED" | "SYSTEM_PROVIDED" | "USER_CONFIRMED";
}

/**
 * Custom field that represents POSIX account information. Description of the
 * field family: go/fbs-posix. If account has non-empty Username or Uid we will
 * enforce global uniqueness of (AccountNamespace, CustomerKey, SystemId, Uid)
 * and (AccountNamespace, CustomerKey, SystemId, Username) tuples to ensure
 * there are no duplicates.
 */
export interface AppsPeopleOzExternalMergedpeopleapiPosixAccount {
  /**
   * The user visible value is used to distinguish identical posix account
   * fields with different customer key values.
   */
  accountId?: string;
  /**
   * Value indicates the uniqueness namespace that applies to the POSIX
   * information. The value is included in all POSIX account uniqueness indices.
   * The indexing prevents two accounts within the same customer from having the
   * same username. Namespacing allows Windows and Linux users to share the same
   * username.
   */
  accountNamespace?:  | "LINUX_GSUITE" | "LINUX_CONSUMER" | "WINDOWS_GSUITE" | "WINDOWS_CONSUMER";
  /**
   * Value indicates whether the POSIX information is associated with a
   * non-human entity and the validation logic to apply during PosixAccount
   * mutation.
   */
  accountType?:  | "LINUX_USER_ACCOUNT" | "LINUX_SERVICE_ACCOUNT" | "LINUX_EXTERNAL_USER" | "WINDOWS_USER_ACCOUNT" | "WINDOWS_SERVICE_ACCOUNT" | "WINDOWS_EXTERNAL_USER";
  /**
   * The customer associated with the POSIX identity. If the user is already
   * associated with a G Suite Customer, this field has the same value as
   * http://google3/ccc/hosted/policies/settings/dthree_customer_info.proto
   */
  customerKey?: bigint;
  /**
   * The value is automatically set to a SHA-256 fingerprint of the POSIX
   * account. A fingerprint should uniquely identify a POSIX account entry.
   */
  fingerprint?: string;
  /**
   * The GECOS (user information) entry for this account.
   */
  gecos?: string;
  /**
   * The default group ID.
   */
  gid?: bigint;
  /**
   * The path to the home directory for this account.
   */
  homeDirectory?: string;
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
  /**
   * Value indicates whether to use Linux or Windows specific validation logic
   * during PosixAccount mutation.
   */
  operatingSystemType?:  | "OPERATING_SYSTEM_TYPE_UNSPECIFIED" | "LINUX" | "WINDOWS";
  /**
   * The path to the login shell for this account.
   */
  shell?: string;
  /**
   * System identifier for which account Username or Uid apply to. If not
   * specified on mutate by a caller it will default to empty value if either
   * Username or Uid are being set. SystemId does require to have a value (even
   * an empty one) because it is included into null-filtered Spanner index used
   * to enforce uniqueness on Username and Uid fields.
   */
  systemId?: string;
  /**
   * The user ID.
   */
  uid?: bigint;
  /**
   * The username of the account.
   */
  username?: string;
}

function serializeAppsPeopleOzExternalMergedpeopleapiPosixAccount(data: any): AppsPeopleOzExternalMergedpeopleapiPosixAccount {
  return {
    ...data,
    customerKey: data["customerKey"] !== undefined ? String(data["customerKey"]) : undefined,
    gid: data["gid"] !== undefined ? String(data["gid"]) : undefined,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
    uid: data["uid"] !== undefined ? String(data["uid"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiPosixAccount(data: any): AppsPeopleOzExternalMergedpeopleapiPosixAccount {
  return {
    ...data,
    customerKey: data["customerKey"] !== undefined ? BigInt(data["customerKey"]) : undefined,
    gid: data["gid"] !== undefined ? BigInt(data["gid"]) : undefined,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
    uid: data["uid"] !== undefined ? BigInt(data["uid"]) : undefined,
  };
}

export interface AppsPeopleOzExternalMergedpeopleapiProductMetadata {
  productSource?:  | "PRODUCT_SOURCE_UNKNOWN" | "PRODUCT_SOURCE_DEFAULT" | "PRODUCT_SOURCE_ASSISTANT" | "PRODUCT_SOURCE_JANATA" | "PRODUCT_SOURCE_SPEED_DIAL";
}

/**
 * Product profiles failure type: the status of the rpc to fetch the product
 * profile.
 */
export interface AppsPeopleOzExternalMergedpeopleapiProductProfileFailure {
  failureType?:  | "PRODUCT_PROFILE_FAILURE_TYPE_UNKNOWN" | "RPC_FAILURE";
}

/**
 * Stats pertaining to incoming edges and views, visible to the requester (with
 * acls applied). Related to, but not equal to,
 * com.google.focus.proto.Storage.UserVisibleStats.
 */
export interface AppsPeopleOzExternalMergedpeopleapiProfileOwnerStats {
  /**
   * Replacement for deprecated follower_count. Comes from the EdgeSummary.
   */
  incomingAnyCircleCount?: bigint;
  /**
   * Deprecated. This field is no longer populated by the server.
   */
  viewCount?: bigint;
}

function serializeAppsPeopleOzExternalMergedpeopleapiProfileOwnerStats(data: any): AppsPeopleOzExternalMergedpeopleapiProfileOwnerStats {
  return {
    ...data,
    incomingAnyCircleCount: data["incomingAnyCircleCount"] !== undefined ? String(data["incomingAnyCircleCount"]) : undefined,
    viewCount: data["viewCount"] !== undefined ? String(data["viewCount"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiProfileOwnerStats(data: any): AppsPeopleOzExternalMergedpeopleapiProfileOwnerStats {
  return {
    ...data,
    incomingAnyCircleCount: data["incomingAnyCircleCount"] !== undefined ? BigInt(data["incomingAnyCircleCount"]) : undefined,
    viewCount: data["viewCount"] !== undefined ? BigInt(data["viewCount"]) : undefined,
  };
}

/**
 * This is a Google+-only field (and thus does not exist for consumer users).
 * See go/fbs-g+-deprecation.
 */
export interface AppsPeopleOzExternalMergedpeopleapiProfileUrl {
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
  url?: string;
}

function serializeAppsPeopleOzExternalMergedpeopleapiProfileUrl(data: any): AppsPeopleOzExternalMergedpeopleapiProfileUrl {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiProfileUrl(data: any): AppsPeopleOzExternalMergedpeopleapiProfileUrl {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

/**
 * Message to represent a user's set of preferred pronouns, see
 * go/pronouns-backend.
 */
export interface AppsPeopleOzExternalMergedpeopleapiPronoun {
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
  pronounData?: SocialGraphApiProtoPronounData;
}

function serializeAppsPeopleOzExternalMergedpeopleapiPronoun(data: any): AppsPeopleOzExternalMergedpeopleapiPronoun {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiPronoun(data: any): AppsPeopleOzExternalMergedpeopleapiPronoun {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

export interface AppsPeopleOzExternalMergedpeopleapiRawDeviceContactAnalyticalInfo {
  /**
   * The data set within the account that this raw contact belongs to.
   */
  dataSet?: string;
  /**
   * The CP2 dirty field which indicates the sync state of the raw contact:
   * https://developer.android.com/reference/android/provider/ContactsContract.SyncColumns#DIRTY
   * True if the row is changed but not synced
   */
  dirty?: boolean;
  /**
   * Whether the source ID exists for non-Google contacts. Won't set for Google
   * contacts.
   */
  sourceIdExist?: boolean;
  /**
   * The Sync Info of a raw contact.
   */
  syncInfo?: SocialGraphApiProtoSyncInfo;
}

/**
 * Raw device contact information.
 */
export interface AppsPeopleOzExternalMergedpeopleapiRawDeviceContactInfo {
  /**
   * Account name of raw contact, e.g. "google@gmail.com".
   */
  accountName?: string;
  /**
   * Account type of raw contact, e.g. "com.google" or "com.linkedin.android".
   */
  accountType?: string;
  /**
   * The detailed app-specific endpoint data available for the given
   * RawDeviceContactInfo instance. This proto should be used to obtain the list
   * of actions and mimetypes supported by the third-party app. Design:
   * go/3p-contact-upload
   */
  appContactData?: SocialGraphApiAppContactData[];
  /**
   * The app-specific endpoint data needed for app action fulfillment. Usage of
   * this field should be avoided on the server-side, and should use the more
   * detailed |full_app_info| field.
   */
  appInfo?: AppsPeopleOzExternalMergedpeopleapiAppUniqueInfo;
  /**
   * If true, this raw contact can be used on other devices than the one it
   * originated from. Assigned by the server.
   */
  crossDeviceAllowed?: boolean;
  /**
   * Extra metadata for this raw contact.
   */
  deviceContactMetadata?: AppsPeopleOzExternalMergedpeopleapiDeviceContactExtraMetadata;
  /**
   * The focus contact id for Google contacts.
   */
  googleContactId?: bigint;
  /**
   * The base64 serialized
   * social.graph.peopleapi.proto.internal.RawDeviceContactId. This id should be
   * used to correlate to field.metadata.encoded_container_id when the
   * field.metadata.container_type is RAW_DEVICE_CONTACT The id also correlates
   * to person.metadata.identity_info.source_id.id.
   */
  id?: string;
  /**
   * The type of photo from the device (if any).
   */
  photoType?:  | "PHOTO_TYPE_UNKNOWN" | "NO_PHOTO" | "THUMBNAIL" | "FULL_SIZE_PHOTO";
  /**
   * The id of the raw contact on the device.
   */
  rawContactId?: bigint;
  /**
   * Only to be used by Romanesco team specifically for analytics.
   */
  rawDeviceContactAnalyticalInfo?: AppsPeopleOzExternalMergedpeopleapiRawDeviceContactAnalyticalInfo;
}

function serializeAppsPeopleOzExternalMergedpeopleapiRawDeviceContactInfo(data: any): AppsPeopleOzExternalMergedpeopleapiRawDeviceContactInfo {
  return {
    ...data,
    deviceContactMetadata: data["deviceContactMetadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiDeviceContactExtraMetadata(data["deviceContactMetadata"]) : undefined,
    googleContactId: data["googleContactId"] !== undefined ? String(data["googleContactId"]) : undefined,
    rawContactId: data["rawContactId"] !== undefined ? String(data["rawContactId"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiRawDeviceContactInfo(data: any): AppsPeopleOzExternalMergedpeopleapiRawDeviceContactInfo {
  return {
    ...data,
    deviceContactMetadata: data["deviceContactMetadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiDeviceContactExtraMetadata(data["deviceContactMetadata"]) : undefined,
    googleContactId: data["googleContactId"] !== undefined ? BigInt(data["googleContactId"]) : undefined,
    rawContactId: data["rawContactId"] !== undefined ? BigInt(data["rawContactId"]) : undefined,
  };
}

/**
 * Metadata information about a profile. This message replaces legacy
 * profile-specific singleton fields from the PersonMetadata proto (singleton
 * top level Person fields are not compatible with non-profile-centric person
 * results, which may include multiple profile containers).
 */
export interface AppsPeopleOzExternalMergedpeopleapiReadOnlyProfileInfo {
  /**
   * The account email linked to the profile, if any exists and is visible to
   * the requester.
   */
  accountEmail?: AppsPeopleOzExternalMergedpeopleapiAccountEmail;
  /**
   * Indicates whether the profile owner has blocked this person.
   */
  blockType?:  | "BLOCK_TYPE_UNKNOWN" | "CIRCLE" | "LEGACY"[];
  /**
   * CustomerInfo for dasher user. The reader has to explicitly request this in
   * the field_mask as 'read_only_profile_info.customer_info'
   */
  customerInfo?: AppsPeopleOzExternalMergedpeopleapiCustomerInfo;
  /**
   * DEPRECATED. Use the `ReadOnlyProfileInfo.customer_info` field instead
   * (b/138120418). Only populated if in_viewer_domain is true.
   */
  domainInfo?: AppsPeopleOzExternalMergedpeopleapiReadOnlyProfileInfoDomainInfo;
  /**
   * Indicates whether this person is blocking the profile owner.
   */
  incomingBlockType?:  | "BLOCK_TYPE_UNKNOWN" | "CIRCLE" | "LEGACY"[];
  /**
   * DEPRECATED. Proxying trust between users in a domain should use
   * go/flex-orgs-platform. For more info see:
   * http://doc/18i0-C7vWcz2UuXYBsmulnriVCK3_EuMPpRlPa2OmMHw#heading=h.dobotdwx25kg
   * Indicates whether the profile owner is in the same domain as the viewer.
   */
  inViewerDomain?: boolean;
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
  /**
   * DEPRECATED.
   */
  objectType?:  | "OBJECT_TYPE_UNKNOWN" | "PERSON" | "PAGE";
  /**
   * The Focus-obfuscated Gaia ID of the profile owner (go/obfuscated-ids).
   */
  ownerId?: string;
  ownerUserType?:  | "OWNER_USER_TYPE_UNKNOWN" | "GOOGLE_USER" | "GPLUS_USER" | "GPLUS_DISABLED_BY_ADMIN" | "GOOGLE_APPS_USER" | "GOOGLE_APPS_SELF_MANAGED_USER" | "GOOGLE_FAMILY_USER" | "GOOGLE_FAMILY_CHILD_USER" | "GOOGLE_APPS_ADMIN_DISABLED" | "GOOGLE_ONE_USER" | "GOOGLE_FAMILY_CONVERTED_CHILD_USER"[];
  /**
   * DEPRECATED. Please use `person.plus_page_info` instead.
   */
  plusPageType?:  | "PLUS_PAGE_TYPE_UNKNOWN" | "LOCAL" | "COMPANY" | "BRAND" | "CELEBRITY" | "CAUSE" | "ENTERTAINMENT" | "OTHER" | "OBSOLETE_PRIVATE";
  /**
   * Stats/counters pertaining to followers and incoming edges.
   */
  profileOwnerStats?: AppsPeopleOzExternalMergedpeopleapiProfileOwnerStats;
}

function serializeAppsPeopleOzExternalMergedpeopleapiReadOnlyProfileInfo(data: any): AppsPeopleOzExternalMergedpeopleapiReadOnlyProfileInfo {
  return {
    ...data,
    customerInfo: data["customerInfo"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiCustomerInfo(data["customerInfo"]) : undefined,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
    profileOwnerStats: data["profileOwnerStats"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiProfileOwnerStats(data["profileOwnerStats"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiReadOnlyProfileInfo(data: any): AppsPeopleOzExternalMergedpeopleapiReadOnlyProfileInfo {
  return {
    ...data,
    customerInfo: data["customerInfo"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiCustomerInfo(data["customerInfo"]) : undefined,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
    profileOwnerStats: data["profileOwnerStats"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiProfileOwnerStats(data["profileOwnerStats"]) : undefined,
  };
}

/**
 * DEPRECATED.
 */
export interface AppsPeopleOzExternalMergedpeopleapiReadOnlyProfileInfoDomainInfo {
  /**
   * DEPRECATED. Organization badge for the domain this person is a member of.
   * The badge is the primary hosted domain.
   */
  domainBadge?: string[];
  /**
   * DEPRECATED. Hosted domain this person is a member of. Formerly only
   * available via PersonExtendedData.
   */
  domainName?: string[];
}

/**
 * Relation stores the related person between the contact or profile and a
 * third person. See go/relation-vs-relationship for relation vs relationship
 * explanation. This field currently includes RelationshipToMe data in fields
 * value and canonical_value for ContainerType CONTACT_ANNOTATION. This will be
 * moved to RelationshipToMe in b/221081499.
 */
export interface AppsPeopleOzExternalMergedpeopleapiRelation {
  /**
   * Canonicalized `value` of the relation from this person to the user. This
   * is currently used for data from contact annotations. Possible canonical
   * values are based from
   * http://google3/googledata/quality/aliases/relationship_en.config.
   */
  canonicalValue?: string;
  /**
   * The `type` translated and formatted in the request locale. See
   * go/people-api-howto/localization for details on how to usage.
   */
  formattedType?: string;
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
  /**
   * The person whose email matches the Relation.value field, if it is a valid
   * email address. This field is read-only and ignored on update.
   */
  relationDetails?: AppsPeopleOzExternalMergedpeopleapiRelationRelationDetails;
  /**
   * The relation type. The type can be free form or one of these predefined
   * values: * `spouse` * `child` * `mother` * `father` * `parent` * `brother` *
   * `sister` * `friend` * `relative` * `domesticPartner` * `manager` *
   * `assistant` * `referredBy` * `partner`
   */
  type?: string;
  /**
   * The person this relation applies to. Custom value provided by the user.
   */
  value?: string;
}

function serializeAppsPeopleOzExternalMergedpeopleapiRelation(data: any): AppsPeopleOzExternalMergedpeopleapiRelation {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiRelation(data: any): AppsPeopleOzExternalMergedpeopleapiRelation {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

export interface AppsPeopleOzExternalMergedpeopleapiRelationRelationDetails {
  /**
   * Equivalent to Name.display_name for the person_id profile.
   */
  displayName?: string;
  /**
   * Equivalent to Organization.title for the primary organization of the
   * person_id profile.
   */
  jobTitle?: string;
  personId?: string;
  /**
   * Equivalent to Photo.url for the person_id profile.
   */
  photoUrl?: string;
}

/**
 * Deprecated in b/122464133. No data returned for this field.
 */
export interface AppsPeopleOzExternalMergedpeopleapiRelationshipInterest {
  /**
   * The `type` translated and formatted in the request locale. See
   * go/people-api-howto/localization for details on how to usage.
   */
  formattedType?: string;
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
  /**
   * These fields may give away the sexual orientation of the user.
   */
  type?: string;
}

function serializeAppsPeopleOzExternalMergedpeopleapiRelationshipInterest(data: any): AppsPeopleOzExternalMergedpeopleapiRelationshipInterest {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiRelationshipInterest(data: any): AppsPeopleOzExternalMergedpeopleapiRelationshipInterest {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

/**
 * Deprecated in b/122464133. No data returned for this field.
 */
export interface AppsPeopleOzExternalMergedpeopleapiRelationshipStatus {
  /**
   * The `type` translated and formatted in the request locale. See
   * go/people-api-howto/localization for details on how to usage.
   */
  formattedType?: string;
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
  type?: string;
}

function serializeAppsPeopleOzExternalMergedpeopleapiRelationshipStatus(data: any): AppsPeopleOzExternalMergedpeopleapiRelationshipStatus {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiRelationshipStatus(data: any): AppsPeopleOzExternalMergedpeopleapiRelationshipStatus {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

/**
 * User preference for shared endorsements. See go/se-devguide and
 * go/sharedendorsements for details, including guidance on which contexts are
 * which.
 */
export interface AppsPeopleOzExternalMergedpeopleapiRightOfPublicityState {
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
  state?:  | "STATE_UNSPECIFIED" | "NOT_OK_TO_DISPLAY" | "OK_TO_DISPLAY" | "OK_TO_DISPLAY_IN_NON_ADS_COMMERCIAL_CONTEXT";
}

function serializeAppsPeopleOzExternalMergedpeopleapiRightOfPublicityState(data: any): AppsPeopleOzExternalMergedpeopleapiRightOfPublicityState {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiRightOfPublicityState(data: any): AppsPeopleOzExternalMergedpeopleapiRightOfPublicityState {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

/**
 * Information specific to rosters like Google Groups and Chatrooms.
 */
export interface AppsPeopleOzExternalMergedpeopleapiRosterDetails {
  /**
   * Abridged / sample subset of member details of the roster. NOTE: This field
   * is only returned if the request's field mask includes
   * "person.roster_details.abridged_roster_memberships".
   * http://cs/symbol:google.apps.cloudidentity.groups.internal.GroupSummary.abridged_memberships
   */
  abridgedRosterMemberships?: AppsPeopleOzExternalMergedpeopleapiRosterMember[];
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
  /**
   * Indicates the number of members and sub-rosters of the roster. Corresponds
   * to
   * http://cs/symbol:google.apps.cloudidentity.groups.internal.Group.direct_member_count_per_type
   */
  rosterMemberCount?: AppsPeopleOzExternalMergedpeopleapiRosterMemberCount;
}

function serializeAppsPeopleOzExternalMergedpeopleapiRosterDetails(data: any): AppsPeopleOzExternalMergedpeopleapiRosterDetails {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
    rosterMemberCount: data["rosterMemberCount"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiRosterMemberCount(data["rosterMemberCount"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiRosterDetails(data: any): AppsPeopleOzExternalMergedpeopleapiRosterDetails {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
    rosterMemberCount: data["rosterMemberCount"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiRosterMemberCount(data["rosterMemberCount"]) : undefined,
  };
}

/**
 * Represents details of a member of a roster. Used in RosterDetails.
 * Corresponds to
 * http://cs/symbol:google.apps.cloudidentity.groups.internal.Membership
 */
export interface AppsPeopleOzExternalMergedpeopleapiRosterMember {
  /**
   * Type of the member.
   */
  memberType?:  | "ROSTER_MEMBER_TYPE_UNSPECIFIED" | "PERSON" | "ROSTER";
  /**
   * Focus-Obfuscated Gaia Id of the member.
   */
  personId?: string;
}

/**
 * Represents the summary of member counts of a roster. Used in RosterDetails.
 * Corresponds to
 * http://cs/symbol:google.apps.cloudidentity.groups.internal.Group.DirectMemberCountPerType
 */
export interface AppsPeopleOzExternalMergedpeopleapiRosterMemberCount {
  /**
   * Indicates the number of direct sub-rosters of the roster. This comes from
   * http://cs/symbol:google.apps.cloudidentity.groups.internal.Group.DirectMemberCountPerType.group_count
   */
  directGroupCount?: bigint;
  /**
   * Indicates the number of direct, non-roster members of the roster. This
   * comes from
   * http://cs/symbol:google.apps.cloudidentity.groups.internal.Group.DirectMemberCountPerType.user_count
   */
  directUserCount?: bigint;
}

function serializeAppsPeopleOzExternalMergedpeopleapiRosterMemberCount(data: any): AppsPeopleOzExternalMergedpeopleapiRosterMemberCount {
  return {
    ...data,
    directGroupCount: data["directGroupCount"] !== undefined ? String(data["directGroupCount"]) : undefined,
    directUserCount: data["directUserCount"] !== undefined ? String(data["directUserCount"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiRosterMemberCount(data: any): AppsPeopleOzExternalMergedpeopleapiRosterMemberCount {
  return {
    ...data,
    directGroupCount: data["directGroupCount"] !== undefined ? BigInt(data["directGroupCount"]) : undefined,
    directUserCount: data["directUserCount"] !== undefined ? BigInt(data["directUserCount"]) : undefined,
  };
}

/**
 * Profile for Janata and Search. go/janata-profile-in-sgbe
 */
export interface AppsPeopleOzExternalMergedpeopleapiSearchProfile {
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
  searchProfileData?: SocialGraphApiProtoSearchProfileData;
}

function serializeAppsPeopleOzExternalMergedpeopleapiSearchProfile(data: any): AppsPeopleOzExternalMergedpeopleapiSearchProfile {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
    searchProfileData: data["searchProfileData"] !== undefined ? serializeSocialGraphApiProtoSearchProfileData(data["searchProfileData"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiSearchProfile(data: any): AppsPeopleOzExternalMergedpeopleapiSearchProfile {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
    searchProfileData: data["searchProfileData"] !== undefined ? deserializeSocialGraphApiProtoSearchProfileData(data["searchProfileData"]) : undefined,
  };
}

/**
 * As of 03/2018 is not supported for user Profile.
 */
export interface AppsPeopleOzExternalMergedpeopleapiSipAddress {
  /**
   * The `type` translated and formatted in the request locale. See
   * go/people-api-howto/localization for details on how to usage.
   */
  formattedType?: string;
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
  /**
   * The type of the SIP address. The type can be free form or or one of these
   * predefined values: * `home` * `work` * `mobile` * `other`
   */
  type?: string;
  value?: string;
}

function serializeAppsPeopleOzExternalMergedpeopleapiSipAddress(data: any): AppsPeopleOzExternalMergedpeopleapiSipAddress {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiSipAddress(data: any): AppsPeopleOzExternalMergedpeopleapiSipAddress {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

export interface AppsPeopleOzExternalMergedpeopleapiSkills {
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
  value?: string;
}

function serializeAppsPeopleOzExternalMergedpeopleapiSkills(data: any): AppsPeopleOzExternalMergedpeopleapiSkills {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiSkills(data: any): AppsPeopleOzExternalMergedpeopleapiSkills {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

/**
 * The social connection of this person to the viewer. NOTE: this is used by
 * go/starlight, but not actually used or returned in PeopleAPI. See b/27281119
 * for context.
 */
export interface AppsPeopleOzExternalMergedpeopleapiSocialConnection {
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
  type?:  | "SOCIAL_CONNECTION_UNKNOWN" | "NO_CONNECTION" | "GPLUS_SECOND_HOP" | "DIRECT_CONNECTION" | "SELF"[];
}

function serializeAppsPeopleOzExternalMergedpeopleapiSocialConnection(data: any): AppsPeopleOzExternalMergedpeopleapiSocialConnection {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiSocialConnection(data: any): AppsPeopleOzExternalMergedpeopleapiSocialConnection {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

export interface AppsPeopleOzExternalMergedpeopleapiSortKeys {
  affinity?: AppsPeopleOzExternalMergedpeopleapiAffinity[];
  /**
   * Deprecated. This field is only populated with 0.000 for legacy reasons.
   * Clients should not use this field.
   */
  interactionRank?: string;
  lastName?: string;
  lastNameRaw?: string;
  name?: string;
  /**
   * Raw name strings that were used to generate the name and last_name sort
   * keys fields above. Contacts+ need them to generate section headers for list
   * view (b/30642866).
   */
  nameRaw?: string;
}

/**
 * Id of a single source from the merged person.
 */
export interface AppsPeopleOzExternalMergedpeopleapiSourceIdentity {
  /**
   * The type of source. To be deprecated infavor of container_type
   */
  container?:  | "UNKNOWN" | "PROFILE" | "CONTACT" | "CIRCLE" | "PLACE" | "ACCOUNT" | "EXTERNAL_ACCOUNT" | "DOMAIN_PROFILE" | "DOMAIN_CONTACT" | "DEVICE_CONTACT" | "GOOGLE_GROUP" | "AFFINITY" | "RAW_DEVICE_CONTACT" | "CONTACT_ANNOTATION" | "DELEGATED_CONTACT";
  /**
   * The type of the source.
   */
  containerType?:  | "UNKNOWN_CONTAINER" | "PROFILE" | "CONTACT" | "CIRCLE" | "PLACE" | "ACCOUNT" | "EXTERNAL_ACCOUNT" | "DOMAIN_PROFILE" | "DOMAIN_CONTACT" | "DEVICE_CONTACT" | "GOOGLE_GROUP" | "NAMED_CHAT_ROOM" | "UNNAMED_CHAT_ROOM" | "AFFINITY" | "RAW_DEVICE_CONTACT" | "CONTACT_ANNOTATION" | "DELEGATED_CONTACT";
  /**
   * In sync responses, indicates whether the identity source has been deleted.
   * Not applicable to GOOGLE_GROUP.
   */
  deleted?: boolean;
  /**
   * The encoded id of the data source. This field correlates to
   * PersonFieldMetadata.encoded_container_id. The possible values of this `id`
   * field are as follows based on the value of the `container_type` field:
   * CONTACT: Hex-encoded contact id. PROFILE: DOMAIN_PROFILE: GOOGLE_GROUP:
   * NAMED_CHAT_ROOM: Focus-obfuscated Gaia ID. DOMAIN_CONTACT:
   * Synthetic-contact id representing the domain shared contact. PLACE: Encoded
   * PlaceId (go/javagoog/maps/api/places/util/PlaceIdEncoder.java)
   * RAW_DEVICE_CONTACT: Pair of device_id and raw_contact_id, encoded as base64
   * serialized social.graph.peopleapi.proto.internal.RawDeviceContactId proto.
   * CONTACT_ANNOTATION: Pair of annotation_id and event_timestamp, encoded as
   * base64 serialized social.graph.peopleapi.proto.internal.ContactAnnotationId
   * proto. -- DEPRECATED container types -- If the container is CIRCLE, then
   * the id is going to be the synthetic- contact id representing the email-only
   * circle member or gaia circle member for which the requester does not have a
   * contact for.
   */
  id?: string;
  /**
   * Last update timestamp of this source. NOTE: Only populated for CONTACT
   * container type in Java PeopleAPI. Populated for CONTACT, PROFILE,
   * DOMAIN_PROFILE in Sharpen implementation. NOTE: Not populated for
   * GOOGLE_GROUP.
   */
  lastUpdated?: Date;
  /**
   * **DEPRECATED** Please use `last_updated` field instead. Last update
   * timestamp of this source in microseconds. NOTE: Only populated for CONTACT
   * container type.
   */
  lastUpdatedMicros?: bigint;
  /**
   * NOTE: Not populated for GOOGLE_GROUP.
   */
  sourceEtag?: string;
}

function serializeAppsPeopleOzExternalMergedpeopleapiSourceIdentity(data: any): AppsPeopleOzExternalMergedpeopleapiSourceIdentity {
  return {
    ...data,
    lastUpdated: data["lastUpdated"] !== undefined ? data["lastUpdated"].toISOString() : undefined,
    lastUpdatedMicros: data["lastUpdatedMicros"] !== undefined ? String(data["lastUpdatedMicros"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiSourceIdentity(data: any): AppsPeopleOzExternalMergedpeopleapiSourceIdentity {
  return {
    ...data,
    lastUpdated: data["lastUpdated"] !== undefined ? new Date(data["lastUpdated"]) : undefined,
    lastUpdatedMicros: data["lastUpdatedMicros"] !== undefined ? BigInt(data["lastUpdatedMicros"]) : undefined,
  };
}

/**
 * Custom field that represents SSH public keys associated with the user. We
 * can treat the field as a map from a string fingerprint to the SSH public key
 * information.
 */
export interface AppsPeopleOzExternalMergedpeopleapiSshPublicKey {
  expirationTime?: Date;
  /**
   * The value is automatically set to a SHA-256 fingerprint of an SSH public
   * key. A fingerprint should uniquely identify an SSH public key.
   */
  fingerprint?: string;
  key?: string;
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
}

function serializeAppsPeopleOzExternalMergedpeopleapiSshPublicKey(data: any): AppsPeopleOzExternalMergedpeopleapiSshPublicKey {
  return {
    ...data,
    expirationTime: data["expirationTime"] !== undefined ? data["expirationTime"].toISOString() : undefined,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiSshPublicKey(data: any): AppsPeopleOzExternalMergedpeopleapiSshPublicKey {
  return {
    ...data,
    expirationTime: data["expirationTime"] !== undefined ? new Date(data["expirationTime"]) : undefined,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

/**
 * This message mirrors the ContactPhoneNumber message in
 * ccc/grand_central/common/types.proto. For various reasons, we cannot take on
 * a direct dependency. See other proto file for most recent documentation.
 */
export interface AppsPeopleOzExternalMergedpeopleapiStructuredPhone {
  /**
   * The phone formatted type. See docs from mirrored proto:
   * http://google3/ccc/grand_central/common/types.proto?l=128&rcl=241000760
   */
  formattedType?: string;
  phoneNumber?: AppsPeopleOzExternalMergedpeopleapiStructuredPhonePhoneNumber;
  shortCode?: AppsPeopleOzExternalMergedpeopleapiStructuredPhoneShortCode;
  /**
   * The type of phone. See docs from mirrored proto:
   * http://google3/ccc/grand_central/common/types.proto?l=125&rcl=241000760
   */
  type?: string;
}

export interface AppsPeopleOzExternalMergedpeopleapiStructuredPhonePhoneNumber {
  e164?: string;
  i18nData?: AppsPeopleOzExternalMergedpeopleapiStructuredPhonePhoneNumberI18nData;
}

export interface AppsPeopleOzExternalMergedpeopleapiStructuredPhonePhoneNumberI18nData {
  countryCode?: number;
  internationalNumber?: string;
  isValid?: boolean;
  nationalNumber?: string;
  regionCode?: string;
  validationResult?:  | "UNKNOWN" | "IS_POSSIBLE" | "INVALID_COUNTRY_CODE" | "TOO_SHORT" | "TOO_LONG" | "IS_POSSIBLE_LOCAL_ONLY" | "INVALID_LENGTH";
}

export interface AppsPeopleOzExternalMergedpeopleapiStructuredPhoneShortCode {
  /**
   * The phone code. See docs from mirrored proto:
   * http://google3/ccc/grand_central/common/types.proto?l=70&rcl=241000760
   */
  code?: string;
  countryCode?: string;
}

export interface AppsPeopleOzExternalMergedpeopleapiTagline {
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
  value?: string;
}

function serializeAppsPeopleOzExternalMergedpeopleapiTagline(data: any): AppsPeopleOzExternalMergedpeopleapiTagline {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiTagline(data: any): AppsPeopleOzExternalMergedpeopleapiTagline {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

/**
 * *UNSUPPORTED*. This message is never populated and is no longer used.
 */
export interface AppsPeopleOzExternalMergedpeopleapiTeamsExtendedData {
  admins?: AppsPeopleOzExternalMergedpeopleapiPerson[];
  adminTo?: AppsPeopleOzExternalMergedpeopleapiPerson[];
  dottedLineManagers?: AppsPeopleOzExternalMergedpeopleapiPerson[];
  dottedLineReports?: AppsPeopleOzExternalMergedpeopleapiPersonListWithTotalNumber;
  failures?:  | "UNKNOWN_FAILURE" | "MANAGEMENT_CHAIN" | "REPORTS" | "DOTTED_LINE_REPORTS" | "DOTTED_LINE_MANAGERS" | "ADMINS" | "ADMIN_TO"[];
  managementChain?: AppsPeopleOzExternalMergedpeopleapiPerson[];
  reports?: AppsPeopleOzExternalMergedpeopleapiPersonListWithTotalNumber;
}

function serializeAppsPeopleOzExternalMergedpeopleapiTeamsExtendedData(data: any): AppsPeopleOzExternalMergedpeopleapiTeamsExtendedData {
  return {
    ...data,
    admins: data["admins"] !== undefined ? data["admins"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiPerson(item))) : undefined,
    adminTo: data["adminTo"] !== undefined ? data["adminTo"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiPerson(item))) : undefined,
    dottedLineManagers: data["dottedLineManagers"] !== undefined ? data["dottedLineManagers"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiPerson(item))) : undefined,
    dottedLineReports: data["dottedLineReports"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonListWithTotalNumber(data["dottedLineReports"]) : undefined,
    managementChain: data["managementChain"] !== undefined ? data["managementChain"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiPerson(item))) : undefined,
    reports: data["reports"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonListWithTotalNumber(data["reports"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiTeamsExtendedData(data: any): AppsPeopleOzExternalMergedpeopleapiTeamsExtendedData {
  return {
    ...data,
    admins: data["admins"] !== undefined ? data["admins"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiPerson(item))) : undefined,
    adminTo: data["adminTo"] !== undefined ? data["adminTo"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiPerson(item))) : undefined,
    dottedLineManagers: data["dottedLineManagers"] !== undefined ? data["dottedLineManagers"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiPerson(item))) : undefined,
    dottedLineReports: data["dottedLineReports"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonListWithTotalNumber(data["dottedLineReports"]) : undefined,
    managementChain: data["managementChain"] !== undefined ? data["managementChain"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiPerson(item))) : undefined,
    reports: data["reports"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonListWithTotalNumber(data["reports"]) : undefined,
  };
}

export interface AppsPeopleOzExternalMergedpeopleapiUserDefined {
  key?: string;
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
  value?: string;
}

function serializeAppsPeopleOzExternalMergedpeopleapiUserDefined(data: any): AppsPeopleOzExternalMergedpeopleapiUserDefined {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiUserDefined(data: any): AppsPeopleOzExternalMergedpeopleapiUserDefined {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

/**
 * DEPRECATED in favor of ProfileStats. Stats pertaining to incoming edges and
 * views, visible to the requester (with acls applied). Related to, but not
 * equal to, com.google.focus.proto.Storage.UserVisibleStats.
 */
export interface AppsPeopleOzExternalMergedpeopleapiUserVisibleStats {
  /**
   * Replacement for deprecated follower_count. Comes from the EdgeSummary.
   */
  incomingAnyCircleCount?: bigint;
  viewCount?: bigint;
}

function serializeAppsPeopleOzExternalMergedpeopleapiUserVisibleStats(data: any): AppsPeopleOzExternalMergedpeopleapiUserVisibleStats {
  return {
    ...data,
    incomingAnyCircleCount: data["incomingAnyCircleCount"] !== undefined ? String(data["incomingAnyCircleCount"]) : undefined,
    viewCount: data["viewCount"] !== undefined ? String(data["viewCount"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiUserVisibleStats(data: any): AppsPeopleOzExternalMergedpeopleapiUserVisibleStats {
  return {
    ...data,
    incomingAnyCircleCount: data["incomingAnyCircleCount"] !== undefined ? BigInt(data["incomingAnyCircleCount"]) : undefined,
    viewCount: data["viewCount"] !== undefined ? BigInt(data["viewCount"]) : undefined,
  };
}

/**
 * Store metadata information like annotation-id and product source for visible
 * to guests contacts go/visible-to-guests.
 */
export interface AppsPeopleOzExternalMergedpeopleapiVisibleToGuests {
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
}

function serializeAppsPeopleOzExternalMergedpeopleapiVisibleToGuests(data: any): AppsPeopleOzExternalMergedpeopleapiVisibleToGuests {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiVisibleToGuests(data: any): AppsPeopleOzExternalMergedpeopleapiVisibleToGuests {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

export interface AppsPeopleOzExternalMergedpeopleapiWebContactsExtendedData {
  /**
   * Used by Contacts client-side to indicate whether a person is not
   * completed.
   */
  isIncomplete?: boolean;
}

export interface AppsPeopleOzExternalMergedpeopleapiWebsite {
  /**
   * The `type` translated and formatted in the request locale. See
   * go/people-api-howto/localization for details on how to usage.
   */
  formattedType?: string;
  metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
  /**
   * Currently in Oz: "Links": Links with no rel. "Other profiles": Links with
   * rel=ME. "Contributor to": Links with rel=CONTRIBUTOR_TO or
   * PAST_CONTRIBUTOR_TO.
   */
  rel?: AppsPeopleOzExternalMergedpeopleapiWebsiteRelationshipInfo[];
  /**
   * The type of the website. The type can be free form or one of these
   * predefined values: * `home` * `work` * `blog` * `profile` * `homePage` *
   * `ftp` * `reservations` * `appInstallPage`: website for a Currents
   * application. * `other`
   */
  type?: string;
  value?: string;
}

function serializeAppsPeopleOzExternalMergedpeopleapiWebsite(data: any): AppsPeopleOzExternalMergedpeopleapiWebsite {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiWebsite(data: any): AppsPeopleOzExternalMergedpeopleapiWebsite {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata(data["metadata"]) : undefined,
  };
}

export interface AppsPeopleOzExternalMergedpeopleapiWebsiteRelationshipInfo {
  type?:  | "UNKNOWN" | "ME" | "NOT_ME" | "CONTRIBUTOR_TO" | "PAST_CONTRIBUTOR_TO";
}

/**
 * Extension data for use in Youtube Product Profile.
 */
export interface AppsPeopleOzExternalMergedpeopleapiYoutubeExtendedData {
  /**
   * Information about a channel created by the user. A user can create
   * multiple Youtube channels.
   */
  channelData?: AppsPeopleOzExternalMergedpeopleapiChannelData[];
  /**
   * Failure type if there is an error when fetching product profile data.
   */
  failure?: AppsPeopleOzExternalMergedpeopleapiProductProfileFailure;
}

function serializeAppsPeopleOzExternalMergedpeopleapiYoutubeExtendedData(data: any): AppsPeopleOzExternalMergedpeopleapiYoutubeExtendedData {
  return {
    ...data,
    channelData: data["channelData"] !== undefined ? data["channelData"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiChannelData(item))) : undefined,
  };
}

function deserializeAppsPeopleOzExternalMergedpeopleapiYoutubeExtendedData(data: any): AppsPeopleOzExternalMergedpeopleapiYoutubeExtendedData {
  return {
    ...data,
    channelData: data["channelData"] !== undefined ? data["channelData"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiChannelData(item))) : undefined,
  };
}

/**
 * Access settings for providers.
 */
export interface AssistantApiAccessControlOutput {
  /**
   * If true, the user consented to use YouTube Kids as a video provider for
   * non-unicorn users(voice recognized adults or guest). Unicorn accounts
   * shouldnt use this setting.
   */
  allowNonUnicornUserAccessYoutubeKids?: boolean;
  guestAccessOnYoutube?:  | "UNKNOWN_GUEST_ACCESS" | "USE_DEFAULT_ACCOUNT_FOR_GUEST" | "DISABLED_FOR_GUEST";
}

/**
 * The features supported by the ActionV2 protocol. Note that after we move on
 * to ConversationProto for all surfaces we can remove this message.
 */
export interface AssistantApiActionV2SupportedFeatures {
  /**
   * This flag is used to work around a bug in AGSA 6.8 that got away. The bug
   * prevents users from accessing their shopping list if the URL of the
   * shopping list is not a keep.google.com URL. This will happen when switch
   * the backend that stores the shopping list from Keep to a backend maintained
   * by the Google Shopping Express team.
   */
  expressUrlInSettingsResponseSupported?: boolean;
  /**
   * Whether client supports reconnect client input in action v2 payload. This
   * capability is needed to determine if client supports parsing client input
   * payload from actionv2 proto for workflow purposes. See
   * go/personal-workflow. OWNER:nyzstar,vvvemuri.
   */
  reconnectClientInputSupported?: boolean;
  /**
   * Whether or not the surface supports a simple UnsupportedAction instead of
   * a ModalState punt card for rendering. For ActionV2 punt cards, the
   * ModalState extension on the ResourceSet is the canonical way of building
   * punt cards. However, while most all devices support the ActionV2 protocol,
   * not all devices handle the ModalState rendering as part of the ActionV2.
   * For these devices, we want to build a modified ActionV2 for punt cards
   * which omits this ModalState. At present, this is only Android Wear and
   * should not be used for other devices if they support ModalState or
   * Conversation protocol.
   */
  simpleActionV2PuntSupported?: boolean;
  /**
   * A list of all the action types supported by the client. These should be
   * the string representation of majel.ActionTypes within
   * "quality/majel/api/proto/action_v2.proto".
   */
  supportedActionType?: string[];
  /**
   * Checks if screenshots can be taken on the client. This field is set on the
   * client from AGSA 7.2 onwards.
   */
  takeScreenshotSupported?: boolean;
  /**
   * If IMMERSIVE_ACTIONS UiType is supported by the client.
   */
  voiceDelightImmersiveUiSupported?: boolean;
  /**
   * If Voice Delight Stickers are supported by the client. In order to support
   * Voice Delight stickers, the client should know how to extract sticker_url
   * from VoiceDelightSystemInteractionSegment.
   */
  voiceDelightStickersSupported?: boolean;
  /**
   * If Voice Delight Suggestion Chips are supported by the client. In order to
   * support Voice Delight Suggestion Chips, the client should know how to
   * extract suggestions form VoiceDelightSystemInteraction.ResourceSet.
   */
  voiceDelightSuggestionsSupported?: boolean;
}

/**
 * Capabilities related to Android intent support. These capabilities can apply
 * to any device on the Android platform. Provides the list of Android package
 * names that support a given Android intent.
 */
export interface AssistantApiAndroidIntentCapabilities {
  androidIntentCapability?: AssistantApiAndroidIntentCapabilitiesAndroidIntentCapability[];
}

export interface AssistantApiAndroidIntentCapabilitiesAndroidIntentCapability {
  /**
   * The Action name of the Android Intent in standard notation
   * (https://developer.android.com/reference/android/content/Intent#getAction()).
   */
  intentActionName?: string;
  /**
   * The Android provider packages that support the intent, e.g.
   * "com.google.android.deskclock".
   */
  packageNames?: string[];
}

/**
 * Used to describe app capabilities of the device installed apps reported to
 * the server.
 */
export interface AssistantApiAppCapabilities {
  /**
   * Indicates whether the provider is compatible for media fulfillment on this
   * surface. For example, Amazon Music isn't compatible with the driving mode.
   */
  allowlistedForMediaFulfillment?: boolean;
  /**
   * Currently unused. Will be used in the future when integrating with
   * incremental app capabilities.
   */
  appIntegrationsSettings?: AssistantApiAppIntegrationsSettings;
  /**
   * This system app is disabled in settings.
   */
  disabledSystemApp?: boolean;
  /**
   * The installed app of the provider.
   */
  provider?: AssistantApiCoreTypesProvider;
  /**
   * This provider has integrated its cloud backend with Google, and Google can
   * route the user queries to the provider's cloud.
   */
  routableToProviderCloud?: boolean;
  /**
   * This provider has an app that supports on-device search through the
   * provider's own inventory.
   */
  searchableOnDevice?: boolean;
  /**
   * This provider has integrated its content with Google, and Google has
   * enabled to serve its content as a server-side solution.
   */
  searchableOnServer?: boolean;
  /**
   * This provider has an app that supports starting new media playback when
   * there is no screen (e.g. by integrating with the Bisto SDK).
   */
  supportsScreenlessInitiation?: boolean;
  /**
   * This provider is an app which should be used for query annotations. This
   * is useful for apps which may not be already indexed by Google or are client
   * specific.
   */
  whitelistedForAnnotation?: boolean;
}

function serializeAssistantApiAppCapabilities(data: any): AssistantApiAppCapabilities {
  return {
    ...data,
    provider: data["provider"] !== undefined ? serializeAssistantApiCoreTypesProvider(data["provider"]) : undefined,
  };
}

function deserializeAssistantApiAppCapabilities(data: any): AssistantApiAppCapabilities {
  return {
    ...data,
    provider: data["provider"] !== undefined ? deserializeAssistantApiCoreTypesProvider(data["provider"]) : undefined,
  };
}

/**
 * Used to describe the incremental change of app capabilities of the device
 * installed apps reported to the server.
 */
export interface AssistantApiAppCapabilitiesDelta {
  /**
   * Currently unused. Will be used in the future when integrating with
   * incremental app capabilities.
   */
  appIntegrationsSettings?: AssistantApiAppIntegrationsSettings;
  /**
   * The installed app of the provider.
   */
  providerDelta?: AssistantApiCoreTypesProviderDelta;
}

function serializeAssistantApiAppCapabilitiesDelta(data: any): AssistantApiAppCapabilitiesDelta {
  return {
    ...data,
    providerDelta: data["providerDelta"] !== undefined ? serializeAssistantApiCoreTypesProviderDelta(data["providerDelta"]) : undefined,
  };
}

function deserializeAssistantApiAppCapabilitiesDelta(data: any): AssistantApiAppCapabilitiesDelta {
  return {
    ...data,
    providerDelta: data["providerDelta"] !== undefined ? deserializeAssistantApiCoreTypesProviderDelta(data["providerDelta"]) : undefined,
  };
}

export interface AssistantApiAppControlSupport {
  enabled?:  | "DEFAULT_DISABLED" | "ENABLED_WITH_SMART_DICTATION";
}

/**
 * Contains the app privacy bits used for App Integrations implicit request.
 * (go/app-privacy-settings-for-implicit-requests)
 */
export interface AssistantApiAppIntegrationsSettings {
  /**
   * Whether to enable Assistant to handle request with predicted apps.
   */
  handleRequestsWithPredictedApps?:  | "UNSET" | "FALSE" | "TRUE";
}

export interface AssistantApiAssistantContinuedPresenceSupport {
  /**
   * Indicates in what cases assistant continued presence can be shown as a
   * plate. This field is white-listed as being PII-free. Please do not add PII
   * here.
   */
  plateSupport?:  | "DEFAULT_NO_PLATE" | "SEARCH_ONLY";
}

/**
 * These capabilities represent the audio input features associated with the
 * device. This includes what kind of audio input the device can handle, and
 * what the privacy circumstances of that input are.
 */
export interface AssistantApiAudioInput {
  environment?:  | "SURROUNDING_USERS" | "AUTHENTICATED_USER_ONLY";
  quality?:  | "VOICE_QUALITY" | "MUSIC_QUALITY";
}

/**
 * These capabilities represent the audio output features associated with the
 * device. This includes what kind of audio output the device can handle, and
 * what the privacy circumstances of that output are.
 */
export interface AssistantApiAudioOutput {
  alwaysOnSpeaker?:  | "UNKNOWN" | "NOT_SUPPORTED" | "SUPPORTED";
  environment?:  | "SURROUNDING_USERS" | "AUTHENTICATED_USER_ONLY";
  mediaTtsMixable?:  | "MEDIA_TTS_MIXABLE_UNKNOWN" | "MEDIA_TTS_MIXABLE_NOT_SUPPORTED" | "MEDIA_TTS_MIXABLE_SUPPORTED";
  quality?:  | "VOICE_QUALITY" | "MUSIC_QUALITY";
  volumeProperties?: AssistantApiVolumeProperties;
}

/**
 * CallCapabilities supported by a surface. See go/call-capabilities. Next ID:
 * 7
 */
export interface AssistantApiCallCapabilities {
  /**
   * The supported call formats on the surface.
   */
  callFormats?:  | "UNSPECIFIED_FORMAT" | "AUDIO" | "VIDEO" | "TEXT"[];
  /**
   * The supported call mediums on the surface.
   */
  callMediums?:  | "UNSPECIFIED_MEDIUM" | "PSTN" | "VOIP" | "EMAIL" | "ONLINE_CHAT" | "TEXT_MESSAGING" | "MESSAGE"[];
  /**
   * The call options this surface can provide. For example, SPEAKERPHONE is
   * available on Android OPA while iOPA doesn't support it yet.
   */
  callOptions?:  | "UNSPECIFIED_CALL_OPTION" | "SPEAKERPHONE" | "BLUETOOTH" | "HEADSET" | "MIC" | "CAMERA"[];
  /**
   * If true, APP_ID queries initiated by this device should fall back to
   * execution on the tethered device if it's available and if the primary
   * device cannot perform the action (e.g. due to the app not being installed).
   */
  fallbackToTetheredDeviceAppCapabilities?: boolean;
  /**
   * Should only be checked if nonempty.
   */
  supportedRecipientTypes?:  | "UNSPECIFIED_ENDPOINT" | "PHONE_NUMBER" | "EMAIL_ADDRESS" | "APP_UNIQUE_ID" | "EMERGENCY_PHONE_NUMBER" | "VOICEMAIL"[];
  /**
   * Whether the surface supports Duo calling email endpoints.
   */
  supportsDuoEmailEndpoint?: boolean;
}

/**
 * These capabilities represent the camera features associated with the device.
 */
export interface AssistantApiCameraCapabilities {
  /**
   * Whether the device supports Face Match.
   */
  faceMatchCapable?: boolean;
  /**
   * Whether the device has a camera.
   */
  hasCamera?: boolean;
}

/**
 * These capabilities present the capability of the device running camera
 * receiver apps.
 */
export interface AssistantApiCameraReceiverCapabilities {
  /**
   * Whether the device has limited camera stream capability. If true, check
   * supported_camera_receivers for detailed supported cameras.
   */
  hasLimitedCameraStreamCapability?: boolean;
  /**
   * The camera receiver cast apps the device supports. Only used if
   * has_limited_camera_stream_capability is true.
   */
  supportedCameraReceivers?: AssistantApiCoreTypesCastAppInfo[];
}

/**
 * Information about the readiness of Home app features on the device. As of
 * January 2023, this is only populated by Assistant on Android.
 */
export interface AssistantApiCapabilitiesHomeAppCapabilities {
  /**
   * The app's installation and setup state. This is most pertinent for Tangor,
   * where lock screen Smart Home queries are fulfilled by a Home app activity
   * that may be blocked if this value is not `SETUP_STATE_COMPLETE`.
   */
  setupState?:  | "SETUP_STATE_UNKNOWN" | "SETUP_STATE_INCOMPLETE" | "SETUP_STATE_COMPLETE";
}

/**
 * Capabilities that are associated with Assistants on auto surfaces. This is
 * different from other capabilities such as CarSettingsCapabilities,
 * CloudCarCapabilities since they are specific to settings and 3P cloud
 * information. All the auto/car Assistant specific capabilities should live
 * here.
 */
export interface AssistantApiCarAssistantCapabilities {
  /**
   * Indicates whether the current Assistant should provide a multi Assistant
   * specific punt when there are multiple Auto specific Google Assistants
   * (Android Auto Projected (AAP) and Android Auto Embedded (AAE)) in the same
   * GAS enabled car. This will be used by both AAP and AAE. Design doc:
   * go/doubledash++
   */
  shouldPuntMultiAssistantMode?: boolean;
}

/**
 * Capabilities that are associated with Assistant Settings on auto surfaces.
 */
export interface AssistantApiCarSettingsCapabilities {
  /**
   * If true, it indicates that the auto surface client should receive a warmer
   * welcome TTS for signed-out users. For signed-in user, we will rely on
   * server side metadata. go/aaae:preview-lang
   */
  playWarmerWelcome?: boolean;
  /**
   * If true, it indicates that the client can be used to add cars after
   * account linking with the OEM.
   */
  supportsAddingCars?: boolean;
}

export interface AssistantApiCastAssistantSettingLinkingResult {
  /**
   * Cast linking status for ATV surfaces. This is derived from error messages
   * returned from Cast Orchestration Server and will be used for data profiling
   * only(go/katniss-settings-dashboard).
   */
  castLinkingStatus?:  | "NOT_SET" | "SUCCEED" | "DEVICE_CONFLICT" | "DEVICE_NAME_EMPTY" | "CLIENT_ID_MISSING_TAG" | "INVALID_DEVICE_ID" | "DATA_SYNC_THROTTLED" | "CREATE_ROBOT_ACCOUNT_FAILED" | "UNAUTHORIZED_CLIENT" | "OTHER_ERROR";
  /**
   * The error msg returned from COS, truncated in case it's too large.
   */
  truncatedErrorMsg?: string;
}

/**
 * These capabilities represent capabilities that have to do with casting that
 * pertain to this device. Next ID: 9
 */
export interface AssistantApiCastCapabilities {
  /**
   * Whether the device has limited camera stream capability and if yes, which
   * receivers are supported.
   */
  cameraReceiverCapabilities?: AssistantApiCameraReceiverCapabilities;
  /**
   * The supported protocols for camera streaming. The value is used as string
   * in go/smarthome-internal-api#camera-stream, so using a string for this
   * field instead of an enum. Supported protocols: (align the definition in
   * go/smarthome-camerastream-trait) - "hls": HTTP Live Streaming - "dash":
   * Dynamic Adaptive Streaming over HTTP - "smooth_stream": Smooth Streaming -
   * "progressive_mp4": Progressive MP4 (will likely only be used for Clips) -
   * "webrtc": WebRTC (currently, only H.264 is supported) - "nexustalk":
   * Internal-only protocol used for Nest
   */
  cameraStreamSupportedProtocols?: string[];
  /**
   * True if we can cast things to this device.
   */
  canReceiveCast?: boolean;
  /**
   * Optional for primarily cast devices (e.g., Chirp, Chromecast). For devices
   * that are NOT primarily cast devices, but having a cast receiver as
   * secondary functionality, this field SHOULD store the cast-device-id to be
   * used to send remote casting commands to the device. Example: Android TV,
   * which supports both Android-native actions as well as remote casting using
   * its built-in cast receiver. Android TV device id contains a DUSI id, which
   * is not a cast-device-id. When executing a cast command on the Android TV,
   * this field is used to route the cast command (through CloudCastService) to
   * the cast receiver on the device.
   */
  deviceId?: AssistantApiCoreTypesDeviceId;
  /**
   * Whether this device supports dynamic groups or not. It implies if a Stream
   * Control operation (transfer, expansion, and contraction) could be applied
   * on this device since Stream Control is implemented as part of dynamic
   * groups (ie, adding/removing devices from playback)
   */
  dynamicGroupsSupported?: boolean;
  groupType?:  | "NONE" | "STATIC_GROUP" | "DYNAMIC_GROUP" | "STEREO_PAIR";
  /**
   * Whether UI overlay applications are supported on this device. It's used by
   * Chromecast only.
   */
  overlayApplicationsSupported?: boolean;
  /**
   * Whether the device supports playing games through Yeti. This is set by the
   * cast device when the device is updated: Chromecast updates -> Chromecast
   * registers its capabilities with CCS -> CCS passes the capabilities to the
   * AssistantSettingsService -> AssistantSettingsService stores the device's
   * capabilities. go/yeti-gaming-supported-cast-capability
   */
  yetiGamingSupported?: boolean;
}

/**
 * The properties of the client op device.MODIFY_SETTING. This proto is stored
 * in the SupportedClientOp proto.
 */
export interface AssistantApiClientOpPropertiesDeviceModifySettingClientOpProperty {
  /**
   * Additional specific setting capabilities. This boolean is used to indicate
   * whether we want to skip the Android and GSA version check in
   * CheckSettingSchemaAndMaybeGetUris() from
   * assistant/vertical/device/fulfillment/utils/setting_utils.h. Consider
   * setting this field to true if your device is neither Android or GSA
   * (especially when the UserAgent string of your device's TaskRequest will not
   * contain a valid/up-to-date Android/GSA version).
   */
  skipAndroidAndGsaVersionCheck?: boolean;
  /**
   * Uses DeviceSetting enum which corresponds to setting_id. This indicates
   * which specific settings are supported by client. An empty list implies all
   * settings are supported.
   */
  supportedSettings?:  | "UNSPECIFIED" | "ABOUT_ME" | "ACCESSIBILITY" | "ACTIVE_EDGE" | "ACTIVE_EDGE_SENSITIVITY" | "ADAPTIVE_BATTERY" | "ADAPTIVE_BRIGHTNESS" | "ADAPTIVE_CHARGING" | "ADAPTIVE_CONNECTIVITY" | "ADAPTIVE_SOUND" | "ADD_ACCOUNT" | "ADD_BLUETOOTH_DEVICE" | "ADD_DEVICE" | "ADD_FINGERPRINT" | "ADS_TRACKING" | "AIRPLANE_MODE" | "ALARM_VOLUME" | "ALARM_SOUND" | "ALLOW_MULTIPLE_USERS" | "AMBIENT_DISPLAY_ALWAYS_ON" | "AMBIENT_DISPLAY_NEW_NOTIFICATION" | "ANDROID_AUTO" | "ANDROID_VERSION" | "APP_BATTERY_USAGE" | "APP_DATA_USAGE" | "APP_DETAILS" | "APP_SHORTCUT" | "APPS_NOTIFICATIONS" | "APPS_STORAGE" | "ASSISTANT_ACCOUNT" | "ASSISTANT_FACE_MATCH" | "ASSISTANT_LANGUAGE" | "ASSISTANT_VOICE_MATCH" | "AUTO_ROTATE" | "AUTO_ROTATE_FACE_DETECTION" | "BACKUP" | "BATTERY_LEVEL" | "BATTERY_LOW" | "BATTERY_PERCENTAGE" | "BATTERY_PRESENT" | "BATTERY_SAVER" | "BATTERY_SAVER_SCHEDULE" | "BATTERY_SHARE" | "BATTERY_USAGE" | "BIOMETRIC" | "BLUETOOTH" | "BLUETOOTH_NAME" | "BLUETOOTH_ADDRESS" | "BLUETOOTH_SETTINGS" | "BRIGHTNESS_LEVEL" | "BUBBLES" | "CALL_VOLUME" | "CAMERA_DOUBLE_TWIST" | "CAST" | "CAR_CRASH_DETECTION" | "COLOR_INVERSION" | "COLOR_CORRECTION" | "CONVERSATIONS" | "CHARGING_SOUNDS_AND_VIBRATION" | "CHARGING_STATE" | "CONNECTED_DEVICES" | "CONTACTLESS_PAYMENTS" | "DATA_ROAMING" | "DATA_SAVER" | "DATA_USAGE" | "DATA_LIMIT" | "DATA_LIMIT_LEVEL" | "DATA_WARNING" | "DATA_WARNING_LEVEL" | "DEFAULT_ALARM_SOUND" | "DEFAULT_NOTIFICATION_SOUND" | "DEFAULT_APPS" | "DEVELOPER_OPTIONS" | "DEVICE_ASSISTANT_APP" | "DEVICE_NAME" | "DISPLAY_OVER_OTHER_APPS" | "DISPLAY_SIZE" | "DO_NOT_DISTURB" | "DO_NOT_DISTURB_MESSAGES" | "DO_NOT_DISTURB_CALLS" | "DO_NOT_DISTURB_ALARMS" | "DO_NOT_DISTURB_SCHEDULES" | "DOUBLE_TAP_CHECK_PHONE" | "DRIVING_MODE" | "EARTHQUAKE_ALERTS" | "EMERGENCY" | "EMERGENCY_ALERTS" | "EMERGENCY_CONTACTS" | "EMERGENCY_INFORMATION" | "ETHERNET_TETHERING" | "EXTRA_DIM" | "EXTREME_BATTERY_SAVER" | "FACTORY_RESET" | "FIND_MY_DEVICE" | "FLASHLIGHT" | "FOCUS_MODE" | "FONT_SIZE" | "FREE_UP_SPACE" | "FINGERPRINT_MANAGER" | "GESTURES" | "HAPTIC_FEEDBACK_VIBRATION" | "HARD_KEYBOARD" | "HEADS_UP" | "HIGH_REFRESH_RATE" | "HOT_SPOT" | "HOTSPOT_TETHERING" | "HOT_WORD" | "IP_ADDRESS" | "IMPROVE_LOCATION_ACCURACY" | "JUMP_TO_CAMERA" | "KEYBOARD_SHORTCUTS" | "LIFT_CHECK_PHONE" | "LIVE_TRANSLATE" | "LOCATION" | "LOCATION_HISTORY" | "LOCATION_BLUETOOTH_SCANNING" | "LOCATION_WIFI_SCANNING" | "LOCK_SCREEN" | "LOCK_SCREEN_DEVICE_CONTROLS" | "LOCK_SCREEN_WALLET" | "MAC_ADDRESS" | "MAGNIFICATION" | "MAGNIFY_BUTTON" | "MAGNIFY_TRIPLE_TAP" | "MANIFY_BUTTON" | "MANIFY_TRIPLE_TAP" | "MEDIA" | "MEDIA_VOLUME" | "MICROPHONE_ACCESS" | "MOBILE" | "MOBILE_DATA" | "MUSIC" | "MUTE_MODE" | "NETWORK" | "NETWORK_RESET" | "NFC" | "NIGHT_LIGHT_INTENSITY" | "NIGHT_LIGHT_SWITCH" | "NIGHT_MODE" | "NOTIFICATION_BADGE" | "NOTIFICATION_SOUND" | "NOTIFICATION_ON_SCREEN" | "NOTIFICATION_HISTORY" | "NOTIFY_FOR_PUBLIC_NETWORKS" | "ONEHANDED_MODE" | "OS_VERSION" | "PASSWORD" | "PERMISSION_MANAGER" | "PERMISSION_USAGE" | "PERSONALIZATION" | "PRINTING" | "PHONE_NUMBER" | "PICTURE_IN_PICTURE" | "POINTER_SPEED" | "POWER_MENU" | "REMINDERS" | "REQUIRE_DEVICE_UNLOCK_FOR_NFC" | "RINGTONE" | "RING_VOLUME" | "NEARBY_DEVICES_SCANNING" | "NEARBY_SHARE" | "SCREEN_LOCKING_SOUND" | "SCREEN_MAGNIFICATION" | "SCREEN_TIMEOUT" | "SCREEN_LOCK" | "SCREEN_SAVER" | "SELECT_TO_SPEAK" | "SET_TIME_AUTOMATICALLY" | "SET_TIME_ZONE_AUTOMATICALLY" | "SETTINGS" | "SIM" | "SIM_MANAGER" | "SPEECH_RATE" | "STORAGE_USAGE" | "SWIPE_FOR_NOTIFICATION" | "SWITCH_ACCESS" | "SYSTEM_UPDATE" | "SYSTEM_UPDATES" | "SYSTEM_NAVIGATION" | "SYSTEM_NAVIGATION_GESTURES" | "SYSTEM_NAVIGATION_BUTTONS" | "TALKBACK_PASSWORDS" | "TEXT_TO_SPEECH" | "TIME_ZONE" | "UNUSED_APPS" | "USB" | "USB_TETHERING" | "VERBOSE_TTS" | "VIBRATE" | "VIBRATION" | "VIBRATION_MODE" | "VOICE" | "VOLUME_LEVEL" | "WAKE_SCREEN_FOR_NOTIFICATIONS" | "WALLPAPERS" | "WEBVIEW" | "WIFI" | "WIFI_ADD_NETWORK" | "WIFI_ADD_NETWORK_QR_CODE" | "WIFI_CALLING" | "WIFI_HOTSPOT" | "ABOUT_PHONE" | "ACCOUNTS" | "APPLICATION" | "ASSISTANT" | "AUDIO" | "BATTERY" | "BELL_SCHEDULE" | "CONTINUED_CONVERSATION" | "DATE_TIME" | "DARK_THEME" | "DEVICE_INFO" | "DICTIONARY" | "DIGITAL_WELLBEING" | "DISPLAY" | "LANGUAGE" | "NIGHT_LIGHT" | "NOTIFICATION" | "NOTIFICATION_VOLUME" | "PHONE_RINGTONE" | "PRIVACY" | "ROAMING" | "ROUTINES" | "SEARCH" | "SECURITY" | "SOUND" | "SPELL_CHECKER" | "SYSTEM" | "STORAGE" | "VPN" | "AUTOCLICK" | "CARET_HIGHLIGHT" | "CHROMEVOX" | "CURSOR_HIGHLIGHT" | "DOCKED_MAGNIFIER" | "FOCUS_HIGHLIGHT" | "FULLSCREEN_MAGNIFIER" | "HIGH_CONTRAST_MODE" | "LARGE_CURSOR" | "MONO_AUDIO" | "STICKY_KEYS" | "TAP_DRAGGING" | "VIRTUAL_KEYBOARD" | "WEARABLE_AMBIENT" | "WEARABLE_NOISE_CANCELLATION" | "WEARABLE_TOUCH_CONTROLS" | "RAISE_TO_TALK" | "BEDTIME_MODE" | "THEATER_MODE" | "TOUCH_LOCK"[];
  /**
   * Additional specific setting capabilities. This boolean is used to indicate
   * if do not disturb with duration is supported through device.MODIFY_SETTING
   * clientop on a client or not.
   */
  supportsDoNotDisturbWithDuration?: boolean;
  /**
   * Additional specific setting capabilities. This boolean is used to indicate
   * if new unmute logic is enabled on a client or not.
   */
  supportsMuteUnmute?: boolean;
}

/**
 * The properties of the provider.OPEN ClientOp. This proto is stored in the
 * SupportedClientOp proto with the key provider.OPEN.
 */
export interface AssistantApiClientOpPropertiesProviderOpenClientOpProperty {
  /**
   * Whether conversation is kept alive after opening the app. See
   * go/keep-opa-conversation-alive for details.
   */
  keepsConversationAliveAfterOpeningApp?: boolean;
}

/**
 * Used to describe clock capabilities of the device (for example, capabilities
 * related to maximum number of supported alarms and timers that can be created
 * on the device). Fields may be populated by clients or be backfilled by SAL
 * (in case of Timon, for example).
 */
export interface AssistantApiClockCapabilities {
  /**
   * Maximum number of alarms that can be created on the client.
   */
  maxSupportedAlarms?: number;
  /**
   * Maximum extended timer duration supported by the client. The extended
   * timer duration is the total start-to-finish duration after an
   * AddTimeToTimer operation. E.g. if a user sets a timer for 30 minutes, and
   * later adds 10 minutes, the extended duration is 40 minutes.
   */
  maxSupportedExtendedTimerDuration?: AssistantApiDuration;
  /**
   * Maximum duration of timers that can be created on the client.
   */
  maxSupportedTimerDuration?: AssistantApiDuration;
  /**
   * Maximum number of timers that can be created on the client.
   */
  maxSupportedTimers?: number;
  /**
   * The preferred provider to use for stopwatch related functionality.
   */
  preferredStopwatchProvider?: AssistantApiCoreTypesProvider;
  /**
   * Whether the client restricts alarms to ring within the next 24 hours.
   */
  restrictAlarmsToNext24h?: boolean;
}

function serializeAssistantApiClockCapabilities(data: any): AssistantApiClockCapabilities {
  return {
    ...data,
    maxSupportedExtendedTimerDuration: data["maxSupportedExtendedTimerDuration"] !== undefined ? serializeAssistantApiDuration(data["maxSupportedExtendedTimerDuration"]) : undefined,
    maxSupportedTimerDuration: data["maxSupportedTimerDuration"] !== undefined ? serializeAssistantApiDuration(data["maxSupportedTimerDuration"]) : undefined,
    preferredStopwatchProvider: data["preferredStopwatchProvider"] !== undefined ? serializeAssistantApiCoreTypesProvider(data["preferredStopwatchProvider"]) : undefined,
  };
}

function deserializeAssistantApiClockCapabilities(data: any): AssistantApiClockCapabilities {
  return {
    ...data,
    maxSupportedExtendedTimerDuration: data["maxSupportedExtendedTimerDuration"] !== undefined ? deserializeAssistantApiDuration(data["maxSupportedExtendedTimerDuration"]) : undefined,
    maxSupportedTimerDuration: data["maxSupportedTimerDuration"] !== undefined ? deserializeAssistantApiDuration(data["maxSupportedTimerDuration"]) : undefined,
    preferredStopwatchProvider: data["preferredStopwatchProvider"] !== undefined ? deserializeAssistantApiCoreTypesProvider(data["preferredStopwatchProvider"]) : undefined,
  };
}

/**
 * UI capabilities for the surfaces rendering Comms features. See
 * go/rohan-comms-fluid-actions-customization.
 */
export interface AssistantApiCommunicationUiCapabilities {
  fluidActionsUiType?:  | "DEFAULT" | "SIMPLIFIED";
}

export interface AssistantApiContactLookupCapabilities {
  /**
   * If true, contact.LOOKUP should be routed to the tethered device (if
   * present) if the tethered device supports contact.LOOKUP and the primary
   * device does not.
   */
  fallbackToTetheredDevice?: boolean;
}

/**
 * The android app information of the provider. Like, Spotify. Next ID: 16
 * LINT.IfChange
 */
export interface AssistantApiCoreTypesAndroidAppInfo {
  accountType?: string;
  /**
   * Intent associated with the app. We include intents here as different
   * versions of the same app may support different intents. In those cases, the
   * package_name is not enough to identify the app and we should use the
   * combination of package_name and android_intent. This field might contain
   * sensitive data, if represents ClientOp with encapsulated PII such as user
   * query.
   */
  androidIntent?: string;
  /**
   * Store the app unique id endpoint. This will be passed over to app to
   * fulfill the action.
   */
  appUniqueId?: string;
  /**
   * The android app version. Deprecated because
   * https://developer.android.com/reference/android/content/pm/PackageInfo.html#getLongVersionCode
   */
  appVersion?: number;
  /**
   * data_mimetype and account_type are the what AGSA uses to filter which
   * contacts support this Android app in ContactProvider.
   */
  dataMimetype?: string;
  /**
   * If true, client should broadcast the intent instead of open the intent.
   */
  isBroadcastIntent?: boolean;
  /**
   * App is the default app for it's core functionality. For example, it will
   * be true for Android messages if it is the default app to send and receive
   * SMS on the phone.
   */
  isDefault?: boolean;
  /**
   * The localized app name.
   */
  localizedAppName?: string;
  /**
   * The long android app version.
   */
  longVersionCode?: bigint;
  /**
   * Store mimetype of this endpoint. We will use this as the differentiator
   * for Assistant to know whether to use the RawContact for messaging, call or
   * video call. For example, send message mimetype for whatsapp:
   * "vnd.android.cursor.item/vnd.com.whatsapp.profile" voice call mimetype for
   * whatsapp: "vnd.android.cursor.item/vnd.com.whatsapp.voip.call"
   */
  mimetype?: string;
  /**
   * The android app package of the provider, like "com.spotify.music".
   */
  packageName?: string;
  /**
   * The OemProviderType is specific for OEM system Android apps. For example,
   * in Auto Embedded, the OEM will have a system Radio/Media app. The system
   * apps capabilities/core functionalities are captured here. For physical
   * media sources, the OEM may decide to implement one media app (thus, one
   * package name) that handles multiple physical media sources. For these
   * cases, each physical media source will be sent as different providers even
   * though the package name is the same.
   */
  providerType?:  | "UNKNOWN_OEM_PROVIDER_TYPE" | "RADIO_PROVIDER_TYPE" | "SXM_RADIO_PROVIDER_TYPE";
  /**
   * Id of the app's Android shortcut to be launched by Assistant. The client
   * is expected to use the Android LauncherApps API to execute this shortcut
   * which in turn will open the app. For example, Whatsapp may create an
   * Android shortcut for a frequently messaged contact with an id
   * "contact_123". This field will contain that id and the client can execute
   * it to open up the chat with that particular contact. If this field is set,
   * the package_name field must also be set since both will be used by the
   * LauncherApps API for execution. If this field is set, the intent related
   * fields will be ignored and not used as a fallback. Design:
   * go/shortcut-id-in-provider-open-clientop This field should only be set for
   * devices with Android API level >= 25 (since that is the version from which
   * the LauncherApps startShortcut API is available)
   */
  shortcutId?: string;
  /**
   * The fully qualified target class name of the provider, like
   * "com.example.myapp.GetOrderService".
   */
  targetClass?: string;
  /**
   * The android app version name, like "4.1.091.05.40d", "11.2.7.21.alpha".
   * Android Docs:
   * https://developer.android.com/reference/android/content/pm/PackageInfo#versionName
   */
  versionName?: string;
}

function serializeAssistantApiCoreTypesAndroidAppInfo(data: any): AssistantApiCoreTypesAndroidAppInfo {
  return {
    ...data,
    longVersionCode: data["longVersionCode"] !== undefined ? String(data["longVersionCode"]) : undefined,
  };
}

function deserializeAssistantApiCoreTypesAndroidAppInfo(data: any): AssistantApiCoreTypesAndroidAppInfo {
  return {
    ...data,
    longVersionCode: data["longVersionCode"] !== undefined ? BigInt(data["longVersionCode"]) : undefined,
  };
}

/**
 * The change of AndroidAppInfo, e.g. app installation or deletion for
 * incremental delta app info upload.
 */
export interface AssistantApiCoreTypesAndroidAppInfoDelta {
  /**
   * The android app information of the provider. Like, Spotify.
   */
  androidAppInfo?: AssistantApiCoreTypesAndroidAppInfo;
  /**
   * The client-side timestamp in millis when the app is last updated,
   * installed or deleted.
   */
  lastUpdateTimestamp?: Date;
  /**
   * App is installed or deleted.
   */
  updateType?:  | "UNKNOWN_TYPE" | "IS_INSTALLED" | "IS_DELETED";
}

function serializeAssistantApiCoreTypesAndroidAppInfoDelta(data: any): AssistantApiCoreTypesAndroidAppInfoDelta {
  return {
    ...data,
    androidAppInfo: data["androidAppInfo"] !== undefined ? serializeAssistantApiCoreTypesAndroidAppInfo(data["androidAppInfo"]) : undefined,
    lastUpdateTimestamp: data["lastUpdateTimestamp"] !== undefined ? data["lastUpdateTimestamp"].toISOString() : undefined,
  };
}

function deserializeAssistantApiCoreTypesAndroidAppInfoDelta(data: any): AssistantApiCoreTypesAndroidAppInfoDelta {
  return {
    ...data,
    androidAppInfo: data["androidAppInfo"] !== undefined ? deserializeAssistantApiCoreTypesAndroidAppInfo(data["androidAppInfo"]) : undefined,
    lastUpdateTimestamp: data["lastUpdateTimestamp"] !== undefined ? new Date(data["lastUpdateTimestamp"]) : undefined,
  };
}

/**
 * This proto contains the information of a calendar event, including title,
 * start time, end time, etc. IMPORTANT: The definition of CalendarEvent proto
 * is being moved to
 * //assistant/api/core_types/governed/calendar_event_type.proto. All existing
 * references will be updated to point to the new location. If you are adding a
 * reference, use the new one instead. LINT.IfChange(CalendarEvent) NEXT_ID: 26
 */
export interface AssistantApiCoreTypesCalendarEvent {
  /**
   * Attendees invited to the event, usually includes also the organizer.
   */
  attendees?: AssistantApiCoreTypesCalendarEventAttendee[];
  /**
   * The background color of the event, in RGB format.
   */
  backgroundColor?: number;
  /**
   * Optional calendar containing the event.
   */
  calendarId?: string;
  /**
   * The person who created this event.
   */
  creator?: AssistantApiCoreTypesCalendarEventAttendee;
  /**
   * Optional description of the event (plain text).
   */
  description?: string;
  /**
   * The end time of the event. Start and end time must either both be date or
   * both be datetime. End is exclusive, ie. the first day / first second when
   * the event is over.
   */
  end?: AssistantApiDateTime;
  /**
   * Optional event id provided by assistant server. Needs to be unique, at
   * least on a per-user and calendar level, ideally globally unique. If none is
   * given, the server will assign an id.
   */
  eventId?: string;
  /**
   * The flair name, calculated according to the event title (go/as-cal-flair).
   * With the flair name, background images can be got from gstatic (go/scs):
   * https://ssl.gstatic.com/tmly/f8944938hffheth4ew890ht4i8/flairs/
   */
  flairName?: string;
  /**
   * The foreground color of the event, in RGB format.
   */
  foregroundColor?: number;
  /**
   * Whether the guests can invite other guests.
   */
  guestsCanInviteOthers?: boolean;
  /**
   * Whether the guests can modify the event.
   */
  guestsCanModify?: boolean;
  /**
   * Whether the guests of the event can be seen. If false, the user is
   * reported as the only attendee to the event, even though there may be more
   * attendees.
   */
  guestsCanSeeGuests?: boolean;
  /**
   * Optional id of the Habit (Calendar Goal) this event is linked to
   */
  habitId?: string;
  /**
   * Optional status for this habit event instance.
   */
  habitStatus?:  | "UNKNOWN_STATUS" | "ACTIVE" | "DEFERRAL_REQUESTED" | "COMPLETE" | "UNDEFERRABLE";
  /**
   * Absolute link to this event in the Calendar web UI.
   */
  htmlLink?: string;
  /**
   * Optional location of the event (plain text).
   */
  location?: string;
  meetingContacts?: AssistantApiCoreTypesCalendarEventMeetingContact[];
  /**
   * The organizer of this event.
   */
  organizer?: AssistantApiCoreTypesCalendarEventAttendee;
  /**
   * Whether not all attendees are included in the attendee list. This is set
   * when the attendees list has been truncated (e.g., when the number of
   * attendees is beyond the maxAttendees limitation).
   */
  otherAttendeesExcluded?: boolean;
  /**
   * The user's response (the owner of this copy of the event) to this event.
   */
  participationResponse?:  | "RESPONSE_STATUS_UNSPECIFIED" | "NEEDS_ACTION" | "DECLINED" | "TENTATIVE" | "ACCEPTED";
  /**
   * If this is an instance of a recurring event, recurring_event_id identifies
   * the recurring series as a whole.
   */
  recurringEventId?: string;
  /**
   * Meeting rooms associated to this event.
   */
  rooms?: AssistantApiCoreTypesCalendarEventRoom[];
  /**
   * The start time of the event. This event is an all-day event if start has
   * no time_of_day.
   */
  start?: AssistantApiDateTime;
  /**
   * The title of the event.
   */
  summary?: string;
  /**
   * Optional visibility of the event.
   */
  visibility?:  | "DEFAULT" | "PUBLIC" | "PRIVATE" | "CONFIDENTIAL" | "SECRET" | "SHADOW" | "UNKNOWN";
}

function serializeAssistantApiCoreTypesCalendarEvent(data: any): AssistantApiCoreTypesCalendarEvent {
  return {
    ...data,
    meetingContacts: data["meetingContacts"] !== undefined ? data["meetingContacts"].map((item: any) => (serializeAssistantApiCoreTypesCalendarEventMeetingContact(item))) : undefined,
  };
}

function deserializeAssistantApiCoreTypesCalendarEvent(data: any): AssistantApiCoreTypesCalendarEvent {
  return {
    ...data,
    meetingContacts: data["meetingContacts"] !== undefined ? data["meetingContacts"].map((item: any) => (deserializeAssistantApiCoreTypesCalendarEventMeetingContact(item))) : undefined,
  };
}

/**
 * Next id: 8
 */
export interface AssistantApiCoreTypesCalendarEventAttendee {
  /**
   * Display name, present only if available.
   */
  displayName?: string;
  /**
   * Email address of the attendee (calendar), for regular events. For +Events,
   * this field is not populated, instead "id" is used.
   */
  email?: string;
  /**
   * Given (first) name, present only if available. This is used for generating
   * meeting titles as given name is preferred over display (full) name (ie:
   * "Jeff : Sundar" is better than "Jeff Dean : Sundar Pichai").
   */
  givenName?: string;
  /**
   * Profile ID of the principal, for +Events. For regular events, this field
   * is not populated, instead "email" is used.
   */
  id?: string;
  /**
   * Is this the organizer?
   */
  organizer?: boolean;
  /**
   * Attendees response status.
   */
  responseStatus?:  | "RESPONSE_STATUS_UNSPECIFIED" | "NEEDS_ACTION" | "DECLINED" | "TENTATIVE" | "ACCEPTED";
  /**
   * Is this the owner of this copy of the event?
   */
  self?: boolean;
}

/**
 * Next id: 10
 */
export interface AssistantApiCoreTypesCalendarEventMeetingContact {
  /**
   * ID that corresponds to in ConferenceData.conference_id in
   * calendar.common.ConferenceData proto. For Meet, this is the identifier used
   * to join a meeting via URL.
   */
  conferenceId?: string;
  dialInNumberClasses?:  | "NUMBER_CLASS_UNSPECIFIED" | "LOW_COST" | "HIGH_COST" | "LEGACY"[];
  /**
   * Default meeting phone number, for example: "tel:+1-475-777-1840"
   */
  phoneNumberUri?: string;
  /**
   * A PIN that the participant will need to input after dialing in the
   * conference.
   */
  pinNumber?: string;
  /**
   * Provider info for the meeting.
   */
  provider?: AssistantApiCoreTypesProvider;
  /**
   * The region code for the default meeting phone number
   */
  regionCode?: string;
  source?:  | "SOURCE_UNSPECIFIED" | "STRUCTURED_DATA" | "UNSTRUCTURED_DATA";
  /**
   * The universal meeting PIN number for phone numbers in all available
   * countries
   */
  universalPinNumber?: string;
  /**
   * URL that can be used to join the meeting.
   */
  url?: string;
}

function serializeAssistantApiCoreTypesCalendarEventMeetingContact(data: any): AssistantApiCoreTypesCalendarEventMeetingContact {
  return {
    ...data,
    provider: data["provider"] !== undefined ? serializeAssistantApiCoreTypesProvider(data["provider"]) : undefined,
  };
}

function deserializeAssistantApiCoreTypesCalendarEventMeetingContact(data: any): AssistantApiCoreTypesCalendarEventMeetingContact {
  return {
    ...data,
    provider: data["provider"] !== undefined ? deserializeAssistantApiCoreTypesProvider(data["provider"]) : undefined,
  };
}

/**
 * A room that is available for a potential meeting or has been booked for a
 * scheduled meeting. Next id: 4
 */
export interface AssistantApiCoreTypesCalendarEventRoom {
  /**
   * Room email that identifies the room and is used to book it.
   */
  email?: string;
  /**
   * Additional room details. Read-only, populated on request.
   */
  locationDetails?: AssistantApiCoreTypesCalendarEventRoomRoomLocationDetails;
  /**
   * Room name (ex: "MTV-PR55-5-A-Shadow 5K0 (13) GVC (No external guests)").
   */
  name?: string;
}

/**
 * Room location details. Read-only, populated on request. Next id: 8
 */
export interface AssistantApiCoreTypesCalendarEventRoomRoomLocationDetails {
  /**
   * Building where the room is (ex: "PR55").
   */
  building?: string;
  /**
   * City where the room is (ex: "MTV").
   */
  city?: string;
  /**
   * Floor where the room is (ex: "5").
   */
  floor?: string;
  /**
   * The latitude in degrees.
   */
  latitude?: number;
  /**
   * The longitude in degrees.
   */
  longitude?: number;
  /**
   * Section in the floor (ex: "A").
   */
  section?: string;
  /**
   * Room name (ex: "Shadow 5K0").
   */
  simpleName?: string;
}

/**
 * This empty type allows us to publish sensitive calendar events to
 * go/attentional-entities, while maintaining BUILD visibility protection for
 * their contents. The BUILD-visibility-protected extension to this message is
 * defined at
 * http://google3/assistant/verticals/calendar/proto/multi_account_calendar_event.proto
 * IMPORTANT: The definition of CalendarEventWrapper proto is being moved to
 * //assistant/api/core_types/governed/calendar_event_type.proto. All existing
 * references will be updated to point to the new location. If you are adding a
 * reference, use the new one instead.
 */
export interface AssistantApiCoreTypesCalendarEventWrapper {
}

/**
 * The cast app information of the provider.
 */
export interface AssistantApiCoreTypesCastAppInfo {
  /**
   * The cast app id. |cast_app_id| is the ID of the cast app used on the
   * current device and |content_app_id| is the ID of the app that provides the
   * actual content. For example, in a group playback, on a follower device, the
   * |cast_app_id| is the follower cast app ID and the |content_app_id| is the
   * leader cast app ID.
   */
  castAppId?: string;
  /**
   * The id of the cast app that provides the content in a group. The field
   * will always be filled. In the case of a group playback and the current
   * device is a follower, the |cast_app_id| has the ID of the follower app, and
   * |content_app_id| has ID of the actual content app. In all other cases,
   * |content_app_id| and |cast_app_id| will be the same.
   */
  contentAppId?: string;
}

/**
 * The ChromeOS app information of the provider. Next ID: 3
 */
export interface AssistantApiCoreTypesChromeOsAppInfo {
  /**
   * The localized app name.
   */
  localizedAppName?: string;
  /**
   * Unique package name that identifies a ChromeOS app of the provider.
   */
  packageName?: string;
}

/**
 * The third party provider information.
 */
export interface AssistantApiCoreTypesCloudProviderInfo {
  agentStyle?: AssistantApiCoreTypesCloudProviderInfoAgentStyle;
  /**
   * URL to a directory page about the third party agent in Assistant HQ. This
   * is a universal (https) URL that may be handled natively by clients to show
   * HQ or launch to the HQ directory web page.
   */
  directoryUrl?: string;
  /**
   * The logo url for the third party provider.
   */
  logoUrl?: string;
  /**
   * The user visible name of the cloud provider, which may be used for example
   * in the chat header during a conversation with the third party.
   */
  name?: string;
}

/**
 * The style customizations for the 3p agent.
 */
export interface AssistantApiCoreTypesCloudProviderInfoAgentStyle {
  /**
   * The background color of the agent. Used if no background image is
   * specified for the given display orientation, or if the provided background
   * image does not fit.
   */
  backgroundColor?: AssistantApiCoreTypesGovernedColor;
  headerTheme?:  | "DEFAULT" | "DARK" | "LIGHT";
  /**
   * URL for the background image of the agent on landscape display.
   */
  landscapeBackgroundImageUrl?: string;
  /**
   * URL for the image containing the 3p logo. This can include logomark and
   * logotype, or logotype only. If present, this can be used in place of the
   * square logo contained in the top level logo_url field in CloudProviderInfo.
   * See go/cards-logo-customization for details on applying this logo.
   */
  logoUrl?: string;
  /**
   * The color of the mask to apply to the background. See
   * go/aog-cards-background-mask for details on applying this mask.
   */
  maskColor?: AssistantApiCoreTypesGovernedColor;
  /**
   * URL for the background image of the agent on portrait display.
   */
  portraitBackgroundImageUrl?: string;
  /**
   * The primary color of the agent. Used by the client to style the header and
   * suggestion chips.
   */
  primaryColor?: AssistantApiCoreTypesGovernedColor;
}

/**
 * The identification information for third party devices that integrates with
 * the assistant. All of these fields will be populated by the third party when
 * the query is sent from the third party device. Next Id: 5
 */
export interface AssistantApiCoreTypesDeviceConfig {
  /**
   * Pantheon Project ID that uniquely identifies the consumer project ID.
   * Required
   */
  agentId?: string;
  /**
   * Unique identifier for the device. Example: DBCDW098234. Required
   */
  deviceId?: string;
}

/**
 * LINT.IfChange(DeviceId) Specifies identifier of a device AKA surface. Note
 * there may be multiple device ids for the same physical device E.g. Allo app
 * and Assistant app on Nexus. Note: DeviceId usage is complicated. Please do
 * not depend on it for surface specific logic. Please use
 * google3/assistant/api/capabilities.proto instead. IMPORTANT: When checking
 * for equality between two `DeviceId`s, you should always use an
 * `isSameDevice{As}` function to check for equality, as deep equality between
 * `DeviceId`'s is not guaranteed. * C++:
 * http://google3/assistant/assistant_server/util/device_id_util.cc;l=23;rcl=421295740
 * * Dart:
 * http://google3/assistant/context/util/lib/device_id.dart;l=26;rcl=442126145 *
 * Java:
 * http://google3/java/com/google/assistant/assistantserver/utils/DeviceIdHelper.java;l=9;rcl=390378522
 * See http://go/deviceid-equality for more details. Next ID: 14
 */
export interface AssistantApiCoreTypesDeviceId {
  /**
   * The client_instance_id on devices with GSA. See 'client_instance_field' in
   * go/androidids.
   */
  agsaClientInstanceId?: string;
  /**
   * Allo Id. Corresponds to the GBotRequest.Sender.sender. NOTE(dychen): This
   * may change to standard android/ios physical device ids in order to enable
   * shared data (e.g. installed app on physical device shared between Allo and
   * Opa apps on Nexus).
   */
  alloDeviceId?: string;
  /**
   * A unique device ID for Assistant devices as proposed by go/ocelot-team to
   * solve the device id fragmentation problem. The value of this id is the
   * HomeGraph id of the device. See go/ocelot-track-0-registry-design. New
   * surfaces should use the canonical_device_id instead of using other ids, and
   * the registration should utilize the DeviceDataLayer (go/ddl-v0). Please
   * contact the assistant-state-management@ team for guidance. Note: We didn't
   * reuse |home_graph_device_id| because in Assistant code base
   * |home_graph_device_id| is common to associate it with 3P devices. See
   * go/project-yellowstone for more context.
   */
  canonicalDeviceId?: string;
  /**
   * If set, indicates that the device is a cast device, and contains the UUID
   * of the cast device. Corresponds to the device_id field of the CastDevice
   * proto.
   */
  castDeviceId?: string;
  /**
   * DUSI (go/dusi) is used as the identifier here. This identifier is unique
   * to the user and device. This will help identify which device or application
   * the user's request originated from. This is not to be confused with the
   * client_instance_id that android devices provide. This is currently used by
   * surfaces that use the assistant-legacy-nexus and assistant-legacy-clockwork
   * pipelines. DUSI is created and set in S3. This field is only filled for
   * GAIA requests.
   */
  clientInstanceId?: string;
  /**
   * A device ID produced by a connected dock, which is registered in
   * HomeGraph.
   */
  connectedDockId?: string;
  /**
   * The unique DeviceConfig to the specific third party device. It is also
   * used by Android Auto Embedded first party device. See go/opa-ids.
   */
  deviceConfig?: AssistantApiCoreTypesDeviceConfig;
  /**
   * The device's surface type. This is the string version of surface_type. The
   * server should use the SurfaceType value derived from this string. If the
   * device_type isn't supported within the SurfaceType enum, it will be set as
   * UNKNOWN. Developers should use the enum in ServerParams instead of this
   * string.
   */
  deviceType?: string;
  /**
   * The unique device ID for HomeGraph devices. This is the HomeGraph ID,
   * created when the device is registered into HomeGraph. It is immutable for
   * the same device unless it is completely deleted and recreated. See
   * go/home-graph for details.
   */
  homeGraphDeviceId?: string;
  /**
   * The unique ID for libassistant based devices. See go/libassistant-id for
   * details.
   */
  libassistantDeviceId?: string;
  /**
   * If set, indicates that the device is participating the multi-hotword
   * arbitration and the id is an UUID to distinguish it from other devices. It
   * should also be consistent between requests from a single device within a
   * session (or short duration).
   */
  multiHotwordArbitrationDeviceId?: string;
  /**
   * The unique device ID for the Assistant App on iOS. See go/opa-ios-design
   * for details.
   */
  opaIosDeviceId?: string;
  /**
   * The unique ID of a Quartz device. See go/quartz-design-doc for more
   * details. Quartz ID is a hash of (android_id + gaia).
   */
  quartzDeviceId?: string;
}

/**
 * IMPORTANT: The definition of DeviceUserIdentity is being moved to
 * //assistant/api/core_types/governed/device_user_identity.proto. All existing
 * references will be updated to point to the new location. If you are adding a
 * reference, use the new DeviceUserIdentity instead of this one. //
 * LINT.IfChange
 */
export interface AssistantApiCoreTypesDeviceUserIdentity {
  /**
   * The identifier of the device.
   */
  deviceId?: AssistantApiCoreTypesDeviceId;
  /**
   * The identifier of the user.
   */
  gaiaId?: bigint;
}

function serializeAssistantApiCoreTypesDeviceUserIdentity(data: any): AssistantApiCoreTypesDeviceUserIdentity {
  return {
    ...data,
    gaiaId: data["gaiaId"] !== undefined ? String(data["gaiaId"]) : undefined,
  };
}

function deserializeAssistantApiCoreTypesDeviceUserIdentity(data: any): AssistantApiCoreTypesDeviceUserIdentity {
  return {
    ...data,
    gaiaId: data["gaiaId"] !== undefined ? BigInt(data["gaiaId"]) : undefined,
  };
}

/**
 * Represents a color in the RGBA color space. This message mirrors
 * google.type.Color.
 */
export interface AssistantApiCoreTypesGovernedColor {
  /**
   * The fraction of this color that should be applied to the pixel. That is,
   * the final pixel color is defined by the equation: pixel color = alpha *
   * (this color) + (1.0 - alpha) * (background color) This means that a value
   * of 1.0 corresponds to a solid color, whereas a value of 0.0 corresponds to
   * a completely transparent color. If omitted, this color object is to be
   * rendered as a solid color (as if the alpha value had been explicitly given
   * with a value of 1.0).
   */
  alpha?: number;
  /**
   * The amount of blue in the color as a value in the interval [0, 1].
   */
  blue?: number;
  /**
   * The amount of green in the color as a value in the interval [0, 1].
   */
  green?: number;
  /**
   * The amount of red in the color as a value in the interval [0, 1].
   */
  red?: number;
}

/**
 * Task metadata information describing the ringtone. Next id: 11
 */
export interface AssistantApiCoreTypesGovernedRingtoneTaskMetadata {
  /**
   * The category related with the ringtone. It's used to generate ringtone
   * related with the category if the entity_mid is not be populated. E.g. for
   * instrument, the ringtone may be piano sound.
   */
  category?:  | "UNKNOWN_CATEGORY" | "ANIMAL" | "CHARACTER" | "EMOTION" | "INSTRUMENT" | "MEDIA" | "SPORTS_EQUIPMENT" | "VEHICLE" | "ON_DEVICE" | "FUNTIME";
  characterAlarmMetadata?: AssistantApiCoreTypesGovernedRingtoneTaskMetadataCharacterAlarmMetadata;
  characterTag?: string;
  /**
   * The freebase mid of the entity related to the ringtone. It will be used to
   * generate the ringtone for the alarm or timer (with support for i18n). For
   * instance, for the "cat" mid, the related ringtone will be a cat sound in
   * some language, and for the "Beyonce" mid, the ringtone will be, e.g., a
   * playlist of Beyonce's best hits.
   */
  entityMid?: string;
  funtimeMetadata?: AssistantApiCoreTypesGovernedRingtoneTaskMetadataFuntimeMetadata;
  genMlAlarmMetadata?: AssistantApiCoreTypesGovernedRingtoneTaskMetadataGenMlAlarmMetadata;
  /**
   * Gentle wake information for this alarm.
   */
  gentleWakeInfo?: AssistantApiCoreTypesGovernedRingtoneTaskMetadataGentleWakeInfo;
  onDeviceAlarmMetadata?: AssistantApiCoreTypesGovernedRingtoneTaskMetadataOnDeviceAlarmMetadata;
  /**
   * Will be deprecated. Use OnDeviceAlarmMetadata.
   */
  onDeviceAlarmSound?:  | "DEFAULT" | "MELLOW" | "MODERN_TIMES" | "BEAUTIFUL_MIND" | "LITTLE_SUNSHINE" | "TOUCH_OF_ZEN" | "ABOUT_TIME" | "RANDOM" | "BOROBUDUR" | "PEBBLES" | "BRIGHT_MORNING" | "ACROSS_THE_VALLEY" | "MORNING_SONG" | "KYOTO" | "AWAKEN" | "CUCKOO" | "DIGITAL_BLAST" | "ACOUSTIC_SUNLIGHT" | "SUNRISE_BOSSA" | "CALM_GLOW" | "ANTIQUE_CLOCK" | "JUST_BIRDS" | "JUNGLE_AMBIENCE" | "QUAINT_VILLAGE" | "BUBBLY_BOSSA" | "ACOUSTIC_JAM" | "EUPHORIC";
  routineAlarmMetadata?: AssistantApiCoreTypesGovernedRingtoneTaskMetadataRoutineAlarmMetadata;
}

function serializeAssistantApiCoreTypesGovernedRingtoneTaskMetadata(data: any): AssistantApiCoreTypesGovernedRingtoneTaskMetadata {
  return {
    ...data,
    funtimeMetadata: data["funtimeMetadata"] !== undefined ? serializeAssistantApiCoreTypesGovernedRingtoneTaskMetadataFuntimeMetadata(data["funtimeMetadata"]) : undefined,
    gentleWakeInfo: data["gentleWakeInfo"] !== undefined ? serializeAssistantApiCoreTypesGovernedRingtoneTaskMetadataGentleWakeInfo(data["gentleWakeInfo"]) : undefined,
    onDeviceAlarmMetadata: data["onDeviceAlarmMetadata"] !== undefined ? serializeAssistantApiCoreTypesGovernedRingtoneTaskMetadataOnDeviceAlarmMetadata(data["onDeviceAlarmMetadata"]) : undefined,
  };
}

function deserializeAssistantApiCoreTypesGovernedRingtoneTaskMetadata(data: any): AssistantApiCoreTypesGovernedRingtoneTaskMetadata {
  return {
    ...data,
    funtimeMetadata: data["funtimeMetadata"] !== undefined ? deserializeAssistantApiCoreTypesGovernedRingtoneTaskMetadataFuntimeMetadata(data["funtimeMetadata"]) : undefined,
    gentleWakeInfo: data["gentleWakeInfo"] !== undefined ? deserializeAssistantApiCoreTypesGovernedRingtoneTaskMetadataGentleWakeInfo(data["gentleWakeInfo"]) : undefined,
    onDeviceAlarmMetadata: data["onDeviceAlarmMetadata"] !== undefined ? deserializeAssistantApiCoreTypesGovernedRingtoneTaskMetadataOnDeviceAlarmMetadata(data["onDeviceAlarmMetadata"]) : undefined,
  };
}

export interface AssistantApiCoreTypesGovernedRingtoneTaskMetadataCharacterAlarmMetadata {
  /**
   * For character alarm, the media resources are provided through AOG apps.
   * During alarm trigger phase, aog apps with the specified agent_ids are used
   * to get the media resources. Multiple "AoG agents" can satisfy a
   * character_tag. So the user will select the agents they want at alarm
   * creation time. The chosen agents will be recorded so that the resources
   * only from those agents will be used at trigger time. The number of selected
   * agent_ids will not exceed 3. See go/character-alarm-aog.
   */
  agentIds?: string[];
  /**
   * The Character Alarm tag. Tags are needed to identify the theme of the
   * alarm. For example, if the tag is 'astronaut', astronaut based audio is
   * played during alarm ring. Note : We have made it repeated so that the user
   * can choose multiple character alarm themes at one go. At present, the user
   * is allowed to choose only one theme during alarm creation.
   */
  characterTags?: string[];
  /**
   * Icons urls corresponding to a character. Note : We have made it repeated
   * so that we can show different images when the alarm rings. At present, we
   * only support only one image.
   */
  iconUrls?: string[];
}

/**
 * Used to make timers and alarms more delightful. See go/funtime-engdesign for
 * more details.
 */
export interface AssistantApiCoreTypesGovernedRingtoneTaskMetadataFuntimeMetadata {
  /**
   * For FunTime alarms and timers, the media resources are provided through
   * AOG apps during their ringtone. Multiple AoG agents can satisfy a label. So
   * a random agent will be chosen from those that are supplied. See
   * go/funtime-engdesign.
   */
  agentIds?: string[];
  /**
   * These bytes may represent the blob of the Rive animation that we pass to
   * the Opal App. We will deprecate this field if we figure out a solution to
   * load the animation from the web.
   */
  animationBlob?: Uint8Array;
  /**
   * Url for Rive animation that is brought up on ring. Rive is a lightweight
   * animation library that is compatible with Flutter on Opal. See
   * https://rive.app/.
   */
  animationUrl?: string;
  /**
   * The url used to load the image that is at the center of the timer during
   * timer countdown visuals.
   */
  timerHeroUrl?: string;
  /**
   * This is used to call S3 to realize the TTS. Is in the form of bytes
   * because of a circular dependency issue in libassistant protos. It is a
   * serialized proto of type speech.s3.TtsServiceRequest.
   */
  ttsServiceRequestBytes?: Uint8Array;
}

function serializeAssistantApiCoreTypesGovernedRingtoneTaskMetadataFuntimeMetadata(data: any): AssistantApiCoreTypesGovernedRingtoneTaskMetadataFuntimeMetadata {
  return {
    ...data,
    animationBlob: data["animationBlob"] !== undefined ? encodeBase64(data["animationBlob"]) : undefined,
    ttsServiceRequestBytes: data["ttsServiceRequestBytes"] !== undefined ? encodeBase64(data["ttsServiceRequestBytes"]) : undefined,
  };
}

function deserializeAssistantApiCoreTypesGovernedRingtoneTaskMetadataFuntimeMetadata(data: any): AssistantApiCoreTypesGovernedRingtoneTaskMetadataFuntimeMetadata {
  return {
    ...data,
    animationBlob: data["animationBlob"] !== undefined ? decodeBase64(data["animationBlob"] as string) : undefined,
    ttsServiceRequestBytes: data["ttsServiceRequestBytes"] !== undefined ? decodeBase64(data["ttsServiceRequestBytes"] as string) : undefined,
  };
}

/**
 * Metadata for machine learning generated audio samples. This will be similar
 * to character alarms, Category will be set MEDIA but this metadata field will
 * be used to identify the ringtone type on surface.
 * (go/magenta-alarm-ringtones).
 */
export interface AssistantApiCoreTypesGovernedRingtoneTaskMetadataGenMlAlarmMetadata {
  isEnabled?: boolean;
  /**
   * Label for the generated ringtone.
   */
  ringtoneLabel?: string;
}

/**
 * Gentle wake actions like slowly brightening the room/device screen leading
 * up to the alarm firing (go/cube-gentle-wake-up).
 */
export interface AssistantApiCoreTypesGovernedRingtoneTaskMetadataGentleWakeInfo {
  /**
   * Specifies how long the effect lasts. Allowed for effect to last after the
   * alarm has started ringing. If unset or negative or 0, effect is assumed to
   * last until alarm trigger time.
   */
  effectDurationMs?: bigint;
  /**
   * Indicates if gentle wake action is to be performed before this alarm
   * fires. This is enabled only if the device supports sunrise alarm
   * capability. http://cs/symbol:assistant.api.SunriseFeaturesSupport
   */
  isEnabled?: boolean;
  /**
   * Specifies how long before the alarm fire time, the wakeup effect will
   * start. ALWAYS POSITIVE.
   */
  startTimedeltaMs?: bigint;
}

function serializeAssistantApiCoreTypesGovernedRingtoneTaskMetadataGentleWakeInfo(data: any): AssistantApiCoreTypesGovernedRingtoneTaskMetadataGentleWakeInfo {
  return {
    ...data,
    effectDurationMs: data["effectDurationMs"] !== undefined ? String(data["effectDurationMs"]) : undefined,
    startTimedeltaMs: data["startTimedeltaMs"] !== undefined ? String(data["startTimedeltaMs"]) : undefined,
  };
}

function deserializeAssistantApiCoreTypesGovernedRingtoneTaskMetadataGentleWakeInfo(data: any): AssistantApiCoreTypesGovernedRingtoneTaskMetadataGentleWakeInfo {
  return {
    ...data,
    effectDurationMs: data["effectDurationMs"] !== undefined ? BigInt(data["effectDurationMs"]) : undefined,
    startTimedeltaMs: data["startTimedeltaMs"] !== undefined ? BigInt(data["startTimedeltaMs"]) : undefined,
  };
}

/**
 * This describes the alarm sound resource enum and the alarm sound label for
 * the on device alarm sound. On-device ringtones are product specific, hence
 * Opal/UI layer will be responsible for populating this metadata at
 * creation/edit. The enum map will be used to convert to an internal resource
 * id used by libassistant for accessing the asset which are not exposed to UI.
 */
export interface AssistantApiCoreTypesGovernedRingtoneTaskMetadataOnDeviceAlarmMetadata {
  /**
   * Opal/UI layer will set this bit based on the user selection.
   */
  onDeviceAlarmSound?:  | "DEFAULT" | "MELLOW" | "MODERN_TIMES" | "BEAUTIFUL_MIND" | "LITTLE_SUNSHINE" | "TOUCH_OF_ZEN" | "ABOUT_TIME" | "RANDOM" | "BOROBUDUR" | "PEBBLES" | "BRIGHT_MORNING" | "ACROSS_THE_VALLEY" | "MORNING_SONG" | "KYOTO" | "AWAKEN" | "CUCKOO" | "DIGITAL_BLAST" | "ACOUSTIC_SUNLIGHT" | "SUNRISE_BOSSA" | "CALM_GLOW" | "ANTIQUE_CLOCK" | "JUST_BIRDS" | "JUNGLE_AMBIENCE" | "QUAINT_VILLAGE" | "BUBBLY_BOSSA" | "ACOUSTIC_JAM" | "EUPHORIC";
  /**
   * A string label to identify the alarm sound name. Opal/UI layer will set
   * this as per product definition. This will be used to display the name of
   * the selected ringtone.
   */
  onDeviceAlarmSoundLabel?: string;
  /**
   * This is used to call S3 to realize the TTS. Is in the form of bytes
   * because of a circular dependency issue in libassistant protos. It is a
   * serialized proto of type speech.s3.TtsServiceRequest. This request will
   * contain an ssml with the url to the ringtone files hosted on gstatic.
   */
  ttsServiceRequestBytes?: Uint8Array;
}

function serializeAssistantApiCoreTypesGovernedRingtoneTaskMetadataOnDeviceAlarmMetadata(data: any): AssistantApiCoreTypesGovernedRingtoneTaskMetadataOnDeviceAlarmMetadata {
  return {
    ...data,
    ttsServiceRequestBytes: data["ttsServiceRequestBytes"] !== undefined ? encodeBase64(data["ttsServiceRequestBytes"]) : undefined,
  };
}

function deserializeAssistantApiCoreTypesGovernedRingtoneTaskMetadataOnDeviceAlarmMetadata(data: any): AssistantApiCoreTypesGovernedRingtoneTaskMetadataOnDeviceAlarmMetadata {
  return {
    ...data,
    ttsServiceRequestBytes: data["ttsServiceRequestBytes"] !== undefined ? decodeBase64(data["ttsServiceRequestBytes"] as string) : undefined,
  };
}

export interface AssistantApiCoreTypesGovernedRingtoneTaskMetadataRoutineAlarmMetadata {
  /**
   * The unique id for each routine. When the alrm is dismissed, it will
   * trigger the routine of the routine alarm's creator if feasible.
   */
  routineId?: string;
}

/**
 * The Home app information of the provider. Next ID: 3
 */
export interface AssistantApiCoreTypesHomeAppInfo {
  /**
   * The localized app name.
   */
  localizedAppName?: string;
  /**
   * Unique package name that identifies a Home app of the provider.
   */
  packageName?: string;
}

/**
 * An image represents the data about an image or a photo. IMPORTANT: The
 * definition of the Image message is being moved to
 * //assistant/api/core_types/governed/image_type.proto. All existing references
 * will be updated to point to the new location. If you are adding a reference,
 * use the new Image message instead of this one. LINT.IfChange NextId: 13
 */
export interface AssistantApiCoreTypesImage {
  /**
   * A text description of the image to be used for accessibility, e.g. screen
   * readers.
   */
  accessibilityText?: string;
  /**
   * App identifier. This field is specific to mobile surfaces and stands for
   * app package name for Android surface, and app bundle identifier for iOS. In
   * case identifier is specified but invalid, some default icon will be used,
   * e.g. PackageManager.getDefaultActivityIcon() for Android. If you want to
   * show image for AGSA versions which don't support this field, you can
   * specify source_url as backup.
   */
  appIconIdentifier?: string;
  /**
   * This is the image that is displayed as the badge on the main image.
   */
  badgeImage?: AssistantApiCoreTypesImage;
  /**
   * Content of the image in bytes.
   */
  content?: Uint8Array;
  height?: number;
  /**
   * Indicate the data source where the image is fetched.
   */
  imageSource?:  | "UNKNOWN" | "PLACEHOLDER" | "VISUAL_DICT" | "LAVD" | "VISUAL_DICT_DEFAULT_LOCALE";
  /**
   * Content of image in form of JSON representation.
   */
  jsonContent?: string;
  /**
   * Text used to generate a letter drawable (a letter icon with color). It
   * will be the default icon if the source_url is empty or cannot be rendered.
   */
  letterDrawableText?: string;
  /**
   * Url of the image provider, which is the website containing the image. For
   * example, https://www.agentx.com.
   */
  providerUrl?: string;
  /**
   * The source url of the image. For example, https://www.agentx.com/logo.png
   */
  sourceUrl?: string;
  /**
   * Type of the source url.
   */
  sourceUrlType?:  | "DEFAULT_URL_TYPE" | "LOTTIE" | "DUO_CLIENT" | "CONTACT_ID";
  /**
   * The width and height of the image in pixels.
   */
  width?: number;
}

function serializeAssistantApiCoreTypesImage(data: any): AssistantApiCoreTypesImage {
  return {
    ...data,
    badgeImage: data["badgeImage"] !== undefined ? serializeAssistantApiCoreTypesImage(data["badgeImage"]) : undefined,
    content: data["content"] !== undefined ? encodeBase64(data["content"]) : undefined,
  };
}

function deserializeAssistantApiCoreTypesImage(data: any): AssistantApiCoreTypesImage {
  return {
    ...data,
    badgeImage: data["badgeImage"] !== undefined ? deserializeAssistantApiCoreTypesImage(data["badgeImage"]) : undefined,
    content: data["content"] !== undefined ? decodeBase64(data["content"] as string) : undefined,
  };
}

/**
 * Info for targeting a feature provided directly by the Assistant surface
 * itself. i.e Could be pointing to AGSA audio player for AUDIO_PLAYER on AGSA.
 */
export interface AssistantApiCoreTypesInternalProviderInfo {
  /**
   * Specifying which type of internal provider.
   */
  type?:  | "UNKNOWN_INTERNAL_PROVIDER_TYPE" | "AUDIO_PLAYER" | "AUDIO_PLAYER_V2" | "MEDIA_PLAYER" | "MEDIA_PLAYER_IOS" | "AUDIO_ONLY_PLAYER" | "NARRATED_WEB_MEDIA_PLAYER" | "LIBASSISTANT_MEDIA_PLAYER" | "LENS_PLAYER" | "NEWS_PLAYER";
}

/**
 * The iOS app information of the provider. Next ID: 4
 */
export interface AssistantApiCoreTypesIosAppInfo {
  /**
   * Bundle identifier that identifies an iOS app of the provider.
   */
  bundleIdentifier?: string;
  /**
   * The localized app name.
   */
  localizedAppName?: string;
  /**
   * A URL to open the provider's app.
   */
  openAppUrl?: string;
}

/**
 * The KaiOS app information of the provider. Next ID: 4
 */
export interface AssistantApiCoreTypesKaiOsAppInfo {
  /**
   * The localized app name.
   */
  localizedAppName?: string;
  /**
   * A URL to open the provider's app.
   */
  openAppUrl?: string;
  /**
   * Unique package name that identifies a KaiOS app of the provider.
   */
  packageName?: string;
}

/**
 * Geographic coordinate information for location.
 */
export interface AssistantApiCoreTypesLocationCoordinates {
  /**
   * The accuracy of the coordinates in meters.
   */
  accuracyMeters?: number;
  /**
   * Latitude degrees.
   */
  latDegrees?: number;
  /**
   * Longitude degrees.
   */
  lngDegrees?: number;
}

/**
 * This proto captures the contents of a messaging app notification that is
 * typically part of a conversation thread. Next Id: 20
 */
export interface AssistantApiCoreTypesMessageNotification {
  /**
   * App name of the message notification, e.g. Hangouts.
   */
  appName?: string;
  /**
   * The key used to group this notification into a cluster.
   */
  bundleId?: string;
  /**
   * Uri for the attachment (image, audio, video etc.).
   */
  dataUri?: string;
  /**
   * The group key of a proactive notification. Details in
   * assistant.api.client_op.NotificationArgs.grouping_key.
   */
  groupingKey?: string;
  /**
   * Name of the group associated with the message notification. This field is
   * set iff this is a group message.
   */
  groupName?: string;
  /**
   * Index of the message notification.
   */
  index?: number;
  /**
   * Boolean indicating if the mark_as_read action is available for this
   * message.
   */
  markAsReadActionAvailable?: boolean;
  /**
   * Length of the message/notification content in characters. Note: We can't
   * send the full content because of privacy restriction, preventing sending
   * client content to our backends. Concatenated message_length of all
   * notification_entries.
   */
  messageLength?: number;
  messageRecipientType?:  | "UNKNOWN" | "INDIVIDUAL" | "GROUP";
  /**
   * Mime type of the data_uri. e.g. 'audio/wav', 'video/mp4', 'image/png'.
   */
  mimeType?: string;
  notificationEntries?: AssistantApiCoreTypesMessageNotificationNotificationEntry[];
  /**
   * On-device cache key for notification icon.
   */
  notificationIconKey?: string;
  /**
   * String key of the notification. It is the key from original
   * StatusBarNotification received from Android OS. It is used to identify the
   * original notification to send a reply.
   */
  notificationKey?: string;
  /**
   * The opaque_token of a proactive notification. Details in
   * assistant.api.client_op.NotificationArgs.opaque_token.
   */
  opaqueToken?: Uint8Array;
  /**
   * App pkg of the message notification, e.g. "com.google.android.talk".
   */
  packageName?: string;
  /**
   * Timestamp of the last notification's post time.
   */
  postTime?: bigint;
  /**
   * Boolean indicating if the reply action is available for this message.
   */
  replyActionAvailable?: boolean;
  sender?: AssistantApiCoreTypesMessageNotificationPerson;
  /**
   * Sender's name of the message notification, e.g. Elsa. Last sender name in
   * case of a group conversation.
   */
  senderName?: string;
}

function serializeAssistantApiCoreTypesMessageNotification(data: any): AssistantApiCoreTypesMessageNotification {
  return {
    ...data,
    notificationEntries: data["notificationEntries"] !== undefined ? data["notificationEntries"].map((item: any) => (serializeAssistantApiCoreTypesMessageNotificationNotificationEntry(item))) : undefined,
    opaqueToken: data["opaqueToken"] !== undefined ? encodeBase64(data["opaqueToken"]) : undefined,
    postTime: data["postTime"] !== undefined ? String(data["postTime"]) : undefined,
  };
}

function deserializeAssistantApiCoreTypesMessageNotification(data: any): AssistantApiCoreTypesMessageNotification {
  return {
    ...data,
    notificationEntries: data["notificationEntries"] !== undefined ? data["notificationEntries"].map((item: any) => (deserializeAssistantApiCoreTypesMessageNotificationNotificationEntry(item))) : undefined,
    opaqueToken: data["opaqueToken"] !== undefined ? decodeBase64(data["opaqueToken"] as string) : undefined,
    postTime: data["postTime"] !== undefined ? BigInt(data["postTime"]) : undefined,
  };
}

/**
 * Structure of each notification in the MessageNotification Bundle. Attribute
 * sender_name could be different in case of group messages. Next Id: 6
 */
export interface AssistantApiCoreTypesMessageNotificationNotificationEntry {
  /**
   * Uri for the attachment (image, audio, video etc.).
   */
  dataUri?: string;
  /**
   * Content of the message body in the notification.
   */
  messageBody?: string;
  /**
   * Mime type of the data_uri. e.g. 'audio/wav', 'video/mp4', 'image/png'.
   */
  mimeType?: string;
  /**
   * Timestamp of the notification's post time.
   */
  postTime?: Date;
  /**
   * Sender of the message notification.
   */
  sender?: AssistantApiCoreTypesMessageNotificationPerson;
}

function serializeAssistantApiCoreTypesMessageNotificationNotificationEntry(data: any): AssistantApiCoreTypesMessageNotificationNotificationEntry {
  return {
    ...data,
    postTime: data["postTime"] !== undefined ? data["postTime"].toISOString() : undefined,
  };
}

function deserializeAssistantApiCoreTypesMessageNotificationNotificationEntry(data: any): AssistantApiCoreTypesMessageNotificationNotificationEntry {
  return {
    ...data,
    postTime: data["postTime"] !== undefined ? new Date(data["postTime"]) : undefined,
  };
}

/**
 * Mirrors part of https://developer.android.com/reference/android/app/Person
 * Next Id: 4
 */
export interface AssistantApiCoreTypesMessageNotificationPerson {
  isImportant?: boolean;
  key?: string;
  name?: string;
}

/**
 * Provider. Like, Spotify or iHeartRadio. Next ID: 13
 */
export interface AssistantApiCoreTypesProvider {
  /**
   * The android app information of the provider.
   */
  androidAppInfo?: AssistantApiCoreTypesAndroidAppInfo;
  /**
   * The cast app information of the provider.
   */
  castAppInfo?: AssistantApiCoreTypesCastAppInfo;
  /**
   * The ChromeOS app information of the provider.
   */
  chromeosAppInfo?: AssistantApiCoreTypesChromeOsAppInfo;
  /**
   * The third party provider information.
   */
  cloudProviderInfo?: AssistantApiCoreTypesCloudProviderInfo;
  /**
   * A URL to fallback to if app can not be opened.
   */
  fallbackUrl?: string;
  homeAppInfo?: AssistantApiCoreTypesHomeAppInfo;
  /**
   * Public URL pointing to an icon image for the provider. e.g.
   * https://lh3.googleusercontent.com/UrY7BAZ-XfXGpfkeWg0zCCeo-7ras4DCoRalC_WXXWTK9q5b0Iw7B0YQMsVxZaNB7DM
   */
  iconImageUrl?: string;
  /**
   * The internal assistant provider information.
   */
  internalProviderInfo?: AssistantApiCoreTypesInternalProviderInfo;
  /**
   * The iOS app information of the provider.
   */
  iosAppInfo?: AssistantApiCoreTypesIosAppInfo;
  /**
   * The KaiOS app information of the provider.
   */
  kaiosAppInfo?: AssistantApiCoreTypesKaiOsAppInfo;
  /**
   * The sip information of the provider.
   */
  sipProviderInfo?: AssistantApiCoreTypesSipProviderInfo;
  /**
   * The web provider information.
   */
  webProviderInfo?: AssistantApiCoreTypesWebProviderInfo;
}

function serializeAssistantApiCoreTypesProvider(data: any): AssistantApiCoreTypesProvider {
  return {
    ...data,
    androidAppInfo: data["androidAppInfo"] !== undefined ? serializeAssistantApiCoreTypesAndroidAppInfo(data["androidAppInfo"]) : undefined,
    webProviderInfo: data["webProviderInfo"] !== undefined ? serializeAssistantApiCoreTypesWebProviderInfo(data["webProviderInfo"]) : undefined,
  };
}

function deserializeAssistantApiCoreTypesProvider(data: any): AssistantApiCoreTypesProvider {
  return {
    ...data,
    androidAppInfo: data["androidAppInfo"] !== undefined ? deserializeAssistantApiCoreTypesAndroidAppInfo(data["androidAppInfo"]) : undefined,
    webProviderInfo: data["webProviderInfo"] !== undefined ? deserializeAssistantApiCoreTypesWebProviderInfo(data["webProviderInfo"]) : undefined,
  };
}

/**
 * ProviderDelta. The incremental change, e.g. installation or deletion for
 * Spotify or iHeartRadio. Currently it is for Android only. A few
 * considerations for edge cases: - If the app being deleted is not found from
 * Footprints, it is ignored. - For Footprint upload through Geller, the gPRC
 * response is available for client to retry in the next upload if the upload
 * fails. - For Assistant Request, there is no upload status similar to the
 * current AppCapabilities. Next ID: 4
 */
export interface AssistantApiCoreTypesProviderDelta {
  /**
   * The android app information of the provider.
   */
  androidAppInfoDelta?: AssistantApiCoreTypesAndroidAppInfoDelta;
  /**
   * A URL to fallback to if app can not be opened.
   */
  fallbackUrl?: string;
  /**
   * Public URL pointing to an icon image for the provider. e.g.
   * https://lh3.googleusercontent.com/UrY7BAZ-XfXGpfkeWg0zCCeo-7ras4DCoRalC_WXXWTK9q5b0Iw7B0YQMsVxZaNB7DM
   */
  iconImageUrl?: string;
}

function serializeAssistantApiCoreTypesProviderDelta(data: any): AssistantApiCoreTypesProviderDelta {
  return {
    ...data,
    androidAppInfoDelta: data["androidAppInfoDelta"] !== undefined ? serializeAssistantApiCoreTypesAndroidAppInfoDelta(data["androidAppInfoDelta"]) : undefined,
  };
}

function deserializeAssistantApiCoreTypesProviderDelta(data: any): AssistantApiCoreTypesProviderDelta {
  return {
    ...data,
    androidAppInfoDelta: data["androidAppInfoDelta"] !== undefined ? deserializeAssistantApiCoreTypesAndroidAppInfoDelta(data["androidAppInfoDelta"]) : undefined,
  };
}

/**
 * Session Initiation Protocol (SIP) information for providers that use SIP to
 * initiate multimedia communication sessions, like Google Voice and Fi.
 * https://en.wikipedia.org/wiki/Session_Initiation_Protocol
 */
export interface AssistantApiCoreTypesSipProviderInfo {
  /**
   * The providers id (MID) which is the primary identifier for a call provider
   * within the Assistant. A MID, or machine identifier, is a unique identifier
   * issued by Knowledge Graph for all entities contained in it's graph.
   */
  providerId?: string;
  /**
   * Calling realm to be use for each call. i.e. For anonymous, this would be
   * set to anonymous.chirp.google.com
   */
  realm?: string;
  /**
   * If true, client should use the Birdsong TaCL API for this call. Uses the
   * VoiceCallManager API by default. For more details:
   * go/birdsong-migration-google-home
   */
  useBirdsongTacl?: boolean;
}

/**
 * The set of information that helps the server identify the surface. This
 * replaces the User-Agent string within the Assistant Server. Note: The
 * SurfaceIdentity proto should only be used to derive the capabilities of a
 * surface. It should not be accessed outside of the CapabilityBuilder or
 * CapabilityChecker. NEXT ID: 5 IMPORTANT: The definitions of the
 * SurfaceIdentity and SurfaceVersion protos are being moved to
 * //assistant/api/core_types/governed/surface_identity.proto All existing
 * references will be updated to point to the new location. If you are adding a
 * reference, use the new SurfaceIdentity and SurfaceVersion protos instead of
 * the protos defined here. LINT.IfChange
 */
export interface AssistantApiCoreTypesSurfaceIdentity {
  /**
   * The identifier of the device.
   */
  deviceId?: AssistantApiCoreTypesDeviceId;
  /**
   * The device's surface type. The types are defined at
   * google3/assistant/api/core_types/surfaces.gcl. NOTE: This is the new field
   * that is going to replace the `surface_type_string` field above. For more
   * details please refer to go/ontologicalize-surface-type.
   */
  surfaceType?:  | "UNKNOWN_TYPE" | "ACCL" | "AGSA" | "ANDROID" | "ANDROID_AUTO" | "ANDROID_LITE" | "ANDROID_PHONE" | "ANDROID_SCREENLESS" | "ANDROID_SMART_DISPLAY" | "ANDROID_TABLET" | "ANDROID_THINGS" | "ANDROID_THINGS_CUBE" | "ANDROID_THINGS_JASPER" | "ANDROID_TV" | "ANDROID_WEAR" | "ASSISTANT_KIT" | "ASSISTANT_SDK" | "AUTO" | "CAST_OS" | "CHROME_OS" | "CHROMECAST_MANHATTAN" | "CLOUD_DEVICE" | "CROS" | "FITBIT_OS_WATCH" | "FITBIT_OS_WATCH_ANDROID" | "FITBIT_OS_WATCH_IOS" | "GOOGLE_HOME" | "HEADPHONE" | "HEADPHONE_ANDROID" | "HEADPHONE_IOS" | "IOPA" | "IOS" | "IOS_SCREENLESS" | "IPAD" | "IPHONE" | "KAI_OS" | "KAI_OS_AMA" | "LIBASSISTANT" | "PHONE" | "PIXEL" | "PIXEL5" | "PIXEL6" | "PIXEL7" | "PIXEL_BUDS" | "PIXEL_TABLET" | "PIXEL_TABLET_HUB_MODE" | "PIXEL_TABLET_PERSONAL_MODE" | "PIXEL_WATCH" | "SCREENLESS" | "SMART_DISPLAY" | "SPEAKER" | "TABLET" | "TELEPHONE" | "THING" | "WATCH" | "WEAR_OS" | "WEAR_OS_WATCH";
  /**
   * The device's surface type. This is the string version of the
   * assistant.api.core_types.SurfaceType enum. The server should not use this
   * field, rather it should use the SurfaceType value derived from this string.
   */
  surfaceTypeString?: string;
  /**
   * The version of the surface/client. This is different from the Conversation
   * protocol version.
   */
  surfaceVersion?: AssistantApiCoreTypesSurfaceVersion;
}

/**
 * Specifies the types of device surfaces. LINT.IfChange When adding new
 * surface types make sure that My Activity
 * (https://myactivity.google.com/product/assistant) will correctly render by
 * adding your enum to http://cs/symbol:GetAssistSurfaceName%20f:%5C.cc$ If your
 * type doesn't fit in to any of the existing surfaces messages, add a new
 * message in
 * http://google3/personalization/footprints/boq/uservisible/events/intl/smh_frontend_messages.h.
 */
export interface AssistantApiCoreTypesSurfaceType {
  type?:  | "UNKNOWN" | "ANDROID_ALLO" | "ANDROID_AUTO" | "ANDROID_THINGS_CUBE" | "ANDROID_THINGS_JASPER" | "ANDROID_TV" | "ANDROID_TV_KIDS" | "ANDROID_WEAR" | "AR_GLASSES" | "ASSISTANT_SDK" | "AUDIOWEAR" | "BUBBLE_CHARACTERS_IOS" | "CAPABILITY_BASED_SURFACE" | "CHROMECAST_ASSISTANT" | "CHROMECAST_MANHATTAN" | "CHROMECAST_SEARCH" | "CLOUD_DEVICE" | "COMPANION_SCREEN" | "DYNAMITE_WEB" | "ENSEMBLE" | "EYESFREE_AGSA" | "EYESFREE_GMM" | "GBOARD" | "GLASS" | "GOOGLE_HOME" | "HANGOUTS_CHATBOT" | "IOS_ALLO" | "IOS_GSA" | "IOS_WEAR" | "LIBASSISTANT" | "LINE_CHATBOT" | "MULTIMODAL_AGSA" | "NON_ASSISTANT_SURFACE" | "OPA_AGSA" | "OPA_AGSA_CHROME_OS" | "OPA_ANDROID_AUTO" | "OPA_ANDROID_LITE" | "OPA_ANDROID_SCREENLESS" | "OPA_ANDROID_SMART_DISPLAY" | "OPA_ANDROID_TABLET" | "OPA_CROS" | "OPA_GACS" | "OPA_IOS" | "OPA_IOS_SCREENLESS" | "OPA_KAIOS" | "OPA_MOBILE_WEB" | "RTOS_PHONE" | "SMS_CHATBOT" | "TELEGRAM_CHATBOT" | "TELEPHONE_ASSISTANT" | "VERILY_ONDUO" | "YOUTUBE_APP" | "AGSA_BISTO_FOR_EVAL" | "COGSWORTH_FOR_EVAL" | "LOCKHART_MIC_FOR_EVAL" | "OPA_ANDROID_AUTO_EMBEDDED_FAKE" | "SPARK" | "WALLE" | "UNIT_TESTING";
}

/**
 * The version of the surface/client. New surfaces are encouraged to only use
 * the major field to keep track of version number. The minor field may be
 * used for surfaces that rely on both the major and minor fields to define
 * their version.
 */
export interface AssistantApiCoreTypesSurfaceVersion {
  major?: number;
  minor?: number;
}

/**
 * The web information of the provider. Next ID: 5
 */
export interface AssistantApiCoreTypesWebProviderInfo {
  /**
   * Serialized storage (context) persisted and retrieved for the app and home.
   */
  homeStorage?: string;
  /**
   * The localized app name.
   */
  localizedAppName?: string;
  /**
   * A URL to open the provider's app.
   */
  openAppUrl?: string;
  /**
   * Info about 3P Custom NLU used in this web provider. TODO(b/321644453)
   * remove when QRewrite is able to call SERoot.
   */
  thirdPartyCustomNluInfo?: AssistantApiCoreTypesWebProviderInfoThirdPartyCustomNluInfo;
}

function serializeAssistantApiCoreTypesWebProviderInfo(data: any): AssistantApiCoreTypesWebProviderInfo {
  return {
    ...data,
    thirdPartyCustomNluInfo: data["thirdPartyCustomNluInfo"] !== undefined ? serializeAssistantApiCoreTypesWebProviderInfoThirdPartyCustomNluInfo(data["thirdPartyCustomNluInfo"]) : undefined,
  };
}

function deserializeAssistantApiCoreTypesWebProviderInfo(data: any): AssistantApiCoreTypesWebProviderInfo {
  return {
    ...data,
    thirdPartyCustomNluInfo: data["thirdPartyCustomNluInfo"] !== undefined ? deserializeAssistantApiCoreTypesWebProviderInfoThirdPartyCustomNluInfo(data["thirdPartyCustomNluInfo"]) : undefined,
  };
}

export interface AssistantApiCoreTypesWebProviderInfoThirdPartyCustomNluInfo {
  /**
   * The locale of this agent version, represented by BCP-47 language strings,
   * such as "en", "en-US", "fr", "fr-CA", "sr-Latn", "zh-Hans-CN", etc.
   */
  locale?: string;
  /**
   * Unique internal identifier of 3P Custom NLU agent. UUID.
   */
  nluAgentId?: string;
  /**
   * Identifies the 3P Custom NLU agent version.
   */
  nluAgentVersion?: bigint;
}

function serializeAssistantApiCoreTypesWebProviderInfoThirdPartyCustomNluInfo(data: any): AssistantApiCoreTypesWebProviderInfoThirdPartyCustomNluInfo {
  return {
    ...data,
    nluAgentVersion: data["nluAgentVersion"] !== undefined ? String(data["nluAgentVersion"]) : undefined,
  };
}

function deserializeAssistantApiCoreTypesWebProviderInfoThirdPartyCustomNluInfo(data: any): AssistantApiCoreTypesWebProviderInfoThirdPartyCustomNluInfo {
  return {
    ...data,
    nluAgentVersion: data["nluAgentVersion"] !== undefined ? BigInt(data["nluAgentVersion"]) : undefined,
  };
}

export interface AssistantApiCrossDeviceExecutionCapability {
  /**
   * Whether the device has torus/usonia capabililities enabled or not.
   */
  localConnectivityEnabled?: boolean;
  /**
   * Whether the device supports cast media originated from a remote device to
   * be executed through local execution and can upload results asynchronously.
   * Needs to be checked before sending remote media initiation through local
   * channel since it needs an async result upload path.
   */
  remoteCastMediaEnabled?: boolean;
}

/**
 * A Gregorian calendar date. IMPORTANT: The definition of Date proto is being
 * moved to //assistant/api/core_types/governed/datetime_type.proto. All
 * existing references will be updated to point to the new location. If you are
 * adding a reference, use the new one instead.
 */
export interface AssistantApiDate {
  /**
   * The day, in 1...31.
   */
  day?: number;
  /**
   * The month, in 1...12.
   */
  month?: number;
  /**
   * The year, e.g. 2016.
   */
  year?: number;
}

/**
 * A date-time specification, combining a date and civil time (relative to a
 * given timezone). IMPORTANT: The definition of DateTime proto is being moved
 * to //assistant/api/core_types/governed/datetime_type.proto. All existing
 * references will be updated to point to the new location. If you are adding a
 * reference, use the new one instead.
 */
export interface AssistantApiDateTime {
  /**
   * A Gregorian calendar date.
   */
  date?: AssistantApiDate;
  /**
   * A civil time relative to a timezone.
   */
  timeOfDay?: AssistantApiTimeOfDay;
  /**
   * A time zone in IANA format.
   */
  timeZone?: AssistantApiTimeZone;
}

/**
 * This message describes roughly what a surface is capable of doing and
 * metadata around those capabilities. These capabilities are determined based
 * on: - device hardware - software - status (e.g. volume level, battery
 * percentage) These capabilities refer to the surface and not the physical
 * device. The list of supported surfaces can be found in the
 * assistant.api.core_types.SurfaceType enum. A surface's capabilities can
 * differ from the device's. An example would be ANDROID_ALLO running on Pixel.
 * Allo does not support AudioInput while the Pixel does. In this case,
 * audio_input will be set to false for Assistant Allo requests while it might
 * be set to true for OPA_NEXUS requests. Next ID: 34
 */
export interface AssistantApiDeviceCapabilities {
  /**
   * Capabilites related to Android intent support.
   */
  androidIntentCapabilities?: AssistantApiAndroidIntentCapabilities;
  /**
   * These capabilities are scoped to the ability to gather audio. It includes
   * information like the type of audio that can be gathered (e.g. public,
   * private).
   */
  audioInput?: AssistantApiAudioInput;
  /**
   * These capabilities are scoped to the ability to play audio. It includes
   * information like the type of audio that can be played (e.g. public,
   * private).
   */
  audioOutput?: AssistantApiAudioOutput;
  /**
   * The call capabilities of this device. go/call-capabilities
   */
  callCapabilities?: AssistantApiCallCapabilities;
  /**
   * These capabilities are scoped to the camera abilities of this device.
   */
  camera?: AssistantApiCameraCapabilities;
  /**
   * UX restrictions for Auto.
   */
  carUxRestrictions?:  | "UX_RESTRICTIONS_UNSPECIFIED" | "UX_RESTRICTIONS_BASELINE" | "UX_RESTRICTIONS_FULLY_RESTRICTED" | "UX_RESTRICTIONS_NO_KEYBOARD" | "UX_RESTRICTIONS_NO_VIDEO"[];
  /**
   * These capabilities are scoped to the cast abilities of this device.
   */
  cast?: AssistantApiCastCapabilities;
  communicationUiCapabilities?: AssistantApiCommunicationUiCapabilities;
  contactLookupCapabilities?: AssistantApiContactLookupCapabilities;
  /**
   * This is the same device id that is specified in the conversation protocol
   * and should be unique to each device/user/model combination. For example, if
   * a request is coming from a watch through AGSA the watch and AGSA should
   * have different device_ids. Note: this field should only be used to
   * determine which device the capabilities belong to and not to access the id
   * of the device. Instead DeviceProperties should be used and accessed through
   * ParamsAccessor.
   */
  deviceId?: AssistantApiCoreTypesDeviceId;
  /**
   * Capabilities related to Android tablet UX experience.
   */
  deviceUxMode?:  | "DEVICE_UX_MODE_DEFAULT" | "DEVICE_UX_MODE_SUPPORT_LIMITED_SHARED_LOCKSCREEN";
  /**
   * Indicates that the device has connection to cellular network that allows
   * it to make voice calls. This is distinct from device just being capable of
   * voice telephony, because the device can be capable yet miss the suitable
   * SIM card (for example, it could miss SIM card altogether, or have data-only
   * SIM card).
   */
  hasVoiceTelephony?: boolean;
  /**
   * Indicates if the client supports Javascript Whatsnext (go/jwn). Also
   * contains the Jwn libraries present on the client along with their versions.
   */
  jwnCapabilities?: AssistantApiJwnCapabilities;
  /**
   * Capabilities related to Lens Perception, i.e. image understanding. See
   * go/lens-perception-sdk.
   */
  lensPerceptionCapabilities?: AssistantApiLensPerceptionCapabilities;
  /**
   * These capabilities are scoped to the location abilities of this device.
   */
  location?: AssistantApiLocationCapabilities;
  /**
   * Data which is produced for logging and debugging. Servers MUST NOT use
   * this for any other purposes, such as branching on it.
   */
  loggingOnlyData?: AssistantApiLoggingOnlyData;
  messageCapabilities?: AssistantApiMessageCapabilities;
  /**
   * These capabilities are scoped to abilities of the device to move around.
   */
  movement?: AssistantApiMovementCapabilities;
  /**
   * DEPRECATED: Use SystemNotificationRestrictions instead. Specifies whether
   * the surface is able to display notifications. This field is superficially
   * similar to ProactiveNotificationOutput, but unlike that field which tracks
   * a per-user preference on the OPA side, this field captures whether the
   * surface is capable of displaying notifications.
   */
  notificationCapabilities?:  | "NO_NOTIFICATION_CAPABILITY" | "NOTIFICATIONS_DISABLED" | "NOTIFICATIONS_ENABLED";
  /**
   * Settings, that reflect whether a specific notification type is allowed for
   * current device, e.g. if the user opted out from notification category or
   * category group. This settings are server-side stored and evaluated unlike
   * SystemNotificationRestrictions field.
   */
  notificationOutputRestrictions?: AssistantApiNotificationOutputRestrictions;
  /**
   * These are user configured restrictions indicating what the device is
   * allowed to output from the privacy point of view.
   */
  outputRestrictions?: AssistantApiOutputRestrictions;
  /**
   * Capability to support Pop on lockscreen.
   */
  popOnLockscreenCapability?:  | "POP_ON_LOCKSCREEN_DEFAULT" | "POP_ON_LOCKSCREEN_ENABLED" | "POP_ON_LOCKSCREEN_DISABLED";
  /**
   * Indicates if the client has safety related restriction.
   */
  safetyRestrictions?:  | "DEFAULT_NO_SAFETY_RESTRICTION" | "DISTRACTION_SAFETY_RESTRICTION";
  /**
   * These capabilities are scoped to the ability to see and interact with the
   * Assistant through a screen. If the device has no screen it should send an
   * empty ScreenCapabilities. Sending no ScreenCapabilities will cause this to
   * be overridden with the surface default.
   */
  screen?: AssistantApiScreenCapabilities;
  /**
   * Capabilities related to SODA (Speech On-Device API).
   */
  sodaCapabilities?: AssistantApiSodaCapabilities;
  /**
   * These capabilities are scoped to the software available on the device as
   * well as the set of supported Assistant features.
   */
  software?: AssistantApiSoftwareCapabilities;
  /**
   * DEPRECATED Capabilities related to speech detection on devices.
   */
  speechCapabilities?: AssistantApiSpeechCapabilities;
  /**
   * Locales supported by assistant settings for speaking and display. This is
   * independent from device language that is defined in device setting. New
   * locales are added based on rollout, whitelist and app version releases
   * because older versions does not have model support. Currently supported
   * locale list differs by surface type.
   */
  supportedLocale?: string[];
  /**
   * The set of information that helps the server identify the surface.
   */
  surfaceIdentity?: AssistantApiCoreTypesSurfaceIdentity;
  /**
   * The device's surface type. This is the string version of the
   * assistant.api.core_types.SurfaceType enum. The server should not use this
   * field, rather it should use the SurfaceType value derived from this string.
   */
  surfaceTypeString?: string;
  /**
   * Restrictions related to system-level notifications. This field is
   * superficially similar to ProactiveNotificationOutput, but unlike that field
   * which tracks a per-user preference on the OPA side, this field captures
   * system level notifications restrictions. This field is not stored and is
   * merged to capablities from conversation params. It exists mostly for
   * logging purposes of android channel state and global app-level notification
   * opt out.
   */
  systemNotificationRestrictions?: AssistantApiSystemNotificationRestrictions;
  /**
   * Capabilities related to third party integration.
   */
  thirdPartyCapabilities?: AssistantApiThirdPartyCapabilities;
}

function serializeAssistantApiDeviceCapabilities(data: any): AssistantApiDeviceCapabilities {
  return {
    ...data,
    loggingOnlyData: data["loggingOnlyData"] !== undefined ? serializeAssistantApiLoggingOnlyData(data["loggingOnlyData"]) : undefined,
    software: data["software"] !== undefined ? serializeAssistantApiSoftwareCapabilities(data["software"]) : undefined,
  };
}

function deserializeAssistantApiDeviceCapabilities(data: any): AssistantApiDeviceCapabilities {
  return {
    ...data,
    loggingOnlyData: data["loggingOnlyData"] !== undefined ? deserializeAssistantApiLoggingOnlyData(data["loggingOnlyData"]) : undefined,
    software: data["software"] !== undefined ? deserializeAssistantApiSoftwareCapabilities(data["software"]) : undefined,
  };
}

/**
 * A Duration represents a signed, fixed-length span of time represented as a
 * count of seconds and fractions of seconds at nanosecond resolution. It is
 * independent of any calendar and concepts like "day" or "month". It is related
 * to Timestamp in that the difference between two Timestamp values is a
 * Duration and it can be added or subtracted from a Timestamp. Range is
 * approximately +-10,000 years.
 */
export interface AssistantApiDuration {
  /**
   * Signed fractions of a second at nanosecond resolution of the span of time.
   * Durations less than one second are represented with a 0 `seconds` field and
   * a positive or negative `nanos` field. For durations of one second or more,
   * a non-zero value for the `nanos` field must be of the same sign as the
   * `seconds` field. Must be from -999,999,999 to +999,999,999 inclusive.
   */
  nanos?: number;
  /**
   * Signed seconds of the span of time. Must be from -315,576,000,000 to
   * +315,576,000,000 inclusive.
   */
  seconds?: bigint;
}

function serializeAssistantApiDuration(data: any): AssistantApiDuration {
  return {
    ...data,
    seconds: data["seconds"] !== undefined ? String(data["seconds"]) : undefined,
  };
}

function deserializeAssistantApiDuration(data: any): AssistantApiDuration {
  return {
    ...data,
    seconds: data["seconds"] !== undefined ? BigInt(data["seconds"]) : undefined,
  };
}

export interface AssistantApiFeatureSpecificActionSupport {
  /**
   * Whether client supports clarification suggestion chip to be displayed see
   * |assistant.suggestions.ClarificationData|
   */
  clarificationDataSupported?: boolean;
}

export interface AssistantApiFitnessFeatureSupport {
  /**
   * A list of fitness activity types supported by this client.
   */
  supportedActivities?:  | "TYPE_UNSPECIFIED" | "WALK" | "RUN" | "ELLIPTICAL" | "SWIM" | "WEIGHTS" | "TREADMILL" | "BIKE" | "YOGA" | "WORKOUT" | "BOOT_CAMP" | "CIRCUIT_TRAINING" | "GOLF" | "HIKING" | "INTERVAL_TRAINING" | "KICKBOXING" | "MARTIAL_ARTS" | "PILATES" | "SPINNING" | "STAIR_CLIMBING" | "TENNIS" | "AEROBICS" | "CORE_TRAINING" | "DANCING" | "HIGH_INTENSITY_INTERVAL_TRAINING" | "KAYAKING" | "ROWING" | "SKIING" | "STANDUP_PADDLEBOARDING" | "STRENGTH_TRAINING" | "SNOWBOARDING"[];
}

export interface AssistantApiFluidActionsSupport {
  /**
   * Specifies the params proto that Fluid Actions uses to sync state with
   * server.
   */
  stateSyncMethod?:  | "STATE_SYNC_METHOD_UNSPECIFIED" | "DIALOG_STATE_PARAMS";
}

/**
 * Capabilities of Google assistant conversation service(GACS) devices. These
 * capabilites including supported GACS actions and response size limitations.
 */
export interface AssistantApiGacsCapabilities {
  /**
   * DeviceId of the accessory device (eg. watch) Commonly the go/dusi (eg.
   * client_instance_id) is provided.
   */
  deviceId?: AssistantApiCoreTypesDeviceId;
  /**
   * Configuration sent by device.
   */
  responseConfig?: GoogleAssistantAccessoryV1ResponseConfig;
  /**
   * DEPRECATED: Format of TTS audio requested by the device.
   */
  ttsEncoding?:  | "LINEAR_16BIT" | "MULAW" | "ALAW" | "MP3" | "MP3_64KBPS" | "SPEEX" | "SPEEX_WITH_HEADER_BYTE" | "SPEEX_IN_OGG" | "OPUS_IN_OGG" | "OPUS_24KBPS_IN_OGG" | "OPUS_16KBPS_IN_OGG" | "OPUS_12KBPS_IN_OGG" | "OPUS_16KBPS_CONTAINERLESS" | "OPUS_24KBPS_CONTAINERLESS" | "OPUS_32KBPS_CONTAINERLESS";
}

function serializeAssistantApiGacsCapabilities(data: any): AssistantApiGacsCapabilities {
  return {
    ...data,
    responseConfig: data["responseConfig"] !== undefined ? serializeGoogleAssistantAccessoryV1ResponseConfig(data["responseConfig"]) : undefined,
  };
}

function deserializeAssistantApiGacsCapabilities(data: any): AssistantApiGacsCapabilities {
  return {
    ...data,
    responseConfig: data["responseConfig"] !== undefined ? deserializeGoogleAssistantAccessoryV1ResponseConfig(data["responseConfig"]) : undefined,
  };
}

/**
 * Capabilities related to GCM.
 */
export interface AssistantApiGcmCapabilities {
  /**
   * GCM registration id for the device. Used to pass messages to the device.
   */
  gcmRegistrationId?: string;
  /**
   * Assistant supports GCM on the device. ClientOps can be sent to it over GCM
   * and will be executed.
   */
  supportsAssistantGcm?: boolean;
  /**
   * If it is set to true, then it indicates to server that device is capable
   * of receiving a GCM payload with serialized client input. The client input
   * will be sent back to Assistant Server over conversation protocol.
   */
  supportsClientInputOverGcm?: boolean;
}

/**
 * The gesture capabilities related to Selina. Next ID: 4
 */
export interface AssistantApiGestureCapabilities {
  /**
   * Whether Gesture is supported. When false, override the value for tap and
   * omniswipe.
   */
  gestureSensing?: boolean;
  /**
   * Whether omniswipe is supported
   */
  omniswipeGestureCapable?: boolean;
  /**
   * Whether tap is supported
   */
  tapGestureCapable?: boolean;
}

/**
 * DEPRECATED: Use AccessControlOutput instead. Access settings for guests.
 */
export interface AssistantApiGuestAccessOutput {
  guestAccessOnYoutube?:  | "UNKNOWN_GUEST_ACCESS" | "USE_DEFAULT_ACCOUNT_FOR_GUEST" | "DISABLED_FOR_GUEST";
}

export interface AssistantApiImmersiveCanvasSupport {
  /**
   * Whether the client supports confirmation messages in Immersive Canvas
   * actions.
   */
  confirmationMessageSupported?: boolean;
  /**
   * Whether the client support canvas pause signal. If true, the Assistant
   * Server will send a signal when canvas transitioning to pause mode.
   */
  pauseSignalSupported?: boolean;
}

/**
 * These capabilities are used to determine the jwn libraries and their
 * versions that are present on the client.
 */
export interface AssistantApiJwnCapabilities {
  /**
   * The name and version of the jwn libraries currently stored on the client.
   * These are the same that the server communicated when the library was first
   * sent down.
   */
  librariesVersionMap?: {
    [key: string]: string
  };
  /**
   * Compression algorithms supported on the client. Server can choose one of
   * these to compress WhatsNext Javascript programs and libraries.
   */
  supportedCompressionMode?:  | "NONE" | "BROTLI" | "FLATE"[];
  /**
   * Whether the client supports running jwn code.
   */
  supportsJwn?: boolean;
}

/**
 * Capabilities related to Lens Perception, i.e. image understanding. See
 * go/loa-lens-device-capabilities. Next ID: 6
 */
export interface AssistantApiLensPerceptionCapabilities {
  /**
   * Whether the device supports Lens Perception.
   */
  hasLensPerception?: boolean;
  /**
   * Indicates whether Lens supports Lens Direct Intent (go/lensdirectintent).
   */
  isLensDirectIntentAvailable?: boolean;
  /**
   * Indicates whether Lens supports Live view-finder experience.
   */
  isLensLiveViewfinderAvailable?: boolean;
  /**
   * Indicates whether Lens supports Post-capture experience with an image
   * payload.
   */
  isLensPostCaptureAvailable?: boolean;
  /**
   * Contains the capabilities that Lens can support.
   */
  lensCapabilities?: AssistantApiLensPerceptionCapabilitiesLensCapabilities;
}

/**
 * The set of capabilities that Lens can support. This is the Assistant proto
 * representation of Lens capabilities defined at
 * j/c/g/android/apps/gsa/search/shared/service/proto/lens_service_event.proto
 * Next ID: 7
 */
export interface AssistantApiLensPerceptionCapabilitiesLensCapabilities {
  /**
   * The presence of this message means that Dining is supported.
   */
  dining?: AssistantApiLensPerceptionCapabilitiesLensCapabilitiesDining;
  /**
   * The presence of this message means that Education is supported.
   */
  education?: AssistantApiLensPerceptionCapabilitiesLensCapabilitiesEducation;
  /**
   * The presence of this message means that Outdoor is supported.
   */
  outdoor?: AssistantApiLensPerceptionCapabilitiesLensCapabilitiesOutdoor;
  /**
   * The presence of this message means that Shopping is supported.
   */
  shopping?: AssistantApiLensPerceptionCapabilitiesLensCapabilitiesShopping;
  /**
   * The presence of this message means that intenting directly into the text
   * filter is supported.
   */
  text?: AssistantApiLensPerceptionCapabilitiesLensCapabilitiesText;
  /**
   * The presence of this message means that Translation is supported.
   */
  translate?: AssistantApiLensPerceptionCapabilitiesLensCapabilitiesTranslate;
}

/**
 * Dining recognition capability. For example popular dishes on a given
 * restaurant menu image.
 */
export interface AssistantApiLensPerceptionCapabilitiesLensCapabilitiesDining {
}

/**
 * Education recognition capability.
 */
export interface AssistantApiLensPerceptionCapabilitiesLensCapabilitiesEducation {
}

/**
 * Outdoor place recognition capability. For example recognizing storefronts.
 */
export interface AssistantApiLensPerceptionCapabilitiesLensCapabilitiesOutdoor {
}

/**
 * Shopping recognition capability.
 */
export interface AssistantApiLensPerceptionCapabilitiesLensCapabilitiesShopping {
}

/**
 * Text recognition capability.
 */
export interface AssistantApiLensPerceptionCapabilitiesLensCapabilitiesText {
  /**
   * Indicates whether text-to-speech is supported.
   */
  isTextToSpeechSupported?: boolean;
}

/**
 * Translation capability.
 */
export interface AssistantApiLensPerceptionCapabilitiesLensCapabilitiesTranslate {
  /**
   * The list of language IETF BCP 47 tags that are supported. See the full
   * details in the comment on the equivalent field in:
   * http://google3/java/com/google/android/apps/gsa/search/shared/service/proto/lens_service_event.proto;l=55;rcl=355512559
   */
  supportedLanguageTags?: string[];
}

export interface AssistantApiLiveTvChannelCapabilities {
  /**
   * A list of channel providers each of which provides a list of its channels.
   */
  channelsByProvider?: AssistantApiLiveTvChannelCapabilitiesChannelsByProvider[];
}

export interface AssistantApiLiveTvChannelCapabilitiesChannelsByProvider {
  /**
   * A list of channels provided by this input. Keep the performance impact in
   * mind when the number/size of the channels is large. When there are too many
   * channels, consider stripping out some data.
   */
  channels?: AssistantApiLiveTvChannelCapabilitiesLiveTvChannel[];
  /**
   * An identifier to identify the input source. For example for TIF based
   * channels, this will be the TIF input ID to differentiate different tuner
   * apps. See https://source.android.com/devices/tv
   */
  inputId?: string;
  /**
   * Type of provider who provides this channel input.
   */
  providerType?:  | "UNKNOWN_PROVIDER_TYPE" | "OTT_PROVIDER" | "TUNER";
}

export interface AssistantApiLiveTvChannelCapabilitiesLiveTvChannel {
  /**
   * Unique channel identifier.
   */
  channelId?: string;
  /**
   * A list of channel names and synonyms.
   */
  channelName?: string[];
  /**
   * Channel number displayed to user. Optional.
   */
  channelNumber?: string;
  /**
   * A deep link into the Live player app that tunes to this channel.
   */
  deeplink?: string;
  /**
   * KG mid of the channel if it exists in KG.
   */
  mid?: string;
  /**
   * Network KG mid of the channel if it exists in KG
   */
  networkMid?: string;
}

export interface AssistantApiLiveTvProvider {
  /**
   * Contains detailed provider information such as android app package name.
   */
  providerInfo?: AssistantApiCoreTypesProvider;
  /**
   * An provider enum string for OTT providers. The available key can be found
   * in go/ump-provider-enum For Tuner provider, the provider key would be an ID
   * the tuner app uploaded from TIF. See https://source.android.com/devices/tv
   */
  providerKey?: string;
  providerType?:  | "UNKNOWN_PROVIDER_TYPE" | "OTT_PROVIDER" | "TUNER";
}

function serializeAssistantApiLiveTvProvider(data: any): AssistantApiLiveTvProvider {
  return {
    ...data,
    providerInfo: data["providerInfo"] !== undefined ? serializeAssistantApiCoreTypesProvider(data["providerInfo"]) : undefined,
  };
}

function deserializeAssistantApiLiveTvProvider(data: any): AssistantApiLiveTvProvider {
  return {
    ...data,
    providerInfo: data["providerInfo"] !== undefined ? deserializeAssistantApiCoreTypesProvider(data["providerInfo"]) : undefined,
  };
}

export interface AssistantApiLocationCapabilities {
  gpsAvailable?: boolean;
}

/**
 * Data which is produced for logging and debugging. Servers MUST NOT use this
 * for any other purposes, such as branching on it. Next ID: 15
 */
export interface AssistantApiLoggingOnlyData {
  /**
   * The index of the account on the device. Useful when there are multiple
   * accounts on a device such as distinguishing primary user data from
   * secondary users. There is no guarantee that this is a stable number but is
   * relatively stable in practice.
   */
  accountIndex?: number;
  /**
   * A user-readable string describing the ACP version (go/acp-version) of the
   * client app used by the user to originate the conversation.
   */
  acpVersion?: string;
  /**
   * Random identifier assigned to Android mobile devices. Older logs may have
   * previously stored other kinds of android IDs in this field, but all current
   * logs should use the GServices Id. See go/androidids.
   */
  androidId?: bigint;
  /**
   * A user-readable string describing the version of the client app used by
   * the user to originate the conversation.
   */
  appVersion?: string;
  /**
   * An enum specifying when was this ATV AssistantSettings entry initially
   * created.
   */
  assistantSettingsSource?:  | "NOT_SET" | "FIRST_SCREEN_DEVICE_OOBE" | "FIRST_SCREEN_KATNISS_OOBE" | "FIRST_SCREEN_DELEGATION_OOBE" | "FIRST_SCREEN_FIXER_JOB" | "FIRST_SCREEN_FCM_JOB" | "FIRST_SCREEN_HOME_GRAPH_JOB" | "FIRST_SCREEN_PERSONAL_BIT" | "FIRST_SCREEN_VOICE_INPUT_BIT" | "FIRST_SCREEN_OTHER" | "SECOND_SCREEN_AGSA" | "SECOND_SCREEN_GHA_IOS" | "SECOND_SCREEN_GHA_ANDROID";
  /**
   * The type of board used by manufacturer for this device
   */
  boardName?: string;
  /**
   * The revision of board used
   */
  boardRevision?: string;
  /**
   * This field records the linking status between Assistant setting entry and
   * Cast setting entry. Currently only ATV surface populates this field for
   * profiling purpose.
   */
  castAssistantSettingLinkingResult?: AssistantApiCastAssistantSettingLinkingResult;
  /**
   * A user-readable string describing the device's hardware platform.
   */
  deviceModel?: string;
  /**
   * Any relevant info concerning the build options of the embedder (that is
   * the software which runs as the 'driver' of an Assistant library, such as
   * libassistant. the embedder is typically built by a third party)
   */
  embedderBuildInfo?: string;
  /**
   * A string recording the app version that is initially used to created this
   * settings entry.
   */
  initialAppVersion?: string;
  /**
   * default display name of device over mdns. This is specified at the
   * factory, not specified by the user.
   */
  mdnsDisplayName?: string;
  /**
   * A user-readable string describing the device's software platform.
   */
  platformBuild?: string;
  /**
   * A string describing device's release channel. For cast devices, the string
   * will look like "qa-beta-channel", "eng-no-update", etc.
   */
  virtualReleaseChannel?: string;
}

function serializeAssistantApiLoggingOnlyData(data: any): AssistantApiLoggingOnlyData {
  return {
    ...data,
    androidId: data["androidId"] !== undefined ? String(data["androidId"]) : undefined,
  };
}

function deserializeAssistantApiLoggingOnlyData(data: any): AssistantApiLoggingOnlyData {
  return {
    ...data,
    androidId: data["androidId"] !== undefined ? BigInt(data["androidId"]) : undefined,
  };
}

export interface AssistantApiMediaControlSupport {
  /**
   * Whether to prevent confirmations (text, tts) for media control actions
   * while media is playing so that the media session is not interrupted.
   */
  skipConfirmationsWhilePlaying?: boolean;
}

export interface AssistantApiMessageCapabilities {
  /**
   * If true, APP_ID queries initiated by this device should fall back to
   * execution on the tethered device if it's available and if the primary
   * device cannot perform the action (e.g. due to the app not being installed).
   */
  fallbackToTetheredDeviceAppCapabilities?: boolean;
  /**
   * Should only be checked if nonempty.
   */
  supportedRecipientTypes?:  | "UNSPECIFIED_ENDPOINT" | "PHONE_NUMBER" | "EMAIL_ADDRESS" | "APP_UNIQUE_ID" | "EMERGENCY_PHONE_NUMBER" | "VOICEMAIL"[];
}

export interface AssistantApiMovementCapabilities {
  /**
   * Indicates how much the device moves around. E.g., TV has a low mobility
   * level, while Auto has a very high level.
   */
  mobility?:  | "UNSPECIFIED" | "LOW" | "MEDIUM" | "HIGH" | "VERY_HIGH";
}

export interface AssistantApiNotificationOutputRestrictions {
  optOutState?: AssistantApiNotificationOutputRestrictionsOptOutState;
}

/**
 * Per category/category group notification opt out settings.
 */
export interface AssistantApiNotificationOutputRestrictionsOptOutState {
  categoryGroupState?: AssistantApiNotificationOutputRestrictionsOptOutStateCategoryGroupState[];
  categoryState?: AssistantApiNotificationOutputRestrictionsOptOutStateCategoryState[];
}

export interface AssistantApiNotificationOutputRestrictionsOptOutStateCategoryGroupState {
  categoryGroup?:  | "UNSPECIFIED" | "SYSTEM" | "PROMOTIONAL" | "SUBSCRIPTIONS" | "PROACTIVE" | "REMINDERS" | "EXTENDED_ANSWERS" | "FEEDBACK" | "ACTIONS_ON_GOOGLE" | "DUO_MISSED_CALLS" | "HOME_AUTOMATION" | "GETTING_AROUND" | "UNIT_TESTING";
  state?:  | "OPTED_IN" | "OPTED_OUT";
}

export interface AssistantApiNotificationOutputRestrictionsOptOutStateCategoryState {
  category?:  | "UNSPECIFIED" | "SYSTEM_REQUIRED_LOW_PRIORITY" | "SYSTEM_REQUIRED_HIGH_PRIORITY" | "DISCOVERY" | "REALTIME_PROMOTIONAL" | "SUBSCRIPTIONS" | "FLIGHT_UPDATES" | "TRANSPORT_UPDATES" | "BILL_UPDATES" | "PACKAGE_DELIVERY_UPDATES" | "EVENT_UPDATES" | "DUE_DATE_UPDATES" | "CELEBRATION_UPDATES" | "ROUTINE_UPDATES" | "TASK_SUGGESTIONS" | "AT_A_PLACE" | "APP_RECOMMENDATIONS" | "TRAVEL_UPDATES" | "REMINDER_DUE" | "NEW_REMINDER_ASSIGNMENT" | "ASSIGNED_REMINDER_DUE" | "ROUTINE_SETTINGS_UPDATES" | "MAPS_OR_DIRECTIONS" | "MOVIE_SHOWTIMES" | "SPORTS_UPDATES" | "NEWS_UPDATES" | "SONGS_AND_ARTISTS" | "TRANSLATIONS" | "ANSWERS_TO_QUESTIONS" | "SETTINGS_LINKS" | "RESERVATION_UPDATES" | "DEPRECATED_FEEDBACK_REQUESTS" | "FEEDBACK_REQUESTS" | "ACTIONS_ON_GOOGLE" | "DUO_MISSED_CALLS" | "HOME_AUTOMATION" | "TIME_TO_LEAVE" | "COMMUTE" | "OCCASIONALLY_REPEATED_ACTIONS" | "FREQUENTLY_REPEATED_ACTIONS" | "ASPIRE" | "ASSISTANT_DRIVING_MODE" | "DISCOVERY_DEFAULT_PRIORITY" | "HOLIDAY_REMINDERS" | "CROSS_DEVICE_TIMER" | "LIVE_CARD" | "ASYNC_ACTION" | "UNIT_TESTING";
  state?:  | "OPTED_IN" | "OPTED_OUT";
}

/**
 * Encapsulates the action capabilities of the OEM device. This data is merged
 * from Device Model lookup, per-device registration, and per-request context.
 * This data is sent to NLU layer for query understanding.
 */
export interface AssistantApiOemCapabilities {
  /**
   * The OEM Cloud execution capability of this device, containing routing
   * details for cloud fulfillment.
   */
  cloudCapability?: AssistantDevicesPlatformProtoCloudCapability;
  /**
   * If fulfillment is done via 3P cloud and 3P supports device capabilities,
   * this field will be set.
   */
  cloudDeviceCapabilities?: {
    [key: string]: any
  };
  /**
   * Device Model Id from DeviceModelPackage.
   */
  deviceModelId?: string;
  /**
   * Device Model Revision Id from DeviceModelPackage.
   */
  deviceModelRevisionId?: bigint;
  /**
   * Opaque supported action data related to a specific domain of devices, for
   * example for car. go/car-talk-registration-model
   */
  deviceSpecificData?: string;
  /**
   * Internal-only config containing metadata about the Device Model, for
   * example to control the ranking behavior.
   */
  internalCapability?: AssistantDevicesPlatformProtoInternalCapability;
  /**
   * 3P Action Metadata, populated from the Device Model lookup and the client
   * request parameters. For example, an Assistant SDK request would have the
   * billed project id of the Assistant request added here in order to enable
   * any Device Actions developed using the same Google Cloud project. This data
   * is sent to Service Engine to mask triggering for Device Actions.
   */
  thirdPartyActionConfig?: AssistantApiThirdPartyActionConfig;
}

function serializeAssistantApiOemCapabilities(data: any): AssistantApiOemCapabilities {
  return {
    ...data,
    deviceModelRevisionId: data["deviceModelRevisionId"] !== undefined ? String(data["deviceModelRevisionId"]) : undefined,
    thirdPartyActionConfig: data["thirdPartyActionConfig"] !== undefined ? serializeAssistantApiThirdPartyActionConfig(data["thirdPartyActionConfig"]) : undefined,
  };
}

function deserializeAssistantApiOemCapabilities(data: any): AssistantApiOemCapabilities {
  return {
    ...data,
    deviceModelRevisionId: data["deviceModelRevisionId"] !== undefined ? BigInt(data["deviceModelRevisionId"]) : undefined,
    thirdPartyActionConfig: data["thirdPartyActionConfig"] !== undefined ? deserializeAssistantApiThirdPartyActionConfig(data["thirdPartyActionConfig"]) : undefined,
  };
}

/**
 * Definitions of on-device assistant capabilities.
 */
export interface AssistantApiOnDeviceAssistantCapabilities {
  /**
   * Capabilities related to local network arbitration
   * (go/local-network-arbitration). Indicates if the device is capable of being
   * a host device in the LAN whiling doing local network arbitration.
   */
  isLocalNetworkArbitrationSupported?: boolean;
  /**
   * Capabilities related to on-device arbitration(go/arbitration-on-device).
   */
  isOnDeviceArbitrationSupported?: boolean;
  /**
   * Indicates if on-device assistant is enabled on this device. Example
   * usecases: NGA (go/nga) or Marble (go/marble).
   */
  isOnDeviceAssistantSupported?: boolean;
  /**
   * This may be used by NGA. E.g. if understanding happens on device, we can
   * have more aggressive logic when fulfilling some features on the server
   * side, like teleport.
   */
  isOnDeviceUnderstandingSupported?: boolean;
}

/**
 * Definitions of on-device Smart Home capabilities. Next ID: 2
 */
export interface AssistantApiOnDeviceSmartHomeCapabilities {
  /**
   * Master bit for on-device Smart Home features.
   */
  isOnDeviceSmartHomeSupported?: boolean;
}

/**
 * The on-device storage capabilities found on the device.
 */
export interface AssistantApiOnDeviceStorageCapabilities {
  /**
   * Determines if an on-device storage is supported.
   */
  isSupported?: boolean;
}

/**
 * These are user configurable permissions representing what the device is
 * allowed to output. Next ID: 11
 */
export interface AssistantApiOutputRestrictions {
  /**
   * Access settings for all providers.
   */
  accessControlOutput?: AssistantApiAccessControlOutput;
  /**
   * The type of Google Photo content which the device can output.
   */
  googlePhotoContent?:  | "ALL_PHOTO_CONTENT" | "NO_RESTRICTED_PHOTO_CONTENT";
  /**
   * DEPRECATED: Use access_control_output instead. Access settings for guests.
   */
  guestAccessOutput?: AssistantApiGuestAccessOutput;
  /**
   * The level of personal data which the device can output. See
   * go/personal-readout for detail.
   */
  personalData?:  | "PERSONAL_DATA_OUTPUT_UNKNOWN" | "ALL_PERSONAL_DATA_WITH_PROACTIVE" | "ALL_PERSONAL_DATA" | "NO_PERSONAL_DATA";
  /**
   * This controls if the server can proactively send notification to users,
   * and it does not affect scenarios that users ask for information. The
   * notification may include TTS and lights. It could be only lights for chirp.
   */
  proactiveNotificationOutput?:  | "UNKNOWN_PROACTIVE_NOTIFICATION" | "NO_PROACTIVE_NOTIFICATION" | "ALL_PROACTIVE_NOTIFICATIONS";
  /**
   * Restrictions on displaying and interacting with content on proactive
   * surfaces (e.g. Dragonglass home screen). Note: NEVER access this field of
   * OutputRestrictions directly, use the code in
   * assistant/assistant_server/settings/device/device_settings_util.h instead.
   */
  proactiveOutput?: AssistantApiProactiveOutput;
  /**
   * Whether YouTube autoplay is allowed for queries from the user to this
   * device. See go/assistant-youtube-settings for details.
   */
  youtubeAutoplayRestriction?:  | "AUTOPLAY_RESTRICTION_UNSPECIFIED" | "AUTOPLAY_ALLOWED" | "AUTOPLAY_DISABLED";
  /**
   * The type of YouTube content which the device can output.
   */
  youtubeContent?:  | "ALL_YOUTUBE_CONTENT" | "NO_RESTRICTED_CONTENT";
  /**
   * The type of YouTube TV content which the device can output.
   */
  youtubeTvContent?:  | "ALL_YOUTUBE_TV_CONTENT" | "NO_RESTRICTED_YOUTUBE_TV_CONTENT";
}

/**
 * Next ID: 7
 */
export interface AssistantApiProactiveOutput {
  /**
   * Allows displaying all personal data on proactive surfaces with no face
   * match capability.
   */
  allowAllPersonalData?: boolean;
  /**
   * For ANDROID_TV devices, the location that this setting was last changed
   * from. Note: this structure allows to extend to more per-vertical bits in
   * the future.
   */
  androidTvAssistantSettingsSource?:  | "NOT_SET" | "FIRST_SCREEN_DEVICE_OOBE" | "FIRST_SCREEN_KATNISS_OOBE" | "FIRST_SCREEN_DELEGATION_OOBE" | "FIRST_SCREEN_FIXER_JOB" | "FIRST_SCREEN_FCM_JOB" | "FIRST_SCREEN_HOME_GRAPH_JOB" | "FIRST_SCREEN_PERSONAL_BIT" | "FIRST_SCREEN_VOICE_INPUT_BIT" | "FIRST_SCREEN_OTHER" | "SECOND_SCREEN_AGSA" | "SECOND_SCREEN_GHA_IOS" | "SECOND_SCREEN_GHA_ANDROID";
  /**
   * Allows displaying Health and Fitness content on proactive surfaces. This
   * is a sub bit of the device-wide PR bit - the device-wide PR bit must be
   * enabled AND this vertical sub bit must be enabled for H&F content to be
   * shown. This bit will be available on all surfaces that have the
   * proactive-bit enabled. If the proactive-bit is not enabled, then we do not
   * show health and fitness content at all (or even allow access to this
   * setting).
   */
  healthAndFitnessProactive?:  | "NO_HEALTH_AND_FITNESS_PROACTIVE_OUTPUT" | "ALL_HEALTH_AND_FITNESS_PROACTIVE_OUTPUT";
  /**
   * Allows displaying photos content on Dragonglass proactive surfaces. This
   * is a sub bit of the device-wide PR bit - the device-wide PR bit must be
   * enabled AND this vertical sub bit must be enabled for photos content to be
   * shown on Dragonglass surfaces. This bit will be available on all
   * Dragonglass surfaces that have the proactive-bit enabled. If the
   * proactive-bit is not enabled or it's not a Dragonglass surface, then we do
   * not show proactive photos content at all, nor allow access to this setting.
   * See go/opa-photos-sg-settings for more details.
   */
  photosProactive?:  | "UNKNOWN_PHOTOS_PROACTIVE_OUTPUT" | "NO_PHOTOS_PROACTIVE_OUTPUT" | "ALL_PHOTOS_PROACTIVE_OUTPUT";
  /**
   * Whether a device supports proactive output. Note that this is assumed to
   * be true for all Smart Display devices, but surfaces that newly start
   * supporting proactive_output should set this bit.
   */
  supportsProactiveOutput?: boolean;
  /**
   * Settings for displaying personal data on proactive surfaces with face
   * match capability.
   */
  userMatchProactive?:  | "UNKNOWN_USER_MATCH_PROACTIVE" | "NEVER_SHOW" | "ONLY_SHOW_ON_USER_MATCH" | "ALWAYS_SHOW";
}

/**
 * Also known as "Extensions Without Extensions" or "The Poor Man's Any", this
 * simple proto is used to transmit arbitrary protocol buffers over the wire.
 * Unlike extensions: - It does not require the proto type to be compiled into
 * the binary. (Useful so that the proto declaration can be inside the
 * conversation package) - It is compatible with all versions of proto,
 * including proto3 and the wack-tastic version used on ChromecastOS. Server
 * libraries for dealing with it live in
 * google3/assistant/protocol/protobuf_lib.h.
 */
export interface AssistantApiProtobuf {
  /**
   * The serialized protocol buffer.
   */
  protobufData?: Uint8Array;
  /**
   * The type of the protocol buffer to use. This must be a resolvable name
   * (Namespace.ProtoName) and refer to a proto which is either compiled in to
   * both client and server (e.g. a base proto type) or to one which is part of
   * the conversation package.
   */
  protobufType?: string;
}

function serializeAssistantApiProtobuf(data: any): AssistantApiProtobuf {
  return {
    ...data,
    protobufData: data["protobufData"] !== undefined ? encodeBase64(data["protobufData"]) : undefined,
  };
}

function deserializeAssistantApiProtobuf(data: any): AssistantApiProtobuf {
  return {
    ...data,
    protobufData: data["protobufData"] !== undefined ? decodeBase64(data["protobufData"] as string) : undefined,
  };
}

/**
 * Date-based recurrences specify repeating events. Conceptually, a recurrence
 * is a (possibly unbounded) sequence of dates on which an event falls,
 * described by a list of constraints. A date is in a recurrence if and only if
 * it satisfies all of the constraints. Note that devices may support some
 * constraints, but not all. IMPORTANT: The definition of Recurrence proto is
 * being moved to //assistant/api/core_types/governed/datetime_type.proto. All
 * existing references will be updated to point to the new location. If you are
 * adding a reference, use the new one instead.
 */
export interface AssistantApiRecurrence {
  /**
   * The first day of the recurrence. If begin is not set, then the reminder
   * will start infinitely in the past.
   */
  begin?: AssistantApiDate;
  /**
   * A list of blacklisted dates to skip the alarm on.
   */
  blacklistedRanges?: AssistantApiRecurrenceDatetimeRange[];
  /**
   * Specifies the date in a month. For example, if day_of_month is 15, then it
   * represent the 15th day of the specified month.
   */
  dayOfMonth?: number[];
  /**
   * Specifies a weekly or daily recurrence. Constraint: The date falls on one
   * of these days of the week, in 0...6 (Sunday...Saturday).
   */
  dayOfWeek?: number[];
  /**
   * The last day of the recurrence.
   */
  end?: AssistantApiDate;
  /**
   * Multiplier on the frequency of the recurrence. Use this to specify
   * patterns that recur every X days, months, years, etc. Example: [remind me
   * to call mom every 2nd week]. Default is 1 (every day, every month, every
   * year).
   */
  every?: number;
  /**
   * Specifies the month in a year. Constrain: the month falls on one of these
   * months, in 1, 2, ... 12 (January...December).
   */
  monthOfYear?: number[];
  /**
   * The number of occurrences after which the recurrence should end.
   */
  numOccurrences?: number;
  /**
   * Specifies the index of week in a month. For example, the second Tuesday
   * every month, in this case, week_of_month should be 2.
   */
  weekOfMonth?: number[];
}

/**
 * A representation of a range of time with start and end datetime specified.
 */
export interface AssistantApiRecurrenceDatetimeRange {
  /**
   * End date of the range.
   */
  endDate?: AssistantApiDateTime;
  /**
   * Start date of the range.
   */
  startDate?: AssistantApiDateTime;
}

/**
 * These capabilities represent the tactile features associated with the
 * device. This includes, for example, whether the device has a screen, how big
 * the screen is, and privacy of the screen. Next ID: 11
 */
export interface AssistantApiScreenCapabilities {
  /**
   * The scale factor used to convert Scalable Pixel (SP) units to
   * Density-independent Pixel (DP) units (DP = SP * scale factor). Fonts are
   * measured in units of SP, and on some platforms such as Android the SP to DP
   * scale factor can be affected by the font size a user selects in
   * accessibility settings.
   */
  fontScaleFactor?: number;
  /**
   * The types of input that this screen supports. Note that this can be empty
   * in which case the screen's input type is unknown.
   */
  inputType?:  | "TOUCHSCREEN"[];
  /**
   * Mask defined for this device, if any.
   */
  mask?: AssistantApiScreenCapabilitiesMask;
  /**
   * The targeted schema version for ProtoLayout requests.
   */
  protoLayoutTargetedSchema?: AssistantApiScreenCapabilitiesProtoLayoutVersion;
  /**
   * If this field is absent, the resolution of the screen is unknown.
   */
  resolution?: AssistantApiScreenCapabilitiesResolution;
  /**
   * If screen is turned off.
   */
  screenOff?: boolean;
  /**
   * The ability of the client to correctly report screen state.
   */
  screenStateDetection?:  | "UNKNOWN_SCREEN_STATE_DETECTION" | "UNRELIABLE_SCREEN_STATE_DETECTION" | "RELIABLE_SCREEN_STATE_DETECTION";
  /**
   * The primary supported rendering format for display on the device's screen.
   * This may be used to determine what format of card to be returned when
   * rendering cards.
   */
  supportedRenderingFormat?:  | "UNKNOWN_RENDERING_FORMAT" | "CONCISE_TEXT" | "PROTO_LAYOUT" | "ELEMENTS";
  /**
   * The screen states that the client supports. The current screen state is
   * specified in DeviceProperties.screen.
   */
  supportedScreenStates?:  | "UNKNOWN_SCREEN_STATE" | "ON" | "OFF"[];
  /**
   * Whether the device enabled vision help features in accessiblity settings.
   * The settings is config in Assistant App and on-device settings, and stored
   * in footprints. When enabled, font, color and TTS will be adjusted.
   */
  visionHelpEnabled?: boolean;
}

/**
 * A mask applied to the screen's pixel space to determine regions not visible
 * on the physical device.
 */
export interface AssistantApiScreenCapabilitiesMask {
  type?:  | "UNKNOWN_MASK" | "NO_MASK" | "ROUND_MASK";
}

/**
 * Version info for ProtoLayout requests.
 */
export interface AssistantApiScreenCapabilitiesProtoLayoutVersion {
  major?: number;
  minor?: number;
}

/**
 * A Resolution proto indicates the size of the application window. All fields
 * are required.
 */
export interface AssistantApiScreenCapabilitiesResolution {
  /**
   * Dots (pixels) per inch of the screen.
   */
  dpi?: number;
  heightPx?: number;
  /**
   * m_size is the smallest square box size to display a capital letter M so
   * that the user can still easily understand it.
   */
  mSize?: number;
  /**
   * neng_size is the smallest square box size to display a letter  (Neng,
   * U+879A) so that the user can easily understand it. (Neng is a visually
   * dense Chinese letter, and so may require a larger box than an M.)
   */
  nengSize?: number;
  /**
   * The dimensions of the application window, in pixels.
   */
  widthPx?: number;
}

/**
 * The Soli capabilities on Elaine, including gestures and sleep sensing.
 * go/dingo-dc-software Next ID: 4
 */
export interface AssistantApiSelinaCapabilites {
  /**
   * A list of gestures that selina supports
   */
  gestureCapabilities?: AssistantApiGestureCapabilities;
  /**
   * Whether the client supports selina.
   */
  selinaSupported?: boolean;
  /**
   * Whether the client can monitor sleep. This allows us to show sleep CUJ
   * related information: go/TwilightDesign
   */
  sleepSensingSupported?: boolean;
}

export interface AssistantApiSettingsAmbientSettings {
  /**
   * Whether any user sets personal photos on this device. See
   * go/ambient-setting-in-assistant-design.
   */
  anyUserHasSetPersonalPhotos?: boolean;
  /**
   * Whether or not the user's current selection for their ambient photo frame
   * includes the auto-generated "Recent Highlights" album. This is used to
   * determine which users to display the go/opa-photos-memories-tile. See
   * go/opa-photo-memories-imax-optin for more discussion on why this bit was
   * created.
   */
  recentHighlightsEnabled?: boolean;
  /**
   * Whether to enable the personal photo data in the ambient settings:
   * https://screenshot.googleplex.com/Wd4OFkQfOyF See
   * go/opa-photos-ambient-location-date-dd#heading=h.5x4iaouuiett for
   * explanation.
   */
  showPersonalPhotoData?: boolean;
  /**
   * Whether current user sets personal photos on this device. See
   * go/ambient-setting-in-assistant-design.
   */
  showPersonalPhotos?: boolean;
}

/**
 * These capabilties are associated with Assistant Settings on devices.
 */
export interface AssistantApiSettingsAppCapabilities {
  /**
   * Capabilities that are associated with Assistant Settings on auto surfaces.
   */
  carSettingsCapabilities?: AssistantApiCarSettingsCapabilities;
  /**
   * Whether the client supports reissuing query after setting up in Music
   * Settings.
   */
  reissueQueryAfterMusicSetup?: boolean;
  /**
   * Whether the client supports updating payments setting.
   */
  supportsPaymentsSettingsUpdate?: boolean;
}

/**
 * Settings pertaining to auto framing. See go/auto-framing-presentation.
 */
export interface AssistantApiSettingsAutoFramingSettings {
  isAutoFramingEnabled?: boolean;
}

/**
 * Carrier related call settings on the device.
 */
export interface AssistantApiSettingsCarrierCallDeviceSettings {
  /**
   * Whether this device is allowed to receive incoming PSTN calls.
   */
  allowIncomingCalls?: boolean;
}

/**
 * Specification of which communication features can be used.
 */
export interface AssistantApiSettingsCommunicationsFilter {
  state?:  | "UNKNOWN_STATE" | "ALLOW_ALL" | "BLOCK_CALLS_AND_MESSAGES";
}

/**
 * Specification of times when most features on a device are disabled for
 * certain users. During these periods, the device will respond to most
 * interactions with something like "sorry, I'm sleeping right now". Design:
 * go/home-ft-settings-storage PRD: go/home-family-tools-prd
 */
export interface AssistantApiSettingsDeviceDowntimeSettings {
  schedules?: AssistantApiSettingsLabeledDowntimeSchedule[];
  /**
   * The set of users of this device that will have these downtime settings
   * applied. Must have at least one element.
   */
  targets?:  | "UNKNOWN_DEVICE_SUPERVISION_TARGET" | "EVERYONE" | "KID_ACCOUNTS" | "GUESTS"[];
}

/**
 * Defines a set of restrictions on particular device features for a certain
 * set of users. Design: go/home-ft-settings-storage PRD:
 * go/home-family-tools-prd
 */
export interface AssistantApiSettingsDeviceFeatureFilters {
  /**
   * Enables/disables all the filters at the same time. For new devices or
   * non-Cast devices this is always false.
   */
  enabled?: boolean;
  /**
   * The filters (feature restrictions) to apply when `enabled` is true.
   */
  featureFilters?: AssistantApiSettingsFeatureFilters;
  /**
   * The set of users of this device that will have these settings applied.
   * Must have at least one element.
   */
  targets?:  | "UNKNOWN_DEVICE_SUPERVISION_TARGET" | "EVERYONE" | "KID_ACCOUNTS" | "GUESTS"[];
}

export interface AssistantApiSettingsDeviceLogsOptIn {
  /**
   * Indicates whether the crash logs can be uploaded and the device logs can
   * be enabled
   */
  optInEnabled?: boolean;
}

/**
 * Next ID: 73
 */
export interface AssistantApiSettingsDeviceSettings {
  /**
   * 
   * LINT.ThenChange(//depot/google3/assistant/ui/assistant_device_settings_ui.proto)
   */
  ackStatus?:  | "ACK_COMPLETED" | "ACK_PENDING";
  /**
   * A human-readable address string for the location; generally a one-line
   * address such as "34 Masonic Ave, San Francisco CA 94117, United States".
   * Set this field to empty string for deletion, in which case the rest of the
   * location related fields below will be cleared as well.
   */
  address?: string;
  /**
   * The alias names of the device, e.g. my living room tv, tv, living room and
   * etc., which user will usually use to refer to the device in addition to
   * human_friendly_name. It can help speech biasing and query understanding.
   * This field is set by the user and already localized.
   */
  aliasName?: string[];
  /**
   * Whether this device is allowed to receive incoming calls.
   */
  allowIncomingCalls?: boolean;
  /**
   * Ambient settings contains the configuration of Photo Frame on DG device.
   * This field relies on IMAX service to do the update, sync happenes after
   * user updates IMAX device settings or a device registers in CloudCastDevice.
   * So it's more like a cached version instead of definitive source-of-truth.
   * More details at go/ambient-setting-in-assistant-design.
   */
  ambientSettings?: AssistantApiSettingsAmbientSettings;
  /**
   * The additional device ids. Currently used only for ATV.
   * go/project-yellowstone Note: This field is for internal (Within settings)
   * use only.
   */
  ancillaryDeviceId?: AssistantApiSettingsInternalAncillaryDeviceId;
  /**
   * Auto framing settings associated with a device. See
   * go/auto-framing-presentation.
   */
  autoFramingSettings?: AssistantApiSettingsAutoFramingSettings;
  /**
   * Indicates whether the user has enabled Blue Steel. See go/blue-steel for
   * more info on this project.
   */
  blueSteelEnabled?: boolean;
  /**
   * Describes roughly what a device is capable of doing and metadata around
   * those capabilities. Note: this includes device limitations as well as user
   * configurable settings.
   */
  capabilities?: AssistantApiDeviceCapabilities;
  /**
   * city and postal_code are sent to third party AoG Apps as location when
   * permission is granted for precise or coarse location.
   * https://developers.google.com/actions/reference/rest/Shared.Types/Permission
   * city and postal_code have the same description as in Proto Postal Address:
   * https://cs.corp.google.com/piper///depot/google3/location/country/postaladdress.proto
   * city corresponds to locality_name, postal_code corresponds to
   * postal_code_number. These two fields are set in assistant_settings_service
   * by AddressConverter.
   * https://cs.corp.google.com/piper///depot/google3/location/addressformatter/public/addressconverter.h
   * See go/aog-i18n-address-parse for more information
   */
  city?: string;
  /**
   * Status of colocation. go/co-location-work-v2 Note: this is a cache at the
   * Assistant level. The source of truth is inside CastAuthenticationServer,
   * which is only used for Home devices.
   */
  colocationStatus?:  | "COLOCATION_UNKNOWN" | "COLOCATION_ESTABLISHED" | "COLOCATION_NOT_ESTABLISHED" | "COLOCATION_NOT_SUPPORTED";
  /**
   * The timestamp that the device is linked with the user in milliseconds.
   */
  creationTimestampMs?: bigint;
  /**
   * Availability of this device for Assistant Cross-surface handoffs.
   * (go/assistant-cross-surface)
   */
  crossSurfaceAvailability?: AssistantApiSettingsDeviceSettingsCrossSurfaceAvailability;
  /**
   * The identification of the default device which user want to output audio.
   * See go/default-media-output-design for more info.
   */
  defaultAudioDeviceId?: AssistantApiCoreTypesDeviceId;
  /**
   * The identification of the default device which user want to output video.
   * Note that, we don't fallback to this for audio playback when
   * default_audio_device_id is not set. See go/default-media-output-design for
   * more info.
   */
  defaultVideoDeviceId?: AssistantApiCoreTypesDeviceId;
  /**
   * The brand of the device, populated from DeviceOemParams. Examples:
   * "google", "samsung".
   */
  deviceBrand?: string;
  /**
   * The identification of the device.
   */
  deviceId?: AssistantApiCoreTypesDeviceId;
  /**
   * The model ID of the device. This should be globally unique across
   * manufactures/OEMs. Examples: "nest_cam_iq_2017", "comcast_voice_box_2017".
   */
  deviceModelId?: string;
  /**
   * The Device Platform Service lookup revision. (go/device-model-revision)
   * For 1p devices, and most 3p devices with no custom feature, this should be
   * always 0, which means no lookup needed. For 3p devices with custom
   * assistant feature, this is provided directly by OEM as incremental (e.g. 1,
   * 2, 3, ...)
   */
  deviceModelRevision?: number;
  /**
   * Only valid for ATV. Stores the android DUSI for the corresponding user.
   * More details: go/auto-logout-on-unlink.
   */
  dusi?: string;
  /**
   * List of errors that happened during the face enrollment process if it
   * failed. See go/face-match-enrollment-error for more info.
   */
  faceEnrollmentErrors?:  | "UNKNOWN_FACE_ENROLLMENT_ERROR" | "MISSING_FRONTAL_POSE" | "FACE_NOT_DETECTED" | "MULTIPLE_FACE_DETECTED" | "FACE_WITHOUT_SIGNATURE" | "FACE_DETECTION_LOW_CONFIDENCE" | "FACE_LANDMARK_LOW_CONFIDENCE" | "FACE_WITHOUT_CONFIDENCE" | "FACE_TOO_SMALL" | "FAILED_TO_READ_IMAGE" | "FAILED_TO_DECODE_IMAGE" | "FACE_DETECTION_ERROR" | "FACE_WITHOUT_EMBEDDING_CONFIDENCE"[];
  /**
   * Indicates whether the user's face has been successfully enrolled on this
   * device. See go/face-match-server-design for more info.
   */
  faceEnrollmentStatus?:  | "UNKNOWN_STATUS" | "SUCCESS" | "FAILURE" | "PENDING";
  /**
   * Indicates whether the user has enabled Face Match for this device. See
   * go/face-match-server-design for more info on this project.
   */
  faceMatchEnabled?: boolean;
  /**
   * When true, allow data collection of audio on this device for Federated
   * Learning.
   */
  flAudioCacheEnabled?: boolean;
  /**
   * When true, allow data collection of frames on this device.
   */
  flVisualFramesCacheEnabled?: boolean;
  /**
   * Stores GCM info associated with a device. See go/quartz-design-doc for
   * more info.
   */
  gcmSettings?: AssistantApiSettingsGcmSettings;
  /**
   * Holds the data that should be written to HomeGraph. Note: this field is
   * not persisted in Assistant Settings storage. It is simply used for
   * transporting data when client calls UpdateSettings.
   */
  homeGraphData?: AssistantApiSettingsHomeGraphData;
  /**
   * The home graph ID that can be used to lookup the corresponding entry in
   * HomeGraph. go/home-graph. Note: when this field is empty, it doesn't
   * necessarily mean that the device is not in home graph. It just means that
   * Assistant doesn't know about the mapping.
   */
  homeGraphId?: string;
  /**
   * Indicates whether the device is currently in Hospitality mode.
   * go/hospitality-mode-design. This is moved to a per user setting in
   * assistant settings. ref. go/hospitality-settings-v2
   */
  hospitalityModeStatus?: AssistantApiSettingsHospitalityMode;
  /**
   * The level of hotword sensitivity. go/hotword-sensitivity-prd
   */
  hotwordSensitivity?:  | "UNKNOWN_HOTWORD_SENSITIVITY" | "HOTWORD_SENSITIVITY_LOW" | "HOTWORD_SENSITIVITY_NORMAL" | "HOTWORD_SENSITIVITY_HIGH" | "HOTWORD_SENSITIVITY_LOW_2" | "HOTWORD_SENSITIVITY_HIGH_2";
  /**
   * HotwordThresholdAdjustmentFactor contains threshold_adjustment_factor, and
   * it's validity. TAF is a measure of adjustment applied to the hotword
   * threshold as a result of go/autotune. Currently, this is updated from
   * query_settings_frame, but if we move to updating it from the client, this
   * could also contain TAFs as a result of Hotword Sensitivity, in addition to
   * Autotune.
   */
  hotwordThresholdAdjustmentFactor?: AssistantApiSettingsHotwordThresholdAdjustmentFactor;
  /**
   * The human-friendly name of the cast device, e.g., my living room tv. This
   * field is set by the user and already localized.
   */
  humanFriendlyName?: string;
  /**
   * Internal version of the DeviceSettings for measurement of the
   * DeviceSettings mutation race conditions. See
   * go/consistent-assistant-settings-update.
   */
  internalVersion?: AssistantApiSettingsInternalVersion;
  /**
   * Indicates whether the device is also managed through HA cloud sync.
   * go/ha-dev-guide
   */
  isCloudSyncDevice?: boolean;
  /**
   * When true, the user has explicitly allowed audio and visual data
   * collection on this device
   */
  isDeviceActivationCacheEnabled?: boolean;
  /**
   * Specifies if kids-mode is enabled for the device. See
   * go/aff-parentalsupervision-dd.
   */
  kidsMode?: AssistantApiSettingsKidsMode;
  /**
   * Device's latest registration timestamp provided by Cast side. This field
   * is not necessarily up to date. The update frequency is defined in
   * last_registration_update_frequency_in_days field of AssistantConfig in
   * java/com/google/chrome/dongle/common/proto/home_assistant_config.proto.
   * go/cast-last-registration-time
   */
  lastCastRegistrationTimestamp?: Date;
  /**
   * Coarsened hourly timestamp of when the device was last used.
   */
  lastUsedCoarseTimestamp?: Date;
  /**
   * Stores pairing between different devices. See go/quartz-design-doc for
   * more info.
   */
  linkedDeviceId?: AssistantApiCoreTypesDeviceId[];
  /**
   * Please do NOT use this field without prior approval from PWG. Users who
   * have signed in onto this device, go/linked-users-in-pkg.
   */
  linkedUsers?: AssistantApiSettingsLinkedUser[];
  /**
   * The locale for the device: language + region, i.e., en-US, ja-JP.
   */
  locale?: string;
  /**
   * Coordinate information of the device location.
   */
  locationCoordinates?: AssistantApiCoreTypesLocationCoordinates;
  /**
   * The feature proto of the location of the device. Note: client does not
   * need to populate this. It will be auto-populated based on "address" field
   * on server side. Currently, only "bound" and "type" are persisted, since the
   * entire FeatureProto is too big.
   */
  locationFeature?: GeostoreFeatureProto;
  /**
   * See go/marketplace-disclosure for more info.
   */
  marketplaceDisclosure?: AssistantApiSettingsMarketplaceDisclosure;
  masqueradeMode?: AssistantApiSettingsMasqueradeMode;
  /**
   * Information about how to send the user a notification. This won't be
   * populated for fb-conv users (allo group chat users).
   */
  notificationProfile?: AssistantApiSettingsNotificationProfile;
  /**
   * OAuth client id for the device. This field is available for Assistant SDK
   * devices. It is written when the device is registered to the user
   * (AssistantSettingsUiService.LinkAssistantDeviceUi). When user revokes grant
   * on the Assistant device, Assistant Devices Platform Service will receive
   * Pubsub notification with OAuth client id for the revoked device, and we
   * will compare that with this stored id to identity device to remove.
   */
  oauthClientId?: string;
  /**
   * Device specific app related settings.
   */
  onDeviceAppSettings?: AssistantApiSettingsOnDeviceAppSettings;
  /**
   * Specifies if device logs and crashes can be captured during SendFeedback
   */
  optInStatus?: AssistantApiSettingsDeviceLogsOptIn;
  /**
   * DEPRECATED: Use DeviceCapabilities.OutputRestrictions.personal_data
   * instead. Whether the user has enabled payments for this device.
   */
  paymentsEnabled?: boolean;
  /**
   * Metadata about how personalization settings were configured.
   */
  personalizationMetadata?: AssistantApiSettingsPersonalizationMetadata;
  /**
   * Specify whether polite mode is enabled for this device. See
   * go/pretty-please-dd.
   */
  politeMode?: AssistantApiSettingsPoliteMode;
  postalCode?: string;
  /**
   * Trusted device preferences Assistant reauth.
   * go/assistant-reauth-verify-skip.
   */
  reauthTrustedDeviceSettings?: AssistantApiSettingsReauthTrustedDeviceSettings;
  /**
   * A human-readable shortened address. This is usually the street address.
   * Note: client does not need to populate this. It will be auto-populated
   * based on "address" field on server side. Developers can use this field to
   * avoid reading out the full address everytime.
   */
  shortenedAddress?: string;
  /**
   * Indicates whether the user has enabled speaker-id for this device. See
   * go/google-assistant-multi-user for more info on this project.
   */
  speakerIdEnabled?: boolean;
  /**
   * Settings related to TTS output.
   */
  speechOutputSettings?: AssistantApiSettingsSpeechOutputSettings;
  /**
   * Speech/hotword detection related settings.
   */
  speechSettings?: AssistantApiSettingsSpeechSettings;
  /**
   * Restrictions on how and when certain users can use a device. See
   * go/home-ft-prd.
   */
  supervisionSettings?: AssistantApiSettingsDeviceSupervisionSettings;
  /**
   * The type of assistant surface. Only use this field when device type is
   * ASSISTANT.
   */
  surfaceType?: AssistantApiCoreTypesSurfaceType;
  /**
   * Presence indicates a tethered wearable. go/wearable-device-ids.
   */
  tetheredInfo?: AssistantApiSettingsTetheredInfo;
  /**
   * Device time zone. It's mainly used for a one-time notification for new
   * users when they just bought and activated their devices. They may not have
   * used Search or Assistant before, so their timezone info may not available
   * elsewhere when we want to send a notification. This should be used as a
   * fallback only when other timezone sources such as
   * assistant_settings:user_attribute#inferred_user_timezone are not available.
   * Also, when both |time_zone| and |location| are set, the |location| should
   * be preferred to derive the most up to date timezone. This info directly
   * comes from the device through early device setting recording mechanism. See
   * more details at go/early-device-setting-recording.
   */
  timeZone?: AssistantApiTimeZone;
  /**
   * Local network ID of the device (truncated to obfuscate devices and
   * households globally). This is a temporary signal to determine proximity of
   * Assistant devices in a house (HGS place).
   */
  truncatedLocalNetworkId?: string;
  /**
   * DEPRECATED: Use speech_settings instead. Indicates whether the user has
   * enabled trusted voice for this device. See go/hotword-settings-on-cloud for
   * more info on this project.
   */
  trustedVoiceEnabled?: boolean;
  /**
   * The type of the device. Note: this should only be used for grouping
   * devices for UI presentation purpose. Use |capabilities| to decide what the
   * device can do.
   */
  type?:  | "UNKNOWN_DEVICE_TYPE" | "ASSISTANT" | "HOME_AUTOMATION" | "CAST" | "CAST_GROUP" | "QUARTZ" | "QUARTZ_IOS" | "CLOUD_AUTO";
  /**
   * Indicates whether to play verbose tts for Elementary on chirp. See:
   * go/opa-cast-a11y-impl-design fore more info on this project. Note: this
   * should probably be in SpeechOutputSetting below.
   */
  verboseTtsForChromecastEnabled?: boolean;
  /**
   * Coarsened hourly timestamp of when the user was last verified by
   * VoiceMatch on this device. This is used for enforcing VoiceMatch model TTL.
   * go/voicematch-pdd-ttl
   */
  vmLastUsedCoarseTimestamp?: Date;
  /**
   * Indicates whether the user's voice has been successfully enrolled on this
   * device.
   */
  voiceEnrollmentStatus?:  | "VOICE_ENROLLMENT_UNKNOWN_STATUS" | "VOICE_ENROLLMENT_SUCCESS" | "VOICE_ENROLLMENT_FAILURE" | "VOICE_ENROLLMENT_PENDING";
  /**
   * A boolean indicates whether voice input (mic-button, hotword, etc) is
   * enabled.
   */
  voiceInputEnabled?: boolean;
}

function serializeAssistantApiSettingsDeviceSettings(data: any): AssistantApiSettingsDeviceSettings {
  return {
    ...data,
    capabilities: data["capabilities"] !== undefined ? serializeAssistantApiDeviceCapabilities(data["capabilities"]) : undefined,
    creationTimestampMs: data["creationTimestampMs"] !== undefined ? String(data["creationTimestampMs"]) : undefined,
    crossSurfaceAvailability: data["crossSurfaceAvailability"] !== undefined ? serializeAssistantApiSettingsDeviceSettingsCrossSurfaceAvailability(data["crossSurfaceAvailability"]) : undefined,
    hospitalityModeStatus: data["hospitalityModeStatus"] !== undefined ? serializeAssistantApiSettingsHospitalityMode(data["hospitalityModeStatus"]) : undefined,
    internalVersion: data["internalVersion"] !== undefined ? serializeAssistantApiSettingsInternalVersion(data["internalVersion"]) : undefined,
    lastCastRegistrationTimestamp: data["lastCastRegistrationTimestamp"] !== undefined ? data["lastCastRegistrationTimestamp"].toISOString() : undefined,
    lastUsedCoarseTimestamp: data["lastUsedCoarseTimestamp"] !== undefined ? data["lastUsedCoarseTimestamp"].toISOString() : undefined,
    linkedUsers: data["linkedUsers"] !== undefined ? data["linkedUsers"].map((item: any) => (serializeAssistantApiSettingsLinkedUser(item))) : undefined,
    locationFeature: data["locationFeature"] !== undefined ? serializeGeostoreFeatureProto(data["locationFeature"]) : undefined,
    marketplaceDisclosure: data["marketplaceDisclosure"] !== undefined ? serializeAssistantApiSettingsMarketplaceDisclosure(data["marketplaceDisclosure"]) : undefined,
    masqueradeMode: data["masqueradeMode"] !== undefined ? serializeAssistantApiSettingsMasqueradeMode(data["masqueradeMode"]) : undefined,
    notificationProfile: data["notificationProfile"] !== undefined ? serializeAssistantApiSettingsNotificationProfile(data["notificationProfile"]) : undefined,
    reauthTrustedDeviceSettings: data["reauthTrustedDeviceSettings"] !== undefined ? serializeAssistantApiSettingsReauthTrustedDeviceSettings(data["reauthTrustedDeviceSettings"]) : undefined,
    vmLastUsedCoarseTimestamp: data["vmLastUsedCoarseTimestamp"] !== undefined ? data["vmLastUsedCoarseTimestamp"].toISOString() : undefined,
  };
}

function deserializeAssistantApiSettingsDeviceSettings(data: any): AssistantApiSettingsDeviceSettings {
  return {
    ...data,
    capabilities: data["capabilities"] !== undefined ? deserializeAssistantApiDeviceCapabilities(data["capabilities"]) : undefined,
    creationTimestampMs: data["creationTimestampMs"] !== undefined ? BigInt(data["creationTimestampMs"]) : undefined,
    crossSurfaceAvailability: data["crossSurfaceAvailability"] !== undefined ? deserializeAssistantApiSettingsDeviceSettingsCrossSurfaceAvailability(data["crossSurfaceAvailability"]) : undefined,
    hospitalityModeStatus: data["hospitalityModeStatus"] !== undefined ? deserializeAssistantApiSettingsHospitalityMode(data["hospitalityModeStatus"]) : undefined,
    internalVersion: data["internalVersion"] !== undefined ? deserializeAssistantApiSettingsInternalVersion(data["internalVersion"]) : undefined,
    lastCastRegistrationTimestamp: data["lastCastRegistrationTimestamp"] !== undefined ? new Date(data["lastCastRegistrationTimestamp"]) : undefined,
    lastUsedCoarseTimestamp: data["lastUsedCoarseTimestamp"] !== undefined ? new Date(data["lastUsedCoarseTimestamp"]) : undefined,
    linkedUsers: data["linkedUsers"] !== undefined ? data["linkedUsers"].map((item: any) => (deserializeAssistantApiSettingsLinkedUser(item))) : undefined,
    locationFeature: data["locationFeature"] !== undefined ? deserializeGeostoreFeatureProto(data["locationFeature"]) : undefined,
    marketplaceDisclosure: data["marketplaceDisclosure"] !== undefined ? deserializeAssistantApiSettingsMarketplaceDisclosure(data["marketplaceDisclosure"]) : undefined,
    masqueradeMode: data["masqueradeMode"] !== undefined ? deserializeAssistantApiSettingsMasqueradeMode(data["masqueradeMode"]) : undefined,
    notificationProfile: data["notificationProfile"] !== undefined ? deserializeAssistantApiSettingsNotificationProfile(data["notificationProfile"]) : undefined,
    reauthTrustedDeviceSettings: data["reauthTrustedDeviceSettings"] !== undefined ? deserializeAssistantApiSettingsReauthTrustedDeviceSettings(data["reauthTrustedDeviceSettings"]) : undefined,
    vmLastUsedCoarseTimestamp: data["vmLastUsedCoarseTimestamp"] !== undefined ? new Date(data["vmLastUsedCoarseTimestamp"]) : undefined,
  };
}

export interface AssistantApiSettingsDeviceSettingsCrossSurfaceAvailability {
  /**
   * Last known locale of the client.
   */
  lastKnownClientLocale?: string;
  /**
   * This is the timestamp when the AssistantRequestParams (in
   * ASSISTANT_SNAPSHOT corpus) were last written for this device.
   */
  lastParamsWriteTimestamp?: Date;
}

function serializeAssistantApiSettingsDeviceSettingsCrossSurfaceAvailability(data: any): AssistantApiSettingsDeviceSettingsCrossSurfaceAvailability {
  return {
    ...data,
    lastParamsWriteTimestamp: data["lastParamsWriteTimestamp"] !== undefined ? data["lastParamsWriteTimestamp"].toISOString() : undefined,
  };
}

function deserializeAssistantApiSettingsDeviceSettingsCrossSurfaceAvailability(data: any): AssistantApiSettingsDeviceSettingsCrossSurfaceAvailability {
  return {
    ...data,
    lastParamsWriteTimestamp: data["lastParamsWriteTimestamp"] !== undefined ? new Date(data["lastParamsWriteTimestamp"]) : undefined,
  };
}

export interface AssistantApiSettingsDeviceSupervisionSettings {
  /**
   * Specification of times that a device shouldn't respond to certain users.
   * See go/home-ft-prd.
   */
  downtimeSettings?: AssistantApiSettingsDeviceDowntimeSettings;
  /**
   * Restrictions on features that certain users can access on a device. See
   * go/home-ft-prd.
   */
  featureFilters?: AssistantApiSettingsDeviceFeatureFilters;
}

/**
 * Specifies a period of up to 24 hours when downtime should be enabled,
 * starting at certain time on a certain day of the week, and ending at a later
 * time on either that day or the following day.
 */
export interface AssistantApiSettingsDowntimePeriod {
  /**
   * True if downtime should be enabled during this period.
   */
  enabled?: boolean;
  /**
   * Time of day that this downtime period should end. Required. If end_time >
   * start_time, end_time is relative to start_day. Otherwise, end_time is
   * relative to the day after start_day. For example, start_day: MONDAY,
   * start_time: 9 p.m., end_time: 6 a.m. means that the downtime period starts
   * at 9 p.m. on Monday and ends at 6 a.m. on Tuesday.
   */
  endTime?: GoogleTypeTimeOfDay;
  /**
   * The day of the week when this downtime period starts. Required.
   */
  startDay?:  | "DAY_OF_WEEK_UNSPECIFIED" | "MONDAY" | "TUESDAY" | "WEDNESDAY" | "THURSDAY" | "FRIDAY" | "SATURDAY" | "SUNDAY";
  /**
   * Time of day that this downtime period should start. Required.
   */
  startTime?: GoogleTypeTimeOfDay;
}

/**
 * Specification of when downtime is enabled on different days of the week.
 * Contains up to 7 DowntimePeriod messages, up to one per day of the week.
 */
export interface AssistantApiSettingsDowntimeSchedule {
  /**
   * True if this downtime schedule should be enabled.
   */
  enabled?: boolean;
  /**
   * Downtime entries for the days of the week, in no particular order. There
   * can be at most one period defined for each day of the week. Days of the
   * week with no explicit period defined are treated as disabled, so the device
   * is available all day (modulo an end time that may spill over from the
   * previous day).
   */
  periods?: AssistantApiSettingsDowntimePeriod[];
}

/**
 * Duo related call settings on the device. Next ID: 5
 */
export interface AssistantApiSettingsDuoCallDeviceSettings {
  /**
   * True if Duo Knock Kncok feature is enabled on the device.
   */
  allowKnockKnock?: boolean;
  /**
   * Boolean indicating if user has explicitly marked this device to be linked
   * or not. This bit is used in case where unexpected errors occur and we have
   * to check for account/device status and mark the device linked after
   * verification.
   */
  shouldBeLinked?: boolean;
  /**
   * The call state of the device (i.e. whether an Duo call account has been
   * setup on the device).
   */
  state?:  | "UNKNOWN_LINK_STATE" | "NOT_LINKED" | "LINKED" | "LINKED_WAITING" | "LINK_ERROR";
  /**
   * Client device settings: settings which are populated by client to give to
   * duocore. TalkBack is an accessibility service that helps blind and
   * vision-impaired users interact with their devices. Indicates whether
   * talkback is enabled for the device. Note: this is per device settings
   * currently filled by client for all users.
   */
  talkbackEnabled?: boolean;
}

/**
 * Specification of which assistant features are allowed for a particular
 * device or user account.
 */
export interface AssistantApiSettingsFeatureFilters {
  communicationsFilter?: AssistantApiSettingsCommunicationsFilter;
  musicFilter?: AssistantApiSettingsMusicFilter;
  newsFilter?: AssistantApiSettingsNewsFilter;
  podcastFilter?: AssistantApiSettingsPodcastFilter;
  searchFilter?: AssistantApiSettingsSearchFilter;
  thirdPartyAppsFilter?: AssistantApiSettingsThirdPartyAppsFilter;
  videoFilter?: AssistantApiSettingsVideoFilter;
  webviewFilter?: AssistantApiSettingsWebviewFilter;
}

export interface AssistantApiSettingsGcmSettings {
  gcmId?: string;
  gcmPackage?: string;
}

/**
 * Next ID: 8
 */
export interface AssistantApiSettingsHomeGraphData {
  /**
   * Agent ID, aka project ID. Used as the AgentDeviceId.agent_id of device
   * when calling Home Graph Service.
   */
  agentId?: string;
  /**
   * See go/ha-dev-guide and HomeGraphItem.attribute in
   * //assistant/verticals/homeautomation/proto/home_graph.proto
   */
  attributes?: {
    [key: string]: any
  };
  /**
   * Device ID, used as AgentDeviceId.device_id of device when calling Home
   * Graph Service.
   */
  deviceId?: string;
  /**
   * HGS device type. See
   * java/com/google/home/graph/service/config/protoconf.pi for the exhaustive
   * list of type strings.
   */
  deviceType?: string;
  /**
   * Whether device data should be written to Home Graph via Assistant
   * device_settings. Assistant SDK and Google Home write their devices into
   * Home Graph through AssistantSettingsService, while Home Automation Partner
   * devices (e.g. SmartThings, Philips Hue, Nest, TP-Link, etc.) don't need to
   * be written to Home Graph through AssistantSettingsService. This field
   * decides whether AssistantSettingsService writes devices to Home Graph or
   * not.
   */
  shouldWriteToHomeGraph?: boolean;
  /**
   * Supported traits of the device. See
   * java/com/google/home/graph/service/config/protoconf.pi for the exhaustive
   * list of trait-strings.
   */
  supportedTraits?: string[];
  /**
   * Whether the device supports direct response. See
   * HomeGraphItem.supports_direct_response in
   * //assistant/verticals/homeautomation/proto/home_graph.proto
   */
  supportsDirectResponse?: boolean;
}

export interface AssistantApiSettingsHospitalityCardSettings {
  /**
   * Config for Hospitality UI modules.
   */
  cardConfig?: AssistantApiSettingsHospitalityCardSettingsCardConfig[];
  /**
   * Toggle media tap gesture tutorial card.
   */
  showMediaTapGestureTutorial?: boolean;
  /**
   * Toggle photo swipe gesture tutorial card.
   */
  showPhotoSwipeGestureTutorial?: boolean;
  /**
   * Config for YouTube video cards.
   */
  youtubeCardConfig?: AssistantApiSettingsHospitalityCardSettingsYouTubeCardConfig[];
}

function serializeAssistantApiSettingsHospitalityCardSettings(data: any): AssistantApiSettingsHospitalityCardSettings {
  return {
    ...data,
    cardConfig: data["cardConfig"] !== undefined ? data["cardConfig"].map((item: any) => (serializeAssistantApiSettingsHospitalityCardSettingsCardConfig(item))) : undefined,
  };
}

function deserializeAssistantApiSettingsHospitalityCardSettings(data: any): AssistantApiSettingsHospitalityCardSettings {
  return {
    ...data,
    cardConfig: data["cardConfig"] !== undefined ? data["cardConfig"].map((item: any) => (deserializeAssistantApiSettingsHospitalityCardSettingsCardConfig(item))) : undefined,
  };
}

/**
 * Configuration for hospitality card.
 */
export interface AssistantApiSettingsHospitalityCardSettingsCardConfig {
  /**
   * Whether the UI module requires user action. If true, the UI module can
   * peek on to the top of Ambient. See
   * SmartDisplayModuleState::ACTIVE_ACTION_REQUIRED.
   */
  activeActionRequired?: boolean;
  /**
   * Whether the UI module is dismissable.
   */
  dismissable?: boolean;
  /**
   * The time that the module is effective and visible to the user. If not set,
   * the module is effective immediately.
   */
  effectiveTime?: AssistantApiTimestamp;
  /**
   * The time that the module is expired and invisible to the user. If not set,
   * the module never expires.
   */
  expiryTime?: AssistantApiTimestamp;
  /**
   * The image URL for the UI module.
   */
  imageUrl?: string;
  /**
   * Module ID.
   */
  moduleId?:  | "UNKNOWN" | "MID_STAY_SURVEY" | "CHECK_OUT" | "CHECK_IN" | "RESET";
  /**
   * Payload query to the partner AoG action when user responds to UI Module,
   * e.g. Tell the hotel how my stay is going.
   */
  payloadQuery?: string;
  /**
   * Title of the message to be shown to user at the top of the UI Module.
   */
  title?: string;
}

function serializeAssistantApiSettingsHospitalityCardSettingsCardConfig(data: any): AssistantApiSettingsHospitalityCardSettingsCardConfig {
  return {
    ...data,
    effectiveTime: data["effectiveTime"] !== undefined ? serializeAssistantApiTimestamp(data["effectiveTime"]) : undefined,
    expiryTime: data["expiryTime"] !== undefined ? serializeAssistantApiTimestamp(data["expiryTime"]) : undefined,
  };
}

function deserializeAssistantApiSettingsHospitalityCardSettingsCardConfig(data: any): AssistantApiSettingsHospitalityCardSettingsCardConfig {
  return {
    ...data,
    effectiveTime: data["effectiveTime"] !== undefined ? deserializeAssistantApiTimestamp(data["effectiveTime"]) : undefined,
    expiryTime: data["expiryTime"] !== undefined ? deserializeAssistantApiTimestamp(data["expiryTime"]) : undefined,
  };
}

/**
 * Configuration for YouTube video card (Stargazer tile).
 */
export interface AssistantApiSettingsHospitalityCardSettingsYouTubeCardConfig {
  /**
   * URL of image to go on card. The URL must be a public link accessible from
   * ZeroState.
   */
  imageUrl?: string;
  /**
   * ID of YouTube playlist to play on card tap. A playlist is used instead of
   * a single video id to avoid autoplaying related videos. The playlist and the
   * videos it contains must be public or unlisted to be accessible from
   * ZeroState.
   */
  playlistId?: string;
  /**
   * Text on card (i.e., video title).
   */
  text?: string;
}

/**
 * Hospitality mode config for the current device. go/hospitality-mode-design.
 * Next ID: 17
 */
export interface AssistantApiSettingsHospitalityMode {
  /**
   * List of AOG app context ids that are linked to this device. These apps
   * will have access to the structure information for the device.
   */
  aogContextId?: string[];
  /**
   * Invocation phrase for hotel's AoG action. Used for ZS promotion card and
   * "talk to my hotel" rewrites. Setting this to an empty value will mark it
   * unset.
   */
  aogInvocationPhrase?: string;
  branding?: AssistantApiSettingsHospitalityModeBranding;
  cardSettings?: AssistantApiSettingsHospitalityCardSettings;
  /**
   * The time when we received a request to reset the device.
   */
  deviceClearRequest?: AssistantApiTimestamp;
  /**
   * Should the dialog have a shorter ttl. See
   * go/ipp-consumer-prd#heading=h.ibu9b1ysdl4t and
   * go/interpreter-device-clear#bookmark=id.hw8ey1bzjadn for context.
   */
  dialogTtlOverrideMicros?: bigint;
  /**
   * Identifier for the enterprise which owns the device. Setting this to an
   * empty value will mark it unset.
   */
  enterpriseId?: string;
  /**
   * Indicates whether this device is in the hospitality mode.
   */
  hospitalityModeEnabled?: boolean;
  /**
   * Last time the device was cleared and placed in hospitality mode. Will be
   * set when the switch is toggled on and reset when a guest checks out. On the
   * device this triggers removing alarms, timers, etc.
   */
  lastDeviceClear?: AssistantApiTimestamp;
  /**
   * Indicates when hospitality settings were last updated.
   */
  lastModifiedTimestamp?: AssistantApiTimestamp;
  /**
   * Last time the welcome message was played for the guest. If last_welcomed <
   * welcome_request, the message should be replayed and this time set.
   */
  lastWelcomed?: AssistantApiTimestamp;
  /**
   * Indicates whether or not the device must be reset manually (by voice or
   * touch), as opposed to being automatically reset.
   * go/hospitality-manual-reset
   */
  manualResetRequired?: boolean;
  /**
   * In order promoted languages for interpreter devices. This represents
   * languages by BCP-47 language strings, such as "en", "en-US", "fr", "fr-CA",
   * "sr-Latn", "zh-Hans-CN", "zh-Hant-HK",etc.
   */
  promotedLanguages?: string[];
  type?:  | "UNKNOWN_TYPE" | "HOTEL_ROOM" | "INTERPRETER" | "SENIOR_LIVING_ROOM" | "RETAIL_DEMO";
  /**
   * Whether we allow users to initiate clearing the device verbally. We
   * generally allow this for private devices and not for public ones.
   */
  verbalResetSupported?: boolean;
  /**
   * The time when we received a request to welcome the user.
   */
  welcomeRequest?: AssistantApiTimestamp;
}

function serializeAssistantApiSettingsHospitalityMode(data: any): AssistantApiSettingsHospitalityMode {
  return {
    ...data,
    cardSettings: data["cardSettings"] !== undefined ? serializeAssistantApiSettingsHospitalityCardSettings(data["cardSettings"]) : undefined,
    deviceClearRequest: data["deviceClearRequest"] !== undefined ? serializeAssistantApiTimestamp(data["deviceClearRequest"]) : undefined,
    dialogTtlOverrideMicros: data["dialogTtlOverrideMicros"] !== undefined ? String(data["dialogTtlOverrideMicros"]) : undefined,
    lastDeviceClear: data["lastDeviceClear"] !== undefined ? serializeAssistantApiTimestamp(data["lastDeviceClear"]) : undefined,
    lastModifiedTimestamp: data["lastModifiedTimestamp"] !== undefined ? serializeAssistantApiTimestamp(data["lastModifiedTimestamp"]) : undefined,
    lastWelcomed: data["lastWelcomed"] !== undefined ? serializeAssistantApiTimestamp(data["lastWelcomed"]) : undefined,
    welcomeRequest: data["welcomeRequest"] !== undefined ? serializeAssistantApiTimestamp(data["welcomeRequest"]) : undefined,
  };
}

function deserializeAssistantApiSettingsHospitalityMode(data: any): AssistantApiSettingsHospitalityMode {
  return {
    ...data,
    cardSettings: data["cardSettings"] !== undefined ? deserializeAssistantApiSettingsHospitalityCardSettings(data["cardSettings"]) : undefined,
    deviceClearRequest: data["deviceClearRequest"] !== undefined ? deserializeAssistantApiTimestamp(data["deviceClearRequest"]) : undefined,
    dialogTtlOverrideMicros: data["dialogTtlOverrideMicros"] !== undefined ? BigInt(data["dialogTtlOverrideMicros"]) : undefined,
    lastDeviceClear: data["lastDeviceClear"] !== undefined ? deserializeAssistantApiTimestamp(data["lastDeviceClear"]) : undefined,
    lastModifiedTimestamp: data["lastModifiedTimestamp"] !== undefined ? deserializeAssistantApiTimestamp(data["lastModifiedTimestamp"]) : undefined,
    lastWelcomed: data["lastWelcomed"] !== undefined ? deserializeAssistantApiTimestamp(data["lastWelcomed"]) : undefined,
    welcomeRequest: data["welcomeRequest"] !== undefined ? deserializeAssistantApiTimestamp(data["welcomeRequest"]) : undefined,
  };
}

/**
 * TODO(b/169423976) Consider moving Branding out of user level settings into
 * enterprise level settings. Partner branding fields used to customize the ui.
 * Next ID: 7
 */
export interface AssistantApiSettingsHospitalityModeBranding {
  /**
   * Brand display in the UI
   */
  displayName?: string;
  /**
   * Brand display in the UI for languages that the enterprise has a localized
   * name that is different from its global branding name. For example, Hilton
   * is '' in Japanese and '' in Chinese. The keys are hospitality
   * supported display locales, e.g. en, ja-JP, etc, defined in experiment
   * parameter Hospitality__hospitality_display_supported_locales.
   */
  displayNameForLanguage?: {
    [key: string]: string
  };
  largeLogoUrl?: string;
  smallLogoUrl?: string;
}

/**
 * HotwordThresholdAdjustmentFactor contains threshold_adjustment_factor, and
 * it's validity. value should only be considered when is_valid = true.
 */
export interface AssistantApiSettingsHotwordThresholdAdjustmentFactor {
  /**
   * Currently, is_valid is set to false whenever the TAF is not an Autotune
   * aware value. This includes hotword sensitivity users, or devices not
   * eligible for autotune.
   */
  isValid?: boolean;
  value?: number;
}

/**
 * Represents supporting device ids.
 */
export interface AssistantApiSettingsInternalAncillaryDeviceId {
  /**
   * Contains device ids known to devices. eg. For ATV, it contains
   * client_instance_id and cast_id.
   */
  deviceId?: AssistantApiCoreTypesDeviceId;
}

/**
 * Represents a version of a specifit setting, e.g. DeviceSettings.
 */
export interface AssistantApiSettingsInternalVersion {
  /**
   * Contains the timestamp when this version was generated.
   */
  generationTime?: Date;
  /**
   * Integer value of the version, it is a monotonically increasing number and
   * starts at 0. On every update it is incremented by 1.
   */
  id?: bigint;
}

function serializeAssistantApiSettingsInternalVersion(data: any): AssistantApiSettingsInternalVersion {
  return {
    ...data,
    generationTime: data["generationTime"] !== undefined ? data["generationTime"].toISOString() : undefined,
    id: data["id"] !== undefined ? String(data["id"]) : undefined,
  };
}

function deserializeAssistantApiSettingsInternalVersion(data: any): AssistantApiSettingsInternalVersion {
  return {
    ...data,
    generationTime: data["generationTime"] !== undefined ? new Date(data["generationTime"]) : undefined,
    id: data["id"] !== undefined ? BigInt(data["id"]) : undefined,
  };
}

/**
 * Kids mode config for the current device. go/aff-parentalsupervision-dd
 */
export interface AssistantApiSettingsKidsMode {
  kidsModeEnabled?: boolean;
  /**
   * Identifier of the account currently specified to be used with kids mode.
   */
  obfuscatedGaiaId?: string;
}

export interface AssistantApiSettingsLabeledDowntimeSchedule {
  /**
   * User-provided name for this schedule.
   */
  displayName?: string;
  schedule?: AssistantApiSettingsDowntimeSchedule;
}

/**
 * Represents the profile of the user who has signed in onto this device. Next
 * id: 5
 */
export interface AssistantApiSettingsLinkedUser {
  /**
   * Time of linking of the device with the user provided by Cast.
   */
  castLinkingTime?: Date;
  /**
   * Primary email address of the user.
   */
  email?: string;
  gaiaId?: bigint;
  /**
   * Supports features which depend on profile name, when no matching contact
   * is found.
   */
  names?: AppsPeopleOzExternalMergedpeopleapiName[];
}

function serializeAssistantApiSettingsLinkedUser(data: any): AssistantApiSettingsLinkedUser {
  return {
    ...data,
    castLinkingTime: data["castLinkingTime"] !== undefined ? data["castLinkingTime"].toISOString() : undefined,
    gaiaId: data["gaiaId"] !== undefined ? String(data["gaiaId"]) : undefined,
    names: data["names"] !== undefined ? data["names"].map((item: any) => (serializeAppsPeopleOzExternalMergedpeopleapiName(item))) : undefined,
  };
}

function deserializeAssistantApiSettingsLinkedUser(data: any): AssistantApiSettingsLinkedUser {
  return {
    ...data,
    castLinkingTime: data["castLinkingTime"] !== undefined ? new Date(data["castLinkingTime"]) : undefined,
    gaiaId: data["gaiaId"] !== undefined ? BigInt(data["gaiaId"]) : undefined,
    names: data["names"] !== undefined ? data["names"].map((item: any) => (deserializeAppsPeopleOzExternalMergedpeopleapiName(item))) : undefined,
  };
}

export interface AssistantApiSettingsMarketplaceDisclosure {
  /**
   * True if the user has confirmed the marketplace disclosure.
   */
  confirmed?: boolean;
  /**
   * The time user confirmed the marketplace disclosure.
   */
  timestampMs?: bigint;
}

function serializeAssistantApiSettingsMarketplaceDisclosure(data: any): AssistantApiSettingsMarketplaceDisclosure {
  return {
    ...data,
    timestampMs: data["timestampMs"] !== undefined ? String(data["timestampMs"]) : undefined,
  };
}

function deserializeAssistantApiSettingsMarketplaceDisclosure(data: any): AssistantApiSettingsMarketplaceDisclosure {
  return {
    ...data,
    timestampMs: data["timestampMs"] !== undefined ? BigInt(data["timestampMs"]) : undefined,
  };
}

/**
 * Guest mode for the current device. go/assistant-guest-mode-summary
 */
export interface AssistantApiSettingsMasqueradeMode {
  lastEnterGuestModeTimestamp?: AssistantApiTimestamp;
  lastExitGuestModeTimestamp?: AssistantApiTimestamp;
  masqueradeModeEnabled?: boolean;
}

function serializeAssistantApiSettingsMasqueradeMode(data: any): AssistantApiSettingsMasqueradeMode {
  return {
    ...data,
    lastEnterGuestModeTimestamp: data["lastEnterGuestModeTimestamp"] !== undefined ? serializeAssistantApiTimestamp(data["lastEnterGuestModeTimestamp"]) : undefined,
    lastExitGuestModeTimestamp: data["lastExitGuestModeTimestamp"] !== undefined ? serializeAssistantApiTimestamp(data["lastExitGuestModeTimestamp"]) : undefined,
  };
}

function deserializeAssistantApiSettingsMasqueradeMode(data: any): AssistantApiSettingsMasqueradeMode {
  return {
    ...data,
    lastEnterGuestModeTimestamp: data["lastEnterGuestModeTimestamp"] !== undefined ? deserializeAssistantApiTimestamp(data["lastEnterGuestModeTimestamp"]) : undefined,
    lastExitGuestModeTimestamp: data["lastExitGuestModeTimestamp"] !== undefined ? deserializeAssistantApiTimestamp(data["lastExitGuestModeTimestamp"]) : undefined,
  };
}

/**
 * Specification of which music features can be used.
 */
export interface AssistantApiSettingsMusicFilter {
  /**
   * Providers available at the time user updated settings.
   */
  availableProviders?:  | "UNKNOWN_MUSIC_PROVIDER" | "YOUTUBE_MUSIC" | "GOOGLE_PLAY_MUSIC" | "SPOTIFY" | "APPLE_MUSIC" | "PANDORA"[];
  /**
   * Represents the state for the music provider filter.
   */
  providerFilterState?:  | "UNKNOWN_STATE" | "ALLOW_ALL_PROVIDERS" | "ALLOW_WHITELISTED_PROVIDERS";
  state?:  | "UNKNOWN_STATE" | "ALLOW_ALL" | "BLOCK_EXPLICIT" | "BLOCK_ALL";
  /**
   * Contains the list of whitelisted music providers.
   */
  whitelistedProviders?:  | "UNKNOWN_MUSIC_PROVIDER" | "YOUTUBE_MUSIC" | "GOOGLE_PLAY_MUSIC" | "SPOTIFY" | "APPLE_MUSIC" | "PANDORA"[];
}

/**
 * Specification of which news features can be used.
 */
export interface AssistantApiSettingsNewsFilter {
  state?:  | "UNKNOWN_STATE" | "ALLOW_ALL_NEWS" | "BLOCK_ALL_NEWS";
}

export interface AssistantApiSettingsNotificationProfile {
  /**
   * Each device can have only one type of notification profile.
   */
  alloNotificationProfile?: AssistantApiSettingsNotificationProfileAlloNotificationProfile;
}

function serializeAssistantApiSettingsNotificationProfile(data: any): AssistantApiSettingsNotificationProfile {
  return {
    ...data,
    alloNotificationProfile: data["alloNotificationProfile"] !== undefined ? serializeAssistantApiSettingsNotificationProfileAlloNotificationProfile(data["alloNotificationProfile"]) : undefined,
  };
}

function deserializeAssistantApiSettingsNotificationProfile(data: any): AssistantApiSettingsNotificationProfile {
  return {
    ...data,
    alloNotificationProfile: data["alloNotificationProfile"] !== undefined ? deserializeAssistantApiSettingsNotificationProfileAlloNotificationProfile(data["alloNotificationProfile"]) : undefined,
  };
}

export interface AssistantApiSettingsNotificationProfileAlloNotificationProfile {
  /**
   * The send token of the conversation with the user.
   */
  botSendToken?: ChatBotPlatformBotSendToken;
  /**
   * The fireball id of this user.
   */
  id?: ChatBotPlatformFireballId;
}

function serializeAssistantApiSettingsNotificationProfileAlloNotificationProfile(data: any): AssistantApiSettingsNotificationProfileAlloNotificationProfile {
  return {
    ...data,
    botSendToken: data["botSendToken"] !== undefined ? serializeChatBotPlatformBotSendToken(data["botSendToken"]) : undefined,
    id: data["id"] !== undefined ? serializeChatBotPlatformFireballId(data["id"]) : undefined,
  };
}

function deserializeAssistantApiSettingsNotificationProfileAlloNotificationProfile(data: any): AssistantApiSettingsNotificationProfileAlloNotificationProfile {
  return {
    ...data,
    botSendToken: data["botSendToken"] !== undefined ? deserializeChatBotPlatformBotSendToken(data["botSendToken"]) : undefined,
    id: data["id"] !== undefined ? deserializeChatBotPlatformFireballId(data["id"]) : undefined,
  };
}

export interface AssistantApiSettingsOnDeviceAppSettings {
  /**
   * On device carrier call related settings.
   */
  carrierCallDeviceSettings?: AssistantApiSettingsCarrierCallDeviceSettings;
  /**
   * On device duo call related settings.
   */
  duoCallDeviceSettings?: AssistantApiSettingsDuoCallDeviceSettings;
}

export interface AssistantApiSettingsPersonalizationMetadata {
  faceMatch?:  | "PERSONALIZATION_FLOW_UNKNOWN" | "PERSONALIZATION_FLOW_DEVICE" | "PERSONALIZATION_FLOW_TWOOBE" | "PERSONALIZATION_FLOW_SLA" | "PERSONALIZATION_FLOW_DEVICE_DELEGATED_CUSTODIO";
  personalResults?:  | "PERSONALIZATION_FLOW_UNKNOWN" | "PERSONALIZATION_FLOW_DEVICE" | "PERSONALIZATION_FLOW_TWOOBE" | "PERSONALIZATION_FLOW_SLA" | "PERSONALIZATION_FLOW_DEVICE_DELEGATED_CUSTODIO";
  voiceMatch?:  | "PERSONALIZATION_FLOW_UNKNOWN" | "PERSONALIZATION_FLOW_DEVICE" | "PERSONALIZATION_FLOW_TWOOBE" | "PERSONALIZATION_FLOW_SLA" | "PERSONALIZATION_FLOW_DEVICE_DELEGATED_CUSTODIO";
}

/**
 * Specification of which podcast features can be used.
 */
export interface AssistantApiSettingsPodcastFilter {
  state?:  | "UNKNOWN_STATE" | "ALLOW_ALL_PODCASTS" | "BLOCK_ALL_PODCASTS";
}

/**
 * Polite mode config for the current device. go/polite-mode-dd
 */
export interface AssistantApiSettingsPoliteMode {
  politeModeEnabled?: boolean;
}

/**
 * Settings related to Assistant reauth. go/assistant-reauth-verify-skip Next
 * id: 2
 */
export interface AssistantApiSettingsReauthTrustedDeviceSettings {
  /**
   * Mapping from integrator client id to device's trust settings. Id from
   * assistant/agent_platform/transactions/reauth/reauth_client.proto.
   */
  trustSettingsForClient?: {
    [key: string]: AssistantApiSettingsReauthTrustedDeviceSettingsTrustSettings
  };
}

function serializeAssistantApiSettingsReauthTrustedDeviceSettings(data: any): AssistantApiSettingsReauthTrustedDeviceSettings {
  return {
    ...data,
    trustSettingsForClient: data["trustSettingsForClient"] !== undefined ? Object.fromEntries(Object.entries(data["trustSettingsForClient"]).map(([k, v]: [string, any]) => ([k, serializeAssistantApiSettingsReauthTrustedDeviceSettingsTrustSettings(v)]))) : undefined,
  };
}

function deserializeAssistantApiSettingsReauthTrustedDeviceSettings(data: any): AssistantApiSettingsReauthTrustedDeviceSettings {
  return {
    ...data,
    trustSettingsForClient: data["trustSettingsForClient"] !== undefined ? Object.fromEntries(Object.entries(data["trustSettingsForClient"]).map(([k, v]: [string, any]) => ([k, deserializeAssistantApiSettingsReauthTrustedDeviceSettingsTrustSettings(v)]))) : undefined,
  };
}

/**
 * Next id: 6
 */
export interface AssistantApiSettingsReauthTrustedDeviceSettingsTrustSettings {
  /**
   * If true, don't ask user to trust this device again.
   */
  neverAskAgain?: boolean;
  /**
   * DEPRECATED: Use never_ask_again instead. Expiration timestamp of "never
   * ask again" status. If this field is set and is later than current
   * timestamp, we should NOT ask the user whether they'd like to trust this
   * device.
   */
  neverAskExpirationTimestamp?: Date;
  /**
   * Expiration timestamp of "trusted" status. If this field is set and is
   * later than current timestamp, we can consider this device to be trusted.
   */
  trustDeviceExpirationTimestamp?: Date;
}

function serializeAssistantApiSettingsReauthTrustedDeviceSettingsTrustSettings(data: any): AssistantApiSettingsReauthTrustedDeviceSettingsTrustSettings {
  return {
    ...data,
    neverAskExpirationTimestamp: data["neverAskExpirationTimestamp"] !== undefined ? data["neverAskExpirationTimestamp"].toISOString() : undefined,
    trustDeviceExpirationTimestamp: data["trustDeviceExpirationTimestamp"] !== undefined ? data["trustDeviceExpirationTimestamp"].toISOString() : undefined,
  };
}

function deserializeAssistantApiSettingsReauthTrustedDeviceSettingsTrustSettings(data: any): AssistantApiSettingsReauthTrustedDeviceSettingsTrustSettings {
  return {
    ...data,
    neverAskExpirationTimestamp: data["neverAskExpirationTimestamp"] !== undefined ? new Date(data["neverAskExpirationTimestamp"]) : undefined,
    trustDeviceExpirationTimestamp: data["trustDeviceExpirationTimestamp"] !== undefined ? new Date(data["trustDeviceExpirationTimestamp"]) : undefined,
  };
}

/**
 * Specification of which search features can be used.
 */
export interface AssistantApiSettingsSearchFilter {
  state?:  | "UNKNOWN_STATE" | "ALLOW_SAFE_SEARCH" | "BLOCK_SEARCH";
}

/**
 * Settings related to TTS output.
 */
export interface AssistantApiSettingsSpeechOutputSettings {
  speechOutput?:  | "UNSPECIFIED" | "VERBOSE" | "MIN_VERBOSITY" | "HANDS_FREE_ONLY";
}

/**
 * Settings related to speech detection. See go/hotword-settings-on-cloud for
 * more info. Next ID: 16
 */
export interface AssistantApiSettingsSpeechSettings {
  /**
   * Indicates whether Continued Conversation is enabled for this device.
   */
  continuedConversationEnabled?: boolean;
  /**
   * Stores the device model type e.g Pixel.
   */
  deviceModelType?: string;
  /**
   * Whether the device has DSP chip to enable always on hotword detection.
   */
  dspAvailable?: boolean;
  /**
   * Whether hotword has been enabled by the user during navigation.
   */
  hotwordInNavigationEnabled?:  | "UNAVAILABLE" | "ENABLED" | "DISABLED" | "UNDECIDED" | "OPA_DISABLED" | "UNSUPPORTED_LOCALE" | "INCOMPLETE" | "ENABLED_WITHOUT_OPA_AVAILABILITY";
  /**
   * Stores hotword setting status for the locales which don't support voice
   * match.
   */
  hotwordSetting?:  | "UNAVAILABLE" | "ENABLED" | "DISABLED" | "UNDECIDED" | "OPA_DISABLED" | "UNSUPPORTED_LOCALE" | "INCOMPLETE" | "ENABLED_WITHOUT_OPA_AVAILABILITY";
  /**
   * Whether pin/pattern lockscreen has been enabled by the user.
   */
  lockscreenEnabled?: boolean;
  /**
   * Stores if Assistant is available for the user's device/locale, where
   * Enabled means it is available and disabled means it is not.
   */
  opaEligibilityState?:  | "UNAVAILABLE" | "ENABLED" | "DISABLED" | "UNDECIDED" | "OPA_DISABLED" | "UNSUPPORTED_LOCALE" | "INCOMPLETE" | "ENABLED_WITHOUT_OPA_AVAILABILITY";
  /**
   * Stores if Assistant is available for the user's device/locale. Deprecated
   * as bools do not give accurate true/false ratios due to old clients
   * reporting the default value.
   */
  opaEligible?: boolean;
  /**
   * Stores the Android SDK version. This comes from
   * android.os.Build.VERSION.SDK_INT.
   */
  sdkVersion?: number;
  /**
   * Whether speaker ID model is present for the user.
   */
  speakerIdModelPresent?: boolean;
  /**
   * Indicates whether the user has enabled speaker-id (fromAnyScreen/alwaysOn)
   * for this device. Deprecated - use voice_match_setting instead
   */
  speakerIdRecognitionEnabled?: boolean;
  /**
   * Indicates whether the user has enabled trusted voice for this device.
   */
  trustedVoiceEnabled?: boolean;
  /**
   * A bool indicating whether device supports unlocking device with hotword.
   */
  unlockWithHotwordAvailable?: boolean;
  /**
   * Stores if user was migrated from undecided to declined as apart of Mariko
   * project. Used for potential growth targeting.
   */
  userMigratedToDeclined?: boolean;
  /**
   * Stores the hotword/voice match setting status for the locales which
   * support voice match.
   */
  voiceMatchSetting?:  | "UNAVAILABLE" | "ENABLED" | "DISABLED" | "UNDECIDED" | "OPA_DISABLED" | "UNSUPPORTED_LOCALE" | "INCOMPLETE" | "ENABLED_WITHOUT_OPA_AVAILABILITY";
}

export interface AssistantApiSettingsTetheredInfo {
  /**
   * The host this wearable is tethered to (e.g. phone). When host is AGSA then
   * this is agsa_client_instance_id. When host is IOPA then this is
   * opa_ios_device_id.
   */
  primaryHostDeviceId?: string;
}

/**
 * Specification of which third party apps can be used.
 */
export interface AssistantApiSettingsThirdPartyAppsFilter {
  state?:  | "UNKNOWN_STATE" | "ALLOW_ALL" | "ALLOW_CERTIFIED_FOR_FAMILIES" | "BLOCK_ALL";
}

/**
 * Specification of which video features can be used.
 */
export interface AssistantApiSettingsVideoFilter {
  /**
   * State that indicates whether autoplay is enabled for youtube videos.
   */
  autoplayToggleState?:  | "UNKNOWN_STATE" | "ENABLED" | "DISABLED";
  /**
   * Providers available at the time user updated settings.
   */
  availableProviders?:  | "UNKNOWN_VIDEO_PROVIDER" | "YOUTUBE" | "YOUTUBE_TV" | "YOUTUBE_KIDS"[];
  /**
   * Represents the state for the video provider filter.
   */
  providerFilterState?:  | "UNKNOWN_STATE" | "ALLOW_ALL_PROVIDERS" | "ALLOW_WHITELISTED_PROVIDERS";
  state?:  | "UNKNOWN_STATE" | "ALLOW_ALL" | "BLOCK_MATURE_CONTENT" | "BLOCK_ALL";
  /**
   * Contains the list of whitelisted video providers.
   */
  whitelistedProviders?:  | "UNKNOWN_VIDEO_PROVIDER" | "YOUTUBE" | "YOUTUBE_TV" | "YOUTUBE_KIDS"[];
}

/**
 * Specification of which webview features can be used.
 */
export interface AssistantApiSettingsWebviewFilter {
  /**
   * Indicates if user has consented Jasper warning message.
   */
  jasperWebviewConsent?: boolean;
  state?:  | "UNKNOWN_STATE" | "ALLOW_ALL_WEBSITES" | "BLOCK_ALL_WEBSITES";
}

/**
 * The method of sign in which the client supports.
 */
export interface AssistantApiSignInMethod {
  method?:  | "UNSPECIFIED" | "NOT_ALLOWED" | "PHONE_APP" | "ON_DEVICE_MENU" | "WEB_APP";
  /**
   * Make Google sign-in mandatory for using Google Assistant on the device.
   */
  signInRequired?: boolean;
}

/**
 * Capabilities related to SODA (Speech On-Device API). Next ID: 5
 */
export interface AssistantApiSodaCapabilities {
  /**
   * Whether the device supports different levels of hotword sensitivity.
   * go/hotword-sensitivity-prd
   */
  supportsHotwordSensitivity?: boolean;
  /**
   * Whether Simple Stop (go/simple-stop) is enabled on the device. Simple stop
   * allows users to stop firing alarms and timers by just saying "stop" without
   * first saying the hotword.
   */
  supportsSimpleStop?: boolean;
  /**
   * Whether the device supports speaker-id (speaker identification based on
   * hotword and/or spoken query - go/speaker-id). Note: there are existing
   * devices that support speaker-id but does not have this capability set. Not
   * having this field populated doesn't necessarily mean the device doesn't
   * support speaker-id.
   */
  supportsSpeakerId?: boolean;
  /**
   * Whether the device supports WarmWords (go/warm-words-framework).
   */
  supportsWarmWords?: boolean;
}

/**
 * These capabilities represent what software features the client supports.
 * This should be determined based on the client's various software versions
 * (OS, GSA version, etc). Next ID: 27
 */
export interface AssistantApiSoftwareCapabilities {
  /**
   * IMPORTANT: Only one of AppCapabilities and AppCapabilitiesDelta should be
   * in the SoftwareCapabilities. In the edge case if the client sends up both
   * AppCapabilities and AppCapabilitiesDelta, AppCapabilitiesDelta is ignored.
   * Complete list of app capabilities.
   */
  appCapabilities?: AssistantApiAppCapabilities[];
  /**
   * Incremental update for app capabilities.
   */
  appCapabilitiesDelta?: AssistantApiAppCapabilitiesDelta[];
  /**
   * App integrations settings for each packge name.
   */
  appIntegrationsSettings?: {
    [key: string]: AssistantApiAppIntegrationsSettings
  };
  /**
   * Capabilities related to Assistant on Auto surfaces.
   */
  carAssistantCapabilities?: AssistantApiCarAssistantCapabilities;
  /**
   * Capabilities related to clock functionality, like alarms, timers, etc.
   */
  clockCapabilities?: AssistantApiClockCapabilities;
  /**
   * A top-level version of Conversation protocol where the versions are
   * explicitly defined at go/conversation-versions.
   */
  conversationVersion?: AssistantApiSupportedConversationVersion;
  /**
   * For torus x-device execution support
   */
  crossDeviceExecutionCapabilities?: AssistantApiCrossDeviceExecutionCapability;
  gacsCapabilities?: AssistantApiGacsCapabilities;
  gcmCapabilities?: AssistantApiGcmCapabilities;
  /**
   * Google Home app features.
   */
  homeAppCapabilities?: AssistantApiCapabilitiesHomeAppCapabilities;
  /**
   * Capabilities related to live TV channels.
   */
  liveTvChannelCapabilities?: AssistantApiLiveTvChannelCapabilities;
  /**
   * List of actions OEM supports. This includes built-in actions and custom
   * actions.
   */
  oemCapabilities?: AssistantApiOemCapabilities;
  /**
   * on-device Assistant capabilities
   */
  onDeviceAssistantCapabilities?: AssistantApiOnDeviceAssistantCapabilities;
  /**
   * Capability bits for on-device Smart Home. go/framework-for-local-semex
   */
  onDeviceSmartHomeCapabilities?: AssistantApiOnDeviceSmartHomeCapabilities;
  /**
   * Reflects the storage capabilities on the device.
   */
  onDeviceStorageCapabilities?: AssistantApiOnDeviceStorageCapabilities;
  /**
   * The operating system of the device.
   */
  operatingSystem?:  | "OS_TYPE_UNKNOWN" | "OS_TYPE_ANDROID" | "OS_TYPE_CAST" | "OS_TYPE_FUCHSIA" | "OS_TYPE_LINUX";
  /**
   * An ordered list containing the live tv providers available in the client.
   * The order of the providers reflects the ranking in the client and will be
   * respected by server as well.
   */
  orderedLiveTvProviders?: AssistantApiLiveTvProvider[];
  /**
   * The Soli capabilities on Elaine. go/dingo-dc-software
   */
  selinaCapabilities?: AssistantApiSelinaCapabilites;
  settingsAppCapabilities?: AssistantApiSettingsAppCapabilities;
  supportedClientOp?: AssistantApiSupportedClientOp[];
  supportedFeatures?: AssistantApiSupportedFeatures;
  supportedMsgVersion?: AssistantApiSupportedProtocolVersion;
  supportedProviderTypes?: AssistantApiSupportedProviderTypes;
  surfaceProperties?: AssistantApiSurfaceProperties;
}

function serializeAssistantApiSoftwareCapabilities(data: any): AssistantApiSoftwareCapabilities {
  return {
    ...data,
    appCapabilities: data["appCapabilities"] !== undefined ? data["appCapabilities"].map((item: any) => (serializeAssistantApiAppCapabilities(item))) : undefined,
    appCapabilitiesDelta: data["appCapabilitiesDelta"] !== undefined ? data["appCapabilitiesDelta"].map((item: any) => (serializeAssistantApiAppCapabilitiesDelta(item))) : undefined,
    clockCapabilities: data["clockCapabilities"] !== undefined ? serializeAssistantApiClockCapabilities(data["clockCapabilities"]) : undefined,
    gacsCapabilities: data["gacsCapabilities"] !== undefined ? serializeAssistantApiGacsCapabilities(data["gacsCapabilities"]) : undefined,
    oemCapabilities: data["oemCapabilities"] !== undefined ? serializeAssistantApiOemCapabilities(data["oemCapabilities"]) : undefined,
    orderedLiveTvProviders: data["orderedLiveTvProviders"] !== undefined ? data["orderedLiveTvProviders"].map((item: any) => (serializeAssistantApiLiveTvProvider(item))) : undefined,
    supportedClientOp: data["supportedClientOp"] !== undefined ? data["supportedClientOp"].map((item: any) => (serializeAssistantApiSupportedClientOp(item))) : undefined,
    supportedFeatures: data["supportedFeatures"] !== undefined ? serializeAssistantApiSupportedFeatures(data["supportedFeatures"]) : undefined,
  };
}

function deserializeAssistantApiSoftwareCapabilities(data: any): AssistantApiSoftwareCapabilities {
  return {
    ...data,
    appCapabilities: data["appCapabilities"] !== undefined ? data["appCapabilities"].map((item: any) => (deserializeAssistantApiAppCapabilities(item))) : undefined,
    appCapabilitiesDelta: data["appCapabilitiesDelta"] !== undefined ? data["appCapabilitiesDelta"].map((item: any) => (deserializeAssistantApiAppCapabilitiesDelta(item))) : undefined,
    clockCapabilities: data["clockCapabilities"] !== undefined ? deserializeAssistantApiClockCapabilities(data["clockCapabilities"]) : undefined,
    gacsCapabilities: data["gacsCapabilities"] !== undefined ? deserializeAssistantApiGacsCapabilities(data["gacsCapabilities"]) : undefined,
    oemCapabilities: data["oemCapabilities"] !== undefined ? deserializeAssistantApiOemCapabilities(data["oemCapabilities"]) : undefined,
    orderedLiveTvProviders: data["orderedLiveTvProviders"] !== undefined ? data["orderedLiveTvProviders"].map((item: any) => (deserializeAssistantApiLiveTvProvider(item))) : undefined,
    supportedClientOp: data["supportedClientOp"] !== undefined ? data["supportedClientOp"].map((item: any) => (deserializeAssistantApiSupportedClientOp(item))) : undefined,
    supportedFeatures: data["supportedFeatures"] !== undefined ? deserializeAssistantApiSupportedFeatures(data["supportedFeatures"]) : undefined,
  };
}

/**
 * DEPRECATED These capabilties are associated with speech detection on
 * devices.
 */
export interface AssistantApiSpeechCapabilities {
  /**
   * A bool indicating whether device supports dsp based hotword detection.
   */
  dspAvailable?: boolean;
  /**
   * A bool indicating whether device supports unlocking device with hotword.
   */
  unlockWithHotwordAvailable?: boolean;
}

/**
 * Next ID: 18
 */
export interface AssistantApiSuggestionsSupport {
  /**
   * Whether client supports user impersonation on suggestion chip click.
   * go/suggestion-click-impersonation
   */
  clickImpersonationSupported?: boolean;
  /**
   * Whether client supports suggestions debug data to be displayed.
   */
  debugDataSupported?: boolean;
  /**
   * Whether DRL history chip is supported. Related bug: http://b/241837879,
   * http://b/171854732 Design doc: http://go/panthera-history-chip-dd DRL
   * history chip was originally rolled out to Panthera in
   * http://google3/googledata/experiments/mobile/agsa/studies/agsa_nga/opa_panthera_one_input_ui_launch.gcl?l=55&rcl=384682900.
   * We plan to roll it out to NGA and TNG. drl_history_chip_supported bit
   * specifies whether the client support (and should have) DRL history chip.
   */
  drlHistoryChipSupported?: boolean;
  /**
   * Whether client supports escape hatches aka post execution suggestions
   * go/nga-escape-hatch-prd
   */
  escapeHatchSupported?:  | "UNSUPPORTED" | "NGA_ESCAPE_HATCH";
  /**
   * Whether the client can rewrite suggestion query text into executed text,
   * if the latter is present. If this feature is disabled, the rewrite happens
   * in Assistant Server.
   */
  executedTextSupported?: boolean;
  /**
   * Whether the client supports passing back `execution_context` from
   * |assistant.api.client_op.SuggestionProcessingParams| when the suggestion is
   * clicked or spoken.
   */
  executionContextSupported?: boolean;
  /**
   * Whether the client supports features in |SuggestionFeatureSpecificAction|.
   */
  featureSpecificActionSupport?: AssistantApiFeatureSpecificActionSupport;
  /**
   * Whether the client supports handling App Actions' notification when the
   * suggestion is clicked. This will allow the server to populate the
   * `app_actions_notification_data` extension field from
   * |SuggestionFeatureSpecificAction| proto message.
   */
  featureSpecificAppActionsNotificationSupported?: boolean;
  /**
   * Whether the multi-step try saying suggestion feature is supported. dd:
   * go/tng-multi-step-simplified
   */
  multiStepTrySayingSupported?: boolean;
  /**
   * Whether the rule_id field in the execution_context is supported. This is a
   * temporary workaround to be able to identify clicks on Person entity
   * suggestions on Sabrina and is expected to be eventually deprecated.
   * TODO(b/185517153) : Deprecate (but do not delete) once click tracking is
   * correctly sent up from the Katniss client.
   */
  ruleIdInExecutionContextSupported?: boolean;
  /**
   * Whether the client can show executed_text after the click on the
   * suggestion chip. Must be set to false on TNG. TNG disregards
   * |SuggestionProcessingParams.show_executed_text| field and always treats it
   * as if |show_executed_text=true|.
   */
  showExecutedTextSupported?: boolean;
  /**
   * Whether the client can show chip as (text | translation).
   * go/lang-partner-doc
   */
  showTranslationSupported?: boolean;
  /**
   * A list of suggestions display targets supported by this client. If unset
   * only DEFAULT SuggestionDisplayTarget is supported.
   */
  supportedDisplayTargets?: AssistantApiSuggestionsSupportDisplayTargetSupport[];
  /**
   * Whether client supports widget suggestion chip to be displayed.
   */
  widgetDataSupported?: boolean;
}

export interface AssistantApiSuggestionsSupportDisplayTargetSupport {
  /**
   * Whether the client can rewrite suggestion query text into executed text,
   * if the latter is present for the display target.
   */
  executedTextSupported?: boolean;
  /**
   * Whether PresentationParams.header_text is supported for the display
   * target.
   */
  headerTextSupported?: boolean;
  /**
   * Whether Suggestion.repress_impression is supported. If not repressed
   * suggestions are not returned.
   */
  repressImpressionSupported?: boolean;
  /**
   * Display target that is supported.
   */
  target?:  | "DEFAULT" | "NGA_INPUT_PLATE" | "CONVERSATION_STARTERS" | "QUICK_ACTIONS" | "TACTILE_ASSISTANT_SUGGESTS" | "TACTILE_MY_ACTIONS" | "TRY_SAYING" | "RICH_SUGGESTIONS";
}

export interface AssistantApiSunriseFeaturesSupport {
  /**
   * If true, the device can slowly brighten the screen and simulate sunrise
   * experience. Alarms with sunrise field enabled can be set on this device.
   */
  sunriseSimulationSupported?: boolean;
}

/**
 * These are the set of ClientOps that are supported by the device.
 */
export interface AssistantApiSupportedClientOp {
  /**
   * This should be the same as the name of the SemanticClientOp that is
   * supported.
   */
  clientOpName?: string;
  /**
   * The properties associated with the ClientOp. This proto should be
   * associated with the client_op_name.
   */
  clientOpProperties?: AssistantApiProtobuf;
  supportedExecution?: AssistantApiSupportedClientOpSupportedExecution;
  /**
   * A version of 0 is the equivalent to not having support for that client_op
   * type. Note that a client_op is also unsupported if it is not included at
   * all in the list of supported client_ops.
   */
  version?: number;
}

function serializeAssistantApiSupportedClientOp(data: any): AssistantApiSupportedClientOp {
  return {
    ...data,
    clientOpProperties: data["clientOpProperties"] !== undefined ? serializeAssistantApiProtobuf(data["clientOpProperties"]) : undefined,
  };
}

function deserializeAssistantApiSupportedClientOp(data: any): AssistantApiSupportedClientOp {
  return {
    ...data,
    clientOpProperties: data["clientOpProperties"] !== undefined ? deserializeAssistantApiProtobuf(data["clientOpProperties"]) : undefined,
  };
}

/**
 * Additional properties that client can support for executing the client op.
 * They are surface-specific execution properties and are unrelated to the
 * execution model.
 */
export interface AssistantApiSupportedClientOpSupportedExecution {
  /**
   * ClientOp execution supports special rendering behavior while the user is
   * in the middle of expressing their query. This behavior includes: 1) New
   * partial output always over-writes prior partial output. 2) Canceling the
   * interaction removes partial fulfilment from any user visible interaction
   * history. If this is true, whether to apply the special rendering behavior
   * will be determined by PartialFulfillmentRenderingParams. More details can
   * be found at go/ma-natcon-pf-api.
   */
  supportsPartialFulfillment?: boolean;
  /**
   * Client can support synchronous execution of the client op. For tts.OUTPUT
   * client op it means that client would honor |synchronous_playback_args|
   * argument. Please see more at go/synchronous-sounds-design.
   */
  supportsSynchronousExecution?: boolean;
}

/**
 * The overall Conversation Protocol version. As we make fundamental changes to
 * Conversation protocol that are non-backwards compatible, we will increment
 * the protocol version. By default, all clients will support version 0. All
 * versions are documented at go/conversation-versions.
 */
export interface AssistantApiSupportedConversationVersion {
  /**
   * Whether conversation protocol is supported explicitly. If true,
   * SingleDeviceCapabilityChecker::SupportsConversationProtocol will always
   * return true.
   */
  supportsConversationProtocol?: boolean;
  /**
   * The supported version number.
   */
  version?: number;
}

/**
 * These are the set of features that are supported by the device. It's a part
 * of the SoftwareCapabilities of the device. Next ID: 63
 */
export interface AssistantApiSupportedFeatures {
  /**
   * Whether the client supports the alternative message notification sources
   * on AAE, in which case notification-related operations can access it.
   */
  aaeNotificationSourceSupported?: boolean;
  /**
   * In what way is assistant continued presence supported. (go/opa-acp-prd)
   */
  acpSupport?: AssistantApiAssistantContinuedPresenceSupport;
  actionV2SupportedFeatures?: AssistantApiActionV2SupportedFeatures;
  /**
   * Whether the client supports AlarmTimerManager API
   * (go/alarm-timer-manager-api).
   */
  alarmTimerManagerApiSupported?: boolean;
  /**
   * The client information for app control support. More details in: go/acaia.
   */
  appControlSupport?: AssistantApiAppControlSupport;
  /**
   * Whether the client supports the assistant explore section. This field will
   * be active only when the Explore section is available to the user. This
   * means that the user is (a) signed-in, (b) a IOPA / AGSA user, and (c) in a
   * locale where explore is available.
   */
  assistantExploreSupported?: boolean;
  /**
   * Whether Assistant for Kids (a.k.a. Designed for Family) features are
   * supported.
   */
  assistantForKidsSupported?: boolean;
  /**
   * Whether communications flows for the client can bypass the DI/DC check.
   * The client will enforce some other equivalent permission as necessary
   * concerning access to device contacts and apps.
   */
  bypassDiDcCheckForComms?: boolean;
  /**
   * Whether or not Assistant should enforce the dismissal of communication
   * notifications associated with messages.
   */
  bypassMsgNotificationDismissal?: boolean;
  /**
   * Whether the client supports 1m providers (go/1m-partner-expansion).
   */
  client1mProvidersSupported?: boolean;
  /**
   * Whether the client can batch client op results before sending them to the
   * server.
   */
  clientOpResultBatchingSupported?: boolean;
  /**
   * Whether the client supports confirmation flow before announcement of
   * multiple messages. If set to true the user will be prompted once and
   * confirmation will be taken before all the messages are announced.
   */
  confirmationBeforeReadingMultipleMessagesSupported?: boolean;
  /**
   * Whether the client supports cross-device broadcast (i.e. on Torus).
   */
  crossDeviceBroadcastSupported?: boolean;
  /**
   * The version of cross device broadcast (ie; broadcast on torus) which the
   * client supports.
   */
  crossDeviceBroadcastVersion?:  | "CROSS_DEVICE_BROADCAST_NOT_SUPPORTED" | "CROSS_DEVICE_BROADCAST_V1";
  /**
   * Whether the client supports csat visual overlay. (go/sd-od-csat)
   */
  csatVisualOverlaySupported?: boolean;
  /**
   * The features set which duo client on the device supports. This should be
   * serialized from proto {@code duo_client_api.DuoClientApiFeatures}.
   */
  duoClientApiFeatures?: Uint8Array;
  /**
   * Whether the client supports Duo group calling.
   */
  duoGroupCallingSupported?: boolean;
  /**
   * Information about what support this device has for fitness.
   */
  fitnessFeatureSupport?: AssistantApiFitnessFeatureSupport;
  /**
   * Fluid Actions features supported by the client. If this field is not set
   * in the incoming request, it could mean that the client does not support
   * Fluid Actions. Alternatively, it could mean that the client supports Fluid
   * Actions, but syncs state with server using the old protocol, namely
   * ConversationStateParams. When b/140733618 is resolved, Surface Adaptation
   * Layer will add this field for old clients that support Fluid Actions
   * framework.
   */
  fluidActionsSupport?: AssistantApiFluidActionsSupport;
  /**
   * Whether the surface client op performer supports Funtime alarms and
   * timers. go/funtime-engdesign
   */
  funtimeSupported?: boolean;
  /**
   * Whether account linking via Google Deep Integrations (GDI) is supported.
   * go/opa-gdi-design
   */
  gdiSupported?: boolean;
  /**
   * Whether the client supports the Gearhead message notification source, in
   * which case notification-related operations can access it.
   */
  gearheadNotificationSourceSupported?: boolean;
  /**
   * Whether the client has a physical radio installed.
   */
  hasPhysicalRadio?: boolean;
  /**
   * Whether the client supports confirmation messages in Immersive Canvas
   * actions. Deprecated: use the filed in immersive_canvas_support.
   */
  immersiveCanvasConfirmationMessageSupported?: boolean;
  immersiveCanvasSupport?: AssistantApiImmersiveCanvasSupport;
  /**
   * Whether the client supports account linking in-dialog (askForSignIn). This
   * is used before this feature is moved to conversation protocol. To support
   * this, the client needs to: - Integrate with Google Deep Integrations. -
   * Have logic to send the result of account linking back to AS.
   */
  inDialogAccountLinkingSupported?: boolean;
  /**
   * Whether paired-phone contact upload is needed for communications queries
   * to work (e.g. on AAE).
   */
  isPairedPhoneContactUploadNeededForComms?: boolean;
  /**
   * Whether a Bluetooth-paired phone is a core component of communications
   * flows on the client.
   */
  isPairedPhoneNeededForComms?: boolean;
  /**
   * Which way of launching the keyboard the client supports.
   */
  launchKeyboardSupported?:  | "LAUNCH_KEYBOARD_UNSUPPORTED" | "OPA_ANDROID_LAUNCH_KEYBOARD_URI";
  /**
   * Whether the client has Google Lens (Assistant Eyes).
   */
  lensSupported?: boolean;
  /**
   * Whether the surface supports LiveCards. In cases where the user intent
   * flow cannot be completed within the Assistant, LiveCards are used to take
   * the user to an external app or website. These cards will be pushed to the
   * Google Home app via the PushMessage ClientOp.
   */
  liveCardsSupported?: boolean;
  /**
   * Whether the client supports Assistant dialogs within Maps. This field will
   * be set only when the Maps on the surface supports Assistant dialogs
   * embedded within Maps. go/gsa-gmm.
   */
  mapsDialogsSupported?: boolean;
  /**
   * Whether the device supports masquerade mode (go/masquerade).
   */
  masqueradeModeSupported?: boolean;
  /**
   * Information about how client handles media controls (play, pause, skip
   * ...)
   */
  mediaControlSupport?: AssistantApiMediaControlSupport;
  /**
   * The ability of the client to detect media sessions on the device.
   */
  mediaSessionDetection?:  | "UNKNOWN_MEDIA_SESSION_DETECTION" | "RELIABLE_MEDIA_SESSION_DETECTION" | "UNRELIABLE_MEDIA_SESSION_DETECTION" | "NO_MEDIA_SESSION_DETECTION" | "MEDIA_SESSION_DETECTION_DISABLED_SCREEN_CONTEXT";
  /**
   * Whether the client supports joining a Google Meet meeting.
   */
  meetSupported?: boolean;
  /**
   * Whether the client can render no input response or just ignore it. No
   * input response is returned when client has a no speech input interaction,
   * eg. user tapped mic but didn't say anything.
   */
  noInputResponseSupported?: boolean;
  /**
   * When the entry source is search, whether the client supports rendering a
   * similar response as OPA one does. Entry source is defined at
   * http://cs/symbol:assistant.api.params.DeviceProperties.EntrySource
   */
  opaOnSearchSupported?: boolean;
  /**
   * Whether or not the client supports enabling parental controls. When a
   * device to supports parental controls, it has the software necessary to
   * store the relevant information required for parental controls to work. This
   * information includes a boolean "enabled bit" as well as the obfuscated gaia
   * ID of the kid account selected for use with parental controls. Devices
   * supportings kids mode send this information to S3 via S3ClientInfo in every
   * request. See go/aff-kidsproduct for details.
   */
  parentalControlsSupported?: boolean;
  /**
   * Whether the client supports persistent display. The new feature allows
   * Assistant devices with screen to display a continuously updating permanent
   * display, such as ambient weather, without the need for a user to ask the
   * Assistant. Design doc: go/assistant-persistent-display.
   */
  persistentDisplaySupported?: boolean;
  /**
   * Whether the client supports the privacy-aware lockscreen protocol
   * (go/assistant-lockscreen-spec).
   */
  privacyAwareLockscreenSupported?: boolean;
  /**
   * Whether the client has remote casting enabled. For ex: we want to disable
   * this for clients like Auto.
   */
  remoteCloudCastingEnabled?: boolean;
  /**
   * Whether the Assistant Server should generate feedback suggestion chips.
   */
  serverGeneratedFeedbackChipsEnabled?: boolean;
  /**
   * Whether the client supports SmartHome lock screen logic (i.e. on Tangor).
   */
  shLockScreenSupported?: boolean;
  /**
   * Which kind of sign in the client supports.
   */
  signInMethod?: AssistantApiSignInMethod;
  /**
   * Whether the client can monitor sleep. This allows us to show sleep CUJ
   * related information: go/TwilightDesign Use for development only, see the
   * same field in DeviceCapabilities.SoftwareCapabilities.SelinaCapabilities.
   */
  sleepSensingSupported?: boolean;
  /**
   * Whether the client supports smart space cross-device timers.
   * (go/ss-x-device-timer)
   */
  smartspaceCrossDeviceTimerSupported?: boolean;
  /**
   * Whether or not the client supports gesture detection via soli chips. The
   * reason to prepend the name with soli is to distinguish it from computer
   * vision based methods, e.g. Newman devices.
   */
  soliGestureDetectionSupported?: boolean;
  /**
   * Suggestion chips features, supported by the client.
   */
  suggestionsSupport?: AssistantApiSuggestionsSupport;
  /**
   * Whether the client supports the sunrise screen brightening feature before
   * the alarm fires. This is used to indicate whether sunrise alarms can be set
   * on the device.
   * http://cs/symbol:assistant.api.core_types.governed.RingtoneTaskMetadata.GentleWakeInfo
   */
  sunriseFeaturesSupport?: AssistantApiSunriseFeaturesSupport;
  /**
   * Whether the client supports faster optimization for tap_to_read feature.
   */
  tapToReadOptimizationSupported?: boolean;
  /**
   * Whether the device supports the 3p GUI framework, which allows third
   * parties to enter the conversation with the user, showing their logo next to
   * their chat bubbles, etc. go/3p-phone
   */
  thirdPartyGuiSupported?: boolean;
  /**
   * Transactions features, supported by the client. Transactions feature may
   * includes how Transactions team want to populate additional information from
   * the device to the server.
   */
  transactionFeaturesSupport?: AssistantApiTransactionFeaturesSupport;
  /**
   * The version of transactions which the client supports.
   */
  transactionsVersion?:  | "NO_TRANSACTIONS" | "TRANSACTIONS_INITIAL_LAUNCH" | "TRANSACTIONS_V2" | "TRANSACTIONS_V3";
  /**
   * If set, it indicates that the client can open a separate HTML
   * browser/webviewer (full viewer) to display certain visual results. These
   * visual results usually require more memory to render (e.g. high resolution
   * photos). Compared to the regular viewer that display all other Assistant
   * result, the full viewer does not have memory limit. The field is copied
   * from the device model. See
   * http://google3/assistant/devices_platform/proto/device_model_capabilities.proto?l=225&rcl=312576471
   * Also see go/webassistant-full-card-viewer.
   */
  usesSeparateFullViewer?: boolean;
  /**
   * Whether the client supports viewing of reminder hub page or not. Default
   * is supported. Set to true to disable returning reminder hub page url in
   * reminder responses.
   */
  viewReminderHubPageNotSupported?: boolean;
  /**
   * Whether the client supports the programmatic warm welcome tutorial. Design
   * doc: go/opal-pww-design.
   */
  warmWelcomeTutorialSupported?: boolean;
  /**
   * Whether the supports opening a URL in a web browser. For example, we want
   * to disable this for clients like Chirp.
   */
  webBrowserSupported?: boolean;
  /**
   * Whether or not the client supports WhatsNext in the protocol.
   */
  whatsNextSupported?: boolean;
  /**
   * Whether the client supports joining a Zoom meeting.
   */
  zoomSupported?: boolean;
}

function serializeAssistantApiSupportedFeatures(data: any): AssistantApiSupportedFeatures {
  return {
    ...data,
    duoClientApiFeatures: data["duoClientApiFeatures"] !== undefined ? encodeBase64(data["duoClientApiFeatures"]) : undefined,
  };
}

function deserializeAssistantApiSupportedFeatures(data: any): AssistantApiSupportedFeatures {
  return {
    ...data,
    duoClientApiFeatures: data["duoClientApiFeatures"] !== undefined ? decodeBase64(data["duoClientApiFeatures"] as string) : undefined,
  };
}

/**
 * Contains versions of protocol buffer messages. This is the equivalence of a
 * proto3 map, keyed by a protocol buffer messages name, and the value is the
 * version of this message. e.g. {"assistant.api.core_types.Timer": 2,
 * "assistant.api.core_types.Alarm": 1} See go/assistant-protocol-versioning for
 * more details.
 */
export interface AssistantApiSupportedProtocolVersion {
  messageVersion?: AssistantApiSupportedProtocolVersionMessageVersionPair[];
}

export interface AssistantApiSupportedProtocolVersionMessageVersionPair {
  /**
   * The full path of a message which should start from the package name. e.g.
   * "assistant.api.core_types.Timer".
   */
  messageName?: string;
  /**
   * The supported version number.
   */
  version?: number;
}

/**
 * Types of providers that are supported by the client. For example, ChromeOS
 * support both web app and Android app (for eligible devices).
 */
export interface AssistantApiSupportedProviderTypes {
  supportedTypes?:  | "PROVIDER_TYPE_UNSPECIFIED" | "ANDROID_APP" | "CAST_APP" | "CLOUD_PROVIDER" | "SIP_PROVIDER" | "IOS_APP" | "INTERNAL_PROVIDER" | "WEB_PROVIDER" | "KAIOS_APP" | "HOME_APP" | "CHROMEOS_APP"[];
}

/**
 * Properties of the surface that are not hardware related or feature specific.
 */
export interface AssistantApiSurfaceProperties {
  executionCapabilities?: AssistantApiSurfacePropertiesExecutionCapabilities;
  /**
   * If this field is unset, the response format is unknown
   */
  responseDisplayFormat?:  | "SINGLE_ITEM" | "MULTIPLE_ITEMS" | "FULL_HISTORY";
  /**
   * If true, the client supports receiving multiple responses. See
   * go/multiple-response-in-media-use-cases for more details.
   */
  supportsMultiResponse?: boolean;
}

/**
 * Describes the capabilities that are related to the execution of client ops
 * on the device.
 */
export interface AssistantApiSurfacePropertiesExecutionCapabilities {
  /**
   * Completes the preloading ie., sets up the stage for the execution of
   * client ops on the device while the previous conv delta is being executed.
   * Refer to go/preload-convdelta for more information.
   */
  supportsClientOpPreloading?: boolean;
  /**
   * A value of true indicates that the client supports streaming of
   * non-finalized responses by use of ClientExecutionParams.response_stream_id.
   * and ClientExecutionParams.to_be_finalized.
   */
  supportsNonFinalizedResponses?: boolean;
  /**
   * If true, the client supports receiving non-materialized interactions
   * (go/as-streaming-protocol-nm).
   */
  supportsNonMaterializedInteractions?: boolean;
}

/**
 * Restrictions related to system-level notifications.
 */
export interface AssistantApiSystemNotificationRestrictions {
  categoryState?: AssistantApiSystemNotificationRestrictionsNotificationCategoryState[];
  channelState?: AssistantApiSystemNotificationRestrictionsNotificationChannelState[];
  /**
   * Specifies whether the surface is able to display notifications.
   */
  notificationCapabilities?:  | "NO_NOTIFICATION_CAPABILITY" | "NOTIFICATIONS_DISABLED" | "NOTIFICATIONS_ENABLED";
}

/**
 * Notification channels state for the new server driven channels.
 */
export interface AssistantApiSystemNotificationRestrictionsNotificationCategoryState {
  /**
   * Notification channel type.
   */
  categoryId?: number;
  /**
   * Weather the notifications on this channel are disabled.
   */
  disabled?: boolean;
  disabledReason?:  | "NONE" | "ASSISTANT_CATEGORY_SETTING" | "ASSISTANT_OVERALL_SETTING" | "OS_APP_DISABLED" | "OS_CHANNEL_GROUP_DISABLED" | "OS_CHANNEL_DISABLED";
}

/**
 * Notification channels state.
 */
export interface AssistantApiSystemNotificationRestrictionsNotificationChannelState {
  /**
   * Notification channel type.
   */
  channelType?:  | "TYPE_UNKNOWN" | "TYPE_OPA_PROACTIVE" | "TYPE_OPA_HANDOFF" | "TYPE_OPA_MISC" | "TYPE_OPA_RECOMMENDATIONS" | "TYPE_OPA_PRODUCT_UPDATES" | "TYPE_OPA_THIRD_PARTY";
  /**
   * Whether the notifications on this channel are enabled.
   */
  enabled?: boolean;
}

/**
 * 3P Action Metadata. Next ID: 3
 */
export interface AssistantApiThirdPartyActionConfig {
  /**
   * DeviceActionCapability from DeviceModelPackage.
   */
  deviceActionCapability?: AssistantDevicesPlatformProtoDeviceActionCapability;
  /**
   * List of Action project capabilities.
   */
  projectConfigs?: AssistantApiThirdPartyActionConfigProjectConfig[];
}

function serializeAssistantApiThirdPartyActionConfig(data: any): AssistantApiThirdPartyActionConfig {
  return {
    ...data,
    deviceActionCapability: data["deviceActionCapability"] !== undefined ? serializeAssistantDevicesPlatformProtoDeviceActionCapability(data["deviceActionCapability"]) : undefined,
  };
}

function deserializeAssistantApiThirdPartyActionConfig(data: any): AssistantApiThirdPartyActionConfig {
  return {
    ...data,
    deviceActionCapability: data["deviceActionCapability"] !== undefined ? deserializeAssistantDevicesPlatformProtoDeviceActionCapability(data["deviceActionCapability"]) : undefined,
  };
}

/**
 * Metadata for ActionPackage. Device Actions are disabled by default unless
 * explicitly enabled for the device here, see go/3p-device-actions-v2-design.
 */
export interface AssistantApiThirdPartyActionConfigProjectConfig {
  /**
   * Google cloud project id for which the Action Package or Device Model is
   * registered.
   */
  projectId?: string;
}

export interface AssistantApiThirdPartyCapabilities {
  /**
   * Restrictions for the device to share any data with third party apps. See
   * details in go/atv-dsc.
   */
  dataSharingRestrictions?:  | "DEFAULT_NO_DATA_SHARING_RESTRICTION" | "NO_SHARING_ALLOWED_WITH_THIRD_PARTY" | "SHARING_STATUS_NOT_SET" | "NO_SHARING_ALLOWED_WITH_THIRD_PARTY_FROM_OOBE";
}

/**
 * A civil time relative to a timezone. IMPORTANT: The definition of TimeOfDay
 * proto is being moved to
 * //assistant/api/core_types/governed/datetime_type.proto. All existing
 * references will be updated to point to the new location. If you are adding a
 * reference, use the new one instead.
 */
export interface AssistantApiTimeOfDay {
  /**
   * The hour, in 0...23.
   */
  hour?: number;
  /**
   * The minute, in 0...59.
   */
  minute?: number;
  /**
   * The fraction of seconds in nanoseconds, in 0..999999999.
   */
  nanosecond?: number;
  /**
   * The second, in 0...59. Leap seconds are not supported.
   */
  second?: number;
}

/**
 * An absolute point in time independent of timezone or calendar, based on the
 * proto3 Timestamp (//google/protobuf/timestamp.proto). IMPORTANT: The
 * definition of Timestamp proto is being moved to
 * //assistant/api/core_types/governed/datetime_type.proto. All existing
 * references will be updated to point to the new location. If you are adding a
 * reference, use the new one instead. NOTE: THIS IS NO LONGER RECOMMENDED TO BE
 * USED. It was originally defined separately from google.protobuf.Timestamp due
 * to incompatibility with proto2 syntax. The incompatibility issues have since
 * been resolved and so the Google-wide standard representation of
 * google.protobuf.Timestamp should be preferred. In fact, google.protobuf.*
 * protos in general are now recommended to be used in new APIs.
 */
export interface AssistantApiTimestamp {
  /**
   * Non-negative fractions of a second at nanosecond resolution.
   */
  nanos?: number;
  /**
   * Seconds of UTC time since the Unix epoch.
   */
  seconds?: bigint;
}

function serializeAssistantApiTimestamp(data: any): AssistantApiTimestamp {
  return {
    ...data,
    seconds: data["seconds"] !== undefined ? String(data["seconds"]) : undefined,
  };
}

function deserializeAssistantApiTimestamp(data: any): AssistantApiTimestamp {
  return {
    ...data,
    seconds: data["seconds"] !== undefined ? BigInt(data["seconds"]) : undefined,
  };
}

/**
 * A time zone. Conceptually, a time zone is a set of rules associated with a
 * location that describes a UTC offset and how it changes over time (e.g.
 * Daylight Saving Time). The offset is used to compute the local date and time.
 * IMPORTANT: The definition of TimeZone enum is being moved to
 * //assistant/api/core_types/governed/datetime_type.proto. All existing
 * references will be updated to point to the new location. If you are adding a
 * reference, use the new one instead.
 */
export interface AssistantApiTimeZone {
  /**
   * Time zone in IANA format, e.g. America/Los_Angeles for USA Pacific Time.
   */
  ianaId?: string;
}

export interface AssistantApiTransactionFeaturesSupport {
  /**
   * If true, setting this boolean means the device should not support voice
   * PIN. For example, although the phone supports both voice and PIN pad, but
   * we don't want users using voice.
   * https://docs.google.com/document/d/1M8iJQX3GuxGZGeidS8Gl4KJt3LuBWAIlolPlW10DkxU/edit#heading=h.8ovvdd3i2thv
   */
  voicePinSuppressed?: boolean;
}

export interface AssistantApiVolumeProperties {
  /**
   * The volume percentages for spelled out values.
   */
  defaultVolumePercentage?: number;
  highVolumePercentage?: number;
  /**
   * The number of levels to move for a step.
   */
  levelStepSize?: number;
  lowVolumePercentage?: number;
  /**
   * The max number of volume levels the client supports.
   */
  maximumVolumeLevel?: number;
  mediumVolumePercentage?: number;
  veryHighVolumePercentage?: number;
  veryLowVolumePercentage?: number;
}

/**
 * Capability with regard to support of alarms by the client.
 */
export interface AssistantDevicesPlatformProtoAlarmCapability {
  /**
   * Maximum number of alarms that can be created on the client. Zero or unset
   * indicates no maximum limit.
   */
  maxSupportedAlarms?: number;
  /**
   * Whether the client restricts alarms to ring within the next 24 hours.
   */
  restrictAlarmsToNextDay?: boolean;
  /**
   * Whether the client supports the STOP alarm action. If this is false, stop
   * actions will be represented by the MUTATE action, and the device may need
   * to check alarm state to determine if there's a firing alarm that needs to
   * be dismissed.
   */
  supportsStopAction?: boolean;
}

export interface AssistantDevicesPlatformProtoArgSpec {
  intValueSpec?: AssistantDevicesPlatformProtoIntValueSpec;
  optionValueSpec?: AssistantDevicesPlatformProtoOptionValueSpec;
  type?:  | "TYPE_UNSPECIFIED" | "BOOL" | "INTEGER" | "OPTION";
}

function serializeAssistantDevicesPlatformProtoArgSpec(data: any): AssistantDevicesPlatformProtoArgSpec {
  return {
    ...data,
    intValueSpec: data["intValueSpec"] !== undefined ? serializeAssistantDevicesPlatformProtoIntValueSpec(data["intValueSpec"]) : undefined,
  };
}

function deserializeAssistantDevicesPlatformProtoArgSpec(data: any): AssistantDevicesPlatformProtoArgSpec {
  return {
    ...data,
    intValueSpec: data["intValueSpec"] !== undefined ? deserializeAssistantDevicesPlatformProtoIntValueSpec(data["intValueSpec"]) : undefined,
  };
}

export interface AssistantDevicesPlatformProtoCallCallCapability {
}

export interface AssistantDevicesPlatformProtoClientReconnectCapability {
}

/**
 * States the cloud capabilities of the device, i.e. the endpoint(s) to use for
 * cloud execution of Actions or Registration.
 */
export interface AssistantDevicesPlatformProtoCloudCapability {
  /**
   * The list of CloudEndpoints supported by this Device Model. Note that each
   * should have a unique |name|. If any cloud endpoints are provided here, then
   * the first one in the list will be used by default for all Cloud Execution.
   * An Intent may override the default by providing an |execution_config|.
   */
  cloudEndpoints?: AssistantDevicesPlatformProtoCloudEndpoint[];
}

/**
 * A cloud endpoints associates with this device, it can be used for query
 * parsing, or cloud execution.
 */
export interface AssistantDevicesPlatformProtoCloudEndpoint {
  /**
   * The name for this cloud endpoint. It's unique per Locale. This is not an
   * API resource name. Ex: sample-nlu-endpoint
   */
  name?: string;
  /**
   * The list of scopes to be provided in the OAuth2 token. They must be a
   * subset of the scopes registered in the Account Linking flow, or the request
   * will fail. If the client itself provides the token, then this field is
   * ignored.
   */
  scopes?: string[];
  /**
   * The URL for this endpoint, it must start with https.
   */
  url?: string;
}

/**
 * This capability represents device action needed capability. Next ID: 10
 */
export interface AssistantDevicesPlatformProtoDeviceActionCapability {
  /**
   * Integrate your device with Google's Smart Home solution by putting your
   * device into Google's Home Graph, a database that stores and provides
   * contextual data about the home and its devices. For example, Home Graph can
   * store the concept of a living room that contains multiple types of devices,
   * when you say "turn on the light" to a device, if you have light in the
   * living room, that light will be turned on.
   */
  assistantDeviceInRoomOptOut?: boolean;
  /**
   * Specifies behavior for built-in device actions for this device model. If
   * not specified, defaults to ENABLE_CONFIGURED_INTENTS_ONLY.
   */
  builtInIntentMode?:  | "INTENT_MODE_UNSPECIFIED" | "ENABLE_ALL" | "ENABLE_ALL_AUTO_ACTIONS" | "ENABLE_CONFIGURED_INTENTS_ONLY" | "PUNT_FOR_UNCONFIGURED_INTENTS";
  /**
   * Specifies which custom device actions should be enabled for this device
   * model. This will only affect the behavior of intents corresponding to those
   * from the Action Package of this project. If not specified, defaults to
   * ENABLE_ALL.
   */
  customIntentMode?:  | "INTENT_MODE_UNSPECIFIED" | "ENABLE_ALL" | "ENABLE_ALL_AUTO_ACTIONS" | "ENABLE_CONFIGURED_INTENTS_ONLY" | "PUNT_FOR_UNCONFIGURED_INTENTS";
  /**
   * Default instructions for routing of any Intent. The data here could be
   * overridden for specific Intents if provided directly in the 'intents'
   * field.
   */
  defaultExecutionConfig?: AssistantDevicesPlatformProtoExecutionConfig;
  /**
   * Specifies capabilities for device actions that are inlined in the
   * google.assistant.embedded.v1.DeviceAction message.
   */
  inlinedActionCapability?: AssistantDevicesPlatformProtoInlinedActionCapability;
  /**
   * Intent configurations. Built-in and custom intents may be configured here.
   * Note that built-in intents will always behave with IntentMode of
   * ENABLE_CONFIGURED_INTENTS_ONLY. The IntentMode for custom intents can be
   * changed using the custom_intent_mode. To configure an intent, list it here
   * with its intent name, e.g. "MY_CUSTOM_INTENT",
   * "google.assistant.car.model.capabilities.AC_TEMPERATURE".
   */
  intents?: AssistantDevicesPlatformProtoIntent[];
  /**
   * Provided data which augments the device action capabilities. Some built-in
   * intents may require additional configuration to be provided. One example
   * could be the list of channels available for the
   * `action.intent.SelectChannel` intent.
   */
  providedData?: AssistantDevicesPlatformProtoProvidedData[];
  /**
   * List of built-in traits such as "action.devices.traits.OnOff" See
   * java/com/google/home/graph/service/config/protoconf.pi As of Nov. 2017, we
   * also support custom traits for EAP users. We'll eventually disable custom
   * traits once custom actions are in place.
   */
  traits?: string[];
  /**
   * Specifies the format how Google routes queries to 3P cloud. By default,
   * this field is unset, all partners should get shallow NLU. This is needed
   * *ONLY* for specific partners for strong business reasons.
   */
  understandingConfig?: AssistantDevicesPlatformProtoUnderstandingConfig;
}

function serializeAssistantDevicesPlatformProtoDeviceActionCapability(data: any): AssistantDevicesPlatformProtoDeviceActionCapability {
  return {
    ...data,
    inlinedActionCapability: data["inlinedActionCapability"] !== undefined ? serializeAssistantDevicesPlatformProtoInlinedActionCapability(data["inlinedActionCapability"]) : undefined,
    intents: data["intents"] !== undefined ? data["intents"].map((item: any) => (serializeAssistantDevicesPlatformProtoIntent(item))) : undefined,
  };
}

function deserializeAssistantDevicesPlatformProtoDeviceActionCapability(data: any): AssistantDevicesPlatformProtoDeviceActionCapability {
  return {
    ...data,
    inlinedActionCapability: data["inlinedActionCapability"] !== undefined ? deserializeAssistantDevicesPlatformProtoInlinedActionCapability(data["inlinedActionCapability"]) : undefined,
    intents: data["intents"] !== undefined ? data["intents"].map((item: any) => (deserializeAssistantDevicesPlatformProtoIntent(item))) : undefined,
  };
}

export interface AssistantDevicesPlatformProtoDeviceModifySettingCapability {
  clientOpProperty?: AssistantApiClientOpPropertiesDeviceModifySettingClientOpProperty;
}

export interface AssistantDevicesPlatformProtoDeviceTakePhotoCapability {
}

/**
 * Specifies the routing capabilities of the Intent. It will apply only when
 * the Intent is triggered. Next ID: 8
 */
export interface AssistantDevicesPlatformProtoExecutionConfig {
  /**
   * Instructions for performing a cloud execution request for the Intent when
   * the execution_type is set to CLOUD. If non-empty, then the device execution
   * would be routed to the CloudEndpoint specified by this name. The Account
   * Linking exchange may be performed to fetch the OAuth access token, and the
   * access token will be included in the HTTP header.
   */
  cloudEndpointName?: string;
  /**
   * If this field is set, then the Syndication cloud call will be disabled for
   * this intent. Note this only applies if any Syndication cloud endpoint is
   * associated with the Device Model, otherwise setting this field does
   * nothing. By default, all Intents that are enabled and supported by the
   * Syndication API will be routed through the Syndication cloud endpoint if
   * it's provided.
   */
  cloudIntentTranslationDisabled?: boolean;
  /**
   * Specifies the intent command format for this Action. For example, in order
   * to launch an Android intent instead of receiving the device action payload
   * on the client, then this field can be set with
   * "intent:/#Intent;...;my_extra={$.params.channels[0].channelCode};end" The
   * parameter "{$.params.channels[0].channelCode}" is in JSON path format, and
   * will be replaced with the content from the original device action payload.
   * Thus, with # JSON "execution": [ { "command":
   * "action.devices.commands.SelectChannel", "params": { "channels": [{
   * "channelName": "exampleChannel", "channelCode": "1-1" }] } } ] as the
   * original action result, then the final result would look like
   * "intent:/#Intent;...;my_extra=\"1-1\";end"
   */
  intentCommandFormat?: string;
  /**
   * If this field is set, then local execution capability is disabled for all
   * matching intents.
   */
  localDisabled?: boolean;
  /**
   * Specifies how to execute this Action when it is invoked locally (from the
   * same device.)
   */
  localExecutionType?:  | "DEFAULT" | "CLOUD";
  /**
   * If this field is set, then remote execution capability is disabled for all
   * matching intents.
   */
  remoteDisabled?: boolean;
  /**
   * Specifies how to execute this Action when it is invoked remotely (from a
   * different device.)
   */
  remoteExecutionType?:  | "DEFAULT" | "CLOUD";
}

export interface AssistantDevicesPlatformProtoInlinedActionCapability {
  /**
   * Specifies capabilities for handling on-device alarms. The presence of this
   * field, even if empty, implies that the device supports alarms.
   */
  alarm?: AssistantDevicesPlatformProtoAlarmCapability;
  /**
   * Specifies the size limits on responses. If message is not defined then no
   * limits exist.
   */
  responseLimits?: AssistantDevicesPlatformProtoResponseLimits;
  /**
   * Specifies capabilities for handling assistant.embedded.v1.DeviceOp.
   */
  supportedDeviceOps?: AssistantDevicesPlatformProtoSupportedDeviceOps;
  /**
   * Whether this device model package support sdk.EXECUTE client_op (a.k.a
   * action.devices.EXECUTE intent), which will be filled into
   * google.assistant.embedded.v1.DeviceAction.device_request_json. It is
   * default to true (and not public), since all 3P will depends on the
   * device_request_json. Only internal projects like Edoras will set this to
   * false.
   */
  supportSdkExecute?: boolean;
  /**
   * Specifies whether server can send a series of responses for a single
   * query. Example: Routines where multiple actions to be executed one after
   * another.
   */
  supportsMultiResponse?: boolean;
  /**
   * Specifies capabilities for handling on-device timers. The presence of this
   * field, even if empty, implies that the device supports timers.
   */
  timer?: AssistantDevicesPlatformProtoTimerCapability;
}

function serializeAssistantDevicesPlatformProtoInlinedActionCapability(data: any): AssistantDevicesPlatformProtoInlinedActionCapability {
  return {
    ...data,
    timer: data["timer"] !== undefined ? serializeAssistantDevicesPlatformProtoTimerCapability(data["timer"]) : undefined,
  };
}

function deserializeAssistantDevicesPlatformProtoInlinedActionCapability(data: any): AssistantDevicesPlatformProtoInlinedActionCapability {
  return {
    ...data,
    timer: data["timer"] !== undefined ? deserializeAssistantDevicesPlatformProtoTimerCapability(data["timer"]) : undefined,
  };
}

/**
 * An intent configures the behavior of a device action for this device. Next
 * ID: 7
 */
export interface AssistantDevicesPlatformProtoIntent {
  /**
   * List of arguments associated this intent. Each of which depends a template
   * for the expected argument.
   */
  argSpecs?: {
    [key: string]: AssistantDevicesPlatformProtoArgSpec
  };
  /**
   * Instructions for the routing of this Intent.
   */
  executionConfig?: AssistantDevicesPlatformProtoExecutionConfig;
  /**
   * The name of the intent.
   */
  name?: string;
  /**
   * List of provided data names used by this intent. Note that some built-in
   * intents will not function properly without provided data, such as
   * `action.intent.SwitchChannel` or `action.intent.AppSelector`.
   */
  providedDataNames?: string[];
  /**
   * Security configuration for this Intent.
   */
  securityConfig?: AssistantDevicesPlatformProtoSecurityConfig;
  /**
   * The conditions which must be met by the device before executing this
   * Intent. More than one can be provided, in which case the conditions operate
   * with the "AND" operator, i.e. the first condition which is failed will be
   * used to restrict the execution of this Intent.
   */
  triggerConditions?: AssistantDevicesPlatformProtoTriggerCondition[];
}

function serializeAssistantDevicesPlatformProtoIntent(data: any): AssistantDevicesPlatformProtoIntent {
  return {
    ...data,
    argSpecs: data["argSpecs"] !== undefined ? Object.fromEntries(Object.entries(data["argSpecs"]).map(([k, v]: [string, any]) => ([k, serializeAssistantDevicesPlatformProtoArgSpec(v)]))) : undefined,
    triggerConditions: data["triggerConditions"] !== undefined ? data["triggerConditions"].map((item: any) => (serializeAssistantDevicesPlatformProtoTriggerCondition(item))) : undefined,
  };
}

function deserializeAssistantDevicesPlatformProtoIntent(data: any): AssistantDevicesPlatformProtoIntent {
  return {
    ...data,
    argSpecs: data["argSpecs"] !== undefined ? Object.fromEntries(Object.entries(data["argSpecs"]).map(([k, v]: [string, any]) => ([k, deserializeAssistantDevicesPlatformProtoArgSpec(v)]))) : undefined,
    triggerConditions: data["triggerConditions"] !== undefined ? data["triggerConditions"].map((item: any) => (deserializeAssistantDevicesPlatformProtoTriggerCondition(item))) : undefined,
  };
}

/**
 * Capabilities that may only be set internally. Only internal callers (i.e.
 * Googlers or Google owned projects) will be able to set these, thanks to
 * go/assistant-device-model-package-ownership.
 */
export interface AssistantDevicesPlatformProtoInternalCapability {
  /**
   * When using the Assistant SDK (Embedded Assistant API), the project id used
   * to authenticate the gRPC request is checked and must match against the
   * project id of the Device Model. We will additionally allow the project ids
   * listed in the device model here to be let through. See
   * https://docs.google.com/document/d/1InAczpQJs6LCH1l--2yy67JM9hsBJbiL57fusnL3A8A
   */
  allowedAssistantSdkAuthProjectIds?: string[];
  /**
   * Load the assistant.api.AppCapabilities from DEVICE_INSTALLED_APP footprint
   * corpus. See go/edoras-geller.
   */
  appCapabilitiesFromDeviceInstallApps?: boolean;
  /**
   * Uses this endpoint for device action fulfillment when there's no endpoint
   * in syndication_metadata. 1p surfaces/devices such as telephone can enable
   * this for its cloud action fulfillment without enabling the whole
   * syndication experience.
   */
  cloudDeviceActionEndpoint?: AssistantDevicesPlatformProtoCloudEndpoint;
  /**
   * Signals that the model will have updated ranking behavior as described in
   * https://docs.google.com/document/d/1SN_AgadRr_cdIrFe-qgRbIX2J1sOE7lcRXAvM1GUPoU.
   */
  deviceActionsEligibleForHighConfidence?: boolean;
  /**
   * Make Google sign-in mandatory for using Google Assistant on the device.
   * (This bit is initially added for Samsung TV.)
   */
  forceSignIn?: boolean;
  /**
   * When looking up device (for example for disclosure consent check), then
   * always use the third party device id for lookup instead of any other device
   * id which would normally have higher precedence, such as cast_device_id.
   */
  forceThirdPartyDeviceIdForDeviceLookup?: boolean;
  /**
   * Adds "transactions.AUTHENTICATION" for car automation probers. Since the
   * probers run as Assistant SDK requests, voice match always fails for car
   * automation requests, so we add this client op as a hack to allow probers to
   * appear as personal devices and bypass voice match. See b/137221645.
   */
  forceTransactionsAuthentication?: boolean;
  /**
   * Signals that this device can "render" raw search results even with no
   * screen (e.g., using a text reader). If this is true, fallback search
   * results can be returned as a custom device action in a SearchResults
   * message.
   * http://google3/assistant/embedded/proto_translation/utils/proto/search_results.proto
   */
  hasCustomSearchResultsRendering?: boolean;
  /**
   * When looking up device (for example for disclosure consent check), use
   * this project id as part of the primary key for the device lookup (i.e.
   * instead of the device_config.agent_id.) The precedence is as follows: 1)
   * this field, if set for the device's device model 2) device_config.agent_id
   * 3) device_model.project_id
   */
  overrideProjectIdForDeviceLookup?: string;
  stadiaAssistantConfig?: AssistantDevicesPlatformProtoInternalCapabilityStadiaAssistantConfig;
  /**
   * Telephone server is able to send attribution to user feature phone. See
   * go/telephone-attribution.
   */
  telephoneAttribution?: boolean;
}

/**
 * The StadiaAssistantConfig. This field should only be set if the device model
 * is a Stadia.
 */
export interface AssistantDevicesPlatformProtoInternalCapabilityStadiaAssistantConfig {
  stadiaPlatform?:  | "UNSPECIFIED" | "CHROMECAST" | "WEB_BROWSER";
}

export interface AssistantDevicesPlatformProtoIntValueSpec {
  maxValue?: bigint;
  minValue?: bigint;
}

function serializeAssistantDevicesPlatformProtoIntValueSpec(data: any): AssistantDevicesPlatformProtoIntValueSpec {
  return {
    ...data,
    maxValue: data["maxValue"] !== undefined ? String(data["maxValue"]) : undefined,
    minValue: data["minValue"] !== undefined ? String(data["minValue"]) : undefined,
  };
}

function deserializeAssistantDevicesPlatformProtoIntValueSpec(data: any): AssistantDevicesPlatformProtoIntValueSpec {
  return {
    ...data,
    maxValue: data["maxValue"] !== undefined ? BigInt(data["maxValue"]) : undefined,
    minValue: data["minValue"] !== undefined ? BigInt(data["minValue"]) : undefined,
  };
}

export interface AssistantDevicesPlatformProtoMediaNextCapability {
}

export interface AssistantDevicesPlatformProtoMediaPauseCapability {
}

export interface AssistantDevicesPlatformProtoMediaPlayMediaCapability {
}

export interface AssistantDevicesPlatformProtoMediaPreviousCapability {
}

export interface AssistantDevicesPlatformProtoMediaResumeCapability {
}

export interface AssistantDevicesPlatformProtoMediaStopCapability {
}

export interface AssistantDevicesPlatformProtoOptionValueSpec {
  values?: string[];
}

/**
 * Provided data which augments the device action capabilities. Some built-in
 * intents may require additional configuration to be provided. One example
 * could be the list of channels available for the `action.intent.SelectChannel`
 * intent.
 */
export interface AssistantDevicesPlatformProtoProvidedData {
  name?: string;
}

export interface AssistantDevicesPlatformProtoProviderOpenCapability {
  clientOpProperty?: AssistantApiClientOpPropertiesProviderOpenClientOpProperty;
}

/**
 * Specifies the size limits on responses receivable by the client.
 */
export interface AssistantDevicesPlatformProtoResponseLimits {
  /**
   * Max size in bytes of the total serialized AssistResponse receivable by the
   * client. If response exceeds this max, response may be modified by the
   * server.
   */
  maxAssistResponseSizeBytes?: number;
  /**
   * Maximum size in bytes (not characters) of text the display can handle
   * (which may be different from how much the display can show at a time due to
   * scrolling).
   */
  maxDisplayLinesBytes?: number;
  /**
   * Maximum size in bytes (not characters) for each suggestion chip.
   */
  maxSuggestionChipBytes?: number;
  /**
   * Maximum number of suggestion chips the device can handle to display.
   */
  maxSuggestionChips?: number;
}

/**
 * Encapsulates security configuration for a single intent of a device model.
 */
export interface AssistantDevicesPlatformProtoSecurityConfig {
  /**
   * Specifies auth mechanism to be used upon remote request for device action.
   */
  authMechanismForRemoteRequests?:  | "NONE" | "ENABLED" | "FINGERPRINT_OR_PASSWORD" | "PIN";
}

export interface AssistantDevicesPlatformProtoSendChatMessageCapability {
}

/**
 * This message will specify supports for fields in
 * |assistant.embedded.v1.DeviceOp|, for a device model package. See
 * go/easi-client-op2 for more info.
 */
export interface AssistantDevicesPlatformProtoSupportedDeviceOps {
  /**
   * |call_call| specifies the support for the call.CALL clientop, and the
   * corresponding call_call field in assistant.embedded.v1.DeviceOp.
   */
  callCall?: AssistantDevicesPlatformProtoCallCallCapability;
  /**
   * |client_reconnect| indicates support for client.RECONNECT using
   * assistant.embedded.v1.DeviceOp. There is an alternative API/capability for
   * client.RECONNECT specified in RoutineCapability.supports_reconnect. Client
   * should choose between this and RoutineCapability but not both.
   */
  clientReconnect?: AssistantDevicesPlatformProtoClientReconnectCapability;
  /**
   * |device_modify_setting| specifies the support for device.MODIFY_SETTING
   * client_op, and the corresponding device_modify_setting field in
   * assistant.embedded.v1.DeviceOp.
   */
  deviceModifySetting?: AssistantDevicesPlatformProtoDeviceModifySettingCapability;
  /**
   * [device_take_photo] specifies the support for the device.TAKE_PHOTO
   * clientop, and the corresponding device_take_photo field in
   * assistant.embedded.v1.DeviceOp.
   */
  deviceTakePhoto?: AssistantDevicesPlatformProtoDeviceTakePhotoCapability;
  mediaNext?: AssistantDevicesPlatformProtoMediaNextCapability;
  mediaPause?: AssistantDevicesPlatformProtoMediaPauseCapability;
  mediaPlayMedia?: AssistantDevicesPlatformProtoMediaPlayMediaCapability;
  mediaPrevious?: AssistantDevicesPlatformProtoMediaPreviousCapability;
  mediaResume?: AssistantDevicesPlatformProtoMediaResumeCapability;
  mediaStop?: AssistantDevicesPlatformProtoMediaStopCapability;
  /**
   * |provider_open| specifies the support for provider.OPEN client_op, and the
   * corresponding provider_open field in assistant.embedded.v1.DeviceOp.
   */
  providerOpen?: AssistantDevicesPlatformProtoProviderOpenCapability;
  /**
   * |send_chat_message| specifies the support for the chat_message.SEND
   * clientop, and the corresponding send_chat_message field in
   * assistant.embedded.v1.DeviceOp.
   */
  sendChatMessage?: AssistantDevicesPlatformProtoSendChatMessageCapability;
}

/**
 * Capability with regard to support of timers by the client.
 */
export interface AssistantDevicesPlatformProtoTimerCapability {
  /**
   * Maximum extended timer duration supported by the client. The extended
   * timer duration is the total start-to-finish duration after an
   * AddTimeToTimer operation. E.g. if a user sets a timer for 30 minutes, and
   * later adds 10 minutes, the extended duration is 40 minutes. Zero or unset
   * indicates no maximum limit.
   */
  maxSupportedExtendedTimerDuration?: AssistantApiDuration;
  /**
   * Maximum timer duration supported by the client. Zero or unset indicates no
   * maximum limit.
   */
  maxSupportedTimerDuration?: AssistantApiDuration;
  /**
   * Maximum number of timers that can be created on the client. Zero or unset
   * indicates no maximum limit.
   */
  maxSupportedTimers?: number;
  /**
   * Whether the client supports the MUTATE timer action. If this is false,
   * mutate operations may be handled by sending a pair of REMOVE and CREATE
   * timer actions to replace the existing timer instead of mutating it.
   */
  supportsMutateAction?: boolean;
}

function serializeAssistantDevicesPlatformProtoTimerCapability(data: any): AssistantDevicesPlatformProtoTimerCapability {
  return {
    ...data,
    maxSupportedExtendedTimerDuration: data["maxSupportedExtendedTimerDuration"] !== undefined ? serializeAssistantApiDuration(data["maxSupportedExtendedTimerDuration"]) : undefined,
    maxSupportedTimerDuration: data["maxSupportedTimerDuration"] !== undefined ? serializeAssistantApiDuration(data["maxSupportedTimerDuration"]) : undefined,
  };
}

function deserializeAssistantDevicesPlatformProtoTimerCapability(data: any): AssistantDevicesPlatformProtoTimerCapability {
  return {
    ...data,
    maxSupportedExtendedTimerDuration: data["maxSupportedExtendedTimerDuration"] !== undefined ? deserializeAssistantApiDuration(data["maxSupportedExtendedTimerDuration"]) : undefined,
    maxSupportedTimerDuration: data["maxSupportedTimerDuration"] !== undefined ? deserializeAssistantApiDuration(data["maxSupportedTimerDuration"]) : undefined,
  };
}

/**
 * A TriggerCondition is described as a set of states which must be met by the
 * device. It also includes instructions to the Assistant on what kind of
 * response to execute when the condition is not met.
 */
export interface AssistantDevicesPlatformProtoTriggerCondition {
  /**
   * The map of state keys along with their values which must be returned by
   * the device, for example to start the dishwasher you may require states:
   * {"door": "CLOSED", "detergent_status": "READY"}.
   */
  requiredStateValues?: {
    [key: string]: AssistantDevicesPlatformProtoArgSpec
  };
  /**
   * A simple TTS to play.
   */
  simpleTts?: string;
  /**
   * Refers to a defined ConditionalResult keyed by its status. It could be a
   * built-in or custom ConditionalResult for this Intent. Note: the states
   * provided by the device MUST contain all of the states required by the
   * ConditionalResult.
   */
  status?: string;
}

function serializeAssistantDevicesPlatformProtoTriggerCondition(data: any): AssistantDevicesPlatformProtoTriggerCondition {
  return {
    ...data,
    requiredStateValues: data["requiredStateValues"] !== undefined ? Object.fromEntries(Object.entries(data["requiredStateValues"]).map(([k, v]: [string, any]) => ([k, serializeAssistantDevicesPlatformProtoArgSpec(v)]))) : undefined,
  };
}

function deserializeAssistantDevicesPlatformProtoTriggerCondition(data: any): AssistantDevicesPlatformProtoTriggerCondition {
  return {
    ...data,
    requiredStateValues: data["requiredStateValues"] !== undefined ? Object.fromEntries(Object.entries(data["requiredStateValues"]).map(([k, v]: [string, any]) => ([k, deserializeAssistantDevicesPlatformProtoArgSpec(v)]))) : undefined,
  };
}

/**
 * Specifies the NLU level that Google performs, which determines the request
 * format sent to the 3P cloud.
 */
export interface AssistantDevicesPlatformProtoUnderstandingConfig {
  /**
   * Specifies the NLU level for the intent.
   */
  nluLevel?:  | "DEFAULT_SHALLOW_NLU" | "NO_NLU" | "DEEP_NLU";
}

/**
 * The information associated with an error while selecting the target device.
 * Next ID: 2
 */
export interface AssistantDeviceTargetingDeviceTargetingError {
  type?:  | "UNKNOWN_ERROR" | "NO_DEVICE_IN_SAME_STRUCTURE" | "NO_DEVICE_IN_SAME_NETWORK_OR_LOCATION" | "NO_DEVICE_IN_SAME_STRUCTURE_OR_NETWORK_OR_LOCATION" | "NO_DEVICE_SATISFIES_SAME_STRUCTURE_OR_UNKNOWN_IF_OWNED" | "NO_DEVICE_SATISFIES_CAPABILITIES_REQUIREMENT" | "NO_DEVICE_MATCHED_DEVICE_ANNOTATION" | "MULTI_TARGET_DEVICE_NOT_SUPPORTED" | "NO_DEVICE_AFTER_LOCAL_DEVICE_EXCLUDED" | "UNABLE_TO_TARGET_ONLY_LOCAL_DEVICE" | "NO_DEVICE_MATCHED_REQUIRED_TRAITS" | "NO_DEVICE_MATCHED_REQUIRED_DEVICE_TYPE" | "NO_DEVICE_IN_SAME_OR_MENTIONED_STRUCTURE" | "NO_DEVICE_SATISFIES_PLAYBACK_REQUIREMENT" | "STRUCT_DISAMBIG_NOT_SUPPORTED" | "ROOM_DISAMBIG_NOT_SUPPORTED" | "UNRECOGNIZED_DEVICE_NAME" | "NO_LINKED_REMOTE_DEVICES" | "NO_LINKED_REMOTE_VIDEO_DEVICES" | "NO_SAFE_DEVICE_WITH_SCREEN" | "ALL_QUALIFIED_DEVICES_OFFLINE" | "CROSS_STRUCTURE_TARGETING_DISALLOWED" | "NO_DEVICE_MEETS_PROVIDER_REQUIREMENT" | "MISSING_LOCAL_DEVICE_SETTING" | "NO_DEVICE_HAS_REQUIRED_APP" | "HYBRID_DEVICE_NOT_QUALIFIED" | "NO_NEARBY_DEVICES";
}

export interface AssistantGroundingRankerAssistantInteractionFeatures {
  timeDecayed14dHalfLife?: number;
  /**
   * Frequency features.
   */
  timeDecayed1dHalfLife?: number;
  timeDecayed7dHalfLife?: number;
  timeDecayedAccepted14dHalfLife?: number;
  timeDecayedAuis14dHalfLife?: number;
  timeDecayedCanceled14dHalfLife?: number;
  timeDecayedDeclined14dHalfLife?: number;
  timeSinceLastButOneCanceledActionSecs?: number;
  timeSinceLastButOneCompletedActionSecs?: number;
  timeSinceLastButTwoCanceledActionSecs?: number;
  timeSinceLastButTwoCompletedActionSecs?: number;
  timeSinceLastCanceledActionSecs?: number;
  /**
   * Recency features.
   */
  timeSinceLastCompletedActionSecs?: number;
}

/**
 * Features to be passed from Contact GP to HGR. Next ID: 13
 */
export interface AssistantGroundingRankerContactGroundingProviderFeatures {
  /**
   * Concept id for relationships in English, e.g. "Mother" for all non-English
   * locales. It's only populated for source = RELATIONSHIP.
   */
  conceptId?: string;
  contactSource?:  | "FOCUS_CONTACT" | "DEVICE_CONTACT" | "GMAIL_INFERENCE" | "S3_DECORATOR" | "RELATIONSHIP" | "VANITY" | "SIGNED_OUT_DEVICE" | "SHARED_CONTACT" | "FAMILY_MEMBER" | "SHARED_DEVICE_USER" | "ON_DEVICE_CONTACT_LOOKUP";
  /**
   * Whether the query is a relationship query based on the annotation source.
   */
  isRelationshipFromAnnotation?: boolean;
  /**
   * Whether the contact has relationship in the contact metadata.
   */
  isRelationshipFromSource?: boolean;
  /**
   * Whether only populates a single candidate.
   */
  isSingleCandidate?: boolean;
  /**
   * Whether the contact is starred contact.
   */
  isStarred?: boolean;
  matchedNameType?:  | "UNSPECIFIED" | "GIVEN_NAME" | "FAMILY_NAME" | "FULL_NAME" | "NICKNAME" | "OTHER" | "INITIAL_WITH_FAMILY_NAME" | "EMAIL_USERNAME" | "VANITY_NICKNAME" | "GIVEN_NAME_ALIAS" | "FULL_NAME_ALIAS" | "HOMOPHONE_GIVEN_NAME" | "HOMOPHONE_FAMILY_NAME" | "HOMOPHONE_FULL_NAME" | "HOMOPHONE_NICKNAME" | "GIVEN_MIDDLE_NAME" | "GIVEN_NAME_WITH_FAMILY_NAME_INITIAL" | "EMAIL_OF_FAMILY_MEMBER";
  /**
   * Number of alternate contact names from fuzzy contact match. (Not suggest
   * using it since it can change due to retrieval iteration)
   */
  numAlternateNameFromFuzzyContactMatch?: number;
  /**
   * Number of alternate contact names from S3_HYPOTHESES. (Not suggest using
   * it since it can change due to retrieval iteration)
   */
  numAlternateNamesFromS3?: number;
  /**
   * Number of alternate contact names from interpretation. (Not suggest using
   * it since it can change due to retrieval iteration)
   */
  numAlternativeNamesFromInterpretation?: number;
  /**
   * Number of contacts populated by the contact Grounding Provider. (Not
   * suggest using it since it can change due to retrieval iteration)
   */
  numCandidates?: number;
  recognitionAlternateSource?:  | "NONE" | "S3_HYPOTHESES" | "GENIE_QUERY_ALTERNATIVES" | "NAME_CORRECTION_LOG" | "FUZZY_CONTACT_MATCH" | "NEURAL_CONTACT_MATCH" | "NEURAL_CONTACT_MATCH_DARK_LAUNCH";
}

/**
 * Device contact affinity from android call logs.
 */
export interface AssistantGroundingRankerDeviceContactAffinityFeatures {
  aggregateAffinity?: number;
  callAffinity?: number;
  messageAffinity?: number;
}

/**
 * Next ID: 4
 */
export interface AssistantGroundingRankerGroundingProviderFeatures {
  contactGroundingProviderFeatures?: AssistantGroundingRankerContactGroundingProviderFeatures;
  mediaGroundingProviderFeatures?: AssistantGroundingRankerMediaGroundingProviderFeatures;
  providerGroundingProviderFeatures?: AssistantGroundingRankerProviderGroundingProviderFeatures;
}

export interface AssistantGroundingRankerLaaFeatures {
  bindingSet?: AssistantGroundingRankerLaaFeaturesBindingSet;
  communicationEndpoint?: AssistantGroundingRankerLaaFeaturesCommunicationEndpoint;
  contact?: AssistantGroundingRankerLaaFeaturesContact;
  provider?: AssistantGroundingRankerLaaFeaturesProvider;
}

export interface AssistantGroundingRankerLaaFeaturesBindingSet {
  assistantInteractionFeatures?: AssistantGroundingRankerAssistantInteractionFeatures;
}

export interface AssistantGroundingRankerLaaFeaturesCommunicationEndpoint {
  assistantInteractionFeatures?: AssistantGroundingRankerAssistantInteractionFeatures;
}

export interface AssistantGroundingRankerLaaFeaturesContact {
  assistantInteractionFeatures?: AssistantGroundingRankerAssistantInteractionFeatures;
  deviceContactAffinityFeatures?: AssistantGroundingRankerDeviceContactAffinityFeatures;
}

export interface AssistantGroundingRankerLaaFeaturesProvider {
  assistantInteractionFeatures?: AssistantGroundingRankerAssistantInteractionFeatures;
}

/**
 * Features to be passed from Media GP to HGR. Next ID: 6
 */
export interface AssistantGroundingRankerMediaGroundingProviderFeatures {
  /**
   * Whether the candidate is YouTube CAST_VIDEO candidate. CAST_VIDEO is a
   * deeplink platform. This signal will be used to promote YouTube Music
   * screenful candidates with CAST_VIDEO platform for free users because free
   * users cannot get exact entities in screenless response and can get exact
   * entities with ads in screenful response.
   */
  isCastVideo?: boolean;
  /**
   * True if the media deeplink has tag SEED_RADIO.
   */
  isSeedRadio?: boolean;
  /**
   * True if the user requests seed radio.
   */
  isSeedRadioRequest?: boolean;
  /**
   * MSC(Media Short Click) rate. MSC rate = total number of MSC events / total
   * number of MSC candidates The event is considered as MSC candidate if the
   * event is a media seeking query(excluding follow-ons) and the media result
   * is successfully fulfilled. The event is MSC event if any of the following
   * is in the following queries within 30 secs: FOLLOWED_BY_DUPLICATE
   * FOLLOWED_BY_ADD_OR_DELETE_MANUAL_REFINEMENT FOLLOWED_BY_SAME_VERTICAL
   * (MEDIA) FOLLOWED_BY_STOP More details: go/media-ranking,
   * go/billboard-navboost, go/magma-music-actions-efrac
   */
  mscRate?: number;
  /**
   * Scubed predicted SAI value (pSAI) for music populated by a regression
   * model that incorporates a BERT model signal as well as other Scubed
   * signals.
   */
  scubedPSaiMusic?: number;
}

/**
 * Features to be extracted from Provider GP for ranking in HGR. Next ID: 2
 */
export interface AssistantGroundingRankerProviderGroundingProviderFeatures {
  /**
   * Provider quality score in the range [0,1] that can be used for ranking
   * providers. Incorporates both policy rules and quality considerations.
   */
  pslScore?: number;
}

export interface AssistantLogsAllMediaStreamLog {
  /**
   * All active media streams while the user issues the query.
   */
  streams?: AssistantLogsMediaStreamLog[];
  /**
   * The stream selected by stream transfer logic to be transferred to another
   * device. It will be empty for other features. Target_stream is different
   * from target_device since target_stream could have multiple devices.
   */
  targetStream?: AssistantLogsMediaStreamLog;
}

/**
 * This message logs details on ambiguous device targeting logic. 1. It first
 * takes a list of ambiguous devices 2. Then applies two filters: structure
 * filter and playability filter. 3. If more than one device remains, it tiggers
 * DeviceSelectionDialog to let the user pick one device.
 */
export interface AssistantLogsAmbiguousTargetDeviceLog {
  /**
   * Device index of the initial ambiguous devices. The device index in this
   * message is consistent with the device index in DeviceInfoLog. It would be
   * used to track more detailed information of a device if needed.
   */
  ambiguousDeviceIndex?: number[];
  /**
   * DeviceInfo for devices after the filters and promoters. - When device
   * targeting is only configured for single target, these are ambiguous devices
   * that would have been the output of Lumos. Downstream may perform extra
   * check before disambiguation dialog. For example, Media Initiation checks
   * playability for devices. The output here is before the check. - When
   * configured for multi-target, these are just the target devices. For privacy
   * consideration, we may only log device id field inside.
   */
  devicesAfterPromoters?: AssistantLogsDeviceInfoLog[];
  /**
   * the final targeted device selected by playability filter or
   * DeviceSelectionDialog
   */
  finalTargetDevice?: AssistantLogsDeviceInfoLog;
  /**
   * Device index of the devices after playability filter
   */
  playabilityFilteredDevicesIndex?: number[];
  /**
   * When there is no qualified devices after playability check, it would
   * populate punt_info below. If all devices are filtered out for the same
   * reason, there would only be one item. Otherwise, there will be multiple
   * items.
   */
  puntInfoLog?: AssistantLogsAmbiguousTargetDeviceLogPuntInfoLog[];
  /**
   * Device index of the devices after structure filter
   */
  structureFilteredDeviceIndex?: number[];
}

/**
 * PuntInfoLog is used to log why devices get filtered out during media content
 * playability check. It contains media excuse, provider mid and also index of
 * devices filtered by them.
 */
export interface AssistantLogsAmbiguousTargetDeviceLogPuntInfoLog {
  /**
   * Index of devices that have the same punt info during playability check,
   * i.e. same media_excuse and provider_mid.
   */
  deviceIndex?: number[];
  /**
   * Excuse for media action triggering. See:
   * assistant/verticals/media/proto/media_excuse.proto.
   */
  mediaExcuse?: number;
  /**
   * Provider id that the excuse belongs to. This is the KG MID of the
   * provider, e.g., "/m/09jcvs" for Youtube.
   */
  providerMid?: string;
}

/**
 * This is the log version of
 * apps.people.oz.external.mergedpeopleapi.DeviceContactInfo Next ID: 2
 */
export interface AssistantLogsCommunicationDeviceContactInfoLog {
  /**
   * This list provides account information from the raw contact which is the
   * source of this field.
   */
  rawContactInfo?: AssistantLogsCommunicationRawDeviceContactInfoLog[];
}

/**
 * This is the log version of fuzzy ngram match results that's used for
 * generating the best fuzzy match. Next ID: 3
 */
export interface AssistantLogsCommunicationFuzzyNgramMatchLog {
  relativeCost?: number;
  type?:  | "NONE" | "EDIT_DISTANCE" | "GENIE_PLEXICON_DISTANCE" | "GENIE_ALTERNATIVE_RECOGNITION" | "JAPANESE_NAME_TRANSLITERATOR";
}

/**
 * From google3/quality/qrewrite/proto/account_provenance.proto;l=14 We need to
 * copy this as the above proto has Enum field which is not compatible between
 * proto2 and proto3. go/proto2-versus-proto3#enums
 */
export interface AssistantLogsCommunicationGoogleAccountProvenance {
  email?: string;
  gaiaId?: bigint;
  isDasherAccount?: boolean;
}

function serializeAssistantLogsCommunicationGoogleAccountProvenance(data: any): AssistantLogsCommunicationGoogleAccountProvenance {
  return {
    ...data,
    gaiaId: data["gaiaId"] !== undefined ? String(data["gaiaId"]) : undefined,
  };
}

function deserializeAssistantLogsCommunicationGoogleAccountProvenance(data: any): AssistantLogsCommunicationGoogleAccountProvenance {
  return {
    ...data,
    gaiaId: data["gaiaId"] !== undefined ? BigInt(data["gaiaId"]) : undefined,
  };
}

/**
 * Contact meta data. Next ID: 30
 */
export interface AssistantLogsCommunicationPersonalContactDataLog {
  /**
   * Google AccountProvenance of the contact.
   */
  accountProvenance?: AssistantLogsCommunicationGoogleAccountProvenance;
  /**
   * Populated if matched_name_type is GIVEN_NAME_ALIAS or FULL_NAME_ALIAS.
   */
  commonNameAliasConfidence?: number;
  /**
   * Concept id for relationships in English, e.g. "Mother" for all non-English
   * locales. It's only populated for source = RELATIONSHIP.
   */
  conceptId?: string;
  /**
   * Integer value corresponding to DeviceContactExtraMetadata.Attribute enum.
   * http://google3/social/graph/wire/proto/merged_person.proto?l=933&rcl=320308954
   */
  deviceContactAttributes?: number[];
  /**
   * # emails stored for the contact.
   */
  emailIdCount?: number;
  /**
   * Populate only if ContactRecognitionAlternate.Source is
   * 'FUZZY_CONTACT_MATCH'.
   */
  fuzzyNgramMatch?: AssistantLogsCommunicationFuzzyNgramMatchLog[];
  /**
   * Contact owner's gaia id from
   * cs/symbol::symbol:quality_qrewrite.PersonalContactData.shared_contact_owner_gaia_id.
   * Only populated for is_shared = true and non sign-out mode and user is not
   * the owner of the contact(shared contact from other user).
   */
  gaiaId?: bigint;
  /**
   * Boolean value indicating whether selected contact is from different
   * account than the logged in account.
   */
  isContactFromSecondaryAccount?: boolean;
  /**
   * If this is a shared contact. This is true in 2 cases: - User is calling
   * their own contacts that have been marked as shared. - User is calling
   * shared contacts from some other user's contact list.
   */
  isShared?: boolean;
  /**
   * Indicate the contact matches the transliterated query.
   */
  isTransliteratedMatch?: boolean;
  /**
   * True if the contact is a vanity contact(has email = user's email address).
   */
  isVanityContact?: boolean;
  /**
   * If the lookup was done using relationship which is visible to guests. This
   * value will only be set if lookup was done using relationship. E.g. user has
   * a guest relationship (doctor) -> (John) And user says "call doctor", then
   * this value will be true.
   */
  isVisibleToGuestsRelationship?: boolean;
  /**
   * The matched name type of a contact candidate.
   */
  matchedNameType?:  | "UNSPECIFIED" | "GIVEN_NAME" | "FAMILY_NAME" | "FULL_NAME" | "NICKNAME" | "OTHER" | "INITIAL_WITH_FAMILY_NAME" | "EMAIL_USERNAME" | "VANITY_NICKNAME" | "GIVEN_NAME_ALIAS" | "FULL_NAME_ALIAS" | "HOMOPHONE_GIVEN_NAME" | "HOMOPHONE_FAMILY_NAME" | "HOMOPHONE_FULL_NAME" | "HOMOPHONE_NICKNAME" | "GIVEN_MIDDLE_NAME" | "GIVEN_NAME_WITH_FAMILY_NAME_INITIAL" | "EMAIL_OF_FAMILY_MEMBER";
  /**
   * Alternate recognition term which was used to match this contact.
   */
  matchedRecognitionAlternateName?: string;
  /**
   * Ngram matched by starlight lookup for fuzzy matching in fulfillment. We
   * need this to analyze how many contacts are returned by starlight lookup
   * that is not matched by fuzzy matching. For example, "Komal Dear" is matched
   * to "Komal Dr" by fuzzy match. When doing starlight lookup, "Komal" and "Dr"
   * will be looked up separately. So "Dr xxx" will also be returned. We want to
   * see how often this happens.
   */
  matchedStarlightLookupName?: string[];
  /**
   * PersonMetadata of the selected contact.
   */
  metadata?: AssistantLogsCommunicationPersonMetadataLog;
  /**
   * The indices of the contact in |candidate_contact| whose name matches the
   * |selected_contact_data|. |candidate_contact|:
   * http://google3/logs/proto/assistant/contact.proto?l=111&rcl=306283376
   * |selected_contact_data|:
   * http://google3/logs/proto/assistant/contact.proto?l=108&rcl=306283376
   */
  nameMatchedContactIndex?: number[];
  /**
   * The original name in the query as transcribed by ASR.
   */
  originalQueryName?: string;
  /**
   * Information regarding the phone endpoints of the selected contact.
   * Currently it is only logged for selected candidate.
   */
  phone?: AssistantLogsCommunicationPhoneLog[];
  /**
   * # phone_numbers stored for the contact.
   */
  phoneNumberCount?: number;
  /**
   * Encodes if pkg_person was resolved via a name or relationship reference.
   */
  pkgReferenceType?:  | "UNKNOWN_PKG_REFERENCE_TYPE" | "PKG_NAME_REFERENCE" | "PKG_RELATIONSHIP_REFERENCE";
  /**
   * Populate only if ContactRecognitionAlternate.Source is not NONE.
   */
  recognitionAlternateScore?: number;
  /**
   * Recognition alternative source type. If not none, then it indicates the
   * personal contact data is alternative and how the alternative is fulfilled.
   */
  recognitionAlternateSource?:  | "NONE" | "S3_HYPOTHESES" | "GENIE_QUERY_ALTERNATIVES" | "NAME_CORRECTION_LOG" | "FUZZY_CONTACT_MATCH" | "NEURAL_CONTACT_MATCH" | "NEURAL_CONTACT_MATCH_DARK_LAUNCH";
  /**
   * The number of resolved relationship names and contact pointers from
   * Assistant Memory.
   */
  relationshipMemoryCount?: number;
  /**
   * Information regarding the selected phone endpoint. Currently it is only
   * logged for selected candidate.
   */
  selectedPhone?: AssistantLogsCommunicationPhoneLog;
  /**
   * Shortcut information of the contact.
   */
  shortcutContactInfo?: MajelContactInformationShortcutInformation;
  /**
   * The contact source of a contact candidate.
   */
  source?:  | "UNKNOWN" | "FOCUS_CONTACT" | "DEVICE_CONTACT" | "GMAIL_INFERENCE" | "S3_DECORATOR" | "RELATIONSHIP" | "VANITY" | "SIGNED_OUT_DEVICE" | "SHARED_CONTACT" | "FAMILY_MEMBER" | "SHARED_DEVICE_USER" | "ON_DEVICE_CONTACT_LOOKUP";
  /**
   * Integer value corresponding to SystemContactGroup enum.
   * http://google3/social/graph/wire/proto/merged_person.proto?l=3151&rcl=320308954
   */
  systemContactGroupId?: number[];
  /**
   * DEPRECATED. Use phone instead. Used before 2020-01-13. Number of phone
   * numbers annotated with Whatsapp.
   */
  whatsappPhoneNumberCount?: number;
}

function serializeAssistantLogsCommunicationPersonalContactDataLog(data: any): AssistantLogsCommunicationPersonalContactDataLog {
  return {
    ...data,
    accountProvenance: data["accountProvenance"] !== undefined ? serializeAssistantLogsCommunicationGoogleAccountProvenance(data["accountProvenance"]) : undefined,
    gaiaId: data["gaiaId"] !== undefined ? String(data["gaiaId"]) : undefined,
  };
}

function deserializeAssistantLogsCommunicationPersonalContactDataLog(data: any): AssistantLogsCommunicationPersonalContactDataLog {
  return {
    ...data,
    accountProvenance: data["accountProvenance"] !== undefined ? deserializeAssistantLogsCommunicationGoogleAccountProvenance(data["accountProvenance"]) : undefined,
    gaiaId: data["gaiaId"] !== undefined ? BigInt(data["gaiaId"]) : undefined,
  };
}

/**
 * This is the log version of
 * apps.people.oz.external.mergedpeopleapi.PersonMetadata Next ID: 2
 */
export interface AssistantLogsCommunicationPersonMetadataLog {
  deviceContactInfo?: AssistantLogsCommunicationDeviceContactInfoLog[];
}

/**
 * This is the log version of apps.people.oz.external.mergedpeopleapi.Phone
 * proto. Next ID: 3
 */
export interface AssistantLogsCommunicationPhoneLog {
  /**
   * This list provides account information from the raw contact which is the
   * source of this field.
   */
  rawDeviceContactInfo?: AssistantLogsCommunicationRawDeviceContactInfoLog[];
  /**
   * Label for phone number in the Contacts app. It can have standard values
   * provided by the app e.g. MOBILE, HOME, WORK etc, but users are allowed to
   * modify. So essentially it becomes user content.
   */
  type?: string;
}

/**
 * This is the log version of
 * apps.people.oz.external.mergedpeopleapi.RawDeviceContactInfo proto. Next ID:
 * 3
 */
export interface AssistantLogsCommunicationRawDeviceContactInfoLog {
  /**
   * Account type of raw contact, e.g. "com.google" or "com.linkedin.android".
   */
  accountType?: string;
}

/**
 * Log device info of default speaker and tv
 */
export interface AssistantLogsDefaultDeviceLog {
  defaultSpeaker?: AssistantLogsDeviceInfoLog;
  defaultTv?: AssistantLogsDeviceInfoLog;
  sourceDeviceId?: string;
}

export interface AssistantLogsDefaultDevicesLog {
  localDefaultDevices?: AssistantLogsDefaultDeviceLog;
  /**
   * Default settings of nearby devices.
   */
  nearbyDefaultDevices?: AssistantLogsDefaultDeviceLog[];
}

/**
 * Device annotation mention from query
 */
export interface AssistantLogsDeviceAnnotationLog {
  /**
   * The raw text mentioning a device from the query, such as "any tv".
   */
  rawTextFromQuery?: string;
  /**
   * The annotation type mentioned in the query.
   */
  type?:  | "NO_DEVICE_ANNOTATION" | "DEVICE_ID_ANNOTATION" | "DEVICE_TYPE_ANNOTATION" | "DEVICE_TEXT_ANNOTATION";
  /**
   * The matched device name set by the user, such as "big screen tv".
   */
  userDefinedName?: string;
}

/**
 * The information related to the device.
 */
export interface AssistantLogsDeviceInfoLog {
  /**
   * Device identifier string for the current device used in the arbitration
   * service.
   */
  arbitrationDeviceId?: string;
  connectivity?:  | "UNKNOWN_CONNECTIVITY" | "ONLINE_STATE" | "OFFLINE_STATE";
  /**
   * The identification of the device. DeviceId (go/as-device-id) has multiple
   * fields. To consloidate it to a single to make dremel easier, we use the
   * string obtained by calling go/get-device-id.
   */
  deviceId?: string;
  /**
   * The identification of the device. The logging version of the full
   * DeviceId.
   */
  deviceIdLog?: AssistantLogsSettingsDeviceIdLog;
  /**
   * We index linked devices and log these index to avoid logging device_id.
   * device_index should always be a positive number or -1. -1 means this device
   * is not in homegraph.
   */
  deviceIndex?: number;
  /**
   * This is the device_model_id field in device_settings proto. It has the
   * same value for the same type of devices. e.g. Sonos.Sonos One.S13
   */
  deviceModelId?: string;
  /**
   * 
   * LINT.ThenChange(//depot/google3/assistant/context/proto/device_arbitration.proto:EstimatedRelativeDistance)
   */
  distance?:  | "UNKNOWN_DISTANCE" | "CLOSEST" | "EQUALLY_CLOSE" | "FURTHER";
  /**
   * The lumos processor which eliminated this device, if applicable
   */
  eliminatingLumosProcessor?:  | "UNKNOWN_LUMOS_PROCESSOR" | "CAPABILITIES_FILTER" | "DEVICE_ANNOTATION_FILTER" | "DEVICE_CONNECTIVITY_FILTER" | "LOCAL_DEVICE_INCLUSIVENESS_FILTER" | "LOCATION_FILTER" | "MEDIA_PLAYBACK_FILTER" | "SAFETY_FILTER" | "TRAITS_FILTER" | "DEVICE_TYPE_FILTER" | "APP_FILTER" | "HYBRID_DEVICE_PROPERTIES_FILTER" | "NEARBY_DEVICE_FILTER" | "DEFAULT_MEDIA_OUTPUT_PROMOTER" | "DEVICE_GROUP_PROMOTER" | "LOCAL_DEVICE_PROMOTER" | "LOCATION_PROMOTER" | "MEDIA_FOCUS_PROMOTER" | "MEDIA_PLAYBACK_PROMOTER" | "SAME_NAME_DEVICE_PROMOTER" | "PHONE_TARGETING_PROMOTER" | "TRAITS_PROMOTER" | "DEVICE_TYPE_PROMOTER";
  isRemote?: boolean;
  /**
   * This flag indicates this is a non-local device that is tethered to
   * local/originating device. Tethered device is a special case of is_remote
   * and typically used in wearable scenarios. This is always false for local
   * device and when it is true, it implies is_remote is also true.
   */
  isTethered?: boolean;
  mediaCapabilities?: AssistantLogsMediaCapabilities;
  mediaDeviceType?:  | "UNKNOWN_DEVICE_TYPE" | "ASSISTANT" | "HOME_AUTOMATION" | "CAST" | "CAST_GROUP" | "QUARTZ" | "QUARTZ_IOS" | "CLOUD_AUTO";
  /**
   * User defined device name
   */
  name?: string;
  /**
   * This field should be populated only when there is at least one session on
   * this device.
   */
  sessions?: AssistantLogsDeviceMediaSessionLog[];
  /**
   * This field should be populated only when the device is an Assistant
   * device.
   */
  surfaceType?:  | "UNKNOWN" | "ANDROID_ALLO" | "ANDROID_AUTO" | "ANDROID_THINGS_CUBE" | "ANDROID_THINGS_JASPER" | "ANDROID_TV" | "ANDROID_TV_KIDS" | "ANDROID_WEAR" | "AR_GLASSES" | "ASSISTANT_SDK" | "AUDIOWEAR" | "BUBBLE_CHARACTERS_IOS" | "CAPABILITY_BASED_SURFACE" | "CHROMECAST_ASSISTANT" | "CHROMECAST_MANHATTAN" | "CHROMECAST_SEARCH" | "CLOUD_DEVICE" | "COMPANION_SCREEN" | "DYNAMITE_WEB" | "ENSEMBLE" | "EYESFREE_AGSA" | "EYESFREE_GMM" | "GBOARD" | "GLASS" | "GOOGLE_HOME" | "HANGOUTS_CHATBOT" | "IOS_ALLO" | "IOS_GSA" | "IOS_WEAR" | "LIBASSISTANT" | "LINE_CHATBOT" | "MULTIMODAL_AGSA" | "NON_ASSISTANT_SURFACE" | "OPA_AGSA" | "OPA_AGSA_CHROME_OS" | "OPA_ANDROID_AUTO" | "OPA_ANDROID_LITE" | "OPA_ANDROID_SCREENLESS" | "OPA_ANDROID_SMART_DISPLAY" | "OPA_ANDROID_TABLET" | "OPA_CROS" | "OPA_GACS" | "OPA_IOS" | "OPA_IOS_SCREENLESS" | "OPA_KAIOS" | "OPA_MOBILE_WEB" | "RTOS_PHONE" | "SMS_CHATBOT" | "TELEGRAM_CHATBOT" | "TELEPHONE_ASSISTANT" | "VERILY_ONDUO" | "YOUTUBE_APP" | "AGSA_BISTO_FOR_EVAL" | "COGSWORTH_FOR_EVAL" | "LOCKHART_MIC_FOR_EVAL" | "OPA_ANDROID_AUTO_EMBEDDED_FAKE" | "SPARK" | "WALLE" | "UNIT_TESTING";
}

/**
 * Log about the media session on a device.
 */
export interface AssistantLogsDeviceMediaSessionLog {
  deviceId?: AssistantApiCoreTypesDeviceId;
  mediaSessionType?:  | "UNKNOWN" | "SINGLE_DEVICE_SESSION" | "STATIC_GROUP_SESSION" | "DYNAMIC_GROUP_SESSION";
  /**
   * The type of the media session. If provider does not report this field, we
   * ## compute it by mapping provider type to media type. Here is the mapping:
   * |ProviderType |MediaItemMetadata.Type|
   * |-------------------------------------- |MUSIC |TRACK | |VIDEO |VIDEO |
   * |LIVE_TV |TV_CHANNEL | |AUDIOBOOK |AUDIO_BOOK | |PODCAST |PODCAST_EPISODE |
   * ## |LIVE_STREAMING|VIDEO |
   */
  mediaType?:  | "UNKNOWN" | "TRACK" | "ALBUM" | "ARTIST" | "PLAYLIST" | "EPISODE" | "MOVIE" | "PHOTO" | "TV_SHOW_EPISODE" | "MUSIC_GENRE" | "MUSIC_STATION" | "AUDIO_BOOK" | "CHAPTER" | "RADIO_STATION" | "MUSIC_MIX" | "SPORTS_EVENT" | "TV_CHANNEL" | "VIDEO" | "YOUTUBE_CHANNEL" | "YOUTUBE_VIDEO_PLAYLIST" | "TV_SHOW" | "NEWS" | "NARRATED_WEB" | "NEWS_CALL_TO_ACTION" | "AUDIO_STORY" | "PODCAST_SERIES" | "PODCAST_EPISODE";
  /**
   * The playback states of the session.
   */
  playbackState?:  | "UNKNOWN_STATE" | "STOPPED" | "PAUSED" | "PLAYING" | "FAST_FORWARDING" | "REWINDING" | "BUFFERING" | "ERROR" | "CONNECTING" | "SKIPPING_TO_PREVIOUS" | "SKIPPING_TO_NEXT" | "SKIPPING_TO_QUEUE_ITEM";
  /**
   * The KG mid of the media provider.
   */
  providerMid?: string;
  supportedTransportControl?:  | "UNKNOWN_COMMAND" | "PLAY_FROM_SEARCH" | "PLAY_FROM_URI" | "SEND_CUSTOM_ACTION" | "SKIP_TO_NEXT" | "SKIP_TO_PREVIOUS" | "PLAY" | "PAUSE" | "STOP" | "SET_RATING" | "SEEK_TO" | "SHUFFLE" | "REWIND" | "FAST_FORWARD" | "SKIP_TO_QUEUE_ITEM" | "SET_REPEAT_MODE" | "SET_CAPTIONING_ENABLED"[];
}

/**
 * Contains information logged in target device selection. See
 * go/improve-device-targeting-logging for details. Next Id: 22
 */
export interface AssistantLogsDeviceSelectionLog {
  /**
   * Default settings of all nearby devices Deprecated, use default_devices_log
   * instead.
   */
  allDefaultDevices?: AssistantLogsDefaultDeviceLog[];
  /**
   * Logs all active media sessions.
   */
  allMediaStreamLog?: AssistantLogsAllMediaStreamLog;
  /**
   * DeviceSelectionLog for counterfactual logging.
   */
  counterfactualDeviceSelectionLog?: AssistantLogsDeviceSelectionLog;
  /**
   * Include default tv and default speaker Deprecated, use all_default_devices
   * below.
   */
  defaultDevices?: AssistantLogsDefaultDeviceLog;
  defaultDevicesLog?: AssistantLogsDefaultDevicesLog;
  /**
   * Temporaray field for debugging ANDROID_AUTO multi_target_devices punt.
   * This will be removed once we identify the root cause.
   */
  devicesStr?: string[];
  inputErrorLog?: AssistantLogsInputErrorLog[];
  /**
   * Now we just log the media sessions on local device Deprecated, use
   * NearbyDevicesLog::LocalDevice instead.
   */
  localDevice?: AssistantLogsDeviceInfoLog;
  /**
   * Indicates which library populated the device_selection_log for this query.
   */
  logDataSource?:  | "UNKNOWN" | "MEDIA_FOCUS_SELECTOR" | "LUMOS_DEVICE_TARGETING_LIBRARY";
  /**
   * The Media Focus information. This field should be populated only when
   * there is a Media Focus. Deprecated, use media_focuses below instead.
   */
  mediaFocus?: AssistantLogsMediaFocusInfoLog;
  /**
   * Media focuses on all devices.
   */
  mediaFocusesLog?: AssistantLogsMediaFocusesLog;
  /**
   * All nearby devices and local device.
   */
  nearbyDevicesLog?: AssistantLogsNearbyDevicesLog;
  /**
   * This should log the query annotation features found in the device, such as
   * the device annotation, the room annotation, and the structure annotation
   * from the query.
   */
  queryAnnotation?: AssistantLogsQueryAnnotationLog;
  /**
   * The result of device selection.
   */
  selectionResult?: AssistantLogsDeviceSelectionResultLog;
  testCodes?: AssistantLogsDeviceTargetingTestCode[];
}

function serializeAssistantLogsDeviceSelectionLog(data: any): AssistantLogsDeviceSelectionLog {
  return {
    ...data,
    counterfactualDeviceSelectionLog: data["counterfactualDeviceSelectionLog"] !== undefined ? serializeAssistantLogsDeviceSelectionLog(data["counterfactualDeviceSelectionLog"]) : undefined,
    nearbyDevicesLog: data["nearbyDevicesLog"] !== undefined ? serializeAssistantLogsNearbyDevicesLog(data["nearbyDevicesLog"]) : undefined,
  };
}

function deserializeAssistantLogsDeviceSelectionLog(data: any): AssistantLogsDeviceSelectionLog {
  return {
    ...data,
    counterfactualDeviceSelectionLog: data["counterfactualDeviceSelectionLog"] !== undefined ? deserializeAssistantLogsDeviceSelectionLog(data["counterfactualDeviceSelectionLog"]) : undefined,
    nearbyDevicesLog: data["nearbyDevicesLog"] !== undefined ? deserializeAssistantLogsNearbyDevicesLog(data["nearbyDevicesLog"]) : undefined,
  };
}

/**
 * Log the selection result. Next ID: 11
 */
export interface AssistantLogsDeviceSelectionResultLog {
  /**
   * Deprecated, please use qualified_devices.
   */
  ambiguousTargetDevices?: AssistantLogsAmbiguousTargetDeviceLog;
  deviceSelectionDecisionSummary?: AssistantLogsMediaDeviceSelectionDecisionSummary;
  deviceTargetingErrorType?:  | "UNKNOWN_ERROR" | "NO_DEVICE_IN_SAME_STRUCTURE" | "NO_DEVICE_IN_SAME_NETWORK_OR_LOCATION" | "NO_DEVICE_IN_SAME_STRUCTURE_OR_NETWORK_OR_LOCATION" | "NO_DEVICE_SATISFIES_SAME_STRUCTURE_OR_UNKNOWN_IF_OWNED" | "NO_DEVICE_SATISFIES_CAPABILITIES_REQUIREMENT" | "NO_DEVICE_MATCHED_DEVICE_ANNOTATION" | "MULTI_TARGET_DEVICE_NOT_SUPPORTED" | "NO_DEVICE_AFTER_LOCAL_DEVICE_EXCLUDED" | "UNABLE_TO_TARGET_ONLY_LOCAL_DEVICE" | "NO_DEVICE_MATCHED_REQUIRED_TRAITS" | "NO_DEVICE_MATCHED_REQUIRED_DEVICE_TYPE" | "NO_DEVICE_IN_SAME_OR_MENTIONED_STRUCTURE" | "NO_DEVICE_SATISFIES_PLAYBACK_REQUIREMENT" | "STRUCT_DISAMBIG_NOT_SUPPORTED" | "ROOM_DISAMBIG_NOT_SUPPORTED" | "UNRECOGNIZED_DEVICE_NAME" | "NO_LINKED_REMOTE_DEVICES" | "NO_LINKED_REMOTE_VIDEO_DEVICES" | "NO_SAFE_DEVICE_WITH_SCREEN" | "ALL_QUALIFIED_DEVICES_OFFLINE" | "CROSS_STRUCTURE_TARGETING_DISALLOWED" | "NO_DEVICE_MEETS_PROVIDER_REQUIREMENT" | "MISSING_LOCAL_DEVICE_SETTING" | "NO_DEVICE_HAS_REQUIRED_APP" | "HYBRID_DEVICE_NOT_QUALIFIED" | "NO_NEARBY_DEVICES";
  /**
   * The class name for the final filter/promoter used by Lumos for device
   * targeting. This filter or promoter runs for all users, and contains no data
   * specific to the individual user.
   */
  finalLumosStage?: string;
  /**
   * //////////////////////////////////////////////////////////////////////////
   * Ambiguous Results: the library failed to select the final target device(s)
   * but it narrows down to a set of devices which are all valid target device
   * candidates. The client needs to do further disambiguation, e.g., giving a
   * dialog or having costomized logic. The low confidence target device means
   * the library falied to select the target device but it picked two devices
   * for the client to do disambiguation.
   */
  lowConfidenceTargetDevice?: AssistantLogsLowConfidenceTargetDeviceLog;
  /**
   * //////////////////////////////////////////////////////////////////////////
   * This field log the error while selecting target device in
   * media_focus_selector.
   */
  mediaFocusSelectionErrorType?:  | "UNKNOWN_ERROR" | "FOUND_MULTIPLE_DEVICES" | "REQUESTED_DEVICE_HAS_NO_SCREEN" | "NO_LINKED_REMOTE_DEVICES" | "NO_LINKED_REMOTE_VIDEO_DEVICES" | "UNRECOGNIZED_DEVICE_NAME" | "UNRECOGNIZED_VIDEO_DEVICE_NAME" | "NO_DEVICE_MEETS_PROVIDER_REQUIREMENT" | "MULTIPLE_DEVICES_MEET_PROVIDER_REQUIREMENT" | "REMOTE_CLOUD_CASTING_NOT_ALLOWED" | "NO_SAFE_DEVICE_WITH_SCREEN" | "NO_DEVICE_MEETS_PLAYBACK_REQUIREMENT" | "MULTIPLE_DEVICES_MEET_PLAYBACK_REQUIREMENT" | "NO_VALID_DEVICE_IN_REQUESTED_ROOM" | "NO_DEVICE_FOUND_IN_REQUESTED_ROOM" | "MULTIPLE_DEVICES_FOUND_IN_REQUESTED_ROOM" | "ALL_QUALIFIED_DEVICES_IN_DIFFERENT_STRUCTURE" | "QUALIFIED_DEVICE_OFFLINE" | "ALL_QUALIFIED_DEVICES_OFFLINE" | "CROSS_STRUCTURE_TARGETING_DISALLOWED" | "NO_DEVICE_MEETS_STADIA_GAMING_CAPABILITY" | "MEDIA_STATES_MISSING" | "NO_DEVICE_SATISFIES_CAPABILITIES_REQUIREMENT" | "HYBRID_DEVICE_NOT_QUALIFIED";
  /**
   * The log for each stage of Lumos, showing the number of eliminated devices
   * from each processor.
   */
  processorInfo?: AssistantLogsLumosProcessorInfo[];
  /**
   * We will apply several filters and dialogs to select a target device if
   * media_focus_selector fail to select one. This field should log the devices
   * left after each filter or dialog. It also log the detailed info of the
   * final target device.
   */
  qualifiedDevices?: AssistantLogsAmbiguousTargetDeviceLog;
  /**
   * //////////////////////////////////////////////////////////////////////////
   * Unambiguous Results: the library successfully selected the final target
   * device(s) and no further disambiguation is needed. Deprecated, please use
   * target_device.
   */
  singleTargetDevice?: AssistantLogsDeviceInfoLog;
  targetDevice?: AssistantLogsTargetDeviceLog;
}

/**
 * Test code is used to track special events happening in Device Targeting
 * Library. Next Id: 2
 */
export interface AssistantLogsDeviceTargetingTestCode {
  type?:  | "UNKNOWN" | "IGNORE_NESTED_DEVICE_MENTION_WITH_ID" | "INCOMPLETE_LOCAL_AUTO_SETTINGS_FOUND" | "FINAL_RESULT_RESOLVED_BY_NEARBY_DEVICE";
}

export interface AssistantLogsInputErrorLog {
  errorCode?: number;
  errorType?:  | "ERROR_UNKNOWN" | "ERROR_DEVICE_PROPERTIES" | "ERROR_HOME_GRAPH" | "ERROR_CAPABILITIES_ACROSS_DEVICES";
}

/**
 * Represents the case where there is a target device with low confidence so
 * that the library didn't directly target it. Instead, the library returns the
 * low confidence target device and the fallback device for the client to decide
 * to either trigger a dialog to disambiguate or select one of them based on
 * extra business logic. Next ID: 3
 */
export interface AssistantLogsLowConfidenceTargetDeviceLog {
  /**
   * The fallback device.
   */
  fallbackDeviceLog?: AssistantLogsDeviceInfoLog;
  /**
   * The selected low confidence focus device.
   */
  lowConfTargetDeviceLog?: AssistantLogsDeviceInfoLog;
}

export interface AssistantLogsLumosProcessorInfo {
  /**
   * Number of candidate devices after this stage is run.
   */
  devicesAfterRun?: number;
  /**
   * Number of candidate devices before this stage is run.
   */
  devicesBeforeRun?: number;
  /**
   * Name of the processor for this stage.
   */
  processorName?:  | "UNKNOWN_LUMOS_PROCESSOR" | "CAPABILITIES_FILTER" | "DEVICE_ANNOTATION_FILTER" | "DEVICE_CONNECTIVITY_FILTER" | "LOCAL_DEVICE_INCLUSIVENESS_FILTER" | "LOCATION_FILTER" | "MEDIA_PLAYBACK_FILTER" | "SAFETY_FILTER" | "TRAITS_FILTER" | "DEVICE_TYPE_FILTER" | "APP_FILTER" | "HYBRID_DEVICE_PROPERTIES_FILTER" | "NEARBY_DEVICE_FILTER" | "DEFAULT_MEDIA_OUTPUT_PROMOTER" | "DEVICE_GROUP_PROMOTER" | "LOCAL_DEVICE_PROMOTER" | "LOCATION_PROMOTER" | "MEDIA_FOCUS_PROMOTER" | "MEDIA_PLAYBACK_PROMOTER" | "SAME_NAME_DEVICE_PROMOTER" | "PHONE_TARGETING_PROMOTER" | "TRAITS_PROMOTER" | "DEVICE_TYPE_PROMOTER";
}

export interface AssistantLogsMediaCapabilities {
  canReceiveRemoteAction?: boolean;
  hasScreen?: boolean;
}

/**
 * A summary of the reasons that we chose a certain target device.
 */
export interface AssistantLogsMediaDeviceSelectionDecisionSummary {
  deviceSelectionPreferenceUsed?:  | "UNKNOWN_PRIORITY" | "SINGLE_QUALIFIED_SESSION_PREFERRED" | "FOCUS_SESSION_PREFERRED" | "FOCUS_DEVICE_SESSION_PREFERRED" | "LOCAL_DEVICE_SESSION_PREFERRED" | "PLAYING_DEVICE_STATE_PREFERRED" | "BUFFERING_DEVICE_STATE_PREFERRED" | "PAUSED_DEVICE_STATE_PREFERRED" | "STOPPED_DEVICE_STATE_PREFERRED";
  deviceSelectionReason?:  | "UNKNOWN_REASON" | "SYNDICATION_DEVICE_TARGETED" | "AUTO_DEVICE_TARGETED" | "QUERY_DEVICE_ANNOTATION_TARGETED" | "SINGLE_QUALIFIED_DEVICE_TARGETED" | "CAST_GROUP_TARGETED" | "MEDIA_SESSION_TARGETED" | "FOCUS_DEVICE_TARGETED" | "DEFAULT_DEVICE_TARGETED" | "LOCAL_DEVICE_TARGETED" | "DEVICE_IN_SAME_ROOM_TARGETED" | "AMBIGUOUS_DEVICES_TARGETED" | "LOCAL_GROUP_RETARGETED" | "FOCUS_OF_CLOSE_DEVICE_TARGETED" | "DEFAULT_OF_CLOSE_DEVICE_TARGETED" | "SINGLE_QUALIFIED_CLOSE_DEVICE_TARGETED" | "DEVICE_IN_CLOSE_ROOM_TARGETED" | "TETHERED_DEVICE_TARGETED";
  miscSelectionSignal?:  | "NONE" | "BETTER_MATCH_DEVICE_WITH_HUMAN_FRIENDLY_NAME_FOUND" | "LOCAL_DEVICE_IMPLICITLY_MENTIONED" | "USED_LOOSE_PLAYBACK_STATE_REQUIREMENTS" | "QUERY_3P_DEVICE_ANNOTATION_IGNORED_REQUIREMENTS"[];
}

/**
 * Following are the MDA compatible loggings for media focus, default settings
 * and nearby devices.
 */
export interface AssistantLogsMediaFocusesLog {
  dialogTriggered?: boolean;
  localMediaFocus?: AssistantLogsMediaFocusInfoLog;
  /**
   * Deprecated, use nearby_media_focuses instead.
   */
  mediaFocuses?: AssistantLogsMediaFocusInfoLog[];
  /**
   * MediaFouces found on nearby devices.
   */
  nearbyMediaFocuses?: AssistantLogsMediaFocusInfoLog[];
}

/**
 * The information related to Media Focus. TODO(b/138952173) Deprecate
 * MediaFocusState in logs/proto/majel_gws/media_action_triggering_info.proto
 * and assistant/verticals/media/proto/target_device_info.proto
 */
export interface AssistantLogsMediaFocusInfoLog {
  /**
   * How long the device is in focus so far
   */
  currentFocusDurationSec?: number;
  /**
   * TODO(b/134944092) Log MediaFocusDialogTrigger Enum in focus_status.
   */
  dialogTriggered?: boolean;
  /**
   * 
   * LINT.ThenChange(//depot/google3/logs/proto/majel_gws/media_action_triggering_info.proto)
   * The focus device.
   */
  focusDevice?: AssistantLogsDeviceInfoLog;
  /**
   * The media focus state at the time of the request.
   */
  mediaFocusState?:  | "NO_FOCUS" | "RECENT_FOCUS" | "STALE_FOCUS" | "HARD_FOCUS" | "SOFT_FOCUS";
  /**
   * The source device of media focus.
   */
  sourceDeviceId?: string;
}

/**
 * Media stream is composed of a media session and one or more devices which
 * are hosting (playing) the session. Usually, a session is only hosted by one
 * devcie. However, with cast group or stream transfer/expansion, a session
 * could be hosted by multiple devices, which are playing the same session
 * simultaneously.
 */
export interface AssistantLogsMediaStreamLog {
  /**
   * The device index in this message is consistent with the device index in
   * DeviceInfoLog. This field refers to the devices that hosting the session.
   */
  deviceIndex?: number[];
  session?: AssistantLogsDeviceMediaSessionLog;
}

export interface AssistantLogsNearbyDevicesLog {
  /**
   * The timestamp that DeviceArbitration is created in milliseconds.
   */
  deviceArbitrationCreationTimestampMs?: bigint;
  /**
   * The timestamp that DeviceTargetingInput is built in milliseconds.
   */
  deviceTargetingInputCreationTimestampMs?: bigint;
  eliminatedByFurtherDistance?: number;
  eliminatedByLocalClosest?: number;
  eliminatedByUnknownDifferentRoom?: number;
  eliminatedByUnregisteredDevice?: number;
  localDevice?: AssistantLogsDeviceInfoLog;
  nearbyDevices?: AssistantLogsDeviceInfoLog[];
  numClosestDevices?: number;
  numEquallyCloseDevices?: number;
  numFurtherDevices?: number;
  numHearingDevices?: number;
  numUnknownDistanceDevices?: number;
}

function serializeAssistantLogsNearbyDevicesLog(data: any): AssistantLogsNearbyDevicesLog {
  return {
    ...data,
    deviceArbitrationCreationTimestampMs: data["deviceArbitrationCreationTimestampMs"] !== undefined ? String(data["deviceArbitrationCreationTimestampMs"]) : undefined,
    deviceTargetingInputCreationTimestampMs: data["deviceTargetingInputCreationTimestampMs"] !== undefined ? String(data["deviceTargetingInputCreationTimestampMs"]) : undefined,
  };
}

function deserializeAssistantLogsNearbyDevicesLog(data: any): AssistantLogsNearbyDevicesLog {
  return {
    ...data,
    deviceArbitrationCreationTimestampMs: data["deviceArbitrationCreationTimestampMs"] !== undefined ? BigInt(data["deviceArbitrationCreationTimestampMs"]) : undefined,
    deviceTargetingInputCreationTimestampMs: data["deviceTargetingInputCreationTimestampMs"] !== undefined ? BigInt(data["deviceTargetingInputCreationTimestampMs"]) : undefined,
  };
}

/**
 * Provider annotation annotated from the query. These fields contain the
 * detailed information for the provider. (e.g. for Youtube, package_names
 * contains "com.google.android.youtube", localized_names contains "youtube",
 * and lang contains "en" from "en-US" which depends on user's setting.)
 */
export interface AssistantLogsProviderAnnotationLog {
  lang?: string;
  localizedNames?: string[];
  packageNames?: string[];
}

/**
 * Log about the query requirements
 */
export interface AssistantLogsQueryAnnotationLog {
  /**
   * Deprecated, please use room_annotations.
   */
  deviceAnnotation?: AssistantLogsDeviceAnnotationLog;
  /**
   * Log the device annotations mentioned in the query.
   */
  deviceAnnotations?: AssistantLogsDeviceAnnotationLog[];
  /**
   * Log the provider annotations annotated from the query.
   */
  providerAnnotation?: AssistantLogsProviderAnnotationLog;
  /**
   * TODO(b/171250187) Deprecates the optional RoomAnnotationLog and
   * DeviceAnnotationLog. Deprecated, please use device_annotations.
   */
  roomAnnotation?: AssistantLogsRoomAnnotationLog;
  /**
   * Log the room annotations mentioned in the query.
   */
  roomAnnotations?: AssistantLogsRoomAnnotationLog[];
  /**
   * Log the structure annotations mentioned in the query.
   */
  structureAnnotations?: AssistantLogsStructureAnnotationLog[];
}

/**
 * Annotate a single reminder instance.
 */
export interface AssistantLogsReminderLog {
  /**
   * The reminder is created N seconds ago. This helps tracking how the user
   * issues follow-up actions after reminder is created. For example, whether
   * the user likes to issues another [show reminders] query right after
   * reminder is created?
   */
  createdSecondsAgo?: bigint;
  /**
   * If the reminder is retrieved by a ranking class (see
   * go/opa-reminders-ranker), this will be populated with the class info. Refer
   * to assistant.productivity.ReminderRankingClass.RankingType. Since that
   * proto is in proto2 format, we can only wire by int type.
   */
  retrievedRankingClass?: number;
}

function serializeAssistantLogsReminderLog(data: any): AssistantLogsReminderLog {
  return {
    ...data,
    createdSecondsAgo: data["createdSecondsAgo"] !== undefined ? String(data["createdSecondsAgo"]) : undefined,
  };
}

function deserializeAssistantLogsReminderLog(data: any): AssistantLogsReminderLog {
  return {
    ...data,
    createdSecondsAgo: data["createdSecondsAgo"] !== undefined ? BigInt(data["createdSecondsAgo"]) : undefined,
  };
}

/**
 * Room annotation mentioned in query.
 */
export interface AssistantLogsRoomAnnotationLog {
  /**
   * The raw text mentioning a room from the query, such as "my living room".
   */
  rawTextFromQuery?: string;
  /**
   * The number of rooms annotated, if there are multiple structures. They are
   * guaranteed to have the same text_from_query and name due to exact matching.
   */
  roomCount?: number;
  /**
   * The annotation type mentioned in the query.
   */
  type?:  | "NO_ROOM_ANNOTATION" | "ROOM_ID_ANNOTATION" | "ROOM_TYPE_ANNOTATION" | "ROOM_TEXT_ANNOTATION";
  userDefinedName?: string;
}

/**
 * The logging-version of DeviceId proto, which identifies a device. This
 * mirrors
 * cs/google3/assistant/api/core_types/device_type.proto?q=symbol:DeviceId Next
 * ID: 6
 */
export interface AssistantLogsSettingsDeviceIdLog {
  /**
   * The client_instance_id on devices with GSA. See 'client_instance_field' in
   * go/androidids.
   */
  agsaClientInstanceId?: string;
  /**
   * A unique device ID for Assistant devices as proposed by go/ocelot-team.
   */
  canonicalDeviceId?: string;
  /**
   * If set, indicates that the device is a cast device, and contains the UUID
   * of the cast device. Corresponds to the device_id field of the CastDevice
   * proto.
   */
  castDeviceId?: string;
  /**
   * DUSI (go/dusi) is used as the identifier here. This identifier is unique
   * to the user and device. This will help identify which device or application
   * the user's request originated from. This is not to be confused with the
   * client_instance_id that android devices provide. This is currently used by
   * surfaces that use the assistant-legacy-nexus and assistant-legacy-clockwork
   * pipelines. DUSI is created and set in S3. This field is only filled for
   * GAIA requests.
   */
  clientInstanceId?: string;
  /**
   * The unique device ID for HomeGraph devices. This is the HomeGraph ID,
   * created when the device is registered into HomeGraph. It is immutable for
   * the same device unless it is completely deleted and recreated. See
   * go/home-graph for details. }
   */
  homeGraphDeviceId?: string;
  /**
   * The unique ID for libassistant based devices.
   */
  libassistantDeviceId?: string;
}

/**
 * Structure annotation mentioned in query.
 */
export interface AssistantLogsStructureAnnotationLog {
  /**
   * The raw text mentioning a structure from the query, such as "my house".
   */
  rawTextFromQuery?: string;
  /**
   * The annotation type mentioned in the query.
   */
  type?:  | "NO_STRUCTURE_ANNOTATION" | "STRUCTURE_ID_ANNOTATION" | "STRUCTURE_TEXT_ANNOTATION";
  userDefinedName?: string;
}

/**
 * Represents the case where the library successfully selects the target
 * device. It could be one or multiple devices. Next ID: 4
 */
export interface AssistantLogsTargetDeviceLog {
  devices?: AssistantLogsDeviceInfoLog[];
  lowConfidenceReason?:  | "UNKNOWN_REASON" | "LOCAL_FALLBACK" | "MANUAL_DEFINED_REASON" | "SINGLE_NEARBY_DEVICE" | "PERSONAL_RESPONSE_BIT_OPTOUT_ON_LOCKED_PHONE" | "FURTHER_LOCAL_DEVICE";
  resultConfidenceLevel?:  | "UNKNOWN" | "LOW_CONFIDENCE" | "HIGH_CONFIDENCE";
}

/**
 * Signals to be used by the Prefulfillment Ranker. Derived from the
 * ParsingSignals and GroundingSignals carried by the FunctionCall.
 * LINT.IfChange Next ID: 44
 */
export interface AssistantPrefulfillmentRankerPrefulfillmentSignals {
  /**
   * Assistant User Interaction Score for binding set.
   */
  bindingSetAuis?: number;
  /**
   * Pauis score for the binding set
   */
  bindingSetPauis?: number;
  /**
   * A parsing score that is independently calibrated by each parser/IG.
   */
  calibratedParsingScore?: number;
  /**
   * Whether the intent is dominant according to NSP deep-media.
   */
  deepMediaDominant?: boolean;
  /**
   * Indicates interpretation dominance predicted by KScorer
   */
  dominant?: boolean;
  /**
   * The total effective length of the spans for the arguments used to
   * construct the parse. May include vertical specific adjustments. Eg: For the
   * query [delete my 7 p.m. alarm called chicken] and intent
   * Delete_alarm(alarm_object=RD(category=AlarmObject( label="chicken",
   * trigger_time_datetime=<< 7 PM >>))), the effective argument span is "7
   * p.m." + "chicken" (total length of 13).
   */
  effectiveArgSpanLength?: number;
  /**
   * Whether this is a fulfillable, dominant Media intent.
   */
  fulfillableDominantMedia?: boolean;
  /**
   * Grounding Signals. Score indicating how grounded the intent is, populated
   * by the Grounding Box.
   */
  groundabilityScore?: number;
  /**
   * Grounding Provider related ranking features, including general Grounding
   * Provider ranking features(shared among multiple GPs) and specific Grounding
   * Provider ranking features(provided by a specific GP).
   */
  groundingProviderFeatures?: AssistantGroundingRankerGroundingProviderFeatures;
  /**
   * Whether the interpretation has a Search answer group object, signifying it
   * came from Search resolution.
   */
  hasAnswerGroup?: boolean;
  /**
   * This is a cross-intent feature which is calculated by iterating all intent
   * candidates. This feature should be populated in post-IG stage (before GB).
   */
  inQueryMaxEffectiveArgSpanLength?: number;
  /**
   * intent_name is used by PFR ensemble model. See go/pfr_ha_launch_doc
   */
  intentName?: string;
  /**
   * QUS intent-based ranking signals. Assistant User Interaction Score which
   * is aggregated using intent name.
   */
  intentNameAuisScore?: number;
  /**
   * Assistant User Interaction Score which is aggregated using intent name
   * from exp laelaps.
   */
  intentNameAuisScoreExp?: number;
  /**
   * Feasibility of fulfilling the binding set. Eg: For PlayMedia, this is
   * equivalent to playability. More details: go/hgr-feasibility-feature.
   */
  isFeasible?: boolean;
  /**
   * Whether the intent is fully grounded.
   */
  isFullyGrounded?: boolean;
  /**
   * Whether the intent is a PlayGenericMusic-type intent.
   */
  isPlayGenericMusic?: boolean;
  /**
   * Whether the intent is a podcast intent.
   */
  isPodcastIntent?: boolean;
  /**
   * The rank order of the interpretation as determined by kscorer. The
   * kscorer-determined dominant interpretation, if any, gets a rank of 0. The
   * remaining N interpretations get a rank of 1 through N.
   */
  kscorerRank?: number;
  /**
   * Learn and adapt(go/laa) related features. Design doc:
   * go/laa-profile-signal-for-grounding.
   */
  laaFeatures?: AssistantGroundingRankerLaaFeatures;
  /**
   * This feature is always false / no-op in serving time. In training time,
   * this feature may be set true on specific examples for weighted training
   * where when this signal is true, only cross-intent level features are used
   * for training and other candidate level features are masked (set as
   * missing).
   */
  maskCandidateLevelFeatures?: boolean;
  /**
   * The maximum score assigned by the Horizontal Grounding Ranker (HGR) across
   * all of the intent's binding sets.
   */
  maxHgrScoreAcrossBindingSets?: number;
  /**
   * Number of alternative hypotheses from speech recognition(S3).
   */
  numAlternativeHypothesis?: number;
  /**
   * Sum of the number of constraints used by the Grounding Box to ground each
   * variable.
   */
  numConstraints?: number;
  /**
   * Sum of the number of constraints satisfied for each variable. Depending on
   * the match score for a constraint, this number can be fractional and is in
   * the range [0, num_constraints]. Populated by the Grounding Box.
   */
  numConstraintsSatisfied?: number;
  /**
   * Number of groundable arguments the intent has, populated by the Grounding
   * Box.
   */
  numGroundableArgs?: number;
  /**
   * Number of grounded arguments the intent has, populated by the Grounding
   * Box.
   */
  numGroundedArgs?: number;
  /**
   * Signals as proposed in go/improved-grounding-signals. Number of arguments,
   * possibly nested, that the Grounding Box tried to ground.
   */
  numVariables?: number;
  /**
   * Number of arguments, possibly nested, that the Grounding Box was able to
   * ground. This includes ambiguously grounded arguments.
   */
  numVariablesGrounded?: number;
  /**
   * A ID corresponding to which bucket a given parsing score belongs in.
   */
  parsingScoreMse8BucketId?: number;
  /**
   * Cosine similarity between predicted query-to-term model and assistant
   * intent-type-based salient terms. This is intended to be only used for ACE
   * ranking and only populated for assistant traffic.
   */
  pq2tVsAssistantIbstCosine?: number;
  /**
   * Cosine similarity between predicted query-to-term model and
   * intent-type-based salient terms. This is intended to be used as a backoff
   * to pq2t_vs_qibst_cosine if it is missing.
   */
  pq2tVsIbstCosine?: number;
  /**
   * Intent confidence predicted by the AssistantVerticalClassifier QRewrite
   * servlet.
   */
  predictedIntentConfidence?: number;
  /**
   * The determination made by the SearchDispatchingConfig as to whether and
   * how this interpretation should be dispatched to Search.
   */
  searchDispatch?:  | "UNKNOWN" | "NONE" | "BRIDGE_API" | "FULFILL_INTENT" | "EMIT_ONLY" | "COUNTERFACTUAL_LOG_ONLY" | "CAPACITY_ACCOUNTING";
  /**
   * Average of per-word confidence for top speech recognition hypothesis. The
   * value is from RecognizerHypothesisLog:
   * http://google3/logs/proto/speech/service/recognizer_log.proto?l=848&rcl=281400256
   */
  topHypothesisConfidence?: number;
  /**
   * Horizontal feature that stores information about confidence scores for
   * each resolution within the binding set.
   */
  verticalConfidenceScore?: number;
}

/**
 * A message to represent an item in a list. Just a basic string for now, but
 * extensible for the future.
 */
export interface AssistantProductivityListItem {
  /**
   * [REQUIRED] The name of the list item.
   */
  name?: string;
}

/**
 * Proto descrbing an attachment to an Assistant Reminder. If the attachment
 * has different behavior on different surfaces (e.g., deeplinks), there will be
 * multiple attachments attach to the Reminder. Each of them will specify the
 * surface type and the corresponding deeplink.
 */
export interface AssistantRemindersAttachment {
  /**
   * REQUIRED. An unique identifier for the attachment. We have a plan to index
   * this field, so it's marked as REQUIRED. Chat with opa-reminders-eng@ if you
   * have a use case without an attachment ID.
   */
  id?: string;
  link?: AssistantRemindersAttachmentLink;
  /**
   * REQUIRED. Surface types this attachment should be shown.
   */
  surfaceType?:  | "UNSPECIFIED" | "ANDROID_PHONE"[];
}

export interface AssistantRemindersAttachmentLink {
  /**
   * REQUIRED. The link to surface to frontends (e.g., Hubpage, notifications.)
   * This could also be a surface-specific deeplink (be sure to set
   * `surface_type` accordingly.)
   */
  linkUrl?: string;
  /**
   * REQUIRED. The text for the notification link button. Note: We cannot take
   * nlp_generation.TemplateData yet due to cyclic dependency. The plan is to
   * cut dependency from TemplateData to quality.actions.Reminder.
   */
  notificationText?: AssistantRemindersNlgTemplateKey;
}

/**
 * Since this is stored in BE, any update on this proto needs LGTM by ARIS
 * storage owner
 */
export interface AssistantRemindersMemoryPayload {
  /**
   * Whether the reminder created has a referenced_entity attached to it or
   * not(go/hub-memory-payload). Since we plan to set this in Assistant reminder
   * creation path flow, in case later the referenced_entity is removed from the
   * reminder, then this bit might still remain true. Also in case
   * referenced_entity is later added to reminder(for example when
   * referenced_entity is attached by Server), then also this bit might remain
   * false. This bit will be used to *guess* if the user has a memory-enabled
   * AGSA, thus we'll surface the "open memory" button on hubpage. This check is
   * not perfect, as the user might have other phones with older AGSA, so this
   * is just a *best guess*. This field won't be stored in Memory backend, and
   * will not be populated back when retrieving reminders.
   */
  hasReferencedEntityAtCreation?: boolean;
  /**
   * Id of record that is associated with Reminder. This will be set for all
   * Assistant reminders created after the first launch of the Reminder Memory
   * integration, see go/reminders-memory for more details. Also, this might
   * apply to all other types of reminders.
   */
  recordId?: string;
}

/**
 * Equivalent to nlp_generation.TemplateKey. We cannot use
 * nlp_generation.TemplateKey message directly becasue that proto is defined in
 * a relatively large proto and has other dependencies, which will increase the
 * size unnecessary and might hit many limitations (e.g., 5MiB limitation for
 * Spanner type environment.).
 */
export interface AssistantRemindersNlgTemplateKey {
  /**
   * REQUIRED.
   */
  messageSet?: string;
  /**
   * REQUIRED.
   */
  templateName?: string;
}

export interface AssistantTeleportTeleportNicknameSignals {
  /**
   * Whether the nickname could also refer to a location. For example,
   * "walmart", "starbucks".
   */
  hasLocationInterpretation?: boolean;
  /**
   * Indicates whether the user has the app installed.
   */
  installInfo?:  | "INSTALLATION_INFORMATION_UNAVAILABLE" | "IS_INSTALLED_APP" | "IS_NOT_INSTALLED_APP";
  /**
   * True when the name is generic, i.e when it could refer to multiple
   * packages from different developrs. For example, "mail" is considered a
   * generic name (since it can refer to "gmail", "yahoo mail" etc.) but
   * "facebook" although could refer to both "facebook" and "facebook lite" is
   * not considered generic (both packages are from the same third party).
   */
  isGeneric?: boolean;
  /**
   * The tier of the nickname.
   */
  nicknameTier?:  | "UNKNOWN" | "UNRESTRICTED" | "INTENT_REQUIRED" | "APP_PHRASE_REQUIRED";
  source?:  | "DEFAULT" | "GELLER" | "DEVICE_CAPABILITIES";
}

/**
 * Neural contact match signals.
 */
export interface AssistantVerticalsCommonContactMatchSignal {
  /**
   * Neural contact match similarity score.
   */
  matchScore?: number;
}

/**
 * Metadata for Actions-on-Google configuration.
 */
export interface AssistantVerticalsHomeautomationProtoActionProjectConfig {
  /**
   * Actions-on-Google action context ID. See go/sdm-hospitality-design.
   */
  contextId?: string;
}

/**
 * An agent + device pair that uniquely identifies a device.
 */
export interface AssistantVerticalsHomeautomationProtoAgentDeviceId {
  /**
   * The agent's ID. Generally it is the agent's Google pantheon project id.
   */
  agentId?: string;
  /**
   * Device ID defined by the agent.
   */
  deviceId?: string;
}

/**
 * AgentInformation represents the details needed to support both 1P and 3P
 * partnerships for Home Automation. Next ID: 7
 */
export interface AssistantVerticalsHomeautomationProtoAgentInformation {
  authType?:  | "OPEN_AUTH_DEFAULT" | "NEST_AUTH_PROXY";
  deviceSource?:  | "UNKNOWN" | "CLOUD_SYNC" | "ASSISTANT_SETTING_OOBE" | "LOCAL_SYNC" | "CHIP_SYNC";
  executionPath?:  | "HARPOON_DEFAULT" | "STUBBY";
  /**
   * Unique Agent ID which maps to a specific Agent. Not using Agent Name here
   * as it may change over time.
   */
  id?: string;
  /**
   * Agent's foreign key that uniquely identifies a user's device.
   */
  key?: string;
}

/**
 * Protos representing device or structure attributes. See
 * go/hgs-attributes-protos. Only protos approved and formalized by assistant/HG
 * team should be added here.
 */
export interface AssistantVerticalsHomeautomationProtoAttribute {
  structureBasedRoutine?: AssistantVerticalsHomeautomationProtoCommonStructureBasedRoutine;
}

/**
 * LINT.IfChange(proto_attributes)
 */
export interface AssistantVerticalsHomeautomationProtoAttributes {
  attributeProtos?: AssistantVerticalsHomeautomationProtoAttribute[];
}

/**
 * LINT.IfChange(proto_event_trigger) Next id: 5
 */
export interface AssistantVerticalsHomeautomationProtoCommonEventTrigger {
  enabled?: boolean;
  /**
   * Detailed settings for the event trigger; unset if not applicable.
   */
  eventTriggerPayload?: {
    [key: string]: any
  };
  /**
   * Different event type may have different settings. For example: * SCHEDULED
   * will have event_trigger_payload of
   * cs/symbol:assistant.verticals.voice_shortcut.proto.Schedule * LOCATION will
   * have event_trigger_payload of
   * cs/symbol:assistant.verticals.voice_shortcut.proto.LocationTriggerEvent
   */
  eventTriggerType?:  | "UNKNOWN" | "SCHEDULED" | "LOCATION" | "DEVICE_CONTROL" | "DEVICE_SENSES";
  /**
   * Unique identifier for the EventTrigger, e.g. SCHEDULED_ROUTINES. See the
   * enum values of cs/symbol:WorkflowTriggerInput.TriggerSource
   */
  triggerSource?: number;
}

/**
 * Routines team stores the core Structure Based Routine data as the payload.
 * We will add specific metadata on a per-need basis.
 * LINT.IfChange(proto_structure_based_routine) Next id: 12 These two forms of
 * payload are equivalent data in different formats and both will be stored in
 * Home Graph. 1. The internal format will fan out to the DynamicEntity
 * Footprints for read in Settings flow and Execution. 2. The UI format will be
 * stripped out upon replication to DynamicEntity Footprints due to its
 * redundancy and the Footprints data size limit, i.e. DE Footprints will only
 * contain the internal format.
 */
export interface AssistantVerticalsHomeautomationProtoCommonStructureBasedRoutine {
  /**
   * Whether this Routine is enabled or not. If false, then this Routine can't
   * be triggered by Voice.
   */
  enabled?: boolean;
  /**
   * The unique identifier for a class of workflows. For example: * "sbr_001"
   * => Away * "sbr_002" => Home * "category_template" => CUSTOM
   */
  googlePreconfigWorkflowId?: string;
  language?: string;
  /**
   * Internal format payload primarily for Routines team use.
   */
  payload?: {
    [key: string]: any
  };
  /**
   * The security level of the Structure Based Routine as determined by the
   * most security-sensitive task.
   */
  securityLevel?:  | "UNKNOWN" | "ALLOW_UNVERIFIED" | "ALLOW_VERIFIED";
  shared?: boolean;
  storagePayload?: {
    [key: string]: any
  };
  structureId?: string;
  /**
   * Voice or event triggers.
   */
  triggers?: AssistantVerticalsHomeautomationProtoCommonStructureBasedRoutineTrigger[];
  type?:  | "UNDEFINED" | "CURATED" | "ALARM" | "CUSTOM";
  /**
   * UI format payload primarily for external team use.
   */
  uiPayload?: {
    [key: string]: any
  };
}

/**
 * Next id: 3
 */
export interface AssistantVerticalsHomeautomationProtoCommonStructureBasedRoutineTrigger {
  eventTrigger?: AssistantVerticalsHomeautomationProtoCommonEventTrigger;
  voiceTrigger?: AssistantVerticalsHomeautomationProtoCommonVoiceTrigger;
}

/**
 * LINT.IfChange(proto_voice_trigger) Next id: 2
 */
export interface AssistantVerticalsHomeautomationProtoCommonVoiceTrigger {
  query?: string;
}

/**
 * The Concierge features a structure is eligible for. See {@link
 * home.graph.common.ConciergeFeatures}.
 */
export interface AssistantVerticalsHomeautomationProtoConciergeFeatures {
  conciergeProductFeatures?:  | "UNKNOWN_PRODUCT_FEATURE" | "E911"[];
}

/**
 * Next ID: 5
 */
export interface AssistantVerticalsHomeautomationProtoDeviceTargetingOutputQueryInfo {
  /**
   * The query span for device mention.
   */
  annotatedSpanDevice?: string;
  /**
   * The query span for room mention.
   */
  annotatedSpanRoom?: string;
  /**
   * The query span for structure mention.
   */
  annotatedSpanStructure?: string;
  /**
   * This field is from query_info.processed_mentioned_span in DTO.
   */
  processedMentionedSpan?: string;
}

/**
 * Next ID: 43
 */
export interface AssistantVerticalsHomeautomationProtoHomeAutomation_MetaData {
  /**
   * Custom actions that this item supports.
   */
  actionProjectConfigs?: AssistantVerticalsHomeautomationProtoActionProjectConfig[];
  /**
   * Agent details.
   */
  agentInformation?: AssistantVerticalsHomeautomationProtoAgentInformation;
  /**
   * Device ID that matches the ID passed from the device to discourse_context
   * when a user issues a query to an Assistant-enabled device that is
   * registered with Cast (via CCS (see go/castservers)), or some other service.
   */
  assistantDeviceId?: string;
  /**
   * Attributes data as provided from SYNC. This gets used in mutation and
   * execution and in some potential cases, in biasing.
   */
  attributes?: {
    [key: string]: any
  };
  /**
   * See Device.creator_gaia_ids in //home/graph/proto/service/types.proto. If
   * empty, the GAIA ID from the request EUC is assumed to be the creator. We
   * only need at most one creator_gaia_id.
   */
  creatorGaiaId?: bigint;
  /**
   * Any types that are not the given item type, but derived later. For
   * example, if an item has type action.devices.types.OUTLET but is named
   * "floor lamp" we can derive that it also has type
   * action.devices.types.LIGHT. Also considered along with |type| when
   * triggering type-based actions.
   */
  derivedType?: string[];
  /**
   * See note in home_graph.proto; loaded into DE now to avoid having to
   * double-read assistant settings records as per
   * go/smarthome-removing-assistant-settings
   */
  deviceModelId?: string;
  /**
   * GCM address for cloud execution across google cloud messaging rather than
   * 3p cloud; for future use.
   */
  gcmExecutionAddress?: string;
  /**
   * List of parent group IDs, if the device is added to one or multiple device
   * groups (see go/home-groups). Will be consumed by Smart Home APIs and (in
   * the future) Assistant CTF to populate the group member list of device
   * groups.
   */
  groupIds?: string[];
  /**
   * The hash value from go/de-consistency-check
   */
  hashValue?: string;
  /**
   * Whether local home platform should discover new devices via LAN for the
   * structure.
   */
  lanscanOptedIn?: boolean;
  /**
   * Model name from HomeGraph, populated from model_manifest.model_name. See
   * b/200087451.
   */
  modelName?: string;
  /**
   * Indicates whether notifications have been enabled by a user and will be
   * announced for this device. This is set by the user within the Google app
   * settings, and Google will announce the device notification only if both
   * notification_supported_by_agent and notification_enabled_by_user are true.
   */
  notificationEnabledByUser?: boolean;
  /**
   * Indicates whether the device is capable of sending notifications. This
   * field will be set by the agent (partner) on an incoming SYNC. If a device
   * is not capable of generating notifications, the partner should set this
   * flag to false. If a partner is not capable of calling
   * ReportStateAndNotification to send notifications to Google, the partner
   * should set this flag to false. If there is a user setting in the partner
   * app to enable notifications and it is turned off, the partner should set
   * this flag to false.
   */
  notificationSupportedByAgent?: boolean;
  /**
   * Store custom data for agent calls here. This will likely be short-lived --
   * we will replace this with calls to HGS. (Note: This may end up not
   * temporary if we only need it for a couple partners -- more efficient to
   * have it on a few users than require HGS reads for all users.
   */
  opaqueCustomData?: string;
  /**
   * Operational CHIP Node ID that combines the fabric ID and node id in format
   * of . (Hex format without 0x prefix, for example,
   * 0F001234FA67AA39.1234ABCD1111DDDD).
   */
  operationalNodeId?: string;
  /**
   * Other agent id + foreign id pairs associated with the device. This can be
   * used to represent a group of devices (e.g. Sonos' bonded zone) as a single
   * device, or a device that comes in through different sync flows (e.g. Newman
   * with a Nest camera).
   */
  otherDeviceIds?: AssistantVerticalsHomeautomationProtoAgentDeviceId[];
  /**
   * Additional device sources. This can be the result of the device being
   * merged with other devices with a different source.
   */
  otherDeviceSources?:  | "UNKNOWN" | "CLOUD_SYNC" | "ASSISTANT_SETTING_OOBE" | "LOCAL_SYNC" | "CHIP_SYNC"[];
  /**
   * LINT.IfChange(home_graph_single_parent) At the moment, we just have a
   * single string. In future this will expand with additional metadata from
   * client or cloud execution data store. In today's 'tree' HomeGraph each
   * object has a single parent. In the future this may have a mesh for complex
   * cases -- zones, doors, etc -- so we make this a repeated element today.
   * LINT.ThenChange(//depot/google3/assistant/assistant_server/settings/user_defined_actions/footprints/footprint_accessor.cc:home_graph_single_parent)
   */
  parentNode?: string[];
  /**
   * The type of the parent. Currently only set for devices, to distinguish
   * between structure and room parents. Items currently have only one parent,
   * and entries after the first parent_type are ignored.
   */
  parentType?:  | "UNKNOWN_ITEM_TYPE" | "DEVICE" | "ROOM" | "PLACE" | "GROUP" | "SCENE" | "STRUCTURE"[];
  /**
   * User-given nicknames for an entity (e.g. "My house"). These nicknames are
   * unique to the gaia user. Nickname in DeviceInfo is per-entity level
   * nickname, while personalized_nicknames is per-user per-entity.
   */
  personalizedNicknames?: string[];
  /**
   * Stores the location for the STRUCTURE type.
   */
  physicalLocation?: AssistantVerticalsHomeautomationProtoPhysicalLocation;
  /**
   * We use this to determine if the synonyms matched in the aqua
   * interpretation is plural. Then we will return disambiguate dialog or
   * execute commands with all the targets.
   */
  plural?: string[];
  /**
   * Which of the values was the original, user-provided name -- or our
   * disambiguated, cleaned-up version of it. This is what we use in TTS when we
   * need to identify an object that wasn't just spoken uniquely by the user --
   * in disambiguation dialogue, or in response to a collective interrogative
   * (e.g. "what lights are on in the kitchen?")
   */
  primaryName?: string;
  /**
   * User's role information for this device. This will be used in Home
   * Automation server to decide if user has authority to fulfill its request.
   */
  roleInformation?: AssistantVerticalsHomeautomationProtoRoleInformation;
  /**
   * Only present for a target device. Indicates this target device is
   * reachable by a local (AoGH) path via an AoGH device.
   */
  routableViaGcm?: boolean;
  /**
   * SAFT Document with linguistic annotations for the primary device name.
   */
  saftDocument?: NlpSaftDocument;
  /**
   * Data needed for SDM (fleet management). See go/enterprise-id-in-assistant.
   */
  smartDeviceManagementData?: AssistantVerticalsHomeautomationProtoSmartDeviceManagementData;
  /**
   * SmartHome feature flags that may be enabled per-item.
   */
  smartHomeFeatures?: AssistantVerticalsHomeautomationProtoSmartHomeFeatures;
  /**
   * The features that are available for a structure. Will only be populated if
   * the item_type == STRUCTURE.
   */
  supportedStructureFeatures?: AssistantVerticalsHomeautomationProtoSupportedStructureFeatures;
  /**
   * Map from agent ID to supported traits. Some devices (e.g. Newman) have
   * multiple agents, with each agent being associated with a specific set of
   * traits. This could alternatively have been formatted as map as {trait,
   * agent} pairs instead of the {agent, list of trait} pairs, but we retain
   * this format to be consistent with HomeGraph's representation. In practice,
   * a trait should only be paired with a single agent (i.e. we should not have
   * two agents with the same trait in their value list). This field is optional
   * and should only be provided if the item has multiple agents.
   */
  supportedTraitsByAgent?: {
    [key: string]: AssistantVerticalsHomeautomationProtoHomeAutomation_MetaDataSupportedTraits
  };
  /**
   * This device supports direct response -- if the device itself is issuing
   * the query (which means it's also an assistant surface) we can return its
   * payload directly rather than via cloud.
   */
  supportsDirectResponse?: boolean;
  /**
   * Only present for an AoGH device. HGS Device ID of a target device and the
   * signal strength (RSSI in dB, higher is better) between that target device
   * and the AoGH device. If this map is empty, there are no target devices
   * reachable by this AoGH device.
   */
  targetDeviceSignalStrengths?: {
    [key: string]: bigint
  };
  /**
   * The timestamp at which the TDSS map was last updated. This information is
   * used to help determine which hub would be preferred if multiple hubs report
   * the same reach-ability for a device.
   */
  tdssUpdateTimestamp?: Date;
  /**
   * For SHED devices, some traits can only be executed on 3P cloud, e.g.
   * "action.devices.traits.MediaInitiation", "action.devices.traits.Channel"
   * go/shed-per-trait-routing
   */
  traitRoutingHints?: HomeGraphCommonTraitRoutingHints[];
  /**
   * Map from traits to routing table. Metadata includes preferred execution
   * path per trait and, when Matter is preferred, which endpoint should be used
   * for the trait.
   */
  traitRoutingTable?: {
    [key: string]: HomeGraphCommonRoutingTable
  };
  /**
   * Map of trait to a proto representing the attribute. This is different from
   * the attributes field above which is represented as a struct. The attributes
   * here are represented as protos and will require specific support per trait.
   */
  traitToAttributeProtos?: {
    [key: string]: AssistantVerticalsHomeautomationProtoAttributes
  };
  /**
   * The item type, such as "action.devices.types.VACUUM" - to be used in
   * triggering type-based actions, e.g. "start vacuuming":
   * go/smarthome-type-based-actions.
   */
  type?: string;
  /**
   * The priority order of speech targeting: 1. user_defined_device_type 2.
   * derived_device_type 3. device_type
   */
  userDefinedDeviceType?: string;
  /**
   * Set to which level of voice match is needed. Enum based on string input
   * from the partner in json sync. Values accepted: "none" (but in this case
   * partners won't set it), "owner" [requires matching one of the creator gaia
   * IDs], or "member" [any recognized voice 'enrolled' on the device]. This may
   * expand; only "owner" is in use for first partner, Tile.
   */
  voiceMatchRequired?:  | "ANY" | "OWNER" | "MEMBER";
  /**
   * This device will report state; we can query realtime state from local HGS
   * rather than slow QUERY intent to the 3p cloud.
   */
  willReportState?: boolean;
  /**
   * SAFT Document with linguistic annotations for the zone name, if
   * applicable.
   */
  zoneNameSaftDocument?: NlpSaftDocument;
}

function serializeAssistantVerticalsHomeautomationProtoHomeAutomation_MetaData(data: any): AssistantVerticalsHomeautomationProtoHomeAutomation_MetaData {
  return {
    ...data,
    creatorGaiaId: data["creatorGaiaId"] !== undefined ? String(data["creatorGaiaId"]) : undefined,
    saftDocument: data["saftDocument"] !== undefined ? serializeNlpSaftDocument(data["saftDocument"]) : undefined,
    targetDeviceSignalStrengths: data["targetDeviceSignalStrengths"] !== undefined ? Object.fromEntries(Object.entries(data["targetDeviceSignalStrengths"]).map(([k, v]: [string, any]) => ([k, String(v)]))) : undefined,
    tdssUpdateTimestamp: data["tdssUpdateTimestamp"] !== undefined ? data["tdssUpdateTimestamp"].toISOString() : undefined,
    zoneNameSaftDocument: data["zoneNameSaftDocument"] !== undefined ? serializeNlpSaftDocument(data["zoneNameSaftDocument"]) : undefined,
  };
}

function deserializeAssistantVerticalsHomeautomationProtoHomeAutomation_MetaData(data: any): AssistantVerticalsHomeautomationProtoHomeAutomation_MetaData {
  return {
    ...data,
    creatorGaiaId: data["creatorGaiaId"] !== undefined ? BigInt(data["creatorGaiaId"]) : undefined,
    saftDocument: data["saftDocument"] !== undefined ? deserializeNlpSaftDocument(data["saftDocument"]) : undefined,
    targetDeviceSignalStrengths: data["targetDeviceSignalStrengths"] !== undefined ? Object.fromEntries(Object.entries(data["targetDeviceSignalStrengths"]).map(([k, v]: [string, any]) => ([k, BigInt(v)]))) : undefined,
    tdssUpdateTimestamp: data["tdssUpdateTimestamp"] !== undefined ? new Date(data["tdssUpdateTimestamp"]) : undefined,
    zoneNameSaftDocument: data["zoneNameSaftDocument"] !== undefined ? deserializeNlpSaftDocument(data["zoneNameSaftDocument"]) : undefined,
  };
}

export interface AssistantVerticalsHomeautomationProtoHomeAutomation_MetaDataSupportedTraits {
  traits?: string[];
}

/**
 * Next ID: 9
 */
export interface AssistantVerticalsHomeautomationProtoHomeAutomationDevice {
  /**
   * the next 3 fields are for Lumos output (DTO) that needs to be propagated
   * to the Fulfilment through the HomeAutomationDevice proto.
   */
  deviceSelectionLog?: AssistantLogsDeviceSelectionLog;
  dtoError?: AssistantDeviceTargetingDeviceTargetingError;
  /**
   * This field is from query_info in DTO.
   */
  dtoQueryInfo?: AssistantVerticalsHomeautomationProtoDeviceTargetingOutputQueryInfo;
  /**
   * Device meta data.
   */
  homeautomationMetadata?: AssistantVerticalsHomeautomationProtoHomeAutomation_MetaData;
  /**
   * list of HomeAutomationDeviceItem. After migration completes, we will mark
   * the above 4 field as deprecated and only use this field.
   */
  list?: AssistantVerticalsHomeautomationProtoHomeAutomationDeviceItem[];
  /**
   * Corresponding to casse matched_item CustomTypeItem key.
   */
  matchedItemKey?: string;
  /**
   * Corresponding to casse Argument raw_value.
   */
  matchedItemRawvalue?: string;
  /**
   * Corresponding to casse matched_item CustomTypeItem value.
   */
  matchedItemValue?: string[];
}

function serializeAssistantVerticalsHomeautomationProtoHomeAutomationDevice(data: any): AssistantVerticalsHomeautomationProtoHomeAutomationDevice {
  return {
    ...data,
    deviceSelectionLog: data["deviceSelectionLog"] !== undefined ? serializeAssistantLogsDeviceSelectionLog(data["deviceSelectionLog"]) : undefined,
    homeautomationMetadata: data["homeautomationMetadata"] !== undefined ? serializeAssistantVerticalsHomeautomationProtoHomeAutomation_MetaData(data["homeautomationMetadata"]) : undefined,
    list: data["list"] !== undefined ? data["list"].map((item: any) => (serializeAssistantVerticalsHomeautomationProtoHomeAutomationDeviceItem(item))) : undefined,
  };
}

function deserializeAssistantVerticalsHomeautomationProtoHomeAutomationDevice(data: any): AssistantVerticalsHomeautomationProtoHomeAutomationDevice {
  return {
    ...data,
    deviceSelectionLog: data["deviceSelectionLog"] !== undefined ? deserializeAssistantLogsDeviceSelectionLog(data["deviceSelectionLog"]) : undefined,
    homeautomationMetadata: data["homeautomationMetadata"] !== undefined ? deserializeAssistantVerticalsHomeautomationProtoHomeAutomation_MetaData(data["homeautomationMetadata"]) : undefined,
    list: data["list"] !== undefined ? data["list"].map((item: any) => (deserializeAssistantVerticalsHomeautomationProtoHomeAutomationDeviceItem(item))) : undefined,
  };
}

export interface AssistantVerticalsHomeautomationProtoHomeAutomationDeviceItem {
  /**
   * Device meta data.
   */
  homeautomationMetadata?: AssistantVerticalsHomeautomationProtoHomeAutomation_MetaData;
  /**
   * Corresponding to casse matched_item CustomTypeItem key.
   */
  matchedItemKey?: string;
  /**
   * Corresponding to casse Argument raw_value.
   */
  matchedItemRawvalue?: string;
  /**
   * Corresponding to casse matched_item CustomTypeItem value.
   */
  matchedItemValue?: string[];
}

function serializeAssistantVerticalsHomeautomationProtoHomeAutomationDeviceItem(data: any): AssistantVerticalsHomeautomationProtoHomeAutomationDeviceItem {
  return {
    ...data,
    homeautomationMetadata: data["homeautomationMetadata"] !== undefined ? serializeAssistantVerticalsHomeautomationProtoHomeAutomation_MetaData(data["homeautomationMetadata"]) : undefined,
  };
}

function deserializeAssistantVerticalsHomeautomationProtoHomeAutomationDeviceItem(data: any): AssistantVerticalsHomeautomationProtoHomeAutomationDeviceItem {
  return {
    ...data,
    homeautomationMetadata: data["homeautomationMetadata"] !== undefined ? deserializeAssistantVerticalsHomeautomationProtoHomeAutomation_MetaData(data["homeautomationMetadata"]) : undefined,
  };
}

export interface AssistantVerticalsHomeautomationProtoPhysicalLocation {
  address?: string;
  geoLocation?: GoogleTypeLatLng;
}

/**
 * Represents the users role such as assistant only or manager for a device.
 * Design doc:
 * https://docs.google.com/document/d/1c1hnauEbBfDkywO3GZkI8ejHP765l2tLspmPgckEe2Y/
 */
export interface AssistantVerticalsHomeautomationProtoRoleInformation {
  /**
   * When true, role_type will be ignored, Nest IAM RPC will called to check
   * authority.
   */
  iamCheckRequired?: boolean;
  roleType?:  | "UNDEFINED" | "ASSISTANT_ONLY" | "CAST_LEGACY_LINKED" | "MANAGER";
}

export interface AssistantVerticalsHomeautomationProtoSmartDeviceManagementData {
  /**
   * The enterprise that owns the structure. E.g. Disney, Dream Hotel, etc.
   * This is used for log/analytics purpose. For privacy reasons, we log at
   * enterprise level instead of structure level.
   */
  enterpriseId?: string;
}

/**
 * SmartHome feature flags that may be enabled per-item. LINT.IfChange
 */
export interface AssistantVerticalsHomeautomationProtoSmartHomeFeatures {
  /**
   * Flag indicating whether the background Circadian Lighting effect is
   * enabled for a particular light (go/circadian-lighting-e2e).
   */
  circadianLightingEnabled?: boolean;
  /**
   * Flag indicating whether automatic Energy Savings are enabled for this
   * item.
   */
  energySavingsEnabled?: boolean;
  /**
   * Flag indicating whether Gentle Wake Up is enabled for this item
   * (go/sleep-wake-design).
   */
  gentleWakeupEnabled?: boolean;
  /**
   * Flag indicating whether the user has enabled / disabled sending Home/Away
   * status updates to the device through the Google custom IntelligenceEvents
   * Matter cluster. (go/google-clusters-design)
   */
  homeAwayOverMatterEnabled?: boolean;
}

/**
 * The features a structure supports.
 */
export interface AssistantVerticalsHomeautomationProtoSupportedStructureFeatures {
  conciergeFeatures?: AssistantVerticalsHomeautomationProtoConciergeFeatures;
}

/**
 * Represents the properties of a mention. Next ID: 13
 */
export interface AttentionalEntitiesMentionProperties {
  /**
   * The unique device on which the mention occurred. For example, if the user
   * has two Google Home devices, this indicates which of the two was used.
   */
  deviceId?: AssistantApiCoreTypesDeviceId;
  /**
   * ID of the event that resulted in this entity mention. For user and system
   * turn AEs, this is taken from the ConversationSnapshotId of the snapshot
   * containing this mention. For client AEs, this is empty. This can be used to
   * join back this particular mention to the specific "turn" in which this
   * mention took place.
   */
  eventId?: EventIdMessage;
  /**
   * If this mention corresponds to a WebAnswer, then this defines the score
   * associated with that answer.
   */
  factoidScore?: number;
  /**
   * If present, this entity was mentioned as part of a larger list.
   */
  listEntryInfo?: AttentionalEntitiesMentionPropertiesListEntryInfo;
  /**
   * Estimates the recency of the mention. This is internally computed at
   * runtime on a turn-by-turn basis.
   */
  recency?:  | "RECENCY_UNSPECIFIED" | "MOST_RECENT_TURN";
  /**
   * The semantic role that the entity was used in.
   */
  role?: AttentionalEntitiesSemanticRoleId;
  /**
   * How salient this mention is. This field will only be set if the mention is
   * derived from a SearchAnswerValue. See go/webresultsdata-as-aes for more
   * details.
   */
  salience?:  | "UNKNOWN_SALIENCE" | "PRIMARY" | "METADATA";
  /**
   * Contains metadata about the source of the mention.
   */
  source?: AttentionalEntitiesMentionPropertiesSource;
  /**
   * If present, properties of visual mentions (e.g., how they are displayed to
   * the user, visibility, etc.).
   */
  spatialProperties?: AttentionalEntitiesSpatialProperties;
  /**
   * Details about how this mention was presented.
   */
  surfaceForm?: AttentionalEntitiesSurfaceForm;
  /**
   * Unix timestamp noting (approximately) when this mention occurred. We do
   * not guarantee that the time will correspond precisely to when the user
   * uttered/heard a response. If mentions within a single turn have *different*
   * timestamps, they should accurately reflect the order in which the mentions
   * occurred. If that order is unknown, they should all have the same
   * timestamp.
   */
  timestamp?: Date;
}

function serializeAttentionalEntitiesMentionProperties(data: any): AttentionalEntitiesMentionProperties {
  return {
    ...data,
    eventId: data["eventId"] !== undefined ? serializeEventIdMessage(data["eventId"]) : undefined,
    listEntryInfo: data["listEntryInfo"] !== undefined ? serializeAttentionalEntitiesMentionPropertiesListEntryInfo(data["listEntryInfo"]) : undefined,
    timestamp: data["timestamp"] !== undefined ? data["timestamp"].toISOString() : undefined,
  };
}

function deserializeAttentionalEntitiesMentionProperties(data: any): AttentionalEntitiesMentionProperties {
  return {
    ...data,
    eventId: data["eventId"] !== undefined ? deserializeEventIdMessage(data["eventId"]) : undefined,
    listEntryInfo: data["listEntryInfo"] !== undefined ? deserializeAttentionalEntitiesMentionPropertiesListEntryInfo(data["listEntryInfo"]) : undefined,
    timestamp: data["timestamp"] !== undefined ? new Date(data["timestamp"]) : undefined,
  };
}

/**
 * Contains information about how an entity was presented as part of a list.
 */
export interface AttentionalEntitiesMentionPropertiesListEntryInfo {
  /**
   * The index of the entity presented to the user. NOTE: Indexing starts from
   * 0.
   */
  index?: bigint;
  /**
   * A string which uniquely identifies the list item this entity represents in
   * the list. For example, consider the "OrderPizza" intent with the "size"
   * slot: U: I want to order a pizza A: Sure. What size do you want: large,
   * medium, or small? U: Gigantic The lexical_groundings_id can be "large" to
   * identify the large item in the list. This lexical_groundings_id together
   * with the semantic role fields (i.e., role.intent_id & role.role_id) can be
   * used to match the nlp_semantic_parsing::LexicalGroundings::ValueTermType to
   * utilize lexical grounding for i18n of static list selection items. Note
   * that this field only needs to be populated when developers expect to
   * provide lexical groundings for the list item this entity represents.
   * Effectively, this field will be populated when this entity is published by
   * ListPresentationFrame and the
   * ::quality::dialog_manager::IntentStageSignals::FieldCandidate.lexical_groundings_id
   * field is populated. See go/lpf-i18nv2 & go/taskstate-ae-sync for more
   * details.
   */
  lexicalGroundingsId?: string;
}

function serializeAttentionalEntitiesMentionPropertiesListEntryInfo(data: any): AttentionalEntitiesMentionPropertiesListEntryInfo {
  return {
    ...data,
    index: data["index"] !== undefined ? String(data["index"]) : undefined,
  };
}

function deserializeAttentionalEntitiesMentionPropertiesListEntryInfo(data: any): AttentionalEntitiesMentionPropertiesListEntryInfo {
  return {
    ...data,
    index: data["index"] !== undefined ? BigInt(data["index"]) : undefined,
  };
}

/**
 * The agent or system from which the mention was derived. Each mention
 * corresponds to a single source.
 */
export interface AttentionalEntitiesMentionPropertiesSource {
  client?: AttentionalEntitiesMentionPropertiesSourceClient;
  system?: AttentionalEntitiesMentionPropertiesSourceSystem;
  user?: AttentionalEntitiesMentionPropertiesSourceUser;
}

/**
 * The client provided this entity. Currently, this exclusively corresponds to
 * an entity that was circulated by the client. See go/on-device-aes for more
 * details.
 */
export interface AttentionalEntitiesMentionPropertiesSourceClient {
}

/**
 * The Assistant mentioned this entity. This corresponds to entities annotated
 * during fulfillment. More specifically, these entities are typically provided
 * by developers either via a Monastery frame or an InteractionBuilder.
 */
export interface AttentionalEntitiesMentionPropertiesSourceSystem {
}

/**
 * The user mentioned this entity. It was extracted from a previous winning
 * intent (IntentQuery or IntentUpdate). Such entities are computed at runtime
 * from the interpretation history without any developer intervention.
 */
export interface AttentionalEntitiesMentionPropertiesSourceUser {
}

/**
 * Uniquely identifies a semantic role. When this role corresponds to a slot in
 * a registered user intent (see go/assistant-intent-catalog), then the
 * SemanticRoleId maps precisely onto that slot in the intent catalog. However,
 * not all semantic roles corresponds to such user intent slots.
 */
export interface AttentionalEntitiesSemanticRoleId {
  /**
   * Semantic roles will be defined locally, within the context of a single
   * task/feature. The |intent_id| is a unique identifier for such a local
   * cluster. In most cases, this should be exactly the same as the name of the
   * intent used for TaskState (see go/assistant-intent-catalog). In cases where
   * the intent isn't well-defined, this can be an arbitrary, feature-defined
   * identifier.
   */
  intentId?: string;
  /**
   * Identifier for a semantic role, unique within the namespace of
   * |intent_id|. When this role corresponds to a slot in the intent, the
   * |role_id| should be equal to the name of that argument. For example,
   * consider an entry in the intent catalog: core_intent { id { id: "BookARide"
   * } slot { name: "provider" type { string_type { } } } slot { name:
   * "num_riders" type { number_type { } } } } Then, the |role_id| would be
   * "provider" or "num_riders" when referring to one of these slots. NOTE: when
   * responding to the user, the Assistant may actually make use of other roles
   * such as "ETA" or "driver" that are not part of the intent declaration.
   * These should still be assigned consistent semantic roles. For example, a
   * dialog with the Shopping feature: User: Where can I buy XYZ? Google: [Best
   * Buy in Sunnyvale] has [XYZ] in stock. User: Great! Give me directions. In
   * this case, both "Best Buy" and "XYZ" would be pushed to attentional
   * entities. Best Buy, in this case, may not be an argument in the
   * ShoppingItemStockInquiry intent, but should still have a consistent
   * |role_id| such as "possessing_business".
   */
  roleId?: string;
}

/**
 * Properties of visual mentions (e.g., how they are displayed to the user,
 * visibility, etc.).
 */
export interface AttentionalEntitiesSpatialProperties {
  visibility?:  | "UNKNOWN_VISIBILITY" | "VISIBLE" | "HIDDEN";
}

/**
 * How the entity was presented in this mention at a surface level. For
 * example, "President Barack Obama" or "Barack Obama" or "he" might all be
 * reasonable surface forms for the MID /m/02mjmr.
 */
export interface AttentionalEntitiesSurfaceForm {
  text?: string;
}

/**
 * This data is expected to appear in approximately 2 out of every 1,000
 * documents with an average of 2 fields per document. Rough order of size is in
 * the hundreds of kilobytes per Mustang shard.
 */
export interface BiasingPerDocData {
  biasingfield?: BiasingPerDocDataBiasingField[];
}

function serializeBiasingPerDocData(data: any): BiasingPerDocData {
  return {
    ...data,
    biasingfield: data["biasingfield"] !== undefined ? data["biasingfield"].map((item: any) => (serializeBiasingPerDocDataBiasingField(item))) : undefined,
  };
}

function deserializeBiasingPerDocData(data: any): BiasingPerDocData {
  return {
    ...data,
    biasingfield: data["biasingfield"] !== undefined ? data["biasingfield"].map((item: any) => (deserializeBiasingPerDocDataBiasingField(item))) : undefined,
  };
}

/**
 * A replacement for BiasingPerDocData that is more efficient wrt size in the
 * index.
 */
export interface BiasingPerDocData2 {
  biasingField?: BiasingPerDocData2BiasingField[];
}

export interface BiasingPerDocData2BiasingField {
  /**
   * A fingerprint of the actual name of the field.
   */
  compressedName?: number;
  /**
   * The value, under various representations to get maximum compression.
   * Exactly one of them is guaranteed to be filled. value as a double.
   */
  value?: number;
  /**
   * a floating value, represented as an integer by converting using
   * floating_value * 1000. Useable for all floating values that need 3 digits
   * of precision, and are small enough.
   */
  valueFloat?: number;
  /**
   * value as an int32. When the value is encode-able as an integer.
   */
  valueInt?: number;
}

/**
 * Metadata fields on which we can bias (sort) search results independently
 * from the normal ranking using a ScoreAdjuster
 */
export interface BiasingPerDocDataBiasingField {
  /**
   * Fingerprint of the attribute name (no need to keep long field names)
   */
  Name?: bigint;
  /**
   * Biasing value translated into a double for uniform comparison
   */
  Value?: number;
}

function serializeBiasingPerDocDataBiasingField(data: any): BiasingPerDocDataBiasingField {
  return {
    ...data,
    Name: data["Name"] !== undefined ? String(data["Name"]) : undefined,
  };
}

function deserializeBiasingPerDocDataBiasingField(data: any): BiasingPerDocDataBiasingField {
  return {
    ...data,
    Name: data["Name"] !== undefined ? BigInt(data["Name"]) : undefined,
  };
}

/**
 * A BlobRef is used to refer to a blob in BlobStore. Clients may only
 * manipulate blobs through BlobRefs. BlobRefs should not be sent in the clear
 * outside of Google (for example, encoded in URLs, stored in a client cookie,
 * or referred to in Javascript); for efficiency, the IDs expose internal
 * details of the blobstore (such as machine IPs or cluster names). If clients
 * need to store BlobRefs outside of Google, they must encrypt the BlobRef
 * securely or use an alternative insecure identifier with an id->BlobRef
 * mapping inside our network.
 */
export interface BlobstoreBlobRef {
  BlobID?: Uint8Array;
  Options?: bigint;
  RefID?: Uint8Array;
  ShardBin?: number;
  /**
   * Size of the complete blob, in bytes.
   */
  Size?: bigint;
  /**
   * The ID of the V2 blob this blob has
   */
  SourceV2BlobID?: string;
  /**
   * Deprecated.
   */
  V2ReadBlobToken?: string;
}

function serializeBlobstoreBlobRef(data: any): BlobstoreBlobRef {
  return {
    ...data,
    BlobID: data["BlobID"] !== undefined ? encodeBase64(data["BlobID"]) : undefined,
    Options: data["Options"] !== undefined ? String(data["Options"]) : undefined,
    RefID: data["RefID"] !== undefined ? encodeBase64(data["RefID"]) : undefined,
    Size: data["Size"] !== undefined ? String(data["Size"]) : undefined,
  };
}

function deserializeBlobstoreBlobRef(data: any): BlobstoreBlobRef {
  return {
    ...data,
    BlobID: data["BlobID"] !== undefined ? decodeBase64(data["BlobID"] as string) : undefined,
    Options: data["Options"] !== undefined ? BigInt(data["Options"]) : undefined,
    RefID: data["RefID"] !== undefined ? decodeBase64(data["RefID"] as string) : undefined,
    Size: data["Size"] !== undefined ? BigInt(data["Size"]) : undefined,
  };
}

/**
 * Additional data for Blog/Posts
 */
export interface BlogPerDocData {
  /**
   * used for blogurl crowding.
   */
  blogurlFp?: bigint;
  /**
   * This score captures how spammy the client is that the micropost was
   * created with. The higher the score the worse.
   */
  clientSpamminess?: number;
  /**
   * For the threaded conversation view. Only populated in docs with provider
   * type SYNTHETIC_CONVERSATION_DOC.
   */
  convTree?: BlogsearchConversationTree;
  copycatScore?: number;
  docQualityScore?: number;
  /**
   * A syntactic reshare is a document that is * created from an original and
   * shared with friends and * we detect this resharing property by
   * syntactically parsing the doc. . For example, a retweet is an example of a
   * syntactic_reshare because we can detect that it's a reshare by grepping for
   * "RT @".
   */
  isSyntacticReshare?: boolean;
  /**
   * Experimental data for quality experiments. This will NOT be populated in
   * prod, but we will use this for experiments.
   */
  microblogQualityExptData?: Proto2BridgeMessageSet;
  /**
   * For replies/reshares. num_mentions = number of times the pattern @foo
   * appears in the document.
   */
  numMentions?: number;
  outlinks?: BlogPerDocDataOutlinks[];
  /**
   * The fingerprint for the body text of the microblog post. It is copied from
   * MicroBlogPost.post_content_fingerprint.
   */
  postContentFingerprint?: number;
  qualityScore?: number;
  /**
   * Blog scoring signals.
   */
  spamScore?: number;
  universalWhitelisted?: boolean;
  /**
   * User and doc quality scores for updates (aka microposts).
   */
  userQualityScore?: number;
}

function serializeBlogPerDocData(data: any): BlogPerDocData {
  return {
    ...data,
    blogurlFp: data["blogurlFp"] !== undefined ? String(data["blogurlFp"]) : undefined,
    convTree: data["convTree"] !== undefined ? serializeBlogsearchConversationTree(data["convTree"]) : undefined,
    outlinks: data["outlinks"] !== undefined ? data["outlinks"].map((item: any) => (serializeBlogPerDocDataOutlinks(item))) : undefined,
  };
}

function deserializeBlogPerDocData(data: any): BlogPerDocData {
  return {
    ...data,
    blogurlFp: data["blogurlFp"] !== undefined ? BigInt(data["blogurlFp"]) : undefined,
    convTree: data["convTree"] !== undefined ? deserializeBlogsearchConversationTree(data["convTree"]) : undefined,
    outlinks: data["outlinks"] !== undefined ? data["outlinks"].map((item: any) => (deserializeBlogPerDocDataOutlinks(item))) : undefined,
  };
}

/**
 * Resolved url and site spamscore for outlinks in updates (aka microposts).
 */
export interface BlogPerDocDataOutlinks {
  /**
   * Representative id for an equivalence class of URLs. E.g.
   * http://youtube.com/watch?v=12 and
   * http://youtube.com/watch?v=12&feature=related have the same aggregation id
   * since they're effectively the same webpage
   */
  aggregationFp?: bigint;
  resolvedUrl?: string;
  siteSpamScore?: number;
  title?: string;
}

function serializeBlogPerDocDataOutlinks(data: any): BlogPerDocDataOutlinks {
  return {
    ...data,
    aggregationFp: data["aggregationFp"] !== undefined ? String(data["aggregationFp"]) : undefined,
  };
}

function deserializeBlogPerDocDataOutlinks(data: any): BlogPerDocDataOutlinks {
  return {
    ...data,
    aggregationFp: data["aggregationFp"] !== undefined ? BigInt(data["aggregationFp"]) : undefined,
  };
}

export interface BlogsearchConversationNode {
  /**
   * The username of the author of the microblog post represented by this node.
   */
  authorName?: string;
  /**
   * A list of docids of child nodes.
   */
  children?: string[];
  /**
   * The creation date of the doc.
   */
  date?: bigint;
  /**
   * Docid of the microblog post represented by this node.
   */
  docid?: string;
  /**
   * The docid of the parent node. The root of the tree will leave this empty.
   */
  parent?: string;
}

function serializeBlogsearchConversationNode(data: any): BlogsearchConversationNode {
  return {
    ...data,
    date: data["date"] !== undefined ? String(data["date"]) : undefined,
  };
}

function deserializeBlogsearchConversationNode(data: any): BlogsearchConversationNode {
  return {
    ...data,
    date: data["date"] !== undefined ? BigInt(data["date"]) : undefined,
  };
}

export interface BlogsearchConversationTree {
  /**
   * The id of this conversation.
   */
  convId?: string;
  /**
   * The nodes in this conversation. No particular order is assumed.
   */
  nodes?: BlogsearchConversationNode[];
}

function serializeBlogsearchConversationTree(data: any): BlogsearchConversationTree {
  return {
    ...data,
    nodes: data["nodes"] !== undefined ? data["nodes"].map((item: any) => (serializeBlogsearchConversationNode(item))) : undefined,
  };
}

function deserializeBlogsearchConversationTree(data: any): BlogsearchConversationTree {
  return {
    ...data,
    nodes: data["nodes"] !== undefined ? data["nodes"].map((item: any) => (deserializeBlogsearchConversationNode(item))) : undefined,
  };
}

/**
 * Information to indicate BG availability for businesses. This message is
 * filled from Topic Server and stored in the GSR in Superroot.
 */
export interface BlueGingerClientVisibleProtoBlueGingerSupportedServices {
  /**
   * List of supported modules for a business.
   */
  modules?: BlueGingerClientVisibleProtoBlueGingerSupportedServicesBlueGingerModule[];
}

export interface BlueGingerClientVisibleProtoBlueGingerSupportedServicesBlueGingerModule {
  /**
   * Module name, e.g. hairdresser_reservation. from
   * quality/views/extraction/kcube/bg/modules/modules.bzl.
   */
  name?: string;
  /**
   * Services of this module that are supported by the business, e.g. haircuts.
   */
  services?: string[];
  useCase?:  | "UNKNOWN_USE_CASE" | "OPENING_HOURS" | "ON_DEMAND_OPENING_HOURS" | "GEO_DATA_EXTRACTION" | "OPERATING_MODE_EXTRACTION" | "RESTAURANT_RESERVATION" | "MASSAGE_RESERVATION" | "HAIRDRESSER_RESERVATION" | "NAIL_SALON_RESERVATION" | "RUNNING_LATE" | "FOOD_ORDERING" | "LOCAL_INVENTORY_CHECK" | "ON_DEMAND_LOCAL_INVENTORY" | "WAITLIST" | "CHECK_WAIT" | "CHEFBOT" | "ADS_CALL_CENTER_AUTHENTICATION" | "PLAYSTORE" | "TAKING_RESTAURANT_RESERVATIONS" | "CALL_CENTER_DEMO" | "ASSISTED_CALL_DEMO" | "BUSINESS_OPT_IN" | "CALLJOY_PILOT" | "ASSISTANT_REMINDERS_DEMO" | "HAPPY_BIRTHDAY" | "ASSISTED_IVR" | "DUPLEX_FOR_BUSINESS_PILOT" | "SAY_THE_SAME_THING" | "COVID_FAQ" | "VANCOUVER" | "MEENAPLEX" | "REMOVED_USE_CASE_6" | "SEMI_DELEGATED_CALLING" | "HARDWARE_SETUP" | "DUMDA_BOT" | "SMART_REPLY" | "DUPLEX_ZERO" | "SPAM_FILTER" | "TEXT" | "IVR_CRAWLING" | "VOICEMAIL" | "INBOUND_SMB" | "CCAI_DEMO" | "DIALOGFLOW_DELEGATION" | "AD_LEAD_VERIFICATION" | "GET_HUMAN" | "CHECK_INSURANCE_ACCEPTANCE";
}

/**
 * Per-doc data for the web page about the cited book Approximate size is on
 * average ~10bytes
 */
export interface BookCitationPerDocData {
  /**
   * the book id for the main citation
   */
  bookId?: bigint;
  /**
   * the discretized citation score for the main book. we map the raw score
   * 1.0-20.0 to 0 - 127
   */
  discretizedCitationScore?: number;
  /**
   * Is there a preview or excerpt of the book on this document?
   */
  previewable?: boolean;
  /**
   * book id for the second citation if we can't separate the two top citations
   * (they are too close).
   */
  secondBookId?: bigint;
  /**
   * the discretized score for the second citation
   */
  secondDiscretizedCitationScore?: number;
}

function serializeBookCitationPerDocData(data: any): BookCitationPerDocData {
  return {
    ...data,
    bookId: data["bookId"] !== undefined ? String(data["bookId"]) : undefined,
    secondBookId: data["secondBookId"] !== undefined ? String(data["secondBookId"]) : undefined,
  };
}

function deserializeBookCitationPerDocData(data: any): BookCitationPerDocData {
  return {
    ...data,
    bookId: data["bookId"] !== undefined ? BigInt(data["bookId"]) : undefined,
    secondBookId: data["secondBookId"] !== undefined ? BigInt(data["secondBookId"]) : undefined,
  };
}

/**
 * We divide up a week into individual open intervals. If any are present then
 * they must be arranged in strictly increasing order, with non-empty spaces
 * between successive intervals, and all times between 0 and 604800, the number
 * of seconds in a week.
 */
export interface BusinessHours {
  dayopen?: number;
  interval?: BusinessHoursInterval[];
}

export interface BusinessHoursInterval {
  /**
   * The interval ends at the start of this second
   */
  end?: number;
  /**
   * Time in seconds since Midnight-Monday-Morn
   */
  start?: number;
}

/**
 * Token to be exposed and stored by the bot
 */
export interface ChatBotPlatformBotSendToken {
  /**
   * Time since epoch (micros) that this will expire
   */
  expiryTimeMicros?: bigint;
  /**
   * Encrypted InternalSendToken
   */
  sendToken?: Uint8Array;
}

function serializeChatBotPlatformBotSendToken(data: any): ChatBotPlatformBotSendToken {
  return {
    ...data,
    expiryTimeMicros: data["expiryTimeMicros"] !== undefined ? String(data["expiryTimeMicros"]) : undefined,
    sendToken: data["sendToken"] !== undefined ? encodeBase64(data["sendToken"]) : undefined,
  };
}

function deserializeChatBotPlatformBotSendToken(data: any): ChatBotPlatformBotSendToken {
  return {
    ...data,
    expiryTimeMicros: data["expiryTimeMicros"] !== undefined ? BigInt(data["expiryTimeMicros"]) : undefined,
    sendToken: data["sendToken"] !== undefined ? decodeBase64(data["sendToken"] as string) : undefined,
  };
}

export interface ChatBotPlatformFireballId {
  /**
   * When used as a user ID, it's the phone number of the sender. When used as
   * a session ID: For group conversation, it is the group ID. For 1 to 1, it is
   * the receiver or sender phone number. For 1 to bot, it is the receiver phone
   * number or empty.
   */
  id?: GoogleInternalCommunicationsInstantmessagingV1Id;
}

function serializeChatBotPlatformFireballId(data: any): ChatBotPlatformFireballId {
  return {
    ...data,
    id: data["id"] !== undefined ? serializeGoogleInternalCommunicationsInstantmessagingV1Id(data["id"]) : undefined,
  };
}

function deserializeChatBotPlatformFireballId(data: any): ChatBotPlatformFireballId {
  return {
    ...data,
    id: data["id"] !== undefined ? deserializeGoogleInternalCommunicationsInstantmessagingV1Id(data["id"]) : undefined,
  };
}

/**
 * Per-URL porn scores for the URLs associated with the corresponding image.
 */
export interface ClassifierPornAggregatedUrlPornScores {
  averageUrlPornScore?: number;
  urlCount?: number;
}

/**
 * Next ID: 6
 */
export interface ClassifierPornClassifierData {
  classification?: ClassifierPornClassifierDataClassification[];
  /**
   * Records whether the image linker is run already. This is only used for
   * Alexandria but NOT for Segindexer.
   */
  imageBasedDetectionDone?: boolean;
  timestamp?: bigint;
}

function serializeClassifierPornClassifierData(data: any): ClassifierPornClassifierData {
  return {
    ...data,
    timestamp: data["timestamp"] !== undefined ? String(data["timestamp"]) : undefined,
  };
}

function deserializeClassifierPornClassifierData(data: any): ClassifierPornClassifierData {
  return {
    ...data,
    timestamp: data["timestamp"] !== undefined ? BigInt(data["timestamp"]) : undefined,
  };
}

export interface ClassifierPornClassifierDataClassification {
  label?: string;
  score?: number;
}

/**
 * Next ID: 3
 */
export interface ClassifierPornDocumentData {
  classifierdata?: ClassifierPornClassifierData;
  sitedata?: ClassifierPornSiteData;
}

function serializeClassifierPornDocumentData(data: any): ClassifierPornDocumentData {
  return {
    ...data,
    classifierdata: data["classifierdata"] !== undefined ? serializeClassifierPornClassifierData(data["classifierdata"]) : undefined,
    sitedata: data["sitedata"] !== undefined ? serializeClassifierPornSiteData(data["sitedata"]) : undefined,
  };
}

function deserializeClassifierPornDocumentData(data: any): ClassifierPornDocumentData {
  return {
    ...data,
    classifierdata: data["classifierdata"] !== undefined ? deserializeClassifierPornClassifierData(data["classifierdata"]) : undefined,
    sitedata: data["sitedata"] !== undefined ? deserializeClassifierPornSiteData(data["sitedata"]) : undefined,
  };
}

/**
 * Generic output for one vertical.
 */
export interface ClassifierPornQueryClassifierOutput {
  /**
   * This field is only filled for the CSAI vertical.
   */
  csaiClassification?:  | "NOT_PROTECTED" | "PROTECTED" | "STRONGLY_PROTECTED";
  /**
   * DO NOT USE: This field is temporary and should be used only for the CSAI
   * Onebox. This field is the result of the regular expression classifier alone
   * as opposed to a combination with Seti classifier as in csai_classification
   * field.
   */
  csaiRegexpHighConfidenceClassification?:  | "NOT_PROTECTED" | "PROTECTED" | "STRONGLY_PROTECTED";
  /**
   * Human-readable debug information about the classification. This field is
   * only set if output_debug is set in the classification input.
   */
  debug?: string;
  /**
   * The bit that shows if this classifier outputs positive classification for
   * the input query. Set by thresholding with a recommended threshold.
   */
  isPositive?: boolean;
  /**
   * The score that the classifier assigned to the input query. This is filled
   * by all verticals.
   */
  score?: number;
}

/**
 * Multi-label classification output. It contains the output for each vertical.
 * The output for some verticals can be empty, in case that vertical is not
 * supported by the classifier or if the set of verticals was restricted using
 * MultiLabelClassifierInput.verticals.
 */
export interface ClassifierPornQueryMultiLabelClassifierOutput {
  csai?: ClassifierPornQueryClassifierOutput;
  fringe?: ClassifierPornQueryClassifierOutput;
  medical?: ClassifierPornQueryClassifierOutput;
  offensive?: ClassifierPornQueryClassifierOutput;
  porn?: ClassifierPornQueryClassifierOutput;
  spoof?: ClassifierPornQueryClassifierOutput;
  violence?: ClassifierPornQueryClassifierOutput;
  vulgar?: ClassifierPornQueryClassifierOutput;
}

/**
 * QuerySats contains the information about the queries that users typed to
 * search for this image.
 */
export interface ClassifierPornQueryStats {
  /**
   * A query text porn score for the queries which have clicks to the image:
   * query_text_porn_score := sum(clicks(query) * text_porn_score(query)) /
   * sum(clicks(query))
   */
  queryTextPornScore?: number;
  totalClicks?: number;
}

/**
 * ReferrerCounts stores how many referrers an images has and how many of them
 * were classified as porn and as adult/softporn respectively. Note that a
 * referrer is usually a landing page, but as of March 2011 this also includes
 * referrers which an image can 'inherit' by propagating counts from near
 * duplicate images.
 */
export interface ClassifierPornReferrerCounts {
  adult?: number;
  /**
   * Number of referrers which are classified as porn and as adult.
   */
  porn?: number;
  /**
   * Total number of referrers.
   */
  total?: number;
}

/**
 * Next ID: 52
 */
export interface ClassifierPornSiteData {
  /**
   * The average pedo page score for the site.
   */
  avgPedoPageScore?: number;
  finalPedoSiteScore?: number;
  /**
   * The number of pages that were used to compute the scores and ratios.
   */
  numberOfPages?: bigint;
  /**
   * The number of pages with pedo restrict.
   */
  numberOfPedoPages?: bigint;
  /**
   * Sitechunk used to compute the signals. The field is present only for data
   * created after December 2022.
   */
  site?: string;
  /**
   * The ratio of porn/softporn of the site this page belongs to.
   */
  sitePornRatio?: number;
  siteSoftpornRatio?: number;
  versionedscore?: ClassifierPornSiteDataVersionedScore[];
  violenceStats?: ClassifierPornSiteViolenceStats;
}

function serializeClassifierPornSiteData(data: any): ClassifierPornSiteData {
  return {
    ...data,
    numberOfPages: data["numberOfPages"] !== undefined ? String(data["numberOfPages"]) : undefined,
    numberOfPedoPages: data["numberOfPedoPages"] !== undefined ? String(data["numberOfPedoPages"]) : undefined,
    violenceStats: data["violenceStats"] !== undefined ? serializeClassifierPornSiteViolenceStats(data["violenceStats"]) : undefined,
  };
}

function deserializeClassifierPornSiteData(data: any): ClassifierPornSiteData {
  return {
    ...data,
    numberOfPages: data["numberOfPages"] !== undefined ? BigInt(data["numberOfPages"]) : undefined,
    numberOfPedoPages: data["numberOfPedoPages"] !== undefined ? BigInt(data["numberOfPedoPages"]) : undefined,
    violenceStats: data["violenceStats"] !== undefined ? deserializeClassifierPornSiteViolenceStats(data["violenceStats"]) : undefined,
  };
}

/**
 * The site porn score of the site to which the page of interest belongs to.
 * Multiple versions are kept across large changes for some time. The Version-4
 * score is the average Universal Page Probability of all the site's pages, and
 * will come with populated verticals4_score and site_rule (if any rule fires)
 * fields. When using this score it is recommended to subscribe to the following
 * mailing list: g/safesearch-announce.
 */
export interface ClassifierPornSiteDataVersionedScore {
  score?: number;
  siteRule?:  | "HIGH_PORN_FRACTION_RULE" | "DEPRECATED_USER_GENERATED_CONTENT_RULE" | "DEPRECATED_SITES_WITH_IGNORED_SCORES_LIST"[];
  version?: number;
  /**
   * Please talk to safesearch@ before relying on any of these internal fields:
   */
  verticals4Score?: number;
}

/**
 * Next ID: 6
 */
export interface ClassifierPornSiteViolenceStats {
  meanFinalViolenceScore?: number;
  numberOfImages?: bigint;
  numberOfVideos?: bigint;
  videoViolenceScore?: number;
}

function serializeClassifierPornSiteViolenceStats(data: any): ClassifierPornSiteViolenceStats {
  return {
    ...data,
    numberOfImages: data["numberOfImages"] !== undefined ? String(data["numberOfImages"]) : undefined,
    numberOfVideos: data["numberOfVideos"] !== undefined ? String(data["numberOfVideos"]) : undefined,
  };
}

function deserializeClassifierPornSiteViolenceStats(data: any): ClassifierPornSiteViolenceStats {
  return {
    ...data,
    numberOfImages: data["numberOfImages"] !== undefined ? BigInt(data["numberOfImages"]) : undefined,
    numberOfVideos: data["numberOfVideos"] !== undefined ? BigInt(data["numberOfVideos"]) : undefined,
  };
}

/**
 * The basic message that contains a single decision output of go/deeptagger.
 */
export interface CommerceDatastoreDeepTag {
  /**
   * The confidence of the tag, encoded to 14 bits (range [0, 16383]). Due to
   * modeling details, a large number of tags become trustworthy with confidence
   * greater than 0.001, so two bytes of precision are required.
   */
  confidence?: number;
  /**
   * A Deep Tag enum in uint32 form.
   */
  tag?: number;
}

/**
 * Image-level deep tags: essentially equivalent to the proto above but
 * containing tags that are computed at the image level. These image signals are
 * maintained by the Visual Shopping team (visual-shopping@). *** If you do use
 * the signals, please add an entry in go/ShoppingImageAttributeClients to be
 * notified for model upgrade. *** We recommend our clients against using the
 * raw confidence value directly. Instead, the clients should use the library,
 * cs/ads/shopping/visual/deeptags/public/single_tag.h and
 * cs/ads/shopping/visual/deeptags/public/single_scored_tag.h to specify an
 * operating point in terms of precision or recall. See the following code
 * example:
 * http://google3/shopping/visual/explore_looks/looks_offline_pipeline.cc?l=268&rcl=304165166
 * *** `model_outputs` is a repeated field. Please check `version` to get the
 * model you desire to use, instead of indexing the model_outputs directly e.g.
 * model_outputs(0). We will remove the old versions in the future and this will
 * lead to incorrect model. *** Models: As of Q2 2020, we have two models
 * running within Shopping: model one only has the overlay tag, which we are
 * deprecating, and model two has the tags specified in
 * go/VisualShoppingImageAttributes.
 */
export interface CommerceDatastoreImageDeepTags {
  /**
   * The set of outputs for a series of model versions. The size of this field
   * should not extend beyond 4 at any time: two versions for slow-update track
   * dependencies, and two versions for fast-update track dependencies.
   */
  modelOutputs?: CommerceDatastoreImageDeepTagsModelOutput[];
}

export interface CommerceDatastoreImageDeepTagsModelOutput {
  backgroundType?: CommerceDatastoreDeepTag;
  collage?: CommerceDatastoreDeepTag;
  /**
   * We are looking to deploy a model for the Ads team to identify images with
   * bad cropping. The model will be for Ads only and we will not populate the
   * cropping field in CDS.
   */
  cropping?: CommerceDatastoreDeepTag;
  modelType?: CommerceDatastoreDeepTag;
  /**
   * Tag corresponds to the shopping non-family safe (nfs) image signal.
   */
  nfs?: CommerceDatastoreDeepTag;
  objectCount?: CommerceDatastoreDeepTag;
  /**
   * Tag corresponding to unwanted text overlay (watermarks, logos, promotional
   * elements, artifacts, etc).
   */
  overlay?: CommerceDatastoreDeepTag;
  selfie?: CommerceDatastoreDeepTag;
  /**
   * Tag corresponding to the text overlay classifier (watermarks, logos,
   * promotional elements, artifacts, etc).
   */
  textOverlay?: CommerceDatastoreDeepTag[];
  version?: number;
}

/**
 * Protocol record used for collecting together all information about a
 * document. Please consult go/dj-explorer for two basic questions about
 * `CompositeDoc`: - Where should I look up certain information (e.g: pagerank,
 * language)? - What does each field in CompositeDoc mean and who should I
 * contact if I have questions? To add a new field into CompositeDoc, or change
 * existing field's size significantly, please file a ticket at go/dj-new-field,
 * fill in necessary information and get approved by docjoin-access@ team. Next
 * id: 191
 */
export interface CompositeDoc {
  /**
   * Contains necessary information to enforce row level Docjoin access
   * control.
   */
  accessRequirements?: IndexingPrivacyAccessAccessRequirements;
  additionalchecksums?: CompositeDocAdditionalChecksums;
  alternatename?: CompositeDocAlternateName[];
  anchors?: Anchors;
  anchorStats?: IndexingDocjoinerAnchorStatistics;
  /**
   * This field is present iff the page has a bad SSL certificate itself or in
   * its redirect chain.
   */
  badSslCertificate?: IndexingBadSSLCertificate;
  /**
   * Visible content checksum as computed by
   * repository::parsehandler::checksum::Checksum96bitsParseHandler. The value
   * is a Fprint96 in "key format" (i.e., by Fprint96::AsKey()).
   */
  ContentChecksum96?: Uint8Array;
  cseId?: QualityProseCSEUrlInfo[];
  /**
   * URL should only be selected for CSE Index if it's pagerank is higher than
   * cse_pagerank_cutoff.
   */
  csePagerankCutoff?: number;
  /**
   * Contains the tracking version of various data fields in CompositeDoc.
   */
  dataVersion?: IndexingDocjoinerDataVersion;
  doc?: GDocumentBase;
  /**
   * A generic container to hold document annotations and signals. For a full
   * list of extensions live today, see go/wde.
   */
  docAttachments?: Proto2BridgeMessageSet;
  /**
   * Info about "selected" images associated with the document for which we
   * (already) have ImageData. For each image URL, some fixed number of
   * documents are selected as web referrers for the image URL, and within those
   * selected documents, we say the image is "selected". Within the remaining
   * documents, we say the image is "rejected". Note that this distinction is
   * slightly different from selected for indexing. Only images within
   * doc_images where is_indexed_by_imagesearch is true will be selected for
   * indexing. You can find the rejected images at
   * composite_doc.doc_attachments().get(). You can find images that are
   * selected, but for which we have no ImageData (yet) at
   * composite_doc.image_indexing_info().selected_not_indexed_image_link()
   */
  docImages?: ImageData[];
  /**
   * This message set is used for data pushed into the index using the signals
   * framework that is never to be used in Mustang or TG Continuum
   * scoring/snippeting code. Any protocol buffer stored in this message set is
   * automatically returned in a docinfo response - it ends up in the "info"
   * message set in the WWWSnippetResponse, so it can be used in post-doc
   * twiddlers and for display in GWS with no code changes in Mustang or
   * Teragoogle.
   */
  docinfoPassthroughAttachments?: Proto2BridgeMessageSet;
  /**
   * Info about videos embedded in the document.
   */
  docVideos?: ImageRepositoryVideoProperties[];
  /**
   * Data produced by the embedded-content system. This is a thin message,
   * containing only embedded_links_info data for the embedder and
   * JavaScript/CSS embedded links (the embedded-content bigtable also contains
   * snapshots, compressed document trees and all embedded link types). Provided
   * using the index signal API.
   */
  embeddedContentInfo?: IndexingEmbeddedContentEmbeddedContentInfo;
  extradup?: CompositeDocExtraDup[];
  forwardingdup?: CompositeDocForwardingDup[];
  includedcontent?: CompositeDocIncludedContent[];
  indexinginfo?: CompositeDocIndexingInfo;
  /**
   * Serialized indexing intermediate data.
   */
  indexingIntermediate?: Uint8Array;
  /**
   * This field associates a document to particular labels and assigns
   * confidence values to them.
   */
  labelData?: QualityLabelsGoogleLabelData;
  liveexperimentinfo?: CompositeDocLiveExperimentInfo;
  localinfo?: LocalWWWInfo;
  /**
   * Localized alternate names are similar to alternate names, except that it
   * is associated with a language different from its canonical. This is the
   * subset of webmaster-provided localized alternate names being in the dup
   * cluster of this document. Used during serving for swapping in the URL based
   * on regional and language preferences of the user.
   */
  localizedAlternateName?: IndexingConverterLocalizedAlternateName[];
  localizedvariations?: CompositeDocLocalizedVariations;
  /**
   * Only present in partial cdocs.
   */
  partialUpdateInfo?: CompositeDocPartialUpdateInfo;
  perDocData?: PerDocData;
  /**
   * Porn related data used for image and web search porn classification as
   * well as for diagnostics purposes.
   */
  porninfo?: ClassifierPornDocumentData;
  properties?: DocProperties;
  /**
   * Contains information necessary to perform policy decision on the usage of
   * the data assosiated with this cdoc.
   */
  ptoken?: PtokenPToken;
  qualitysignals?: CompositeDocQualitySignals;
  /**
   * Information about the most recent creation and expiration of this domain.
   * It's extracted from domainedge signal.
   */
  registrationinfo?: RegistrationInfo;
  /**
   * If present, indicates that some content was inserted, deleted, or replaced
   * in the document's content (in CompositeDoc::doc::Content::Representation),
   * and stores information about what was inserted, deleted, or replaced.
   */
  richcontentData?: IndexingConverterRichContentData;
  /**
   * rich snippet extracted from the content of a document.
   */
  richsnippet?: RichsnippetsPageMap;
  robotsinfolist?: CompositeDocRobotsInfoList;
  /**
   * to copy to per-doc
   */
  scaledIndyRank?: number;
  /**
   * Sitelinks: a collection of interesting links a user might be interested
   * in, given they are interested in this document. WARNING: this is different
   * from the crawler Sitemaps (see SitemapsSignals in the attachments).
   */
  sitemap?: Sitemap;
  /**
   * Row timestamp in CDoc storage.
   */
  storageRowTimestampMicros?: bigint;
  subindexid?:  | "LTG_CANDIDATE" | "NOSUBINDEX" | "BASE" | "CSEINDEX_EXTENDED" | "DAILY" | "TIMBIT_PROTECTED" | "LANDFILL1" | "LANDFILL2" | "LANDFILL3" | "LANDFILL_BLOGSEARCH" | "LANDFILL_SOCIAL" | "INSTANT" | "UNIFIED_LANDFILL" | "BLOGSEARCH_DYNAMIC_ASSIMILATED" | "BLOGSEARCH_EXTENDED" | "MOFFETT" | "UNSELECTED_DOCUMENTS" | "AQUARIUS" | "WEBSEARCH_FRESH" | "WEBSEARCH1" | "WEBSEARCH2" | "WEBSEARCH3" | "UNIFIED_ZEPPELIN_HIGH_QUALITY" | "ASIANREGIONAL" | "EMEAREGIONAL" | "CSEINDEX" | "BASEREGIONAL" | "BLACKHOLE" | "XBASE" | "FRESHBASE" | "XASIANREGIONAL" | "XEMEAREGIONAL" | "XBASEREGIONAL" | "BLIMPIE" | "BLIMPIEPP" | "GOODYEAR" | "GOODYEARPP" | "QUASAR" | "ZEPPELIN1" | "ZEPPELIN2" | "ZEPPELIN3" | "ZEPPELIN_STAGING" | "PULSAR" | "TIMBIT" | "LANDFILL_CSE" | "UNIFIED_ZEPPELIN"[];
  syntacticDate?: QualityTimebasedSyntacticDate;
  /**
   * WARNING!!! "url" field in CompositeDoc is optional, and is usually
   * missing: e.g., Docjoin CompositeDoc's don't have CompositeDoc::url.
   * has_url() checking is often useful. So don't rely on CompositeDoc::url
   * unless you're sure otherwise. Usually you want to use
   * CompositeDoc::doc::url instead.
   */
  url?: string;
  /**
   * Date in the url extracted by quality/snippets/urldate/date-in-url.cc This
   * is given as midnight GMT on the date in question.
   */
  urldate?: bigint;
}

function serializeCompositeDoc(data: any): CompositeDoc {
  return {
    ...data,
    additionalchecksums: data["additionalchecksums"] !== undefined ? serializeCompositeDocAdditionalChecksums(data["additionalchecksums"]) : undefined,
    alternatename: data["alternatename"] !== undefined ? data["alternatename"].map((item: any) => (serializeCompositeDocAlternateName(item))) : undefined,
    anchors: data["anchors"] !== undefined ? serializeAnchors(data["anchors"]) : undefined,
    anchorStats: data["anchorStats"] !== undefined ? serializeIndexingDocjoinerAnchorStatistics(data["anchorStats"]) : undefined,
    badSslCertificate: data["badSslCertificate"] !== undefined ? serializeIndexingBadSSLCertificate(data["badSslCertificate"]) : undefined,
    ContentChecksum96: data["ContentChecksum96"] !== undefined ? encodeBase64(data["ContentChecksum96"]) : undefined,
    dataVersion: data["dataVersion"] !== undefined ? serializeIndexingDocjoinerDataVersion(data["dataVersion"]) : undefined,
    doc: data["doc"] !== undefined ? serializeGDocumentBase(data["doc"]) : undefined,
    docImages: data["docImages"] !== undefined ? data["docImages"].map((item: any) => (serializeImageData(item))) : undefined,
    docVideos: data["docVideos"] !== undefined ? data["docVideos"].map((item: any) => (serializeImageRepositoryVideoProperties(item))) : undefined,
    embeddedContentInfo: data["embeddedContentInfo"] !== undefined ? serializeIndexingEmbeddedContentEmbeddedContentInfo(data["embeddedContentInfo"]) : undefined,
    extradup: data["extradup"] !== undefined ? data["extradup"].map((item: any) => (serializeCompositeDocExtraDup(item))) : undefined,
    forwardingdup: data["forwardingdup"] !== undefined ? data["forwardingdup"].map((item: any) => (serializeCompositeDocForwardingDup(item))) : undefined,
    includedcontent: data["includedcontent"] !== undefined ? data["includedcontent"].map((item: any) => (serializeCompositeDocIncludedContent(item))) : undefined,
    indexinginfo: data["indexinginfo"] !== undefined ? serializeCompositeDocIndexingInfo(data["indexinginfo"]) : undefined,
    indexingIntermediate: data["indexingIntermediate"] !== undefined ? encodeBase64(data["indexingIntermediate"]) : undefined,
    labelData: data["labelData"] !== undefined ? serializeQualityLabelsGoogleLabelData(data["labelData"]) : undefined,
    liveexperimentinfo: data["liveexperimentinfo"] !== undefined ? serializeCompositeDocLiveExperimentInfo(data["liveexperimentinfo"]) : undefined,
    localinfo: data["localinfo"] !== undefined ? serializeLocalWWWInfo(data["localinfo"]) : undefined,
    localizedAlternateName: data["localizedAlternateName"] !== undefined ? data["localizedAlternateName"].map((item: any) => (serializeIndexingConverterLocalizedAlternateName(item))) : undefined,
    localizedvariations: data["localizedvariations"] !== undefined ? serializeCompositeDocLocalizedVariations(data["localizedvariations"]) : undefined,
    partialUpdateInfo: data["partialUpdateInfo"] !== undefined ? serializeCompositeDocPartialUpdateInfo(data["partialUpdateInfo"]) : undefined,
    perDocData: data["perDocData"] !== undefined ? serializePerDocData(data["perDocData"]) : undefined,
    porninfo: data["porninfo"] !== undefined ? serializeClassifierPornDocumentData(data["porninfo"]) : undefined,
    properties: data["properties"] !== undefined ? serializeDocProperties(data["properties"]) : undefined,
    qualitysignals: data["qualitysignals"] !== undefined ? serializeCompositeDocQualitySignals(data["qualitysignals"]) : undefined,
    richcontentData: data["richcontentData"] !== undefined ? serializeIndexingConverterRichContentData(data["richcontentData"]) : undefined,
    richsnippet: data["richsnippet"] !== undefined ? serializeRichsnippetsPageMap(data["richsnippet"]) : undefined,
    robotsinfolist: data["robotsinfolist"] !== undefined ? serializeCompositeDocRobotsInfoList(data["robotsinfolist"]) : undefined,
    sitemap: data["sitemap"] !== undefined ? serializeSitemap(data["sitemap"]) : undefined,
    storageRowTimestampMicros: data["storageRowTimestampMicros"] !== undefined ? String(data["storageRowTimestampMicros"]) : undefined,
    syntacticDate: data["syntacticDate"] !== undefined ? serializeQualityTimebasedSyntacticDate(data["syntacticDate"]) : undefined,
    urldate: data["urldate"] !== undefined ? String(data["urldate"]) : undefined,
  };
}

function deserializeCompositeDoc(data: any): CompositeDoc {
  return {
    ...data,
    additionalchecksums: data["additionalchecksums"] !== undefined ? deserializeCompositeDocAdditionalChecksums(data["additionalchecksums"]) : undefined,
    alternatename: data["alternatename"] !== undefined ? data["alternatename"].map((item: any) => (deserializeCompositeDocAlternateName(item))) : undefined,
    anchors: data["anchors"] !== undefined ? deserializeAnchors(data["anchors"]) : undefined,
    anchorStats: data["anchorStats"] !== undefined ? deserializeIndexingDocjoinerAnchorStatistics(data["anchorStats"]) : undefined,
    badSslCertificate: data["badSslCertificate"] !== undefined ? deserializeIndexingBadSSLCertificate(data["badSslCertificate"]) : undefined,
    ContentChecksum96: data["ContentChecksum96"] !== undefined ? decodeBase64(data["ContentChecksum96"] as string) : undefined,
    dataVersion: data["dataVersion"] !== undefined ? deserializeIndexingDocjoinerDataVersion(data["dataVersion"]) : undefined,
    doc: data["doc"] !== undefined ? deserializeGDocumentBase(data["doc"]) : undefined,
    docImages: data["docImages"] !== undefined ? data["docImages"].map((item: any) => (deserializeImageData(item))) : undefined,
    docVideos: data["docVideos"] !== undefined ? data["docVideos"].map((item: any) => (deserializeImageRepositoryVideoProperties(item))) : undefined,
    embeddedContentInfo: data["embeddedContentInfo"] !== undefined ? deserializeIndexingEmbeddedContentEmbeddedContentInfo(data["embeddedContentInfo"]) : undefined,
    extradup: data["extradup"] !== undefined ? data["extradup"].map((item: any) => (deserializeCompositeDocExtraDup(item))) : undefined,
    forwardingdup: data["forwardingdup"] !== undefined ? data["forwardingdup"].map((item: any) => (deserializeCompositeDocForwardingDup(item))) : undefined,
    includedcontent: data["includedcontent"] !== undefined ? data["includedcontent"].map((item: any) => (deserializeCompositeDocIncludedContent(item))) : undefined,
    indexinginfo: data["indexinginfo"] !== undefined ? deserializeCompositeDocIndexingInfo(data["indexinginfo"]) : undefined,
    indexingIntermediate: data["indexingIntermediate"] !== undefined ? decodeBase64(data["indexingIntermediate"] as string) : undefined,
    labelData: data["labelData"] !== undefined ? deserializeQualityLabelsGoogleLabelData(data["labelData"]) : undefined,
    liveexperimentinfo: data["liveexperimentinfo"] !== undefined ? deserializeCompositeDocLiveExperimentInfo(data["liveexperimentinfo"]) : undefined,
    localinfo: data["localinfo"] !== undefined ? deserializeLocalWWWInfo(data["localinfo"]) : undefined,
    localizedAlternateName: data["localizedAlternateName"] !== undefined ? data["localizedAlternateName"].map((item: any) => (deserializeIndexingConverterLocalizedAlternateName(item))) : undefined,
    localizedvariations: data["localizedvariations"] !== undefined ? deserializeCompositeDocLocalizedVariations(data["localizedvariations"]) : undefined,
    partialUpdateInfo: data["partialUpdateInfo"] !== undefined ? deserializeCompositeDocPartialUpdateInfo(data["partialUpdateInfo"]) : undefined,
    perDocData: data["perDocData"] !== undefined ? deserializePerDocData(data["perDocData"]) : undefined,
    porninfo: data["porninfo"] !== undefined ? deserializeClassifierPornDocumentData(data["porninfo"]) : undefined,
    properties: data["properties"] !== undefined ? deserializeDocProperties(data["properties"]) : undefined,
    qualitysignals: data["qualitysignals"] !== undefined ? deserializeCompositeDocQualitySignals(data["qualitysignals"]) : undefined,
    richcontentData: data["richcontentData"] !== undefined ? deserializeIndexingConverterRichContentData(data["richcontentData"]) : undefined,
    richsnippet: data["richsnippet"] !== undefined ? deserializeRichsnippetsPageMap(data["richsnippet"]) : undefined,
    robotsinfolist: data["robotsinfolist"] !== undefined ? deserializeCompositeDocRobotsInfoList(data["robotsinfolist"]) : undefined,
    sitemap: data["sitemap"] !== undefined ? deserializeSitemap(data["sitemap"]) : undefined,
    storageRowTimestampMicros: data["storageRowTimestampMicros"] !== undefined ? BigInt(data["storageRowTimestampMicros"]) : undefined,
    syntacticDate: data["syntacticDate"] !== undefined ? deserializeQualityTimebasedSyntacticDate(data["syntacticDate"]) : undefined,
    urldate: data["urldate"] !== undefined ? BigInt(data["urldate"]) : undefined,
  };
}

/**
 * Additional checksums of the document.
 */
export interface CompositeDocAdditionalChecksums {
  /**
   * Same as ContentChecksum96 but without transient boilerplate.
   */
  NoTransientChecksum96?: Uint8Array;
  /**
   * Deprecated. Use simhash_v2 and simhash_v2_significance instead.
   */
  SimHash?: bigint;
  SimHashIsTrusted?: boolean;
  /**
   * Simhash-v2 is generated by SimHashParseHandler, designed as a complete
   * replacement of simhash-v1 (a.k.a. the original simhash above) from
   * ApproxDupsParseHandler. Simhash-v2 uses a revised algorithm so that it is
   * expected to work better in most cases than simhash-v1. They coexist in
   * current transition period, then simhash-v1 will be retired.
   */
  simhashV2?: bigint;
  /**
   * Simhash-v2-significance is used to describe the confidence about the
   * corresponding simhash-v2 value. It is defined as the average absolute
   * difference from zero of all internal state components when finalizing a
   * simhash-v2 value in HashMultiSetDotCauchy. We used to compare the
   * significance against some pre-defined threshold (default: 20) to get a
   * boolean value "trusted_simhash_v2". However, it is possible that this field
   * is missing while "simhash_v2" is present, in such case (1) Use
   * "SimHashIsTrusted" instead if it is present, AND/OR (2) Assume "simhash_v2"
   * is trusted if its value is non-zero.
   */
  simhashV2Significance?: number;
}

function serializeCompositeDocAdditionalChecksums(data: any): CompositeDocAdditionalChecksums {
  return {
    ...data,
    NoTransientChecksum96: data["NoTransientChecksum96"] !== undefined ? encodeBase64(data["NoTransientChecksum96"]) : undefined,
    SimHash: data["SimHash"] !== undefined ? String(data["SimHash"]) : undefined,
    simhashV2: data["simhashV2"] !== undefined ? String(data["simhashV2"]) : undefined,
  };
}

function deserializeCompositeDocAdditionalChecksums(data: any): CompositeDocAdditionalChecksums {
  return {
    ...data,
    NoTransientChecksum96: data["NoTransientChecksum96"] !== undefined ? decodeBase64(data["NoTransientChecksum96"] as string) : undefined,
    SimHash: data["SimHash"] !== undefined ? BigInt(data["SimHash"]) : undefined,
    simhashV2: data["simhashV2"] !== undefined ? BigInt(data["simhashV2"]) : undefined,
  };
}

/**
 * Alternate names are some urls that we would like to associate with documents
 * in addition to canonicals. Sometimes we may want to serve these
 * alternatenames instead of canonicals. Alternames in CompositeDoc should come
 * from WebMirror pipeline.
 */
export interface CompositeDocAlternateName {
  /**
   * Fp96 of webmirror equivalence class as of last time this was exported.
   */
  ecnFp?: Uint8Array;
  Url?: string;
  /**
   * See webutil/urlencoding
   */
  UrlEncoding?: number;
}

function serializeCompositeDocAlternateName(data: any): CompositeDocAlternateName {
  return {
    ...data,
    ecnFp: data["ecnFp"] !== undefined ? encodeBase64(data["ecnFp"]) : undefined,
  };
}

function deserializeCompositeDocAlternateName(data: any): CompositeDocAlternateName {
  return {
    ...data,
    ecnFp: data["ecnFp"] !== undefined ? decodeBase64(data["ecnFp"] as string) : undefined,
  };
}

/**
 * The top non-forwarding dups of the canonical url.
 */
export interface CompositeDocExtraDup {
  /**
   * Fp96 of webmirror equivalence class as of last time this was exported.
   */
  ecnFp?: Uint8Array;
  /**
   * The url of the non-forwarding dup.
   */
  url?: string;
}

function serializeCompositeDocExtraDup(data: any): CompositeDocExtraDup {
  return {
    ...data,
    ecnFp: data["ecnFp"] !== undefined ? encodeBase64(data["ecnFp"]) : undefined,
  };
}

function deserializeCompositeDocExtraDup(data: any): CompositeDocExtraDup {
  return {
    ...data,
    ecnFp: data["ecnFp"] !== undefined ? decodeBase64(data["ecnFp"] as string) : undefined,
  };
}

/**
 * The top forwarding dups of the canonical url. (note: it may actually include
 * some dups that are NOT used for forwarding data but for making "info:"
 * complete)
 */
export interface CompositeDocForwardingDup {
  /**
   * The name of the url's webmirror equivalence class.
   */
  ecn?: Uint8Array;
  ecnFp?: Uint8Array;
  /**
   * The purpose(s) of the forwarding dup indicating if it is used for
   * forwarding signal/anchors generally, or only for forwarding some specific
   * signal (e.g. navboost), or for some other purposes (e.g., not for
   * forwarding any data but for making "info:" complete). See
   * indexing/dups/public/dups.h for more details.
   */
  purposes?: number;
  /**
   * Raw pagerank of the url.
   */
  rawPagerank?: number;
  /**
   * The webmirror repid of the forwarding dup.
   */
  repid?: Uint8Array;
  /**
   * The url of the forwarding dup.
   */
  url?: string;
  /**
   * The encoding of the url (see webutil/urlencoding for details).
   */
  urlencoding?: number;
}

function serializeCompositeDocForwardingDup(data: any): CompositeDocForwardingDup {
  return {
    ...data,
    ecn: data["ecn"] !== undefined ? encodeBase64(data["ecn"]) : undefined,
    ecnFp: data["ecnFp"] !== undefined ? encodeBase64(data["ecnFp"]) : undefined,
    repid: data["repid"] !== undefined ? encodeBase64(data["repid"]) : undefined,
  };
}

function deserializeCompositeDocForwardingDup(data: any): CompositeDocForwardingDup {
  return {
    ...data,
    ecn: data["ecn"] !== undefined ? decodeBase64(data["ecn"] as string) : undefined,
    ecnFp: data["ecnFp"] !== undefined ? decodeBase64(data["ecnFp"] as string) : undefined,
    repid: data["repid"] !== undefined ? decodeBase64(data["repid"] as string) : undefined,
  };
}

export interface CompositeDocIncludedContent {
  includedDoc?: GDocumentBase;
  linkUrl?: string;
  perDocData?: PerDocData;
  properties?: DocProperties;
  /**
   * Indicate how this content came to be included. Legal values are
   * constructed by bitwise-OR-ing values from the included_content::SourceType
   * enum. Default SourceTypeBitfield = included_content::INCLUDED_FRAME
   */
  SourceTypeBitfield?: bigint;
}

function serializeCompositeDocIncludedContent(data: any): CompositeDocIncludedContent {
  return {
    ...data,
    includedDoc: data["includedDoc"] !== undefined ? serializeGDocumentBase(data["includedDoc"]) : undefined,
    perDocData: data["perDocData"] !== undefined ? serializePerDocData(data["perDocData"]) : undefined,
    properties: data["properties"] !== undefined ? serializeDocProperties(data["properties"]) : undefined,
    SourceTypeBitfield: data["SourceTypeBitfield"] !== undefined ? String(data["SourceTypeBitfield"]) : undefined,
  };
}

function deserializeCompositeDocIncludedContent(data: any): CompositeDocIncludedContent {
  return {
    ...data,
    includedDoc: data["includedDoc"] !== undefined ? deserializeGDocumentBase(data["includedDoc"]) : undefined,
    perDocData: data["perDocData"] !== undefined ? deserializePerDocData(data["perDocData"]) : undefined,
    properties: data["properties"] !== undefined ? deserializeDocProperties(data["properties"]) : undefined,
    SourceTypeBitfield: data["SourceTypeBitfield"] !== undefined ? BigInt(data["SourceTypeBitfield"]) : undefined,
  };
}

/**
 * Contains information *mostly* used within indexing (e.g. not used for
 * building the production serving shards). Most of this data is generated only
 * in Alexandria, however there are exceptions.
 */
export interface CompositeDocIndexingInfo {
  /**
   * To hold extra info for building a final cdoc from raw cdoc and goldmine
   * annotations.
   */
  cdocBuildInfo?: IndexingDocjoinerCDocBuildInfo;
  /**
   * Whether current page is under content protection, i.e. a page has been
   * crawled as an error page, but we preserve its last known good content and
   * keep its crawl_status as converter.CrawlStatus::CONTENT.
   */
  contentProtected?: boolean;
  /**
   * If set, indicates that the crawl status was converted to ROBOTED for the
   * reason specified by the enum value in
   * converter.RobotedReasons.ConvertToRobotedReasons. See
   * indexing/converter/proto/converter.proto for details. If unset, then the
   * document was not converted to roboted, and if the document crawl status is
   * ROBOTED, then the document is disallowed (at least to Google) in
   * robots.txt.
   */
  convertToRobotedReason?: number;
  /**
   * One of the enum values in converter.CrawlStatus.State (see
   * indexing/converter/proto/converter.proto for details). Default is
   * converter.CrawlStatus::CONTENT. The document is roboted if the value is
   * converter.CrawlStatus::ROBOTED.
   */
  crawlStatus?: number;
  demotionTags?:  | "DEMOTION_TYPE_NONE" | "DEMOTION_TYPE_BADURLS_DEMOTE"[];
  /**
   * One of the enum values in converter.ErrorPageType (see
   * indexing/converter/proto/error-page-detector-enum.proto for detail).
   * Default is converter::ERROR_PAGE_NONE.
   */
  errorType?: number;
  freshdocsCorpora?:  | "WEB" | "REALTIME" | "CSE" | "CSE_PREMIUM" | "BUSTER_IMAGES" | "NEWS" | "VIDEO" | "YOUTUBE" | "WEB_INSTANT" | "WEB_DAILY" | "CACHE_COLON"[];
  /**
   * The host id of the document. Used chiefly to determine whether the
   * document is part of a parked domain.
   */
  hostid?: bigint;
  /**
   * A short descriptive string to help identify the IE application or setup
   * where this CDoc is generated. For example: websearch_m3 This field is for
   * debuggability purposes.
   */
  ieIdentifier?: string;
  /**
   * Indexing info about images (i.e. image links missing image data, etc).
   */
  imageIndexingInfo?: ImageSearchImageIndexingInfo;
  /**
   * The timestamp (the time since the Epoch, in microseconds) when the docjoin
   * is exported from indexing. The main purpose of this field is to identify
   * different versions of the same document.
   */
  indexingTs?: bigint;
  /**
   * Page is deleted when indexing choice flips between different corpora (e.g.
   * desktop, mobile, archive, scholar, etc.) for the same URL. It's only set
   * for deletion cdocs. Downstreams using URL as key should ignore the current
   * deletion if the field is set.
   */
  isSiblingDeletion?: boolean;
  /**
   * If set, the timestamp in microseconds when the URL stopped being
   * canonical. This should never be set for exported canonical documents. This
   * field is used by dups during canonical flip, and by webmain when doc
   * selection switched between desktop and mobile. Union respects this
   * timestamp to prevent old doc being deleted until the new doc is picked up
   */
  noLongerCanonicalTimestamp?: bigint;
  /**
   * This score is calculated by re-mapping the back onto the partition's score
   * distribution, such that the score represents the score of the equivalently
   * ranked organically-selected document.
   */
  normalizedClickScore?: number;
  /**
   * The raw navboost count for the canonical url without aggregating the
   * navboost from dup urls. This field is used when building forwarding map.
   */
  rawNavboost?: number;
  /**
   * The timestamp (the time since the Epoch, in microseconds) to represent doc
   * version, which is used in the downstream processing after Raffia. If it's
   * not set, indexing_ts will be used as row_timestamp. The timestamp is
   * generally set by reprocessing to set slightly newer indexing_ts such that
   * the system can respect the reprocessed version to overwrite old data in
   * storage.
   */
  rowTimestamp?: bigint;
  /**
   * Selection tier rank is a language normalized score ranging from 0-1 over
   * the serving tier (Base, Zeppelins, Landfills) for this document.
   */
  selectionTierRank?: number;
  /**
   * The tracing ids is to label the version of url for url status tracking.
   * This repeated field will carry at most 10 tracing id. See more details in
   * go/rich-tracing-design There will be less than 2% base+uz cdocs carrying
   * this field. The major sources of tracing ids include: * Indexing API pushed
   * urls * Index Metrics sampling urls The tracing ids will be written into
   * cdocs by Webmain Ramifier. The consumer of the tracing ids is Union serving
   * notification collector see more at go/serving-notification-from-union
   */
  tracingId?: string[];
  /**
   * Changerate information for this doc (see
   * crawler/changerate/changerate.proto for details).
   */
  urlChangerate?: CrawlerChangerateUrlChangerate;
  /**
   * Url change history for this doc (see crawler/changerate/changerate.proto
   * for details). Note if a doc has more than 20 changes, we only keep the last
   * 20 changes here to avoid adding to much data in its docjoin.
   */
  urlHistory?: CrawlerChangerateUrlHistory;
  /**
   * UrlPatternSignals for this doc, used to compute document score in LTG (see
   * indexing/signal_aggregator/proto/signal-aggregator.proto for details).
   */
  urlPatternSignals?: IndexingSignalAggregatorUrlPatternSignals;
  /**
   * Indexing info about videos.
   */
  videoIndexingInfo?: ImageRepositoryVideoIndexingInfo;
}

function serializeCompositeDocIndexingInfo(data: any): CompositeDocIndexingInfo {
  return {
    ...data,
    hostid: data["hostid"] !== undefined ? String(data["hostid"]) : undefined,
    indexingTs: data["indexingTs"] !== undefined ? String(data["indexingTs"]) : undefined,
    noLongerCanonicalTimestamp: data["noLongerCanonicalTimestamp"] !== undefined ? String(data["noLongerCanonicalTimestamp"]) : undefined,
    rowTimestamp: data["rowTimestamp"] !== undefined ? String(data["rowTimestamp"]) : undefined,
    urlHistory: data["urlHistory"] !== undefined ? serializeCrawlerChangerateUrlHistory(data["urlHistory"]) : undefined,
    urlPatternSignals: data["urlPatternSignals"] !== undefined ? serializeIndexingSignalAggregatorUrlPatternSignals(data["urlPatternSignals"]) : undefined,
  };
}

function deserializeCompositeDocIndexingInfo(data: any): CompositeDocIndexingInfo {
  return {
    ...data,
    hostid: data["hostid"] !== undefined ? BigInt(data["hostid"]) : undefined,
    indexingTs: data["indexingTs"] !== undefined ? BigInt(data["indexingTs"]) : undefined,
    noLongerCanonicalTimestamp: data["noLongerCanonicalTimestamp"] !== undefined ? BigInt(data["noLongerCanonicalTimestamp"]) : undefined,
    rowTimestamp: data["rowTimestamp"] !== undefined ? BigInt(data["rowTimestamp"]) : undefined,
    urlHistory: data["urlHistory"] !== undefined ? deserializeCrawlerChangerateUrlHistory(data["urlHistory"]) : undefined,
    urlPatternSignals: data["urlPatternSignals"] !== undefined ? deserializeIndexingSignalAggregatorUrlPatternSignals(data["urlPatternSignals"]) : undefined,
  };
}

/**
 * Contains information needed for end-to-end live experiments. For a cdoc
 * generated by production pipeline, it includes experiment IDs that have
 * selected current document. For a cdoc generated by experiment pipeline, it
 * includes current experiment ID.
 */
export interface CompositeDocLiveExperimentInfo {
  /**
   * List of necessary information for each live experiments.
   */
  perLiveExperimentInfo?: CompositeDocLiveExperimentInfoPerLiveExperimentInfo[];
}

function serializeCompositeDocLiveExperimentInfo(data: any): CompositeDocLiveExperimentInfo {
  return {
    ...data,
    perLiveExperimentInfo: data["perLiveExperimentInfo"] !== undefined ? data["perLiveExperimentInfo"].map((item: any) => (serializeCompositeDocLiveExperimentInfoPerLiveExperimentInfo(item))) : undefined,
  };
}

function deserializeCompositeDocLiveExperimentInfo(data: any): CompositeDocLiveExperimentInfo {
  return {
    ...data,
    perLiveExperimentInfo: data["perLiveExperimentInfo"] !== undefined ? data["perLiveExperimentInfo"].map((item: any) => (deserializeCompositeDocLiveExperimentInfoPerLiveExperimentInfo(item))) : undefined,
  };
}

/**
 * Contains information for a live experiment.
 */
export interface CompositeDocLiveExperimentInfoPerLiveExperimentInfo {
  /**
   * ID of a live experiment.
   */
  experimentId?: string;
  /**
   * Partial CDoc for a live experiment.
   */
  partialCdoc?: CompositeDoc;
}

function serializeCompositeDocLiveExperimentInfoPerLiveExperimentInfo(data: any): CompositeDocLiveExperimentInfoPerLiveExperimentInfo {
  return {
    ...data,
    partialCdoc: data["partialCdoc"] !== undefined ? serializeCompositeDoc(data["partialCdoc"]) : undefined,
  };
}

function deserializeCompositeDocLiveExperimentInfoPerLiveExperimentInfo(data: any): CompositeDocLiveExperimentInfoPerLiveExperimentInfo {
  return {
    ...data,
    partialCdoc: data["partialCdoc"] !== undefined ? deserializeCompositeDoc(data["partialCdoc"]) : undefined,
  };
}

export interface CompositeDocLocalizedVariations {
  /**
   * A subset of computed variations, only the members which are dups to the
   * main url. Used during serving for swapping in the URL based on regional and
   * language preferences of the user.
   */
  dupsComputedAlternateNames?: IndexingDupsComputedLocalizedAlternateNamesLocaleEntry[];
  /**
   * All localized alternate names provided by the webmaster (canonical and
   * dups, indexed and not-indexed). Used on the ranking side for swapping out
   * results based on the webmaster preference.
   */
  webmasterAlternateNames?: IndexingConverterLocalizedAlternateName[];
}

function serializeCompositeDocLocalizedVariations(data: any): CompositeDocLocalizedVariations {
  return {
    ...data,
    dupsComputedAlternateNames: data["dupsComputedAlternateNames"] !== undefined ? data["dupsComputedAlternateNames"].map((item: any) => (serializeIndexingDupsComputedLocalizedAlternateNamesLocaleEntry(item))) : undefined,
    webmasterAlternateNames: data["webmasterAlternateNames"] !== undefined ? data["webmasterAlternateNames"].map((item: any) => (serializeIndexingConverterLocalizedAlternateName(item))) : undefined,
  };
}

function deserializeCompositeDocLocalizedVariations(data: any): CompositeDocLocalizedVariations {
  return {
    ...data,
    dupsComputedAlternateNames: data["dupsComputedAlternateNames"] !== undefined ? data["dupsComputedAlternateNames"].map((item: any) => (deserializeIndexingDupsComputedLocalizedAlternateNamesLocaleEntry(item))) : undefined,
    webmasterAlternateNames: data["webmasterAlternateNames"] !== undefined ? data["webmasterAlternateNames"].map((item: any) => (deserializeIndexingConverterLocalizedAlternateName(item))) : undefined,
  };
}

/**
 * Contains information about the partial updates present in a partial
 * CompositeDoc.
 */
export interface CompositeDocPartialUpdateInfo {
  /**
   * List of goldmine annotator updates present in the enclosing partial cdoc.
   */
  goldmineAnnotatorNames?: string[];
  /**
   * List of images signal updates present in the enclosing partial cdoc.
   * Images signal name for a images signal is the unique name for the signal
   * according to SignalSpec.
   */
  imagesSignalNames?: string[];
  /**
   * Contains last full indexing information for partial updates.
   */
  lastFullIndexingInfo?: CompositeDocPartialUpdateInfoLastFullIndexingInfo[];
  /**
   * Which tier we should do cdoc lookup to merge partial cdocs. This uses the
   * integer value of indexing.selection.CorpusId. NOT intended for other usage.
   */
  shouldLookupDocjoinsTier?: number;
  /**
   * List of signal updates present in the enclosing partial cdoc. Signal name
   * for a signal is unique name for the signal according to SignalSpec.
   */
  signalNames?: string[];
}

function serializeCompositeDocPartialUpdateInfo(data: any): CompositeDocPartialUpdateInfo {
  return {
    ...data,
    lastFullIndexingInfo: data["lastFullIndexingInfo"] !== undefined ? data["lastFullIndexingInfo"].map((item: any) => (serializeCompositeDocPartialUpdateInfoLastFullIndexingInfo(item))) : undefined,
  };
}

function deserializeCompositeDocPartialUpdateInfo(data: any): CompositeDocPartialUpdateInfo {
  return {
    ...data,
    lastFullIndexingInfo: data["lastFullIndexingInfo"] !== undefined ? data["lastFullIndexingInfo"].map((item: any) => (deserializeCompositeDocPartialUpdateInfoLastFullIndexingInfo(item))) : undefined,
  };
}

/**
 * Last full indexing information for the partial CDoc.
 */
export interface CompositeDocPartialUpdateInfoLastFullIndexingInfo {
  /**
   * The corpus of last full updates.
   */
  corpus?:  | "RAFFIA_WEBSEARCH" | "RAFFIA_FASTPATH_DAILY" | "RAFFIA_FASTPATH_INSTANT";
  /**
   * Last full update indexing timestamp in microseconds.
   */
  lastFullIndexingTsMicros?: bigint;
}

function serializeCompositeDocPartialUpdateInfoLastFullIndexingInfo(data: any): CompositeDocPartialUpdateInfoLastFullIndexingInfo {
  return {
    ...data,
    lastFullIndexingTsMicros: data["lastFullIndexingTsMicros"] !== undefined ? String(data["lastFullIndexingTsMicros"]) : undefined,
  };
}

function deserializeCompositeDocPartialUpdateInfoLastFullIndexingInfo(data: any): CompositeDocPartialUpdateInfoLastFullIndexingInfo {
  return {
    ...data,
    lastFullIndexingTsMicros: data["lastFullIndexingTsMicros"] !== undefined ? BigInt(data["lastFullIndexingTsMicros"]) : undefined,
  };
}

/**
 * Note: This is a misleading name as of 2022/10/14. The field is still set and
 * has meaningful data, but no longer holds quality signals. All the data are
 * freshness-related and they're not particularly sensitive.
 */
export interface CompositeDocQualitySignals {
  /**
   * Contains a date used for the "Date Last Modified" toolbelt restrict mode.
   * Note: this date is a combined date and is different from the pure
   * shingle-based signal stored in contentage.last_significant_update field.
   */
  lastSignificantUpdate?: QualityTimebasedLastSignificantUpdate;
  pagetype?: QualityTimebasedPageType;
}

function serializeCompositeDocQualitySignals(data: any): CompositeDocQualitySignals {
  return {
    ...data,
    lastSignificantUpdate: data["lastSignificantUpdate"] !== undefined ? serializeQualityTimebasedLastSignificantUpdate(data["lastSignificantUpdate"]) : undefined,
  };
}

function deserializeCompositeDocQualitySignals(data: any): CompositeDocQualitySignals {
  return {
    ...data,
    lastSignificantUpdate: data["lastSignificantUpdate"] !== undefined ? deserializeQualityTimebasedLastSignificantUpdate(data["lastSignificantUpdate"]) : undefined,
  };
}

/**
 * List of robots info parsed for the user-agents other than the default used
 * to crawl this page.
 */
export interface CompositeDocRobotsInfoList {
  newsRobotsInfo?: IndexingConverterRobotsInfo;
}

function serializeCompositeDocRobotsInfoList(data: any): CompositeDocRobotsInfoList {
  return {
    ...data,
    newsRobotsInfo: data["newsRobotsInfo"] !== undefined ? serializeIndexingConverterRobotsInfo(data["newsRobotsInfo"]) : undefined,
  };
}

function deserializeCompositeDocRobotsInfoList(data: any): CompositeDocRobotsInfoList {
  return {
    ...data,
    newsRobotsInfo: data["newsRobotsInfo"] !== undefined ? deserializeIndexingConverterRobotsInfo(data["newsRobotsInfo"]) : undefined,
  };
}

/**
 * A message containing per doc signals that are compressed and included in
 * Mustang and TeraGoogle. For TeraGoogle, this message is included in
 * perdocdata which means it can be used in preliminary scoring. CAREFUL: For
 * TeraGoogle, this data resides in very limited serving memory (Flash storage)
 * for a huge number of documents. Next id: 42
 */
export interface CompressedQualitySignals {
  /**
   * anchor_mismatch_demotion: converted from QualityBoost.mismatched.boost.
   */
  anchorMismatchDemotion?: number;
  /**
   * authority promotion: converted from QualityBoost.authority.boost
   */
  authorityPromotion?: number;
  /**
   * baby_panda_demotion: converted from QualityBoost.rendered.boost.
   */
  babyPandaDemotion?: number;
  /**
   * New BabyPanda demotion, applied on top of Panda. This is meant to replace
   * |baby_panda_demotion|.
   */
  babyPandaV2Demotion?: number;
  /**
   * Impressions, unsquashed, host level, not to be used with compressed
   * ratios. Not to be used in Pattern Data.
   */
  crapsAbsoluteHostSignals?: number;
  crapsNewHostSignals?: bigint;
  crapsNewPatternSignals?: bigint;
  /**
   * For craps_[url|pattern]_signals, please avoid accessing these fields
   * directly, even in minor ways like checking has_craps_*. Instead, please use
   * methods from quality/navboost/craps/craps-lossy-compression.h or talk to
   * dice-team.
   */
  crapsNewUrlSignals?: bigint;
  crapsUnscaledIpPriorBadFraction?: number;
  /**
   * Page quality signals converted from fields in proto QualityBoost in
   * quality/q2/proto/quality-boost.proto. To save indexing space, we convert
   * the float values in [0, 1] to integers in range [0, 1023] (use 10 bits).
   * exact_match_domain_demotion: converted from QualityBoost.emd.boost.
   */
  exactMatchDomainDemotion?: number;
  /**
   * This field is *not* propagated to shards, but it's populated at serving
   * time by go/web-signal-joins (see b/207344056). See go/0DayLEs for details.
   * This is only meant to be used during LEs, it should *not* be used for
   * launches.
   */
  experimentalNsrTeamData?: QualityNsrExperimentalNsrTeamData;
  /**
   * This field is *not* propagated to shards, but it's populated at serving
   * time by go/web-signal-joins (see b/207344056). See go/0DayLEs for details.
   * This is only meant to be used during LEs, it should *not* be used for
   * launches.
   */
  experimentalNsrTeamWsjData?: QualityNsrExperimentalNsrTeamWSJData[];
  /**
   * This field is *not* propagated to shards. It is meant to be populated at
   * serving time using one of the versions present in the
   * `experimental_nsr_team_wsj_data` field above (using the
   * `ExperimentalNsrTeamDataOverridesParams` opti to populate it; see
   * http://source/search?q=ExperimentalNsrTeamDataOverridesParams%20file:ascorer.proto).
   * The purpose of this field is to be read by an experimental Q* component, in
   * order to quickly run LEs with new delta components. See go/0DayLEs for
   * details.
   */
  experimentalQstarDeltaSignal?: number;
  /**
   * This field is *not* propagated to shards. It is meant to be populated at
   * serving time using one of the versions present in the
   * `experimental_nsr_team_wsj_data` field above (using the
   * `ExperimentalNsrTeamDataOverridesParams` opti to populate it; see
   * http://source/search?q=ExperimentalNsrTeamDataOverridesParams%20file:ascorer.proto).
   * The purpose of this field is to be read by an experimental Q* component, in
   * order to quickly run LEs with new components. See go/0DayLEs for details.
   */
  experimentalQstarSignal?: number;
  /**
   * This field is *not* propagated to shards. It is meant to be populated at
   * serving time using one of the versions present in the
   * `experimental_nsr_team_wsj_data` field above (using the
   * `ExperimentalNsrTeamDataOverridesParams` opti to populate it; see
   * http://source/search?q=ExperimentalNsrTeamDataOverridesParams%20file:ascorer.proto).
   * The purpose of this field is to be read by an experimental Q* component, in
   * order to quickly run LEs with new site components. See go/0DayLEs for
   * details.
   */
  experimentalQstarSiteSignal?: number;
  /**
   * S2V low quality score: converted from quality_nsr.NsrData, applied in
   * Qstar. See quality_nsr::util::ConvertNsrDataToLowQuality.
   */
  lowQuality?: number;
  /**
   * nav_demotion: converted from QualityBoost.nav_demoted.boost.
   */
  navDemotion?: number;
  /**
   * NSR confidence score: converted from quality_nsr.NsrData.
   */
  nsrConfidence?: number;
  /**
   * NSR override bid, used in Q* for emergency overrides.
   */
  nsrOverrideBid?: number;
  /**
   * Versioned NSR score to be used in continuous evaluation of the upcoming
   * NSR version and assess quality impact on various slices.
   */
  nsrVersionedData?: NSRVersionedItem[];
  /**
   * PairwiseQ data for QTJ. This field is *not* propagated to shards, but is
   * populated at serving time by go/web-signal-joins. See b/175762140
   */
  pairwiseqScoringData?: PairwiseQScoringData;
  /**
   * Versioned PairwiseQ score to be used in continuous evaluation of the
   * upcoming PairwiseQ versions and assess quality impact on various slices.
   */
  pairwiseqVersionedData?: PairwiseQVersionedItem[];
  /**
   * This is the encoding of Panda fields in the proto SiteQualityFeatures in
   * quality/q2/proto/site_quality_features.proto. The encoding/decoding is
   * performed using functions from quality_coati::coati_util.
   */
  pandaDemotion?: number;
  /**
   * Encoded page-level PQ signals.
   */
  pqData?: number;
  /**
   * Stripped page-level signals, not present in the encoded field 'pq_data'.
   */
  pqDataProto?: QualityNsrPQData;
  productReviewPDemotePage?: number;
  /**
   * Product review demotion/promotion confidences. (Times 1000 and floored)
   */
  productReviewPDemoteSite?: number;
  productReviewPPromotePage?: number;
  productReviewPPromoteSite?: number;
  /**
   * Fields product_review_p_review_page and product_review_p_uhq_page are for
   * promoting/demoting HQ/LQ review pages in NGS. See go/pr-boosts for details.
   * The possibility of a page being a review page.
   */
  productReviewPReviewPage?: number;
  /**
   * The possibility of a page being a high quality review page.
   */
  productReviewPUhqPage?: number;
  /**
   * Scam model score. Used as one of the web page quality qstar signals. Value
   * range from 0 to 1023.
   */
  scamness?: number;
  /**
   * serp demotion: applied in Qstar.
   */
  serpDemotion?: number;
  /**
   * site_authority: converted from quality_nsr.SiteAuthority, applied in
   * Qstar.
   */
  siteAuthority?: number;
  /**
   * Versioned TopicEmbeddings data to be populated later into superroot / used
   * directly in scorers.
   */
  topicEmbeddingsVersionedData?: QualityAuthorityTopicEmbeddingsVersionedItem[];
  /**
   * Unauthoritative score. Used as one of the web page quality qstar signals.
   */
  unauthoritativeScore?: number;
  /**
   * NSR for low-quality videos, converted from quality_nsr.NsrData.vlq_nsr.
   */
  vlqNsr?: number;
}

function serializeCompressedQualitySignals(data: any): CompressedQualitySignals {
  return {
    ...data,
    crapsNewHostSignals: data["crapsNewHostSignals"] !== undefined ? String(data["crapsNewHostSignals"]) : undefined,
    crapsNewPatternSignals: data["crapsNewPatternSignals"] !== undefined ? String(data["crapsNewPatternSignals"]) : undefined,
    crapsNewUrlSignals: data["crapsNewUrlSignals"] !== undefined ? String(data["crapsNewUrlSignals"]) : undefined,
    topicEmbeddingsVersionedData: data["topicEmbeddingsVersionedData"] !== undefined ? data["topicEmbeddingsVersionedData"].map((item: any) => (serializeQualityAuthorityTopicEmbeddingsVersionedItem(item))) : undefined,
  };
}

function deserializeCompressedQualitySignals(data: any): CompressedQualitySignals {
  return {
    ...data,
    crapsNewHostSignals: data["crapsNewHostSignals"] !== undefined ? BigInt(data["crapsNewHostSignals"]) : undefined,
    crapsNewPatternSignals: data["crapsNewPatternSignals"] !== undefined ? BigInt(data["crapsNewPatternSignals"]) : undefined,
    crapsNewUrlSignals: data["crapsNewUrlSignals"] !== undefined ? BigInt(data["crapsNewUrlSignals"]) : undefined,
    topicEmbeddingsVersionedData: data["topicEmbeddingsVersionedData"] !== undefined ? data["topicEmbeddingsVersionedData"].map((item: any) => (deserializeQualityAuthorityTopicEmbeddingsVersionedItem(item))) : undefined,
  };
}

/**
 * The following protobuf is used to store an attribution from one page to
 * (usually) one other page, giving credit for the content. This information is
 * used during ranking to promote the attributed page. This protobuf is copied
 * from a quality_contra::SelectedAttribution. See
 * //quality/contra/authorship/attribution and
 * https://qwiki.corp.google.com/display/Q/ContentTrackingContentAttribution.
 */
export interface ContentAttributions {
  /**
   * Selected outgoing attributions extracted on FreshDocs.
   */
  freshdocsOutgoing?: ContentAttributionsOutgoingAttribution[];
  /**
   * Selected outgoing attributions extracted via offline MR jobs.
   */
  offlineOutgoing?: ContentAttributionsOutgoingAttribution[];
  /**
   * Selected outgoing attributions extracted online on Alexandria.
   */
  onlineOutgoing?: ContentAttributionsOutgoingAttribution[];
}

function serializeContentAttributions(data: any): ContentAttributions {
  return {
    ...data,
    freshdocsOutgoing: data["freshdocsOutgoing"] !== undefined ? data["freshdocsOutgoing"].map((item: any) => (serializeContentAttributionsOutgoingAttribution(item))) : undefined,
    offlineOutgoing: data["offlineOutgoing"] !== undefined ? data["offlineOutgoing"].map((item: any) => (serializeContentAttributionsOutgoingAttribution(item))) : undefined,
    onlineOutgoing: data["onlineOutgoing"] !== undefined ? data["onlineOutgoing"].map((item: any) => (serializeContentAttributionsOutgoingAttribution(item))) : undefined,
  };
}

function deserializeContentAttributions(data: any): ContentAttributions {
  return {
    ...data,
    freshdocsOutgoing: data["freshdocsOutgoing"] !== undefined ? data["freshdocsOutgoing"].map((item: any) => (deserializeContentAttributionsOutgoingAttribution(item))) : undefined,
    offlineOutgoing: data["offlineOutgoing"] !== undefined ? data["offlineOutgoing"].map((item: any) => (deserializeContentAttributionsOutgoingAttribution(item))) : undefined,
    onlineOutgoing: data["onlineOutgoing"] !== undefined ? data["onlineOutgoing"].map((item: any) => (deserializeContentAttributionsOutgoingAttribution(item))) : undefined,
  };
}

/**
 * This is a copy of quality_contra::SelectedAttribution::SelectedInfo. The url
 * is converted to docid and other fields are copied directly.
 */
export interface ContentAttributionsOutgoingAttribution {
  bestEvidenceType?:  | "PAGE_LINK_TO" | "SITE_LINK_TO" | "SITE_OTHER_PAGE_LINK_TO" | "ORG_OTHER_SITE_LINK_TO" | "ORG_OTHER_PAGE_LINK_TO" | "SITE_SCORE_BASED" | "LOW_CONFIDENCE_LINK_TO" | "ANCHOR_ATTRIBUTION_TO" | "SITE_NAME_MENTION" | "SITE_NAME_MENTION_KEYWORDED" | "EVIDENCE_TYPE_END";
  docid?: bigint;
  properties?: number;
  usableForClustering?: boolean;
}

function serializeContentAttributionsOutgoingAttribution(data: any): ContentAttributionsOutgoingAttribution {
  return {
    ...data,
    docid: data["docid"] !== undefined ? String(data["docid"]) : undefined,
  };
}

function deserializeContentAttributionsOutgoingAttribution(data: any): ContentAttributionsOutgoingAttribution {
  return {
    ...data,
    docid: data["docid"] !== undefined ? BigInt(data["docid"]) : undefined,
  };
}

export interface ContentAwareCropsIndexing {
  /**
   * Compact representation for Mustang storage. See
   * image/search/utils/packed_crops.h for details on the packing format.
   */
  mustangBytes?: Uint8Array;
  mustangBytesVersion?: number;
}

function serializeContentAwareCropsIndexing(data: any): ContentAwareCropsIndexing {
  return {
    ...data,
    mustangBytes: data["mustangBytes"] !== undefined ? encodeBase64(data["mustangBytes"]) : undefined,
  };
}

function deserializeContentAwareCropsIndexing(data: any): ContentAwareCropsIndexing {
  return {
    ...data,
    mustangBytes: data["mustangBytes"] !== undefined ? decodeBase64(data["mustangBytes"] as string) : undefined,
  };
}

/**
 * Contains lexical metadata for a given reference. For example, this proto
 * will be used to store locale-specific Lexical mids for contact relationships
 * (e.g. /g/11gv0vypg4 is the mid for mother in english and /g/11gmy_gv87 is for
 * mother in french) as an extension to QRefAnnotation::other_metadata, when
 * available.
 */
export interface CopleyLexicalMetadata {
  /**
   * Mid for an entity that has lexical data (a LexiconEntry). See
   * https://g3doc.corp.google.com/nlp/generation/g3doc/lexical_data.md for for
   * more information about lexical data. This is the canonical mid for this
   * entity (eg. it would be for "mother" in EN even if user referred to "mom").
   */
  canonicalLexicalMid?: string;
}

/**
 * Represents a reference made by a user that refers to some personal entity.
 */
export interface CopleyPersonalReference {
  /**
   * The manner in which the entity was referenced (e.g. "my hotel", "the
   * airport").
   */
  personalReferenceType?:  | "PERSONAL_UNKNOWN_REFERENCE" | "PERSONAL_HOTEL_REFERENCE" | "PERSONAL_HOTEL_BOOKING_AGENT_REFERENCE" | "PERSONAL_RESTAURANT_REFERENCE" | "PERSONAL_RESTAURANT_BOOKING_AGENT_REFERENCE" | "PERSONAL_PARKING_REFERENCE" | "PERSONAL_FLIGHT_REFERENCE" | "PERSONAL_GENERIC_SOCIAL_EVENT_REFERENCE" | "PERSONAL_CONCERT_REFERENCE" | "PERSONAL_SPORTS_REFERENCE" | "PERSONAL_MOVIE_REFERENCE" | "PERSONAL_TOUR_REFERENCE" | "PERSONAL_HOME_REFERENCE" | "PERSONAL_WORK_REFERENCE" | "PERSONAL_MAPS_ALIAS_REFERENCE" | "PERSONAL_CONTACT_REFERENCE" | "PERSONAL_CONTACT_PERSON_REFERENCE" | "PERSONAL_CONTACT_LOCATION_REFERENCE" | "PERSONAL_FAMILY_MEMBER_REFERENCE" | "PERSONAL_CONTACT_BIRTHDAY_REFERENCE" | "PERSONAL_CONTACT_ADDRESS_REFERENCE" | "PERSONAL_RELATIONSHIP_REFERENCE" | "PERSONAL_RELATIONSHIP_PERSON_REFERENCE" | "PERSONAL_RELATIONSHIP_LOCATION_REFERENCE" | "PERSONAL_MEMORABLE_DATE_REFERENCE" | "PERSONAL_MEMORY_ANNIVERSARY_DATE_REFERENCE" | "PERSONAL_MEMORY_PAYDAY_DATE_REFERENCE" | "PERSONAL_MEMORY_WEDDING_DATE_REFERENCE" | "PERSONAL_MEMORY_BIRTHDAY_DATE_REFERENCE" | "PERSONAL_MEMORY_EXAM_DATE_REFERENCE" | "PERSONAL_MEMORY_MATHEXAM_DATE_REFERENCE" | "PERSONAL_MEMORY_OILCHANGE_DATE_REFERENCE" | "PERSONAL_MEMORY_GRADUATION_DATE_REFERENCE";
}

/**
 * General message used to store metadata about references to personal
 * entities, even if those entities cannot be resolved.
 */
export interface CopleyPersonalReferenceMetadata {
  /**
   * A list of all references made. Empty if no personal references exist.
   * Multiple references can be present when multiple references were made in a
   * single query, or the type of reference was ambiguous.
   */
  references?: CopleyPersonalReference[];
  /**
   * The strength of the personal reference. For example "my flight" may
   * receive a high reference_score, whereas "the airport" may receive a low
   * score.
   */
  referenceScore?: number;
  /**
   * Subreference metadata for all compound references on this span.
   */
  subreferenceMetadata?: CopleySubreferenceMetadata;
}

export interface CopleySourceTypeList {
  sourceTypeMetadata?: CopleySourceTypeMetadata[];
}

function serializeCopleySourceTypeList(data: any): CopleySourceTypeList {
  return {
    ...data,
    sourceTypeMetadata: data["sourceTypeMetadata"] !== undefined ? data["sourceTypeMetadata"].map((item: any) => (serializeCopleySourceTypeMetadata(item))) : undefined,
  };
}

function deserializeCopleySourceTypeList(data: any): CopleySourceTypeList {
  return {
    ...data,
    sourceTypeMetadata: data["sourceTypeMetadata"] !== undefined ? data["sourceTypeMetadata"].map((item: any) => (deserializeCopleySourceTypeMetadata(item))) : undefined,
  };
}

/**
 * Contains the source and type information related to a personal entity, for
 * example if it's an hotel or a restaurant (type) and if it comes from gmail,
 * calendar, etc. (source). Next ID: 13
 */
export interface CopleySourceTypeMetadata {
  /**
   * Annotation ID of a contact annotation, e.g. a relationship set via
   * Assistant. This ID is generated by People Write Server. It is used to
   * delete Contact Annotations via People API.
   */
  contactAnnotationId?: string;
  displayableName?: string;
  /**
   * Only used if personal_data_provenance == PERSONAL_SOURCE_GMAIL. Used to
   * create a link to the source email in the form:
   * mail.google.com/mail/u/0/?extsrc=sync&client=h&plid={email_identifier}
   */
  emailIdentifier?: string;
  /**
   * Populated for some footprints data sources; uniquely identifies the
   * footprint that generated the personal data that this provenance is attached
   * to.
   */
  eventId?: EventIdMessage;
  localDiscoverySettingsMetadata?: PersonalizationSettingsApiProtoLocalDiscoveryLocalDiscoverySettingsMetadata;
  personalDataProvenance?:  | "PERSONAL_SOURCE_UNKNOWN" | "PERSONAL_SOURCE_GMAIL" | "PERSONAL_SOURCE_CALENDAR" | "PERSONAL_SOURCE_MAPS_ALIAS" | "PERSONAL_SOURCE_FOCUS" | "PERSONAL_SOURCE_FOCUS_CONSISTENT" | "PERSONAL_SOURCE_FOCUS_TOP_N_CONTACTS" | "PERSONAL_SOURCE_ASSISTANT_CONTACT_AFFINITY" | "PERSONAL_SOURCE_ASSISTANT_MEMORY" | "PERSONAL_SOURCE_PWS" | "PERSONAL_SOURCE_HOUSEHOLD" | "PERSONAL_SOURCE_HULK_PLACES" | "PERSONAL_SOURCE_FOCUS_OWNER" | "PERSONAL_SOURCE_WHITEPAGES" | "PERSONAL_SOURCE_ASSISTANT_DEVICES" | "PERSONAL_SOURCE_TEACH_LEARN" | "PERSONAL_SOURCE_GELLER_ANSWERS" | "PERSONAL_SOURCE_LAMS_SETTINGS" | "PERSONAL_SOURCE_GAIA" | "PERSONAL_SOURCE_XTALK" | "PERSONAL_SOURCE_MOVIE_DIALOG" | "PERSONAL_SOURCE_MEDIA_HABITUAL_CACHE" | "PERSONAL_SOURCE_PERSONAL_TOPICSERVER" | "PERSONAL_SOURCE_PHOTO_LABELS" | "PERSONAL_SOURCE_PEOPLE_API" | "PERSONAL_SOURCE_CONTEXT_API" | "PERSONAL_SOURCE_MUSIC_PREFERRED_PROVIDER" | "PERSONAL_SOURCE_STASH" | "PERSONAL_SOURCE_SMART_HOME_DEVICES" | "PERSONAL_SOURCE_DEVICE_STATES" | "PERSONAL_SOURCE_HANDBAG_PERSONALIZED_WEBREF_ENTITIES" | "PERSONAL_GRAPH_PEOPLE_SIGNAL_POST_PROCESSING" | "PERSONAL_SOURCE_PERSONALIZED_PRONUNCIATIONS" | "PERSONAL_SOURCE_DEVICE_INSTALLED_APPS" | "PERSONAL_SOURCE_CONTACT_AGGREGATED_DATA" | "PERSONAL_SOURCE_DYNAMIC_ENTITY_INDEX" | "PERSONAL_SOURCE_STADIA" | "PERSONAL_SOURCE_COMMUNAL_GROUP" | "PERSONAL_SOURCE_LOCATION_SHARING" | "PERSONAL_SOURCE_MAPS_SEARCH" | "PERSONAL_SOURCE_MEDIA_USER_CONTEXT_INFO" | "PERSONAL_SOURCE_MEDIA_USER_ENTITIES" | "PERSONAL_SOURCE_DEVICE_SIGNED_IN_ACCOUNTS" | "PERSONAL_SOURCE_ASSISTANT_USER_PROFILES";
  personalDataType?:  | "PERSONAL_UNKNOWN" | "PERSONAL_HOTEL" | "PERSONAL_RESTAURANT" | "PERSONAL_PARKING" | "PERSONAL_FLIGHT" | "PERSONAL_SOCIAL_EVENT" | "PERSONAL_MAPS_ALIAS" | "PERSONAL_CONTACT" | "PERSONAL_PROFILE" | "PERSONAL_BILL" | "PERSONAL_CAR_RENTAL" | "PERSONAL_GENERIC_EVENT" | "PERSONAL_TRAIN" | "PERSONAL_BUS" | "PERSONAL_TAXI" | "PERSONAL_FERRY" | "PERSONAL_PHONE_NUMBER" | "PERSONAL_DEVICE" | "PERSONAL_PREFERENCE" | "PERSONAL_DIETARY_RESTRICTION" | "PERSONAL_MEDIA_HABITUAL_CACHE" | "PERSONAL_NEWS_PREFERENCE" | "PERSONAL_FAVORITE" | "PERSONAL_GAMER_CONTACT";
  provenanceCategory?:  | "PROVENANCE_CATEGORY_UNKNOWN" | "CORE_APPS_DATA"[];
  /**
   * Sensitivity applying to this copley annotation.
   */
  sensitivity?: KnowledgeAnswersSensitivitySensitivity;
}

function serializeCopleySourceTypeMetadata(data: any): CopleySourceTypeMetadata {
  return {
    ...data,
    eventId: data["eventId"] !== undefined ? serializeEventIdMessage(data["eventId"]) : undefined,
    sensitivity: data["sensitivity"] !== undefined ? serializeKnowledgeAnswersSensitivitySensitivity(data["sensitivity"]) : undefined,
  };
}

function deserializeCopleySourceTypeMetadata(data: any): CopleySourceTypeMetadata {
  return {
    ...data,
    eventId: data["eventId"] !== undefined ? deserializeEventIdMessage(data["eventId"]) : undefined,
    sensitivity: data["sensitivity"] !== undefined ? deserializeKnowledgeAnswersSensitivitySensitivity(data["sensitivity"]) : undefined,
  };
}

/**
 * Represents the most compound resolved entities and most nested unresolved
 * references for a span. Useful for punting.
 */
export interface CopleySubreferenceMetadata {
  /**
   * Resolved entities are sorted from highest resolution score to lowest.
   */
  mostCompoundResolvedEntities?: CopleySubreferenceResolution[];
  /**
   * This is a merged representation of the compound reference having the
   * most_compound_resolved_entities as an argument.
   */
  mostNestedUnresolvedReference?: CopleySubreferenceReference;
}

/**
 * Represents a reference that may be part of a larger compound reference. For
 * example, "my brother's birthday" will have a subreference that may have
 * references for "my brother".
 */
export interface CopleySubreferenceReference {
  /**
   * Type of reference. There may be multiple for a single reference (e.g.
   * relationship and contact).
   */
  personalReferenceTypes?:  | "PERSONAL_UNKNOWN_REFERENCE" | "PERSONAL_HOTEL_REFERENCE" | "PERSONAL_HOTEL_BOOKING_AGENT_REFERENCE" | "PERSONAL_RESTAURANT_REFERENCE" | "PERSONAL_RESTAURANT_BOOKING_AGENT_REFERENCE" | "PERSONAL_PARKING_REFERENCE" | "PERSONAL_FLIGHT_REFERENCE" | "PERSONAL_GENERIC_SOCIAL_EVENT_REFERENCE" | "PERSONAL_CONCERT_REFERENCE" | "PERSONAL_SPORTS_REFERENCE" | "PERSONAL_MOVIE_REFERENCE" | "PERSONAL_TOUR_REFERENCE" | "PERSONAL_HOME_REFERENCE" | "PERSONAL_WORK_REFERENCE" | "PERSONAL_MAPS_ALIAS_REFERENCE" | "PERSONAL_CONTACT_REFERENCE" | "PERSONAL_CONTACT_PERSON_REFERENCE" | "PERSONAL_CONTACT_LOCATION_REFERENCE" | "PERSONAL_FAMILY_MEMBER_REFERENCE" | "PERSONAL_CONTACT_BIRTHDAY_REFERENCE" | "PERSONAL_CONTACT_ADDRESS_REFERENCE" | "PERSONAL_RELATIONSHIP_REFERENCE" | "PERSONAL_RELATIONSHIP_PERSON_REFERENCE" | "PERSONAL_RELATIONSHIP_LOCATION_REFERENCE" | "PERSONAL_MEMORABLE_DATE_REFERENCE" | "PERSONAL_MEMORY_ANNIVERSARY_DATE_REFERENCE" | "PERSONAL_MEMORY_PAYDAY_DATE_REFERENCE" | "PERSONAL_MEMORY_WEDDING_DATE_REFERENCE" | "PERSONAL_MEMORY_BIRTHDAY_DATE_REFERENCE" | "PERSONAL_MEMORY_EXAM_DATE_REFERENCE" | "PERSONAL_MEMORY_MATHEXAM_DATE_REFERENCE" | "PERSONAL_MEMORY_OILCHANGE_DATE_REFERENCE" | "PERSONAL_MEMORY_GRADUATION_DATE_REFERENCE"[];
  /**
   * Highest reference score for any references merged in this span.
   */
  referenceScore?: number;
  /**
   * Only set for unresolved relationship references and can be used to get the
   * canonical word for the relationship (e.g. "mother") in TTS.
   */
  relationshipLexicalInfo?: CopleyLexicalMetadata;
}

/**
 * Represents a resolution that may be part of a larger compound reference. For
 * example, "my brother's birthday" will have a subreference that may have
 * resolutions for "my brother".
 */
export interface CopleySubreferenceResolution {
  /**
   * Can be used with PKG Service for looking up metadata about this entity at
   * fulfillment/GenX time.
   */
  mid?: string;
  /**
   * Name of the entity represented by this resolution.
   */
  name?: string;
  /**
   * A resolution score of 0 indicates that it did not resolve to a real
   * entity.
   */
  resolutionScore?: number;
}

export interface CorpusSelectionInfo {
  corpus?:  | "UNKNOWN" | "LENS";
  /**
   * Corpus specific score for an image
   */
  corpusScore?: number;
  /**
   * Whether an image was selected for indexing.
   */
  isSelectedForIndexing?: boolean;
  /**
   * Set of referrers indexed with the image.
   */
  referrerDocid?: bigint[];
  /**
   * Set of referrer urls indexed with the image.
   */
  referrerUrls?: string[];
}

function serializeCorpusSelectionInfo(data: any): CorpusSelectionInfo {
  return {
    ...data,
    referrerDocid: data["referrerDocid"] !== undefined ? data["referrerDocid"].map((item: any) => (String(item))) : undefined,
  };
}

function deserializeCorpusSelectionInfo(data: any): CorpusSelectionInfo {
  return {
    ...data,
    referrerDocid: data["referrerDocid"] !== undefined ? data["referrerDocid"].map((item: any) => (BigInt(item))) : undefined,
  };
}

export interface CountryClickDistribution {
  /**
   * To store confidence in the distribution in cases when total is not set.
   */
  confidence?: number;
  item?: CountryClickDistributionItem[];
  /**
   * To store total clicks on this page/domain.
   */
  total?: number;
}

export interface CountryClickDistributionItem {
  doubleValue?: number;
  name?: string;
  value?: number;
}

/**
 * If you add new fields to this message, do not use any tag value less than
 * the "Next free tag" below. The lower tag values might be missing in this
 * file, but they were used in past for some field, so cannot be used again.
 * Next free tag: 44
 */
export interface CountryCountryAttachment {
  /**
   * Store weighted click distribution for page level country-id
   * classification.
   */
  clickDistribution?: CountryClickDistribution;
  /**
   * Is true if the country attachment was computed through the UGC pipeline.
   */
  countryidFromUgc?: boolean;
  /**
   * A non critical field to store debug info for a country attachment. Used in
   * experiments and for debugging.
   */
  debug?: string;
  /**
   * Set to the signal source URLs when merging country signals in Alexandria
   * during sitemoves. Essentially if sites A and B move to C, and we merge A
   * and B's signal to C, in the countryattachment signal C will have URL A and
   * B as source_url. Only used for debugging and it doesn't show up in
   * docjoins.
   */
  debugSourceUrl?: string[];
  /**
   * Specifies the origin of `geo_locations`. Right now, it can either come
   * from deprecated Docloc system or the new Brainloc system when Docloc
   * doesn't have sufficient evidence.
   */
  documentLocationSource?:  | "UNSPECIFIED" | "DOCLOC" | "BRAINLOC" | "LOGLOC";
  existNextLevel?: boolean;
  /**
   * Booleans to keep track of where the country-id of the page came from.
   * These are used for debugging and/or unittests, and cleared in production.
   */
  fromLanguageFallback?: boolean;
  fromRestricts?: boolean;
  fromSgDomains?: boolean;
  fromTld?: boolean;
  fromUgc?: boolean;
  fromUrlPattern?: boolean;
  fromWmx?: boolean;
  /**
   * New MetroID: Now called GeoLocations since the locations could be
   * sublocalities, cities or states. GeoLocations are always more fine grained
   * than country. TODO (jayeshv): Once new MetroID/GeoLocations is launched
   * everywhere, deleted old MetroID related fields.
   */
  geoLocations?: CountryGeoLocations;
  global?: boolean;
  /**
   * Set to true if the local_countries field can be used for country restricts
   * as well.
   */
  isValidForCountryRestrict?: boolean;
  /**
   * two-letter(lower-case) countrycode, e.g. us countries that is local to
   */
  localCountries?: string[];
  /**
   * Fields that actually store the country id in docjoins. The format of this
   * data is defined in //i18n/identifiers/stableinternalregionconverter.cc.
   * Converter defined there can be used to convert it to RegionCode format.
   */
  localCountryCodes?: number[];
  /**
   * Metro locations: list of NavBoost feature V2 associated with a doc, along
   * with the enclosing province. Metro locations with new tags.
   */
  metroIdList?: CountryMetroNBFeature[];
  /**
   * Metro level data. metro_location_id stores geotokens for metro restricts.
   */
  metroLocationId?: string[];
  /**
   * Metro navboost: list of (NavBoost feature V2, navboost float) pairs.
   */
  metroNavboost?: CountryMetroNBFeature[];
  provinceGeotokenList?: CountryProvinceGeotoken[];
  /**
   * two-letter(lower-case) countrycode, e.g. us countries that is related to,
   * but not local to
   */
  relatedCountries?: string[];
  relatedCountryCodes?: number[];
  /**
   * List of two-letter(lower-case) countrycodes(e.g. us) valid for restricts.
   * Typically cloned out of local_countries if is_valid_for_country_restrict is
   * set to true.
   */
  restrictCountries?: string[];
  /**
   * [Experimental]: Top salient countries for a doc. If a country can not be
   * found on this field it can be considered that this doc is not relevant to
   * it.
   */
  salientCountries?: CountrySalientCountry[];
  salientCountrySet?: QualitySalientCountriesSalientCountrySet;
  /**
   * Domain name of keys in filtering metro reducer class, used only by the
   * intermediate mapreduces to produce filtered data.
   */
  sitename?: string;
  /**
   * Super global pages get lesser demotion than global pages. A document can
   * only be either global or super_global but not both.
   */
  superGlobal?: boolean;
  urlPatternBasedCountry?: number;
  /**
   * Language and country extracted using the URL pattern map.
   */
  urlPatternBasedLanguage?: number;
  /**
   * This is used to store the visible country id computed from logs data
   */
  userVisibleCountryFromLogs?: string;
  /**
   * This is the country id we show to users on the result page. This is kept
   * different from country demotion country id because we dont want to expose
   * our backoff and url based detection algorithm - also we want to be ultra
   * conservative in showing this.
   */
  userVisibleLocalCountry?: number;
  /**
   * If result is global, store weight above ideal, as a confidence signal.
   * Used in query localness, cleared in production CountryAttachment.
   */
  weightAboveIdealForLocalness?: number;
  /**
   * Country specified for a web-site through webmaster console.
   */
  wmxCountry?: string;
}

function serializeCountryCountryAttachment(data: any): CountryCountryAttachment {
  return {
    ...data,
    geoLocations: data["geoLocations"] !== undefined ? serializeCountryGeoLocations(data["geoLocations"]) : undefined,
  };
}

function deserializeCountryCountryAttachment(data: any): CountryCountryAttachment {
  return {
    ...data,
    geoLocations: data["geoLocations"] !== undefined ? deserializeCountryGeoLocations(data["geoLocations"]) : undefined,
  };
}

/**
 * Stores one location and all meta-data associated with that location.
 */
export interface CountryGeoLocation {
  /**
   * The radius (in miles) around the assigned location that the document gets
   * 50% of its clicks.
   */
  clickRadius50Percent?: number;
  /**
   * Confidence on the location. Ranges in [0.0, 1.0]. Cleared during index
   * creation.
   */
  confidence?: number;
  /**
   * Confidence mapped to [0, 100]. Converted to integer for efficient storage.
   * Populated during index creation.
   */
  confidencePercent?: number;
  /**
   * Used for compressed docloc data. In compressed data, instead of
   * location_info, only an integer ID for that LocationInfo is stored. A
   * separate lookup table is used to get full LocationInfo from the internal
   * ID.
   */
  internalId?: number;
  locationInfo?: CountryLocationInfo;
  /**
   * True if this location is assigned to one of the subpages, and not to the
   * page itself. If the total number of locations assigned to all the subpages
   * of a page is small (usually up to 5), then that page also gets assigned
   * those locations, and this flag is set for those locations.
   */
  propagatedFromASubpage?: boolean;
}

function serializeCountryGeoLocation(data: any): CountryGeoLocation {
  return {
    ...data,
    locationInfo: data["locationInfo"] !== undefined ? serializeCountryLocationInfo(data["locationInfo"]) : undefined,
  };
}

function deserializeCountryGeoLocation(data: any): CountryGeoLocation {
  return {
    ...data,
    locationInfo: data["locationInfo"] !== undefined ? deserializeCountryLocationInfo(data["locationInfo"]) : undefined,
  };
}

/**
 * List of locations assigned to a document.
 */
export interface CountryGeoLocations {
  geoLocation?: CountryGeoLocation[];
  /**
   * This will be set to true for documents which receive several clicks but
   * are not assigned any location because the click distribution is flat.
   * Typical examples are global sites like facebook.com, chains like
   * walmart.com, informational sites like wikipedia.org etc. This flag is not
   * propagated to deeper pages since this signal is meant to indicate that a
   * website or a part of website is conclusively non-local, so propagating this
   * information to deeper pages does not make sense. If this flag is set, then
   * the only possible geo_location will be the ones which are
   * propagated_from_a_subpage.
   */
  isNonLocationSpecific?: boolean;
  /**
   * Depth of the URL from it's nearest parent in GeoLocation data. Webpages
   * inherhit locations from their parent pages. For example, if foo.com/a is
   * assigned location L1, and foo.com/a/b is not assigned any location, then
   * http://www.foo.com/a/b inherits location L1 from it's nearest parent
   * foo.com/a in GeoLocation data. This attribute is the distance from the
   * nearest parent which is present in GeoLocation data. In this particular
   * case, it will be 1.
   */
  propagationDepthFromParent?: number;
}

function serializeCountryGeoLocations(data: any): CountryGeoLocations {
  return {
    ...data,
    geoLocation: data["geoLocation"] !== undefined ? data["geoLocation"].map((item: any) => (serializeCountryGeoLocation(item))) : undefined,
  };
}

function deserializeCountryGeoLocations(data: any): CountryGeoLocations {
  return {
    ...data,
    geoLocation: data["geoLocation"] !== undefined ? data["geoLocation"].map((item: any) => (deserializeCountryGeoLocation(item))) : undefined,
  };
}

/**
 * This represents one location.
 */
export interface CountryLocationInfo {
  /**
   * The latitude and longitude of the conceptual center of the location. For
   * cities, this would be the center of the downtown, or maybe the location of
   * city hall. For states and countries it might be the capital city. But there
   * are no guarantees and this may be any random point inside the location.
   */
  center?: GeostorePointProto;
  city?: string;
  /**
   * Human readable name hierarchy. Only the relevant fields will be present.
   * For example for city GeoLocations, sub_locality field will not be present.
   * Cleared during index creation.
   */
  country?: string;
  county?: string;
  /**
   * Oyster feature ID of the enclosing state. Cleared during index creation.
   */
  enclosingStateFeatureId?: GeostoreFeatureIdProto;
  /**
   * Oyster feature ID of the location. Cleared during index creation.
   */
  featureId?: GeostoreFeatureIdProto;
  state?: string;
  /**
   * 32 bit fingerprint of the feature id of the state of this location. For
   * cities and sub-localities it will be the enclosing state. For state
   * locations, it will be fingerprint of the feture-id of the location itself.
   * Populated during index creation.
   */
  stateIdFprint?: number;
  subLocality?: string;
  /**
   * Type of the location (sub-locality, city, state etc).
   */
  type?:  | "TYPE_ANY" | "TYPE_TRANSPORTATION" | "TYPE_ROUTE" | "TYPE_DEPRECATED_HIGHWAY_DO_NOT_USE" | "TYPE_HIGHWAY" | "TYPE_HIGHWAY_1" | "TYPE_HIGHWAY_2" | "TYPE_HIGHWAY_3" | "TYPE_HIGHWAY_4" | "TYPE_HIGHWAY_5" | "TYPE_HIGHWAY_6" | "TYPE_HIGHWAY_7" | "TYPE_HIGHWAY_8" | "TYPE_HIGHWAY_9" | "TYPE_BICYCLE_ROUTE" | "TYPE_TRAIL" | "TYPE_SEGMENT" | "TYPE_ROAD" | "TYPE_RAILWAY" | "TYPE_STANDARD_TRACK" | "TYPE_JR_TRACK" | "TYPE_NARROW_TRACK" | "TYPE_MONORAIL_TRACK" | "TYPE_SUBWAY_TRACK" | "TYPE_LIGHT_RAIL_TRACK" | "TYPE_BROAD_TRACK" | "TYPE_HIGH_SPEED_RAIL" | "TYPE_TROLLEY_TRACK" | "TYPE_FERRY" | "TYPE_FERRY_BOAT" | "TYPE_FERRY_TRAIN" | "TYPE_VIRTUAL_SEGMENT" | "TYPE_INTERSECTION" | "TYPE_TRANSIT" | "TYPE_TRANSIT_STATION" | "TYPE_BUS_STATION" | "TYPE_TRAMWAY_STATION" | "TYPE_TRAIN_STATION" | "TYPE_SUBWAY_STATION" | "TYPE_FERRY_TERMINAL" | "TYPE_AIRPORT" | "TYPE_AIRPORT_CIVIL" | "TYPE_AIRPORT_MILITARY" | "TYPE_AIRPORT_MIXED" | "TYPE_HELIPORT" | "TYPE_SEAPLANE_BASE" | "TYPE_AIRSTRIP" | "TYPE_CABLE_CAR_STATION" | "TYPE_GONDOLA_LIFT_STATION" | "TYPE_FUNICULAR_STATION" | "TYPE_SPECIAL_STATION" | "TYPE_HORSE_CARRIAGE_STATION" | "TYPE_MONORAIL_STATION" | "TYPE_SEAPORT" | "TYPE_TRANSIT_STOP" | "TYPE_TRANSIT_TRIP" | "TYPE_TRANSIT_DEPARTURE" | "TYPE_TRANSIT_LEG" | "TYPE_TRANSIT_LINE" | "TYPE_TRANSIT_AGENCY_DEPRECATED_VALUE" | "TYPE_TRANSIT_TRANSFER" | "TYPE_SEGMENT_PATH" | "TYPE_ROAD_SIGN" | "TYPE_INTERSECTION_GROUP" | "TYPE_PATHWAY" | "TYPE_RESTRICTION_GROUP" | "TYPE_TOLL_CLUSTER" | "TYPE_POLITICAL" | "TYPE_COUNTRY" | "TYPE_ADMINISTRATIVE_AREA" | "TYPE_ADMINISTRATIVE_AREA1" | "TYPE_US_STATE" | "TYPE_GB_COUNTRY" | "TYPE_JP_TODOUFUKEN" | "TYPE_ADMINISTRATIVE_AREA2" | "TYPE_GB_FORMER_POSTAL_COUNTY" | "TYPE_GB_TRADITIONAL_COUNTY" | "TYPE_ADMINISTRATIVE_AREA3" | "TYPE_ADMINISTRATIVE_AREA4" | "TYPE_ADMINISTRATIVE_AREA5" | "TYPE_ADMINISTRATIVE_AREA6" | "TYPE_ADMINISTRATIVE_AREA7" | "TYPE_ADMINISTRATIVE_AREA8" | "TYPE_ADMINISTRATIVE_AREA9" | "TYPE_COLLOQUIAL_AREA" | "TYPE_RESERVATION" | "TYPE_LOCALITY" | "TYPE_GB_POST_TOWN" | "TYPE_JP_GUN" | "TYPE_JP_SHIKUCHOUSON" | "TYPE_JP_SUB_SHIKUCHOUSON" | "TYPE_COLLOQUIAL_CITY" | "TYPE_SUBLOCALITY" | "TYPE_US_BOROUGH" | "TYPE_GB_DEPENDENT_LOCALITY" | "TYPE_JP_OOAZA" | "TYPE_JP_KOAZA" | "TYPE_JP_GAIKU" | "TYPE_GB_DOUBLE_DEPENDENT_LOCALITY" | "TYPE_JP_CHIBAN" | "TYPE_JP_EDABAN" | "TYPE_SUBLOCALITY1" | "TYPE_SUBLOCALITY2" | "TYPE_SUBLOCALITY3" | "TYPE_SUBLOCALITY4" | "TYPE_SUBLOCALITY5" | "TYPE_NEIGHBORHOOD" | "TYPE_CONSTITUENCY" | "TYPE_DESIGNATED_MARKET_AREA" | "TYPE_SCHOOL_DISTRICT" | "TYPE_LAND_PARCEL" | "TYPE_DISPUTED_AREA" | "TYPE_POLICE_JURISDICTION" | "TYPE_STATISTICAL_AREA" | "TYPE_CONSTITUENCY_FUTURE" | "TYPE_PARK" | "TYPE_GOLF_COURSE" | "TYPE_LOCAL_PARK" | "TYPE_NATIONAL_PARK" | "TYPE_US_NATIONAL_PARK" | "TYPE_US_NATIONAL_MONUMENT" | "TYPE_NATIONAL_FOREST" | "TYPE_PROVINCIAL_PARK" | "TYPE_PROVINCIAL_FOREST" | "TYPE_CAMPGROUNDS" | "TYPE_HIKING_AREA" | "TYPE_BUSINESS" | "TYPE_GOVERNMENT" | "TYPE_BORDER_CROSSING" | "TYPE_CITY_HALL" | "TYPE_COURTHOUSE" | "TYPE_EMBASSY" | "TYPE_LIBRARY" | "TYPE_SCHOOL" | "TYPE_UNIVERSITY" | "TYPE_EMERGENCY" | "TYPE_HOSPITAL" | "TYPE_PHARMACY" | "TYPE_POLICE" | "TYPE_FIRE" | "TYPE_DOCTOR" | "TYPE_DENTIST" | "TYPE_VETERINARIAN" | "TYPE_TRAVEL_SERVICE" | "TYPE_LODGING" | "TYPE_RESTAURANT" | "TYPE_GAS_STATION" | "TYPE_PARKING" | "TYPE_POST_OFFICE" | "TYPE_REST_AREA" | "TYPE_CASH_MACHINE" | "TYPE_CAR_RENTAL" | "TYPE_CAR_REPAIR" | "TYPE_SHOPPING" | "TYPE_GROCERY" | "TYPE_TOURIST_DESTINATION" | "TYPE_ECO_TOURIST_DESTINATION" | "TYPE_BIRD_WATCHING" | "TYPE_FISHING" | "TYPE_HUNTING" | "TYPE_NATURE_RESERVE" | "TYPE_TEMPLE" | "TYPE_CHURCH" | "TYPE_GURUDWARA" | "TYPE_HINDU_TEMPLE" | "TYPE_MOSQUE" | "TYPE_SYNAGOGUE" | "TYPE_STADIUM" | "TYPE_BAR" | "TYPE_MOVIE_RENTAL" | "TYPE_COFFEE" | "TYPE_GOLF" | "TYPE_BANK" | "TYPE_DOODLE" | "TYPE_GROUNDS" | "TYPE_AIRPORT_GROUNDS" | "TYPE_BUILDING_GROUNDS" | "TYPE_CEMETERY" | "TYPE_HOSPITAL_GROUNDS" | "TYPE_INDUSTRIAL" | "TYPE_MILITARY" | "TYPE_SHOPPING_CENTER" | "TYPE_SPORTS_COMPLEX" | "TYPE_UNIVERSITY_GROUNDS" | "TYPE_DEPRECATED_TARMAC" | "TYPE_ENCLOSED_TRAFFIC_AREA" | "TYPE_PARKING_LOT" | "TYPE_PARKING_GARAGE" | "TYPE_OFF_ROAD_AREA" | "TYPE_BORDER" | "TYPE_BUILDING" | "TYPE_GEOCODED_ADDRESS" | "TYPE_NATURAL_FEATURE" | "TYPE_TERRAIN" | "TYPE_SAND" | "TYPE_BEACH" | "TYPE_DUNE" | "TYPE_ROCKY" | "TYPE_ICE" | "TYPE_GLACIER" | "TYPE_BUILT_UP_AREA" | "TYPE_VEGETATION" | "TYPE_SHRUBBERY" | "TYPE_WOODS" | "TYPE_AGRICULTURAL" | "TYPE_GRASSLAND" | "TYPE_TUNDRA" | "TYPE_DESERT" | "TYPE_SALT_FLAT" | "TYPE_WATER" | "TYPE_OCEAN" | "TYPE_BAY" | "TYPE_BIGHT" | "TYPE_LAGOON" | "TYPE_SEA" | "TYPE_STRAIT" | "TYPE_INLET" | "TYPE_FJORD" | "TYPE_LAKE" | "TYPE_SEASONAL_LAKE" | "TYPE_RESERVOIR" | "TYPE_POND" | "TYPE_RIVER" | "TYPE_RAPIDS" | "TYPE_DISTRIBUTARY" | "TYPE_CONFLUENCE" | "TYPE_WATERFALL" | "TYPE_SPRING" | "TYPE_GEYSER" | "TYPE_HOT_SPRING" | "TYPE_SEASONAL_RIVER" | "TYPE_WADI" | "TYPE_ESTUARY" | "TYPE_WETLAND" | "TYPE_WATER_NAVIGATION" | "TYPE_FORD" | "TYPE_CANAL" | "TYPE_HARBOR" | "TYPE_CHANNEL" | "TYPE_REEF" | "TYPE_REEF_FLAT" | "TYPE_REEF_GROWTH" | "TYPE_REEF_EXTENT" | "TYPE_REEF_ROCK_SUBMERGED" | "TYPE_IRRIGATION" | "TYPE_DAM" | "TYPE_DRINKING_WATER" | "TYPE_CURRENT" | "TYPE_WATERING_HOLE" | "TYPE_TECTONIC" | "TYPE_WATERING_HOLE_DEPRECATED" | "TYPE_VOLCANO" | "TYPE_LAVA_FIELD" | "TYPE_FISSURE" | "TYPE_FAULT" | "TYPE_LAND_MASS" | "TYPE_CONTINENT" | "TYPE_ISLAND" | "TYPE_ATOLL" | "TYPE_OCEAN_ROCK_EXPOSED" | "TYPE_CAY" | "TYPE_PENINSULA" | "TYPE_ISTHMUS" | "TYPE_ELEVATED" | "TYPE_PEAK" | "TYPE_NUNATAK" | "TYPE_SPUR" | "TYPE_PASS" | "TYPE_PLATEAU" | "TYPE_RIDGE" | "TYPE_RAVINE" | "TYPE_CRATER" | "TYPE_KARST" | "TYPE_CLIFF" | "TYPE_VISTA" | "TYPE_DIGITAL_ELEVATION_MODEL" | "TYPE_UPLAND" | "TYPE_TERRACE" | "TYPE_SLOPE" | "TYPE_CONTOUR_LINE" | "TYPE_PAN" | "TYPE_UNSTABLE_HILLSIDE" | "TYPE_MOUNTAIN_RANGE" | "TYPE_UNDERSEA" | "TYPE_SUBMARINE_SEAMOUNT" | "TYPE_SUBMARINE_RIDGE" | "TYPE_SUBMARINE_GAP" | "TYPE_SUBMARINE_PLATEAU" | "TYPE_SUBMARINE_DEEP" | "TYPE_SUBMARINE_VALLEY" | "TYPE_SUBMARINE_BASIN" | "TYPE_SUBMARINE_SLOPE" | "TYPE_SUBMARINE_CLIFF" | "TYPE_SUBMARINE_PLAIN" | "TYPE_SUBMARINE_FRACTURE_ZONE" | "TYPE_CAVE" | "TYPE_ROCK" | "TYPE_ARCHIPELAGO" | "TYPE_POSTAL" | "TYPE_POSTAL_CODE" | "TYPE_POSTAL_CODE_PREFIX" | "TYPE_PREMISE" | "TYPE_SUB_PREMISE" | "TYPE_SUITE" | "TYPE_POST_TOWN" | "TYPE_POSTAL_ROUND" | "TYPE_META_FEATURE" | "TYPE_DATA_SOURCE" | "TYPE_LOCALE" | "TYPE_TIMEZONE" | "TYPE_BUSINESS_CHAIN" | "TYPE_PHONE_NUMBER_PREFIX" | "TYPE_PHONE_NUMBER_AREA_CODE" | "TYPE_BUSINESS_CORRIDOR" | "TYPE_ADDRESS_TEMPLATE" | "TYPE_TRANSIT_AGENCY" | "TYPE_FUTURE_GEOMETRY" | "TYPE_EVENT" | "TYPE_EARTHQUAKE" | "TYPE_HURRICANE" | "TYPE_WEATHER_CONDITION" | "TYPE_TRANSIENT" | "TYPE_ENTRANCE" | "TYPE_CARTOGRAPHIC" | "TYPE_HIGH_TENSION" | "TYPE_SKI_TRAIL" | "TYPE_SKI_LIFT" | "TYPE_SKI_BOUNDARY" | "TYPE_WATERSHED_BOUNDARY" | "TYPE_TARMAC" | "TYPE_WALL" | "TYPE_PICNIC_AREA" | "TYPE_PLAY_GROUND" | "TYPE_TRAIL_HEAD" | "TYPE_GOLF_TEEING_GROUND" | "TYPE_GOLF_PUTTING_GREEN" | "TYPE_GOLF_ROUGH" | "TYPE_GOLF_SAND_BUNKER" | "TYPE_GOLF_FAIRWAY" | "TYPE_GOLF_HOLE" | "TYPE_DEPRECATED_GOLF_SHOP" | "TYPE_CAMPING_SITE" | "TYPE_DESIGNATED_BARBECUE_PIT" | "TYPE_DESIGNATED_COOKING_AREA" | "TYPE_CAMPFIRE_PIT" | "TYPE_WATER_FOUNTAIN" | "TYPE_LITTER_RECEPTACLE" | "TYPE_LOCKER_AREA" | "TYPE_ANIMAL_ENCLOSURE" | "TYPE_CARTOGRAPHIC_LINE" | "TYPE_ESTABLISHMENT" | "TYPE_ESTABLISHMENT_GROUNDS" | "TYPE_ESTABLISHMENT_BUILDING" | "TYPE_ESTABLISHMENT_POI" | "TYPE_ESTABLISHMENT_SERVICE" | "TYPE_CELESTIAL" | "TYPE_ROAD_MONITOR" | "TYPE_PUBLIC_SPACES_AND_MONUMENTS" | "TYPE_STATUE" | "TYPE_TOWN_SQUARE" | "TYPE_LEVEL" | "TYPE_COMPOUND" | "TYPE_COMPOUND_GROUNDS" | "TYPE_COMPOUND_BUILDING" | "TYPE_COMPOUND_SECTION" | "TYPE_TERMINAL_POINT" | "TYPE_REGULATED_AREA" | "TYPE_LOGICAL_BORDER" | "TYPE_DO_NOT_USE_RESERVED_TO_CATCH_GENERATED_FILES" | "TYPE_UNKNOWN";
}

function serializeCountryLocationInfo(data: any): CountryLocationInfo {
  return {
    ...data,
    enclosingStateFeatureId: data["enclosingStateFeatureId"] !== undefined ? serializeGeostoreFeatureIdProto(data["enclosingStateFeatureId"]) : undefined,
    featureId: data["featureId"] !== undefined ? serializeGeostoreFeatureIdProto(data["featureId"]) : undefined,
  };
}

function deserializeCountryLocationInfo(data: any): CountryLocationInfo {
  return {
    ...data,
    enclosingStateFeatureId: data["enclosingStateFeatureId"] !== undefined ? deserializeGeostoreFeatureIdProto(data["enclosingStateFeatureId"]) : undefined,
    featureId: data["featureId"] !== undefined ? deserializeGeostoreFeatureIdProto(data["featureId"]) : undefined,
  };
}

/**
 * A metro feature, keyed by NavBoost feature id V2. This can be a metro id, a
 * boost, or extended in the future to add probabilities or weights.
 */
export interface CountryMetroNBFeature {
  /**
   * The enclosing_province_geotoken is a 32 bit fingerprint of the state
   * encosing the (metro) id. MetroId's can span multiple states. Enclosing
   * geotoken is filled in with the state name for disambiguation.
   * ProvinceGeotoken field is different as it indicates an "interest". Format:
   * 32 bit fingerprint(__state__country).
   */
  enclosingProvinceGeotoken?: number;
  /**
   * A 32 bit navboost v2 feature id encoding (country, language, metro).
   * NavBoosterUtils class (google3/quality/navboost/nav_booster_utils.h)
   * provides functions to decode this feature.
   */
  id?: number;
  /**
   * This is the multiplier to apply to the result for this locale & query.
   * NOTE: This is for serving purposes only and should not be populated in the
   * index.
   */
  navboost?: number;
}

/**
 * A 32 bit fingerprint of a state level geotoken. The geotoken is in the
 * following format: __state__country. These indicate a page is of interest to
 * these states/regions of a country. The use of message is to enable easy
 * additions of probabilities or weights per metro id in the future.
 */
export interface CountryProvinceGeotoken {
  geotoken?: number;
}

/**
 * Salient Countries is an estimated probability (salience) of a doc to be
 * relevant to a country. On this message, countries are represented as int32
 * (the format of this data is defined in
 * i18n/identifiers/stableinternalregionconverter.cc). Salience is a value in
 * range [0.0 - 1.0] in which 1.0 represents a high likelihood to be relevant to
 * the country
 */
export interface CountrySalientCountry {
  compressedSalience?: number;
  countryCode?: number;
  salience?: number;
}

/**
 * Proto contains parameters for a multiple component distributions, where each
 * component has non-negative weight and the sum of component weights is 1.
 */
export interface CrawlerChangerateMultipleComponentDistribution {
  components?: CrawlerChangerateSingleComponentDistribution[];
}

/**
 * Proto contains parameters of a single component distribution.
 */
export interface CrawlerChangerateSingleComponentDistribution {
  /**
   * Scaling factor to ensure the approximated posterior to have the same scale
   * as the product of prior and likelihood. This value is used to compute
   * posterior weights. Uses log scale to provide a wider range. This field is
   * for internal use only.
   */
  logScaling?: number;
  /**
   * The type indicates the type of the distribution.
   */
  type?:  | "LOG_GAMMA" | "INV_GAMMA" | "GAMMA" | "LOG_NORMAL";
  /**
   * The weight is only used in multiple component scenarios.
   */
  weight?: number;
}

/**
 * NEXT_TAG: 13
 */
export interface CrawlerChangerateUrlChange {
  /**
   * Duplicate UrlChanges crawled within a specified time range will be merged
   * together. UrlChanges are considered duplicates if the simhash,
   * simhash_is_trusted, simhash_v2, simhash_v2_is_trusted, and shingle_simhash
   * are the same. additional_changes_merged indiciates the number of duplicate
   * UrlChanges merged into this UrlChange.
   */
  additionalChangesMerged?: number;
  /**
   * Deprecated fields. The fraction of tiles (0 to 1) that changed.
   */
  fractionalTileChange?: number;
  /**
   * The length in seconds of the change.
   */
  interval?: number;
  /**
   * Whether the content of the off-domain links changed.
   */
  offDomainLinksChange?: boolean;
  /**
   * The new count of off-domain links, if they changed.
   */
  offDomainLinksCount?: number;
  /**
   * The new count of on-domain links, if the count changed.
   */
  onDomainLinksCount?: number;
  /**
   * Whether the number of on-domain links changed.
   */
  onDomainLinksCountChange?: boolean;
  /**
   * The old simhash value obtained from shingles.
   */
  shingleSimhash?: IndexingConverterShingleFingerprint;
  /**
   * The simhash-v1 value. Use of simhash-v1 is deprecated, and newer UrlChange
   * should only contain simhash-v2. During this transition period, UrlChange
   * can contain either simhash or simhash_v2. It is possible that previous
   * UrlChange only contain simhash-v1 and the next UrlChange only contain
   * simhash-v2. In this case, we skip that interval in our changerate
   * computation. [go/changerate-simhash-v2-migration]
   */
  simhash?: bigint;
  /**
   * Whether the simhash-v1 should be trusted.
   */
  simhashIsTrusted?: boolean;
  /**
   * The simhash-v2 value.
   */
  simhashV2?: bigint;
  /**
   * Whether the simhash-v2 value should be trusted.
   */
  simhashV2IsTrusted?: boolean;
}

function serializeCrawlerChangerateUrlChange(data: any): CrawlerChangerateUrlChange {
  return {
    ...data,
    shingleSimhash: data["shingleSimhash"] !== undefined ? serializeIndexingConverterShingleFingerprint(data["shingleSimhash"]) : undefined,
    simhash: data["simhash"] !== undefined ? String(data["simhash"]) : undefined,
    simhashV2: data["simhashV2"] !== undefined ? String(data["simhashV2"]) : undefined,
  };
}

function deserializeCrawlerChangerateUrlChange(data: any): CrawlerChangerateUrlChange {
  return {
    ...data,
    shingleSimhash: data["shingleSimhash"] !== undefined ? deserializeIndexingConverterShingleFingerprint(data["shingleSimhash"]) : undefined,
    simhash: data["simhash"] !== undefined ? BigInt(data["simhash"]) : undefined,
    simhashV2: data["simhashV2"] !== undefined ? BigInt(data["simhashV2"]) : undefined,
  };
}

/**
 * The next available field number is 22. To access the best estimate of change
 * period, please use GetChangePeriod in predict-change-rate.h to select between
 * this and other change period estimates below.
 */
export interface CrawlerChangerateUrlChangerate {
  /**
   * The approximated posterior distribution.
   */
  approximatedPosterior?: CrawlerChangerateMultipleComponentDistribution;
  /**
   * The "significance" of the average change we saw of this document (from 0
   * to 1). Influenced by content changes. This can be used for prioritizing the
   * crawl (higher significance first).
   */
  averageChangeSignificance?: number;
  /**
   * 
   * ////////////////////////////////////////////////////////////////////////////
   * The classic changerate estimation.
   * ////////////////////////////////////////////////////////////////////////////
   * The classic estimate of change period (in seconds). It is computed by
   * inserted a "fake" change and no-change interval as a prior distribution.
   * This field is generally not used and should NOT be accessed directly. See
   * above for correct method for determining the change period estimate.
   */
  changeperiod?: number;
  /**
   * The confidence (between 0 and 1) in the changeperiod guess.
   */
  confidence?: number;
  /**
   * 
   * ////////////////////////////////////////////////////////////////////////////
   * The changerate estimation based on the global prior.
   * ////////////////////////////////////////////////////////////////////////////
   * The global-based changeperiod. This is our estimate (in seconds) for the
   * average time between changes. It is computed using the new prior method
   * based on global_based_prior_period and the global_based_prior_strength
   * specified below. This is used for computing pattern priors. Use
   * pattern_based_change_period or changeperiod fields for all other purposes.
   */
  globalBasedChangePeriod?: number;
  /**
   * The 'confidence' of the global-based changeperiod. This is the n-th root
   * of the posterior evaluated at MAP point, where n is the number of history
   * intervals. For now, it is hard to interpret the meaning of the absolute
   * values of 'average' posterior cross different sets of data.
   */
  globalBasedChangePeriodConfidence?: number;
  /**
   * The 2 parameters below specify the prior employed in calculating the
   * global_based_change_period. These values are precomputed through an offline
   * analysis and specified via flags.
   */
  globalBasedPriorPeriod?: number;
  globalBasedPriorStrength?: number;
  /**
   * The last time (unix timestamp) we saw a changed copy of the document.
   * Provided iff we have seen the page change.
   */
  lastChanged?: number;
  /**
   * The "significance" of the last change we saw of this document (from 0 to
   * 1). Influenced by content changes, etc. This can be used for prioritizing
   * the crawl (higher significance first).
   */
  lastChangeSignificance?: number;
  /**
   * The last time (unix timestamp) we saw a fetched copy of the document.
   */
  lastFetched?: number;
  /**
   * The number of intervals we've seen for this document (where an interval is
   * two different versions).
   */
  numIntervals?: number;
  /**
   * 
   * ////////////////////////////////////////////////////////////////////////////
   * The changerate estimation based on the pattern prior.
   * ////////////////////////////////////////////////////////////////////////////
   * The pattern-based changeperiod. This is our estimate (in seconds) for the
   * average time between changes. It is calculated based on the
   * pattern_based_prior_period and pattern_based_prior_strength below. This
   * quantity will eventually replace the old changeperiod calculation.
   */
  patternBasedChangePeriod?: number;
  /**
   * The same as global_based_change_period_confidence, except it is computed
   * using pattern based priors.
   */
  patternBasedChangePeriodConfidence?: number;
  /**
   * The lower edge of a confidence interval for the pattern-based change
   * period.
   */
  patternBasedLowerChangePeriod?: number;
  /**
   * The 2 parameters below specify the prior employed in calculating the
   * pattern_based_change_period. These values are calculated in a separate
   * process and looked up based on the URL pattern.
   */
  patternBasedPriorPeriod?: number;
  patternBasedPriorStrength?: number;
  /**
   * The version number of the algorithm, refer to ChangePeriodVersion for more
   * information.
   */
  patternChangePeriodVersion?: number;
  /**
   * 
   * ////////////////////////////////////////////////////////////////////////////
   * Basic information of a document.
   * ////////////////////////////////////////////////////////////////////////////
   * The type of the document determined by crawl histories, refer to TYPE for
   * more information.
   */
  type?: number;
  /**
   * 
   * ////////////////////////////////////////////////////////////////////////////
   * The UGC changerate estimation.
   * ////////////////////////////////////////////////////////////////////////////
   * Information on change period generated from user generated content (UGC)
   * change history.
   */
  ugcChangePeriod?: number;
  ugcChangePeriodConfidence?: number;
}

export interface CrawlerChangerateUrlHistory {
  /**
   * All the changes we've seen for this URL.
   */
  change?: CrawlerChangerateUrlChange[];
  /**
   * The latest version we've seen.
   */
  latestVersion?: CrawlerChangerateUrlVersion;
  /**
   * This field in only set in 'url_history' column of Union repository to
   * avoid having to read CompositeDocs.
   */
  url?: string;
}

function serializeCrawlerChangerateUrlHistory(data: any): CrawlerChangerateUrlHistory {
  return {
    ...data,
    change: data["change"] !== undefined ? data["change"].map((item: any) => (serializeCrawlerChangerateUrlChange(item))) : undefined,
    latestVersion: data["latestVersion"] !== undefined ? serializeCrawlerChangerateUrlVersion(data["latestVersion"]) : undefined,
  };
}

function deserializeCrawlerChangerateUrlHistory(data: any): CrawlerChangerateUrlHistory {
  return {
    ...data,
    change: data["change"] !== undefined ? data["change"].map((item: any) => (deserializeCrawlerChangerateUrlChange(item))) : undefined,
    latestVersion: data["latestVersion"] !== undefined ? deserializeCrawlerChangerateUrlVersion(data["latestVersion"]) : undefined,
  };
}

/**
 * NEXT_TAG: 15
 */
export interface CrawlerChangerateUrlVersion {
  /**
   * Same as the field in UrlChange. This allows us to merge identical
   * UrlVersions into a single UrlVersion.
   */
  additionalChangesMerged?: number;
  /**
   * The content type of the page.
   */
  contentType?: number;
  /**
   * Whether this is an IMS response (a 304, not modified).
   */
  isImsNotModified?: boolean;
  /**
   * The date from the LastModified header, if present.
   */
  lastModified?: number;
  /**
   * The checksum of all the off-domain links on the page.
   */
  offDomainLinksChecksum?: number;
  /**
   * The count of all the off-domain links on the page.
   */
  offDomainLinksCount?: number;
  /**
   * The count of all the on-domain links on the page. We aren't worried about
   * the contents themselves, since they might often change (e.g., session ids).
   * We assume that a change in the number of links is significant, however.
   */
  onDomainLinksCount?: number;
  /**
   * The simhash value obtained from shingles.
   */
  shingleSimhash?: IndexingConverterShingleFingerprint;
  /**
   * The simhash-v1 value. The simhash-v1 is now deprecated and new UrlVersions
   * should only populate simhash-v2. During migration phase from using
   * simhash-v1 to simhash-v2, it is possible that previous UrlChange only
   * contain simhash-v1 and the next UrlChange / UrlVersion could only contain
   * simhash-v2. In this case, we skip that interval in our changerate
   * computation. [go/changerate-simhash-v2-migration]
   */
  simhash?: bigint;
  /**
   * Whether the simhash-v1 should be trusted.
   */
  simhashIsTrusted?: boolean;
  /**
   * The simhash-v2 value.
   */
  simhashV2?: bigint;
  /**
   * Whether the simhash-v2 value should be trusted.
   */
  simhashV2IsTrusted?: boolean;
  /**
   * The tiles of the document body. We use int32s instead of int64s (the norm)
   * in order to save space. Since rare inaccuracy doesn't really matter, we've
   * decided this is an okay tradeoff.
   */
  tile?: number[];
  /**
   * The timestamp we crawled the page.
   */
  timestamp?: number;
}

function serializeCrawlerChangerateUrlVersion(data: any): CrawlerChangerateUrlVersion {
  return {
    ...data,
    shingleSimhash: data["shingleSimhash"] !== undefined ? serializeIndexingConverterShingleFingerprint(data["shingleSimhash"]) : undefined,
    simhash: data["simhash"] !== undefined ? String(data["simhash"]) : undefined,
    simhashV2: data["simhashV2"] !== undefined ? String(data["simhashV2"]) : undefined,
  };
}

function deserializeCrawlerChangerateUrlVersion(data: any): CrawlerChangerateUrlVersion {
  return {
    ...data,
    shingleSimhash: data["shingleSimhash"] !== undefined ? deserializeIndexingConverterShingleFingerprint(data["shingleSimhash"]) : undefined,
    simhash: data["simhash"] !== undefined ? BigInt(data["simhash"]) : undefined,
    simhashV2: data["simhashV2"] !== undefined ? BigInt(data["simhashV2"]) : undefined,
  };
}

export interface CrowdingPerDocData {
  newscluster?: CrowdingPerDocDataNewsCluster[];
}

function serializeCrowdingPerDocData(data: any): CrowdingPerDocData {
  return {
    ...data,
    newscluster: data["newscluster"] !== undefined ? data["newscluster"].map((item: any) => (serializeCrowdingPerDocDataNewsCluster(item))) : undefined,
  };
}

function deserializeCrowdingPerDocData(data: any): CrowdingPerDocData {
  return {
    ...data,
    newscluster: data["newscluster"] !== undefined ? data["newscluster"].map((item: any) => (deserializeCrowdingPerDocDataNewsCluster(item))) : undefined,
  };
}

/**
 * For crowding in news we need to keep data about the last X clustering
 * iterations around.
 */
export interface CrowdingPerDocDataNewsCluster {
  /**
   * Fingerprint combination of all urls in a cluster
   */
  ClusterId?: bigint;
  /**
   * This is the X in the "and X related >>" link on headlines and search
   * results
   */
  ClusterSize?: number;
  /**
   * When was this clustered (needed for keeping last X iterations around and
   * discarding earlier ones)
   */
  ClusterTimeStamp?: number;
}

function serializeCrowdingPerDocDataNewsCluster(data: any): CrowdingPerDocDataNewsCluster {
  return {
    ...data,
    ClusterId: data["ClusterId"] !== undefined ? String(data["ClusterId"]) : undefined,
  };
}

function deserializeCrowdingPerDocDataNewsCluster(data: any): CrowdingPerDocDataNewsCluster {
  return {
    ...data,
    ClusterId: data["ClusterId"] !== undefined ? BigInt(data["ClusterId"]) : undefined,
  };
}

export interface DeepCropIndexing {
  /**
   * Compact representation for indexing, see creatism::CropBitmap for details
   * on the packing format.
   */
  cropBytes?: Uint8Array;
}

function serializeDeepCropIndexing(data: any): DeepCropIndexing {
  return {
    ...data,
    cropBytes: data["cropBytes"] !== undefined ? encodeBase64(data["cropBytes"]) : undefined,
  };
}

function deserializeDeepCropIndexing(data: any): DeepCropIndexing {
  return {
    ...data,
    cropBytes: data["cropBytes"] !== undefined ? decodeBase64(data["cropBytes"] as string) : undefined,
  };
}

export interface DeepCropPixels {
  /**
   * Pixels version of the DeepCropIndexing bytes, this corresponds to the crop
   * box for a given image (based input image size and desired aspect ratio).
   */
  x0?: number;
  x1?: number;
  y0?: number;
  y1?: number;
}

/**
 * NOTE: In segindexer, the docproperties of a document may be reused from a
 * previous cycle if its content is not changed. If you add a new field to
 * DocProperties, make sure it is taken care (i.e., gets copied from a previous
 * cycle to the current document) in CDocProperties::EndDocument().
 */
export interface DocProperties {
  /**
   * The average weighted font size of a term in the doc body
   */
  avgTermWeight?: number;
  /**
   * Missing or meaningless title
   */
  badTitle?: boolean;
  badtitleinfo?: DocPropertiesBadTitleInfo[];
  /**
   * A Language enum value. See: go/language-enum
   */
  languages?: number[];
  /**
   * Leading text information generated by
   * google3/quality/snippets/leadingtext/leadingtext-detector.cc
   */
  leadingtext?: SnippetsLeadingtextLeadingTextInfo;
  numPunctuations?: number;
  numTags?: number;
  /**
   * The number of tokens, tags and punctuations in the tokenized contents.
   * This is an approximation of the number of tokens, tags and punctuations we
   * end up with in mustang, but is inexact since we drop some tokens in mustang
   * and also truncate docs at a max cap.
   */
  numTokens?: number;
  /**
   * The restricts for CSE structured search.
   */
  proseRestrict?: string[];
  restricts?: string[];
  /**
   * The time CDocProperties::StartDocument() is called, encoded as seconds
   * past the epoch (Jan 1, 1970). This value is always refreshed and not
   * reused.
   */
  timestamp?: bigint;
  /**
   * Extracted from the title tag of the content. This is typically extracted
   * by TitleMetaCollector defined at google3/segindexer/title-meta-collector.h.
   * Please see its documentation for the format and other caveats.
   */
  title?: string;
}

function serializeDocProperties(data: any): DocProperties {
  return {
    ...data,
    timestamp: data["timestamp"] !== undefined ? String(data["timestamp"]) : undefined,
  };
}

function deserializeDocProperties(data: any): DocProperties {
  return {
    ...data,
    timestamp: data["timestamp"] !== undefined ? BigInt(data["timestamp"]) : undefined,
  };
}

/**
 * Bad title information.
 */
export interface DocPropertiesBadTitleInfo {
  score?: number;
  type?:  | "NOT_BAD" | "MISSING_OR_MEANINGLESS" | "BOILERPLATE" | "FOREIGN" | "UNREADABLE" | "NAKED" | "NO_QUERY_SUPPORT" | "NO_SITE_INFO";
}

export interface DrishtiDenseFeatureData {
  /**
   * If extra is present it must be of the same length as value.
   */
  extra?: DrishtiFeatureExtra[];
  generalExtra?: DrishtiFeatureExtra;
  /**
   * Dense data.
   */
  value?: number[];
}

export interface DrishtiFeatureExtra {
}

export interface DrishtiFeatureSetData {
  /**
   * Extra information for this particular FeatureSetData (example timestamp of
   * this frame in the video). (Almost never used).
   */
  extra?: DrishtiFeatureExtra[];
  /**
   * The following can have multiple FeatureSetElement(s) Each of these
   * FeatureSetElement correspond to the various feature groups. One concrete
   * example is the way these features are generated - example audio, video or
   * OCR.
   */
  feature?: DrishtiFeatureSetDataFeatureSetElement[];
  /**
   * Labels for this particular FeatureSetData. (Almost never used). Only
   * interesting when you have (for example) frame level labels.
   */
  label?: DrishtiLabelSetElement[];
}

function serializeDrishtiFeatureSetData(data: any): DrishtiFeatureSetData {
  return {
    ...data,
    feature: data["feature"] !== undefined ? data["feature"].map((item: any) => (serializeDrishtiFeatureSetDataFeatureSetElement(item))) : undefined,
    label: data["label"] !== undefined ? data["label"].map((item: any) => (serializeDrishtiLabelSetElement(item))) : undefined,
  };
}

function deserializeDrishtiFeatureSetData(data: any): DrishtiFeatureSetData {
  return {
    ...data,
    feature: data["feature"] !== undefined ? data["feature"].map((item: any) => (deserializeDrishtiFeatureSetDataFeatureSetElement(item))) : undefined,
    label: data["label"] !== undefined ? data["label"].map((item: any) => (deserializeDrishtiLabelSetElement(item))) : undefined,
  };
}

/**
 * A FeatureSetElement stores the features coming from a single group.
 */
export interface DrishtiFeatureSetDataFeatureSetElement {
  dense?: DrishtiDenseFeatureData;
  indexed?: DrishtiIndexedFeatureData;
  /**
   * A name for the feature group: example "AUDIO", "VIDEO", "OCR", etc.
   */
  name?: string;
  quantized?: DrishtiQuantizedDenseFeatureData;
  quantizedByteDense?: DrishtiQuantizedByteDenseFeatureData;
  quantizedByteIndexed?: DrishtiQuantizedByteIndexedFeatureData;
  sparse?: DrishtiSparseFeatureData;
}

function serializeDrishtiFeatureSetDataFeatureSetElement(data: any): DrishtiFeatureSetDataFeatureSetElement {
  return {
    ...data,
    indexed: data["indexed"] !== undefined ? serializeDrishtiIndexedFeatureData(data["indexed"]) : undefined,
    quantized: data["quantized"] !== undefined ? serializeDrishtiQuantizedDenseFeatureData(data["quantized"]) : undefined,
    quantizedByteDense: data["quantizedByteDense"] !== undefined ? serializeDrishtiQuantizedByteDenseFeatureData(data["quantizedByteDense"]) : undefined,
    quantizedByteIndexed: data["quantizedByteIndexed"] !== undefined ? serializeDrishtiQuantizedByteIndexedFeatureData(data["quantizedByteIndexed"]) : undefined,
  };
}

function deserializeDrishtiFeatureSetDataFeatureSetElement(data: any): DrishtiFeatureSetDataFeatureSetElement {
  return {
    ...data,
    indexed: data["indexed"] !== undefined ? deserializeDrishtiIndexedFeatureData(data["indexed"]) : undefined,
    quantized: data["quantized"] !== undefined ? deserializeDrishtiQuantizedDenseFeatureData(data["quantized"]) : undefined,
    quantizedByteDense: data["quantizedByteDense"] !== undefined ? deserializeDrishtiQuantizedByteDenseFeatureData(data["quantizedByteDense"]) : undefined,
    quantizedByteIndexed: data["quantizedByteIndexed"] !== undefined ? deserializeDrishtiQuantizedByteIndexedFeatureData(data["quantizedByteIndexed"]) : undefined,
  };
}

/**
 * This represents a sequence (ordered) of FeatureSetData elements.
 */
export interface DrishtiFeatureSetDataSequence {
  /**
   * FeatureSetData contains the features. In most scenarios, you only have one
   * element. However, multiple elements are appropriate in case of videos where
   * each element may correspond to a frame in the video.
   */
  element?: DrishtiFeatureSetData[];
  /**
   * Some extra information about this FeatureSetDataSequence. (Almost never
   * used).
   */
  extra?: DrishtiFeatureExtra[];
  /**
   * Global (video-level) labels. In most cases, you only have one
   * LabelSetElement. All the labels will be stored in this single
   * LabelSetElement. Scenarios where you may have multiple LabelSetElement(s)
   * is (for example) when you want to differentiate the labels into various
   * sub-groups - eg, central vs relevant, kg-ids vs queries, etc.
   */
  label?: DrishtiLabelSetElement[];
  /**
   * If set, must be same length as element. Each entry is the timestamp in
   * microseconds where the FeatureSetData element was extracted.
   */
  timestamp?: bigint[];
}

function serializeDrishtiFeatureSetDataSequence(data: any): DrishtiFeatureSetDataSequence {
  return {
    ...data,
    element: data["element"] !== undefined ? data["element"].map((item: any) => (serializeDrishtiFeatureSetData(item))) : undefined,
    label: data["label"] !== undefined ? data["label"].map((item: any) => (serializeDrishtiLabelSetElement(item))) : undefined,
    timestamp: data["timestamp"] !== undefined ? data["timestamp"].map((item: any) => (String(item))) : undefined,
  };
}

function deserializeDrishtiFeatureSetDataSequence(data: any): DrishtiFeatureSetDataSequence {
  return {
    ...data,
    element: data["element"] !== undefined ? data["element"].map((item: any) => (deserializeDrishtiFeatureSetData(item))) : undefined,
    label: data["label"] !== undefined ? data["label"].map((item: any) => (deserializeDrishtiLabelSetElement(item))) : undefined,
    timestamp: data["timestamp"] !== undefined ? data["timestamp"].map((item: any) => (BigInt(item))) : undefined,
  };
}

export interface DrishtiIndexedFeatureData {
  /**
   * If extra is present it must be of the same length as index and value.
   */
  extra?: DrishtiFeatureExtra[];
  generalExtra?: DrishtiFeatureExtra;
  /**
   * Indexed data. index and value must be of the same length.
   */
  index?: bigint[];
  value?: number[];
}

function serializeDrishtiIndexedFeatureData(data: any): DrishtiIndexedFeatureData {
  return {
    ...data,
    index: data["index"] !== undefined ? data["index"].map((item: any) => (String(item))) : undefined,
  };
}

function deserializeDrishtiIndexedFeatureData(data: any): DrishtiIndexedFeatureData {
  return {
    ...data,
    index: data["index"] !== undefined ? data["index"].map((item: any) => (BigInt(item))) : undefined,
  };
}

export interface DrishtiLabelSetData {
  extra?: DrishtiFeatureExtra[];
  generalExtra?: DrishtiFeatureExtra;
  targetClass?: bigint[];
  targetClassName?: string[];
  targetValue?: number[];
  targetWeight?: number[];
  /**
   * Weight assigned to this set of labels.
   */
  weight?: number;
}

function serializeDrishtiLabelSetData(data: any): DrishtiLabelSetData {
  return {
    ...data,
    targetClass: data["targetClass"] !== undefined ? data["targetClass"].map((item: any) => (String(item))) : undefined,
  };
}

function deserializeDrishtiLabelSetData(data: any): DrishtiLabelSetData {
  return {
    ...data,
    targetClass: data["targetClass"] !== undefined ? data["targetClass"].map((item: any) => (BigInt(item))) : undefined,
  };
}

export interface DrishtiLabelSetElement {
  label?: DrishtiLabelSetData;
  name?: string;
}

function serializeDrishtiLabelSetElement(data: any): DrishtiLabelSetElement {
  return {
    ...data,
    label: data["label"] !== undefined ? serializeDrishtiLabelSetData(data["label"]) : undefined,
  };
}

function deserializeDrishtiLabelSetElement(data: any): DrishtiLabelSetElement {
  return {
    ...data,
    label: data["label"] !== undefined ? deserializeDrishtiLabelSetData(data["label"]) : undefined,
  };
}

/**
 * Proto message to store quantized dense feature data.
 */
export interface DrishtiQuantizedByteDenseFeatureData {
  /**
   * If extra is present it must be of the same length as value.
   */
  extra?: DrishtiFeatureExtra[];
  generalExtra?: DrishtiFeatureExtra;
  /**
   * Quantized values for the feature.
   */
  value?: Uint8Array;
}

function serializeDrishtiQuantizedByteDenseFeatureData(data: any): DrishtiQuantizedByteDenseFeatureData {
  return {
    ...data,
    value: data["value"] !== undefined ? encodeBase64(data["value"]) : undefined,
  };
}

function deserializeDrishtiQuantizedByteDenseFeatureData(data: any): DrishtiQuantizedByteDenseFeatureData {
  return {
    ...data,
    value: data["value"] !== undefined ? decodeBase64(data["value"] as string) : undefined,
  };
}

/**
 * Proto message to store quantized indexed feature data.
 */
export interface DrishtiQuantizedByteIndexedFeatureData {
  /**
   * If extra is present it must be of the same length as value.
   */
  extra?: DrishtiFeatureExtra[];
  generalExtra?: DrishtiFeatureExtra;
  index?: bigint[];
  /**
   * Quantized values for the feature.
   */
  value?: Uint8Array;
}

function serializeDrishtiQuantizedByteIndexedFeatureData(data: any): DrishtiQuantizedByteIndexedFeatureData {
  return {
    ...data,
    index: data["index"] !== undefined ? data["index"].map((item: any) => (String(item))) : undefined,
    value: data["value"] !== undefined ? encodeBase64(data["value"]) : undefined,
  };
}

function deserializeDrishtiQuantizedByteIndexedFeatureData(data: any): DrishtiQuantizedByteIndexedFeatureData {
  return {
    ...data,
    index: data["index"] !== undefined ? data["index"].map((item: any) => (BigInt(item))) : undefined,
    value: data["value"] !== undefined ? decodeBase64(data["value"] as string) : undefined,
  };
}

export interface DrishtiQuantizedDenseFeatureData {
  /**
   * If extra is present it must be of the same length as value.
   */
  extra?: DrishtiFeatureExtra[];
  generalExtra?: DrishtiFeatureExtra;
  /**
   * Quantized Dense data.
   */
  value?: Uint8Array[];
}

function serializeDrishtiQuantizedDenseFeatureData(data: any): DrishtiQuantizedDenseFeatureData {
  return {
    ...data,
    value: data["value"] !== undefined ? data["value"].map((item: any) => (encodeBase64(item))) : undefined,
  };
}

function deserializeDrishtiQuantizedDenseFeatureData(data: any): DrishtiQuantizedDenseFeatureData {
  return {
    ...data,
    value: data["value"] !== undefined ? data["value"].map((item: any) => (decodeBase64(item as string))) : undefined,
  };
}

export interface DrishtiSparseFeatureData {
  /**
   * If extra is present it must be of the same length as label and value.
   */
  extra?: DrishtiFeatureExtra[];
  generalExtra?: DrishtiFeatureExtra;
  /**
   * Indexed data. label and value must be of the same length.
   */
  label?: string[];
  value?: number[];
}

/**
 * The attributes of encoded thumbnail images. Next id: 7.
 */
export interface DrishtiVesperEncodedThumbnail {
  /**
   * JPEG/WEBP quality factor in range [0,100].
   */
  encodingQuality?: number;
  /**
   * Image encoding type.
   */
  encodingType?:  | "UNKNOWN" | "JPEG" | "WEBP" | "PNG";
  height?: number;
  /**
   * Encoded thumbnail bytes. Prefer this over `image_string` as we are not
   * supposed to store image bytes in a proto string field.
   */
  imageBytes?: Uint8Array;
  /**
   * Please migrate to `image_bytes`.
   */
  imageString?: string;
  /**
   * Thumbnail resolution.
   */
  width?: number;
}

function serializeDrishtiVesperEncodedThumbnail(data: any): DrishtiVesperEncodedThumbnail {
  return {
    ...data,
    imageBytes: data["imageBytes"] !== undefined ? encodeBase64(data["imageBytes"]) : undefined,
  };
}

function deserializeDrishtiVesperEncodedThumbnail(data: any): DrishtiVesperEncodedThumbnail {
  return {
    ...data,
    imageBytes: data["imageBytes"] !== undefined ? decodeBase64(data["imageBytes"] as string) : undefined,
  };
}

/**
 * LINT: LEGACY_NAMES MovingThumbnail is defined as a short video clip that
 * represents the whole video content. Next id: 17.
 */
export interface DrishtiVesperMovingThumbnail {
  /**
   * The begin timestamp in milliseconds.
   */
  beginTimestampMs?: number;
  /**
   * The duration of the moving thumbnail in milliseconds. Note that the
   * duration may not be the difference between begin_timestamp_ms and
   * end_timestamp_ms, esp when the moving thumbnail covers multiple clips from
   * the video.
   */
  durationMs?: number;
  encodedGifAnimation?: Uint8Array;
  /**
   * The encoded video string.
   */
  encodedVideoString?: Uint8Array;
  /**
   * The encoded WebP animation.
   */
  encodedWebpAnimation?: Uint8Array;
  /**
   * The end timestamp in milliseconds.
   */
  endTimestampMs?: number;
  /**
   * Pixel height of the moving thumbnail.
   */
  height?: number;
  /**
   * MovingThumbnail id (e.g., the video id).
   */
  id?: string;
  /**
   * If set, this is the algorithm version used to generate this moving
   * thumbnail.
   */
  movingThumbnailerVersion?:  | "V0" | "V1" | "DEPRECATED_V2" | "DEPRECATED_V3" | "V4" | "V5" | "V6" | "SHORT_PREVIEW_V0" | "LIVE_MOVING_THUMBNAILER" | "MANUAL";
  /**
   * MovingThumbnail name.
   */
  name?:  | "UNKNOWN" | "MQDEFAULT" | "MQDEFAULT_6S" | "LQDEFAULT_6S" | "MQ220P_5S" | "MQDEFAULT_6S_HIGHLIGHT" | "MQDEFAULT_6S_PRE_HIGHLIGHT" | "MQDEFAULT_6S_THIRD_HIGHLIGHT" | "MQDEFAULT_6S_ZOOM_IN" | "SD360P_6S_ZOOM_IN" | "MQDEFAULT_3S" | "MQDEFAULT_6S_480x270" | "MQDEFAULT_1S" | "MQ_SHORTS_PREVIEW" | "HQ_SHORTS_PREVIEW";
  /**
   * The score of the moving thumbnail.
   */
  score?: number;
  scoreComponents?: DrishtiVesperMovingThumbnailScoreComponents;
  /**
   * A set of single frame thumbnails in the MovingThumbnail.
   */
  thumbnails?: DrishtiVesperThumbnail[];
  /**
   * MovingThumbnail type.
   */
  type?:  | "TYPE_UNKNOWN" | "AN_GIF" | "AN_WEBP" | "AN_MP4" | "AN_WEBM";
  /**
   * The actual quality of the Webp animation. Note this value may not be equal
   * to the quality value requested in the animation creator's options. This is
   * because other requirements, such as the max file size, may force the
   * creator to lower the actual quality value.
   */
  webpQualityLevel?: number;
  /**
   * Pixel width of the moving thumbnail.
   */
  width?: number;
}

function serializeDrishtiVesperMovingThumbnail(data: any): DrishtiVesperMovingThumbnail {
  return {
    ...data,
    encodedGifAnimation: data["encodedGifAnimation"] !== undefined ? encodeBase64(data["encodedGifAnimation"]) : undefined,
    encodedVideoString: data["encodedVideoString"] !== undefined ? encodeBase64(data["encodedVideoString"]) : undefined,
    encodedWebpAnimation: data["encodedWebpAnimation"] !== undefined ? encodeBase64(data["encodedWebpAnimation"]) : undefined,
    thumbnails: data["thumbnails"] !== undefined ? data["thumbnails"].map((item: any) => (serializeDrishtiVesperThumbnail(item))) : undefined,
  };
}

function deserializeDrishtiVesperMovingThumbnail(data: any): DrishtiVesperMovingThumbnail {
  return {
    ...data,
    encodedGifAnimation: data["encodedGifAnimation"] !== undefined ? decodeBase64(data["encodedGifAnimation"] as string) : undefined,
    encodedVideoString: data["encodedVideoString"] !== undefined ? decodeBase64(data["encodedVideoString"] as string) : undefined,
    encodedWebpAnimation: data["encodedWebpAnimation"] !== undefined ? decodeBase64(data["encodedWebpAnimation"] as string) : undefined,
    thumbnails: data["thumbnails"] !== undefined ? data["thumbnails"].map((item: any) => (deserializeDrishtiVesperThumbnail(item))) : undefined,
  };
}

/**
 * Sum of individual score components within a moving thumbnail. Used as input
 * for weight fitting.
 */
export interface DrishtiVesperMovingThumbnailScoreComponents {
  audienceRewindRatioScore?: number;
  iconicFaceScore?: number;
  matchingScore?: number;
  motionScore?: number;
  titleMatchingScore?: number;
  videoThumbQualityScore?: number;
}

/**
 * The attributes of a video thumbnail.
 */
export interface DrishtiVesperThumbnail {
  /**
   * Thumbnail dense features
   */
  denseFeatures?: number[];
  /**
   * Thumbnail image as an encoded image. Deprecated, use encoded_thumbnails
   * instead.
   */
  encodedImageString?: string;
  /**
   * Thumbnail image as an encoded image with smaller resolution. Deprecated,
   * use encoded_thumbnails instead.
   */
  encodedImageStringSmall?: string;
  /**
   * Encoded thumbnail images.
   */
  encodedThumbnails?: DrishtiVesperEncodedThumbnail[];
  /**
   * Thumbnail id.
   */
  id?: string;
  /**
   * Text in video thumbnails that was detected by OCR.
   */
  ocrText?: string;
  /**
   * Thumbnail quality scores.
   */
  qualityScores?: DrishtiVesperThumbnailQualityScore[];
  /**
   * If true, this thumbnail should update default thumbnail.
   */
  shouldUpdateDefaultThumbnail?: boolean;
  /**
   * Thumbnailer Version.
   */
  thumbnailerModelVersion?:  | "VERSION_UNKNOWN" | "VERSION_FIRST" | "VERSION_RANDOM" | "VERSION_4" | "VERSION_5" | "VERSION_6" | "VERSION_7" | "VERSION_8" | "VERSION_SHORTS_4" | "VERSION_SHORTS_5" | "VERSION_SHORTS_6" | "VERSION_STORY_4" | "VERSION_STORY_5" | "VERSION_MOVING_4" | "VERSION_MOVING_5" | "VERSION_MOVING_6" | "VERSION_MOVING_SHORTS_0" | "VERSION_MOVING_LIVE_0" | "VERSION_MOVING_MANUAL_0" | "VERSION_LITE_1" | "VERSION_CUSTOM" | "VERSION_REJECTED";
  /**
   * Thumbnail timestamp in milliseconds.
   */
  timestampMs?: number;
  /**
   * Thumbnail type.
   */
  type?:  | "UNKNOWN" | "MAIN_THUMB_CUSTOM" | "MAIN_THUMB_NON_CUSTOM" | "SHOT_THUMB" | "NUMBERED_THUMB" | "KEY_FRAME" | "FRAME" | "AUTO";
  userReportedThumbnail?: DrishtiVesperUserReportUserReportedThumbnail;
  /**
   * All user reported thumbnails of interest.
   */
  userReportedThumbnails?: DrishtiVesperUserReportUserReportedThumbnail[];
  /**
   * Thumbnail version, i.e., the unix time in seconds when the thumbnail was
   * created.
   */
  version?: number;
}

function serializeDrishtiVesperThumbnail(data: any): DrishtiVesperThumbnail {
  return {
    ...data,
    encodedThumbnails: data["encodedThumbnails"] !== undefined ? data["encodedThumbnails"].map((item: any) => (serializeDrishtiVesperEncodedThumbnail(item))) : undefined,
  };
}

function deserializeDrishtiVesperThumbnail(data: any): DrishtiVesperThumbnail {
  return {
    ...data,
    encodedThumbnails: data["encodedThumbnails"] !== undefined ? data["encodedThumbnails"].map((item: any) => (deserializeDrishtiVesperEncodedThumbnail(item))) : undefined,
  };
}

export interface DrishtiVesperThumbnailQualityScore {
  score?: number;
  type?:  | "UNKNOWN" | "PHOTO_QUALITY" | "PAMIR_IMAGE_QUALITY" | "VIDEO_THUMB_QUALITY" | "SALIENCY" | "COMPLEXITY" | "SHARPNESS" | "CLOSE_UP" | "BEEHIVE_QUALITY" | "ICONIC_FACE" | "DUMMY" | "COLORFULNESS" | "MOTION" | "RETENTION_STATS" | "FACIAL_EXPRESSION" | "MATCHING" | "LUCKYSHOT_SHARPNESS" | "SINGLE_FACE_MODULE" | "TITLE_MATCHING" | "FACE_CLUSTERING" | "FACE_MATCHING" | "RACY_SCORE" | "NON_RACY_SCORE" | "SALIENCY_COVERAGE" | "AUDIENCE_WATCH_DATA" | "AUDIENCE_REWATCH_DATA" | "AUDIENCE_REWIND_RATIO" | "AUDIENCE_DROPOFF_RATIO" | "HIGHLIGHT_SCORE" | "JOY_FACE" | "EYE_OPEN" | "FACE_RATIO" | "OCR_RACY_SCORE" | "SHOT_BOUNDARY" | "NIMA" | "FOREGROUND_MOTION_SALIENCY" | "PAGE_QUALITY" | "GLOBAL_MOTION" | "CHAPTER_TITLE_MATCHING" | "DBSCAN_FRAME_CHAPTER_SIMILARITY" | "EYES_NOT_VISIBLY_CLOSED" | "ENGAGINESS" | "MERGED";
}

/**
 * Proto holding values for details about human labels.
 */
export interface DrishtiVesperUserReportHumanLabel {
  racyLevel?:  | "UNKNOWN" | "SAFE" | "BORDERLINE" | "SEXUAL";
}

/**
 * Proto holding values for details about score and the source model.
 */
export interface DrishtiVesperUserReportModelScore {
  modelName?: string;
  score?: number;
}

/**
 * Proto holding values for user reported thumbnails. Next id: 12
 */
export interface DrishtiVesperUserReportUserReportedThumbnail {
  denseFeatures?: number[];
  /**
   * Number of days in which volume is calculated.
   */
  duration?: number;
  humanLabel?: DrishtiVesperUserReportHumanLabel;
  /**
   * Daily aggregared impressions for the reported video.
   */
  impressions?: number;
  /**
   * Whether the thumbnail needs a human label.
   */
  needHumanLabel?: boolean;
  rawHumanLabels?: DrishtiVesperUserReportHumanLabel[];
  reportScore?: DrishtiVesperUserReportModelScore;
  reportType?:  | "UNKNOWN" | "RACY";
  score?: DrishtiVesperUserReportModelScore;
  useCase?:  | "UNKNOWN" | "TRAIN" | "EVAL";
  /**
   * Number of reports.
   */
  volume?: number;
}

/**
 * Video level container for thumbnail with its attributes, e.g., timestamp,
 * id, quality scores, annotations, or features.
 */
export interface DrishtiVesperVideoThumbnail {
  /**
   * Video id.
   */
  id?: string;
  movingThumbnails?: DrishtiVesperMovingThumbnail[];
  thumbnails?: DrishtiVesperThumbnail[];
}

function serializeDrishtiVesperVideoThumbnail(data: any): DrishtiVesperVideoThumbnail {
  return {
    ...data,
    movingThumbnails: data["movingThumbnails"] !== undefined ? data["movingThumbnails"].map((item: any) => (serializeDrishtiVesperMovingThumbnail(item))) : undefined,
    thumbnails: data["thumbnails"] !== undefined ? data["thumbnails"].map((item: any) => (serializeDrishtiVesperThumbnail(item))) : undefined,
  };
}

function deserializeDrishtiVesperVideoThumbnail(data: any): DrishtiVesperVideoThumbnail {
  return {
    ...data,
    movingThumbnails: data["movingThumbnails"] !== undefined ? data["movingThumbnails"].map((item: any) => (deserializeDrishtiVesperMovingThumbnail(item))) : undefined,
    thumbnails: data["thumbnails"] !== undefined ? data["thumbnails"].map((item: any) => (deserializeDrishtiVesperThumbnail(item))) : undefined,
  };
}

/**
 * Deep-linking data is used to construct a deep-link URI for an activity or
 * frame's embed, such that on click, the user is taken to the right place in a
 * mobile app. If the app is not installed, the user is taken to the app store.
 * If not on mobile, an analogous web uri is used.
 */
export interface EmbedsDeepLinkData {
  /**
   * Application ID (or project ID) from Google API Console.
   */
  appId?: bigint;
  /**
   * The data for a Google API Console client is entered by a developer during
   * client registration and is stored in PackagingService.
   */
  client?: EmbedsPackagingServiceClient[];
  /**
   * The ID for non-URL content. Embeds may either have no analogous web
   * presence or prefer a native mobile experience if supported. In the case of
   * no web presence, instead of setting the "url" field of an embed, such
   * developers will set this field and other content fields, e.g. thumbnail,
   * title, description. If set, this field is used to construct the deep-link
   * URI. Note that the native experience is preferred over the web link and the
   * web link is used as a fallback.
   */
  deepLinkId?: string;
  /**
   * Analogous web presence. Used as desktop fallback or when no native link
   * data is present.
   */
  url?: string;
}

function serializeEmbedsDeepLinkData(data: any): EmbedsDeepLinkData {
  return {
    ...data,
    appId: data["appId"] !== undefined ? String(data["appId"]) : undefined,
  };
}

function deserializeEmbedsDeepLinkData(data: any): EmbedsDeepLinkData {
  return {
    ...data,
    appId: data["appId"] !== undefined ? BigInt(data["appId"]) : undefined,
  };
}

/**
 * Represents an embedded object in an update. This is a wrapper class that can
 * contain a single specific item proto in an extension field. Think of it as a
 * base class like `Message` in Java. Each item proto must declare that it
 * extends this proto: message ExampleObject { option (item_type) =
 * EXAMPLE_OBJECT; extend EmbedClientItem { optional ExampleObject
 * example_object = ; } } See go/es-embeds for details.
 */
export interface EmbedsEmbedClientItem {
  /**
   * The canonical ID of the embed. If absent, the canonical ID is equal to the
   * ID; if present, then the canonical ID represents an "equivalence class" of
   * embeds which really refer to the same object. (For example, the URLs
   * http://www.foo.com/ and http://foo.com/ refer to the same object) This
   * field may be updated periodically by background processes.
   */
  canonicalId?: string;
  /**
   * Deep-linking data to take the user to the right place in a mobile app.
   * This is only used for preview and attribution. Links that are specific to a
   * given embed type should live on that specific embed's proto by using Link.
   * See http://goto.google.com/mariana-design.
   */
  deepLinkData?: EmbedsDeepLinkData;
  /**
   * The ID of the embed. This corresponds to the schema.org ID, as represented
   * in the ItemScope.id field.
   */
  id?: string;
  /**
   * The provenance of the embed, populated when the embed originated from a
   * web fetch. The provenance captures information about the web page the embed
   * had originated, like the URL that was retrieved and the retrieved URL's
   * canonical form. This is useful in the case where the URL shared by the URL
   * redirects (e.g., in the case of a shortened URL).
   */
  provenance?: EmbedsProvenance;
  /**
   * The ID used to identify the embed during rendering. This field will match
   * ID, if set, otherwise it will be the ID of the parent activity. This field
   * is only populated on the server for client use and is not persisted to
   * storage.
   */
  renderId?: string;
  /**
   * Signature of the embed, used for verification.
   */
  signature?: string;
  /**
   * Transient generic data that will not be saved on the server.
   */
  transientData?: EmbedsTransientData;
  /**
   * The first value in `type` determines which extension field will be set.
   * When creating an EmbedClientItem, you only need to set the first (primary)
   * type in this field. When the server receives the item, it will populate the
   * full type list using the parent annotations in the ItemType enum.
   */
  type?:  | "UNKNOWN" | "ACTION_V2" | "ADD_ACTION_V2" | "AGGREGATE_RATING_V2" | "ARTICLE_V2" | "ASSESS_ACTION_V2" | "AUDIO_OBJECT_V2" | "BASIC_INTERACTION_V2" | "BLOG_POSTING_V2" | "BLOG_V2" | "BOOK_V2" | "BUY_ACTION_V2" | "CHECK_IN_ACTION_V2" | "CHECKIN_V2" | "COLLEXION_V2" | "COMMENT_ACTION_V2" | "COMMENT_V2" | "COMMUNICATE_ACTION_V2" | "CONSUME_ACTION_V2" | "CREATE_ACTION_V2" | "CREATIVE_WORK_V2" | "DISCOVER_ACTION_V2" | "DOCUMENT_OBJECT_V2" | "DRAWING_OBJECT_V2" | "DRIVE_OBJECT_V2" | "EMOTISHARE_V2" | "ENTRY_POINT_V2" | "EVENT_TIME_V2" | "EVENT_V2" | "FILE_OBJECT_V2" | "FIND_ACTION_V2" | "FINANCIAL_QUOTE_V2" | "FORM_OBJECT_V2" | "GEO_COORDINATES_V2" | "GOOGLE_OFFER_V2" | "HANGOUT_CHAT_MESSAGE" | "HANGOUT_QUOTE" | "HANGOUT_V2" | "HOA_PLUS_EVENT_V2" | "IMAGE_OBJECT_V2" | "INTERACT_ACTION_V2" | "INTERACTION_V2" | "LISTEN_ACTION_V2" | "LOCAL_BUSINESS_V2" | "LOCAL_PLUS_PHOTO_ALBUM_V2" | "MAGAZINE_V2" | "MEDIA_OBJECT_V2" | "MOBILE_APPLICATION_V2" | "MOVIE_V2" | "MUSIC_ALBUM_V2" | "MUSIC_GROUP_V2" | "MUSIC_PLAYLIST_V2" | "MUSIC_RECORDING_V2" | "NEWS_ARTICLE_V2" | "OFFER_V2" | "ORGANIZATION_V2" | "ORGANIZE_ACTION_V2" | "PERSON_V2" | "PLACE_REVIEW_V2" | "PLACE_V2" | "PLAN_ACTION_V2" | "PLAY_MUSIC_ALBUM_V2" | "PLAY_MUSIC_TRACK_V2" | "PLAY_OBJECT_V2" | "PLUS_AUDIO_V2" | "PLUS_EVENT_V2" | "PLUS_MEDIA_COLLECTION_V2" | "PLUS_MEDIA_OBJECT_V2" | "PLUS_PAGE_V2" | "PLUS_PHOTOS_ADDED_TO_COLLECTION_V2" | "PLUS_PHOTO_ALBUM_V2" | "PLUS_PHOTO_COLLECTION_V2" | "PLUS_PHOTO_V2" | "PLUS_POST_V2" | "PLUS_RESHARE_V2" | "PLUS_SOFTWARE_APPLICATION_V2" | "POLL_OPTION_V2" | "POLL_V2" | "POSTAL_ADDRESS_V2" | "PRESENTATION_OBJECT_V2" | "PRODUCT_REVIEW_V2" | "RATING_V2" | "REACT_ACTION_V2" | "RESERVATION_V2" | "RESERVE_ACTION_V2" | "REVIEW_V2" | "REVIEW_ACTION_V2" | "SOFTWARE_APPLICATION_V2" | "SPREADSHEET_OBJECT_V2" | "SQUARE_INVITE_V2" | "SQUARE_V2" | "STICKER_V2" | "STORY_V2" | "THING_V2" | "TRADE_ACTION_V2" | "DEPRECATED_TOUR_OBJECT_V2" | "TV_EPISODE_V2" | "TV_SERIES_V2" | "UPDATE_ACTION_V2" | "VIEW_ACTION_V2" | "VIDEO_OBJECT_V2" | "VIDEO_GALLERY_V2" | "WANT_ACTION_V2" | "WEB_PAGE_V2" | "WRITE_ACTION_V2" | "YOUTUBE_CHANNEL_V2" | "GOOGLE_USER_PHOTO_V2" | "GOOGLE_USER_PHOTO_ALBUM" | "GOOGLE_PHOTO_RECIPE" | "THING" | "CREATIVE_WORK" | "EVENT" | "INTANGIBLE" | "ORGANIZATION" | "PERSON" | "PLACE" | "PRODUCT" | "ARTICLE" | "BLOG_POSTING" | "NEWS_ARTICLE" | "SCHOLARLY_ARTICLE" | "BLOG" | "BOOK" | "COMMENT" | "ITEM_LIST" | "MAP" | "MEDIA_OBJECT" | "AUDIO_OBJECT" | "IMAGE_OBJECT" | "MUSIC_VIDEO_OBJECT" | "VIDEO_OBJECT" | "MOVIE" | "MUSIC_PLAYLIST" | "MUSIC_ALBUM" | "MUSIC_RECORDING" | "PAINTING" | "PHOTOGRAPH" | "RECIPE" | "REVIEW" | "SCULPTURE" | "SOFTWARE_APPLICATION" | "MOBILE_APPLICATION" | "WEB_APPLICATION" | "TV_EPISODE" | "TV_SEASON" | "TV_SERIES" | "WEB_PAGE" | "ABOUT_PAGE" | "CHECKOUT_PAGE" | "COLLECTION_PAGE" | "IMAGE_GALLERY" | "VIDEO_GALLERY" | "CONTACT_PAGE" | "ITEM_PAGE" | "PROFILE_PAGE" | "SEARCH_RESULTS_PAGE" | "WEB_PAGE_ELEMENT" | "SITE_NAVIGATION_ELEMENT" | "TABLE" | "WP_AD_BLOCK" | "WP_FOOTER" | "WP_HEADER" | "WP_SIDEBAR" | "APP_INVITE" | "EMOTISHARE" | "BUSINESS_EVENT" | "CHILDRENS_EVENT" | "COMEDY_EVENT" | "DANCE_EVENT" | "EDUCATION_EVENT" | "FESTIVAL" | "FOOD_EVENT" | "LITERARY_EVENT" | "MUSIC_EVENT" | "SALE_EVENT" | "SOCIAL_EVENT" | "SPORTS_EVENT" | "THEATER_EVENT" | "VISUAL_ARTS_EVENT" | "RESERVATION" | "TRAVEL_EVENT" | "CORPORATION" | "EDUCATIONAL_ORGANIZATION" | "COLLEGE_OR_UNIVERSITY" | "ELEMENTARY_SCHOOL" | "HIGH_SCHOOL" | "MIDDLE_SCHOOL" | "PRESCHOOL" | "SCHOOL" | "GOVERNMENT_ORGANIZATION" | "LOCAL_BUSINESS" | "ANIMAL_SHELTER" | "AUTOMOTIVE_BUSINESS" | "AUTO_BODY_SHOP" | "AUTO_DEALER" | "AUTO_PARTS_STORE" | "AUTO_RENTAL" | "AUTO_REPAIR" | "AUTO_WASH" | "GAS_STATION" | "MOTORCYCLE_DEALER" | "MOTORCYCLE_REPAIR" | "CHILD_CARE" | "DRY_CLEANING_OR_LAUNDRY" | "EMERGENCY_SERVICE" | "FIRE_STATION" | "HOSPITAL" | "POLICE_STATION" | "EMPLOYMENT_AGENGY" | "ENTERTAINMENT_BUSINESS" | "ADULT_ENTERTAINMENT" | "AMUSEMENT_PARK" | "ART_GALLERY" | "CASINO" | "COMEDY_CLUB" | "MOVIE_THEATER" | "NIGHT_CLUB" | "FINANCIAL_SERVICE" | "ACCOUNTING_SERVICE" | "AUTOMATED_TELLER" | "BANK_OR_CREDIT_UNION" | "INSURANCE_AGENCY" | "FOOD_ESTABLISHMENT" | "BAKERY" | "BAR_OR_PUB" | "BREWERY" | "CAFE_OR_COFFEE_SHOP" | "FAST_FOOD_RESTAURANT" | "ICE_CREAM_SHOP" | "RESTAURANT" | "WINERY" | "GOVERNMENT_OFFICE" | "POST_OFFICE" | "HEALTH_AND_BEAUTY_BUSINESS" | "BEAUTY_SALON" | "DAY_SPA" | "HAIR_SALON" | "HEALTH_CLUB" | "NAIL_SALON" | "TATTOO_PARLOR" | "HOME_AND_CONSTRUCTION_BUSINESS" | "ELECTRICIAN" | "GENERAL_CONTRACTOR" | "HVAC_BUSINESS" | "HOUSE_PAINTER" | "LOCKSMITH" | "MOVING_COMPANY" | "PLUMBER" | "ROOFING_CONTRACTOR" | "INTERNET_CAFE" | "LIBRARY" | "LODGING_BUSINESS" | "BED_AND_BREAKFAST" | "HOSTEL" | "HOTEL" | "MOTEL" | "MEDICAL_ORGANIZATION" | "DENTIST" | "MEDICAL_CLINIC" | "OPTICIAN" | "PHARMACY" | "PHYSICIAN" | "VETERINARY_CARE" | "PROFESSIONAL_SERVICE" | "ATTORNEY" | "NOTARY" | "RADIO_STATION" | "REAL_ESTATE_AGENT" | "RECYCLING_CENTER" | "SELF_STORAGE" | "SHOPPING_CENTER" | "SPORTS_ACTIVITY_LOCATION" | "BOWLING_ALLEY" | "EXERCISE_GYM" | "GOLF_COURSE" | "PUBLIC_SWIMMING_POOL" | "SKI_RESORT" | "SPORTS_CLUB" | "STADIUM_OR_ARENA" | "TENNIS_COMPLEX" | "STORE" | "BIKE_STORE" | "BOOK_STORE" | "CLOTHING_STORE" | "COMPUTER_STORE" | "CONVENIENCE_STORE" | "DEPARTMENT_STORE" | "ELECTRONICS_STORE" | "FLORIST" | "FURNITURE_STORE" | "GARDEN_STORE" | "GROCERY_STORE" | "HARDWARE_STORE" | "HOBBY_SHOP" | "HOME_GOODS_STORE" | "JEWELRY_STORE" | "LIQUOR_STORE" | "MENS_CLOTHING_STORE" | "MOBILE_PHONE_STORE" | "MOVIE_RENTAL_STORE" | "MUSIC_STORE" | "OFFICE_EQUIPMENT_STORE" | "OUTLET_STORE" | "PAWN_SHOP" | "PET_STORE" | "SHOE_STORE" | "SPORTING_GOODS_STORE" | "TIRE_SHOP" | "TOY_STORE" | "WHOLESALE_STORE" | "TELEVISION_STATION" | "TOURIST_INFORMATION_CENTER" | "TRAVEL_AGENCY" | "PERFORMING_GROUP" | "MUSIC_GROUP" | "ADMINISTRATIVE_AREA" | "CITY" | "COUNTRY" | "STATE" | "CIVIC_STRUCTURE" | "AIRPORT" | "AQUARIUM" | "BEACH" | "BUS_STATION" | "BUS_STOP" | "CAMPGROUND" | "CEMETERY" | "CREMATORIUM" | "EVENT_VENUE" | "GOVERNMENT_BUILDING" | "CITY_HALL" | "COURTHOUSE" | "DEFENCE_ESTABLISHMENT" | "EMBASSY" | "LEGISLATIVE_BUILDING" | "MUSEUM" | "MUSIC_VENUE" | "PARK" | "PARKING_FACILITY" | "PERFORMING_ARTS_THEATER" | "PLACE_OF_WORSHIP" | "BUDDHIST_TEMPLE" | "CATHOLIC_CHURCH" | "CHURCH" | "HINDU_TEMPLE" | "MOSQUE" | "SYNAGOGUE" | "PLAYGROUND" | "R_V_PARK" | "RESIDENCE" | "APARTMENT_COMPLEX" | "GATED_RESIDENCE_COMMUNITY" | "SINGLE_FAMILY_RESIDENCE" | "TOURIST_ATTRACTION" | "SUBWAY_STATION" | "TAXI_STAND" | "TRAIN_STATION" | "ZOO" | "LANDFORM" | "BODY_OF_WATER" | "CANAL" | "LAKE_BODY_OF_WATER" | "OCEAN_BODY_OF_WATER" | "POND" | "RESERVOIR" | "RIVER_BODY_OF_WATER" | "SEA_BODY_OF_WATER" | "WATERFALL" | "CONTINENT" | "MOUNTAIN" | "VOLCANO" | "LANDMARKS_OR_HISTORICAL_BUILDINGS" | "USER_INTERACTION" | "USER_PLUS_ONES" | "ENUMERATION" | "BOOK_FORMAT_TYPE" | "ITEM_AVAILABILITY" | "OFFER_ITEM_CONDITION" | "JOB_POSTING" | "LANGUAGE" | "OFFER" | "QUANTITY" | "DISTANCE" | "DURATION" | "ENERGY" | "MASS" | "RATING" | "AGGREGATE_RATING" | "STRUCTURED_VALUE" | "CONTACT_POINT" | "POSTAL_ADDRESS" | "GEO_COORDINATES" | "GEO_SHAPE" | "NUTRITION_INFORMATION" | "PRESENTATION_OBJECT" | "DOCUMENT_OBJECT" | "SPREADSHEET_OBJECT" | "FORM_OBJECT" | "DRAWING_OBJECT" | "PLACE_REVIEW" | "FILE_OBJECT" | "PLAY_MUSIC_TRACK" | "PLAY_MUSIC_ALBUM" | "MAGAZINE" | "CAROUSEL_FRAME" | "PLUS_EVENT" | "HANGOUT" | "HANGOUT_BROADCAST" | "HANGOUT_CONSUMER" | "CHECKIN" | "EXAMPLE_OBJECT" | "SQUARE" | "SQUARE_INVITE" | "PLUS_PHOTO" | "PLUS_PHOTO_ALBUM" | "LOCAL_PLUS_PHOTO_ALBUM" | "PRODUCT_REVIEW" | "FINANCIAL_QUOTE" | "DEPRECATED_TOUR_OBJECT" | "PLUS_PAGE" | "GOOGLE_CHART" | "PLUS_PHOTOS_ADDED_TO_COLLECTION" | "RECOMMENDED_PEOPLE" | "PLUS_POST" | "DATE" | "DRIVE_OBJECT_COLLECTION" | "NEWS_MEDIA_ORGANIZATION" | "DYNAMITE_ATTACHMENT_METADATA" | "DYNAMITE_MESSAGE_METADATA"[];
}

function serializeEmbedsEmbedClientItem(data: any): EmbedsEmbedClientItem {
  return {
    ...data,
    deepLinkData: data["deepLinkData"] !== undefined ? serializeEmbedsDeepLinkData(data["deepLinkData"]) : undefined,
    provenance: data["provenance"] !== undefined ? serializeEmbedsProvenance(data["provenance"]) : undefined,
  };
}

function deserializeEmbedsEmbedClientItem(data: any): EmbedsEmbedClientItem {
  return {
    ...data,
    deepLinkData: data["deepLinkData"] !== undefined ? deserializeEmbedsDeepLinkData(data["deepLinkData"]) : undefined,
    provenance: data["provenance"] !== undefined ? deserializeEmbedsProvenance(data["provenance"]) : undefined,
  };
}

/**
 * Developers register a client in Google API Console to get the deep-linking
 * feature on Google+ posts or frames about their apps. The client data is
 * stored in this proto.
 */
export interface EmbedsPackagingServiceClient {
  /**
   * Android app's package name to generate the deep-link URI.
   */
  androidPackageName?: string;
  /**
   * iOS app's App Store ID to generate the App Store URL when app is not
   * installed on device.
   */
  iosAppStoreId?: string;
  /**
   * iOS app's bundle ID to generate the deep-link URI.
   */
  iosBundleId?: string;
  /**
   * Type of Google API Console client.
   */
  type?:  | "ANDROID" | "IOS";
}

/**
 * This field records where the ItemScope was retrieved, if it was created via
 * a web fetch.
 */
export interface EmbedsProvenance {
  /**
   * Annotation blob from Annotation Service.
   */
  annotationBlob?: Uint8Array;
  /**
   * Canonical url of the retrieved_url, if one was resolved during retrieval,
   * for example, if a rel="canonical" link tag was provided in the retrieved
   * web page.
   */
  canonicalUrl?: string;
  /**
   * The url originally passed in the PRS request, which should be used to
   * re-discover the content. Note that this URL may be a forwarding service or
   * link shortener (bit.ly), so it should not be assumed to be canonical, but
   * should be used for navigation back to the original source of the itemscope.
   */
  inputUrl?: string;
  /**
   * Contains exact types as parsed, whether or not we recognized that type at
   * parse time. If an itemscope is created by merging SchemaOrg markup and open
   * graph markup then the first itemtype would be schemaorg type, the second
   * would be open graph and so on. example: http://schema.org/VideoObject,
   * og:video.movie Plain text; usually a URL
   */
  itemtype?: string[];
  /**
   * The server retrieved timestamp (in msec).
   */
  retrievedTimestampMsec?: bigint;
  /**
   * The final URL that was the actual source of the itemscope, after any
   * redirects.
   */
  retrievedUrl?: string;
}

function serializeEmbedsProvenance(data: any): EmbedsProvenance {
  return {
    ...data,
    annotationBlob: data["annotationBlob"] !== undefined ? encodeBase64(data["annotationBlob"]) : undefined,
    retrievedTimestampMsec: data["retrievedTimestampMsec"] !== undefined ? String(data["retrievedTimestampMsec"]) : undefined,
  };
}

function deserializeEmbedsProvenance(data: any): EmbedsProvenance {
  return {
    ...data,
    annotationBlob: data["annotationBlob"] !== undefined ? decodeBase64(data["annotationBlob"] as string) : undefined,
    retrievedTimestampMsec: data["retrievedTimestampMsec"] !== undefined ? BigInt(data["retrievedTimestampMsec"]) : undefined,
  };
}

/**
 * Transient generic data that will not be saved on the server.
 */
export interface EmbedsTransientData {
}

/**
 * An EventId is a 128 bit identifier that uniquely identifies an event, such
 * as a query. The event time recorded to the nearest microsecond, along with
 * information about the process generating the event, ensures that all EventIds
 * are unique. Details of this EventId are described in a design document:
 * http://www/eng/designdocs/sawmill/adlogs.html
 */
export interface EventIdMessage {
  /**
   * process_id is an integer that identifies the process on this machine that
   * generated this event. This id is calculated once when the server generates
   * its first event, and may change if the process is migrated to a different
   * host. This field has a very specific format mandated by the logs collection
   * infrastructure, which is subject to change WITHOUT NOTICE. As of
   * 2013-01-09, this format is: uint32 process_id = (time(NULL) << 24) +
   * (getpid() & 0xFFFFFF); If you are generating an extended_pid directly, you
   * MUST use one of the maintained library implementations in order to generate
   * it properly: C++ //borg/borgletlib:extended_pid; call borg::ExtendedPid()
   * Python //borg/borgletlib/python:pyextendedpid; call ExtendedPid() Go
   * //borg/borgletlib/go:extendedpid; call Get() Java
   * //java/com/google/common/logging; call EventId.getPid() If you think that
   * you need to parse the values of this field, please contact
   * logs-collection-dev@ to discuss your requirement.
   */
  processId?: number;
  /**
   * server_ip is the IPv4 address or http://go/ghostid of the machine running
   * the server that created this event message. This allows us to distinguish
   * between events that occur at the same time on different servers. Format:
   * 10.1.2.3 is stored as 0x0a010203, and GHostId 1 as 0x00000001.
   */
  serverIp?: number;
  /**
   * time_usec is the number of microseconds since the epoch (i.e., since
   * 1970-01-01 00:00:00 UTC) as an int64: 1e6 * (unix time) + microseconds.
   * Applications must ensure that EventIdMessages have increasing times,
   * artificially increasing time_usec to one greater than the previous value if
   * necessary. Alternate implementations were considered: 1. storing unix time
   * and microseconds separately would require a bit more storage, and the
   * convenience of having a single value representing the time seemed more
   * useful than having trivial access to a unix time. 2. storing unix time in
   * the upper 32 bits would allow for more precision - up to 4G events/second,
   * but it wouldn't print nicely as a decimal value and it seems unlikely that
   * any single server would ever sustain more than 1M events/second. 3.
   * Java-compatible time uses millis - this would limit servers to 1000 events
   * per second - too small. Other names for this field were considered,
   * including time, time_stamp, and utime. We felt that including the units in
   * the name would tend to produce more readable code. utime might be
   * interpreted as user time. unix timestamp * 1e6 + microseconds
   */
  timeUsec?: bigint;
}

function serializeEventIdMessage(data: any): EventIdMessage {
  return {
    ...data,
    timeUsec: data["timeUsec"] !== undefined ? String(data["timeUsec"]) : undefined,
  };
}

function deserializeEventIdMessage(data: any): EventIdMessage {
  return {
    ...data,
    timeUsec: data["timeUsec"] !== undefined ? BigInt(data["timeUsec"]) : undefined,
  };
}

/**
 * the extra info response from ascorer used to build snippets in GWS
 * experiments
 */
export interface ExtraSnippetInfoResponse {
  matchinfo?: ExtraSnippetInfoResponseMatchInfo;
  querysubitem?: ExtraSnippetInfoResponseQuerySubitem[];
  tidbit?: ExtraSnippetInfoResponseTidbit[];
}

function serializeExtraSnippetInfoResponse(data: any): ExtraSnippetInfoResponse {
  return {
    ...data,
    matchinfo: data["matchinfo"] !== undefined ? serializeExtraSnippetInfoResponseMatchInfo(data["matchinfo"]) : undefined,
    tidbit: data["tidbit"] !== undefined ? data["tidbit"].map((item: any) => (serializeExtraSnippetInfoResponseTidbit(item))) : undefined,
  };
}

function deserializeExtraSnippetInfoResponse(data: any): ExtraSnippetInfoResponse {
  return {
    ...data,
    matchinfo: data["matchinfo"] !== undefined ? deserializeExtraSnippetInfoResponseMatchInfo(data["matchinfo"]) : undefined,
    tidbit: data["tidbit"] !== undefined ? data["tidbit"].map((item: any) => (deserializeExtraSnippetInfoResponseTidbit(item))) : undefined,
  };
}

export interface ExtraSnippetInfoResponseMatchInfo {
  /**
   * bitvector of query items matching the title
   */
  titleMatches?: bigint;
  /**
   * bitvector of query items matching the url
   */
  urlMatches?: bigint;
  /**
   * bitvector of query items considered by chooser
   */
  weightedItems?: bigint;
}

function serializeExtraSnippetInfoResponseMatchInfo(data: any): ExtraSnippetInfoResponseMatchInfo {
  return {
    ...data,
    titleMatches: data["titleMatches"] !== undefined ? String(data["titleMatches"]) : undefined,
    urlMatches: data["urlMatches"] !== undefined ? String(data["urlMatches"]) : undefined,
    weightedItems: data["weightedItems"] !== undefined ? String(data["weightedItems"]) : undefined,
  };
}

function deserializeExtraSnippetInfoResponseMatchInfo(data: any): ExtraSnippetInfoResponseMatchInfo {
  return {
    ...data,
    titleMatches: data["titleMatches"] !== undefined ? BigInt(data["titleMatches"]) : undefined,
    urlMatches: data["urlMatches"] !== undefined ? BigInt(data["urlMatches"]) : undefined,
    weightedItems: data["weightedItems"] !== undefined ? BigInt(data["weightedItems"]) : undefined,
  };
}

/**
 * A query term, phrase, or synonym. An original query term or phrase is called
 * an "item". Each item may have more than one "subitem" if there are synonyms.
 * In rare cases a subitem may correspond to multiple items, such as the subitem
 * "cia" in the query [central intelligence agency].
 */
export interface ExtraSnippetInfoResponseQuerySubitem {
  /**
   * Additional information from the SnippetQuery.
   */
  isHighlighted?: boolean;
  isOptional?: boolean;
  /**
   * true iff this subitem was an original query term or phrase. Can only be
   * false if want_all_query_subitems == true in the request.
   */
  isOriginal?: boolean;
  /**
   * a bitvector of the query items corresponding to this subitem. Typically
   * only one bit is set, but see comment above.
   */
  items?: number;
  /**
   * text associated with this query item
   */
  text?: string;
  /**
   * the weight of this query item, as calculated by SubitemWeight():
   * https://qwiki.corp.google.com/display/Q/SnippetWeights
   */
  weight?: number;
}

export interface ExtraSnippetInfoResponseTidbit {
  anchorinfo?: ExtraSnippetInfoResponseTidbitAnchorInfo;
  /**
   * For tidbits only: position of tidbit in the document. More specifically,
   * tidbit is found at [begin, end) in the document's tokens.
   */
  begin?: number;
  end?: number;
  /**
   * a bitvector of each query term within this tidbit
   */
  items?: bigint;
  /**
   * the score for this tidbit if there was one this is returned for Snippets
   * and Tidbits and is only meaningful for comparing between objects of the
   * same type (snippet to snippet, tidbit to tidbit)
   */
  score?: number;
  /**
   * the tidbit text, with search terms already highlighted
   */
  text?: string;
  type?:  | "TIDBIT" | "BODY" | "META" | "GWD" | "FULL" | "ANCHOR";
}

function serializeExtraSnippetInfoResponseTidbit(data: any): ExtraSnippetInfoResponseTidbit {
  return {
    ...data,
    items: data["items"] !== undefined ? String(data["items"]) : undefined,
  };
}

function deserializeExtraSnippetInfoResponseTidbit(data: any): ExtraSnippetInfoResponseTidbit {
  return {
    ...data,
    items: data["items"] !== undefined ? BigInt(data["items"]) : undefined,
  };
}

/**
 * this information is specific to anchors and is only returned if type ==
 * ANCHOR
 */
export interface ExtraSnippetInfoResponseTidbitAnchorInfo {
  offdomainCount?: number;
  ondomainCount?: number;
}

export interface FaceIndexing {
  /**
   * Always use image/search/utils/face_proto_util.h for packing and unpacking
   * these values.
   */
  mustangBytes?: Uint8Array;
  mustangBytesVersion?: number;
}

function serializeFaceIndexing(data: any): FaceIndexing {
  return {
    ...data,
    mustangBytes: data["mustangBytes"] !== undefined ? encodeBase64(data["mustangBytes"]) : undefined,
  };
}

function deserializeFaceIndexing(data: any): FaceIndexing {
  return {
    ...data,
    mustangBytes: data["mustangBytes"] !== undefined ? decodeBase64(data["mustangBytes"] as string) : undefined,
  };
}

export interface FatcatCompactBinaryClassification {
  /**
   * Either binary_classifier will be set, using the enum above, or
   * binary_classifier_name will be set, if it is not one of the classifiers in
   * the enum - never both.
   */
  binaryClassifier?:  | "BLOG" | "FORUM" | "LOGIN" | "B2B_OK" | "IMAGES" | "SOCIAL" | "PURCHASING_INTENT" | "PORN" | "ADULTISH" | "VIOLENCE_GORE" | "GOSSIP";
  binaryClassifierName?: string;
  /**
   * A CompactDocClassification will not usually have a weight. For a
   * CompactSiteClassification, this value will be 0...127 corresponding to
   * 0.0...1.0, indicating fraction of the site that this label applies to
   */
  discreteFraction?: number;
}

/**
 * The result of PetacatAnnotator. Each result contains: 1. RephilClusters; 2.
 * At most 5 verticals from each taxonomy, sorted by the probabilities in
 * descending order. 3. Binary classification results about page types and
 * sensitive content. The types of taxonomies include: verticals4, geo,
 * verticals4_geo, products_services, icm_im_audiences and icm_im_audiences_dev.
 */
export interface FatcatCompactDocClassification {
  binary?: FatcatCompactBinaryClassification[];
  clusters?: FatcatCompactRephilClusters;
  epoch?: string;
  langCode?: string;
  /**
   * The id of the Rephil model used to generate the Rephil clusters. If it is
   * absent, Rephil 4 is assumed.
   */
  rephilModelId?: number;
  taxonomic?: FatcatCompactTaxonomicClassification[];
  /**
   * not needed if the url is the sstable / bigtable key used during
   * intermediate processing only
   */
  url?: string;
  /**
   * The relative weight of this doc within a site, typically something like
   * pagerank or navboost impressions. May be a large number (like an actual
   * pageviews estimate), not limited to a small range.
   */
  weight?: bigint;
}

function serializeFatcatCompactDocClassification(data: any): FatcatCompactDocClassification {
  return {
    ...data,
    weight: data["weight"] !== undefined ? String(data["weight"]) : undefined,
  };
}

function deserializeFatcatCompactDocClassification(data: any): FatcatCompactDocClassification {
  return {
    ...data,
    weight: data["weight"] !== undefined ? BigInt(data["weight"]) : undefined,
  };
}

export interface FatcatCompactRephilClusters {
  cluster?: FatcatCompactRephilClustersCluster[];
}

export interface FatcatCompactRephilClustersCluster {
  /**
   * 0...127 corresponds to 0.0 - 1.0
   */
  discreteWeight?: number;
  id?: number;
}

/**
 * A version of this proto for logging is available at
 * cs/symbol:logged_fatcat.LoggedCompactTaxonomicClassification
 */
export interface FatcatCompactTaxonomicClassification {
  category?: FatcatCompactTaxonomicClassificationCategory[];
  classifierVersion?: string;
  /**
   * Either taxonomy will be set, using the enum above, or taxonomy_name will
   * be set (if the taxonomy is not one of the ones in the enum) - never both
   */
  taxonomy?:  | "VERTICALS" | "VERTICALS4" | "VERTICALS4_GEO" | "GEO" | "PRODUCTS_SERVICES" | "ICM_IM_AUDIENCES" | "ICM_IM_AUDIENCES_DEV";
  taxonomyName?: string;
}

/**
 * A taxonomic category. A classification consists of weight (totalling 1.0)
 * distributed among one or more categories.
 */
export interface FatcatCompactTaxonomicClassificationCategory {
  /**
   * go/petacat-faq#how-should-i-interpret-classification-weights Discrete to
   * reduce size. Range is [0,127], corresponding to [0.0,1.0].
   */
  discreteWeight?: number;
  /**
   * The category's ID, e.g. 20 for /Sports in the go/verticals4 taxonomy.
   */
  id?: number;
}

/**
 * http://go/contact-detail-hash.
 */
export interface FocusBackendContactDetailHash {
  type?:  | "UNSPECIFIED" | "PHONE" | "EMAIL";
  /**
   * The hash here will be a 16-bit weak hash to avoid reverse engineering for
   * decoding the actual contact detail. The hash value is computed by the
   * fingerprint of the raw contact detail mod 2^16.
   */
  value?: number;
}

/**
 * A contact pointer that represents a contact
 * (http://go/assistant-contact-id).
 */
export interface FocusBackendContactPointer {
  /**
   * The annotation ID. Annotations are only allowed to point to annotations
   * that do not themselves have a pointer (avoids any possibilty of loops).
   * Cast this field to string in javascript to make it compile in js.
   */
  annotationId?: bigint;
  /**
   * The raw contact ID from an active mobile device of the user.
   */
  deviceRawContactId?: FocusBackendDeviceRawContactId;
  /**
   * The contact ID from the Focus backend. Cast this field to string in
   * javascript to make it compile in js.
   */
  focusContactId?: bigint;
  /**
   * Additional contact ids that are not actively used to match contact
   * pointers to contacts.
   */
  otherContactId?: FocusBackendOtherContactId;
  /**
   * The secondary identifier of contact. It will be used when the primary ID
   * doesn't match any contact.
   */
  secondaryId?: FocusBackendSecondaryContactId;
}

function serializeFocusBackendContactPointer(data: any): FocusBackendContactPointer {
  return {
    ...data,
    annotationId: data["annotationId"] !== undefined ? String(data["annotationId"]) : undefined,
    deviceRawContactId: data["deviceRawContactId"] !== undefined ? serializeFocusBackendDeviceRawContactId(data["deviceRawContactId"]) : undefined,
    focusContactId: data["focusContactId"] !== undefined ? String(data["focusContactId"]) : undefined,
    otherContactId: data["otherContactId"] !== undefined ? serializeFocusBackendOtherContactId(data["otherContactId"]) : undefined,
    secondaryId: data["secondaryId"] !== undefined ? serializeFocusBackendSecondaryContactId(data["secondaryId"]) : undefined,
  };
}

function deserializeFocusBackendContactPointer(data: any): FocusBackendContactPointer {
  return {
    ...data,
    annotationId: data["annotationId"] !== undefined ? BigInt(data["annotationId"]) : undefined,
    deviceRawContactId: data["deviceRawContactId"] !== undefined ? deserializeFocusBackendDeviceRawContactId(data["deviceRawContactId"]) : undefined,
    focusContactId: data["focusContactId"] !== undefined ? BigInt(data["focusContactId"]) : undefined,
    otherContactId: data["otherContactId"] !== undefined ? deserializeFocusBackendOtherContactId(data["otherContactId"]) : undefined,
    secondaryId: data["secondaryId"] !== undefined ? deserializeFocusBackendSecondaryContactId(data["secondaryId"]) : undefined,
  };
}

/**
 * //////////////////// DeviceContactId ////////////////////// Used by Device
 * Contacts only. For more details see go/fbs-support-for-device-contacts.
 */
export interface FocusBackendDeviceContactId {
  /**
   * DeviceContact Id.
   */
  ContactId?: bigint;
  /**
   * Device Id.
   */
  DeviceId?: FocusBackendDeviceId;
}

function serializeFocusBackendDeviceContactId(data: any): FocusBackendDeviceContactId {
  return {
    ...data,
    ContactId: data["ContactId"] !== undefined ? String(data["ContactId"]) : undefined,
    DeviceId: data["DeviceId"] !== undefined ? serializeFocusBackendDeviceId(data["DeviceId"]) : undefined,
  };
}

function deserializeFocusBackendDeviceContactId(data: any): FocusBackendDeviceContactId {
  return {
    ...data,
    ContactId: data["ContactId"] !== undefined ? BigInt(data["ContactId"]) : undefined,
    DeviceId: data["DeviceId"] !== undefined ? deserializeFocusBackendDeviceId(data["DeviceId"]) : undefined,
  };
}

/**
 * //////////////////// DeviceId ////////////////////// Used by Device Contacts
 * only. For more details see go/fbs-support-for-device-contacts.
 */
export interface FocusBackendDeviceId {
  /**
   * The GServices id on Android. See go/android-id.
   */
  AndroidDeviceId?: bigint;
  /**
   * DeviceId.Hash is a SHA256 of some attribute of the user and device. For
   * Android devices: Hash = SHA256(gaia_account_name + : + 1 + : +
   * (android id - LSB)); For iOS devices: Hash =
   * TOLOWER(HEX(GMCSComputeUserDeviceToken(userId, iOsDeviceId)) For more
   * details see go/client-instance-id.
   */
  Hash?: string;
}

function serializeFocusBackendDeviceId(data: any): FocusBackendDeviceId {
  return {
    ...data,
    AndroidDeviceId: data["AndroidDeviceId"] !== undefined ? String(data["AndroidDeviceId"]) : undefined,
  };
}

function deserializeFocusBackendDeviceId(data: any): FocusBackendDeviceId {
  return {
    ...data,
    AndroidDeviceId: data["AndroidDeviceId"] !== undefined ? BigInt(data["AndroidDeviceId"]) : undefined,
  };
}

/**
 * //////////////////// DeviceRawContactId ////////////////////// Used by
 * Device Contacts Only. The Raw ID as assigned to the original contact on the
 * device. For more details see go/fbs-support-for-device-contacts.
 */
export interface FocusBackendDeviceRawContactId {
  DeviceId?: FocusBackendDeviceId;
  /**
   * Raw ID assigned by the device. Cast this field to string in javascript to
   * make it compile in js.
   */
  RawContactId?: bigint;
}

function serializeFocusBackendDeviceRawContactId(data: any): FocusBackendDeviceRawContactId {
  return {
    ...data,
    DeviceId: data["DeviceId"] !== undefined ? serializeFocusBackendDeviceId(data["DeviceId"]) : undefined,
    RawContactId: data["RawContactId"] !== undefined ? String(data["RawContactId"]) : undefined,
  };
}

function deserializeFocusBackendDeviceRawContactId(data: any): FocusBackendDeviceRawContactId {
  return {
    ...data,
    DeviceId: data["DeviceId"] !== undefined ? deserializeFocusBackendDeviceId(data["DeviceId"]) : undefined,
    RawContactId: data["RawContactId"] !== undefined ? BigInt(data["RawContactId"]) : undefined,
  };
}

/**
 * Additional contact ids that are not actively used to match contact pointers
 * to contacts. There may be overlap with primary or secondary contact ids.
 */
export interface FocusBackendOtherContactId {
  /**
   * Device contact ID, when available: - The annotation points to a device
   * contact, and the device contact id was correctly populated when the
   * annotation was created. Note that the device contact id is populated once
   * per device contact on a device. It is distinct from RawContactId - a single
   * device contact may have multiple raw contact ids. - The annotation points
   * to a Focus contact that was merged with device contact information in
   * Starlight. When the annotation was created, a device contact id was
   * available on the merged person object. - The contact annotation was created
   * from April 2021 onwards. All prior annotations do not populate this field.
   * ContactPointer creation relies on the client caller to correctly populate
   * the device contact id, and does not enforce any assumptions on availability
   * of this field. This field is repeated because in rare cases Starlight may
   * merge device contact information across different devices into a single
   * merged person object. WARNING: Use with extreme caution! This ID is not
   * stable. For more details see go/fbs-support-for-device-contacts.
   */
  deviceContactId?: FocusBackendDeviceContactId[];
}

function serializeFocusBackendOtherContactId(data: any): FocusBackendOtherContactId {
  return {
    ...data,
    deviceContactId: data["deviceContactId"] !== undefined ? data["deviceContactId"].map((item: any) => (serializeFocusBackendDeviceContactId(item))) : undefined,
  };
}

function deserializeFocusBackendOtherContactId(data: any): FocusBackendOtherContactId {
  return {
    ...data,
    deviceContactId: data["deviceContactId"] !== undefined ? data["deviceContactId"].map((item: any) => (deserializeFocusBackendDeviceContactId(item))) : undefined,
  };
}

/**
 * The secondary ID of a contact.
 */
export interface FocusBackendSecondaryContactId {
  /**
   * The hashes of the contact details (e.g. phone number and email address).
   */
  contactDetailHash?: FocusBackendContactDetailHash[];
  /**
   * The contact's full name, not hashed.
   */
  contactName?: string;
  /**
   * The hash of contact's full name, generated using Fingerprint2011(). Cast
   * this field to string in javascript to make it compile in js.
   */
  contactNameHash?: bigint;
}

function serializeFocusBackendSecondaryContactId(data: any): FocusBackendSecondaryContactId {
  return {
    ...data,
    contactNameHash: data["contactNameHash"] !== undefined ? String(data["contactNameHash"]) : undefined,
  };
}

function deserializeFocusBackendSecondaryContactId(data: any): FocusBackendSecondaryContactId {
  return {
    ...data,
    contactNameHash: data["contactNameHash"] !== undefined ? BigInt(data["contactNameHash"]) : undefined,
  };
}

/**
 * Citation contains the information needed to correctly attribute the source
 * of data.
 */
export interface FreebaseCitation {
  /**
   * Mid of the dataset.
   */
  dataset?: string;
  /**
   * If set to true, the citation is required to be displayed when the data is
   * used.
   */
  isAttributionRequired?: boolean;
  /**
   * Name of the project of the data's origin.
   */
  project?: string;
  /**
   * The name of the provider of this information.
   */
  provider?: string;
  /**
   * A human readable statement of attribution.
   */
  statement?: string;
  /**
   * Uri link associated with this data.
   */
  uri?: string;
}

/**
 * An Id contains the identifiers used to reference this topic (entity) in the
 * Knowledge Graph. The Knowledge Graph supports several forms of identifiers: -
 * "mids" (machine ids) that are assigned at creation time, and support a
 * resolution mechanism that tracks topics after they are merged (for more about
 * mids, see go/kg-mid), - "ids" are human-readable ids (HRIDs) that are derived
 * from a namespace hierarchy stored in Knowledge Graph, and a set of rules, -
 * "guids" are low-level ids historically used in Freebase (pre-Knowledge Graph,
 * deprecated). Only the mid and id are supplied here. Note that mids can be
 * converted to guids or uint64s (see //metaweb/util/mid/mid.h).
 */
export interface FreebaseId {
  /**
   * "id" may be a human readable ID (HRID) or a MID. Originally it was
   * intended to always be a human readable ID, but that convention was not
   * always followed so clients should be wary. Not every topic has an id.
   */
  id?: string;
  /**
   * The "mid" should be used whenever a globally unique, primary key into the
   * Knowledge Graph is needed. These keys are always prefixed with the "/m" and
   * "/g", (and more rarely the "/x" and "/t") namespaces, and are alphanumeric
   * strings consisting of lowercase letters excluding vowels, numbers and the
   * underscore character. (Applications should not assume a constant length for
   * these strings as Livegraph reserves the right to extend the number of
   * characters to accommodate more topics.)
   */
  mid?: string;
}

/**
 * Represents a geopoint, which is one of the possible Value types.
 */
export interface FreebaseLatLong {
  latDeg?: number;
  longDeg?: number;
}

/**
 * Represents a measurements, which is one of the possible Value types. A
 * measurement value like "5.2 meter^2 / second" would be represented as:
 * magnitude: 5.2 unit { unit_mid: "/m/mid_for_meter" power: 2 } unit {
 * unit_mid: "/m/mid_for_second" power: -1 }
 */
export interface FreebaseMeasurement {
  magnitude?: number;
  /**
   * Repeated units are interpreted as a product. i.e. (meter ^ 1) * (second ^
   * -2)
   */
  unit?: FreebaseMeasurementUnit[];
}

export interface FreebaseMeasurementUnit {
  power?: number;
  unit?: FreebaseId;
  /**
   * Deprecated fields.
   */
  unitMid?: string;
}

/**
 * List of { predicate, { object } } to be processed as a Nested Struct. Nested
 * Struct can be recursive. NestedStruct.property_value(i).value(j) may have
 * nested_struct field.
 */
export interface FreebaseNestedStruct {
  propertyValue?: FreebasePropertyValue[];
}

function serializeFreebaseNestedStruct(data: any): FreebaseNestedStruct {
  return {
    ...data,
    propertyValue: data["propertyValue"] !== undefined ? data["propertyValue"].map((item: any) => (serializeFreebasePropertyValue(item))) : undefined,
  };
}

function deserializeFreebaseNestedStruct(data: any): FreebaseNestedStruct {
  return {
    ...data,
    propertyValue: data["propertyValue"] !== undefined ? data["propertyValue"].map((item: any) => (deserializeFreebasePropertyValue(item))) : undefined,
  };
}

/**
 * A PropertyValue associates properties with values in the context of a topic.
 */
export interface FreebasePropertyValue {
  /**
   * The id of the property.
   */
  property?: FreebaseId;
  /**
   * Indicates the total values that exist for this property, even if they
   * aren't all present in the value field, due to truncation.
   */
  totalValueCount?: bigint;
  /**
   * The value associated with the property for the containing topic.
   */
  value?: FreebaseValue[];
  /**
   * If ValueStatus is not set at all, the implication is that there are
   * well-known value(s), specified in the "value" field. (It should be
   * considered malformed data to have value_status set when len(values) > 0.)
   */
  valueStatus?:  | "HAS_UNKNOWN_VALUE" | "HAS_NO_VALUE";
}

function serializeFreebasePropertyValue(data: any): FreebasePropertyValue {
  return {
    ...data,
    totalValueCount: data["totalValueCount"] !== undefined ? String(data["totalValueCount"]) : undefined,
    value: data["value"] !== undefined ? data["value"].map((item: any) => (serializeFreebaseValue(item))) : undefined,
  };
}

function deserializeFreebasePropertyValue(data: any): FreebasePropertyValue {
  return {
    ...data,
    totalValueCount: data["totalValueCount"] !== undefined ? BigInt(data["totalValueCount"]) : undefined,
    value: data["value"] !== undefined ? data["value"].map((item: any) => (deserializeFreebaseValue(item))) : undefined,
  };
}

/**
 * A Topic represents a Knowledge Graph entity with its associated properties
 * and their values.
 */
export interface FreebaseTopic {
  /**
   * The id (mid and human-readable id) of the topic. The id will always be
   * present and will contain a mid value for topics in the topic sstable.
   */
  id?: FreebaseId;
  /**
   * The property-value bindings associated with the topic. Note that in the
   * case where a property is relevant to a topic based on its type, but no
   * values of that property are present for the topic, the PropertyValue will
   * simply not appear, rather than being present with a null value, or empty
   * repeated value list.
   */
  propertyValue?: FreebasePropertyValue[];
}

function serializeFreebaseTopic(data: any): FreebaseTopic {
  return {
    ...data,
    propertyValue: data["propertyValue"] !== undefined ? data["propertyValue"].map((item: any) => (serializeFreebasePropertyValue(item))) : undefined,
  };
}

function deserializeFreebaseTopic(data: any): FreebaseTopic {
  return {
    ...data,
    propertyValue: data["propertyValue"] !== undefined ? data["propertyValue"].map((item: any) => (deserializeFreebasePropertyValue(item))) : undefined,
  };
}

/**
 * Values are effectively a union of several possible Knowledge Graph types:
 * simple primitive datatypes such as booleans, integers and floats, references
 * to other Knowledge Graph topics (by id), or "compound values" which are
 * expressed as embedded topics with associated properties and values. Values
 * occur in indexed order (if any).
 */
export interface FreebaseValue {
  /**
   * key, uri, or datetime. Present when value is bool.
   */
  boolValue?: boolean;
  /**
   * Citation data for this value. See: http://go/kg-clap
   */
  citation?: FreebaseCitation;
  /**
   * Compound values are those that contain either a number of simple valued
   * facets (such as a latitude/longitude pair), or "mediator" topics
   * representing multi-dimensional relationships between topics. In both cases
   * we represent them here with an embedded topic, although the topic's
   * identity is somewhat secondary to the property/value pairs it contains.
   * (The identity is still made available so that it can be used to perform
   * updates to that mediator on the Knowledge Graph.)
   */
  compoundValue?: FreebaseTopic;
  /**
   * Deletion provenance for this value.
   */
  deletionProvenance?: StorageGraphBfgTripleProvenance[];
  /**
   * The lang of the display_value field.
   */
  displayLang?: string;
  /**
   * The display value of this value. This is a i18n-aware formatted value if
   * present.
   */
  displayValue?: string;
  /**
   * An optional name for a proto field.
   */
  expectedProto?: string;
  /**
   * Present when value is float.
   */
  floatValue?: number;
  /**
   * Present when value is an id.
   */
  idValue?: FreebaseId;
  /**
   * Index of the value relative to the containing property (if any). Knowledge
   * Graph supports a loose notion of indexing: some non-unique properties may
   * have indices, while others may not. Furthermore, for a single property,
   * some values may have indices (such as the top 5 actors in a film), while
   * others may not (the film's supporting cast). Un-indexed values will appear
   * at the end of the repeated value list. This field contains the index value
   * only when is present in the Knowledge Graph.
   */
  index?: bigint;
  /**
   * Present when value is int.
   */
  intValue?: bigint;
  /**
   * Whenever the value is text with TYPE_TEXT, the lang field is populated
   * with the III LanguageCode associated with the string_value field.
   */
  lang?: string;
  latLongValue?: FreebaseLatLong;
  measurementValue?: FreebaseMeasurement;
  /**
   * Populated if this value holds NestedStruct. 'type' field needs to be set
   * to TYPE_NESTED_STRUCT.
   */
  nestedStruct?: FreebaseNestedStruct;
  /**
   * Provenance for this value.
   */
  provenance?: StorageGraphBfgTripleProvenance[];
  /**
   * Similar to string_value/etc but contains raw bytes.
   */
  rawValue?: Uint8Array;
  /**
   * Present when value is text, enum,
   */
  stringValue?: string;
  subgraphId?: bigint[];
  /**
   * The ISO-8601 timestamp corresponding to when this value was created (when
   * it was written to the Knowledge Graph). Deprecated in favor of
   * timestamp_usec.
   */
  timestamp?: string;
  /**
   * The microsecond timestamp corresponding to when this value was created.
   */
  timestampUsec?: bigint;
  type?:  | "TYPE_NULL" | "TYPE_ID" | "TYPE_TEXT" | "TYPE_ENUM" | "TYPE_KEY" | "TYPE_URI" | "TYPE_DATETIME" | "TYPE_BOOL" | "TYPE_INT" | "TYPE_FLOAT" | "TYPE_COMPOUND" | "TYPE_PROTO" | "TYPE_EXTENSION" | "TYPE_NESTED_STRUCT" | "TYPE_SEMANTIC_REFERENCE" | "TYPE_LAT_LONG" | "TYPE_MEASUREMENT" | "TYPE_HAS_VALUE" | "TYPE_HAS_NO_VALUE";
}

function serializeFreebaseValue(data: any): FreebaseValue {
  return {
    ...data,
    compoundValue: data["compoundValue"] !== undefined ? serializeFreebaseTopic(data["compoundValue"]) : undefined,
    deletionProvenance: data["deletionProvenance"] !== undefined ? data["deletionProvenance"].map((item: any) => (serializeStorageGraphBfgTripleProvenance(item))) : undefined,
    index: data["index"] !== undefined ? String(data["index"]) : undefined,
    intValue: data["intValue"] !== undefined ? String(data["intValue"]) : undefined,
    nestedStruct: data["nestedStruct"] !== undefined ? serializeFreebaseNestedStruct(data["nestedStruct"]) : undefined,
    provenance: data["provenance"] !== undefined ? data["provenance"].map((item: any) => (serializeStorageGraphBfgTripleProvenance(item))) : undefined,
    rawValue: data["rawValue"] !== undefined ? encodeBase64(data["rawValue"]) : undefined,
    subgraphId: data["subgraphId"] !== undefined ? data["subgraphId"].map((item: any) => (String(item))) : undefined,
    timestampUsec: data["timestampUsec"] !== undefined ? String(data["timestampUsec"]) : undefined,
  };
}

function deserializeFreebaseValue(data: any): FreebaseValue {
  return {
    ...data,
    compoundValue: data["compoundValue"] !== undefined ? deserializeFreebaseTopic(data["compoundValue"]) : undefined,
    deletionProvenance: data["deletionProvenance"] !== undefined ? data["deletionProvenance"].map((item: any) => (deserializeStorageGraphBfgTripleProvenance(item))) : undefined,
    index: data["index"] !== undefined ? BigInt(data["index"]) : undefined,
    intValue: data["intValue"] !== undefined ? BigInt(data["intValue"]) : undefined,
    nestedStruct: data["nestedStruct"] !== undefined ? deserializeFreebaseNestedStruct(data["nestedStruct"]) : undefined,
    provenance: data["provenance"] !== undefined ? data["provenance"].map((item: any) => (deserializeStorageGraphBfgTripleProvenance(item))) : undefined,
    rawValue: data["rawValue"] !== undefined ? decodeBase64(data["rawValue"] as string) : undefined,
    subgraphId: data["subgraphId"] !== undefined ? data["subgraphId"].map((item: any) => (BigInt(item))) : undefined,
    timestampUsec: data["timestampUsec"] !== undefined ? BigInt(data["timestampUsec"]) : undefined,
  };
}

/**
 * Next id: 127
 */
export interface GDocumentBase {
  content?: GDocumentBaseContent;
  /**
   * unix secs from epoch
   */
  ContentExpiryTime?: number;
  directory?: GDocumentBaseDirectory[];
  /**
   * Sometimes the URL displayed in search results should be different from
   * what gets indexed (e.g. in enterprise, content management systems). If this
   * value is not set, we default to the regular URL.
   */
  DisplayUrl?: string;
  /**
   * 64-bit docid of the document (usually fingerprint of URL, but not always).
   * WARNING: This does NOT uniquely identify a document ANYMORE. For a unique
   * identifier across all documents in production please refer to the field
   * 'id().key()' listed above.
   */
  DocId?: bigint;
  /**
   * 96-bit fingerprint of the canonical url's webmirror equivalence class name
   * as of when this cdoc was exported.
   */
  ecnFp?: Uint8Array;
  ExternalFeedMetadata?: string;
  /**
   * Enterprise-specific external metadata. See
   * http://engdoc/eng/designdocs/enterprise/enterprise_indexing_metadata.html
   */
  ExternalHttpMetadata?: string;
  /**
   * Deprecated, do not use, this field is not populated since 2012.
   */
  FilterForSafeSearch?: number;
  /**
   * The primary identifier of a production document is the document key given
   * in the ServingDocumentIdentifier, which is the same as the row-key in
   * Alexandria, and represents a URL and its crawling context. In your
   * production code, please always assume that the document key is the only way
   * to uniquely identify a document. ## Recommended way of reading: const
   * string& doc_key = cdoc.doc().id().key(); ## CHECK(!doc_key.empty()); More
   * background information can be found in
   * google3/indexing/crawler_id/servingdocumentidentifier.proto The
   * ServingDocumentIdentifier uniquely identifies a document in serving and
   * also distinguishes between experimental vs. production documents. The SDI
   * is also used as an input for the union/muppet key generation in serving.
   */
  id?: IndexingCrawlerIdServingDocumentIdentifier;
  /**
   * IP addr in binary (allows for IPv6)
   */
  IPAddr?: Uint8Array;
  /**
   * Localsearch-specific data.
   */
  localsearchDocInfo?: LocalsearchDocInfo;
  NoArchiveReason?: number;
  NoFollowReason?: number;
  NoImageframeOverlayReason?: number;
  NoImageIndexReason?: number;
  /**
   * When these reasons are set to a non zero value, the document should not be
   * indexed, or show a snippet, or show a cache, etc. These reasons are bit
   * maps of indexing.converter.RobotsInfo.RobotedReasons enum values reflecting
   * the places where the restriction was found.
   */
  NoIndexReason?: number;
  NoPreviewReason?: number;
  NoSnippetReason?: number;
  NoTranslateReason?: number;
  /**
   * Ocean-specific data.
   */
  oceanDocInfo?: OceanDocInfo;
  originalcontent?: GDocumentBaseOriginalContent;
  /**
   * Pagerank for doc (if known)
   */
  Pagerank?: number;
  /**
   * Pagerank-NearestSeeds is an alternative pagerank score for the doc.
   */
  PagerankNS?: number;
  /**
   * is the webmirror representative id of the canonical url. Urls with the
   * same repid are considered as dups in webmirror. WARNING: use this field
   * with caution! The webmirror duprules change frequently, so this value only
   * reflects the duprules at the time when the canonical's docjoin is built.
   */
  Repid?: Uint8Array;
  /**
   * Citation data for science articles.
   */
  ScienceMetadata?: ScienceCitation;
  /**
   * WARNING: the URL does NOT uniquely identify a document ANYMORE. For a
   * unique identifier across all documents in production please refer to the
   * field 'id().key()' listed above. Reason: foo.bar:/http and
   * foo.bar:/http:SMARTPHONE share the same URL, but the body of the two
   * documents might differ because of different crawl-context (desktop vs.
   * smartphone in this example).
   */
  URL?: string;
  URLAfterRedirects?: string;
  /**
   * See webutil/urlencoding
   */
  URLEncoding?: number;
  /**
   * The user agent name used to crawl the URL. See
   * //crawler/engine/webmirror_user_agents.h for the list of user-agents (e.g.
   * crawler::WebmirrorUserAgents::kGoogleBot). NOTE: This field is copied from
   * the first WEBMIRROR FetchReplyClientInfo in trawler_fetch_info column. We
   * leave this field unpopulated if no WEBMIRROR FecthReplyClientInfo is found.
   * As the submission of cl/51488336, Alexandria starts to populate this field.
   * However, docjoins from freshdocs (or any other source), won't have this
   * field populated, because we believe no one needs to read this field from
   * freshdocs docjoins.
   */
  userAgentName?: string;
}

function serializeGDocumentBase(data: any): GDocumentBase {
  return {
    ...data,
    content: data["content"] !== undefined ? serializeGDocumentBaseContent(data["content"]) : undefined,
    DocId: data["DocId"] !== undefined ? String(data["DocId"]) : undefined,
    ecnFp: data["ecnFp"] !== undefined ? encodeBase64(data["ecnFp"]) : undefined,
    IPAddr: data["IPAddr"] !== undefined ? encodeBase64(data["IPAddr"]) : undefined,
    oceanDocInfo: data["oceanDocInfo"] !== undefined ? serializeOceanDocInfo(data["oceanDocInfo"]) : undefined,
    Repid: data["Repid"] !== undefined ? encodeBase64(data["Repid"]) : undefined,
    ScienceMetadata: data["ScienceMetadata"] !== undefined ? serializeScienceCitation(data["ScienceMetadata"]) : undefined,
  };
}

function deserializeGDocumentBase(data: any): GDocumentBase {
  return {
    ...data,
    content: data["content"] !== undefined ? deserializeGDocumentBaseContent(data["content"]) : undefined,
    DocId: data["DocId"] !== undefined ? BigInt(data["DocId"]) : undefined,
    ecnFp: data["ecnFp"] !== undefined ? decodeBase64(data["ecnFp"] as string) : undefined,
    IPAddr: data["IPAddr"] !== undefined ? decodeBase64(data["IPAddr"] as string) : undefined,
    oceanDocInfo: data["oceanDocInfo"] !== undefined ? deserializeOceanDocInfo(data["oceanDocInfo"]) : undefined,
    Repid: data["Repid"] !== undefined ? decodeBase64(data["Repid"] as string) : undefined,
    ScienceMetadata: data["ScienceMetadata"] !== undefined ? deserializeScienceCitation(data["ScienceMetadata"]) : undefined,
  };
}

/**
 * Main content section
 */
export interface GDocumentBaseContent {
  AuthMethod?: number;
  /**
   * The actual length of the content: If Representation is compressed, this
   * equals to Content.UncompressedLength; otherwise it is the length of the
   * representation string.
   */
  ContentLength?: number;
  /**
   * See enum ContentType in //depot/google3/webutil/http/content-type.proto.
   */
  ContentType?: number;
  /**
   * Crawled file size of the original document.
   */
  crawledFileSize?: number;
  /**
   * Seconds since Unix epoch.
   */
  CrawlTime?: bigint;
  /**
   * GeometryAnnotations, encoded with GeometryUtil::DeltaEncode() to reduce
   * disk space usage. Use GeometryUtil::DeltaDecode() to decode this field.
   */
  encodedGeometryAnnotations?: Uint8Array;
  /**
   * See //depot/google3/i18n/encodings/public/encodings.h Encoding of
   * representation
   */
  Encoding?: number;
  /**
   * Set to false if Representation does not contain HTTP headers.
   */
  HasHttpHeader?: boolean;
  /**
   * A Language enum value. See: go/language-enum Default is english
   */
  Language?: number;
  /**
   * If OriginalEncoding is present, the body part of the Representation was
   * converted to UTF-8, Encoding was set to UTF8, and OriginalEncoding was set
   * to the original encoding before conversion. However, the HTTP headers part
   * of the content might not be valid UTF-8. -1=an invalid value
   */
  OriginalEncoding?: number;
  /**
   * Possibly compressed for old documents. It is not compressed for docjoins
   * produced by Raffia after ~2012.
   */
  Representation?: Uint8Array;
  /**
   * Historically present if Representation is compressed.
   */
  UncompressedLength?: number;
  /**
   * Whether the content was visual right-to-left, and if so, what type of
   * visual document it is. Must be one of the values in enum VisualType from
   * google3/repository/rtl/visualtype.h Default is NOT_VISUAL_DOCUMENT. See
   * http://wiki/Main/RtlLanguages for background.
   */
  VisualType?: number;
}

function serializeGDocumentBaseContent(data: any): GDocumentBaseContent {
  return {
    ...data,
    CrawlTime: data["CrawlTime"] !== undefined ? String(data["CrawlTime"]) : undefined,
    encodedGeometryAnnotations: data["encodedGeometryAnnotations"] !== undefined ? encodeBase64(data["encodedGeometryAnnotations"]) : undefined,
    Representation: data["Representation"] !== undefined ? encodeBase64(data["Representation"]) : undefined,
  };
}

function deserializeGDocumentBaseContent(data: any): GDocumentBaseContent {
  return {
    ...data,
    CrawlTime: data["CrawlTime"] !== undefined ? BigInt(data["CrawlTime"]) : undefined,
    encodedGeometryAnnotations: data["encodedGeometryAnnotations"] !== undefined ? decodeBase64(data["encodedGeometryAnnotations"] as string) : undefined,
    Representation: data["Representation"] !== undefined ? decodeBase64(data["Representation"] as string) : undefined,
  };
}

/**
 * The Directory proto group holds snippet and title metadata which is made
 * available to the snippet code. The proto group was originally created for
 * metadata coming from the Google Web Directory (gwd) project. It has since
 * come to be used to hold metadata from gwd and other sources.
 */
export interface GDocumentBaseDirectory {
  /**
   * encoded in UTF8
   */
  Category?: string;
  /**
   * encoded in UTF8
   */
  Description?: string;
  DescriptionScore?: number;
  /**
   * "gwd", etc.
   */
  Identifier?: string;
  /**
   * go/language-enum
   */
  Language?: number;
  /**
   * encoded in UTF8
   */
  Title?: string;
  /**
   * Deprecated; do not use. There is no code populating these fields as of Oct
   * 2017.
   */
  TitleScore?: number;
  URL?: string;
}

/**
 * The original, unconverted document, typically PDF or Word. Copied from
 * OriginalDoc field of doclogs. Unlike "Content", this does not contain any
 * HTTP headers. The content may be compressed using the same method as
 * "Content". In practice it is only compressed in the Teragoogle index. It is
 * never compressed in docjoins because those are compressed at the sstable
 * level. In doclogs content will only be compressed if the Trawler fetchreply
 * is also compressed--which is currently never and unlikely to change for
 * performance reasons.
 */
export interface GDocumentBaseOriginalContent {
  Representation?: string;
  /**
   * present iff rep is compressed
   */
  UncompressedLength?: number;
}

/**
 * The generic version of a snippet response
 */
export interface GenericSnippetResponse {
  /**
   * Per-doc debug information.
   */
  debugInfo?: string[];
  /**
   * Servlet-specific response info.
   */
  info?: Proto2BridgeMessageSet;
  /**
   * Lines of the snippet HTML. Typically gws concatenates these and lets the
   * browser wrap. The values include trailing spaces, so inserting additional
   * spaces is not necessary. However, for very old browsers, gws may insert
   * break tags after each snippet line. This field is confusing and poorly
   * named; "snippet_line" would be better. In particular, note that this does
   * not return multiple snippets for a result. Nor are these fields the
   * individual tidbits of the snippet.
   */
  snippet?: string[];
  /**
   * The title HTML. It may contain tags to denote query term matches. It may
   * be already truncated and "..." is put instead (note that truncation does
   * not always happen at the very end of the title text). However the existence
   * of "..." does not guarantee that the snippet generation algorithm truncated
   * it; e.g. webmasters themselves can write "...".
   */
  title?: string;
  /**
   * Snippet-specific members (tag ids 16+, must be optional!) Example:
   * optional NewContentResponse new_response;
   */
  wwwSnippetResponse?: WWWSnippetResponse;
}

function serializeGenericSnippetResponse(data: any): GenericSnippetResponse {
  return {
    ...data,
    wwwSnippetResponse: data["wwwSnippetResponse"] !== undefined ? serializeWWWSnippetResponse(data["wwwSnippetResponse"]) : undefined,
  };
}

function deserializeGenericSnippetResponse(data: any): GenericSnippetResponse {
  return {
    ...data,
    wwwSnippetResponse: data["wwwSnippetResponse"] !== undefined ? deserializeWWWSnippetResponse(data["wwwSnippetResponse"]) : undefined,
  };
}

/**
 * Actions supported by Madden for a local entity.
 */
export interface GeoOndemandAssistantSupportedActions {
  /**
   * Whether this local entity allows guest checkout for reservations.
   */
  allowsGuestCheckout?: boolean;
  /**
   * Whether or not this local entity supports asynchronous restaurant
   * reservations, through the above restaurant_reservation_url.
   */
  isAsynchronousRestaurantReservation?: boolean;
  /**
   * URL for the Madden restaurant reservation flow, e.g. for display in a
   * WebView. Not populated if restaurant reservations are not supported for the
   * local entity.
   */
  restaurantReservationUrl?: string;
}

/**
 * This class holds information about a single access point. An access point
 * establishes a relationship between a feature (like a POI or building) and
 * some other feature. For example, consider a TYPE_LOCALITY feature like
 * Seattle. An access point might be the TYPE_AIRPORT feature for Seattle-Tacoma
 * International Airport. The airport feature defines the access point to gain
 * airplane-based access to Seattle. A feature like Seattle will typically have
 * multiple access points. You can get to Seattle using airplanes, various forms
 * of public transit, or by driving a car. Thus Seattle would have multiple
 * access points. You may be able to get to Seattle by flying into SeaTac, or
 * you might be able to fly into Boeing Field, or Paine Field in Everett. You
 * could drive in from the North/South using I-5, or you could drive in from the
 * East using I-90. Many access points are from the road network. Thus the
 * access point for some building at 123 Main Street would likely be a segment
 * that defines the 100-200 block of "Main Street". A feature at the corner of
 * "Hollywood" and "Vine" streets might have access points from both named
 * streets. Access points are an optional field. Data editors may ignore them
 * when creating features or editing other fields. In these cases, other quality
 * teams will synthesize and update them. Several fields are also optional, as
 * they are derivable from other fields. Access points to non-TYPE_SEGMENT
 * features should always have the following fields set: - feature_type -
 * feature_id - point Location and reference fields: BASIC vs DERIVABLE Access
 * points to TYPE_SEGMENT features must have all the following BASIC fields: -
 * feature_type (of the segment, e.g. TYPE_ROAD or TYPE_VIRTUAL_SEGMENT) -
 * point_off_segment (or point; see "fuzzy point" note below) -
 * unsuitable_travel_mode (may be empty) - level (indoor access points only) The
 * following are DERIVABLE fields, which should only be added if the supplier is
 * confident about their accuracy: - feature_id - point_on_segment -
 * segment_position Editing clients are encouraged to set all fields, but they
 * may set only the BASIC fields, in which case quality teams may use the BASIC
 * fields to snap to an appropriate segment and derive the remaining fields.
 * Example: The segment is split, so that the portion that the access point is
 * on has a new feature ID. Quality teams notice that the point_on_segment is no
 * longer on the segment with feature_id, finds the new nearest segment based on
 * feature_type and existing point_on_segment, and re-derives a new feature_id,
 * point_on_segment, and segment_position, keeping other fields consistent.
 * Fuzzy point special case If the editor does not have side-of-road information
 * for access points or is otherwise unsure of the precise placement of the
 * access point, it may supply the point field (and not point_off_segment) as
 * basic data instead, in which case quality teams may generate the
 * point_off_segment. Identity Access points are considered semantically
 * equivalent if they have the same geometry, including derived fields, and the
 * same references to other features (feature_id, level_feature_id). For the
 * exact definition, see cs/symbol:geostore::AreAccessPointsEquivalent. Field
 * definitions
 */
export interface GeostoreAccessPointProto {
  /**
   * RESERVED
   */
  canEnter?: boolean;
  /**
   * RESERVED
   */
  canExit?: boolean;
  /**
   * The ID of the feature that defines the access point. The bounding box of
   * the feature is expanded to include the bounding box of the feature with the
   * access point in accordance with the standard practice for bucketing
   * map/reduce operations. See the wiki page at
   * http://wiki/Main/OysterBucketingMapReduce for more information. For access
   * points to TYPE_SEGMENT features, this may be re-derived if necessary by
   * looking up the nearest segment to existing geometry.
   */
  featureId?: GeostoreFeatureIdProto;
  /**
   * The type of the feature. Required, to allow handling the access point
   * differently based on feature type. For access points to non-TYPE_SEGMENT
   * features, this cached type also makes things easier for clients that aren't
   * running a bucketing map-reduce. For access points to TYPE_SEGMENT features,
   * this is used to find to find the nearest segment of the given type.
   */
  featureType?: number;
  /**
   * For indoor access points, this should be set to the level that the access
   * point is on. The feature_id should point to the indoor segment, but when it
   * is missing or invalid, and we need to derive it from geometry, only
   * segments on this level will be considered. For non-indoor access points,
   * level should remain unset, and when we derive feature_id from geometry,
   * only segments not on any level (non-indoor segments) will be considered.
   * The bounding box of the level feature is expanded to include the bounding
   * box of the feature with the access point in accordance with the standard
   * practice for bucketing map/reduce operations. See the wiki page at
   * http://wiki/Main/OysterBucketingMapReduce for more information. (Though in
   * general the feature should reside on the level already anyway..)
   */
  levelFeatureId?: GeostoreFeatureIdProto;
  /**
   * Field-level metadata for this access point.
   */
  metadata?: GeostoreFieldMetadataProto;
  /**
   * For access points to non-TYPE_SEGMENT features, the location of the access
   * point. For access points to TYPE_SEGMENT features, this can be supplied as
   * a fuzzy access point that is not guaranteed to be on the correct side of
   * road. It should not be used by end clients in case of TYPE_SEGMENT access
   * points.
   */
  point?: GeostorePointProto;
  /**
   * If the access point is defined by a TYPE_SEGMENT feature, this is the
   * location of the access point displaced slightly to the correct side of the
   * segment. This offset is in a direction perpendicular to the direction of
   * travel along the segment. The actual offset distance is unspecified. It
   * would typically be relatively small (approximately 1 meter). You can
   * subtract the "off segment" point from the "on segment" point to get a
   * vector of unknown length pointing from "on segment" point to the "off
   * segment" point. You can then scale that vector to whatever length you want.
   * Note that extending this displacement vector a large distance (10s of
   * meters) may result in a new point that is in the middle of some other
   * feature (park, street, intersection). This is the preferred basic geometry
   * field for incoming data from editing clients and importers, if side-of-road
   * is well-established.
   */
  pointOffSegment?: GeostorePointProto;
  /**
   * If the access point is defined by a TYPE_SEGMENT feature, this is the
   * point on the centerline of the segment that is closest to the actual access
   * point. May be re-derived if necessary to maintain precise placement on
   * segment.
   */
  pointOnSegment?: GeostorePointProto;
  /**
   * LINT.ThenChange(//depot/google3/geostore/cleanup/callbacks/\
   * ID_DUPLICATE_ACCESS_POINT.cc)
   */
  priority?:  | "TYPE_PRIMARY" | "TYPE_SECONDARY";
  /**
   * If the access point is defined by a TYPE_SEGMENT feature, this is the
   * location of the access point expressed as a fractional distance along the
   * segment. The value runs from 0 to 1 inclusive. May be re-derived if
   * necessary to maintain precise placement on segment.
   */
  segmentPosition?: number;
  /**
   * This list represents the travel modes for which this access-point should
   * be avoided. If this list is empty, the access-point is suitable for any
   * travel mode. If all access points are unsuitable for the current travel
   * mode, client should revert to other heuristics (e.g. feature center). This
   * is only used for access points to TYPE_SEGMENT features; access points to
   * non-TYPE_SEGMENT features, e.g. TYPE_ESTABLISHMENT_POI features with
   * gcid:transit_station GConcepts are just identified by feature_type and
   * feature_id.
   */
  unsuitableTravelMode?:  | "TRAVEL_MODE_MOTOR_VEHICLE" | "TRAVEL_MODE_AUTO" | "TRAVEL_MODE_TWO_WHEELER" | "TRAVEL_MODE_BICYCLE" | "TRAVEL_MODE_PEDESTRIAN" | "TRAVEL_MODE_PUBLIC_TRANSIT"[];
}

function serializeGeostoreAccessPointProto(data: any): GeostoreAccessPointProto {
  return {
    ...data,
    featureId: data["featureId"] !== undefined ? serializeGeostoreFeatureIdProto(data["featureId"]) : undefined,
    levelFeatureId: data["levelFeatureId"] !== undefined ? serializeGeostoreFeatureIdProto(data["levelFeatureId"]) : undefined,
  };
}

function deserializeGeostoreAccessPointProto(data: any): GeostoreAccessPointProto {
  return {
    ...data,
    featureId: data["featureId"] !== undefined ? deserializeGeostoreFeatureIdProto(data["featureId"]) : undefined,
    levelFeatureId: data["levelFeatureId"] !== undefined ? deserializeGeostoreFeatureIdProto(data["levelFeatureId"]) : undefined,
  };
}

/**
 * This class represents a parsed field within an address. NOTE: if you add a
 * field to this proto, please update the AreAddressComponentsEquivalent()
 * function in google3/geostore/base/internal/addresscomponent.cc
 */
export interface GeostoreAddressComponentProto {
  /**
   * The id of the corresponding Feature, if such a feature is defined. As
   * discussed above for feature_type, components of TYPE_FEATURE or
   * TYPE_LANDMARK may have a corresponding feature id.
   */
  featureId?: GeostoreFeatureIdProto;
  /**
   * For components of TYPE_FEATURE or TYPE_LANDMARK, this is the feature type
   * (TYPE_COUNTRY, TYPE_LOCALITY, TYPE_ESTABLISHMENT_POI etc.). Note that some
   * features may not actually exist in the geostore (e.g. a village that we've
   * never heard of), in which case the feature_id will be missing but the
   * feature_type is still specified. Please refer to
   * IsValidAddressComponentFeatureType() in
   * google3/geostore/base/public/addresscomponent.h for the definitive list of
   * feature types allowed for the type (either TYPE_FEATURE or TYPE_LANDMARK)
   * of components.
   */
  featureType?: number;
  /**
   * The order of this address component relative to the ones that share the
   * same feature_type in the AddressProto. For now, the primary use of this
   * index field is to handle ordering issue of multiple occurrences of
   * AddressComponentProto with feature_type of TYPE_ROUTE (and subtypes), or
   * TYPE_POLITICAL, where the order of the address components matters as there
   * are dependences. 0 is the smallest valid index value, representing the most
   * specific address component. Index value of 1 represents a relatively less
   * specific address component of the same feature_type on which the 0-indexed
   * address component depends.
   */
  index?: number;
  /**
   * The parsed_name field contains one or more names of an address component.
   * Its actual contents depends on where in the Geo/Google stack you are
   * reading a feature: 1. When an address is initially parsed via a feed or
   * other raw input and structured as an AddressProto, parsed_name should
   * contain the set of names that corresponds to the (possibly normalized) raw
   * text from the raw input. 2. In MapFacts, the address component may be
   * linked to an actual feature via feature_id. Any address formatting directly
   * from MapFacts should follow links to retrieve names when possible. The
   * parsed_name contents may be formatted directly if the address component is
   * unlinked following the same rules as selecting and formatting the name of a
   * feature. The cached parsed_name is regularly refreshed from the linked
   * feature with the minimal set of names for address components (usually just
   * a single, preferred name, in the local language, plus a Latin-script name:
   * go/story-of-ac-names). 3. In serving systems, the names of linked features
   * may be denormalized into the parsed_name field to facilitate quicker
   * address formatting or for simple data filtering (e.g. finding all geocodes
   * in California by name). If reading a feature from such a system, the
   * parsed_name field could contain multiple names in multiple languages that
   * reflect a cached copy of the names associated with the linked features.
   * Formatting of such names should follow the same rules as selecting and
   * formatting the name of a feature itself.
   */
  parsedName?: GeostoreNameProto[];
  /**
   * Any numerical address component may optionally be specified as a range.
   * For example if a component of TYPE_STREET_NUMBER has the optional "range"
   * attribute, then it represents a range of addresses rather than a single
   * address (see AddressRangeProto for details).
   */
  range?: GeostoreAddressRangeProto;
  /**
   * A place for clients to attach arbitrary data to an address component.
   * Never set in MapFacts.
   */
  temporaryData?: Proto2BridgeMessageSet;
  /**
   * Additional text to append before and/or after the parsed_name, when the
   * address is formatted. Multiple instance should represent translations.
   * Currently, this is only permitted on TYPE_LANDMARK components, and only one
   * instance is permitted.
   */
  textAffix?: GeostoreTextAffixProto[];
  /**
   * Every address component has a type. Most address components correspond to
   * one of the feature types defined in FeatureProto, so rather than defining a
   * separate category system here, instead we mark them as TYPE_FEATURE and
   * store the FeatureProto type in the feature_type() field. This is how we
   * handle countries, cities, streets, etc. However, there are a few types of
   * address components that do not have a corresponding feature type (e.g. PO
   * boxes). These components have their type defined here. An address component
   * of TYPE_STREET_NUMBER may correspond to a physical entity that defines a
   * street number, such as a geocoded address or a land parcel. In this case,
   * the address component may have a link to the corresponding feature. A good
   * reference for what types of address components are possible is the xAL
   * standard, which is a published XML schema:
   * http://www.oasis-open.org/committees/ciq/download.shtml. This standard is
   * the basis of the PostalAddress protocol message.
   */
  type?:  | "TYPE_FEATURE" | "TYPE_POSTAL_CODE_SUFFIX" | "TYPE_POST_BOX" | "TYPE_STREET_NUMBER" | "TYPE_FLOOR" | "TYPE_ROOM" | "TYPE_HOUSE_ID" | "TYPE_DISTANCE_MARKER" | "TYPE_LANDMARK" | "TYPE_PLUS_CODE";
}

function serializeGeostoreAddressComponentProto(data: any): GeostoreAddressComponentProto {
  return {
    ...data,
    featureId: data["featureId"] !== undefined ? serializeGeostoreFeatureIdProto(data["featureId"]) : undefined,
  };
}

function deserializeGeostoreAddressComponentProto(data: any): GeostoreAddressComponentProto {
  return {
    ...data,
    featureId: data["featureId"] !== undefined ? deserializeGeostoreFeatureIdProto(data["featureId"]) : undefined,
  };
}

/**
 * Represents the unparsed portion of an address with an associated language.
 */
export interface GeostoreAddressLinesProto {
  /**
   * The external form of a Google International Identifiers Initiative (III)
   * LanguageCode object. See google3/i18n/identifiers/languagecode.h for
   * details. We place extra restrictions on languages in addition to what the
   * III library requires. See
   * http://go/geo-schema-reference/feature-properties/languages.md
   */
  language?: string;
  /**
   * These lines are in display order.
   */
  line?: string[];
}

/**
 * This class represents an address, partial address, or address range. It is
 * intended to be attached to features to identify their address(es). Some
 * important points about addresses: - The addresses in the Geo Schema do *not*
 * include a component for the name of the feature, i.e. they are not
 * self-referential. For example, the name of a feature might be "Zack's Pizza"
 * and its address would be "123 Main Street". Similarly, streets, cities, and
 * counties do not include themselves as part of their address. The address of
 * "Seattle" is "King County, Washington, USA". If want to construct an address
 * that *does* include the feature name, you can simply prepend it to the other
 * address components. - Lakes, mountains, and other natural features do not
 * normally have addresses. Countries also do not have addresses because they
 * are at the top of the political hierarchy. - Address components in the Geo
 * Schema are listed in a particular order, independent of the conventions used
 * by the country in which they occur. The basic order is "smallest to largest"
 * starting with street numbers and routes, then political features, and ending
 * with postal features. The exact rules are defined by the implementation of
 * the AddressComponentOrdering::IsLessThan() function. - Some types of address
 * components may occur more than once in an address. For example, a UK address
 * with a "dependent thoroughfare" would have two components of TYPE_ROUTE (i.e.
 * street names). These are listed in the order they are normally written.
 */
export interface GeostoreAddressProto {
  /**
   * The unparsed portion (lines) of the address. An address can have multiple
   * unparsed portions. Multiple unparsed portions sharing the same language
   * should be modeled as one address_lines instance having multiple lines.
   * Historically, we also supported uparsed portions in different languages,
   * but we no longer do. Consequently, only one value is allowed for this field
   * despite the fact that it is repeated. See go/address-lines-multi-language
   * for information about why we made this change. If any components are filled
   * in, this is supplemental to (i.e. disjoint from) them. Furthermore, this
   * must be the most specific portion of the address (except for the portion,
   * if any, stored in the name field of feature.proto). Unparsed lines are
   * always formatted together in a block. Other address components are never
   * formatted between the address lines. This doesn't imply that the address
   * lines are always either the first or the last part of the formatted output.
   */
  addressLines?: GeostoreAddressLinesProto[];
  /**
   * A list of parsed address components, e.g. the street, city, etc. An
   * address range is one type of component.
   */
  component?: GeostoreAddressComponentProto[];
  /**
   * ** DEPRECATED ** This field is now deprecated (see b/33268032). If you
   * want to store cross street information as part of an address, use the
   * address_lines field.
   */
  crossStreet?: GeostoreAddressComponentProto[];
  /**
   * Field-level metadata for this address.
   */
  metadata?: GeostoreFieldMetadataProto;
  /**
   * reserved
   */
  partialDenormalization?: GeostoreAddressProto;
  /**
   * The opaque ID of the address template that contains rules for structuring
   * this address. The id of the address template can be retrieved using
   * google3/geostore/address_templates/public/address_templates.h
   */
  templateId?: string;
  /**
   * A place for clients to attach arbitrary data to an address. Never set in
   * MapFacts.
   */
  temporaryData?: Proto2BridgeMessageSet;
}

function serializeGeostoreAddressProto(data: any): GeostoreAddressProto {
  return {
    ...data,
    component: data["component"] !== undefined ? data["component"].map((item: any) => (serializeGeostoreAddressComponentProto(item))) : undefined,
    crossStreet: data["crossStreet"] !== undefined ? data["crossStreet"].map((item: any) => (serializeGeostoreAddressComponentProto(item))) : undefined,
    partialDenormalization: data["partialDenormalization"] !== undefined ? serializeGeostoreAddressProto(data["partialDenormalization"]) : undefined,
  };
}

function deserializeGeostoreAddressProto(data: any): GeostoreAddressProto {
  return {
    ...data,
    component: data["component"] !== undefined ? data["component"].map((item: any) => (deserializeGeostoreAddressComponentProto(item))) : undefined,
    crossStreet: data["crossStreet"] !== undefined ? data["crossStreet"].map((item: any) => (deserializeGeostoreAddressComponentProto(item))) : undefined,
    partialDenormalization: data["partialDenormalization"] !== undefined ? deserializeGeostoreAddressProto(data["partialDenormalization"]) : undefined,
  };
}

/**
 * This class represents a range of numbers in an address. It is an optional
 * additional field in the 'AddressComponentProto' message. This structure can
 * be used to model both single addresses and address ranges. There are two
 * primary use-cases for address ranges: definitions and references. Ranges are
 * being defined when they are present on the addresses of segment features.
 * Ranges are being referenced when they are present on non-segment features.
 * NOTE: If you add fields in this proto, consider updating the
 * AreAddressRangesEquivalent() function in
 * google3/geostore/base/internal/addressrange.cc
 */
export interface GeostoreAddressRangeProto {
  /**
   * Two or more address numbers. Each number represents an address that was
   * mentioned by the data provider.
   */
  number?: number[];
  /**
   * For address range definitions: Two or more interpolation parameter values.
   * The length of this array must match the length of the number array, and
   * each parameter number specifies the position of the corresponding address
   * number. Each value is an interpolation between 0.0 and 1.0 inclusive. The
   * value is proportional to the distance traveled along the segment's polyline
   * starting at its origin. The parameters must be provided in increasing order
   * and the values in the number array must be in strictly increasing or
   * decreasing order. We make an exception for singleton addresses, which are
   * represented as two copies of a (number, parameter) pair, for backwards
   * compatibility. For address range references: This array must be empty.
   */
  parameter?: number[];
  /**
   * If specified, the prefix or suffix is applied to all numbers in the range.
   * For example, this can be used to indicate that addresses B1 through B99 are
   * on one side of the street, while A1 through A99 are on the other side of
   * the street.
   */
  prefix?: string;
  /**
   * If 'same_parity' is true, then all 'number' values must have the same
   * parity (even or odd), and this address range only includes addresses whose
   * parity is the same as the given 'number' values.
   */
  sameParity?: boolean;
  suffix?: string;
  /**
   * A place for clients to attach arbitrary data to an address range. Never
   * set in MapFacts. Here are some examples: Example #1: Single non-numeric
   * address (e.g., "Twelve") At the moment this can only be represented as a
   * street number (with the value in the parsed_name field of the
   * AddressComponentProto). We have future plans to make other changes so we
   * can handle this case. Example #2: Single semi-numeric address (e.g.,
   * "12bis") The number array contains two copies of the single numeric value
   * (12). The prefix is empty and the suffix contains "bis". The parameter
   * array has two identical values specifying the position of the single
   * address. Example #3: Simple address range (e.g., "100 to 198, even numbers
   * only") The number array contains the two values "100" and "198". The prefix
   * and suffix strings are empty in this example. The parameter array has two
   * values, one for each number. The same_parity flag is set in this example.
   */
  temporaryData?: Proto2BridgeMessageSet;
}

/**
 * A features geometry that is populated from the 3D Geometry Store. Please
 * see go/a3d-and-mapfacts for design details.
 */
export interface GeostoreAnchoredGeometryProto {
  /**
   * The ID to be used to fetch the features geometry from the 3D Geometry
   * Store.
   */
  geometryId?: string;
}

/**
 * A container for speed limits that allows tagging with a correctness trust
 * level.
 */
export interface GeostoreAppliedSpeedLimitProto {
  /**
   * The actual speed limit value.
   */
  speedLimit?: GeostoreSpeedLimitProto;
  /**
   * The level of trust we have in this speed limit value.
   */
  trustLevel?:  | "SPEED_LIMIT_TRUST_LEVEL_UNKNOWN" | "LOW_QUALITY" | "HIGH_QUALITY" | "EXACT";
}

/**
 * An AttachmentProto contains structured data of a client-specified type. An
 * attachment is uniquely identified by the combination of its attachment_id and
 * client_name_space fields.
 */
export interface GeostoreAttachmentsAttachmentProto {
  /**
   * attachment_id distinguishes messages of the same type_id associated with
   * the same feature. It can not be set to 0x0.
   */
  attachmentId?: bigint;
  /**
   * This field specifies a namespace identifier that can be used to track the
   * sources of attachments in a human friendly format. Name spaces must be at
   * most 64 characters long and must be composed entirely of alphanumeric
   * characters, hyphens, and underscores. No other characters are allowed.
   */
  clientNameSpace?: string;
  /**
   * comment is a human-readable string that is logged whenever this attachment
   * is processed by the framework.
   */
  comment?: string;
  /**
   * messages contains the structured data for this attachment. It should
   * contain a single message with a type ID matching the value of the type_id
   * field below.
   */
  messages?: Proto2BridgeMessageSet;
  /**
   * type_id determines the type of the actual attachment that should be set in
   * the messages MessageSet. It can not be set to 0x0.
   */
  typeId?: bigint;
}

function serializeGeostoreAttachmentsAttachmentProto(data: any): GeostoreAttachmentsAttachmentProto {
  return {
    ...data,
    attachmentId: data["attachmentId"] !== undefined ? String(data["attachmentId"]) : undefined,
    typeId: data["typeId"] !== undefined ? String(data["typeId"]) : undefined,
  };
}

function deserializeGeostoreAttachmentsAttachmentProto(data: any): GeostoreAttachmentsAttachmentProto {
  return {
    ...data,
    attachmentId: data["attachmentId"] !== undefined ? BigInt(data["attachmentId"]) : undefined,
    typeId: data["typeId"] !== undefined ? BigInt(data["typeId"]) : undefined,
  };
}

/**
 * Used to represent the unique id of an attribute.
 */
export interface GeostoreAttributeIdProto {
  /**
   * The id of the attribute. Stored as a stripped format of the gcid (e.g.
   * "foo" instead of "gcid:att_foo").
   */
  id?: string;
  /**
   * Set because it's required, but not really meaningful in geostore (always
   * set to "Geo").
   */
  providerId?: string;
  type?:  | "ITEMCLASS" | "ATTRIBUTE" | "VALUESPACE" | "DATASTORE";
}

/**
 * Protocol buffer for attaching attributes and values to instances. This is
 * for assigning a particular attribute and value to a repository item, not for
 * metadata. For protocol buffers that represents metadata about attributes and
 * values, see CanonicalAttribute in itemclass.proto and ValueSpace in
 * valuespace.proto.
 */
export interface GeostoreAttributeProto {
  applicationData?: Proto2BridgeMessageSet;
  attributeDisplay?: GeostoreAttributeValueDisplayProto[];
  booleanValue?: boolean;
  /**
   * The canonical attribute for this attribute instance.
   */
  canonicalAttributeId?: GeostoreAttributeIdProto;
  doubleValue?: number;
  /**
   * For those attribute ids that expect their values to be taken from an
   * enumeration-style set of values, that value's gcid should be stored here,
   * e.g. "gcid:attval_yes".
   */
  enumIdValue?: string;
  floatValue?: number;
  int64Value?: bigint;
  integerValue?: number;
  itemClassId?: GeostoreAttributeIdProto;
  /**
   * Field-level metadata for this attribute
   */
  metadata?: GeostoreFieldMetadataProto;
  /**
   * Fully qualified package name because genprotohdf uses genproto for this
   * proto2 syntax:
   * https://wiki.corp.google.com/twiki/bin/view/Main/Proto2WithGenproto
   */
  protoValue?: Proto2BridgeMessageSet;
  /**
   * The attribute value falls into one of these fields, based on value_type:
   */
  stringValue?: string;
  uint32Value?: number;
  /**
   * Used to store language-specific names of this attribute's value (e.g. a
   * translation into another language).
   */
  valueDisplay?: GeostoreAttributeValueDisplayProto[];
  valueSpaceId?: GeostoreAttributeIdProto;
  valueType?:  | "NONE" | "STRING" | "INTEGER" | "DOUBLE" | "BOOLEAN" | "PROTO_VALUE" | "INT64" | "FLOAT" | "DISPLAY_ONLY" | "UINT32" | "ENUM_ID";
}

function serializeGeostoreAttributeProto(data: any): GeostoreAttributeProto {
  return {
    ...data,
    int64Value: data["int64Value"] !== undefined ? String(data["int64Value"]) : undefined,
  };
}

function deserializeGeostoreAttributeProto(data: any): GeostoreAttributeProto {
  return {
    ...data,
    int64Value: data["int64Value"] !== undefined ? BigInt(data["int64Value"]) : undefined,
  };
}

/**
 * Used to help display language-specific names of attributes.
 */
export interface GeostoreAttributeValueDisplayProto {
  language?: string;
  synonym?: string;
}

export interface GeostoreBarrierLogicalMaterialProto {
  material?:  | "UNKNOWN_LOGICAL_MATERIAL" | "CONCRETE" | "METAL" | "PLASTIC" | "STONE" | "TIMBER"[];
}

/**
 * A BestLocaleProto holds information about the best-match locale for a
 * feature. Clients may use this information to determine the appropriate local
 * name of a feature.
 */
export interface GeostoreBestLocaleProto {
  /**
   * The ID of the best-match TYPE_LOCALE feature for this feature.
   */
  locale?: GeostoreFeatureIdProto;
  /**
   * The ID of the localization policy to apply when selecting a name for a
   * feature. This field should always be set. If feature_id is also defined,
   * this field should have the same localization policy ID as the referenced
   * locale feature. Localization policy IDs are arbitrary identifiers (up to
   * some number of bytes; see geostore/base/public/constants.h) that uniquely
   * distinguish a set of language-selection rules.
   */
  localizationPolicyId?: string;
  /**
   * Field-level metadata for this best locale.
   */
  metadata?: GeostoreFieldMetadataProto;
}

function serializeGeostoreBestLocaleProto(data: any): GeostoreBestLocaleProto {
  return {
    ...data,
    locale: data["locale"] !== undefined ? serializeGeostoreFeatureIdProto(data["locale"]) : undefined,
  };
}

function deserializeGeostoreBestLocaleProto(data: any): GeostoreBestLocaleProto {
  return {
    ...data,
    locale: data["locale"] !== undefined ? deserializeGeostoreFeatureIdProto(data["locale"]) : undefined,
  };
}

/**
 * The reference to a BizBuilder listing. For details on BizBuilder see
 * http://g3doc/commerce/bizbuilder/backend/g3doc/index.md
 */
export interface GeostoreBizBuilderReferenceProto {
  /**
   * Listing id. Used in queries to BizBuilder backend for listing access.
   */
  id?: bigint;
}

function serializeGeostoreBizBuilderReferenceProto(data: any): GeostoreBizBuilderReferenceProto {
  return {
    ...data,
    id: data["id"] !== undefined ? String(data["id"]) : undefined,
  };
}

function deserializeGeostoreBizBuilderReferenceProto(data: any): GeostoreBizBuilderReferenceProto {
  return {
    ...data,
    id: data["id"] !== undefined ? BigInt(data["id"]) : undefined,
  };
}

/**
 * A border represents a line of division between two features of the same type
 * (i.e. United States and Mexico, but not California and Mexico). Borders are
 * only used for features that tile an area. For example, country features have
 * borders with one another because they tile an area of land. Country features
 * do not have borders with province features because those two types of
 * features may intersect with each other. The geometry of a border will often
 * be similar (or derived from) the geometry of the two features that it
 * separates. However, it is useful to have borders represented by stand-alone
 * features for map-styling purposes. Ideally, the geometry in a border feature
 * would be exactly the same as the common edges of the polygonal geometry of
 * the two features. This may not always be true in practice. At some point in
 * the future we would like to build a network of borders for features that are
 * supposed to tile with each other. The network would be composed of different
 * border types meeting at endpoint intersections. In the process of building
 * this network, we would perform small geometry corrections to ensure that the
 * borders align properly at all zoom levels. Border features are intended
 * primarily for map drawing, and they would rarely be useful for geocoding. One
 * exception would be for famous borders like the "Mason Dixon Line" or the
 * "Berlin Wall." The standard feature properties have the following
 * interpretations: name - Borders rarely have names unless they notable in
 * their own right (e.g. "Mason Dixon Line", "Berlin Wall"). point - A border
 * should not have point geometry. polyline - A border should have a single
 * polyline that represents the division between the two features. polygon - A
 * border should not have polygon geometry.
 */
export interface GeostoreBorderProto {
  /**
   * The ids of the area features to the left and right of the border, relative
   * to the start and end of this borders' polyline geometry. These features
   * should have the same type as the "type" attribute above. These ids are not
   * required because the corresponding features may be nonexistent or difficult
   * to obtain.
   */
  featureIdLeft?: GeostoreFeatureIdProto;
  featureIdRight?: GeostoreFeatureIdProto;
  /**
   * The logical borders which this border is a part of.
   */
  logicalBorder?: GeostoreFeatureIdProto[];
  /**
   * List of border status overrides. Due to legal reasons, we may be required
   * to display some borders differently on some domains for instance.
   */
  overrideStatus?: GeostoreOverrideBorderStatusProto[];
  /**
   * The border status identifies the legal status of the border line.
   */
  status?:  | "STATUS_NORMAL" | "STATUS_DISPUTED" | "STATUS_UNSURVEYED" | "STATUS_INTERNATIONAL_WATER" | "STATUS_NEVER_DISPLAY" | "STATUS_TREATY" | "STATUS_PROVISIONAL" | "STATUS_NO_LABEL";
  /**
   * The type of the features this border separates. Should always be a subtype
   * of TYPE_POLITICAL. NOTE: as of December 2019, we currently require this to
   * be equal to TYPE_COUNTRY or TYPE_ADMINISTRATIVE_AREA1. In the future, we
   * may support TYPE_BORDER for lower types of political features.
   */
  type?: number;
}

function serializeGeostoreBorderProto(data: any): GeostoreBorderProto {
  return {
    ...data,
    featureIdLeft: data["featureIdLeft"] !== undefined ? serializeGeostoreFeatureIdProto(data["featureIdLeft"]) : undefined,
    featureIdRight: data["featureIdRight"] !== undefined ? serializeGeostoreFeatureIdProto(data["featureIdRight"]) : undefined,
    logicalBorder: data["logicalBorder"] !== undefined ? data["logicalBorder"].map((item: any) => (serializeGeostoreFeatureIdProto(item))) : undefined,
  };
}

function deserializeGeostoreBorderProto(data: any): GeostoreBorderProto {
  return {
    ...data,
    featureIdLeft: data["featureIdLeft"] !== undefined ? deserializeGeostoreFeatureIdProto(data["featureIdLeft"]) : undefined,
    featureIdRight: data["featureIdRight"] !== undefined ? deserializeGeostoreFeatureIdProto(data["featureIdRight"]) : undefined,
    logicalBorder: data["logicalBorder"] !== undefined ? data["logicalBorder"].map((item: any) => (deserializeGeostoreFeatureIdProto(item))) : undefined,
  };
}

export interface GeostoreBoundingMarkerProto {
  /**
   * References to any gcid:physical_lane_marker features that bound this lane
   * or lane connection.
   */
  boundingMarker?: GeostoreFeatureIdProto;
  /**
   * A token that can be used to identify the version of the data about this
   * bounding marker.
   */
  boundingMarkerToken?: string;
  /**
   * Which part of the flowline does this association refer to? These should be
   * between 0 and 1. These are optionally set, but can be approximated
   * geometrically if they arent set. NOTE: These refer to the geometry of this
   * feature.
   */
  flowlineAdjacencyBeginFraction?: number;
  flowlineAdjacencyEndFraction?: number;
  /**
   * Which part of the marker track does this association refer to? These
   * should be between 0 and 1. These are optionally set, but can be
   * approximated geometrically if they arent set. NOTE: These refer to the
   * geometry of the marker feature.
   */
  markerAdjacencyBeginFraction?: number;
  markerAdjacencyEndFraction?: number;
  /**
   * Which side of the flowline does the marker occur on.
   */
  side?:  | "UNKNOWN" | "LEFT" | "RIGHT";
}

function serializeGeostoreBoundingMarkerProto(data: any): GeostoreBoundingMarkerProto {
  return {
    ...data,
    boundingMarker: data["boundingMarker"] !== undefined ? serializeGeostoreFeatureIdProto(data["boundingMarker"]) : undefined,
  };
}

function deserializeGeostoreBoundingMarkerProto(data: any): GeostoreBoundingMarkerProto {
  return {
    ...data,
    boundingMarker: data["boundingMarker"] !== undefined ? deserializeGeostoreFeatureIdProto(data["boundingMarker"]) : undefined,
  };
}

/**
 * This protocol buffer holds the building-specific attributes for features of
 * type TYPE_COMPOUND_BUILDING.
 */
export interface GeostoreBuildingProto {
  /**
   * The height of the base of this building, in meters above ground-level, if
   * known.
   */
  baseHeightMetersAgl?: number;
  /**
   * The level in this building that should get displayed by default. If
   * present, the default display level must be one of this building's levels
   * that are listed in the level[] field, and if a level is set as a default
   * level of one building, all buildings sharing the level should have that
   * same level as their default level. If not present, clients should not
   * display any level by default for that building.
   */
  defaultDisplayLevel?: GeostoreFeatureIdProto;
  /**
   * The number of floors above the base of the building, if known. For example
   * a regular 1-story building would set this to "1". Use a value of
   * GeostoreConstants::kDefaultHeightPerFloor when converting "floors" to
   * "height_meters".
   */
  floors?: number;
  floorsMetadata?: GeostoreFieldMetadataProto;
  /**
   * The height of the building above its base, in meters, if known.
   */
  heightMeters?: number;
  heightMetersMetadata?: GeostoreFieldMetadataProto;
  /**
   * The levels in this building, in no particular order. These levels refer
   * back to the building via another strong reference (the LevelProto.building
   * field).
   */
  level?: GeostoreFeatureIdProto[];
  /**
   * "Structure" denotes a physical architecture of the building that is
   * readily visible. This attribute is useful in that rarer structures can make
   * good landmarks.
   */
  structure?:  | "STRUCTURE_ANY" | "STRUCTURE_TOWER" | "STRUCTURE_DOME" | "STRUCTURE_CASTLE" | "STRUCTURE_SHRINE" | "STRUCTURE_TEMPLE" | "STRUCTURE_TANK";
}

function serializeGeostoreBuildingProto(data: any): GeostoreBuildingProto {
  return {
    ...data,
    defaultDisplayLevel: data["defaultDisplayLevel"] !== undefined ? serializeGeostoreFeatureIdProto(data["defaultDisplayLevel"]) : undefined,
    level: data["level"] !== undefined ? data["level"].map((item: any) => (serializeGeostoreFeatureIdProto(item))) : undefined,
  };
}

function deserializeGeostoreBuildingProto(data: any): GeostoreBuildingProto {
  return {
    ...data,
    defaultDisplayLevel: data["defaultDisplayLevel"] !== undefined ? deserializeGeostoreFeatureIdProto(data["defaultDisplayLevel"]) : undefined,
    level: data["level"] !== undefined ? data["level"].map((item: any) => (deserializeGeostoreFeatureIdProto(item))) : undefined,
  };
}

/**
 * This holds data specific to business chain features.
 */
export interface GeostoreBusinessChainProto {
  /**
   * Canonical GConcepts describe the ideal state of the GConcepts of this
   * business chain's members.
   */
  canonicalGconcepts?: GeostoreCanonicalGConceptProto[];
}

/**
 * A BusinessHoursProto stores a weekly schedule of opening hours for a
 * business (represented as a BusinessHours message) together with other closely
 * related information that is Geo-specific.
 */
export interface GeostoreBusinessHoursProto {
  /**
   * The actual hours represented by this BusinessHoursProto.
   */
  data?: BusinessHours;
  /**
   * Field-level metadata for these hours.
   */
  metadata?: GeostoreFieldMetadataProto;
}

/**
 * Message containing calls to action specified by the business owner.
 */
export interface GeostoreCallToActionProto {
  /**
   * Required.
   */
  ctaType?:  | "CTA_TYPE_UNSPECIFIED" | "CTA_TYPE_BOOK" | "CTA_TYPE_BUY" | "CTA_TYPE_ORDER_ONLINE" | "CTA_TYPE_LEARN_MORE" | "CTA_TYPE_SIGN_UP" | "CTA_TYPE_GET_OFFER";
  url?: GeostoreUrlProto;
}

/**
 * This proto represents a canonical gconcept of a business chain's members.
 */
export interface GeostoreCanonicalGConceptProto {
  gconcept?: GeostoreGConceptInstanceProto;
  /**
   * Whether the gconcept must be on a member. This must be true for a primary
   * gconcept.
   */
  isRequired?: boolean;
}

/**
 * This protocol buffer holds S2 cell covering for the feature. See
 * util/geometry/s2cell_union.h for more information on S2 cells. See
 * geostore/base/public/cellcovering.h for utility functions.
 */
export interface GeostoreCellCoveringProto {
  /**
   * Array of S2 cell ids that represent the covering. There is no preset limit
   * on how many cells can be used.
   */
  cellId?: bigint[];
}

function serializeGeostoreCellCoveringProto(data: any): GeostoreCellCoveringProto {
  return {
    ...data,
    cellId: data["cellId"] !== undefined ? data["cellId"].map((item: any) => (String(item))) : undefined,
  };
}

function deserializeGeostoreCellCoveringProto(data: any): GeostoreCellCoveringProto {
  return {
    ...data,
    cellId: data["cellId"] !== undefined ? data["cellId"].map((item: any) => (BigInt(item))) : undefined,
  };
}

/**
 * Generic item proto. This is intended to have only certain aspects filled
 * (e.g. photo only, name + price). Valid combinations of properties are
 * enforced by linters.
 */
export interface GeostoreComposableItemProto {
  /**
   * Call to action for the individual product.
   */
  callToAction?: GeostoreCallToActionProto;
  jobMetadata?: GeostoreJobMetadata;
  /**
   * Any photos describing this item.
   */
  media?: GeostoreMediaItemProto[];
  /**
   * The repeated name_info field is for price list sections listed in multiple
   * languages. At least one name_info containing id must be specified. There
   * should be at most one name_info for any given language. When representing a
   * job item, there should be exactly one name_info specified.
   */
  nameInfo?: GeostorePriceListNameInfoProto[];
  /**
   * Represents if an item is offered at a business. For TYPE_JOB, this
   * represents if this job is offered by the corresponding business
   */
  offered?:  | "OFFERED_UNSPECIFIED" | "OFFERED" | "OFFERED_NOT" | "OFFERED_ON_WEBSITE";
  /**
   * Price of the item. There should be at most one price for any given
   * currency.
   */
  price?: GeostorePriceRangeProto;
  /**
   * Represents which price format is being used by this item, which determines
   * the usage/meaning of the price field above. Optional  the default value
   * is legal and safe (represents no price if the price field is unset).
   */
  priceFormat?:  | "PRICE_FORMAT_DEFAULT" | "PRICE_FORMAT_VARIES";
  /**
   * Numerical score which can be provided by data sources to indicate
   * preferred item ordering. This is purely a hint  we are not required to
   * followed it if we have a different order we think is better. Higher scores
   * represent items that should be shown more prominently/earlier. Optional.
   */
  rankingHint?: number;
}

function serializeGeostoreComposableItemProto(data: any): GeostoreComposableItemProto {
  return {
    ...data,
    jobMetadata: data["jobMetadata"] !== undefined ? serializeGeostoreJobMetadata(data["jobMetadata"]) : undefined,
  };
}

function deserializeGeostoreComposableItemProto(data: any): GeostoreComposableItemProto {
  return {
    ...data,
    jobMetadata: data["jobMetadata"] !== undefined ? deserializeGeostoreJobMetadata(data["jobMetadata"]) : undefined,
  };
}

/**
 * A count value tagged with a comparison operator. This can be used for axle
 * count, trailer count, etc.
 */
export interface GeostoreCountComparisonProto {
  comparisonOperator?:  | "UNSPECIFIED" | "EQUAL" | "LESS_THAN" | "LESS_THAN_OR_EQUAL" | "GREATER_THAN" | "GREATER_THAN_OR_EQUAL";
  count?: number;
}

/**
 * Possible patterns of a crossing stripe (any element that denotes a point on
 * a segment or lane at which the vehicle must stop or yield). These include
 * crosswalks, stop, and yield lines.
 */
export interface GeostoreCrossingStripePatternProto {
  borderLine?: GeostorePhysicalLineProto;
  borderPattern?:  | "UNKNOWN_BORDER_PATTERN" | "NO_BORDER_PATTERN" | "SOLID" | "DASHED";
  /**
   * Colors found on this crossing.
   */
  color?: GeostorePaintedElementLogicalColorProto[];
  stripePattern?:  | "UNKNOWN_STRIPE_PATTERN" | "NO_STRIPE_PATTERN" | "LONGITUDINAL_STRIPE" | "DIAGONAL_STRIPE" | "LATERAL_STRIPE" | "SINGLE_CROSSING_LINE" | "DOUBLE_CROSSING_LINE" | "TRIANGLE_CROSSING_LINE_POINTING_LEFT" | "TRIANGLE_CROSSING_LINE_POINTING_RIGHT" | "STRUCTURED_CROSSING_LINE";
}

/**
 * Protocol buffer describing a curve that connects two externally specified
 * endpoints.
 */
export interface GeostoreCurveConnectionProto {
  bezierParams?: GeostoreCurveConnectionProtoBezierParams;
  circleParams?: GeostoreCurveConnectionProtoCircleParams;
  type?:  | "UNSPECIFIED" | "BEZIER" | "CIRCLE" | "STRAIGHT_EDGE";
}

export interface GeostoreCurveConnectionProtoBezierParams {
  /**
   * Internal Bezier handles. One can be used for a quadratic curve, two for
   * cubic Beziers.
   */
  controlPoint?: GeostoreCurveConnectionProtoBezierParamsControlPoint[];
}

export interface GeostoreCurveConnectionProtoBezierParamsControlPoint {
  /**
   * We use this parameterization to make curves change predictable when
   * endpoints move. Each point P is defined in terms of the straight edge [S,
   * E] between the start point of the curve S and its end point E. *P / / / S
   * *------------* E Counter-clockwise angle between vector SE and vector SP.
   */
  angleDegrees?: number;
  /**
   * Distance(S, P) in units of Distance(S, E).
   */
  distanceMultiplier?: number;
}

export interface GeostoreCurveConnectionProtoCircleParams {
  /**
   * Arc radius. Must be greater than half-distance between two endpoints.
   */
  radius?: number;
}

/**
 * Every data source used to construct a data repository has an associated
 * feature that provides more information about it. The standard feature
 * properties have the following interpretations: bound - The bounds must
 * includes all features that refer to this data source, so that bucketing
 * MapReduce passes work correctly. name - The provider name associated with
 * this data source. It is expected to remain constant from release to release,
 * and between datasets. address - should be empty. point, polyline, polygon -
 * should be empty. source_info - should not be set. child - should be empty.
 */
export interface GeostoreDataSourceProto {
  /**
   * This is the URL of a website representing this DataSource as a whole. If
   * this DataSource feature is specific to a particular dataset or product, the
   * page may contain information relevant to that dataset or product or may be
   * the main page of the organization.
   */
  attributionUrl?: GeostoreUrlProto[];
  /**
   * A UTF8 string that will be inserted in copyright messages to refer to this
   * copyright owner, e.g. "Tele Atlas".
   */
  copyrightOwner?: string;
  /**
   * The copyright year of this data (which may be different than the year of
   * the release date), e.g. 2005.
   */
  copyrightYear?: number;
  /**
   * A free-form description of this data source. Ideally the description
   * should include: - Where the data was obtained (URL, company name,
   * individual, etc). - Where to find detailed documentation. - A brief summary
   * of the licensing terms. - As much internal and external contact information
   * as possible (e.g. who to ask about licensing questions, interpreting the
   * data, updating the data, fixing bugs in the importer, etc).
   */
  description?: string;
  /**
   * The build information of the importer binary used to generate this data
   * source.
   */
  importerBuildInfo?: string;
  /**
   * The build target of the importer binary used to generate this data source.
   */
  importerBuildTarget?: string;
  /**
   * The Perforce client information of the importer binary used to generate
   * this data source.
   */
  importerClientInfo?: string;
  /**
   * If the importer was built as an MPM, the version number can be stored in
   * this field. As with build_info, this can be useful when tracking down
   * issues that may be due to the use of a particular binary.
   */
  importerMpmVersion?: string;
  /**
   * The timestamp of the importer binary used to generate this data source.
   */
  importerTimestamp?: string;
  /**
   * The provider type of this data source.
   */
  provider?:  | "PROVIDER_ANY" | "PROVIDER_UNKNOWN" | "PROVIDER_NAVTEQ" | "PROVIDER_TELE_ATLAS" | "PROVIDER_TELE_ATLAS_MULTINET" | "PROVIDER_TELE_ATLAS_CODEPOINT" | "PROVIDER_TELE_ATLAS_GEOPOST" | "PROVIDER_TELE_ATLAS_DATAGEO" | "PROVIDER_TELE_ATLAS_ADDRESS_POINTS" | "PROVIDER_TELCONTAR" | "PROVIDER_EUROPA" | "PROVIDER_ROYAL_MAIL" | "PROVIDER_GOOGLE" | "PROVIDER_GOOGLE_HAND_EDIT" | "PROVIDER_GOOGLE_BORDERS" | "PROVIDER_GOOGLE_SUBRANGE" | "PROVIDER_GOOGLE_GT_FUSION" | "PROVIDER_GOOGLE_ZAGAT_CMS" | "PROVIDER_GOOGLE_PLACE_NAVBOOST" | "PROVIDER_GOOGLE_FOOTPRINT" | "PROVIDER_GOOGLE_PRODUCT_TERMS" | "PROVIDER_GOOGLE_POINTCARDS" | "PROVIDER_GOOGLE_BUSINESS_CHAINS" | "PROVIDER_GOOGLE_LOCAL_SUMMARIZATION" | "PROVIDER_GOOGLE_PRONUNCIATIONS" | "PROVIDER_GOOGLE_DUMPLING" | "PROVIDER_GOOGLE_DISTILLERY" | "PROVIDER_GOOGLE_LOCAL_ATTRIBUTE_SUMMARIZATION" | "PROVIDER_GOOGLE_RELATION_MINER" | "PROVIDER_GOOGLE_MAPSPAM" | "PROVIDER_GOOGLE_ROSE" | "PROVIDER_GOOGLE_LOCAL_PLACE_RATINGS" | "PROVIDER_GOOGLE_WIPEOUT" | "PROVIDER_GOOGLE_KNOWLEDGE_GRAPH" | "PROVIDER_GOOGLE_BEEGEES" | "PROVIDER_GOOGLE_REVIEW_SUMMARIZATION" | "PROVIDER_GOOGLE_OFFLINE_NON_CORE_ATTRIBUTE_SUMMARIZATION" | "PROVIDER_GOOGLE_GEO_WORLDMAPS" | "PROVIDER_GOOGLE_GEO_MODERATION" | "PROVIDER_GOOGLE_OYSTER_AUTO_EDITS" | "PROVIDER_GOOGLE_LOCAL_ALCHEMY" | "PROVIDER_GOOGLE_KEROUAC" | "PROVIDER_GOOGLE_MOBRANK" | "PROVIDER_GOOGLE_RAPTURE" | "PROVIDER_GOOGLE_CULTURAL_INSTITUTE" | "PROVIDER_GOOGLE_GEOCODES_FROM_LOCAL_FEEDS" | "PROVIDER_GOOGLE_ATTRIBUTES_FROM_CRAWLED_CHAINS" | "PROVIDER_GOOGLE_TACTILE_MAPS" | "PROVIDER_GOOGLE_MAPS_FOR_MOBILE" | "PROVIDER_GOOGLE_GEO_REALTIME" | "PROVIDER_GOOGLE_PROMINENT_PLACES" | "PROVIDER_GOOGLE_PLACE_ACTIONS" | "PROVIDER_GOOGLE_GT_AUTO_EDITS" | "PROVIDER_GOOGLE_WAZE" | "PROVIDER_GOOGLE_ONTHEGO" | "PROVIDER_GOOGLE_GT_IMPORT" | "PROVIDER_GOOGLE_STRUCTURED_DATA" | "PROVIDER_GOOGLE_HELICOPTER" | "PROVIDER_GOOGLE_ROLLBACK" | "PROVIDER_GOOGLE_RIGHTS_REPAIR" | "PROVIDER_GOOGLE_PERFUME" | "PROVIDER_GOOGLE_MAPS_TRANSLATION" | "PROVIDER_GOOGLE_CALL_ME_MAYBE" | "PROVIDER_GOOGLE_LOCAL_UNIVERSAL" | "PROVIDER_GOOGLE_CROUPIER" | "PROVIDER_GOOGLE_SKYSMART" | "PROVIDER_GOOGLE_RIDDLER" | "PROVIDER_GOOGLE_ROADCLOSURES" | "PROVIDER_GOOGLE_SPORE" | "PROVIDER_GOOGLE_LOCALIZATION" | "PROVIDER_GOOGLE_CATTERMS" | "PROVIDER_GOOGLE_GT_FIELD_OPS" | "PROVIDER_GOOGLE_MATCHMAKER" | "PROVIDER_GOOGLE_ARBITRATION" | "PROVIDER_GOOGLE_BIZBUILDER_OPS" | "PROVIDER_GOOGLE_LOCAL_INVENTORY_ADS" | "PROVIDER_GOOGLE_GT_DRAFTY" | "PROVIDER_GOOGLE_HOTELADS_OPS" | "PROVIDER_GOOGLE_MARKERS" | "PROVIDER_GOOGLE_STATE_MACHINE" | "PROVIDER_GOOGLE_ATTRIBUTES_INFERENCE" | "PROVIDER_GOOGLE_BIKESHARE" | "PROVIDER_GOOGLE_GHOSTWRITER" | "PROVIDER_GOOGLE_EDIT_PLATFORM" | "PROVIDER_GOOGLE_BLUE_GINGER" | "PROVIDER_GOOGLE_GEO_TIGER" | "PROVIDER_GOOGLE_HYADES" | "PROVIDER_GOOGLE_WEBQUARRY" | "PROVIDER_GOOGLE_GEO_MADDEN" | "PROVIDER_GOOGLE_ANDROID_PAY" | "PROVIDER_GOOGLE_OPENING_HOURS_TEAM" | "PROVIDER_GOOGLE_LOCAL_DISCOVERY" | "PROVIDER_GOOGLE_LOCAL_HEALTH" | "PROVIDER_GOOGLE_UGC_MAPS" | "PROVIDER_GOOGLE_FIBER" | "PROVIDER_GOOGLE_REVGEO" | "PROVIDER_GOOGLE_HOTELADS_PARTNER_FRONT_END" | "PROVIDER_GOOGLE_GEO_UGC_TASKS" | "PROVIDER_GOOGLE_GEOCODING" | "PROVIDER_GOOGLE_SPYGLASS" | "PROVIDER_GOOGLE_PLUS_CODES_AS_ADDRESSES" | "PROVIDER_GOOGLE_GEO_CHANGES" | "PROVIDER_GOOGLE_HUME" | "PROVIDER_GOOGLE_MEGAMIND" | "PROVIDER_GOOGLE_GT_ROADSYNTH" | "PROVIDER_GOOGLE_FIREBOLT" | "PROVIDER_GOOGLE_LOCAL_PLACE_OFFERINGS" | "PROVIDER_GOOGLE_UGC_SERVICES" | "PROVIDER_GOOGLE_GEOALIGN" | "PROVIDER_GOOGLE_GT_COMPOUNDS" | "PROVIDER_GOOGLE_FOOD_ORDERING" | "PROVIDER_GOOGLE_HOTEL_KNOWLEDGE_OPS" | "PROVIDER_GOOGLE_URAW" | "PROVIDER_GOOGLE_FLYEYE" | "PROVIDER_GOOGLE_YOUKE" | "PROVIDER_GOOGLE_GT_ZEPHYR" | "PROVIDER_GOOGLE_USER_SAFETY" | "PROVIDER_GOOGLE_ADDRESS_MAKER" | "PROVIDER_GOOGLE_UGC_PHOTOS" | "PROVIDER_GOOGLE_GT_WINDCHIME" | "PROVIDER_GOOGLE_SNAG_FIXER" | "PROVIDER_GOOGLE_GEO_DEALS" | "PROVIDER_GOOGLE_LOCAL_PLACE_TOPICS" | "PROVIDER_GOOGLE_PROPERTY_INSIGHTS" | "PROVIDER_GOOGLE_GEO_CONSUMER_MERCHANT_EXPERIMENTS" | "PROVIDER_GOOGLE_GEO_PORTKEY" | "PROVIDER_GOOGLE_ROAD_MAPPER" | "PROVIDER_GOOGLE_LOCATION_PLATFORM" | "PROVIDER_GOOGLE_POSTTRIP" | "PROVIDER_GOOGLE_TRAVEL_DESTINATION" | "PROVIDER_GOOGLE_GEO_DATA_UPLOAD" | "PROVIDER_GOOGLE_BIZBUILDER_CLEANUP" | "PROVIDER_GOOGLE_USER" | "PROVIDER_GOOGLE_STATION" | "PROVIDER_GOOGLE_GEO_FOOD" | "PROVIDER_GOOGLE_GEO_AR" | "PROVIDER_GOOGLE_GEO_TEMPORAL" | "PROVIDER_GOOGLE_SERVICES_MARKETPLACE" | "PROVIDER_GOOGLE_IMT_CLEANUP" | "PROVIDER_GOOGLE_GEO_FOOD_MENU" | "PROVIDER_GOOGLE_CARENAV" | "PROVIDER_GOOGLE_DRIVING_FEEDS" | "PROVIDER_GOOGLE_DRIVING_UGC" | "PROVIDER_GOOGLE_POLAR" | "PROVIDER_GOOGLE_TRIWILD" | "PROVIDER_GOOGLE_CROWD_COMPUTE_OPS" | "PROVIDER_GOOGLE_SA_FROM_WEB" | "PROVIDER_GOOGLE_POI_ALIGNMENT" | "PROVIDER_GOOGLE_SA_FROM_HULK" | "PROVIDER_GOOGLE_SERVICES_INTERACTIONS" | "PROVIDER_GOOGLE_ROADS_UGC_EDITOR" | "PROVIDER_GOOGLE_SA_FROM_NG_INFERENCE" | "PROVIDER_GOOGLE_GEO_DRIVING_VIZ" | "PROVIDER_GOOGLE_GEO_TASKING" | "PROVIDER_GOOGLE_CROWDTASK_DATACOMPUTE" | "PROVIDER_GOOGLE_CROWDTASK_TASKADS" | "PROVIDER_GOOGLE_CROWDTASK_TASKMATE" | "PROVIDER_GOOGLE_CROWDTASK_FURBALL" | "PROVIDER_GOOGLE_CROWDTASK_ADAP" | "PROVIDER_GOOGLE_GPAY" | "PROVIDER_GOOGLE_GEO_UGC_TRUSTED_USERS" | "PROVIDER_GOOGLE_THIRD_PARTY_DATA_PRODUCTION" | "PROVIDER_GOOGLE_GEOTRACKER" | "PROVIDER_GOOGLE_LOCAL_LANDMARK_INFERENCE" | "PROVIDER_GOOGLE_GEO_CLOSED_LOOP" | "PROVIDER_GOOGLE_SA_FROM_MERCHANT_POSTS" | "PROVIDER_GOOGLE_CORE_DATA_RIGHTS" | "PROVIDER_GOOGLE_SA_FROM_USER_REVIEWS" | "PROVIDER_GOOGLE_GEO_CONTENT_FIXER" | "PROVIDER_GOOGLE_POLYGON_REFINEMENT" | "PROVIDER_GOOGLE_HANASU" | "PROVIDER_GOOGLE_FULLRIGHTS_GEO_DATA_UPLOAD" | "PROVIDER_GOOGLE_FULLRIGHTS_3P_OUTREACH_UPLOAD" | "PROVIDER_GOOGLE_ATTRIBUTION_3P_OUTREACH_UPLOAD" | "PROVIDER_GOOGLE_SA_FROM_FOOD_MENUS" | "PROVIDER_GOOGLE_GT_CONSISTENCY_EDITS" | "PROVIDER_GOOGLE_SA_QUALITY" | "PROVIDER_GOOGLE_GDCE_CLEANUP" | "PROVIDER_GOOGLE_UGC_QUALITY_CHAINS" | "PROVIDER_GOOGLE_ATTRIBUTES_DISCOVERY" | "PROVIDER_GOOGLE_GEO_LDE" | "PROVIDER_GOOGLE_GEO_SIGNAL_TRACKING" | "PROVIDER_GOOGLE_UGC_AGGREGATION" | "PROVIDER_GOOGLE_3D_BASEMAP" | "PROVIDER_GOOGLE_MAPFACTS_PRIVACY" | "PROVIDER_GOOGLE_GT_ALF" | "PROVIDER_GOOGLE_GT_OPERATOR_PROVENANCE" | "PROVIDER_GOOGLE_LOCAL_SERVICES_ADS" | "PROVIDER_GOOGLE_LOCALSEARCH" | "PROVIDER_GOOGLE_TRANSIT" | "PROVIDER_GOOGLE_GEOWIKI" | "PROVIDER_GOOGLE_CHINA_LOCAL_TEAM" | "PROVIDER_GOOGLE_SYNTHESIZED" | "PROVIDER_GOOGLE_INTERNAL_TEST" | "PROVIDER_GOOGLE_DISPUTED_AREAS" | "PROVIDER_GOOGLE_3DWAREHOUSE" | "PROVIDER_GOOGLE_GROUNDS_BUILDER" | "PROVIDER_GOOGLE_SESAME" | "PROVIDER_GOOGLE_GT" | "PROVIDER_GOOGLE_GT_BASEMAP_UPLOAD" | "PROVIDER_GOOGLE_ADSDB" | "PROVIDER_GOOGLE_MACHINE_TRANSLITERATION" | "PROVIDER_GOOGLE_TRAVELSEARCH" | "PROVIDER_GOOGLE_PANORAMIO" | "PROVIDER_GOOGLE_YOUTUBE" | "PROVIDER_GOOGLE_OLD" | "PROVIDER_GOOGLE_STREETVIEW" | "PROVIDER_GOOGLE_STREETVIEW_BIZVIEW" | "PROVIDER_GOOGLE_ZIPIT" | "PROVIDER_GOOGLE_OYSTER_CONNECT_ROUTES" | "PROVIDER_GOOGLE_GOLDEN" | "PROVIDER_GOOGLE_INNERSPACE" | "PROVIDER_GOOGLE_MAPSEARCH" | "PROVIDER_GOOGLE_CATEGORIES_TEAM" | "PROVIDER_GOOGLE_CROWDSENSUS" | "PROVIDER_GOOGLE_LOCAL_ALGORITHMIC_IDENTITY" | "PROVIDER_GOOGLE_FREEBASE" | "PROVIDER_GOOGLE_HOTELADS" | "PROVIDER_GOOGLE_AUTHORITY_PAGES" | "PROVIDER_GOOGLE_PLACES_API" | "PROVIDER_GOOGLE_NAMEHEATMAP" | "PROVIDER_GOOGLE_MAPMAKER" | "PROVIDER_GOOGLE_MAPMAKER_MOBILE" | "PROVIDER_GOOGLE_MAPMAKER_PANCAKE" | "PROVIDER_GOOGLE_MAPMAKER_V2" | "PROVIDER_GOOGLE_LOCAL_CLUSTERING_OPERATOR_OVERRIDE" | "PROVIDER_GOOGLE_SERVED_ON_MAPMAKER" | "PROVIDER_GOOGLE_GT_LOCAL" | "PROVIDER_GOOGLE_GT_LOCAL_WITH_RIGHTS" | "PROVIDER_GOOGLE_LOGS_RANKING_SIGNALS" | "PROVIDER_GOOGLE_ENTITY_NAVBOOST" | "PROVIDER_GOOGLE_RELATED_PLACES" | "PROVIDER_GOOGLE_KNOWN_FOR_TERMS" | "PROVIDER_GOOGLE_SYNTHETIC_AREAS" | "PROVIDER_GOOGLE_AUTHORITY_PAGE_PHOTOS" | "PROVIDER_GOOGLE_CROSS_STREETS" | "PROVIDER_GOOGLE_CORRIDORS" | "PROVIDER_GOOGLE_BICYCLE_RENTAL" | "PROVIDER_GOOGLE_CONCRETE_URLS" | "PROVIDER_GOOGLE_LEANBACK" | "PROVIDER_GOOGLE_LOCKED_LISTINGS" | "PROVIDER_GOOGLE_MONITORING" | "PROVIDER_GOOGLE_SPROUT" | "PROVIDER_GOOGLE_LOCAL_SEARCH_QUALITY" | "PROVIDER_GOOGLE_GOBY" | "PROVIDER_GOOGLE_PROBLEM_REPORT" | "PROVIDER_GOOGLE_CANDID" | "PROVIDER_GOOGLE_BIZBUILDER" | "PROVIDER_AUTOMOTIVE_NAVIGATION_DATA" | "PROVIDER_MAPDATA_SCIENCES" | "PROVIDER_MAPONICS" | "PROVIDER_SKI_RESORTS" | "PROVIDER_ZENRIN" | "PROVIDER_SANBORN" | "PROVIDER_URBAN_MAPPING" | "PROVIDER_US_GOVERNMENT" | "PROVIDER_US_CENSUS" | "PROVIDER_US_POSTAL_SERVICE" | "PROVIDER_US_GEOLOGICAL_SURVEY" | "PROVIDER_US_GNIS" | "PROVIDER_US_LANDSAT" | "PROVIDER_US_NATIONAL_GEOSPATIAL_INTELLIGENCE_AGENCY" | "PROVIDER_US_NGA_GNS" | "PROVIDER_US_SSIBL" | "PROVIDER_US_BUREAU_OF_TRANSPORTATION_STATISTICS" | "PROVIDER_US_NATIONAL_OCEANIC_AND_ATMOSPHERIC_ADMINISTRATION" | "PROVIDER_US_POLAR_GEOSPATIAL_CENTER" | "PROVIDER_US_DEPARTMENT_OF_AGRICULTURE" | "PROVIDER_US_NPI_REGISTRY" | "PROVIDER_US_BUREAU_OF_INDIAN_AFFAIRS" | "PROVIDER_DMTI_SPATIAL" | "PROVIDER_INTERNATIONAL_HYDROGRAPHIC_ORGANIZATION" | "PROVIDER_MAPLINK" | "PROVIDER_KINGWAY" | "PROVIDER_GEOCENTRE" | "PROVIDER_CN_NATIONAL_FOUNDAMENTAL_GIS" | "PROVIDER_CN_MAPABC" | "PROVIDER_SMITHSONIAN_INSTITUTE" | "PROVIDER_TRACKS_FOR_AFRICA" | "PROVIDER_PPWK" | "PROVIDER_LEADDOG" | "PROVIDER_CENTRE_DONNEES_ASTRONOMIQUES_STRASBOURG" | "PROVIDER_GISRAEL" | "PROVIDER_BASARSOFT" | "PROVIDER_MAPINFO" | "PROVIDER_MAPIT" | "PROVIDER_GEOBASE" | "PROVIDER_ORION" | "PROVIDER_CENTRAL_EUROPEAN_DATA_AGENCY" | "PROVIDER_ANASAT" | "PROVIDER_MINED_POSTCODES" | "PROVIDER_DMAPAS" | "PROVIDER_COMMON_LOCALE_DATA_REPOSITORY" | "PROVIDER_CH_SBB" | "PROVIDER_SKENERGY" | "PROVIDER_GBRMPA" | "PROVIDER_KOREA_POST" | "PROVIDER_CN_AUTONAVI" | "PROVIDER_MINED_POI" | "PROVIDER_ML_INFOMAP" | "PROVIDER_SNOOPER" | "PROVIDER_GEOSISTEMAS" | "PROVIDER_AFRIGIS" | "PROVIDER_TRANSNAVICOM" | "PROVIDER_EASYCONNECT" | "PROVIDER_LANTMATERIET" | "PROVIDER_LOGICA" | "PROVIDER_MAPKING" | "PROVIDER_DIANPING" | "PROVIDER_GEONAV" | "PROVIDER_HEIBONSHA" | "PROVIDER_DEUTSCHE_TELEKOM" | "PROVIDER_LINGUISTIC_DATA_CONSORTIUM" | "PROVIDER_ACXIOM" | "PROVIDER_DUN_AND_BRADSTREET" | "PROVIDER_FEDERAL_AVIATION_ADMINISTRATION" | "PROVIDER_INFOUSA" | "PROVIDER_INFOUSA_NIXIE" | "PROVIDER_THOMSON_LOCAL" | "PROVIDER_TELEFONICA_PUBLICIDAD_E_INFORMACION" | "PROVIDER_WIKIPEDIA" | "PROVIDER_INFOBEL" | "PROVIDER_MX_GOVERNMENT" | "PROVIDER_MX_NATIONAL_INSTITUTE_STATISTICS_GEOGRAPHY" | "PROVIDER_MX_SERVICIO_POSTAL_MEXICANO" | "PROVIDER_TELEGATE" | "PROVIDER_TELELISTAS" | "PROVIDER_MAPCITY" | "PROVIDER_EXPLAINER_DC" | "PROVIDER_DAIKEI" | "PROVIDER_NL_CHAMBER_OF_COMMERCE" | "PROVIDER_KOREA_INFO_SERVICE" | "PROVIDER_WIKITRAVEL" | "PROVIDER_FLICKR" | "PROVIDER_DIANCO" | "PROVIDER_VOLT_DELTA" | "PROVIDER_SG_GOVERNMENT" | "PROVIDER_SG_LAND_TRANSPORT_AUTHORITY" | "PROVIDER_MAPBAR" | "PROVIDER_LONGTU" | "PROVIDER_SA_GOVERNMENT" | "PROVIDER_SA_SAUDI_POST" | "PROVIDER_PEAKLIST" | "PROVIDER_LOCAL_BUSINESS_CENTER" | "PROVIDER_LOCAL_FEED_XML" | "PROVIDER_WEB" | "PROVIDER_RAILS_TO_TRAILS" | "PROVIDER_INDIACOM" | "PROVIDER_INFOMEDIA" | "PROVIDER_PICASA" | "PROVIDER_AT_GOVERNMENT" | "PROVIDER_AT_BUNDESAMT_FUR_EICH_UND_VERMESSUNGSWESEN" | "PROVIDER_AT_NATIONAL_TOURIST_OFFICE" | "PROVIDER_AT_AUSTRIA_POST" | "PROVIDER_NO_GOVERNMENT" | "PROVIDER_NO_NORSK_EIENDOMSINFORMASJON" | "PROVIDER_NO_POSTEN_NORGE_AS" | "PROVIDER_CH_GOVERNMENT" | "PROVIDER_CH_SWISS_POST" | "PROVIDER_CH_SWISSTOPO" | "PROVIDER_CH_SWISS_NATIONAL_PARK" | "PROVIDER_NAVIT" | "PROVIDER_GEOSEARCH" | "PROVIDER_DE_GOVERNMENT" | "PROVIDER_BUNDESAMT_KARTOGRAPHIE_UND_GEODASIE" | "PROVIDER_BUNDESNETZAGENTUR" | "PROVIDER_SCHOBER_GROUP" | "PROVIDER_MIREO" | "PROVIDER_PUBLIC_MUNICIPALITY" | "PROVIDER_US_PUBLIC_MUNICIPALITY" | "PROVIDER_US_PUBLIC_MUNICIPALITY_WEBSTER_TEXAS" | "PROVIDER_US_PUBLIC_MUNICIPALITY_AMHERST_MASSACHUSETTS" | "PROVIDER_US_PUBLIC_MUNICIPALITY_BLOOMINGTON_INDIANA" | "PROVIDER_US_PUBLIC_MUNICIPALITY_PASADENA_CALIFORNIA" | "PROVIDER_US_PUBLIC_MUNICIPALITY_CHULA_VISTA_CALIFORNIA" | "PROVIDER_US_PUBLIC_MUNICIPALITY_TEMPE_ARIZONA" | "PROVIDER_US_PUBLIC_MUNICIPALITY_COLUMBUS_OHIO" | "PROVIDER_US_PUBLIC_MUNICIPALITY_PORTAGE_MICHIGAN" | "PROVIDER_US_PUBLIC_MUNICIPALITY_GEORGETOWN_KENTUCKY" | "PROVIDER_US_PUBLIC_MUNICIPALITY_GREENVILLE_SOUTH_CAROLINA" | "PROVIDER_US_PUBLIC_MUNICIPALITY_NASHVILLE_TENNESSEE" | "PROVIDER_US_PUBLIC_MUNICIPALITY_WASHINGTON_DISTRICT_OF_COLUMBIA" | "PROVIDER_US_PUBLIC_MUNICIPALITY_BOULDER_COLORADO" | "PROVIDER_NZ_PUBLIC_MUNICIPALITY" | "PROVIDER_NZ_PUBLIC_MUNICIPALITY_ENVIRONMENT_BAY" | "PROVIDER_PL_PUBLIC_MUNICIPALITY" | "PROVIDER_PL_PUBLIC_MUNICIPALITY_BIELSKO_BIALA" | "PROVIDER_DE_PUBLIC_MUNICIPALITY" | "PROVIDER_DE_PUBLIC_MUNICIPALITY_FRANKFURT" | "PROVIDER_DE_PUBLIC_MUNICIPALITY_HAMBURG" | "PROVIDER_DE_PUBLIC_MUNICIPALITY_KARLSRUHE" | "PROVIDER_PT_PUBLIC_MUNICIPALITY" | "PROVIDER_PT_PUBLIC_MUNICIPALITY_SANTA_CRUZ" | "PROVIDER_AT_PUBLIC_MUNICIPALITY" | "PROVIDER_AT_PUBLIC_MUNICIPALITY_KLAGENFURT" | "PROVIDER_AT_PUBLIC_MUNICIPALITY_LINZ" | "PROVIDER_ES_PUBLIC_MUNICIPALITY" | "PROVIDER_ES_PUBLIC_MUNICIPALITY_AZKOITIA" | "PROVIDER_ES_PUBLIC_MUNICIPALITY_BEASAIN" | "PROVIDER_ES_PUBLIC_MUNICIPALITY_GIRONA" | "PROVIDER_ES_PUBLIC_MUNICIPALITY_SAN_SEBASTIAN" | "PROVIDER_ES_PUBLIC_MUNICIPALITY_CATALUNYA" | "PROVIDER_ES_PUBLIC_MUNICIPALITY_HONDARRIBIA" | "PROVIDER_AU_PUBLIC_MUNICIPALITY" | "PROVIDER_AU_PUBLIC_MUNICIPALITY_LAUNCESTON_TASMANIA" | "PROVIDER_IS_PUBLIC_MUNICIPALITY" | "PROVIDER_IS_PUBLIC_MUNICIPALITY_REYKJAVIK" | "PROVIDER_NL_PUBLIC_MUNICIPALITY" | "PROVIDER_NL_PUBLIC_MUNICIPALITY_AMELSTEVEEN" | "PROVIDER_BE_PUBLIC_MUNICIPALITY" | "PROVIDER_BE_PUBLIC_MUNICIPALITY_ANTWERPEN" | "PROVIDER_CA_PUBLIC_MUNICIPALITY" | "PROVIDER_CA_PUBLIC_MUNICIPALITY_FREDERICTON_NEW_BRUNSWICK" | "PROVIDER_CA_PUBLIC_MUNICIPALITY_KAMLOOPS_BRITISH_COLUMBIA" | "PROVIDER_CA_PUBLIC_MUNICIPALITY_NANAIMO_BRITISH_COLUMBIA" | "PROVIDER_CA_PUBLIC_MUNICIPALITY_BANFF_ALBERTA" | "PROVIDER_CA_PUBLIC_MUNICIPALITY_CALGARY_ALBERTA" | "PROVIDER_CA_PUBLIC_MUNICIPALITY_TORONTO_ONTARIO" | "PROVIDER_SE_PUBLIC_MUNICIPALITY" | "PROVIDER_SE_PUBLIC_MUNICIPALITY_UMEA" | "PROVIDER_UA_PUBLIC_MUNICIPALITY" | "PROVIDER_UA_PUBLIC_MUNICIPALITY_KHARKIV" | "PROVIDER_OTHER_PUBLIC_MUNICIPALITY" | "PROVIDER_OTHER_PUBLIC_MUNICIPALITY_AQUA_CALIENTE_CAHUILLA_INDIANS" | "PROVIDER_FR_PUBLIC_MUNICIPALITY" | "PROVIDER_FR_PUBLIC_MUNICIPALITY_PONT_AUDEMER" | "PROVIDER_FR_PUBLIC_MUNICIPALITY_BORDEAUX" | "PROVIDER_SG_PUBLIC_MUNICIPALITY" | "PROVIDER_BR_PUBLIC_MUNICIPALITY" | "PROVIDER_BR_PUBLIC_MUNICIPALITY_RIO_DE_JANEIRO" | "PROVIDER_MAPCUBE" | "PROVIDER_3D_REALITYMAPS" | "PROVIDER_DEUTSCHES_ZENTRUM_FUR_LUFT_UND_RAUMFAHRT" | "PROVIDER_3D_CITIES_SOCIEDADE_ANONIMA" | "PROVIDER_DISNEY" | "PROVIDER_CYBERCITY" | "PROVIDER_PRECISION_LIGHTWORKS_MODELWORKS" | "PROVIDER_VIRTUAL_HUNGARY_LIMITED" | "PROVIDER_VIRTUEL_CITY" | "PROVIDER_SCREAMPOINT_INTERNATIONAL" | "PROVIDER_AGENTSCHAP_VOOR_GEOGRAFISCHE_INFORMATIE_VLAANDEREN" | "PROVIDER_FR_GOVERNMENT" | "PROVIDER_FR_INSTITUT_GEOGRAPHIQUE_NATIONAL" | "PROVIDER_FR_CADASTRE" | "PROVIDER_DIADIEM" | "PROVIDER_THE_WEATHER_CHANNEL" | "PROVIDER_COWI" | "PROVIDER_FALKPLAN_ANDES" | "PROVIDER_NL_GOVERNMENT" | "PROVIDER_NL_KADASTER" | "PROVIDER_NL_BOARD_OF_TOURISM_AND_CONVENTIONS" | "PROVIDER_DIGITAL_MAP_PRODUCTS" | "PROVIDER_SILICE_DIGITAL" | "PROVIDER_TYDAC" | "PROVIDER_ALBRECHT_GOLF" | "PROVIDER_HEALTH_CH" | "PROVIDER_VISITDENMARK" | "PROVIDER_FLYHERE" | "PROVIDER_DIGITAL_DATA_SERVICES" | "PROVIDER_MECOMO" | "PROVIDER_ZA_GOVERNMENT" | "PROVIDER_ZA_RURAL_DEVELOPMENT_LAND_REFORM" | "PROVIDER_SENSIS" | "PROVIDER_JJCONNECT" | "PROVIDER_OPPLYSNINGEN" | "PROVIDER_TELLUS" | "PROVIDER_IQONIA" | "PROVIDER_BE_GOVERNMENT" | "PROVIDER_BE_NATIONAAL_GEOGRAFISCH_INSTITUUT" | "PROVIDER_BE_BRUSSELS_MOBILITY" | "PROVIDER_YELLOWMAP_AG" | "PROVIDER_STIFTUNG_GESUNDHEIT" | "PROVIDER_GIATA" | "PROVIDER_SANPARKS" | "PROVIDER_CENTRE_DINFORMATIQUE_POUR_LA_REGION_BRUXELLOISE" | "PROVIDER_INFOPORTUGAL" | "PROVIDER_NEGOCIOS_DE_TELECOMUNICACOES_E_SISTEMAS_DE_INFORMACAO" | "PROVIDER_COLLINS_BARTHOLOMEW" | "PROVIDER_PROTECT_PLANET_OCEAN" | "PROVIDER_KARTTAKESKUS" | "PROVIDER_FI_GOVERNMENT" | "PROVIDER_FI_NATIONAL_ROAD_ADMINISTRATION" | "PROVIDER_FI_NATIONAL_LAND_SURVEY" | "PROVIDER_FI_STATISTICS_FINLAND" | "PROVIDER_GB_GOVERNMENT" | "PROVIDER_GB_ORDNANCE_SURVEY" | "PROVIDER_NATURAL_ENGLAND" | "PROVIDER_WELSH_GOVERNMENT" | "PROVIDER_GB_OFFICE_FOR_NATIONAL_STATISTICS" | "PROVIDER_EPSILON" | "PROVIDER_PARTNER_FRONT_END" | "PROVIDER_CARTESIA" | "PROVIDER_SE_GOVERNMENT" | "PROVIDER_SE_TRAFIKVERKET" | "PROVIDER_SE_NATURVARDSVERKET" | "PROVIDER_IE_GOVERNMENT" | "PROVIDER_IE_ORDNANCE_SURVEY_IRELAND" | "PROVIDER_LU_GOVERNMENT" | "PROVIDER_LU_P_AND_T_LUXEMBOURG" | "PROVIDER_LU_ADMINISTRATION_DU_CADASTRE_ET_DE_LA_TOPOGRAPHIE" | "PROVIDER_LU_NATIONAL_TOURIST_OFFICE" | "PROVIDER_MAPFLOW" | "PROVIDER_TKARTOR" | "PROVIDER_JUMPSTART" | "PROVIDER_EPTISA" | "PROVIDER_MC_GOVERNMENT" | "PROVIDER_MC_PRINCIPAUTE_DE_MONACO" | "PROVIDER_MONOLIT" | "PROVIDER_ENVIRONMENTAL_SYSTEMS_RESEARCH_INSTITUTE" | "PROVIDER_MODIS" | "PROVIDER_GEOX" | "PROVIDER_GEODIRECTORY" | "PROVIDER_GEOPLAN" | "PROVIDER_INFODIREKT" | "PROVIDER_GEOGLOBAL" | "PROVIDER_DEUTSCHE_POST" | "PROVIDER_TRACASA" | "PROVIDER_CORREOS" | "PROVIDER_ES_GOVERNMENT" | "PROVIDER_ES_CENTRO_NACIONAL_DE_INFORMACION_GEOGRAFICA" | "PROVIDER_EDIMAP" | "PROVIDER_VERIZON" | "PROVIDER_NATIONAL_GEOGRAPHIC_MAPS" | "PROVIDER_PROMAPS" | "PROVIDER_CONSODATA" | "PROVIDER_DE_AGOSTINI" | "PROVIDER_FEDERPARCHI" | "PROVIDER_NAVIGO" | "PROVIDER_ITALIAMAPPE" | "PROVIDER_CZECOT" | "PROVIDER_NATURAL_EARTH" | "PROVIDER_REGIO" | "PROVIDER_SHIPWRECK_CENTRAL" | "PROVIDER_RUTGERS_STATE_UNIVERSITY" | "PROVIDER_TWINICE" | "PROVIDER_NORTHERN_IRELAND_TOURIST_BOARD" | "PROVIDER_INFOGROUP" | "PROVIDER_TNET" | "PROVIDER_CTT_CORREIOS_DE_PORTUGAL" | "PROVIDER_EUROPARC" | "PROVIDER_IUPPITER" | "PROVIDER_MICHAEL_BAUER_INTERNATIONAL" | "PROVIDER_LEPTON" | "PROVIDER_MAPPOINT" | "PROVIDER_GEODATA" | "PROVIDER_RU_GOVERNMENT" | "PROVIDER_RU_FNS_KLADR" | "PROVIDER_BR_GOVERNMENT" | "PROVIDER_BR_INSTITUTO_BRASILEIRO_DO_MEIO_AMBIENTE_E_DOS_RECURSOS_NATURAIS_RENOVAVEIS" | "PROVIDER_BR_MINISTERIO_DO_MEIO_AMBIENTE" | "PROVIDER_BR_AGENCIA_NACIONAL_DE_AGUAS" | "PROVIDER_BR_INSTITUTO_BRASILEIRO_DE_GEOGRAFIA_E_ESTATISTICA" | "PROVIDER_BR_FUNDACAO_NACIONAL_DO_INDIO" | "PROVIDER_BR_DEPARTAMENTO_NACIONAL_DE_INFRAESTRUTURA_DE_TRANSPORTES" | "PROVIDER_AZAVEA" | "PROVIDER_NORTHSTAR" | "PROVIDER_COMMEDI" | "PROVIDER_NEXUS_GEOGRAFICS" | "PROVIDER_INFOERA" | "PROVIDER_AD_GOVERNMENT" | "PROVIDER_AD_AREA_DE_CARTOGRAFIA" | "PROVIDER_MAXXIMA" | "PROVIDER_SI_GOVERNMENT" | "PROVIDER_SI_AGENCY_FOR_ENVIRONMENT" | "PROVIDER_TRANSPORT_HI_TECH_CONSULTANTS" | "PROVIDER_L1_TECHNOLOGIES" | "PROVIDER_TELEMEDIA" | "PROVIDER_CDCOM_PROGOROD" | "PROVIDER_MIT_CITYGUIDE" | "PROVIDER_SUNCART" | "PROVIDER_MICROMAPPER" | "PROVIDER_RICHI" | "PROVIDER_FORUM44" | "PROVIDER_SEAT" | "PROVIDER_VALASSIS" | "PROVIDER_NAVICOM" | "PROVIDER_COLTRACK" | "PROVIDER_PSMA_AUSTRALIA" | "PROVIDER_PT_DUTA_ASTAKONA_GIRINDA" | "PROVIDER_CA_GOVERNMENT" | "PROVIDER_STATISTICS_CANADA" | "PROVIDER_TOCTOC" | "PROVIDER_RMSI" | "PROVIDER_TRUE_TECHNOLOGY" | "PROVIDER_INCREMENT_P_CORPORATION" | "PROVIDER_GOJAVAS" | "PROVIDER_GEOINFORMATION_GROUP" | "PROVIDER_CYBERSOFT" | "PROVIDER_TSENTR_EFFEKTIVNYKH_TEKHNOLOGIY" | "PROVIDER_EE_GOVERNMENT" | "PROVIDER_EE_MAA_AMET" | "PROVIDER_GASBUDDY" | "PROVIDER_DK_GOVERNMENT" | "PROVIDER_DK_GEODATASTYRELSEN" | "PROVIDER_MURCIA_REGION_GOVERNMENT" | "PROVIDER_CORREIOS" | "PROVIDER_WEST_WORLD_MEDIA" | "PROVIDER_INTERNATIONAL_MAPPING_ASSOCIATION" | "PROVIDER_MEDICARE" | "PROVIDER_POLARIS" | "PROVIDER_TW_GOVERNMENT" | "PROVIDER_TW_MINISTRY_OF_THE_INTERIOR_SURVEYING_AND_MAPPING_CENTER" | "PROVIDER_NORDECA" | "PROVIDER_AFRIMAPPING" | "PROVIDER_OVERDRIVE" | "PROVIDER_PROVIDER_NETWORK_DIRECTORIES" | "PROVIDER_BR_MINISTERIO_DA_SAUDE" | "PROVIDER_DIGITAL_EGYPT" | "PROVIDER_INRIX" | "PROVIDER_ARPINDO" | "PROVIDER_IT_GOVERNMENT" | "PROVIDER_ISTITUTO_GEOGRAFICO_MILITARE" | "PROVIDER_EAST_END_GROUP" | "PROVIDER_INGEOLAN" | "PROVIDER_SEMACONNECT" | "PROVIDER_BLINK" | "PROVIDER_EVGO" | "PROVIDER_CHARGEPOINT" | "PROVIDER_TPL_TRAKKER" | "PROVIDER_OI" | "PROVIDER_MAPARADAR" | "PROVIDER_SINGAPORE_POST" | "PROVIDER_CHARGEMASTER" | "PROVIDER_TESLA" | "PROVIDER_VISICOM" | "PROVIDER_GEOLYSIS" | "PROVIDER_ZEPHEIRA" | "PROVIDER_HUBJECT" | "PROVIDER_PODPOINT" | "PROVIDER_CHARGEFOX" | "PROVIDER_KR_GOVERNMENT" | "PROVIDER_KR_MOLIT" | "PROVIDER_KR_MINISTRY_OF_THE_INTERIOR_AND_SAFETY" | "PROVIDER_CRITCHLOW" | "PROVIDER_EIFRIG" | "PROVIDER_GIREVE" | "PROVIDER_CN_NAVINFO" | "PROVIDER_JAPAN_CHARGE_NETWORK" | "PROVIDER_NOBIL" | "PROVIDER_INDIA_BANKS" | "PROVIDER_INDONESIA_ELECTION_KPU" | "PROVIDER_CAREERS360" | "PROVIDER_SOURCE_LONDON" | "PROVIDER_EVBOX" | "PROVIDER_JP_GOVERNMENT" | "PROVIDER_JP_MINISTRY_OF_THE_ENVIRONMENT" | "PROVIDER_YUMYUM" | "PROVIDER_HWW_AUSTRALIA" | "PROVIDER_CINERGY" | "PROVIDER_MTIME" | "PROVIDER_KULTUNAUT" | "PROVIDER_BLITZ" | "PROVIDER_PIA" | "PROVIDER_INTERPARK" | "PROVIDER_CINEMA_ONLINE" | "PROVIDER_BELBIOS" | "PROVIDER_MOVIESEER" | "PROVIDER_SODAMEDYA" | "PROVIDER_ATMOVIES" | "PROVIDER_HOTELBEDS" | "PROVIDER_VERICRED" | "PROVIDER_CIRRANTIC" | "PROVIDER_GOGO_LABS" | "PROVIDER_ELECTRIFY_AMERICA" | "PROVIDER_CMS_MPPUF" | "PROVIDER_DIGIROAD" | "PROVIDER_KONTEX_GEOMATICS" | "PROVIDER_NZ_GOVERNMENT" | "PROVIDER_NZ_LINZ" | "PROVIDER_NZ_DOC" | "PROVIDER_FASTNED" | "PROVIDER_DESTINY_CS" | "PROVIDER_IONITY" | "PROVIDER_EV_CONNECT" | "PROVIDER_PANPAGES" | "PROVIDER_ETECNIC" | "PROVIDER_VOLTA" | "PROVIDER_NISSAN_MEXICO" | "PROVIDER_BMW_GROUP_LATIN_AMERICA" | "PROVIDER_FEDERAL_ELECTRICITY_COMMISSION_MEXICO" | "PROVIDER_VOLVO_CARS_BRASIL" | "PROVIDER_CHARGE_AND_PARKING" | "PROVIDER_DEDUCE_TECHNOLOGIES" | "PROVIDER_SK_TELECOM" | "PROVIDER_ECO_MOVEMENT" | "PROVIDER_GOOGLE_GMS" | "PROVIDER_EASYWAY" | "PROVIDER_PHYSICIAN_COMPARE" | "PROVIDER_HOSPITAL_COMPARE" | "PROVIDER_ENDOLLA_BARCELONA" | "PROVIDER_BE_CHARGE" | "PROVIDER_ONE_NETWORK" | "PROVIDER_CARENAV_DUPLEX" | "PROVIDER_CARENAV_POI" | "PROVIDER_IN_GOVERNMENT" | "PROVIDER_SURVEY_OF_INDIA" | "PROVIDER_E_ON" | "PROVIDER_ELECTRIFY_CANADA" | "PROVIDER_GRIDCARS" | "PROVIDER_DRIVECO" | "PROVIDER_GREEN_ACTION_STUDIOS" | "PROVIDER_GREEN_ACTION_STUDIO" | "PROVIDER_EVINY" | "PROVIDER_MASTERCARD" | "PROVIDER_VATTENFALL" | "PROVIDER_VIETGIS" | "PROVIDER_UNITE" | "PROVIDER_NEOGY" | "PROVIDER_AMPUP" | "PROVIDER_LOOP" | "PROVIDER_ZEST" | "PROVIDER_EZVOLT";
  /**
   * For every key that is used in raw_data from this source, there must be a
   * corresponding entry in raw_metadata that describes this key.
   */
  rawMetadata?: GeostoreRawMetadataProto[];
  /**
   * A release string that doesn't have to be a date. This is provided so that
   * we can preserve provider release strings that aren't based on dates. If you
   * don't set it, the release_date will get formatted into this field for
   * debugging purposes.
   */
  release?: string;
  /**
   * The release date of this data.
   */
  releaseDate?: GeostoreDateTimeProto;
  /**
   * A data provider defined string describing the source dataset from which
   * the features of this data source were generated. For example, the MultiNet
   * "fra" dataset produces features for both France and Monaco.
   */
  sourceDataset?: string;
}

/**
 * WARNING: Outside of FeatureProto, please avoid in favor of a standard civil
 * time type. Direct usage is error-prone due to the conflation of physical time
 * and civil time (go/httat). In a protocol buffer, please use google.type.Date,
 * with an additional google.type.TimeOfDay for precision finer-grained than a
 * day. (For google.type.DateTime, go/prototime#types cites
 * go/httat#zoned_datetime as a caveat). In a programming language, see
 * go/time-devguide/languages. Additionally in C++,
 * google3/geostore/base/public/datetime.h has conversion functions between
 * DateTimeProto and Abseil's civil time types.
 */
export interface GeostoreDateTimeProto {
  /**
   * This attribute describes the precision of the date and time. It would be
   * unusual for a data provider to provide a precision along with their date.
   * It is more likely that the precision of a date will be inferred from the
   * date format. For example "19th century" is likely to be correct to the
   * century, while "1800" is probably correct to the year. The precision should
   * be semantically interpreted as a cast, so a DateTimeProto object with a
   * seconds value corresponding to 2018-03-28 18:40:00 UTC and a precision of
   * MONTH should be interpreted as "March 2018". The enums above are only some
   * of the possible precision levels for dates and times. Clients may wish to
   * add more precision enums in the future. However, these enums must be
   * ordered by decreasing duration. Clients should be able to write date
   * formatting code that looks like this: if (datetime.precision() <=
   * DateTimeProto::PRECISION_CENTURY) { date =
   * FormatCenturyDate(proto.seconds()); } else if (proto.precision() <= case
   * DateTimeProto::PRECISION_DECADE) { date =
   * FormatDecadeDate(proto.seconds()); } else { ... } See
   * geostore/base/public/datetime.h for date formatting utility functions.
   */
  precision?:  | "PRECISION_CENTURY" | "PRECISION_DECADE" | "PRECISION_YEAR" | "PRECISION_MONTH" | "PRECISION_DAY" | "PRECISION_HOUR" | "PRECISION_MINUTE" | "PRECISION_SECOND";
  /**
   * Number of seconds since (or before) the UNIX epoch (January 1, 1970). This
   * is also the standard epoch for Java and Python time representations. If it
   * is important for this time be displayed correctly for different time zones,
   * convert the time to Coordinated Universal Time (UTC).
   */
  seconds?: number;
}

/**
 * A dimension value tagged with a comparison operator. This can be used for
 * height, width, or length.
 */
export interface GeostoreDimensionComparisonProto {
  comparisonOperator?:  | "UNSPECIFIED" | "EQUAL" | "LESS_THAN" | "LESS_THAN_OR_EQUAL" | "GREATER_THAN" | "GREATER_THAN_OR_EQUAL";
  dimensionWithUnit?: GeostoreDimensionProto;
}

/**
 * A dimension with a numerical value and unit. This can be a height, width, or
 * length.
 */
export interface GeostoreDimensionProto {
  dimension?: number;
  unit?:  | "UNIT_UNKNOWN" | "METERS" | "FEET";
}

/**
 * This holds data specific to rendering a POI on a map. It's derived from data
 * already in MapFacts, e.g. containing features and the feature's point field.
 * If empty, this proto should be ignored for rendering. See
 * go/maps-render-alignment for motivation and more details.
 */
export interface GeostoreDisplayDataProto {
  /**
   * The location where this feature should be rendered.
   */
  displayLocation?: GeostorePointProto;
}

/**
 * This protocol buffer holds the doodle-specific attributes for features of
 * type TYPE_DOODLE.
 */
export interface GeostoreDoodleProto {
  /**
   * The type of this feature -- see comments above.
   */
  type?:  | "TYPE_ANY" | "TYPE_USER_DEFINED_LABEL" | "TYPE_POINT_ANNOTATION" | "TYPE_LINE_ANNOTATION" | "TYPE_AREA_ANNOTATION";
}

/**
 * A single cost which will apply based on the duration of utilization. The
 * cost may apply once, or repeatedly on some interval, to account for the total
 * utilization. If the duration expressed by range_start_seconds and
 * range_end_seconds do not cover the entire duration of the utilization (i.e.
 * from 0 to some time greater than the total utilization time), this must be
 * combined with other DurationBasedRateProtos such that the entire duration of
 * the utilization is accounted for. See go/rate-schema for more details.
 */
export interface GeostoreDurationBasedRateProto {
  /**
   * If true, represents that the rate is free; i.e. the price is 0 in any
   * currency. If this is true, price must be empty.
   */
  isFree?: boolean;
  /**
   * The billable unit of the rate; i.e. after having utilized the service for
   * exactly periodicity_seconds, the total cost should increase by price. For
   * example, if the rate expresses a price per hour, then periodicity_seconds
   * should be set to 3600. If this is unset, then the rate does not vary based
   * on duration, and price represents a flat cost. May only be set if price is
   * nonempty.
   */
  periodicitySeconds?: number;
  /**
   * The total price, in each applicable currency, of utilizing the service for
   * periodicity_seconds, or for the entire duration expressed by
   * range_start_seconds and range_end_seconds if periodicity_seconds is 0. Each
   * entry should have an ID of /measurement_unit/money_value and consist of two
   * properties: one with an ID of /measurement_unit/money_value/amount and a
   * float value with the amount, and another with the ID
   * /measurement_unit/money_value/currency and an ID value with the MID of the
   * proper currency. May only be set if is_free is false.
   */
  price?: FreebaseTopic[];
  /**
   * Upper bound for durations to match, exclusive. Unset implies indefinite.
   */
  rangeEndSeconds?: number;
  /**
   * Lower bound for durations to match, inclusive. Required; a value of 0
   * expresses that the price applies from the start of the utilization period.
   */
  rangeStartSeconds?: number;
}

function serializeGeostoreDurationBasedRateProto(data: any): GeostoreDurationBasedRateProto {
  return {
    ...data,
    price: data["price"] !== undefined ? data["price"].map((item: any) => (serializeFreebaseTopic(item))) : undefined,
  };
}

function deserializeGeostoreDurationBasedRateProto(data: any): GeostoreDurationBasedRateProto {
  return {
    ...data,
    price: data["price"] !== undefined ? data["price"].map((item: any) => (deserializeFreebaseTopic(item))) : undefined,
  };
}

/**
 * Represents raster digital elevation model data.
 */
export interface GeostoreElevationModelProto {
  /**
   * Defines the relative order in which terrain data should be rendered.
   * Features with higher blend_order should be blended on top of features with
   * lower blend_order. NOTE: this is backwards from the way BlendRank works in
   * Magrathean.
   */
  blendOrder?: number;
  /**
   * The zoom level at which this data is defined. Level 0 is world level data,
   * and each increase in zoom level corresponds to a factor of 2 increase in
   * scale.
   */
  dataLevel?: number;
  /**
   * The maximum (finest) level at which this terrain data has sufficient
   * resolution to be displayed.
   */
  dataMaxlevel?: number;
  /**
   * A place to store an elevation data protocol buffer. Currently, this must
   * be a keyhole::AssetTileCompressed (see
   * google3/keyhole/common/proto/magrathean.protodevel).
   */
  elevationData?: Proto2BridgeMessageSet;
  /**
   * If true, all of the data contained in this feature is available at the
   * next highest (more detailed) level. If this is true,
   * partial_child_data_available should also be true.
   */
  fullChildDataAvailable?: boolean;
  /**
   * If true, at least part of the data contained in this feature is available
   * at the next highest (more detailed) level.
   */
  partialChildDataAvailable?: boolean;
}

/**
 * This protocol buffer holds elevation and related data.
 */
export interface GeostoreElevationProto {
  /**
   * The average elevation of the feature in meters above the local mean sea
   * level.
   */
  averageElevationMeters?: number;
  /**
   * Additional details for TYPE_PEAK and TYPE_VOLCANO features.
   */
  peak?: GeostorePeakProto;
}

/**
 * This protocol buffer holds entrance-specific attributes for features of type
 * TYPE_ENTRANCE.
 */
export interface GeostoreEntranceProto {
  allowance?:  | "ENTER_AND_EXIT" | "ENTER_ONLY" | "EXIT_ONLY";
  /**
   * DEPRECATED. Please use enter_or_exit instead.
   */
  canEnter?: boolean;
  /**
   * Whether the target can be entered through this entrance. Whether the
   * target can be exited through this entrance.
   */
  canExit?: boolean;
}

/**
 * Models a relationship between a feature and its entrance or exit.
 */
export interface GeostoreEntranceReferenceProto {
  /**
   * Feature ID of the related entrance. References should refer to
   * TYPE_ENTRANCE or TYPE_COMPOUND features that are entrances or exits of the
   * referencing feature.
   */
  featureId?: GeostoreFeatureIdProto;
}

function serializeGeostoreEntranceReferenceProto(data: any): GeostoreEntranceReferenceProto {
  return {
    ...data,
    featureId: data["featureId"] !== undefined ? serializeGeostoreFeatureIdProto(data["featureId"]) : undefined,
  };
}

function deserializeGeostoreEntranceReferenceProto(data: any): GeostoreEntranceReferenceProto {
  return {
    ...data,
    featureId: data["featureId"] !== undefined ? deserializeGeostoreFeatureIdProto(data["featureId"]) : undefined,
  };
}

/**
 * This protocol buffer holds establishment-specific attributes for features of
 * type TYPE_ESTABLISHMENT.
 */
export interface GeostoreEstablishmentProto {
  /**
   * Reference to BizBuilder data for this establishment. The
   * bizbuilder_reference field indicates that a feature is claimed in CBDB
   * (with the canonical state in MapFacts). The bizbuilder_reference is
   * different from the social_reference's claimed_gaia_id because some
   * BizBuilder clients will not have +Pages. All claimed businesses should have
   * a bizbuilder_reference.
   */
  bizbuilderReference?: GeostoreBizBuilderReferenceProto;
  /**
   * Regular opening hours for the establishment (weekly schedule).
   */
  hours?: GeostoreTimeScheduleProto;
  /**
   * Opening hours for this establishment, including regular weekly hours and
   * exceptional hours (e.g. on holidays). NOTE: in practice, only the
   * exceptional hours are filled in this message. A schema migration for
   * regular weekly hours was planned back in 2015 (see b/23105782) but was not
   * completed and is (as of May 2018) not prioritized. Clients should continue
   * getting regular opening hours from the `hours` field above. In
   * openinghours.h there is a utility function `GetOpeningHoursFromFeature`
   * that merges `EstablishmentProto.hours` into this proto.
   */
  openingHours?: GeostoreOpeningHoursProto;
  /**
   * Pricing for products and services offered. Example: menus for restaurants.
   */
  priceInfo?: GeostorePriceInfoProto;
  serviceArea?: GeostoreServiceAreaProto;
  /**
   * Telephone number and related information.
   */
  telephone?: GeostoreTelephoneProto[];
  /**
   * ** DEPRECATED ** This is deprecated in favor of the top-level (in
   * FeatureProto) set of GConcepts. The type of establishment -- see comments
   * above.
   */
  type?:  | "TYPE_ANY" | "TYPE_UNDEFINED" | "TYPE_DEPRECATED_AVIATION" | "TYPE_BUSINESS" | "TYPE_TRAVEL_SERVICE" | "TYPE_LODGING" | "TYPE_HOTEL" | "TYPE_RESORT" | "TYPE_MOTEL" | "TYPE_HOSTEL" | "TYPE_GUESTHOUSE" | "TYPE_VACATION_RENTAL" | "TYPE_GAS_STATION" | "TYPE_REST_AREA" | "TYPE_CASH_MACHINE" | "TYPE_CAR_RENTAL" | "TYPE_CAR_REPAIR" | "TYPE_TAXI_STAND" | "TYPE_TRAVEL_AGENT" | "TYPE_BICYCLE_RENTAL_POINT" | "TYPE_ELECTRIC_VEHICLE_CHARGING_STATION" | "TYPE_SHOPPING" | "TYPE_GROCERY" | "TYPE_ANTIQUES" | "TYPE_APPAREL" | "TYPE_GIFTS" | "TYPE_JEWELRY" | "TYPE_SPORTING_GOODS" | "TYPE_VEHICLE" | "TYPE_SHOPPING_CENTER" | "TYPE_SUPERMARKET" | "TYPE_FAIRGROUNDS" | "TYPE_MARKET" | "TYPE_PRODUCE_MARKET" | "TYPE_FARMERS_MARKET" | "TYPE_LIQUOR_STORE" | "TYPE_SOUVENIR_SHOP" | "TYPE_INDUSTRIAL" | "TYPE_CONSTRUCTION" | "TYPE_BUILDING_MATERIAL" | "TYPE_SECURITY_PRODUCTS" | "TYPE_MECHANICAL" | "TYPE_TEXTILE" | "TYPE_CHEMICAL" | "TYPE_METAL" | "TYPE_TRANSPORTATION" | "TYPE_FREIGHT" | "TYPE_AVIATION" | "TYPE_COURIER" | "TYPE_MOVING" | "TYPE_PACKAGING" | "TYPE_RAIL" | "TYPE_PUBLIC_TRANSIT" | "TYPE_WAREHOUSE" | "TYPE_DEFENSE" | "TYPE_AGRICULTURE" | "TYPE_PLANTATION" | "TYPE_PLANT_NURSERY" | "TYPE_DESIGN" | "TYPE_UTILITIES" | "TYPE_POWER_PLANT" | "TYPE_SEWAGE_TREATMENT_PLANT" | "TYPE_WATER_TREATMENT_PLANT" | "TYPE_SUBSTATION" | "TYPE_MANUFACTURING" | "TYPE_BIOTECH" | "TYPE_MATERIALS" | "TYPE_MINING" | "TYPE_QUARRY" | "TYPE_TANNERY" | "TYPE_OIL_REFINERY" | "TYPE_ADVERTISING_MARKETING" | "TYPE_LEGAL" | "TYPE_FAMILY_LAW" | "TYPE_IP_LAW" | "TYPE_LABOR_LAW" | "TYPE_PERSONAL_INJURY_LAW" | "TYPE_CRIMINAL_LAW" | "TYPE_PERSONAL_FINANCE" | "TYPE_LIFE_INSURANCE" | "TYPE_LENDING" | "TYPE_ACCOUNTING" | "TYPE_INVESTING" | "TYPE_BANKING" | "TYPE_HEALTH" | "TYPE_HEALTH_EQUIPMENT" | "TYPE_NURSING" | "TYPE_HEALTH_INSURANCE" | "TYPE_HEALTH_FACILITY" | "TYPE_DIAGNOSTIC_CENTER" | "TYPE_HEALTH_RESOURCES" | "TYPE_NUTRITION" | "TYPE_VISION" | "TYPE_COUNSELING" | "TYPE_MASSAGE" | "TYPE_BLOOD_BANK" | "TYPE_HEARING" | "TYPE_HOME_GARDEN" | "TYPE_INTERIOR_DECOR" | "TYPE_DOMESTIC_SERVICES" | "TYPE_APPLIANCES" | "TYPE_PEST_CONTROL" | "TYPE_GARDENING" | "TYPE_ELECTRONICS" | "TYPE_COMPUTER" | "TYPE_COMPUTER_HARDWARE" | "TYPE_COMPUTER_SECURITY" | "TYPE_COMPUTER_SOFTWARE" | "TYPE_COMPUTER_SUPPORT" | "TYPE_AUDIO_DEVICES" | "TYPE_VIDEO_DEVICES" | "TYPE_REAL_ESTATE" | "TYPE_OFFICE_SERVICES" | "TYPE_ENTERTAINMENT" | "TYPE_GAMES" | "TYPE_CASINO" | "TYPE_LOTTO" | "TYPE_VIDEO" | "TYPE_CLUBS" | "TYPE_DISCOTHEQUE" | "TYPE_ANIMATION" | "TYPE_MODELING" | "TYPE_HUMOR" | "TYPE_MOVIES" | "TYPE_MOVIE_RENTAL" | "TYPE_MOVIE_THEATER" | "TYPE_MUSIC" | "TYPE_RADIO" | "TYPE_TV" | "TYPE_BAR" | "TYPE_PRINT_MEDIA" | "TYPE_ADULT" | "TYPE_SEXUAL_SERVICES" | "TYPE_ANIMALS" | "TYPE_PETS" | "TYPE_FISHERY" | "TYPE_ARTS" | "TYPE_BOOKS" | "TYPE_PERFORMING_ARTS" | "TYPE_GALLERY" | "TYPE_AUTOMOTIVE" | "TYPE_PARTS" | "TYPE_AUTO_FINANCE" | "TYPE_AUTO_INSURANCE" | "TYPE_RV" | "TYPE_MOTORCYCLES" | "TYPE_CARS" | "TYPE_TRUCKS_SUVS" | "TYPE_LICENSING" | "TYPE_MAINTENANCE" | "TYPE_PERSONAL_CARE" | "TYPE_BODY_ART" | "TYPE_COSMETICS" | "TYPE_FITNESS" | "TYPE_YOGA_CENTER" | "TYPE_GYM" | "TYPE_HAIR_CARE" | "TYPE_SPA" | "TYPE_BEAUTY_SALON" | "TYPE_CORPORATE_EVENTS" | "TYPE_HUMAN_RESOURCES" | "TYPE_FOOD_AND_DRINK" | "TYPE_BEVERAGE" | "TYPE_RECIPES" | "TYPE_COOKWARE" | "TYPE_CULINARY" | "TYPE_RETAIL" | "TYPE_RESTAURANT" | "TYPE_COFFEE" | "TYPE_BAKERY" | "TYPE_FOOD_CENTER" | "TYPE_TEA" | "TYPE_CAFE" | "TYPE_WINERY" | "TYPE_BREWERY" | "TYPE_FAST_FOOD" | "TYPE_FOOD_DELIVERY" | "TYPE_INTERNET" | "TYPE_WEB_DESIGN" | "TYPE_WEB_HOSTING" | "TYPE_WEB_SERVICES" | "TYPE_LIFESTYLE" | "TYPE_PHOTO_VIDEO" | "TYPE_ACTIVITIES" | "TYPE_BOATING" | "TYPE_CYCLING" | "TYPE_EQUESTRIAN" | "TYPE_FISHING" | "TYPE_HIKING" | "TYPE_HUNTING" | "TYPE_SWIMMING" | "TYPE_GOLF" | "TYPE_GOLF_COURSE" | "TYPE_BASEBALL" | "TYPE_BASKETBALL" | "TYPE_HOCKEY" | "TYPE_MOTOR_SPORTS" | "TYPE_WINTER_SPORTS" | "TYPE_FOOTBALL" | "TYPE_SOCCER" | "TYPE_ICE_SKATING" | "TYPE_BOXING" | "TYPE_CRICKET" | "TYPE_ROWING" | "TYPE_RUGBY" | "TYPE_RACQUET_SPORTS" | "TYPE_ROCK_CLIMBING" | "TYPE_REFERENCES" | "TYPE_MAPS" | "TYPE_TIME" | "TYPE_SCIENTIFIC_EQUIPMENT" | "TYPE_TELECOMMUNICATIONS" | "TYPE_EVENT_VENUE" | "TYPE_BANQUET_HALL" | "TYPE_CONFERENCE_HALL" | "TYPE_WEDDING_HALL" | "TYPE_EXHIBITION_HALL" | "TYPE_COMMUNITY_CENTER" | "TYPE_AUDITORIUM" | "TYPE_FUNCTION_HALL" | "TYPE_CONCERT_HALL" | "TYPE_AMPHITHEATER" | "TYPE_LAUNDRY" | "TYPE_LAUNDROMAT" | "TYPE_DRY_CLEANER" | "TYPE_MORTUARY" | "TYPE_REPAIR_AND_MAINTENANCE" | "TYPE_GOVERNMENT" | "TYPE_BORDER_CROSSING" | "TYPE_CITY_HALL" | "TYPE_COURTHOUSE" | "TYPE_EMBASSY" | "TYPE_LIBRARY" | "TYPE_PRISON" | "TYPE_TAX_OFFICE" | "TYPE_PROSECUTORS_OFFICE" | "TYPE_CONGRESS" | "TYPE_TOWN_COUNCIL" | "TYPE_CAPITOL_BUILDING" | "TYPE_VOTING_FACILITY" | "TYPE_CHECKPOINT" | "TYPE_SCHOOL" | "TYPE_UNIVERSITY" | "TYPE_ORPHANAGE" | "TYPE_KINDERGARTEN" | "TYPE_DAYCARE" | "TYPE_ACADEMY" | "TYPE_TRADE_SCHOOL" | "TYPE_SKILL_INSTRUCTION" | "TYPE_EMERGENCY" | "TYPE_HOSPITAL" | "TYPE_PHARMACY" | "TYPE_POLICE" | "TYPE_FIRE" | "TYPE_DOCTOR" | "TYPE_DENTIST" | "TYPE_VETERINARIAN" | "TYPE_FIRST_AID" | "TYPE_CIVIL_DEFENSE" | "TYPE_TOURIST_DESTINATION" | "TYPE_ECO_TOURIST_DESTINATION" | "TYPE_BIRD_WATCHING" | "TYPE_NATURE_RESERVE" | "TYPE_MUSEUM" | "TYPE_VISITOR_CENTER" | "TYPE_OBSERVATION_DECK" | "TYPE_OBSERVATORY" | "TYPE_SCENIC_POINT" | "TYPE_ZOO" | "TYPE_AQUARIUM" | "TYPE_AMUSEMENT_PARK" | "TYPE_MONUMENT" | "TYPE_PALACE" | "TYPE_FORT" | "TYPE_TOWER" | "TYPE_LIGHTHOUSE" | "TYPE_TEMPLE" | "TYPE_CHURCH" | "TYPE_GURUDWARA" | "TYPE_HINDU_TEMPLE" | "TYPE_MOSQUE" | "TYPE_SYNAGOGUE" | "TYPE_BUDDHIST_TEMPLE" | "TYPE_JAIN_TEMPLE" | "TYPE_BAHAI_TEMPLE" | "TYPE_SHINTO_TEMPLE" | "TYPE_MORMON_TEMPLE" | "TYPE_SPORTS_COMPLEX" | "TYPE_STADIUM" | "TYPE_BOWLING" | "TYPE_BADMINTON" | "TYPE_TENNIS" | "TYPE_TABLE_TENNIS" | "TYPE_PARK" | "TYPE_LOCAL_PARK" | "TYPE_NATIONAL_PARK" | "TYPE_US_NATIONAL_PARK" | "TYPE_US_NATIONAL_MONUMENT" | "TYPE_NATIONAL_FOREST" | "TYPE_NATIONAL_GRASSLAND" | "TYPE_NATIONAL_PRESERVE" | "TYPE_NATIONAL_RECREATION_AREA" | "TYPE_NATIONAL_MONUMENT" | "TYPE_NATIONAL_HISTORIC_AREA" | "TYPE_NATIONAL_SCENIC_AREA" | "TYPE_NATIONAL_SCENIC_ROADWAY_AREA" | "TYPE_NATIONAL_SCENIC_RIVER_AREA" | "TYPE_PROVINCIAL_PARK" | "TYPE_PROVINCIAL_FOREST" | "TYPE_CAMPGROUNDS" | "TYPE_WILDERNESS_AREA" | "TYPE_WILDLIFE_AREA" | "TYPE_BOTANICAL_GARDEN" | "TYPE_GARDEN" | "TYPE_ARBORETUM" | "TYPE_MARINE_PROTECTED_AREA" | "TYPE_AIRPORT" | "TYPE_TARMAC" | "TYPE_HELIPORT" | "TYPE_SEAPLANE_BASE" | "TYPE_MILITARY_AIRBASE" | "TYPE_CEMETERY" | "TYPE_MILITARY" | "TYPE_ENCLOSED_TRAFFIC_AREA" | "TYPE_PARKING" | "TYPE_OFF_ROAD_AREA" | "TYPE_POST_OFFICE" | "TYPE_HOUSING_DEVELOPMENT" | "TYPE_BRIDGE" | "TYPE_ARCHAEOLOGICAL" | "TYPE_HISTORICAL" | "TYPE_RUINS" | "TYPE_TUNNEL" | "TYPE_RESIDENTIAL_DWELLING" | "TYPE_DETACHED_DWELLING" | "TYPE_ATTACHED_DWELLING" | "TYPE_APARTMENT" | "TYPE_GATED_COMMUNITY" | "TYPE_RETIREMENT_HOME" | "TYPE_TOLL_BOOTH" | "TYPE_CULTURAL" | "TYPE_CULTURAL_CENTER" | "TYPE_OVERPASS" | "TYPE_REST_ROOM" | "TYPE_PUBLIC_PHONE" | "TYPE_PHONE_BOOTH" | "TYPE_MANNED_PCO" | "TYPE_RESEARCH_INSTITUTE" | "TYPE_NON_GOVERNMENTAL_ORGANIZATION" | "TYPE_OFFICE_PARK" | "TYPE_MEDITATION_CENTER" | "TYPE_RELIGIOUS" | "TYPE_MONASTERY" | "TYPE_ASHRAM" | "TYPE_PAGODA" | "TYPE_MISSION" | "TYPE_PILGRIM_DESTINATION" | "TYPE_SOCIAL_SERVICE" | "TYPE_RANGER_STATION" | "TYPE_TRANSIT_STATION" | "TYPE_BUS_STATION" | "TYPE_TRAMWAY_STATION" | "TYPE_TRAIN_STATION" | "TYPE_SUBWAY_STATION" | "TYPE_FERRY_TERMINAL" | "TYPE_CABLE_CAR_STATION" | "TYPE_GONDOLA_LIFT_STATION" | "TYPE_FUNICULAR_STATION" | "TYPE_HORSE_CARRIAGE_STATION" | "TYPE_MONORAIL_STATION" | "TYPE_SEAPORT" | "TYPE_NATURAL_FEATURE" | "TYPE_ELEVATED" | "TYPE_PEAK";
}

function serializeGeostoreEstablishmentProto(data: any): GeostoreEstablishmentProto {
  return {
    ...data,
    bizbuilderReference: data["bizbuilderReference"] !== undefined ? serializeGeostoreBizBuilderReferenceProto(data["bizbuilderReference"]) : undefined,
    priceInfo: data["priceInfo"] !== undefined ? serializeGeostorePriceInfoProto(data["priceInfo"]) : undefined,
    serviceArea: data["serviceArea"] !== undefined ? serializeGeostoreServiceAreaProto(data["serviceArea"]) : undefined,
    telephone: data["telephone"] !== undefined ? data["telephone"].map((item: any) => (serializeGeostoreTelephoneProto(item))) : undefined,
  };
}

function deserializeGeostoreEstablishmentProto(data: any): GeostoreEstablishmentProto {
  return {
    ...data,
    bizbuilderReference: data["bizbuilderReference"] !== undefined ? deserializeGeostoreBizBuilderReferenceProto(data["bizbuilderReference"]) : undefined,
    priceInfo: data["priceInfo"] !== undefined ? deserializeGeostorePriceInfoProto(data["priceInfo"]) : undefined,
    serviceArea: data["serviceArea"] !== undefined ? deserializeGeostoreServiceAreaProto(data["serviceArea"]) : undefined,
    telephone: data["telephone"] !== undefined ? data["telephone"].map((item: any) => (deserializeGeostoreTelephoneProto(item))) : undefined,
  };
}

/**
 * An ExceptionalHoursProto holds information about exceptional (non-regular)
 * hours for a business, such as holiday hours.
 */
export interface GeostoreExceptionalHoursProto {
  /**
   * The weekly schedule to be applied for the dates that fall within the
   * range. The schedule may contain hours only for days of the week that occur
   * during the date range specified in the range field.
   */
  hours?: GeostoreBusinessHoursProto;
  /**
   * Field-level metadata for this exception.
   */
  metadata?: GeostoreFieldMetadataProto;
  /**
   * The dates for which this exception applies, expressed as a half open
   * interval. For example, an exception that applies for the entire month of
   * December 2015 should have a range December 1, 2015 to January 1, 2016. Any
   * regular hours that start on days in this range are ignored and replaced by
   * the exceptional hours for that day. The TimeIntervalProto for the range
   * must be a fully specified, non-empty, and non-inverted range of dates.
   * Concretely, the requirements are: * the range must be a TYPE_RANGE interval
   * * the interval may not be inverted * the endpoints of the interval must
   * specify a year, month, and day * the day_type of each endpoint must be type
   * DAY_OF_MONTH * the endpoints may not specify hour, minute, second, week, or
   * week_type * the begin endpoint must predate the end endpoint
   */
  range?: GeostoreTimeIntervalProto;
}

export interface GeostoreExistenceProto {
  /**
   * Indicates whether the place is closed (permanently or temporarily), i.e.,
   * not operational in the present, but was at in the past and/or will be in
   * the future. WARNING: New code should use Geo Schema's libraries instead,
   * specifically the OpeningStatus APIs, available in: * C++
   * (cs/f:google3/geostore/base/public/feature.h%20function:ExistenceState) *
   * Java
   * (cs/f:google3/java/com/google/geostore/base/Existence.java%20function:OpeningStatus)
   * * Python
   * (cs/f:google3/geostore/base/public/python/feature.clif%20existence_state)
   */
  closed?: boolean;
  /**
   * Structured reason for the permanent closure (if any).
   */
  closeReason?:  | "CLOSED" | "MOVED" | "REBRANDED";
  /**
   * RESERVED
   */
  endAsOfDate?: GeostoreDateTimeProto;
  endDate?: GeostoreDateTimeProto;
  /**
   * ** DEPRECATED ** This field is now deprecated (see b/22878252). Please use
   * the Geo Schema GetFeatureBirthTimestamp() API to extract the birth
   * timestamp of a feature. The timestamp in seconds since the UNIX epoch
   * (January 1, 1970) when this feature becomes live in the Geo repository.
   * Different from start_date in that this is the birth date of Google's
   * representation of the place whereas start_date is the birth date of the
   * place in the physical world.
   */
  featureBirthTimestampSeconds?: bigint;
  /**
   * Indicates whether the feature is marked as removed in the Geo repository.
   * Removed features are still present in the Geo repository but are considered
   * to be in an inactive state (not valid for lint purposes, not retrievable
   * except explicitly by feature ID, etc.). NOTE: If you have access to a
   * complete FeatureProto, do NOT read this bit directly to find out whether a
   * feature is removed. Instead, rely on the IsFeatureRemoved() API, available
   * in C++ (geostore/base/public/feature.h) and Java
   * (geostore/base/Feature.java).
   */
  removed?: boolean;
  /**
   * Structured reason why the feature is marked as removed. Relevant only when
   * removed == true.
   */
  removedReason?:  | "UNKNOWN" | "BOGUS" | "PRIVATE" | "PRIVATE_MUST_PURGE" | "SPAM" | "UNSUPPORTED" | "PENDING" | "DUPLICATE" | "OLD_SCHEMA" | "REPLACED" | "ROLLED_BACK";
  /**
   * (Initial) opening and (permanent) closing dates of the establishment, such
   * that start_date is the first day open and end_date is the first day closed.
   * The only allowed precisions are PRECISION_DAY, PRECISION_MONTH,
   * PRECISION_YEAR. DateTimeProto.seconds should have the lowest legal value
   * for the desired date/time and precision. E.g. for PRECISION_MONTH,
   * 2019-02-15 21:10:30 is not valid, it should be 2019-02-01 00:00:00 instead.
   * NOTE: The start_date and end_date are stored in UTC but should be
   * interpreted as being in the local timezone. So clients should convert the
   * DateTimeProto to local (civil) time using UTC+0, and then treat the result
   * as local to the feature.
   */
  startDate?: GeostoreDateTimeProto;
}

function serializeGeostoreExistenceProto(data: any): GeostoreExistenceProto {
  return {
    ...data,
    featureBirthTimestampSeconds: data["featureBirthTimestampSeconds"] !== undefined ? String(data["featureBirthTimestampSeconds"]) : undefined,
  };
}

function deserializeGeostoreExistenceProto(data: any): GeostoreExistenceProto {
  return {
    ...data,
    featureBirthTimestampSeconds: data["featureBirthTimestampSeconds"] !== undefined ? BigInt(data["featureBirthTimestampSeconds"]) : undefined,
  };
}

/**
 * Provenance information for sub-fields of this feature.
 */
export interface GeostoreFeatureFieldMetadataProto {
  fieldProvenance?: GeostoreFeatureFieldMetadataProtoFieldProvenance[];
}

export interface GeostoreFeatureFieldMetadataProtoFieldProvenance {
  /**
   * Represents all fields for which this SourceInfo is valid. NOTE: Field
   * paths are rooted at FeatureProto level.
   */
  fieldPath?: GeostoreStableFieldPathProto[];
  provenance?: GeostoreProvenanceProto;
}

/**
 * Metadata related to the history of a given feature in the Geo repository.
 */
export interface GeostoreFeatureHistoryMetadataProto {
  /**
   * The timestamp (in microseconds since the UNIX epoch) when this feature
   * first went live in the Geo repository. Note that this has no relation to
   * the birth data of that geographical entity in the real world.
   */
  featureBirthTimestampUs?: bigint;
  /**
   * The timestamp (in microseconds since the UNIX epoch) of the last
   * modification to the feature. Note this includes attachment modifications.
   * The feature's initial creation is also considered as a modification. This
   * is useful for those that consume features via both listening to
   * notifications and reading from repository snapshots. This timestamp can be
   * used to decide whether a feature in the snapshot was already seen in a more
   * recent state through the notifications.
   */
  lastModificationTimestampUs?: bigint;
  /**
   * The timestamp (in microseconds since the UNIX epoch) of the deletion time
   * of the feature. If the feature is currently removed, this field gets
   * populated with the timestamp the feature first became removed after being
   * live (or being removed from beginning). This field won't be set if the
   * feature is live.
   */
  removalTimestampUs?: bigint;
}

function serializeGeostoreFeatureHistoryMetadataProto(data: any): GeostoreFeatureHistoryMetadataProto {
  return {
    ...data,
    featureBirthTimestampUs: data["featureBirthTimestampUs"] !== undefined ? String(data["featureBirthTimestampUs"]) : undefined,
    lastModificationTimestampUs: data["lastModificationTimestampUs"] !== undefined ? String(data["lastModificationTimestampUs"]) : undefined,
    removalTimestampUs: data["removalTimestampUs"] !== undefined ? String(data["removalTimestampUs"]) : undefined,
  };
}

function deserializeGeostoreFeatureHistoryMetadataProto(data: any): GeostoreFeatureHistoryMetadataProto {
  return {
    ...data,
    featureBirthTimestampUs: data["featureBirthTimestampUs"] !== undefined ? BigInt(data["featureBirthTimestampUs"]) : undefined,
    lastModificationTimestampUs: data["lastModificationTimestampUs"] !== undefined ? BigInt(data["lastModificationTimestampUs"]) : undefined,
    removalTimestampUs: data["removalTimestampUs"] !== undefined ? BigInt(data["removalTimestampUs"]) : undefined,
  };
}

/**
 * Feature ID forwardings. There are many different types of ID forwardings,
 * some of which are attached to live features, others to removed features. This
 * information is available in multiple forms (with different completeness
 * guarantees): (1) in RPC responses to read requests to the live Geo
 * repository; (2) on disk, as part of the metadata section of features found in
 * the (inactive) features snapshots; (3) on disk, as part of a separate
 * feature_id_forwardings side table.
 */
export interface GeostoreFeatureIdForwardingsProto {
  /**
   * If the feature has been marked as a DUPLICATE of another feature, this is
   * the feature ID of that other feature. Note that the other feature may
   * itself be removed. This field is NOT set in (1).
   */
  duplicateOf?: GeostoreFeatureIdProto;
  /**
   * The feature ID of the forwarded feature. This field is only set in case
   * (3).
   */
  forwardedId?: GeostoreFeatureIdProto;
  /**
   * If other features have been marked as DUPLICATE of this feature, this is
   * the set of all such feature IDs. All feature IDs in this set should be for
   * removed (aka inactive) features. Note that in the context of historical
   * read requests against MapFacts (when
   * ReadRequest.version_selection.timestamp is set), this field won't be set.
   */
  inactiveDuplicate?: GeostoreFeatureIdProto[];
  /**
   * DEPRECATED - Use feature.metadata.feature_replacement_info instead. This
   * field was never populated.
   */
  replacedBy?: GeostoreFeatureIdListProto;
  /**
   * If the feature has been transitively marked as a DUPLICATE of another
   * feature (via a chain of size >= 1), this is the feature ID of that other
   * feature which is the end of the chain. The field is always set even if the
   * chain is of size 1. Note that the other feature may itself be removed. This
   * field is only set in case (3).
   */
  transitivelyDuplicateOf?: GeostoreFeatureIdProto;
}

function serializeGeostoreFeatureIdForwardingsProto(data: any): GeostoreFeatureIdForwardingsProto {
  return {
    ...data,
    duplicateOf: data["duplicateOf"] !== undefined ? serializeGeostoreFeatureIdProto(data["duplicateOf"]) : undefined,
    forwardedId: data["forwardedId"] !== undefined ? serializeGeostoreFeatureIdProto(data["forwardedId"]) : undefined,
    inactiveDuplicate: data["inactiveDuplicate"] !== undefined ? data["inactiveDuplicate"].map((item: any) => (serializeGeostoreFeatureIdProto(item))) : undefined,
    replacedBy: data["replacedBy"] !== undefined ? serializeGeostoreFeatureIdListProto(data["replacedBy"]) : undefined,
    transitivelyDuplicateOf: data["transitivelyDuplicateOf"] !== undefined ? serializeGeostoreFeatureIdProto(data["transitivelyDuplicateOf"]) : undefined,
  };
}

function deserializeGeostoreFeatureIdForwardingsProto(data: any): GeostoreFeatureIdForwardingsProto {
  return {
    ...data,
    duplicateOf: data["duplicateOf"] !== undefined ? deserializeGeostoreFeatureIdProto(data["duplicateOf"]) : undefined,
    forwardedId: data["forwardedId"] !== undefined ? deserializeGeostoreFeatureIdProto(data["forwardedId"]) : undefined,
    inactiveDuplicate: data["inactiveDuplicate"] !== undefined ? data["inactiveDuplicate"].map((item: any) => (deserializeGeostoreFeatureIdProto(item))) : undefined,
    replacedBy: data["replacedBy"] !== undefined ? deserializeGeostoreFeatureIdListProto(data["replacedBy"]) : undefined,
    transitivelyDuplicateOf: data["transitivelyDuplicateOf"] !== undefined ? deserializeGeostoreFeatureIdProto(data["transitivelyDuplicateOf"]) : undefined,
  };
}

/**
 * A simple list of feature IDs.
 */
export interface GeostoreFeatureIdListProto {
  /**
   * The list of feature IDs. While the exact semantics of these IDs are
   * usage-dependent, the list should never be empty or contain duplicates.
   */
  id?: GeostoreFeatureIdProto[];
}

function serializeGeostoreFeatureIdListProto(data: any): GeostoreFeatureIdListProto {
  return {
    ...data,
    id: data["id"] !== undefined ? data["id"].map((item: any) => (serializeGeostoreFeatureIdProto(item))) : undefined,
  };
}

function deserializeGeostoreFeatureIdListProto(data: any): GeostoreFeatureIdListProto {
  return {
    ...data,
    id: data["id"] !== undefined ? data["id"].map((item: any) => (deserializeGeostoreFeatureIdProto(item))) : undefined,
  };
}

/**
 * A globally unique identifier associated with each feature. We use 128-bit
 * identifiers so that we have lots of bits available to distinguish between
 * features. The feature id currently consists of a 64-bit "cell id" that
 * **sometimes** corresponds to the approximate centroid of the feature, plus a
 * 64-bit fingerprint of other identifying information. See more on each
 * respective field in its comments. Feature ids are first assigned when the
 * data is created in MapFacts. After initial creation of the feature, they are
 * immutable. This means that the only properties that you should rely on are
 * that they are unique, and that cell_ids often - but not always - preserve
 * spatial locality. The degree of locality varies as the feature undergoes
 * geometry changes, and should not in general be considered a firm guarantee of
 * the location of any particular feature. In fact, some locationless features
 * have randomized cell IDs! Consumers of FeatureProtos from Mapfacts are
 * guaranteed that fprints in the id field of features will be globally unique.
 * Using the fprint allows consumers who don't need the spatial benefit of cell
 * ids to uniquely identify features in a 64-bit address space. This property is
 * not guaranteed for other sources of FeatureProtos.
 */
export interface GeostoreFeatureIdProto {
  /**
   * The S2CellId corresponding to the approximate location of this feature as
   * of when it was first created. This can be of variable accuracy, ranging
   * from the exact centroid of the feature at creation, a very large S2 Cell,
   * or even being completely randomized for locationless features. Cell ids
   * have the nice property that they follow a space-filling curve over the
   * surface of the earth. (See s2cellid.h for details.) WARNING: Clients should
   * only use cell IDs to perform spatial locality optimizations. There is no
   * strict guarantee that the cell ID of a feature is related to the current
   * geometry of the feature in any way.
   */
  cellId?: bigint;
  /**
   * A 64-bit fingerprint used to identify features. Most clients should rely
   * on MapFacts or OneRing to choose fingerprints. If creating new fprints, the
   * strategy should be chosen so that the chance of collision is remote or
   * non-existent, and the distribution should be reasonably uniform. For
   * example, if the source data assigns unique ids to features, then a
   * fingerprint of the provider name, version, and source id is sufficient.
   */
  fprint?: bigint;
  /**
   * A place for clients to attach arbitrary data to a feature ID. Never set in
   * MapFacts.
   */
  temporaryData?: Proto2BridgeMessageSet;
}

function serializeGeostoreFeatureIdProto(data: any): GeostoreFeatureIdProto {
  return {
    ...data,
    cellId: data["cellId"] !== undefined ? String(data["cellId"]) : undefined,
    fprint: data["fprint"] !== undefined ? String(data["fprint"]) : undefined,
  };
}

function deserializeGeostoreFeatureIdProto(data: any): GeostoreFeatureIdProto {
  return {
    ...data,
    cellId: data["cellId"] !== undefined ? BigInt(data["cellId"]) : undefined,
    fprint: data["fprint"] !== undefined ? BigInt(data["fprint"]) : undefined,
  };
}

/**
 * General metadata related to a given feature in the Geo repository.
 */
export interface GeostoreFeatureMetadataProto {
  /**
   * This field indicates whether the feature is subject to bulk updates.
   * Caution must be exercised while editing such features since the changes
   * made by the edits will be overwritten by the bulk update (if the feature is
   * bulk updated). See go/mapfacts-abu for more information.
   */
  bulkUpdatable?:  | "NOT_BULK_UPDATABLE" | "BULK_UPDATABLE";
  /**
   * core_version_token is an opaque token representing the version of the core
   * fields of the feature. This field is not updated when attachments are
   * changed.
   */
  coreVersionToken?: Uint8Array;
  /**
   * Metadata for tracking when a feature is derived from or replaced by
   * another feature or set of features.
   */
  featureReplacementInfo?: GeostoreFeatureReplacementInfoProto;
  /**
   * Metadata about certain repeated fields and their subfields, for which
   * field type is not granular enough.
   */
  fieldMetadata?: GeostoreFeatureFieldMetadataProto;
  /**
   * Feature ID forwardings, if applicable.
   */
  forwardings?: GeostoreFeatureIdForwardingsProto;
  /**
   * Metadata related to the history.
   */
  history?: GeostoreFeatureHistoryMetadataProto;
  /**
   * version_token is an opaque token representing the version of this feature.
   * It can be used as a concurrency token when sending edits.
   */
  versionToken?: Uint8Array;
}

function serializeGeostoreFeatureMetadataProto(data: any): GeostoreFeatureMetadataProto {
  return {
    ...data,
    coreVersionToken: data["coreVersionToken"] !== undefined ? encodeBase64(data["coreVersionToken"]) : undefined,
    featureReplacementInfo: data["featureReplacementInfo"] !== undefined ? serializeGeostoreFeatureReplacementInfoProto(data["featureReplacementInfo"]) : undefined,
    forwardings: data["forwardings"] !== undefined ? serializeGeostoreFeatureIdForwardingsProto(data["forwardings"]) : undefined,
    history: data["history"] !== undefined ? serializeGeostoreFeatureHistoryMetadataProto(data["history"]) : undefined,
    versionToken: data["versionToken"] !== undefined ? encodeBase64(data["versionToken"]) : undefined,
  };
}

function deserializeGeostoreFeatureMetadataProto(data: any): GeostoreFeatureMetadataProto {
  return {
    ...data,
    coreVersionToken: data["coreVersionToken"] !== undefined ? decodeBase64(data["coreVersionToken"] as string) : undefined,
    featureReplacementInfo: data["featureReplacementInfo"] !== undefined ? deserializeGeostoreFeatureReplacementInfoProto(data["featureReplacementInfo"]) : undefined,
    forwardings: data["forwardings"] !== undefined ? deserializeGeostoreFeatureIdForwardingsProto(data["forwardings"]) : undefined,
    history: data["history"] !== undefined ? deserializeGeostoreFeatureHistoryMetadataProto(data["history"]) : undefined,
    versionToken: data["versionToken"] !== undefined ? decodeBase64(data["versionToken"] as string) : undefined,
  };
}

/**
 * Message to represent a "feature property" as an abstract construct. Most
 * feature properties are mapped one to one with the EditProto field types.
 * However in some cases the EditProto field type granularity is too coarse to
 * support use-cases that rely on feature properties (such as per-value rights
 * tracking). When that is the case, the feature property is augmented with a
 * secondary field.
 */
export interface GeostoreFeaturePropertyIdProto {
  /**
   * Required when field_type == ATTACHMENT.
   */
  attachmentTypeId?: bigint;
  /**
   * Required when field_type == FEATURE_ATTRIBUTE.
   */
  attributeId?: string;
  fieldType?:  | "NONE" | "ACCESS_POINT" | "ADDRESS" | "ANCHORED_GEOMETRY_GEOMETRY_ID" | "ATTACHMENT" | "BIZBUILDER_REFERENCE" | "BORDER_FEATURE_ID_LEFT" | "BORDER_FEATURE_ID_RIGHT" | "BORDER_OVERRIDE_STATUS" | "BORDER_STATUS" | "BORDER_TYPE" | "BORDER_LOGICAL_BORDER" | "BOUND" | "BUILDING_BASE_HEIGHT_METERS_AGL" | "BUILDING_DEFAULT_DISPLAY_LEVEL" | "BUILDING_FLOORS" | "BUILDING_HEIGHT_METERS" | "BUILDING_LEVEL" | "BUILDING_STRUCTURE" | "BUSINESS_CHAIN_CANONICAL_GCONCEPT" | "BUSINESS_HOURS" | "DATA_SOURCE" | "DISPLAY_DATA" | "ENTRANCE_ALLOWANCE" | "ESTABLISHMENT_OPENING_HOURS_EXCEPTION" | "ESTABLISHMENT_OPENING_HOURS_REGULAR_HOURS" | "ESTABLISHMENT_PRICE_INFO" | "ESTABLISHMENT_SERVICE_AREA_SERVED_FEATURE" | "EXISTENCE_STATUS" | "FEATURE_AVERAGE_ELEVATION" | "FEATURE_BEST_LOCALE" | "FEATURE_CELL_COVERING" | "FEATURE_CENTER" | "FEATURE_CHILD" | "FEATURE_EXEMPT_REGULATED_AREA" | "FEATURE_INTERIOR_CELL_COVERING" | "FEATURE_NAME" | "FEATURE_PARENT" | "FEATURE_POSE" | "FEATURE_PREFERRED_VIEWPORT" | "FEATURE_TRACK" | "FEATURE_TYPE" | "FEATURE_WEBSITE" | "FIELD_RIGHTS" | "FUTURE_GEOMETRY" | "FUTURE_GEOMETRY_FOR" | "GCONCEPT" | "GEOMETRY_PRECISION_METERS" | "GEOPOLITICAL_GEOMETRY_REST_OF_WORLD_POLYGON" | "GEOPOLITICAL_GEOMETRY_SELF_POLYGON" | "INFERRED_GEOMETRY_GEOMETRY_COMPOSITION" | "INFERRED_GEOMETRY_DEFINES_GEOMETRY_FOR" | "INTERSECTION" | "INTERSECTION_GROUP" | "INTERSECTION_GROUP_CHILD_GROUP" | "INTERSECTION_GROUP_GROUP_TYPE" | "INTERSECTION_GROUP_PARENT_GROUP" | "INTERSECTION_IN_GROUP" | "INTERSECTION_TOLL_CLUSTER" | "IN_SEGMENT" | "KNOWLEDGE_GRAPH_PROPERTY" | "LABEL_BACKGROUND_COLOR" | "LABEL_TEXT_COLOR" | "LANE_MARKER_BARRIER_MATERIALS" | "LANE_MARKER_CROSSING_PATTERN" | "LANE_MARKER_LINEAR_PATTERN" | "LEVEL_BUILDING" | "LEVEL_NUMBER" | "LOCALE_LANGUAGE" | "LOCALE_LOCALIZATION_POLICY_ID" | "LOGICAL_BORDER_BORDER_SEGMENT" | "LOGICAL_BORDER_STATUS" | "OPERATIONS_TEMPORARY_CLOSURE" | "PARKING_ALLOWANCE" | "PARKING_AVAILABLE" | "PARKING_OPENING_HOURS_EXCEPTION" | "PARKING_OPENING_HOURS_REGULAR_HOURS" | "PARKING_PROVIDER_FEATURE" | "PARKING_RESTRICTION" | "PEAK_PROMINENCE" | "PHONE_NUMBER" | "POINT" | "POLYGON" | "POLYGON_FOR_DISPLAY" | "POLYLINE" | "RANK" | "RANK_SIGNAL" | "REGULATED_AREA_RESTRICTION" | "RELATED_BORDER" | "RELATED_ENTRANCE" | "RELATED_FEATURE" | "RELATED_TERMINAL_POINT" | "RELATED_TIMEZONE" | "RESTRICTION_GROUP_SEGMENT" | "ROAD_MONITOR_MONITORED_ROAD" | "ROUTE_CHILD_TYPE" | "SCHOOL_DISTRICT_TYPE" | "SEGMENT_ADVISORY_MAXIMUM_SPEED" | "SEGMENT_AVERAGE_SPEED" | "SEGMENT_BARRIER" | "SEGMENT_BICYCLE_FACILITY" | "SEGMENT_BICYCLE_SAFETY" | "SEGMENT_CONDITION" | "SEGMENT_CONSTRUCTION_BEGIN_DATE" | "SEGMENT_CONSTRUCTION_END_DATE" | "SEGMENT_CONSTRUCTION_STATUS" | "SEGMENT_COVERED" | "SEGMENT_DISTANCE_TO_EDGE" | "SEGMENT_EDGE_FOLLOWS_SEGMENT_BEGIN_FRACTION" | "SEGMENT_EDGE_FOLLOWS_SEGMENT_END_FRACTION" | "SEGMENT_ELEVATION" | "SEGMENT_ENDPOINT" | "SEGMENT_GRADE_LEVEL_LIST" | "SEGMENT_INTERNAL_TRAVEL_ALLOWANCE" | "SEGMENT_INTERPOLATION_OFFSET_METERS" | "SEGMENT_IS_MAX_PERMITTED_SPEED_DERIVED" | "SEGMENT_LANE" | "SEGMENT_LEGAL_MAXIMUM_SPEED" | "SEGMENT_LEGAL_MINIMUM_SPEED" | "SEGMENT_MAX_SPEED" | "SEGMENT_ON_RIGHT" | "SEGMENT_PATH" | "SEGMENT_PEDESTRIAN_CROSSING" | "SEGMENT_PEDESTRIAN_FACILITY" | "SEGMENT_PEDESTRIAN_GRADE" | "SEGMENT_PRIORITY" | "SEGMENT_RESTRICTION" | "SEGMENT_ROAD_CAMERA" | "SEGMENT_ROAD_SIGN" | "SEGMENT_ROUTE" | "SEGMENT_ROUTE_ASSOCIATION" | "SEGMENT_SEPARATED_ROADWAYS" | "SEGMENT_SURFACE" | "SEGMENT_SWEEP" | "SEGMENT_TOLL_ROAD" | "SEGMENT_USAGE" | "SEGMENT_VISIBLE_LANDMARK" | "SIGN_COMPONENT" | "SOCIAL_REFERENCE_CLAIMED_GAIA_ID" | "SOURCE_INFO" | "STATUS_CLOSED" | "STATUS_CLOSE_REASON" | "STATUS_END_AS_OF_DATE" | "STATUS_END_DATE" | "STATUS_REMOVED" | "STATUS_REMOVED_REASON" | "STATUS_START_DATE" | "STOREFRONT_GEOMETRY" | "SYNTHETIC_GEOMETRY" | "THREE_DIMENSIONAL_MODEL" | "TOLL_CLUSTER_INTERSECTION" | "TRANSIT_LINE_AGENCY" | "TRANSIT_LINE_STATION" | "TRANSIT_LINE_VARIANT_LINE_CONCEPT" | "TRANSIT_LINE_VARIANT_STOP" | "TRANSIT_LINE_VEHICLE_TYPE" | "TRANSIT_STATION_AGENCY" | "VERTICAL_ORDERING_LEVEL" | "WATER_REMOVED_POLYGON" | "DEPRECATED_DO_NOT_USE_EMAIL_ADDRESS" | "DEPRECATED_DO_NOT_USE_RANK_GEOMETRY" | "DEPRECATED_DO_NOT_USE_SEGMENT_INFO" | "DEPRECATED_DO_NOT_USE_SEGMENT_LANE_LIST" | "DEPRECATED_DO_NOT_USE_SEGMENT_WRONG_WAY" | "DEPRECATED_DO_NOT_USE_WEBSITE" | "FEATURE_ATTRIBUTE" | "SOCIAL_REFERENCE" | "CATEGORY" | "DEPRECATED_DO_NOT_USE_CAPITAL" | "DEPRECATED_DO_NOT_USE_DESCRIPTION" | "DEPRECATED_DO_NOT_USE_DISTINCT" | "DEPRECATED_DO_NOT_USE_DUPLICATE" | "EDIT_PRECEDENCE" | "DEPRECATED_DO_NOT_USE_EDIT_PRECEDENCE" | "DEPRECATED_DO_NOT_USE_ENTRANCE_TARGET" | "DEPRECATED_DO_NOT_USE_ESTABLISHMENT_PLACE_ACTION_PAGE" | "DEPRECATED_DO_NOT_USE_ESTABLISHMENT_TYPE" | "DEPRECATED_DO_NOT_USE_EVENT" | "DEPRECATED_DO_NOT_USE_GEOMETRIC_ACCURACY" | "DEPRECATED_DO_NOT_USE_HIGHEST_GRADE" | "DEPRECATED_DO_NOT_USE_ID_TO_OVERRIDE" | "DEPRECATED_DO_NOT_USE_ISSUE_HISTORY" | "DEPRECATED_DO_NOT_USE_ISSUE_METADATA" | "DEPRECATED_DO_NOT_USE_KNOWLEDGE_GRAPH_ID" | "DEPRECATED_DO_NOT_USE_LOWEST_GRADE" | "DEPRECATED_DO_NOT_USE_PAYMENT_TYPES" | "DEPRECATED_DO_NOT_USE_PHOTO" | "DEPRECATED_DO_NOT_USE_PHOTO_URL" | "DEPRECATED_DO_NOT_USE_PLACE_CLOSED" | "DEPRECATED_DO_NOT_USE_POPULATION" | "DEPRECATED_DO_NOT_USE_RANK_USER" | "DEPRECATED_DO_NOT_USE_REMOVE_DUPLICATE" | "DEPRECATED_DO_NOT_USE_REMOVE_PLACE" | "DEPRECATED_DO_NOT_USE_SCHOOL_TYPE" | "DEPRECATED_DO_NOT_USE_SEGMENT_ELEVATION_BEGIN" | "DEPRECATED_DO_NOT_USE_SEGMENT_ELEVATION_END" | "DEPRECATED_DO_NOT_USE_SEGMENT_ELEVATION_MIDDLE" | "DEPRECATED_DO_NOT_USE_SYLLABUS" | "DEPRECATED_DO_NOT_USE_TRACK_CLASS" | "DEPRECATED_DO_NOT_USE_VIEWCODE_INFO" | "DEPRECATED_DO_NOT_USE_WORKAREA" | "DEPRECATED_DO_NOT_USE_INFERRED_GEOMETRY_INCLUDES_GEOMETRY_OF" | "DEPRECATED_DO_NOT_USE_INFERRED_GEOMETRY_EXCLUDES_GEOMETRY_OF";
  /**
   * Required when field_type == KNOWLEDGE_GRAPH_PROPERTY.
   */
  kgPropertyId?: string;
  /**
   * RESERVED
   */
  nameLanguage?: string;
}

function serializeGeostoreFeaturePropertyIdProto(data: any): GeostoreFeaturePropertyIdProto {
  return {
    ...data,
    attachmentTypeId: data["attachmentTypeId"] !== undefined ? String(data["attachmentTypeId"]) : undefined,
  };
}

function deserializeGeostoreFeaturePropertyIdProto(data: any): GeostoreFeaturePropertyIdProto {
  return {
    ...data,
    attachmentTypeId: data["attachmentTypeId"] !== undefined ? BigInt(data["attachmentTypeId"]) : undefined,
  };
}

/**
 * Every entry in the GeoStore database is called a "feature". A feature is
 * represented as a discriminated union of all the different feature types,
 * where the actual feature type is specified by the "type" field. There are
 * also various fields that are meaningful for most or all feature types, such
 * as bounding regions and names. Every feature has a globally unique id that
 * can be used to refer to it from other features.
 */
export interface GeostoreFeatureProto {
  /**
   * Optional access point information. Access points hold detailed information
   * about routing endpoints. For example, the main Google office is at "1600
   * Amphitheatre Parkway". The feature representing that office has a polygon,
   * a center, and an address with components for the street number, route,
   * locality, etc. The access point information, on the other hand, identifies
   * the specific segment, the latitude/longitude of the driveway, and so forth.
   */
  accessPoint?: GeostoreAccessPointProto[];
  /**
   * Address for this feature. A Geo Schema address is designed to model a
   * mailing address, so only features that have mailing addresses in the real
   * world may have addresses. Each feature should have only one address. If you
   * want to describe the geographic location of a feature which does not have a
   * mailing address with respect to other well-known features, some other
   * schema constructs should be used. Note that the field is defined as
   * repeated though features that use this field with its intended semantics
   * are constrained to have a single address even if they may have multiple
   * mailing addresses in the real world. The single address rule is enforced
   * by lint. Current exceptions to the single address rule and mailing address
   * rule are described in the g3doc. Bear note that the schema team is actively
   * working on eliminating these exceptions. http://go/geo-addresses Note the
   * following conventions: - Addresses follow the postal hierarchy, not the
   * political hierarchy. Addresses may have components that refer to political
   * entities when those entities also appear in the postal hierarchy. - As
   * stated previously, but it bears repeating, addresses on features are
   * mailing addresses. In many cases the physical address and the mailing
   * address are the same but the address stored on a feature represents the
   * mailing address of the feature. An example of a non-physical mailing
   * address would be a PO Box. - These addresses are commonly defined and
   * verifiable by a governmental authority (e.g. the United States Postal
   * Service in the United States, Royal Mail in the United Kingdom, Correios in
   * Brazil, etc.) and should follow conventions and rules defined by those
   * authorities.
   */
  address?: GeostoreAddressProto[];
  /**
   * Represents information about the features anchored geometry.
   */
  anchoredGeometry?: GeostoreAnchoredGeometryProto;
  /**
   * The collection of attachments for this feature. Documentation:
   * http://go/geo-attachments
   */
  attachment?: GeostoreAttachmentsAttachmentProto[];
  /**
   * ** DEPRECATED ** A list of attributes that describe defined aspects of
   * this feature. An attribute must be a concrete, high quality, and editable
   * piece of information about a feature, and must be used on some general
   * consumer facing Google property. The data types used for attributes must be
   * primitive types or reusable in a generic manner.
   */
  attribute?: GeostoreAttributeProto[];
  /**
   * Describes the best-match locale for this feature.
   */
  bestLocale?: GeostoreBestLocaleProto;
  border?: GeostoreBorderProto;
  /**
   * A latitude-longitude rectangle used by bucketing MapReduces. See the
   * documentation on bucketing MapReduce for details. This field can be a
   * source of confusion. Because it is called "bound", it is often assumed that
   * it is a tight bound on the geometry but it can be (and often is) much
   * larger. If a tight bound is needed then use the standard
   * GetFeatureGeometryBound() function instead. To be more explicit, if you are
   * using this field for *anything* else than a bucketing MapReduce, you are
   * doing the wrong thing. Not all features are required to have bounding
   * boxes. See geostore::IsBoundRequiredForFeatureType() for the list of
   * feature types required to have a bounding box. This bound field will be
   * updated when a feature changes in MapFacts to include its geometry. Also, a
   * GeoSchema pipeline, go/geo-schema-pipelines-docs#expand-bounds runs
   * periodically to update the field for strong references from other features.
   * Therefore, most editors don't need to edit this field explicitly. See
   * go/geo-changes:no-edit-for-feature-bound for the details.
   */
  bound?: GeostoreRectProto;
  building?: GeostoreBuildingProto;
  /**
   * Data specific to business chain features, e.g., Canonical GConcepts.
   */
  businessChain?: GeostoreBusinessChainProto;
  /**
   * The conceptual center of the feature, used for routing. For cities, this
   * would be the center of the downtown, or maybe the location of city hall.
   * For states and countries it might be the capital city. Most feature types
   * will not have a conceptual center - by default, routing will use the
   * centroid of the feature's geometry. If you need a feature center point
   * consider using GetFeatureGeometryCenter() function from
   * geostore/base/public/feature.h rather than reading from this field
   * directly.
   */
  center?: GeostorePointProto;
  /**
   * Features can define themselves as a collection of other features. For
   * example, a route is a collection of road segments, and a feature for the
   * "Great Lakes" could be defined as lakes Superior, Michigan, Huron, Erie,
   * and Ontario. It is not recommended to design a multi level tree using the
   * child field to build up a feature because it requires fetching many
   * features to see the details of the feature. In practice this is used to
   * model archipelago, route, transit (agencies, lines, trips, departures), and
   * river features. The geometry of a feature is implicitly defined by its
   * children, so if a feature has children then it should not have any points,
   * polylines, or polygons. In general, this field should not be used to
   * represent political or postal hierarchies. For example, a county would not
   * list its cities as children, because the county is not defined in terms of
   * its cities (it also contains unincorporated areas, etc.).
   */
  child?: GeostoreFeatureIdProto[];
  /**
   * S2 cell coverings for this feature. See util/geometry/s2cell_union.h for
   * more information about S2 cells. Coverings are useful for quick containment
   * or intersection tests. S2 covering that consists of cells that intersect
   * with the feature.
   */
  covering?: GeostoreCellCoveringProto;
  dataSource?: GeostoreDataSourceProto;
  /**
   * Data used to render this feature on a map.
   */
  displayData?: GeostoreDisplayDataProto;
  /**
   * ** DEPRECATED **
   */
  doodle?: GeostoreDoodleProto;
  elevation?: GeostoreElevationProto;
  /**
   * Captures elevation data used on TYPE_DIGITAL_ELEVATION_MODEL features.
   */
  elevationModel?: GeostoreElevationModelProto;
  entrance?: GeostoreEntranceProto;
  /**
   * Also allowed on TYPE_BUSINESS_CHAIN and TYPE_TRANSIT_AGENCY features, to
   * model the feature's phone number(s). Other fields within EstablishmentProto
   * are not permitted on non-TYPE_ESTABLISHMENT features.
   */
  establishment?: GeostoreEstablishmentProto;
  /**
   * A list of feature ids of polygon based restrictions that do not apply to
   * this feature. This may only include features of TYPE_REGULATED_AREA that
   * also have a feature.regulated_area.restriction field defined. Setting this
   * field opts the feature out of all restrictions set on that regulated area.
   */
  exemptRegulatedArea?: GeostoreFeatureIdProto[];
  /**
   * Specifies the TYPE_FUTURE_GEOMETRY whose geometry will replace this
   * feature's geometry. If this field is populated, the referenced future
   * geometry must have a future_geometry_for referencing this feature.
   */
  futureGeometry?: GeostoreFeatureIdProto;
  /**
   * Specifies the feature that this feature's geometry will replace. If this
   * field is populated, the referenced feature must have a future_geometry
   * reference back to this feature. This field is only allowed (and required)
   * for TYPE_FUTURE_GEOMETRY features.
   */
  futureGeometryFor?: GeostoreFeatureIdProto;
  /**
   * If set, the feature's actual location can be assumed to be somewhere
   * within a circle of this radius, centered on the feature's location. More
   * information on this field at go/gpm-definition-update. NOTE: Only
   * applicable to features with 'point' geometry. Please contact
   * geo-schema-team@ if you have non-point use cases for which this field would
   * be useful.
   */
  geometryPrecisionMeters?: number;
  /**
   * Geopolitical (unsimplified) polygons for a feature for different
   * geopolitical use cases.
   */
  geopoliticalGeometry?: GeostoreGeopoliticalGeometryProto;
  /**
   * ** DEPRECATED ** Features can have zero or more HTML texts associated with
   * them. These might be HTML balloons used by Google Earth, for example.
   */
  htmlText?: GeostoreHtmlTextProto[];
  /**
   * The globally unique id for this feature.
   */
  id?: GeostoreFeatureIdProto;
  inferredGeometry?: GeostoreInferredGeometryProto;
  /**
   * S2 interior covering that consists of cells completely enclosed within the
   * feature's geometry (for features with polygonal geometry).
   */
  interiorCovering?: GeostoreCellCoveringProto;
  /**
   * Additional internal feature-level attributes that may be set by data
   * providers to be used inside the Geo Data infrastructure. This field should
   * never be present in the output of the Geo Data infrastructure that
   * read-only clients consume.
   */
  internal?: GeostoreInternalFeatureProto;
  intersection?: GeostoreIntersectionProto;
  intersectionGroup?: GeostoreIntersectionGroupProto;
  /**
   * Properties that apply to this feature whose schema is defined in the
   * Knowledge Graph schema (see https://hume.google.com/graph/schema). Not all
   * properties that exist in the KG schema can be asserted via this mechanism.
   * The set of properties that are allowed to be set on a feature depends on
   * the feature's GConcepts (and feature type). For instance, only gcid:country
   * features may have the /geo/type/country/president property (made up
   * example, since that property doesn't actually exist in the KG schema).
   * GConcept hierarchy is taken into account for deciding the set of allowed
   * properties. Additionally, the specific properties allowed are further
   * constrained by the list specified at go/kg-property-allowlist. NOTE: not
   * all types of properties are allowed to appear in the Geo Schema. For now,
   * we limit ourselves to properties whose value type is TYPE_BOOL,
   * TYPE_COMPOUND, TYPE_DATETIME, TYPE_FLOAT, TYPE_ID, TYPE_INT,
   * TYPE_NESTED_STRUCT, TYPE_TEXT, or TYPE_URI. NOTE(b/35039936): We are in the
   * process of changing how a KG property with multiple values is stored in
   * this field. Currently, such a KG property is stored in a single instance of
   * the kg_property field. However, we will be changing this so that each value
   * will be stored in its own instance of kg_property. Any client that wants to
   * read from this field should be prepared to read data represented in either
   * format. See b/35039936 or the announcement at
   * http://g/geo-schema-announce/7IXR3Fex8to/7yFyT5UoAwAJ for an example and
   * more details. The mechanism to assert that a KG property has no value is
   * via the property_value_status field below.
   * freebase.PropertyValue.value_status is not allowed be set here for
   * consistency reason.
   */
  kgProperty?: FreebasePropertyValue[];
  /**
   * RESERVED
   */
  knowledgeGraphReference?: GeostoreKnowledgeGraphReferenceProto;
  laneMarker?: GeostoreLaneMarkerProto;
  /**
   * Represents information about TYPE_LEVEL features.
   */
  level?: GeostoreLevelProto;
  locale?: GeostoreLocaleProto;
  logicalBorder?: GeostoreLogicalBorderProto;
  /**
   * Metadata about this particular feature. Metadata is managed internally by
   * the Geo Data Infrastructure and in general should not be set by clients.
   * Features that don't ultimately come from the Geo repository (MapFacts)
   * won't have any metadata set.
   */
  metadata?: GeostoreFeatureMetadataProto;
  /**
   * The name(s) of this feature. A feature may have different names in
   * different languages, colloquial or "vanity" names, etc.
   */
  name?: GeostoreNameProto[];
  /**
   * Information about this feature's operations, e.g. when this feature is
   * temporarily closed. NOTE: for legacy reasons, some closure-specifc
   * information (e.g. permanent closure reason) lives in ExistenceProto
   * instead. In the future, such information should move here in
   * OperationsProto.
   */
  operations?: GeostoreOperationsProto;
  /**
   * This field is used internally by the pipeline for id stability. It should
   * not be set by individual importers, nor should it be read by consumer
   * clients. In particular, this field will not be present in features read or
   * snapshotted from the Mapfacts Repository.
   */
  originalId?: GeostoreFeatureIdProto;
  parent?: GeostoreFeatureIdProto[];
  /**
   * Describes parking details for the feature.
   */
  parking?: GeostoreParkingProto;
  /**
   * Defines the geometry of the feature. The geometry may be specified as an
   * arbitrary union of points, poses, polylines, tracks, and polygons. Points,
   * poses, polylines, and tracks are assumed to represent regions of
   * unspecified size or width rather than regions of zero area. Most features
   * should have some sort of geometry. Geometry may be synthesized if none is
   * available (e.g., polygons for postal codes). The synthetic_geometry flag
   * should be set in that case. Point is currently enforced as a non-repeating
   * field for all feature types, though it is defined as repeating in case
   * future modeling requires multiple points. The number of allowed polylines,
   * tracks, or polygons vary based on feature type. A feature can have at most
   * one pose (it is an optional field).
   */
  point?: GeostorePointProto[];
  /**
   * ** DEPRECATED ** Detail discussion could be found at b/18611003.
   */
  political?: GeostorePoliticalProto;
  polygon?: GeostorePolygonProto[];
  /**
   * Provide version of the geometry suitable for display. This has been
   * subject to water removal and (possibly) moderate simplification.
   */
  polygonForDisplay?: GeostorePolygonProto;
  polyline?: GeostorePolyLineProto[];
  /**
   * Defines the geometry of a feature as a 6D pose, including lat, lng,
   * altitude, roll, pitch, and yaw along the WGS-84 ellipsoid. Only the lat and
   * lng are strictly required.
   */
  pose?: GeostorePoseProto;
  /**
   * The preferred viewport for this feature. If present, this
   * latitude-longitude rectangle holds the preferred viewport for the feature.
   * For example, it might hold the bounds of the "central" portion of a large
   * city. There are no aspect ratio requirements. This is an optional field: if
   * no viewport is supplied, interested clients can use heuristics to determine
   * a viewport. Calling the standard GetFeatureGeometryBound() function would
   * be a good way to start but note that it can return an empty bounding box
   * (e.g., if the feature has no geometry). The preferred viewport is not
   * necessarily fully contained by the above bounding box.
   */
  preferredViewport?: GeostoreRectProto;
  /**
   * The value status of properties on this feature. For example, this
   * specifies whether the feature is known to have no name (this is the value
   * status of the 'FEATURE_NAME' property). Only property IDs which have no
   * specific value are allowed to have a value status. Note: not all field
   * types will be supported, please contact geo schema team if you want to
   * enable this field for a field type that is not currently supported.
   */
  propertyValueStatus?: GeostorePropertyValueStatusProto[];
  /**
   * WARNING: Please do NOT introduce new uses of this field; treat it as if it
   * were deprecated. For appropriate ranking contacts, see
   * g3doc/company/teams/gdeng/geo-schema-reference/home/feature-properties/rank.md.
   * A floating-point number between 0.0 and 1.0 indicating how "important" we
   * think this feature is. This can be used to decide which features to render
   * on maps, and how to rank results when the user does a search. The rank can
   * depend on any number of factors such as the number of references to this
   * feature in web pages, geographic size, population, number of referring
   * geographic entities, "priority" information encoded in the source data,
   * etc.
   */
  rank?: number;
  /**
   * The rank field is computed as a weighted sum of several signals. This
   * field contains a protocol buffer whose fields give those signals and their
   * weights. Clients should try very hard not to depend on these individual
   * signals and use the single rank field instead. At some point in the future,
   * this field will not be exposed anymore.
   */
  rankDetails?: GeostoreRankDetailsProto;
  /**
   * Geo Ontology GConcept Instances - Design doc linked off
   * http://go/geo-ontology - In order to shield clients from changes in
   * GConcept representation we provide an accessor library:
   * geostore/base/public/gconcept_instance.h
   */
  rawGconceptInstanceContainer?: GeostoreOntologyRawGConceptInstanceContainerProto;
  regulatedArea?: GeostoreRegulatedAreaProto;
  /**
   * For TYPE_COUNTRY or TYPE_ADMINISTRATIVE_AREA1 features, this field defines
   * the associated TYPE_BORDERs which reference this feature. The linked
   * TYPE_BORDERs must have the feature.border set, pointing to this feature.
   * TYPE_COUNTRY or TYPE_ADMINISTRATIVE_AREA1 features must have this field set
   * for each TYPE_BORDER referencing them.
   */
  relatedBorder?: GeostoreFeatureIdProto[];
  /**
   * Logical relationship to other features that are entrances or exits to this
   * feature.
   */
  relatedEntrance?: GeostoreEntranceReferenceProto[];
  /**
   * Geographic or logical relationships to other features. Importers don't
   * need to fill a geographic relationship in - it is handled by related
   * feature processing by a standalone pipeline. Adding "contained by" country
   * relations is however encouraged (and required for TYPE_ROUTE features).
   * WARNING: Updates to this field handled by standalone pipelines are NOT
   * atomic with regard to updates to the features being referenced; we do not
   * guarantee that a given MapFacts snapshot will be consistent between this
   * field and the related features.
   */
  relatedFeature?: GeostoreRelationProto[];
  /**
   * Terminal points associated with this feature. For instance, an airport
   * terminal may have specifically designated pickup and drop-off points.
   */
  relatedTerminalPoint?: GeostoreFeatureIdProto[];
  /**
   * Contains time zones known to be associated with a feature. Most features
   * are associated with the single time zone that contains them. However, some
   * larger features (countries, continents, etc.) are associated with all of
   * the time zones they contain. Most features can have any number of related
   * time zones, but TYPE_SEGMENT and TYPE_ESTABLISHMENT_POI features can have
   * at most 1.
   */
  relatedTimezone?: GeostoreTimezoneProto[];
  restrictionGroup?: GeostoreRestrictionGroupProto;
  roadMonitor?: GeostoreRoadMonitorProto;
  /**
   * Additional details on the feature types below can be found in the
   * individual protocol buffer definitions. These extensions capture data that
   * is specific to a set of feature types and which makes no sense for other
   * feature types.
   */
  route?: GeostoreRouteProto;
  schoolDistrict?: GeostoreSchoolDistrictProto;
  segment?: GeostoreSegmentProto;
  segmentPath?: GeostoreSegmentPathProto;
  sign?: GeostoreRoadSignProto;
  skiBoundary?: GeostoreSkiBoundaryProto;
  skiLift?: GeostoreSkiLiftProto;
  skiTrail?: GeostoreSkiTrailProto;
  /**
   * All establishments must have a social reference. WARNING: Aside from
   * creating new establishments, please do NOT introduce new uses; treat social
   * references as if they were deprecated. For alternatives and more, see
   * g3doc/company/teams/gdeng/geo-schema-reference/home/feature-types/establishments/social-reference.md.
   */
  socialReference?: GeostoreSocialReferenceProto;
  /**
   * A list of the data sources that were used to construct this feature,
   * together with optional "raw data" in the provider's format. Raw data should
   * not be used by production clients but may be useful for exploring data that
   * is not currently converted to a canonical form.
   */
  sourceInfo?: GeostoreSourceInfoProto[];
  /**
   * All features can have "existence" information associated with them.
   */
  status?: GeostoreExistenceProto;
  /**
   * Represents information about the store front geoemtry. Only
   * TYPE_ESTABLISHMENT_POI should have this field set.
   */
  storefrontGeometry?: GeostoreAnchoredGeometryProto[];
  /**
   * We prefer features that have geometry over those that do not. In some
   * cases we synthesize geometry (e.g., polygons for postal codes). This flag
   * is set to indicate features that have such synthetic geometry.
   */
  syntheticGeometry?: boolean;
  /**
   * A place for clients to attach arbitrary data to a feature. Never set in
   * MapFacts.
   */
  temporaryData?: Proto2BridgeMessageSet;
  /**
   * Captures full model representing the feature's 3D geometry. Should only be
   * found on TYPE_COMPOUND_BUILDING features for now, but not part of the
   * BuildingProto extension for possible future extensions.
   */
  threeDimModel?: GeostoreThreeDimensionalModelProto;
  /**
   * Represents information about TYPE_TOLL_CLUSTER features.
   */
  tollCluster?: GeostoreTollClusterProto;
  /**
   * Defines the geometry of a feature as a sequence of 6D poses, including
   * lat, lng, altitude, roll, pitch, and yaw. Only lat and lng are typically
   * required. Each track has an index so that they can be viewed in a stable
   * order.
   */
  track?: GeostoreTrackProto[];
  transitLine?: GeostoreTransitLineProto;
  /**
   * RESERVED
   */
  transitLineVariant?: GeostoreTransitLineVariantProto;
  /**
   * RESERVED
   */
  transitStation?: GeostoreTransitStationProto;
  /**
   * The type of this feature -- see comments above.
   */
  type?:  | "TYPE_ANY" | "TYPE_TRANSPORTATION" | "TYPE_ROUTE" | "TYPE_DEPRECATED_HIGHWAY_DO_NOT_USE" | "TYPE_HIGHWAY" | "TYPE_HIGHWAY_1" | "TYPE_HIGHWAY_2" | "TYPE_HIGHWAY_3" | "TYPE_HIGHWAY_4" | "TYPE_HIGHWAY_5" | "TYPE_HIGHWAY_6" | "TYPE_HIGHWAY_7" | "TYPE_HIGHWAY_8" | "TYPE_HIGHWAY_9" | "TYPE_BICYCLE_ROUTE" | "TYPE_TRAIL" | "TYPE_SEGMENT" | "TYPE_ROAD" | "TYPE_RAILWAY" | "TYPE_STANDARD_TRACK" | "TYPE_JR_TRACK" | "TYPE_NARROW_TRACK" | "TYPE_MONORAIL_TRACK" | "TYPE_SUBWAY_TRACK" | "TYPE_LIGHT_RAIL_TRACK" | "TYPE_BROAD_TRACK" | "TYPE_HIGH_SPEED_RAIL" | "TYPE_TROLLEY_TRACK" | "TYPE_FERRY" | "TYPE_FERRY_BOAT" | "TYPE_FERRY_TRAIN" | "TYPE_VIRTUAL_SEGMENT" | "TYPE_INTERSECTION" | "TYPE_TRANSIT" | "TYPE_TRANSIT_STATION" | "TYPE_BUS_STATION" | "TYPE_TRAMWAY_STATION" | "TYPE_TRAIN_STATION" | "TYPE_SUBWAY_STATION" | "TYPE_FERRY_TERMINAL" | "TYPE_AIRPORT" | "TYPE_AIRPORT_CIVIL" | "TYPE_AIRPORT_MILITARY" | "TYPE_AIRPORT_MIXED" | "TYPE_HELIPORT" | "TYPE_SEAPLANE_BASE" | "TYPE_AIRSTRIP" | "TYPE_CABLE_CAR_STATION" | "TYPE_GONDOLA_LIFT_STATION" | "TYPE_FUNICULAR_STATION" | "TYPE_SPECIAL_STATION" | "TYPE_HORSE_CARRIAGE_STATION" | "TYPE_MONORAIL_STATION" | "TYPE_SEAPORT" | "TYPE_TRANSIT_STOP" | "TYPE_TRANSIT_TRIP" | "TYPE_TRANSIT_DEPARTURE" | "TYPE_TRANSIT_LEG" | "TYPE_TRANSIT_LINE" | "TYPE_TRANSIT_AGENCY_DEPRECATED_VALUE" | "TYPE_TRANSIT_TRANSFER" | "TYPE_SEGMENT_PATH" | "TYPE_ROAD_SIGN" | "TYPE_INTERSECTION_GROUP" | "TYPE_PATHWAY" | "TYPE_RESTRICTION_GROUP" | "TYPE_TOLL_CLUSTER" | "TYPE_POLITICAL" | "TYPE_COUNTRY" | "TYPE_ADMINISTRATIVE_AREA" | "TYPE_ADMINISTRATIVE_AREA1" | "TYPE_US_STATE" | "TYPE_GB_COUNTRY" | "TYPE_JP_TODOUFUKEN" | "TYPE_ADMINISTRATIVE_AREA2" | "TYPE_GB_FORMER_POSTAL_COUNTY" | "TYPE_GB_TRADITIONAL_COUNTY" | "TYPE_ADMINISTRATIVE_AREA3" | "TYPE_ADMINISTRATIVE_AREA4" | "TYPE_ADMINISTRATIVE_AREA5" | "TYPE_ADMINISTRATIVE_AREA6" | "TYPE_ADMINISTRATIVE_AREA7" | "TYPE_ADMINISTRATIVE_AREA8" | "TYPE_ADMINISTRATIVE_AREA9" | "TYPE_COLLOQUIAL_AREA" | "TYPE_RESERVATION" | "TYPE_LOCALITY" | "TYPE_GB_POST_TOWN" | "TYPE_JP_GUN" | "TYPE_JP_SHIKUCHOUSON" | "TYPE_JP_SUB_SHIKUCHOUSON" | "TYPE_COLLOQUIAL_CITY" | "TYPE_SUBLOCALITY" | "TYPE_US_BOROUGH" | "TYPE_GB_DEPENDENT_LOCALITY" | "TYPE_JP_OOAZA" | "TYPE_JP_KOAZA" | "TYPE_JP_GAIKU" | "TYPE_GB_DOUBLE_DEPENDENT_LOCALITY" | "TYPE_JP_CHIBAN" | "TYPE_JP_EDABAN" | "TYPE_SUBLOCALITY1" | "TYPE_SUBLOCALITY2" | "TYPE_SUBLOCALITY3" | "TYPE_SUBLOCALITY4" | "TYPE_SUBLOCALITY5" | "TYPE_NEIGHBORHOOD" | "TYPE_CONSTITUENCY" | "TYPE_DESIGNATED_MARKET_AREA" | "TYPE_SCHOOL_DISTRICT" | "TYPE_LAND_PARCEL" | "TYPE_DISPUTED_AREA" | "TYPE_POLICE_JURISDICTION" | "TYPE_STATISTICAL_AREA" | "TYPE_CONSTITUENCY_FUTURE" | "TYPE_PARK" | "TYPE_GOLF_COURSE" | "TYPE_LOCAL_PARK" | "TYPE_NATIONAL_PARK" | "TYPE_US_NATIONAL_PARK" | "TYPE_US_NATIONAL_MONUMENT" | "TYPE_NATIONAL_FOREST" | "TYPE_PROVINCIAL_PARK" | "TYPE_PROVINCIAL_FOREST" | "TYPE_CAMPGROUNDS" | "TYPE_HIKING_AREA" | "TYPE_BUSINESS" | "TYPE_GOVERNMENT" | "TYPE_BORDER_CROSSING" | "TYPE_CITY_HALL" | "TYPE_COURTHOUSE" | "TYPE_EMBASSY" | "TYPE_LIBRARY" | "TYPE_SCHOOL" | "TYPE_UNIVERSITY" | "TYPE_EMERGENCY" | "TYPE_HOSPITAL" | "TYPE_PHARMACY" | "TYPE_POLICE" | "TYPE_FIRE" | "TYPE_DOCTOR" | "TYPE_DENTIST" | "TYPE_VETERINARIAN" | "TYPE_TRAVEL_SERVICE" | "TYPE_LODGING" | "TYPE_RESTAURANT" | "TYPE_GAS_STATION" | "TYPE_PARKING" | "TYPE_POST_OFFICE" | "TYPE_REST_AREA" | "TYPE_CASH_MACHINE" | "TYPE_CAR_RENTAL" | "TYPE_CAR_REPAIR" | "TYPE_SHOPPING" | "TYPE_GROCERY" | "TYPE_TOURIST_DESTINATION" | "TYPE_ECO_TOURIST_DESTINATION" | "TYPE_BIRD_WATCHING" | "TYPE_FISHING" | "TYPE_HUNTING" | "TYPE_NATURE_RESERVE" | "TYPE_TEMPLE" | "TYPE_CHURCH" | "TYPE_GURUDWARA" | "TYPE_HINDU_TEMPLE" | "TYPE_MOSQUE" | "TYPE_SYNAGOGUE" | "TYPE_STADIUM" | "TYPE_BAR" | "TYPE_MOVIE_RENTAL" | "TYPE_COFFEE" | "TYPE_GOLF" | "TYPE_BANK" | "TYPE_DOODLE" | "TYPE_GROUNDS" | "TYPE_AIRPORT_GROUNDS" | "TYPE_BUILDING_GROUNDS" | "TYPE_CEMETERY" | "TYPE_HOSPITAL_GROUNDS" | "TYPE_INDUSTRIAL" | "TYPE_MILITARY" | "TYPE_SHOPPING_CENTER" | "TYPE_SPORTS_COMPLEX" | "TYPE_UNIVERSITY_GROUNDS" | "TYPE_DEPRECATED_TARMAC" | "TYPE_ENCLOSED_TRAFFIC_AREA" | "TYPE_PARKING_LOT" | "TYPE_PARKING_GARAGE" | "TYPE_OFF_ROAD_AREA" | "TYPE_BORDER" | "TYPE_BUILDING" | "TYPE_GEOCODED_ADDRESS" | "TYPE_NATURAL_FEATURE" | "TYPE_TERRAIN" | "TYPE_SAND" | "TYPE_BEACH" | "TYPE_DUNE" | "TYPE_ROCKY" | "TYPE_ICE" | "TYPE_GLACIER" | "TYPE_BUILT_UP_AREA" | "TYPE_VEGETATION" | "TYPE_SHRUBBERY" | "TYPE_WOODS" | "TYPE_AGRICULTURAL" | "TYPE_GRASSLAND" | "TYPE_TUNDRA" | "TYPE_DESERT" | "TYPE_SALT_FLAT" | "TYPE_WATER" | "TYPE_OCEAN" | "TYPE_BAY" | "TYPE_BIGHT" | "TYPE_LAGOON" | "TYPE_SEA" | "TYPE_STRAIT" | "TYPE_INLET" | "TYPE_FJORD" | "TYPE_LAKE" | "TYPE_SEASONAL_LAKE" | "TYPE_RESERVOIR" | "TYPE_POND" | "TYPE_RIVER" | "TYPE_RAPIDS" | "TYPE_DISTRIBUTARY" | "TYPE_CONFLUENCE" | "TYPE_WATERFALL" | "TYPE_SPRING" | "TYPE_GEYSER" | "TYPE_HOT_SPRING" | "TYPE_SEASONAL_RIVER" | "TYPE_WADI" | "TYPE_ESTUARY" | "TYPE_WETLAND" | "TYPE_WATER_NAVIGATION" | "TYPE_FORD" | "TYPE_CANAL" | "TYPE_HARBOR" | "TYPE_CHANNEL" | "TYPE_REEF" | "TYPE_REEF_FLAT" | "TYPE_REEF_GROWTH" | "TYPE_REEF_EXTENT" | "TYPE_REEF_ROCK_SUBMERGED" | "TYPE_IRRIGATION" | "TYPE_DAM" | "TYPE_DRINKING_WATER" | "TYPE_CURRENT" | "TYPE_WATERING_HOLE" | "TYPE_TECTONIC" | "TYPE_WATERING_HOLE_DEPRECATED" | "TYPE_VOLCANO" | "TYPE_LAVA_FIELD" | "TYPE_FISSURE" | "TYPE_FAULT" | "TYPE_LAND_MASS" | "TYPE_CONTINENT" | "TYPE_ISLAND" | "TYPE_ATOLL" | "TYPE_OCEAN_ROCK_EXPOSED" | "TYPE_CAY" | "TYPE_PENINSULA" | "TYPE_ISTHMUS" | "TYPE_ELEVATED" | "TYPE_PEAK" | "TYPE_NUNATAK" | "TYPE_SPUR" | "TYPE_PASS" | "TYPE_PLATEAU" | "TYPE_RIDGE" | "TYPE_RAVINE" | "TYPE_CRATER" | "TYPE_KARST" | "TYPE_CLIFF" | "TYPE_VISTA" | "TYPE_DIGITAL_ELEVATION_MODEL" | "TYPE_UPLAND" | "TYPE_TERRACE" | "TYPE_SLOPE" | "TYPE_CONTOUR_LINE" | "TYPE_PAN" | "TYPE_UNSTABLE_HILLSIDE" | "TYPE_MOUNTAIN_RANGE" | "TYPE_UNDERSEA" | "TYPE_SUBMARINE_SEAMOUNT" | "TYPE_SUBMARINE_RIDGE" | "TYPE_SUBMARINE_GAP" | "TYPE_SUBMARINE_PLATEAU" | "TYPE_SUBMARINE_DEEP" | "TYPE_SUBMARINE_VALLEY" | "TYPE_SUBMARINE_BASIN" | "TYPE_SUBMARINE_SLOPE" | "TYPE_SUBMARINE_CLIFF" | "TYPE_SUBMARINE_PLAIN" | "TYPE_SUBMARINE_FRACTURE_ZONE" | "TYPE_CAVE" | "TYPE_ROCK" | "TYPE_ARCHIPELAGO" | "TYPE_POSTAL" | "TYPE_POSTAL_CODE" | "TYPE_POSTAL_CODE_PREFIX" | "TYPE_PREMISE" | "TYPE_SUB_PREMISE" | "TYPE_SUITE" | "TYPE_POST_TOWN" | "TYPE_POSTAL_ROUND" | "TYPE_META_FEATURE" | "TYPE_DATA_SOURCE" | "TYPE_LOCALE" | "TYPE_TIMEZONE" | "TYPE_BUSINESS_CHAIN" | "TYPE_PHONE_NUMBER_PREFIX" | "TYPE_PHONE_NUMBER_AREA_CODE" | "TYPE_BUSINESS_CORRIDOR" | "TYPE_ADDRESS_TEMPLATE" | "TYPE_TRANSIT_AGENCY" | "TYPE_FUTURE_GEOMETRY" | "TYPE_EVENT" | "TYPE_EARTHQUAKE" | "TYPE_HURRICANE" | "TYPE_WEATHER_CONDITION" | "TYPE_TRANSIENT" | "TYPE_ENTRANCE" | "TYPE_CARTOGRAPHIC" | "TYPE_HIGH_TENSION" | "TYPE_SKI_TRAIL" | "TYPE_SKI_LIFT" | "TYPE_SKI_BOUNDARY" | "TYPE_WATERSHED_BOUNDARY" | "TYPE_TARMAC" | "TYPE_WALL" | "TYPE_PICNIC_AREA" | "TYPE_PLAY_GROUND" | "TYPE_TRAIL_HEAD" | "TYPE_GOLF_TEEING_GROUND" | "TYPE_GOLF_PUTTING_GREEN" | "TYPE_GOLF_ROUGH" | "TYPE_GOLF_SAND_BUNKER" | "TYPE_GOLF_FAIRWAY" | "TYPE_GOLF_HOLE" | "TYPE_DEPRECATED_GOLF_SHOP" | "TYPE_CAMPING_SITE" | "TYPE_DESIGNATED_BARBECUE_PIT" | "TYPE_DESIGNATED_COOKING_AREA" | "TYPE_CAMPFIRE_PIT" | "TYPE_WATER_FOUNTAIN" | "TYPE_LITTER_RECEPTACLE" | "TYPE_LOCKER_AREA" | "TYPE_ANIMAL_ENCLOSURE" | "TYPE_CARTOGRAPHIC_LINE" | "TYPE_ESTABLISHMENT" | "TYPE_ESTABLISHMENT_GROUNDS" | "TYPE_ESTABLISHMENT_BUILDING" | "TYPE_ESTABLISHMENT_POI" | "TYPE_ESTABLISHMENT_SERVICE" | "TYPE_CELESTIAL" | "TYPE_ROAD_MONITOR" | "TYPE_PUBLIC_SPACES_AND_MONUMENTS" | "TYPE_STATUE" | "TYPE_TOWN_SQUARE" | "TYPE_LEVEL" | "TYPE_COMPOUND" | "TYPE_COMPOUND_GROUNDS" | "TYPE_COMPOUND_BUILDING" | "TYPE_COMPOUND_SECTION" | "TYPE_TERMINAL_POINT" | "TYPE_REGULATED_AREA" | "TYPE_LOGICAL_BORDER" | "TYPE_DO_NOT_USE_RESERVED_TO_CATCH_GENERATED_FILES" | "TYPE_UNKNOWN";
  /**
   * Represents vertical ordering for this feature relative to other
   * geometrically-overlaping features. See go/aboutgrades for more information
   * about distinction among different levels.
   */
  verticalOrdering?: GeostoreVerticalOrderingProto;
  /**
   * A version of the geometry which has water removed but is not simplified
   * (thus having equal or more vertices than polygon_for_display).
   */
  waterRemovedPolygon?: GeostorePolygonProto;
  /**
   * The official website of this feature. Stored as a repeated field to allow
   * for multilingual official websites (see comments in url.proto).
   */
  website?: GeostoreUrlProto[];
}

function serializeGeostoreFeatureProto(data: any): GeostoreFeatureProto {
  return {
    ...data,
    accessPoint: data["accessPoint"] !== undefined ? data["accessPoint"].map((item: any) => (serializeGeostoreAccessPointProto(item))) : undefined,
    address: data["address"] !== undefined ? data["address"].map((item: any) => (serializeGeostoreAddressProto(item))) : undefined,
    attachment: data["attachment"] !== undefined ? data["attachment"].map((item: any) => (serializeGeostoreAttachmentsAttachmentProto(item))) : undefined,
    attribute: data["attribute"] !== undefined ? data["attribute"].map((item: any) => (serializeGeostoreAttributeProto(item))) : undefined,
    bestLocale: data["bestLocale"] !== undefined ? serializeGeostoreBestLocaleProto(data["bestLocale"]) : undefined,
    border: data["border"] !== undefined ? serializeGeostoreBorderProto(data["border"]) : undefined,
    building: data["building"] !== undefined ? serializeGeostoreBuildingProto(data["building"]) : undefined,
    child: data["child"] !== undefined ? data["child"].map((item: any) => (serializeGeostoreFeatureIdProto(item))) : undefined,
    covering: data["covering"] !== undefined ? serializeGeostoreCellCoveringProto(data["covering"]) : undefined,
    establishment: data["establishment"] !== undefined ? serializeGeostoreEstablishmentProto(data["establishment"]) : undefined,
    exemptRegulatedArea: data["exemptRegulatedArea"] !== undefined ? data["exemptRegulatedArea"].map((item: any) => (serializeGeostoreFeatureIdProto(item))) : undefined,
    futureGeometry: data["futureGeometry"] !== undefined ? serializeGeostoreFeatureIdProto(data["futureGeometry"]) : undefined,
    futureGeometryFor: data["futureGeometryFor"] !== undefined ? serializeGeostoreFeatureIdProto(data["futureGeometryFor"]) : undefined,
    geopoliticalGeometry: data["geopoliticalGeometry"] !== undefined ? serializeGeostoreGeopoliticalGeometryProto(data["geopoliticalGeometry"]) : undefined,
    id: data["id"] !== undefined ? serializeGeostoreFeatureIdProto(data["id"]) : undefined,
    inferredGeometry: data["inferredGeometry"] !== undefined ? serializeGeostoreInferredGeometryProto(data["inferredGeometry"]) : undefined,
    interiorCovering: data["interiorCovering"] !== undefined ? serializeGeostoreCellCoveringProto(data["interiorCovering"]) : undefined,
    internal: data["internal"] !== undefined ? serializeGeostoreInternalFeatureProto(data["internal"]) : undefined,
    intersection: data["intersection"] !== undefined ? serializeGeostoreIntersectionProto(data["intersection"]) : undefined,
    intersectionGroup: data["intersectionGroup"] !== undefined ? serializeGeostoreIntersectionGroupProto(data["intersectionGroup"]) : undefined,
    kgProperty: data["kgProperty"] !== undefined ? data["kgProperty"].map((item: any) => (serializeFreebasePropertyValue(item))) : undefined,
    level: data["level"] !== undefined ? serializeGeostoreLevelProto(data["level"]) : undefined,
    logicalBorder: data["logicalBorder"] !== undefined ? serializeGeostoreLogicalBorderProto(data["logicalBorder"]) : undefined,
    metadata: data["metadata"] !== undefined ? serializeGeostoreFeatureMetadataProto(data["metadata"]) : undefined,
    originalId: data["originalId"] !== undefined ? serializeGeostoreFeatureIdProto(data["originalId"]) : undefined,
    parent: data["parent"] !== undefined ? data["parent"].map((item: any) => (serializeGeostoreFeatureIdProto(item))) : undefined,
    parking: data["parking"] !== undefined ? serializeGeostoreParkingProto(data["parking"]) : undefined,
    political: data["political"] !== undefined ? serializeGeostorePoliticalProto(data["political"]) : undefined,
    polygon: data["polygon"] !== undefined ? data["polygon"].map((item: any) => (serializeGeostorePolygonProto(item))) : undefined,
    polygonForDisplay: data["polygonForDisplay"] !== undefined ? serializeGeostorePolygonProto(data["polygonForDisplay"]) : undefined,
    propertyValueStatus: data["propertyValueStatus"] !== undefined ? data["propertyValueStatus"].map((item: any) => (serializeGeostorePropertyValueStatusProto(item))) : undefined,
    regulatedArea: data["regulatedArea"] !== undefined ? serializeGeostoreRegulatedAreaProto(data["regulatedArea"]) : undefined,
    relatedBorder: data["relatedBorder"] !== undefined ? data["relatedBorder"].map((item: any) => (serializeGeostoreFeatureIdProto(item))) : undefined,
    relatedEntrance: data["relatedEntrance"] !== undefined ? data["relatedEntrance"].map((item: any) => (serializeGeostoreEntranceReferenceProto(item))) : undefined,
    relatedFeature: data["relatedFeature"] !== undefined ? data["relatedFeature"].map((item: any) => (serializeGeostoreRelationProto(item))) : undefined,
    relatedTerminalPoint: data["relatedTerminalPoint"] !== undefined ? data["relatedTerminalPoint"].map((item: any) => (serializeGeostoreFeatureIdProto(item))) : undefined,
    restrictionGroup: data["restrictionGroup"] !== undefined ? serializeGeostoreRestrictionGroupProto(data["restrictionGroup"]) : undefined,
    roadMonitor: data["roadMonitor"] !== undefined ? serializeGeostoreRoadMonitorProto(data["roadMonitor"]) : undefined,
    segment: data["segment"] !== undefined ? serializeGeostoreSegmentProto(data["segment"]) : undefined,
    segmentPath: data["segmentPath"] !== undefined ? serializeGeostoreSegmentPathProto(data["segmentPath"]) : undefined,
    sign: data["sign"] !== undefined ? serializeGeostoreRoadSignProto(data["sign"]) : undefined,
    socialReference: data["socialReference"] !== undefined ? serializeGeostoreSocialReferenceProto(data["socialReference"]) : undefined,
    sourceInfo: data["sourceInfo"] !== undefined ? data["sourceInfo"].map((item: any) => (serializeGeostoreSourceInfoProto(item))) : undefined,
    status: data["status"] !== undefined ? serializeGeostoreExistenceProto(data["status"]) : undefined,
    tollCluster: data["tollCluster"] !== undefined ? serializeGeostoreTollClusterProto(data["tollCluster"]) : undefined,
    transitLine: data["transitLine"] !== undefined ? serializeGeostoreTransitLineProto(data["transitLine"]) : undefined,
    transitLineVariant: data["transitLineVariant"] !== undefined ? serializeGeostoreTransitLineVariantProto(data["transitLineVariant"]) : undefined,
    transitStation: data["transitStation"] !== undefined ? serializeGeostoreTransitStationProto(data["transitStation"]) : undefined,
    waterRemovedPolygon: data["waterRemovedPolygon"] !== undefined ? serializeGeostorePolygonProto(data["waterRemovedPolygon"]) : undefined,
  };
}

function deserializeGeostoreFeatureProto(data: any): GeostoreFeatureProto {
  return {
    ...data,
    accessPoint: data["accessPoint"] !== undefined ? data["accessPoint"].map((item: any) => (deserializeGeostoreAccessPointProto(item))) : undefined,
    address: data["address"] !== undefined ? data["address"].map((item: any) => (deserializeGeostoreAddressProto(item))) : undefined,
    attachment: data["attachment"] !== undefined ? data["attachment"].map((item: any) => (deserializeGeostoreAttachmentsAttachmentProto(item))) : undefined,
    attribute: data["attribute"] !== undefined ? data["attribute"].map((item: any) => (deserializeGeostoreAttributeProto(item))) : undefined,
    bestLocale: data["bestLocale"] !== undefined ? deserializeGeostoreBestLocaleProto(data["bestLocale"]) : undefined,
    border: data["border"] !== undefined ? deserializeGeostoreBorderProto(data["border"]) : undefined,
    building: data["building"] !== undefined ? deserializeGeostoreBuildingProto(data["building"]) : undefined,
    child: data["child"] !== undefined ? data["child"].map((item: any) => (deserializeGeostoreFeatureIdProto(item))) : undefined,
    covering: data["covering"] !== undefined ? deserializeGeostoreCellCoveringProto(data["covering"]) : undefined,
    establishment: data["establishment"] !== undefined ? deserializeGeostoreEstablishmentProto(data["establishment"]) : undefined,
    exemptRegulatedArea: data["exemptRegulatedArea"] !== undefined ? data["exemptRegulatedArea"].map((item: any) => (deserializeGeostoreFeatureIdProto(item))) : undefined,
    futureGeometry: data["futureGeometry"] !== undefined ? deserializeGeostoreFeatureIdProto(data["futureGeometry"]) : undefined,
    futureGeometryFor: data["futureGeometryFor"] !== undefined ? deserializeGeostoreFeatureIdProto(data["futureGeometryFor"]) : undefined,
    geopoliticalGeometry: data["geopoliticalGeometry"] !== undefined ? deserializeGeostoreGeopoliticalGeometryProto(data["geopoliticalGeometry"]) : undefined,
    id: data["id"] !== undefined ? deserializeGeostoreFeatureIdProto(data["id"]) : undefined,
    inferredGeometry: data["inferredGeometry"] !== undefined ? deserializeGeostoreInferredGeometryProto(data["inferredGeometry"]) : undefined,
    interiorCovering: data["interiorCovering"] !== undefined ? deserializeGeostoreCellCoveringProto(data["interiorCovering"]) : undefined,
    internal: data["internal"] !== undefined ? deserializeGeostoreInternalFeatureProto(data["internal"]) : undefined,
    intersection: data["intersection"] !== undefined ? deserializeGeostoreIntersectionProto(data["intersection"]) : undefined,
    intersectionGroup: data["intersectionGroup"] !== undefined ? deserializeGeostoreIntersectionGroupProto(data["intersectionGroup"]) : undefined,
    kgProperty: data["kgProperty"] !== undefined ? data["kgProperty"].map((item: any) => (deserializeFreebasePropertyValue(item))) : undefined,
    level: data["level"] !== undefined ? deserializeGeostoreLevelProto(data["level"]) : undefined,
    logicalBorder: data["logicalBorder"] !== undefined ? deserializeGeostoreLogicalBorderProto(data["logicalBorder"]) : undefined,
    metadata: data["metadata"] !== undefined ? deserializeGeostoreFeatureMetadataProto(data["metadata"]) : undefined,
    originalId: data["originalId"] !== undefined ? deserializeGeostoreFeatureIdProto(data["originalId"]) : undefined,
    parent: data["parent"] !== undefined ? data["parent"].map((item: any) => (deserializeGeostoreFeatureIdProto(item))) : undefined,
    parking: data["parking"] !== undefined ? deserializeGeostoreParkingProto(data["parking"]) : undefined,
    political: data["political"] !== undefined ? deserializeGeostorePoliticalProto(data["political"]) : undefined,
    polygon: data["polygon"] !== undefined ? data["polygon"].map((item: any) => (deserializeGeostorePolygonProto(item))) : undefined,
    polygonForDisplay: data["polygonForDisplay"] !== undefined ? deserializeGeostorePolygonProto(data["polygonForDisplay"]) : undefined,
    propertyValueStatus: data["propertyValueStatus"] !== undefined ? data["propertyValueStatus"].map((item: any) => (deserializeGeostorePropertyValueStatusProto(item))) : undefined,
    regulatedArea: data["regulatedArea"] !== undefined ? deserializeGeostoreRegulatedAreaProto(data["regulatedArea"]) : undefined,
    relatedBorder: data["relatedBorder"] !== undefined ? data["relatedBorder"].map((item: any) => (deserializeGeostoreFeatureIdProto(item))) : undefined,
    relatedEntrance: data["relatedEntrance"] !== undefined ? data["relatedEntrance"].map((item: any) => (deserializeGeostoreEntranceReferenceProto(item))) : undefined,
    relatedFeature: data["relatedFeature"] !== undefined ? data["relatedFeature"].map((item: any) => (deserializeGeostoreRelationProto(item))) : undefined,
    relatedTerminalPoint: data["relatedTerminalPoint"] !== undefined ? data["relatedTerminalPoint"].map((item: any) => (deserializeGeostoreFeatureIdProto(item))) : undefined,
    restrictionGroup: data["restrictionGroup"] !== undefined ? deserializeGeostoreRestrictionGroupProto(data["restrictionGroup"]) : undefined,
    roadMonitor: data["roadMonitor"] !== undefined ? deserializeGeostoreRoadMonitorProto(data["roadMonitor"]) : undefined,
    segment: data["segment"] !== undefined ? deserializeGeostoreSegmentProto(data["segment"]) : undefined,
    segmentPath: data["segmentPath"] !== undefined ? deserializeGeostoreSegmentPathProto(data["segmentPath"]) : undefined,
    sign: data["sign"] !== undefined ? deserializeGeostoreRoadSignProto(data["sign"]) : undefined,
    socialReference: data["socialReference"] !== undefined ? deserializeGeostoreSocialReferenceProto(data["socialReference"]) : undefined,
    sourceInfo: data["sourceInfo"] !== undefined ? data["sourceInfo"].map((item: any) => (deserializeGeostoreSourceInfoProto(item))) : undefined,
    status: data["status"] !== undefined ? deserializeGeostoreExistenceProto(data["status"]) : undefined,
    tollCluster: data["tollCluster"] !== undefined ? deserializeGeostoreTollClusterProto(data["tollCluster"]) : undefined,
    transitLine: data["transitLine"] !== undefined ? deserializeGeostoreTransitLineProto(data["transitLine"]) : undefined,
    transitLineVariant: data["transitLineVariant"] !== undefined ? deserializeGeostoreTransitLineVariantProto(data["transitLineVariant"]) : undefined,
    transitStation: data["transitStation"] !== undefined ? deserializeGeostoreTransitStationProto(data["transitStation"]) : undefined,
    waterRemovedPolygon: data["waterRemovedPolygon"] !== undefined ? deserializeGeostorePolygonProto(data["waterRemovedPolygon"]) : undefined,
  };
}

/**
 * Metadata to track feature derivations and replacements. This is used to
 * track feature provenance (particularly for road segments).
 */
export interface GeostoreFeatureReplacementInfoProto {
  /**
   * This feature was created to replace other features that are referenced by
   * this field.
   */
  derivedFrom?: GeostoreFeatureIdProto[];
  /**
   * This feature was replaced by other features that are referenced by this
   * this field.
   */
  replacedBy?: GeostoreFeatureIdProto[];
}

function serializeGeostoreFeatureReplacementInfoProto(data: any): GeostoreFeatureReplacementInfoProto {
  return {
    ...data,
    derivedFrom: data["derivedFrom"] !== undefined ? data["derivedFrom"].map((item: any) => (serializeGeostoreFeatureIdProto(item))) : undefined,
    replacedBy: data["replacedBy"] !== undefined ? data["replacedBy"].map((item: any) => (serializeGeostoreFeatureIdProto(item))) : undefined,
  };
}

function deserializeGeostoreFeatureReplacementInfoProto(data: any): GeostoreFeatureReplacementInfoProto {
  return {
    ...data,
    derivedFrom: data["derivedFrom"] !== undefined ? data["derivedFrom"].map((item: any) => (deserializeGeostoreFeatureIdProto(item))) : undefined,
    replacedBy: data["replacedBy"] !== undefined ? data["replacedBy"].map((item: any) => (deserializeGeostoreFeatureIdProto(item))) : undefined,
  };
}

/**
 * Internal field metadata. This part is not exposed to downstream consumers of
 * the repository (read-only clients) but is available to upstream providers to
 * the repository (read-write clients).
 */
export interface GeostoreFieldMetadataProto {
  internal?: GeostoreInternalFieldMetadataProto;
}

/**
 * Proto used to represent rights for a field type. See go/geo-rights for more
 * details. NOTE: Use google3/geostore/provenance/public/rights.h or
 * google3/java/com/google/geostore/provenance/rights/Rights.java instead of
 * accessing this proto directly.
 */
export interface GeostoreFieldWithRightsProto {
  /**
   * ** DEPRECATED ** If field_type is set to FEATURE_ATTRIBUTE or
   * KNOWLEDGE_GRAPH_PROPERTY, the attribute ID / KG property ID that makes this
   * field with rights complete.
   */
  attributeId?: string;
  featurePropertyId?: GeostoreFeaturePropertyIdProto;
  /**
   * The field type for which the rights level are tracked on. The default
   * value here has to match the value of fieldtype::NONE.
   */
  fieldType?: number;
  /**
   * The minimum rights level for all the current values on the field type.
   */
  minRightsLevel?:  | "UNKNOWN_RIGHTS" | "GT_RIGHTS" | "FULL_RIGHTS";
}

function serializeGeostoreFieldWithRightsProto(data: any): GeostoreFieldWithRightsProto {
  return {
    ...data,
    featurePropertyId: data["featurePropertyId"] !== undefined ? serializeGeostoreFeaturePropertyIdProto(data["featurePropertyId"]) : undefined,
  };
}

function deserializeGeostoreFieldWithRightsProto(data: any): GeostoreFieldWithRightsProto {
  return {
    ...data,
    featurePropertyId: data["featurePropertyId"] !== undefined ? deserializeGeostoreFeaturePropertyIdProto(data["featurePropertyId"]) : undefined,
  };
}

/**
 * Wrapper to hold data related to a lanes track, extendable for future data.
 */
export interface GeostoreFlowLineProto {
  track?: GeostoreTrackProto;
}

/**
 * Example: the choice of chicken, beef, or tofu for the Thai Basil dish. Each
 * option would have its own name, price, allergen info, etc. Note: This proto
 * stores both food and service items despite the name.
 */
export interface GeostoreFoodMenuItemOptionProto {
  allergenAbsent?:  | "ALLERGEN_DAIRY" | "ALLERGEN_EGG" | "ALLERGEN_FISH" | "ALLERGEN_PEANUT" | "ALLERGEN_SHELLFISH" | "ALLERGEN_SOY" | "ALLERGEN_TREE_NUT" | "ALLERGEN_WHEAT"[];
  allergenPresent?:  | "ALLERGEN_DAIRY" | "ALLERGEN_EGG" | "ALLERGEN_FISH" | "ALLERGEN_PEANUT" | "ALLERGEN_SHELLFISH" | "ALLERGEN_SOY" | "ALLERGEN_TREE_NUT" | "ALLERGEN_WHEAT"[];
  calories?: number;
  /**
   * Ingredients of the food dish option.
   */
  ingredients?: GeostoreFoodMenuItemOptionProtoIngredient[];
  /**
   * Photos of the food dish option.
   */
  media?: GeostoreMediaItemProto[];
  /**
   * The repeated name_info field here is for item options with names or
   * descriptions listed in multiple languages. When an item option has no names
   * or descriptions, the size of the repeated field name_info may be 0. For
   * example, when a food menu item does not have multiple options, the item
   * option proto is used only to specify price and nutritional information, so
   * it will not have a name_info field. There should be at most one name_info
   * for any given language.
   */
  nameInfo?: GeostorePriceListNameInfoProto[];
  /**
   * Nutrition facts of the food dish option. Note that it also includes
   * calories information with a finer defined unit information.
   */
  nutritionFacts?: GeostorePriceInfoFoodNutritionFacts;
  /**
   * Size of the order, represented in units of items. (e.g. 4 "skewers, 6
   * "pieces)
   */
  portionSize?: GeostoreFoodMenuItemOptionProtoPortionSize;
  /**
   * Methods on how the food dish option is prepared.
   */
  preparationMethods?:  | "METHOD_UNDEFINED" | "BAKED" | "BOILED" | "BLANCHED" | "BRAISED" | "CODDLED" | "PRESSURE_COOKED" | "SIMMERED" | "STEAMED" | "STEEPED" | "GRILLED" | "FRIED" | "PAN_FRIED" | "STIR_FRIED" | "SAUTEED" | "ROASTED" | "BARBECUED" | "SEARED" | "SMOKED" | "FERMENTED" | "MARINATED" | "PICKLED" | "BASTED" | "KNEADED" | "OTHER_METHOD"[];
  /**
   * We use PriceRangeProto here but we expect the lower_price and upper_price
   * to be both set to equal numbers because an option should have a single
   * price. This field is not required because food item prices may be variable
   * depending on season.
   */
  price?: GeostorePriceRangeProto;
  restriction?:  | "DIET_HALAL" | "DIET_KOSHER" | "DIET_ORGANIC" | "DIET_VEGAN" | "DIET_VEGETARIAN"[];
  /**
   * Number of people can be served by this food dish option.
   */
  servesNumPeople?: number;
  spiciness?:  | "SPICINESS_NONE" | "SPICINESS_MILD" | "SPICINESS_MEDIUM" | "SPICINESS_HOT";
}

/**
 * This message denotes an ingredient information of a food dish.
 */
export interface GeostoreFoodMenuItemOptionProtoIngredient {
  /**
   * The repeated name_info field is for the ingredient in multiple languages.
   */
  nameInfo?: GeostorePriceListNameInfoProto[];
}

/**
 * This message denotes the serving portion size of a food dish.
 */
export interface GeostoreFoodMenuItemOptionProtoPortionSize {
  /**
   * Required.
   */
  quantity?: number;
  /**
   * Required. The repeated name_info field is for the unit in multiple
   * languages.
   */
  unit?: GeostorePriceListNameInfoProto[];
}

/**
 * A food menu item must have a name although it can have multiple names in
 * different languages. Example: Thai Basil. Price for this item is specified in
 * the item_option field. Since the price of an item may be unknown, e.g.
 * seasonal price, there is nothing that requires an item_option to be present
 * in the FoodMenuItemProto.
 */
export interface GeostoreFoodMenuItemProto {
  itemOption?: GeostoreFoodMenuItemOptionProto[];
  /**
   * The repeated name_info field is for items listed in multiple languages.
   */
  nameInfo?: GeostorePriceListNameInfoProto[];
}

/**
 * A GConceptInstanceProto contains a GConceptID (which is the unique
 * identifier of a GConcept, a category in the Geo Ontology).
 */
export interface GeostoreGConceptInstanceProto {
  /**
   * The unique identifier of a GConcept (e.g. "gcid:railway").
   */
  gconceptId?: string;
  /**
   * Field-level metadata for this GConcept.
   */
  metadata?: GeostoreFieldMetadataProto;
  /**
   * The relative prominence of this category to this feature according to the
   * data provider, as one of the values from the enum above. Prominence is a
   * measure of how well the given GConcept describes the feature. An example is
   * a gas station with convenience store and ATM. All three GConcepts are very
   * relevant, but the gas_station GConcept is the most prominent. If the
   * prominence of this GConcept is unknown, this field should not be set.
   */
  prominence?:  | "NON_PRIMARY" | "PRIMARY";
}

/**
 * Encapsulates all the features which, together, define the geometry of a
 * feature. This happens by: 1. taking the union of all polygons of features
 * referenced in includes_geometry_of 2. subtracting the polygons of all the
 * features referenced in excludes_geometry_of
 */
export interface GeostoreGeometryComposition {
  /**
   * Features whose geometry to exclude while composing the geometry of this
   * feature.
   */
  excludesGeometryOf?: GeostoreFeatureIdProto[];
  /**
   * Features whose geometry to include while composing the geometry of this
   * feature.
   */
  includesGeometryOf?: GeostoreFeatureIdProto[];
}

function serializeGeostoreGeometryComposition(data: any): GeostoreGeometryComposition {
  return {
    ...data,
    excludesGeometryOf: data["excludesGeometryOf"] !== undefined ? data["excludesGeometryOf"].map((item: any) => (serializeGeostoreFeatureIdProto(item))) : undefined,
    includesGeometryOf: data["includesGeometryOf"] !== undefined ? data["includesGeometryOf"].map((item: any) => (serializeGeostoreFeatureIdProto(item))) : undefined,
  };
}

function deserializeGeostoreGeometryComposition(data: any): GeostoreGeometryComposition {
  return {
    ...data,
    excludesGeometryOf: data["excludesGeometryOf"] !== undefined ? data["excludesGeometryOf"].map((item: any) => (deserializeGeostoreFeatureIdProto(item))) : undefined,
    includesGeometryOf: data["includesGeometryOf"] !== undefined ? data["includesGeometryOf"].map((item: any) => (deserializeGeostoreFeatureIdProto(item))) : undefined,
  };
}

/**
 * Geopolitical (unsimplified) polygons for a feature for different
 * geopolitical use cases. See go/unsimplified-poly.
 */
export interface GeostoreGeopoliticalGeometryProto {
  /**
   * The unsimplified, water-subtracted polygon representing the feature's
   * geometry as viewed by the rest of the world, which may differ from its
   * default polygon, for example by excluding certain regions.
   */
  restOfWorldPolygon?: GeostorePolygonProto;
  /**
   * The unsimplified, water-subtracted polygon representing the feature's
   * geometry as viewed by the country that administers it, which may differ
   * from its default polygon, for example by including disputed areas.
   */
  selfPolygon?: GeostorePolygonProto;
}

function serializeGeostoreGeopoliticalGeometryProto(data: any): GeostoreGeopoliticalGeometryProto {
  return {
    ...data,
    restOfWorldPolygon: data["restOfWorldPolygon"] !== undefined ? serializeGeostorePolygonProto(data["restOfWorldPolygon"]) : undefined,
    selfPolygon: data["selfPolygon"] !== undefined ? serializeGeostorePolygonProto(data["selfPolygon"]) : undefined,
  };
}

function deserializeGeostoreGeopoliticalGeometryProto(data: any): GeostoreGeopoliticalGeometryProto {
  return {
    ...data,
    restOfWorldPolygon: data["restOfWorldPolygon"] !== undefined ? deserializeGeostorePolygonProto(data["restOfWorldPolygon"]) : undefined,
    selfPolygon: data["selfPolygon"] !== undefined ? deserializeGeostorePolygonProto(data["selfPolygon"]) : undefined,
  };
}

/**
 * The grade level of a segment represents the relative altitude of the segment
 * at a particular point along the segment. This level is in relation to other
 * segments at the same point. For example, you might have a freeway at level =
 * 0 and an overpass at level = 2. Vertical segments are represented by a
 * polyline containing only 1 vertex and exactly two grade_level in
 * segment.proto whose indices are 0. grade_level(0) represents the relative
 * height at the start point of the segments, and grade_level(1) represents the
 * one at the end point.
 */
export interface GeostoreGradeLevelProto {
  /**
   * The index of the point along the segment, where 0 is the starting point.
   * This means that the index of a point along a segment and its sibling will
   * be different.
   */
  index?: number;
  /**
   * The grade level of the indexed point. The grade level can be thought of as
   * a relative vertical ordering with respect to other segments at the same
   * point, where larger/more positive numbers are "higher". Negative grade
   * level values are allowed and are typically used for points below grade
   * level (0 is a common choice to represent the level of points at the ground
   * level). For vertical segments, the height, i.e. the vertical length, is
   * represented by difference of levels in millimeters. For example,
   * feature.segment().grade_level(0).level() == 0 and
   * feature.segment().grade_level(1).level() == 5000, then the length of the
   * vertical segment feature is 5000 millimeters (5 meters).
   */
  level?: number;
}

/**
 * Represents HTML text associated with a feature.
 */
export interface GeostoreHtmlTextProto {
  /**
   * Zero or more texts of the specified type, in various languages. If this is
   * a HTML_DESCRIPTION blob then these texts would hold the description in
   * English, German, and so forth. The text is an HTML fragment, not a full
   * page. The fragment should be suitable for including in a DIV. It must have
   * balanced HTML tags. It may use HTML's "class" attributes to assign classes
   * to HTML elements. This allows the HTML to be formatted by an (external)
   * style sheet. The HTML should not have embedded style sheet definitions, nor
   * should it have embedded JavaScript.
   */
  text?: GeostoreLanguageTaggedTextProto[];
  type?:  | "HTML_DESCRIPTION";
}

/**
 * Inferred geometry defines the geometry of a feature through the geometry of
 * other features. For instance, the geometry of a timezone can be specified as
 * the union of all the countries it applies to. See: go/inferred-geometry and
 * go/geo-schema:composite-geometry-editor for more details.
 */
export interface GeostoreInferredGeometryProto {
  /**
   * Features whose geometry depends on this feature's geometry.
   */
  definesGeometryFor?: GeostoreFeatureIdProto[];
  /**
   * Features whose geometry defines the geometry of this feature.
   */
  geometryComposition?: GeostoreGeometryComposition;
}

function serializeGeostoreInferredGeometryProto(data: any): GeostoreInferredGeometryProto {
  return {
    ...data,
    definesGeometryFor: data["definesGeometryFor"] !== undefined ? data["definesGeometryFor"].map((item: any) => (serializeGeostoreFeatureIdProto(item))) : undefined,
    geometryComposition: data["geometryComposition"] !== undefined ? serializeGeostoreGeometryComposition(data["geometryComposition"]) : undefined,
  };
}

function deserializeGeostoreInferredGeometryProto(data: any): GeostoreInferredGeometryProto {
  return {
    ...data,
    definesGeometryFor: data["definesGeometryFor"] !== undefined ? data["definesGeometryFor"].map((item: any) => (deserializeGeostoreFeatureIdProto(item))) : undefined,
    geometryComposition: data["geometryComposition"] !== undefined ? deserializeGeostoreGeometryComposition(data["geometryComposition"]) : undefined,
  };
}

/**
 * Main proto for all internal fields to be stored at the feature level.
 */
export interface GeostoreInternalFeatureProto {
  /**
   * A unique identifier for this feature's polygon data which is being held
   * externally in Shapestore (see go/shapestore).
   */
  polygonShapeId?: string;
  /**
   * A unique identifier for this feature's rest-of-world view polygon data
   * which is being held externally in Shapestore (see go/shapestore). This is
   * part of the feature's geopolitical geometry.
   */
  restOfWorldPolygonShapeId?: string;
  /**
   * Per-field rights for this feature. See
   * http://g3doc/geostore/g3doc/developers-guide/inputs/rights-tracking for
   * more information.
   */
  rightsStatus?: GeostoreRightsStatusProto;
  /**
   * A unique identifier for this feature's self view polygon data which is
   * being held externally in Shapestore (see go/shapestore). This is part of
   * the feature's geopolitical geometry.
   */
  selfPolygonShapeId?: string;
  /**
   * Trust signals/annotations for the feature. In an input feature, these
   * signals are computed at the beginning of the pipeline and are immutable
   * during the processing. In output features, this proto may define the
   * rules/criteria that a newer edit should meet, in order to be applied.
   */
  trust?: GeostoreTrustSignalsProto;
  /**
   * A unique identifier for this feature's water-removed polygon data which is
   * being held externally in Shapestore (see go/shapestore).
   */
  waterRemovedPolygonShapeId?: string;
}

function serializeGeostoreInternalFeatureProto(data: any): GeostoreInternalFeatureProto {
  return {
    ...data,
    rightsStatus: data["rightsStatus"] !== undefined ? serializeGeostoreRightsStatusProto(data["rightsStatus"]) : undefined,
  };
}

function deserializeGeostoreInternalFeatureProto(data: any): GeostoreInternalFeatureProto {
  return {
    ...data,
    rightsStatus: data["rightsStatus"] !== undefined ? deserializeGeostoreRightsStatusProto(data["rightsStatus"]) : undefined,
  };
}

export interface GeostoreInternalFieldMetadataProto {
  /**
   * Whether or not the piece of data has been generated automatically (i.e.,
   * by a bot/automated process based on heuristics/algorithms rather than
   * coming as a fact set by some human user or data provider based on their
   * knowledge). Note that this does NOT imply that the value was set as a
   * result of a bot operation on the repository, since it is conceivable to use
   * a bot/automated process simply as a way of convenience to ingest large
   * amount of canonical/ground truth data.
   */
  isAuto?: boolean;
  /**
   * Information about the source providing the piece of data this metadata is
   * attached to.
   */
  sourceSummary?: GeostoreInternalSourceSummaryProto;
}

/**
 * Internal-only proto used to express additional information about segments.
 * This is intended for communicating extra information between editing clients
 * and the repository, and should not be used by or visible to clients. WARNING
 * - if you add new fields to InternalSegmentProto, make sure that
 * geostore/tools/internal/mr-mergesegments_test.cc is aware of them.
 */
export interface GeostoreInternalSegmentProto {
  /**
   * The set of restrictions that apply to this segment; these are actually
   * *POSITIVE* restrictions, i.e. they are known to be allowed.
   */
  travelAllowance?: GeostoreRestrictionProto[];
}

function serializeGeostoreInternalSegmentProto(data: any): GeostoreInternalSegmentProto {
  return {
    ...data,
    travelAllowance: data["travelAllowance"] !== undefined ? data["travelAllowance"].map((item: any) => (serializeGeostoreRestrictionProto(item))) : undefined,
  };
}

function deserializeGeostoreInternalSegmentProto(data: any): GeostoreInternalSegmentProto {
  return {
    ...data,
    travelAllowance: data["travelAllowance"] !== undefined ? data["travelAllowance"].map((item: any) => (deserializeGeostoreRestrictionProto(item))) : undefined,
  };
}

export interface GeostoreInternalSourceSummaryProto {
  /**
   * Within the above provider, the dataset from which this piece of data was
   * generated. For fields that are auto-generated the "dataset" is likely to be
   * some algorithm's or program's name. Similar to SourceInfoProto.dataset but
   * with the difference that it is required to always be set. Providers that
   * don't have a concept of dataset may use "default".
   */
  dataset?: string;
  /**
   * The data provider from which this piece of data was generated. Equivalent
   * to SourceInfoProto.provider in the public schema.
   */
  provider?:  | "PROVIDER_ANY" | "PROVIDER_UNKNOWN" | "PROVIDER_NAVTEQ" | "PROVIDER_TELE_ATLAS" | "PROVIDER_TELE_ATLAS_MULTINET" | "PROVIDER_TELE_ATLAS_CODEPOINT" | "PROVIDER_TELE_ATLAS_GEOPOST" | "PROVIDER_TELE_ATLAS_DATAGEO" | "PROVIDER_TELE_ATLAS_ADDRESS_POINTS" | "PROVIDER_TELCONTAR" | "PROVIDER_EUROPA" | "PROVIDER_ROYAL_MAIL" | "PROVIDER_GOOGLE" | "PROVIDER_GOOGLE_HAND_EDIT" | "PROVIDER_GOOGLE_BORDERS" | "PROVIDER_GOOGLE_SUBRANGE" | "PROVIDER_GOOGLE_GT_FUSION" | "PROVIDER_GOOGLE_ZAGAT_CMS" | "PROVIDER_GOOGLE_PLACE_NAVBOOST" | "PROVIDER_GOOGLE_FOOTPRINT" | "PROVIDER_GOOGLE_PRODUCT_TERMS" | "PROVIDER_GOOGLE_POINTCARDS" | "PROVIDER_GOOGLE_BUSINESS_CHAINS" | "PROVIDER_GOOGLE_LOCAL_SUMMARIZATION" | "PROVIDER_GOOGLE_PRONUNCIATIONS" | "PROVIDER_GOOGLE_DUMPLING" | "PROVIDER_GOOGLE_DISTILLERY" | "PROVIDER_GOOGLE_LOCAL_ATTRIBUTE_SUMMARIZATION" | "PROVIDER_GOOGLE_RELATION_MINER" | "PROVIDER_GOOGLE_MAPSPAM" | "PROVIDER_GOOGLE_ROSE" | "PROVIDER_GOOGLE_LOCAL_PLACE_RATINGS" | "PROVIDER_GOOGLE_WIPEOUT" | "PROVIDER_GOOGLE_KNOWLEDGE_GRAPH" | "PROVIDER_GOOGLE_BEEGEES" | "PROVIDER_GOOGLE_REVIEW_SUMMARIZATION" | "PROVIDER_GOOGLE_OFFLINE_NON_CORE_ATTRIBUTE_SUMMARIZATION" | "PROVIDER_GOOGLE_GEO_WORLDMAPS" | "PROVIDER_GOOGLE_GEO_MODERATION" | "PROVIDER_GOOGLE_OYSTER_AUTO_EDITS" | "PROVIDER_GOOGLE_LOCAL_ALCHEMY" | "PROVIDER_GOOGLE_KEROUAC" | "PROVIDER_GOOGLE_MOBRANK" | "PROVIDER_GOOGLE_RAPTURE" | "PROVIDER_GOOGLE_CULTURAL_INSTITUTE" | "PROVIDER_GOOGLE_GEOCODES_FROM_LOCAL_FEEDS" | "PROVIDER_GOOGLE_ATTRIBUTES_FROM_CRAWLED_CHAINS" | "PROVIDER_GOOGLE_TACTILE_MAPS" | "PROVIDER_GOOGLE_MAPS_FOR_MOBILE" | "PROVIDER_GOOGLE_GEO_REALTIME" | "PROVIDER_GOOGLE_PROMINENT_PLACES" | "PROVIDER_GOOGLE_PLACE_ACTIONS" | "PROVIDER_GOOGLE_GT_AUTO_EDITS" | "PROVIDER_GOOGLE_WAZE" | "PROVIDER_GOOGLE_ONTHEGO" | "PROVIDER_GOOGLE_GT_IMPORT" | "PROVIDER_GOOGLE_STRUCTURED_DATA" | "PROVIDER_GOOGLE_HELICOPTER" | "PROVIDER_GOOGLE_ROLLBACK" | "PROVIDER_GOOGLE_RIGHTS_REPAIR" | "PROVIDER_GOOGLE_PERFUME" | "PROVIDER_GOOGLE_MAPS_TRANSLATION" | "PROVIDER_GOOGLE_CALL_ME_MAYBE" | "PROVIDER_GOOGLE_LOCAL_UNIVERSAL" | "PROVIDER_GOOGLE_CROUPIER" | "PROVIDER_GOOGLE_SKYSMART" | "PROVIDER_GOOGLE_RIDDLER" | "PROVIDER_GOOGLE_ROADCLOSURES" | "PROVIDER_GOOGLE_SPORE" | "PROVIDER_GOOGLE_LOCALIZATION" | "PROVIDER_GOOGLE_CATTERMS" | "PROVIDER_GOOGLE_GT_FIELD_OPS" | "PROVIDER_GOOGLE_MATCHMAKER" | "PROVIDER_GOOGLE_ARBITRATION" | "PROVIDER_GOOGLE_BIZBUILDER_OPS" | "PROVIDER_GOOGLE_LOCAL_INVENTORY_ADS" | "PROVIDER_GOOGLE_GT_DRAFTY" | "PROVIDER_GOOGLE_HOTELADS_OPS" | "PROVIDER_GOOGLE_MARKERS" | "PROVIDER_GOOGLE_STATE_MACHINE" | "PROVIDER_GOOGLE_ATTRIBUTES_INFERENCE" | "PROVIDER_GOOGLE_BIKESHARE" | "PROVIDER_GOOGLE_GHOSTWRITER" | "PROVIDER_GOOGLE_EDIT_PLATFORM" | "PROVIDER_GOOGLE_BLUE_GINGER" | "PROVIDER_GOOGLE_GEO_TIGER" | "PROVIDER_GOOGLE_HYADES" | "PROVIDER_GOOGLE_WEBQUARRY" | "PROVIDER_GOOGLE_GEO_MADDEN" | "PROVIDER_GOOGLE_ANDROID_PAY" | "PROVIDER_GOOGLE_OPENING_HOURS_TEAM" | "PROVIDER_GOOGLE_LOCAL_DISCOVERY" | "PROVIDER_GOOGLE_LOCAL_HEALTH" | "PROVIDER_GOOGLE_UGC_MAPS" | "PROVIDER_GOOGLE_FIBER" | "PROVIDER_GOOGLE_REVGEO" | "PROVIDER_GOOGLE_HOTELADS_PARTNER_FRONT_END" | "PROVIDER_GOOGLE_GEO_UGC_TASKS" | "PROVIDER_GOOGLE_GEOCODING" | "PROVIDER_GOOGLE_SPYGLASS" | "PROVIDER_GOOGLE_PLUS_CODES_AS_ADDRESSES" | "PROVIDER_GOOGLE_GEO_CHANGES" | "PROVIDER_GOOGLE_HUME" | "PROVIDER_GOOGLE_MEGAMIND" | "PROVIDER_GOOGLE_GT_ROADSYNTH" | "PROVIDER_GOOGLE_FIREBOLT" | "PROVIDER_GOOGLE_LOCAL_PLACE_OFFERINGS" | "PROVIDER_GOOGLE_UGC_SERVICES" | "PROVIDER_GOOGLE_GEOALIGN" | "PROVIDER_GOOGLE_GT_COMPOUNDS" | "PROVIDER_GOOGLE_FOOD_ORDERING" | "PROVIDER_GOOGLE_HOTEL_KNOWLEDGE_OPS" | "PROVIDER_GOOGLE_URAW" | "PROVIDER_GOOGLE_FLYEYE" | "PROVIDER_GOOGLE_YOUKE" | "PROVIDER_GOOGLE_GT_ZEPHYR" | "PROVIDER_GOOGLE_USER_SAFETY" | "PROVIDER_GOOGLE_ADDRESS_MAKER" | "PROVIDER_GOOGLE_UGC_PHOTOS" | "PROVIDER_GOOGLE_GT_WINDCHIME" | "PROVIDER_GOOGLE_SNAG_FIXER" | "PROVIDER_GOOGLE_GEO_DEALS" | "PROVIDER_GOOGLE_LOCAL_PLACE_TOPICS" | "PROVIDER_GOOGLE_PROPERTY_INSIGHTS" | "PROVIDER_GOOGLE_GEO_CONSUMER_MERCHANT_EXPERIMENTS" | "PROVIDER_GOOGLE_GEO_PORTKEY" | "PROVIDER_GOOGLE_ROAD_MAPPER" | "PROVIDER_GOOGLE_LOCATION_PLATFORM" | "PROVIDER_GOOGLE_POSTTRIP" | "PROVIDER_GOOGLE_TRAVEL_DESTINATION" | "PROVIDER_GOOGLE_GEO_DATA_UPLOAD" | "PROVIDER_GOOGLE_BIZBUILDER_CLEANUP" | "PROVIDER_GOOGLE_USER" | "PROVIDER_GOOGLE_STATION" | "PROVIDER_GOOGLE_GEO_FOOD" | "PROVIDER_GOOGLE_GEO_AR" | "PROVIDER_GOOGLE_GEO_TEMPORAL" | "PROVIDER_GOOGLE_SERVICES_MARKETPLACE" | "PROVIDER_GOOGLE_IMT_CLEANUP" | "PROVIDER_GOOGLE_GEO_FOOD_MENU" | "PROVIDER_GOOGLE_CARENAV" | "PROVIDER_GOOGLE_DRIVING_FEEDS" | "PROVIDER_GOOGLE_DRIVING_UGC" | "PROVIDER_GOOGLE_POLAR" | "PROVIDER_GOOGLE_TRIWILD" | "PROVIDER_GOOGLE_CROWD_COMPUTE_OPS" | "PROVIDER_GOOGLE_SA_FROM_WEB" | "PROVIDER_GOOGLE_POI_ALIGNMENT" | "PROVIDER_GOOGLE_SA_FROM_HULK" | "PROVIDER_GOOGLE_SERVICES_INTERACTIONS" | "PROVIDER_GOOGLE_ROADS_UGC_EDITOR" | "PROVIDER_GOOGLE_SA_FROM_NG_INFERENCE" | "PROVIDER_GOOGLE_GEO_DRIVING_VIZ" | "PROVIDER_GOOGLE_GEO_TASKING" | "PROVIDER_GOOGLE_CROWDTASK_DATACOMPUTE" | "PROVIDER_GOOGLE_CROWDTASK_TASKADS" | "PROVIDER_GOOGLE_CROWDTASK_TASKMATE" | "PROVIDER_GOOGLE_CROWDTASK_FURBALL" | "PROVIDER_GOOGLE_CROWDTASK_ADAP" | "PROVIDER_GOOGLE_GPAY" | "PROVIDER_GOOGLE_GEO_UGC_TRUSTED_USERS" | "PROVIDER_GOOGLE_THIRD_PARTY_DATA_PRODUCTION" | "PROVIDER_GOOGLE_GEOTRACKER" | "PROVIDER_GOOGLE_LOCAL_LANDMARK_INFERENCE" | "PROVIDER_GOOGLE_GEO_CLOSED_LOOP" | "PROVIDER_GOOGLE_SA_FROM_MERCHANT_POSTS" | "PROVIDER_GOOGLE_CORE_DATA_RIGHTS" | "PROVIDER_GOOGLE_SA_FROM_USER_REVIEWS" | "PROVIDER_GOOGLE_GEO_CONTENT_FIXER" | "PROVIDER_GOOGLE_POLYGON_REFINEMENT" | "PROVIDER_GOOGLE_HANASU" | "PROVIDER_GOOGLE_FULLRIGHTS_GEO_DATA_UPLOAD" | "PROVIDER_GOOGLE_FULLRIGHTS_3P_OUTREACH_UPLOAD" | "PROVIDER_GOOGLE_ATTRIBUTION_3P_OUTREACH_UPLOAD" | "PROVIDER_GOOGLE_SA_FROM_FOOD_MENUS" | "PROVIDER_GOOGLE_GT_CONSISTENCY_EDITS" | "PROVIDER_GOOGLE_SA_QUALITY" | "PROVIDER_GOOGLE_GDCE_CLEANUP" | "PROVIDER_GOOGLE_UGC_QUALITY_CHAINS" | "PROVIDER_GOOGLE_ATTRIBUTES_DISCOVERY" | "PROVIDER_GOOGLE_GEO_LDE" | "PROVIDER_GOOGLE_GEO_SIGNAL_TRACKING" | "PROVIDER_GOOGLE_UGC_AGGREGATION" | "PROVIDER_GOOGLE_3D_BASEMAP" | "PROVIDER_GOOGLE_MAPFACTS_PRIVACY" | "PROVIDER_GOOGLE_GT_ALF" | "PROVIDER_GOOGLE_GT_OPERATOR_PROVENANCE" | "PROVIDER_GOOGLE_LOCAL_SERVICES_ADS" | "PROVIDER_GOOGLE_LOCALSEARCH" | "PROVIDER_GOOGLE_TRANSIT" | "PROVIDER_GOOGLE_GEOWIKI" | "PROVIDER_GOOGLE_CHINA_LOCAL_TEAM" | "PROVIDER_GOOGLE_SYNTHESIZED" | "PROVIDER_GOOGLE_INTERNAL_TEST" | "PROVIDER_GOOGLE_DISPUTED_AREAS" | "PROVIDER_GOOGLE_3DWAREHOUSE" | "PROVIDER_GOOGLE_GROUNDS_BUILDER" | "PROVIDER_GOOGLE_SESAME" | "PROVIDER_GOOGLE_GT" | "PROVIDER_GOOGLE_GT_BASEMAP_UPLOAD" | "PROVIDER_GOOGLE_ADSDB" | "PROVIDER_GOOGLE_MACHINE_TRANSLITERATION" | "PROVIDER_GOOGLE_TRAVELSEARCH" | "PROVIDER_GOOGLE_PANORAMIO" | "PROVIDER_GOOGLE_YOUTUBE" | "PROVIDER_GOOGLE_OLD" | "PROVIDER_GOOGLE_STREETVIEW" | "PROVIDER_GOOGLE_STREETVIEW_BIZVIEW" | "PROVIDER_GOOGLE_ZIPIT" | "PROVIDER_GOOGLE_OYSTER_CONNECT_ROUTES" | "PROVIDER_GOOGLE_GOLDEN" | "PROVIDER_GOOGLE_INNERSPACE" | "PROVIDER_GOOGLE_MAPSEARCH" | "PROVIDER_GOOGLE_CATEGORIES_TEAM" | "PROVIDER_GOOGLE_CROWDSENSUS" | "PROVIDER_GOOGLE_LOCAL_ALGORITHMIC_IDENTITY" | "PROVIDER_GOOGLE_FREEBASE" | "PROVIDER_GOOGLE_HOTELADS" | "PROVIDER_GOOGLE_AUTHORITY_PAGES" | "PROVIDER_GOOGLE_PLACES_API" | "PROVIDER_GOOGLE_NAMEHEATMAP" | "PROVIDER_GOOGLE_MAPMAKER" | "PROVIDER_GOOGLE_MAPMAKER_MOBILE" | "PROVIDER_GOOGLE_MAPMAKER_PANCAKE" | "PROVIDER_GOOGLE_MAPMAKER_V2" | "PROVIDER_GOOGLE_LOCAL_CLUSTERING_OPERATOR_OVERRIDE" | "PROVIDER_GOOGLE_SERVED_ON_MAPMAKER" | "PROVIDER_GOOGLE_GT_LOCAL" | "PROVIDER_GOOGLE_GT_LOCAL_WITH_RIGHTS" | "PROVIDER_GOOGLE_LOGS_RANKING_SIGNALS" | "PROVIDER_GOOGLE_ENTITY_NAVBOOST" | "PROVIDER_GOOGLE_RELATED_PLACES" | "PROVIDER_GOOGLE_KNOWN_FOR_TERMS" | "PROVIDER_GOOGLE_SYNTHETIC_AREAS" | "PROVIDER_GOOGLE_AUTHORITY_PAGE_PHOTOS" | "PROVIDER_GOOGLE_CROSS_STREETS" | "PROVIDER_GOOGLE_CORRIDORS" | "PROVIDER_GOOGLE_BICYCLE_RENTAL" | "PROVIDER_GOOGLE_CONCRETE_URLS" | "PROVIDER_GOOGLE_LEANBACK" | "PROVIDER_GOOGLE_LOCKED_LISTINGS" | "PROVIDER_GOOGLE_MONITORING" | "PROVIDER_GOOGLE_SPROUT" | "PROVIDER_GOOGLE_LOCAL_SEARCH_QUALITY" | "PROVIDER_GOOGLE_GOBY" | "PROVIDER_GOOGLE_PROBLEM_REPORT" | "PROVIDER_GOOGLE_CANDID" | "PROVIDER_GOOGLE_BIZBUILDER" | "PROVIDER_AUTOMOTIVE_NAVIGATION_DATA" | "PROVIDER_MAPDATA_SCIENCES" | "PROVIDER_MAPONICS" | "PROVIDER_SKI_RESORTS" | "PROVIDER_ZENRIN" | "PROVIDER_SANBORN" | "PROVIDER_URBAN_MAPPING" | "PROVIDER_US_GOVERNMENT" | "PROVIDER_US_CENSUS" | "PROVIDER_US_POSTAL_SERVICE" | "PROVIDER_US_GEOLOGICAL_SURVEY" | "PROVIDER_US_GNIS" | "PROVIDER_US_LANDSAT" | "PROVIDER_US_NATIONAL_GEOSPATIAL_INTELLIGENCE_AGENCY" | "PROVIDER_US_NGA_GNS" | "PROVIDER_US_SSIBL" | "PROVIDER_US_BUREAU_OF_TRANSPORTATION_STATISTICS" | "PROVIDER_US_NATIONAL_OCEANIC_AND_ATMOSPHERIC_ADMINISTRATION" | "PROVIDER_US_POLAR_GEOSPATIAL_CENTER" | "PROVIDER_US_DEPARTMENT_OF_AGRICULTURE" | "PROVIDER_US_NPI_REGISTRY" | "PROVIDER_US_BUREAU_OF_INDIAN_AFFAIRS" | "PROVIDER_DMTI_SPATIAL" | "PROVIDER_INTERNATIONAL_HYDROGRAPHIC_ORGANIZATION" | "PROVIDER_MAPLINK" | "PROVIDER_KINGWAY" | "PROVIDER_GEOCENTRE" | "PROVIDER_CN_NATIONAL_FOUNDAMENTAL_GIS" | "PROVIDER_CN_MAPABC" | "PROVIDER_SMITHSONIAN_INSTITUTE" | "PROVIDER_TRACKS_FOR_AFRICA" | "PROVIDER_PPWK" | "PROVIDER_LEADDOG" | "PROVIDER_CENTRE_DONNEES_ASTRONOMIQUES_STRASBOURG" | "PROVIDER_GISRAEL" | "PROVIDER_BASARSOFT" | "PROVIDER_MAPINFO" | "PROVIDER_MAPIT" | "PROVIDER_GEOBASE" | "PROVIDER_ORION" | "PROVIDER_CENTRAL_EUROPEAN_DATA_AGENCY" | "PROVIDER_ANASAT" | "PROVIDER_MINED_POSTCODES" | "PROVIDER_DMAPAS" | "PROVIDER_COMMON_LOCALE_DATA_REPOSITORY" | "PROVIDER_CH_SBB" | "PROVIDER_SKENERGY" | "PROVIDER_GBRMPA" | "PROVIDER_KOREA_POST" | "PROVIDER_CN_AUTONAVI" | "PROVIDER_MINED_POI" | "PROVIDER_ML_INFOMAP" | "PROVIDER_SNOOPER" | "PROVIDER_GEOSISTEMAS" | "PROVIDER_AFRIGIS" | "PROVIDER_TRANSNAVICOM" | "PROVIDER_EASYCONNECT" | "PROVIDER_LANTMATERIET" | "PROVIDER_LOGICA" | "PROVIDER_MAPKING" | "PROVIDER_DIANPING" | "PROVIDER_GEONAV" | "PROVIDER_HEIBONSHA" | "PROVIDER_DEUTSCHE_TELEKOM" | "PROVIDER_LINGUISTIC_DATA_CONSORTIUM" | "PROVIDER_ACXIOM" | "PROVIDER_DUN_AND_BRADSTREET" | "PROVIDER_FEDERAL_AVIATION_ADMINISTRATION" | "PROVIDER_INFOUSA" | "PROVIDER_INFOUSA_NIXIE" | "PROVIDER_THOMSON_LOCAL" | "PROVIDER_TELEFONICA_PUBLICIDAD_E_INFORMACION" | "PROVIDER_WIKIPEDIA" | "PROVIDER_INFOBEL" | "PROVIDER_MX_GOVERNMENT" | "PROVIDER_MX_NATIONAL_INSTITUTE_STATISTICS_GEOGRAPHY" | "PROVIDER_MX_SERVICIO_POSTAL_MEXICANO" | "PROVIDER_TELEGATE" | "PROVIDER_TELELISTAS" | "PROVIDER_MAPCITY" | "PROVIDER_EXPLAINER_DC" | "PROVIDER_DAIKEI" | "PROVIDER_NL_CHAMBER_OF_COMMERCE" | "PROVIDER_KOREA_INFO_SERVICE" | "PROVIDER_WIKITRAVEL" | "PROVIDER_FLICKR" | "PROVIDER_DIANCO" | "PROVIDER_VOLT_DELTA" | "PROVIDER_SG_GOVERNMENT" | "PROVIDER_SG_LAND_TRANSPORT_AUTHORITY" | "PROVIDER_MAPBAR" | "PROVIDER_LONGTU" | "PROVIDER_SA_GOVERNMENT" | "PROVIDER_SA_SAUDI_POST" | "PROVIDER_PEAKLIST" | "PROVIDER_LOCAL_BUSINESS_CENTER" | "PROVIDER_LOCAL_FEED_XML" | "PROVIDER_WEB" | "PROVIDER_RAILS_TO_TRAILS" | "PROVIDER_INDIACOM" | "PROVIDER_INFOMEDIA" | "PROVIDER_PICASA" | "PROVIDER_AT_GOVERNMENT" | "PROVIDER_AT_BUNDESAMT_FUR_EICH_UND_VERMESSUNGSWESEN" | "PROVIDER_AT_NATIONAL_TOURIST_OFFICE" | "PROVIDER_AT_AUSTRIA_POST" | "PROVIDER_NO_GOVERNMENT" | "PROVIDER_NO_NORSK_EIENDOMSINFORMASJON" | "PROVIDER_NO_POSTEN_NORGE_AS" | "PROVIDER_CH_GOVERNMENT" | "PROVIDER_CH_SWISS_POST" | "PROVIDER_CH_SWISSTOPO" | "PROVIDER_CH_SWISS_NATIONAL_PARK" | "PROVIDER_NAVIT" | "PROVIDER_GEOSEARCH" | "PROVIDER_DE_GOVERNMENT" | "PROVIDER_BUNDESAMT_KARTOGRAPHIE_UND_GEODASIE" | "PROVIDER_BUNDESNETZAGENTUR" | "PROVIDER_SCHOBER_GROUP" | "PROVIDER_MIREO" | "PROVIDER_PUBLIC_MUNICIPALITY" | "PROVIDER_US_PUBLIC_MUNICIPALITY" | "PROVIDER_US_PUBLIC_MUNICIPALITY_WEBSTER_TEXAS" | "PROVIDER_US_PUBLIC_MUNICIPALITY_AMHERST_MASSACHUSETTS" | "PROVIDER_US_PUBLIC_MUNICIPALITY_BLOOMINGTON_INDIANA" | "PROVIDER_US_PUBLIC_MUNICIPALITY_PASADENA_CALIFORNIA" | "PROVIDER_US_PUBLIC_MUNICIPALITY_CHULA_VISTA_CALIFORNIA" | "PROVIDER_US_PUBLIC_MUNICIPALITY_TEMPE_ARIZONA" | "PROVIDER_US_PUBLIC_MUNICIPALITY_COLUMBUS_OHIO" | "PROVIDER_US_PUBLIC_MUNICIPALITY_PORTAGE_MICHIGAN" | "PROVIDER_US_PUBLIC_MUNICIPALITY_GEORGETOWN_KENTUCKY" | "PROVIDER_US_PUBLIC_MUNICIPALITY_GREENVILLE_SOUTH_CAROLINA" | "PROVIDER_US_PUBLIC_MUNICIPALITY_NASHVILLE_TENNESSEE" | "PROVIDER_US_PUBLIC_MUNICIPALITY_WASHINGTON_DISTRICT_OF_COLUMBIA" | "PROVIDER_US_PUBLIC_MUNICIPALITY_BOULDER_COLORADO" | "PROVIDER_NZ_PUBLIC_MUNICIPALITY" | "PROVIDER_NZ_PUBLIC_MUNICIPALITY_ENVIRONMENT_BAY" | "PROVIDER_PL_PUBLIC_MUNICIPALITY" | "PROVIDER_PL_PUBLIC_MUNICIPALITY_BIELSKO_BIALA" | "PROVIDER_DE_PUBLIC_MUNICIPALITY" | "PROVIDER_DE_PUBLIC_MUNICIPALITY_FRANKFURT" | "PROVIDER_DE_PUBLIC_MUNICIPALITY_HAMBURG" | "PROVIDER_DE_PUBLIC_MUNICIPALITY_KARLSRUHE" | "PROVIDER_PT_PUBLIC_MUNICIPALITY" | "PROVIDER_PT_PUBLIC_MUNICIPALITY_SANTA_CRUZ" | "PROVIDER_AT_PUBLIC_MUNICIPALITY" | "PROVIDER_AT_PUBLIC_MUNICIPALITY_KLAGENFURT" | "PROVIDER_AT_PUBLIC_MUNICIPALITY_LINZ" | "PROVIDER_ES_PUBLIC_MUNICIPALITY" | "PROVIDER_ES_PUBLIC_MUNICIPALITY_AZKOITIA" | "PROVIDER_ES_PUBLIC_MUNICIPALITY_BEASAIN" | "PROVIDER_ES_PUBLIC_MUNICIPALITY_GIRONA" | "PROVIDER_ES_PUBLIC_MUNICIPALITY_SAN_SEBASTIAN" | "PROVIDER_ES_PUBLIC_MUNICIPALITY_CATALUNYA" | "PROVIDER_ES_PUBLIC_MUNICIPALITY_HONDARRIBIA" | "PROVIDER_AU_PUBLIC_MUNICIPALITY" | "PROVIDER_AU_PUBLIC_MUNICIPALITY_LAUNCESTON_TASMANIA" | "PROVIDER_IS_PUBLIC_MUNICIPALITY" | "PROVIDER_IS_PUBLIC_MUNICIPALITY_REYKJAVIK" | "PROVIDER_NL_PUBLIC_MUNICIPALITY" | "PROVIDER_NL_PUBLIC_MUNICIPALITY_AMELSTEVEEN" | "PROVIDER_BE_PUBLIC_MUNICIPALITY" | "PROVIDER_BE_PUBLIC_MUNICIPALITY_ANTWERPEN" | "PROVIDER_CA_PUBLIC_MUNICIPALITY" | "PROVIDER_CA_PUBLIC_MUNICIPALITY_FREDERICTON_NEW_BRUNSWICK" | "PROVIDER_CA_PUBLIC_MUNICIPALITY_KAMLOOPS_BRITISH_COLUMBIA" | "PROVIDER_CA_PUBLIC_MUNICIPALITY_NANAIMO_BRITISH_COLUMBIA" | "PROVIDER_CA_PUBLIC_MUNICIPALITY_BANFF_ALBERTA" | "PROVIDER_CA_PUBLIC_MUNICIPALITY_CALGARY_ALBERTA" | "PROVIDER_CA_PUBLIC_MUNICIPALITY_TORONTO_ONTARIO" | "PROVIDER_SE_PUBLIC_MUNICIPALITY" | "PROVIDER_SE_PUBLIC_MUNICIPALITY_UMEA" | "PROVIDER_UA_PUBLIC_MUNICIPALITY" | "PROVIDER_UA_PUBLIC_MUNICIPALITY_KHARKIV" | "PROVIDER_OTHER_PUBLIC_MUNICIPALITY" | "PROVIDER_OTHER_PUBLIC_MUNICIPALITY_AQUA_CALIENTE_CAHUILLA_INDIANS" | "PROVIDER_FR_PUBLIC_MUNICIPALITY" | "PROVIDER_FR_PUBLIC_MUNICIPALITY_PONT_AUDEMER" | "PROVIDER_FR_PUBLIC_MUNICIPALITY_BORDEAUX" | "PROVIDER_SG_PUBLIC_MUNICIPALITY" | "PROVIDER_BR_PUBLIC_MUNICIPALITY" | "PROVIDER_BR_PUBLIC_MUNICIPALITY_RIO_DE_JANEIRO" | "PROVIDER_MAPCUBE" | "PROVIDER_3D_REALITYMAPS" | "PROVIDER_DEUTSCHES_ZENTRUM_FUR_LUFT_UND_RAUMFAHRT" | "PROVIDER_3D_CITIES_SOCIEDADE_ANONIMA" | "PROVIDER_DISNEY" | "PROVIDER_CYBERCITY" | "PROVIDER_PRECISION_LIGHTWORKS_MODELWORKS" | "PROVIDER_VIRTUAL_HUNGARY_LIMITED" | "PROVIDER_VIRTUEL_CITY" | "PROVIDER_SCREAMPOINT_INTERNATIONAL" | "PROVIDER_AGENTSCHAP_VOOR_GEOGRAFISCHE_INFORMATIE_VLAANDEREN" | "PROVIDER_FR_GOVERNMENT" | "PROVIDER_FR_INSTITUT_GEOGRAPHIQUE_NATIONAL" | "PROVIDER_FR_CADASTRE" | "PROVIDER_DIADIEM" | "PROVIDER_THE_WEATHER_CHANNEL" | "PROVIDER_COWI" | "PROVIDER_FALKPLAN_ANDES" | "PROVIDER_NL_GOVERNMENT" | "PROVIDER_NL_KADASTER" | "PROVIDER_NL_BOARD_OF_TOURISM_AND_CONVENTIONS" | "PROVIDER_DIGITAL_MAP_PRODUCTS" | "PROVIDER_SILICE_DIGITAL" | "PROVIDER_TYDAC" | "PROVIDER_ALBRECHT_GOLF" | "PROVIDER_HEALTH_CH" | "PROVIDER_VISITDENMARK" | "PROVIDER_FLYHERE" | "PROVIDER_DIGITAL_DATA_SERVICES" | "PROVIDER_MECOMO" | "PROVIDER_ZA_GOVERNMENT" | "PROVIDER_ZA_RURAL_DEVELOPMENT_LAND_REFORM" | "PROVIDER_SENSIS" | "PROVIDER_JJCONNECT" | "PROVIDER_OPPLYSNINGEN" | "PROVIDER_TELLUS" | "PROVIDER_IQONIA" | "PROVIDER_BE_GOVERNMENT" | "PROVIDER_BE_NATIONAAL_GEOGRAFISCH_INSTITUUT" | "PROVIDER_BE_BRUSSELS_MOBILITY" | "PROVIDER_YELLOWMAP_AG" | "PROVIDER_STIFTUNG_GESUNDHEIT" | "PROVIDER_GIATA" | "PROVIDER_SANPARKS" | "PROVIDER_CENTRE_DINFORMATIQUE_POUR_LA_REGION_BRUXELLOISE" | "PROVIDER_INFOPORTUGAL" | "PROVIDER_NEGOCIOS_DE_TELECOMUNICACOES_E_SISTEMAS_DE_INFORMACAO" | "PROVIDER_COLLINS_BARTHOLOMEW" | "PROVIDER_PROTECT_PLANET_OCEAN" | "PROVIDER_KARTTAKESKUS" | "PROVIDER_FI_GOVERNMENT" | "PROVIDER_FI_NATIONAL_ROAD_ADMINISTRATION" | "PROVIDER_FI_NATIONAL_LAND_SURVEY" | "PROVIDER_FI_STATISTICS_FINLAND" | "PROVIDER_GB_GOVERNMENT" | "PROVIDER_GB_ORDNANCE_SURVEY" | "PROVIDER_NATURAL_ENGLAND" | "PROVIDER_WELSH_GOVERNMENT" | "PROVIDER_GB_OFFICE_FOR_NATIONAL_STATISTICS" | "PROVIDER_EPSILON" | "PROVIDER_PARTNER_FRONT_END" | "PROVIDER_CARTESIA" | "PROVIDER_SE_GOVERNMENT" | "PROVIDER_SE_TRAFIKVERKET" | "PROVIDER_SE_NATURVARDSVERKET" | "PROVIDER_IE_GOVERNMENT" | "PROVIDER_IE_ORDNANCE_SURVEY_IRELAND" | "PROVIDER_LU_GOVERNMENT" | "PROVIDER_LU_P_AND_T_LUXEMBOURG" | "PROVIDER_LU_ADMINISTRATION_DU_CADASTRE_ET_DE_LA_TOPOGRAPHIE" | "PROVIDER_LU_NATIONAL_TOURIST_OFFICE" | "PROVIDER_MAPFLOW" | "PROVIDER_TKARTOR" | "PROVIDER_JUMPSTART" | "PROVIDER_EPTISA" | "PROVIDER_MC_GOVERNMENT" | "PROVIDER_MC_PRINCIPAUTE_DE_MONACO" | "PROVIDER_MONOLIT" | "PROVIDER_ENVIRONMENTAL_SYSTEMS_RESEARCH_INSTITUTE" | "PROVIDER_MODIS" | "PROVIDER_GEOX" | "PROVIDER_GEODIRECTORY" | "PROVIDER_GEOPLAN" | "PROVIDER_INFODIREKT" | "PROVIDER_GEOGLOBAL" | "PROVIDER_DEUTSCHE_POST" | "PROVIDER_TRACASA" | "PROVIDER_CORREOS" | "PROVIDER_ES_GOVERNMENT" | "PROVIDER_ES_CENTRO_NACIONAL_DE_INFORMACION_GEOGRAFICA" | "PROVIDER_EDIMAP" | "PROVIDER_VERIZON" | "PROVIDER_NATIONAL_GEOGRAPHIC_MAPS" | "PROVIDER_PROMAPS" | "PROVIDER_CONSODATA" | "PROVIDER_DE_AGOSTINI" | "PROVIDER_FEDERPARCHI" | "PROVIDER_NAVIGO" | "PROVIDER_ITALIAMAPPE" | "PROVIDER_CZECOT" | "PROVIDER_NATURAL_EARTH" | "PROVIDER_REGIO" | "PROVIDER_SHIPWRECK_CENTRAL" | "PROVIDER_RUTGERS_STATE_UNIVERSITY" | "PROVIDER_TWINICE" | "PROVIDER_NORTHERN_IRELAND_TOURIST_BOARD" | "PROVIDER_INFOGROUP" | "PROVIDER_TNET" | "PROVIDER_CTT_CORREIOS_DE_PORTUGAL" | "PROVIDER_EUROPARC" | "PROVIDER_IUPPITER" | "PROVIDER_MICHAEL_BAUER_INTERNATIONAL" | "PROVIDER_LEPTON" | "PROVIDER_MAPPOINT" | "PROVIDER_GEODATA" | "PROVIDER_RU_GOVERNMENT" | "PROVIDER_RU_FNS_KLADR" | "PROVIDER_BR_GOVERNMENT" | "PROVIDER_BR_INSTITUTO_BRASILEIRO_DO_MEIO_AMBIENTE_E_DOS_RECURSOS_NATURAIS_RENOVAVEIS" | "PROVIDER_BR_MINISTERIO_DO_MEIO_AMBIENTE" | "PROVIDER_BR_AGENCIA_NACIONAL_DE_AGUAS" | "PROVIDER_BR_INSTITUTO_BRASILEIRO_DE_GEOGRAFIA_E_ESTATISTICA" | "PROVIDER_BR_FUNDACAO_NACIONAL_DO_INDIO" | "PROVIDER_BR_DEPARTAMENTO_NACIONAL_DE_INFRAESTRUTURA_DE_TRANSPORTES" | "PROVIDER_AZAVEA" | "PROVIDER_NORTHSTAR" | "PROVIDER_COMMEDI" | "PROVIDER_NEXUS_GEOGRAFICS" | "PROVIDER_INFOERA" | "PROVIDER_AD_GOVERNMENT" | "PROVIDER_AD_AREA_DE_CARTOGRAFIA" | "PROVIDER_MAXXIMA" | "PROVIDER_SI_GOVERNMENT" | "PROVIDER_SI_AGENCY_FOR_ENVIRONMENT" | "PROVIDER_TRANSPORT_HI_TECH_CONSULTANTS" | "PROVIDER_L1_TECHNOLOGIES" | "PROVIDER_TELEMEDIA" | "PROVIDER_CDCOM_PROGOROD" | "PROVIDER_MIT_CITYGUIDE" | "PROVIDER_SUNCART" | "PROVIDER_MICROMAPPER" | "PROVIDER_RICHI" | "PROVIDER_FORUM44" | "PROVIDER_SEAT" | "PROVIDER_VALASSIS" | "PROVIDER_NAVICOM" | "PROVIDER_COLTRACK" | "PROVIDER_PSMA_AUSTRALIA" | "PROVIDER_PT_DUTA_ASTAKONA_GIRINDA" | "PROVIDER_CA_GOVERNMENT" | "PROVIDER_STATISTICS_CANADA" | "PROVIDER_TOCTOC" | "PROVIDER_RMSI" | "PROVIDER_TRUE_TECHNOLOGY" | "PROVIDER_INCREMENT_P_CORPORATION" | "PROVIDER_GOJAVAS" | "PROVIDER_GEOINFORMATION_GROUP" | "PROVIDER_CYBERSOFT" | "PROVIDER_TSENTR_EFFEKTIVNYKH_TEKHNOLOGIY" | "PROVIDER_EE_GOVERNMENT" | "PROVIDER_EE_MAA_AMET" | "PROVIDER_GASBUDDY" | "PROVIDER_DK_GOVERNMENT" | "PROVIDER_DK_GEODATASTYRELSEN" | "PROVIDER_MURCIA_REGION_GOVERNMENT" | "PROVIDER_CORREIOS" | "PROVIDER_WEST_WORLD_MEDIA" | "PROVIDER_INTERNATIONAL_MAPPING_ASSOCIATION" | "PROVIDER_MEDICARE" | "PROVIDER_POLARIS" | "PROVIDER_TW_GOVERNMENT" | "PROVIDER_TW_MINISTRY_OF_THE_INTERIOR_SURVEYING_AND_MAPPING_CENTER" | "PROVIDER_NORDECA" | "PROVIDER_AFRIMAPPING" | "PROVIDER_OVERDRIVE" | "PROVIDER_PROVIDER_NETWORK_DIRECTORIES" | "PROVIDER_BR_MINISTERIO_DA_SAUDE" | "PROVIDER_DIGITAL_EGYPT" | "PROVIDER_INRIX" | "PROVIDER_ARPINDO" | "PROVIDER_IT_GOVERNMENT" | "PROVIDER_ISTITUTO_GEOGRAFICO_MILITARE" | "PROVIDER_EAST_END_GROUP" | "PROVIDER_INGEOLAN" | "PROVIDER_SEMACONNECT" | "PROVIDER_BLINK" | "PROVIDER_EVGO" | "PROVIDER_CHARGEPOINT" | "PROVIDER_TPL_TRAKKER" | "PROVIDER_OI" | "PROVIDER_MAPARADAR" | "PROVIDER_SINGAPORE_POST" | "PROVIDER_CHARGEMASTER" | "PROVIDER_TESLA" | "PROVIDER_VISICOM" | "PROVIDER_GEOLYSIS" | "PROVIDER_ZEPHEIRA" | "PROVIDER_HUBJECT" | "PROVIDER_PODPOINT" | "PROVIDER_CHARGEFOX" | "PROVIDER_KR_GOVERNMENT" | "PROVIDER_KR_MOLIT" | "PROVIDER_KR_MINISTRY_OF_THE_INTERIOR_AND_SAFETY" | "PROVIDER_CRITCHLOW" | "PROVIDER_EIFRIG" | "PROVIDER_GIREVE" | "PROVIDER_CN_NAVINFO" | "PROVIDER_JAPAN_CHARGE_NETWORK" | "PROVIDER_NOBIL" | "PROVIDER_INDIA_BANKS" | "PROVIDER_INDONESIA_ELECTION_KPU" | "PROVIDER_CAREERS360" | "PROVIDER_SOURCE_LONDON" | "PROVIDER_EVBOX" | "PROVIDER_JP_GOVERNMENT" | "PROVIDER_JP_MINISTRY_OF_THE_ENVIRONMENT" | "PROVIDER_YUMYUM" | "PROVIDER_HWW_AUSTRALIA" | "PROVIDER_CINERGY" | "PROVIDER_MTIME" | "PROVIDER_KULTUNAUT" | "PROVIDER_BLITZ" | "PROVIDER_PIA" | "PROVIDER_INTERPARK" | "PROVIDER_CINEMA_ONLINE" | "PROVIDER_BELBIOS" | "PROVIDER_MOVIESEER" | "PROVIDER_SODAMEDYA" | "PROVIDER_ATMOVIES" | "PROVIDER_HOTELBEDS" | "PROVIDER_VERICRED" | "PROVIDER_CIRRANTIC" | "PROVIDER_GOGO_LABS" | "PROVIDER_ELECTRIFY_AMERICA" | "PROVIDER_CMS_MPPUF" | "PROVIDER_DIGIROAD" | "PROVIDER_KONTEX_GEOMATICS" | "PROVIDER_NZ_GOVERNMENT" | "PROVIDER_NZ_LINZ" | "PROVIDER_NZ_DOC" | "PROVIDER_FASTNED" | "PROVIDER_DESTINY_CS" | "PROVIDER_IONITY" | "PROVIDER_EV_CONNECT" | "PROVIDER_PANPAGES" | "PROVIDER_ETECNIC" | "PROVIDER_VOLTA" | "PROVIDER_NISSAN_MEXICO" | "PROVIDER_BMW_GROUP_LATIN_AMERICA" | "PROVIDER_FEDERAL_ELECTRICITY_COMMISSION_MEXICO" | "PROVIDER_VOLVO_CARS_BRASIL" | "PROVIDER_CHARGE_AND_PARKING" | "PROVIDER_DEDUCE_TECHNOLOGIES" | "PROVIDER_SK_TELECOM" | "PROVIDER_ECO_MOVEMENT" | "PROVIDER_GOOGLE_GMS" | "PROVIDER_EASYWAY" | "PROVIDER_PHYSICIAN_COMPARE" | "PROVIDER_HOSPITAL_COMPARE" | "PROVIDER_ENDOLLA_BARCELONA" | "PROVIDER_BE_CHARGE" | "PROVIDER_ONE_NETWORK" | "PROVIDER_CARENAV_DUPLEX" | "PROVIDER_CARENAV_POI" | "PROVIDER_IN_GOVERNMENT" | "PROVIDER_SURVEY_OF_INDIA" | "PROVIDER_E_ON" | "PROVIDER_ELECTRIFY_CANADA" | "PROVIDER_GRIDCARS" | "PROVIDER_DRIVECO" | "PROVIDER_GREEN_ACTION_STUDIOS" | "PROVIDER_GREEN_ACTION_STUDIO" | "PROVIDER_EVINY" | "PROVIDER_MASTERCARD" | "PROVIDER_VATTENFALL" | "PROVIDER_VIETGIS" | "PROVIDER_UNITE" | "PROVIDER_NEOGY" | "PROVIDER_AMPUP" | "PROVIDER_LOOP" | "PROVIDER_ZEST" | "PROVIDER_EZVOLT";
}

/**
 * Our TYPE_INTERSECTION features model the point where one or more segments
 * terminate. This is topological definition: it may not match what a typical
 * user would think of as an "intersection". Consider the intersections where
 * Hayes, Market, Larkin, and 9th Street meet near (37.77765, -122.41638) in San
 * Francisco. Most people would probably consider this a single feature, even
 * though we model it as four separate TYPE_INTERSECTION features. The
 * TYPE_INTERSECTION_GROUP is used to model the user's concept of a real-world
 * intersection, which also includes turn lanes or a whole roundabout (a logical
 * intersection). For the purposes of modeling turn restrictions and lane
 * connections, a smaller grouping is needed to model the "core" part of the
 * intersection where there are no lane markings. This is called a core or
 * artifact group. An intersection group must contain at least two intersections
 * or add some information (e.g. a name or a polygon) compared to the
 * intersection itself, or else must not exist. The standard feature properties
 * are interpreted as follows: name - Can be used to specify any "special" names
 * associated with this intersection (e.g. Reads Corner intersection, PEI,
 * Canada). Intersections that are named according to their cross streets do not
 * need to specify this field, since this can be determined by looking at the
 * routes associated with each segment. address - This should always be empty.
 * point - Specifies the center of the intersection. This is basically the point
 * where the intersection name should be rendered. Can be omitted in favor of a
 * polygon. polyline - This should always be empty. polygon - Specifies the
 * two-dimensional extent of the intersection. This may substitute to the point
 * field, though having a center set is desirable in this case. child - This
 * should always be empty.
 */
export interface GeostoreIntersectionGroupProto {
  /**
   * All artifact intersection groups that are in this logical group.
   */
  childGroup?: GeostoreFeatureIdProto[];
  groupType?:  | "GROUP_ARTIFACT" | "GROUP_LOGICAL";
  /**
   * The list of TYPE_INTERSECTION features that form this intersection group,
   * but are NOT in any of this group's child groups. This could be an empty
   * list, though that is sub-optimal. Even an empty list would allow the paint
   * team to draw a label for a named intersection, but a non-empty list would,
   * for example, enable PathFinder to generate better directions. Each of the
   * TYPE_INTERSECTION feature referred here must refer back to this feature in
   * its IntersectionProto.
   */
  intersection?: GeostoreFeatureIdProto[];
  /**
   * Parent logical intersection group. An artifact group that does not have an
   * associated parent logical group is assumed to be both an artifact and
   * logical group.
   */
  parentGroup?: GeostoreFeatureIdProto;
}

function serializeGeostoreIntersectionGroupProto(data: any): GeostoreIntersectionGroupProto {
  return {
    ...data,
    childGroup: data["childGroup"] !== undefined ? data["childGroup"].map((item: any) => (serializeGeostoreFeatureIdProto(item))) : undefined,
    intersection: data["intersection"] !== undefined ? data["intersection"].map((item: any) => (serializeGeostoreFeatureIdProto(item))) : undefined,
    parentGroup: data["parentGroup"] !== undefined ? serializeGeostoreFeatureIdProto(data["parentGroup"]) : undefined,
  };
}

function deserializeGeostoreIntersectionGroupProto(data: any): GeostoreIntersectionGroupProto {
  return {
    ...data,
    childGroup: data["childGroup"] !== undefined ? data["childGroup"].map((item: any) => (deserializeGeostoreFeatureIdProto(item))) : undefined,
    intersection: data["intersection"] !== undefined ? data["intersection"].map((item: any) => (deserializeGeostoreFeatureIdProto(item))) : undefined,
    parentGroup: data["parentGroup"] !== undefined ? deserializeGeostoreFeatureIdProto(data["parentGroup"]) : undefined,
  };
}

/**
 * A TYPE_INTERSECTION feature represents a common endpoint of one or more
 * segments in a transportation network at which the segments are connected. An
 * intersection in the real world may be more complicated than that (e.g.,
 * comprise multiple segment endpoints or have extra attributes), which can be
 * modeled with an additional TYPE_INTERSECTION_GROUP feature, if needed (see
 * intersectiongroup.proto). The standard feature properties are interpreted as
 * follows: name - This should always be empty. Intersections that have a
 * "special" name (e.g. Reads Corner intersection, PEI, Canada) should point to
 * a separate TYPE_INTERSECTION_GROUP feature that captures it. Intersections
 * which are named according to their cross streets do not need this
 * requirement, since their name can be determined by looking at the routes
 * associated with each segment. address - This should always be empty. point -
 * Specifies the center of the intersection. This should be the last vertex of
 * all the segments which terminate at this intersection. polyline - This should
 * always be empty. polygon - This should always be empty. child - This should
 * always be empty.
 */
export interface GeostoreIntersectionProto {
  /**
   * The artifact or logical intersection group to which this intersection
   * belongs. If present, the intersection group must also refer back to the
   * intersection. If an intersection is within both the artifact and logical
   * group, then this reference should be to the artifact group.
   */
  intersectionGroup?: GeostoreFeatureIdProto;
  /**
   * RESERVED
   */
  outSegment?: GeostoreFeatureIdProto[];
  /**
   * The list of segments that terminate at this intersection, in any order.
   * Note that all segments are directed towards the intersection, i.e. their
   * endpoints indicate what sort of intersection this is. This should not be
   * empty because an intersection with no associated segment is meaningless.
   */
  segment?: GeostoreFeatureIdProto[];
  /**
   * The toll cluster to which this intersection belongs. If present, the toll
   * cluster must also refer back to the intersection.
   */
  tollClusterId?: GeostoreFeatureIdProto;
}

function serializeGeostoreIntersectionProto(data: any): GeostoreIntersectionProto {
  return {
    ...data,
    intersectionGroup: data["intersectionGroup"] !== undefined ? serializeGeostoreFeatureIdProto(data["intersectionGroup"]) : undefined,
    outSegment: data["outSegment"] !== undefined ? data["outSegment"].map((item: any) => (serializeGeostoreFeatureIdProto(item))) : undefined,
    segment: data["segment"] !== undefined ? data["segment"].map((item: any) => (serializeGeostoreFeatureIdProto(item))) : undefined,
    tollClusterId: data["tollClusterId"] !== undefined ? serializeGeostoreFeatureIdProto(data["tollClusterId"]) : undefined,
  };
}

function deserializeGeostoreIntersectionProto(data: any): GeostoreIntersectionProto {
  return {
    ...data,
    intersectionGroup: data["intersectionGroup"] !== undefined ? deserializeGeostoreFeatureIdProto(data["intersectionGroup"]) : undefined,
    outSegment: data["outSegment"] !== undefined ? data["outSegment"].map((item: any) => (deserializeGeostoreFeatureIdProto(item))) : undefined,
    segment: data["segment"] !== undefined ? data["segment"].map((item: any) => (deserializeGeostoreFeatureIdProto(item))) : undefined,
    tollClusterId: data["tollClusterId"] !== undefined ? deserializeGeostoreFeatureIdProto(data["tollClusterId"]) : undefined,
  };
}

export interface GeostoreJobMetadata {
  /**
   * Describes how much time the service is going to take, e.g. how long it
   * takes to do a haircut. Value of seconds must be from +60 (1 min) to
   * +31,536,000 (365 days) inclusive. Value of nanos must be zero.
   */
  duration?: number /* Duration */;
  /**
   * Represents the name of a potential grouping of items. For TYPE_JOB, this
   * is the category names of the categories that a user picked this job type
   * from at the time of input.
   */
  jobRelatedCategories?: GeostoreJobRelatedCategory[];
  /**
   * Unique identifier for a job. This is required for standard jobs and blank
   * for free-form jobs. Job type ids are prefixed with "job_type_id:". Notice
   * this is a unique string representation of a job across languages. E.g.,
   * job_type_id:air_duct_repair. The existence of a job_type_id means the job
   * type is a standard one, and has a corresponding entry in the Standard Jobs
   * Taxonomy.
   */
  jobTypeId?: string;
  /**
   * Represents the MID corresponding to the job_category entity in the
   * Knowledge Graph. For example, job_type_id="job_type_id:install_faucet",
   * job_type_mid="/g/11hzzxjv3f".
   */
  jobTypeMid?: string;
}

function serializeGeostoreJobMetadata(data: any): GeostoreJobMetadata {
  return {
    ...data,
    duration: data["duration"] !== undefined ? data["duration"] : undefined,
  };
}

function deserializeGeostoreJobMetadata(data: any): GeostoreJobMetadata {
  return {
    ...data,
    duration: data["duration"] !== undefined ? data["duration"] : undefined,
  };
}

/**
 * This is the category that a user picked this job type from at the time of
 * input. The field serves two purposes: 1) The name is used in consumer surface
 * similar to the heading name today (i.e., grouping jobs under the category. 2)
 * The gcid is needed mainly for free-formed entries, for which GMB needs to map
 * them to corresponding categories in the frontend, if applicable. Notice that
 * the name and the id are both not expected to be in sync with gcid deprecation
 * or location category change per product decision. In other words, they are
 * not guaranteed to stay in sync, only guaranteed true at time of creation.
 */
export interface GeostoreJobRelatedCategory {
  gcid?: string;
  language?: string;
  /**
   * Category name in the primary language of the feature. Generally intended
   * to be used as a fallback when we are unable to fetch the name in the user's
   * language.
   */
  name?: string;
}

/**
 * The reference to an entity in the KnowledgeGraph. For details on the
 * KnowledgeGraph see http://goto/kg.
 */
export interface GeostoreKnowledgeGraphReferenceProto {
  /**
   * KG Identifier (MID). For details, see
   * http://go/ke-bg-knowledge-graph#mids.
   */
  id?: string;
}

/**
 * This protocol buffer represents the association between a segment and a
 * landmark feature. Notes: - References to TYPE_SEGMENT features should always
 * point to the even sibling. - Self-references are allowed but the referencing
 * segment's sibling is required to have a self-reference as well (the above
 * requirement to always reference the even sibling still applies).
 */
export interface GeostoreLandmarkReferenceProto {
  /**
   * The type of the landmark feature. Allowed types: - TYPE_CARTOGRAPHIC e.g.
   * a putting green or water hazard - TYPE_COMPOUND e.g. - the Empire state
   * building (TYPE_COMPOUND_BUILDING) - a park (TYPE_COMPOUND_GROUNDS) - a
   * section of a retail store (TYPE_COMPOUND_SECTION) - TYPE_ESTABLISHMENT e.g.
   * - the Eiffel Tower (TYPE_ESTABLISHMENT_BUILDING) - a sports field
   * (TYPE_ESTABLISHMENT_GROUNDS) - Starbucks (TYPE_ESTABLISHMENT_POI) -
   * TYPE_INTERSECTION_GROUP e.g. a major intersection - TYPE_NATURAL_FEATURE
   * e.g. a river - TYPE_SEGMENT e.g. a bike trail or train tracks
   */
  featureType?: number;
  /**
   * The feature ID of the landmark feature.
   */
  landmark?: GeostoreFeatureIdProto;
  /**
   * The mode(s) of travel for which this landmark is useful.
   */
  travelMode?:  | "UNKNOWN" | "TRAVEL_MOTOR_VEHICLE" | "TRAVEL_AUTO" | "TRAVEL_TWO_WHEELER" | "TRAVEL_BICYCLE" | "TRAVEL_PEDESTRIAN"[];
}

function serializeGeostoreLandmarkReferenceProto(data: any): GeostoreLandmarkReferenceProto {
  return {
    ...data,
    landmark: data["landmark"] !== undefined ? serializeGeostoreFeatureIdProto(data["landmark"]) : undefined,
  };
}

function deserializeGeostoreLandmarkReferenceProto(data: any): GeostoreLandmarkReferenceProto {
  return {
    ...data,
    landmark: data["landmark"] !== undefined ? deserializeGeostoreFeatureIdProto(data["landmark"]) : undefined,
  };
}

/**
 * This proto contains attributes relevant to physical lane markers.
 */
export interface GeostoreLaneMarkerProto {
  /**
   * If this is a physical barrier marker, represent materials found on the
   * marker.
   */
  barrierMaterials?: GeostoreBarrierLogicalMaterialProto;
  /**
   * Pattern border and color for crossing markers. These include crosswalks,
   * stop, and yield lines.
   */
  crossingPattern?: GeostoreCrossingStripePatternProto;
  /**
   * Stripe pattern, spacing, and color for longitudinal markers.
   */
  linearPattern?: GeostoreLinearStripePatternProto;
}

/**
 * Describes an individual road lane. Not only driving lanes, but also parking
 * and biking lanes are covered by this. Note that we may eventually add curbs
 * and walking to this schema. MOTIVATION/DESIGN DISCUSSION The intent of this
 * schema is to model a schematic representation of the road for a bunch of use
 * cases within GMM, navigation, map tiles. For rendering, we do not want to
 * represent the geometry of each lane exactly, but do want to model
 * types/width/gaps/lane markings so that a schematic rendering can be made. For
 * navigation, we model lane connectivity and restrictions per lane, so that
 * Pathfinder can potentially pick routes based on lanes, and definitely use the
 * lanes to better describe the path to the driver. This schema is driven by the
 * GT team, which is likely to be the only provider of this data. It is based on
 * compromises that we are working out with other teams, based on what our
 * operators can reasonably collect and what is useful. See docs here:
 * https://docs.google.com/a/google.com/document/d/11XJ1WvqS5Sm7MxWXzzc3tnsk49VhrR3BYFjiRMAzYm0/edit?hl=en_US
 * https://docs.google.com/a/google.com/document/d/1nzdupynTUKE8xY8JcfvQbU-KWtCJ6IwHiTaCxuq40EM/edit?hl=en_US
 * Note: Some lane information (width, surface type, etc) may duplicate or
 * contradict information stored at the segment level.
 */
export interface GeostoreLaneProto {
  /**
   * References to any gcid:physical_lane_marker features that bound this lane.
   */
  boundingMarker?: GeostoreBoundingMarkerProto[];
  /**
   * If the current lane is part of a merge/split area, indicates the type
   * (split or merge) and whether the current lane is on the left or right or in
   * the middle of the merge/split area, as seen in the direction of traffic.
   * See go/lane-split-merge-schema
   */
  conjoinedCategory?:  | "CONJOINED_NONE" | "CONJOINED_SPLIT_LEFT" | "CONJOINED_SPLIT_MIDDLE" | "CONJOINED_SPLIT_RIGHT" | "CONJOINED_MERGE_LEFT" | "CONJOINED_MERGE_MIDDLE" | "CONJOINED_MERGE_RIGHT";
  /**
   * Gap between this lane and the next in meters. This is relevant when the
   * divider is physical, or a wide painted area. For regular painted single or
   * double lines, there is no gap. This distance is duplicated between the
   * innermost lanes for each side. Note that this is not used to describe
   * smallish islands - this is only for long-running gaps. In particular, this
   * models the median width, the gap between HOV lanes/regular lanes on
   * freeways, and the road verge between a curb and sidewalk. Note on split
   * roads: We can model any split road with a median as a single sibling pair
   * with this distance set to the width of the median, or as two one-way
   * sibling pairs.
   */
  distanceToNextLane?: number;
  /**
   * The most logical path for the center of an object to travel along within
   * the lane. Typically, this is the lane's center line, but doesn't have to
   * be.
   */
  flow?: GeostoreFlowLineProto;
  /**
   * Connections to lanes of other segments at the end of this segment. These
   * connections model the connectivity where you don't have to do a lane change
   * maneuver. If any lane connection is present, assume that all others are
   * forbidden. Also note that segment level restrictions do apply if present,
   * and can disallow some turn even if the lanes are connected. For instance,
   * this can happen with timed or vehicle type based restrictions on the
   * segment. If lane connectivity implies a segment-level restriction (can't
   * transition to some target segment), that restriction will also exist as a
   * segment level restriction. In effect - PathFinder does not have to look at
   * lane connectivity to figure out segment connectivity. Example: Typically,
   * lanes are just connected to one other lane. Example: A splitting lane is
   * connected to the two resulting lanes. Example: At an intersection, a lane
   * is connected to crossing lanes according to how lanes are painted across
   * the intersection. In the common case, the target segment will be connected
   * to the same intersection as this segment. That will however NOT be true for
   * complex intersections where there is an intersection group. The connections
   * will be across the whole group, connecting to one of the outgoing segments
   * from the group. This is analogous to how we do turn restrictions around
   * intersection groups.
   */
  laneConnection?: GeostoreLaneProtoLaneConnection[];
  /**
   * clang-format on Whether the divider to the inside of this lane can be
   * crossed. Note that we assume this is symmetric, and that this also
   * describes whether someone in the next inside lane can cross to this one.
   * The "inside" lane is the one with a lower lane_number. Note on lane
   * markers: We do not model the painting, but only the resulting legality.
   * There are many painted marker styles and colors that lead to the same
   * legality. We expect Paint or Driveabout to render lanes stylized, with
   * solid meaning "can't cross", and dashed meaning "can cross". Note on
   * varying legality along segment: ALLOWED takes precedence - even if some
   * small portion has a restriction (such as right before an intersection) ,
   * the lane change will be ALLOWED.
   */
  laneDividerCrossing?:  | "CROSSING_ALLOWED" | "CROSSING_DISALLOWED" | "CROSSING_LEGALLY_DISALLOWED" | "CROSSING_PHYSICALLY_IMPOSSIBLE";
  /**
   * These indicate for what portion of the segment the lane's flowline exactly
   * follows the segment, and the lane is of constant width. This will be set to
   * not include the whole segment where there is a split/turn/merge at either
   * end of the lane. The painting of the lane should completely synthesize the
   * lane geometry outside of this portion, connecting it to neighboring lanes
   * to make graphical nice.
   */
  laneFollowsSegmentBeginFraction?: number;
  laneFollowsSegmentEndFraction?: number;
  /**
   * Lanes are numbered from inside of the road outward, i.e. the lane next to
   * the center line is lane 0. The lanes then stack outwards, towards the side
   * that one drives on this segment (right or left). NOTE: do NOT use the
   * lane_number as index for lookup. Lane_number is not guaranteed to match the
   * segment.lane repeated field index.
   */
  laneNumber?: number;
  /**
   * A token that can be used to identify the version of the data about this
   * lane.
   */
  laneToken?: string;
  /**
   * Field-level metadata for this lane.
   */
  metadata?: GeostoreFieldMetadataProto;
  /**
   * Restrictions that apply to this lane only. Examples include HOV lanes. If
   * a lane restriction implies a segment-level restriction (can't route on the
   * segment at all), that restriction will also exist as a segment level
   * restriction. In effect - PathFinder does not have to look at lane
   * restrictions to figure out segment restrictions.
   */
  restriction?: GeostoreRestrictionProto[];
  /**
   * True if this lane is usable in both directions (left-turn lane, reversing
   * lane, one-lane road, etc). To get the total number of lanes for a road, add
   * up the lanes in each direction counting 0.5 for each shared lane.
   */
  shared?: boolean;
  /**
   * References to any gcid:physical_lane_marker features that intersect this
   * lane, with the implication that a moving vehicle should stop there.
   */
  stopLine?: GeostoreFeatureIdProto[];
  /**
   * clang-format on
   * LINT.ThenChange(//depot/google3/geostore/base/proto/segment.proto) Unlike
   * the surface in SegmentProto, this field does not have a default value. This
   * is because the lane-level surface overrides the segment-level surface. The
   * lane's surface should be unset unless explicitly overriding the segment's
   * surface.
   */
  surface?:  | "SURFACE_UNKNOWN" | "SURFACE_PAVED" | "SURFACE_ASPHALT" | "SURFACE_CONCRETE" | "SURFACE_CHIPSEAL" | "SURFACE_BRICK" | "SURFACE_SETT" | "SURFACE_COBBLESTONE" | "SURFACE_UNPAVED" | "SURFACE_GRAVEL" | "SURFACE_DIRT" | "SURFACE_SAND";
  /**
   * clang-format on
   */
  type?:  | "TYPE_UNKNOWN" | "TYPE_NORMAL" | "TYPE_PASSING" | "TYPE_LEFT_TURN" | "TYPE_LEFT_TURN_OFF" | "TYPE_LEFT_TURN_ON_OFF" | "TYPE_RIGHT_TURN" | "TYPE_RIGHT_TURN_OFF" | "TYPE_RIGHT_TURN_ON_OFF" | "TYPE_BICYCLE" | "TYPE_PARKING" | "TYPE_PARKING_IMPLIED" | "TYPE_PARKING_MARKED" | "TYPE_EXIT_ENTRANCE" | "TYPE_EXIT_LANE" | "TYPE_ENTRANCE_LANE" | "TYPE_PEDESTRIAN" | "TYPE_SIDEWALK_SHOULDER" | "TYPE_VEHICLE_SHOULDER" | "TYPE_OFFSET";
  /**
   * Width of this lane in meters. In many cases, we will collect this data by
   * dividing the total road width by the number of lanes. On accuracy: This is
   * a rough average width along this segment. If and when we wanted to be more
   * accurate, we'd extend this schema to have full polygons for segments/lanes
   * rather than just this average width.
   */
  width?: number;
}

function serializeGeostoreLaneProto(data: any): GeostoreLaneProto {
  return {
    ...data,
    boundingMarker: data["boundingMarker"] !== undefined ? data["boundingMarker"].map((item: any) => (serializeGeostoreBoundingMarkerProto(item))) : undefined,
    laneConnection: data["laneConnection"] !== undefined ? data["laneConnection"].map((item: any) => (serializeGeostoreLaneProtoLaneConnection(item))) : undefined,
    restriction: data["restriction"] !== undefined ? data["restriction"].map((item: any) => (serializeGeostoreRestrictionProto(item))) : undefined,
    stopLine: data["stopLine"] !== undefined ? data["stopLine"].map((item: any) => (serializeGeostoreFeatureIdProto(item))) : undefined,
  };
}

function deserializeGeostoreLaneProto(data: any): GeostoreLaneProto {
  return {
    ...data,
    boundingMarker: data["boundingMarker"] !== undefined ? data["boundingMarker"].map((item: any) => (deserializeGeostoreBoundingMarkerProto(item))) : undefined,
    laneConnection: data["laneConnection"] !== undefined ? data["laneConnection"].map((item: any) => (deserializeGeostoreLaneProtoLaneConnection(item))) : undefined,
    restriction: data["restriction"] !== undefined ? data["restriction"].map((item: any) => (deserializeGeostoreRestrictionProto(item))) : undefined,
    stopLine: data["stopLine"] !== undefined ? data["stopLine"].map((item: any) => (deserializeGeostoreFeatureIdProto(item))) : undefined,
  };
}

export interface GeostoreLaneProtoLaneConnection {
  /**
   * References to any gcid:physical_lane_marker features that bound this lane
   * connection.
   */
  boundingMarker?: GeostoreBoundingMarkerProto[];
  /**
   * A token that can be used to identify the version of the data about this
   * lane connection.
   */
  connectionToken?: string;
  /**
   * Specifies how the flowline should be synthesized in this connection
   * region. If unspecified, heuristics may be used to pick a sweep shape based
   * on retraction values or neighboring curves.
   */
  curve?: GeostoreCurveConnectionProto;
  /**
   * The most logical path for the center of an object to travel along within
   * the lane connection. Typically, this is the lane connection's center line,
   * but doesn't have to be.
   */
  flow?: GeostoreFlowLineProto;
  /**
   * This is the lane number on the target segment. This field is not set if
   * the target segment doesn't have lanes, or we don't know the exact
   * connectivity.
   */
  laneNumber?: number;
  /**
   * True if this connects to the unique, natural continuation of the current
   * lane. At most one LaneConnection per lane can have this field set true.
   * This attribute is of interest to ADAS providers as a hint to which lane a
   * vehicle is likely to follow, in the absence of other information about the
   * vehicle's planned path.
   */
  primaryConnection?: boolean;
  /**
   * This reference to the other segment is weak, since strong would blow up
   * bounds of all segments.
   */
  segment?: GeostoreFeatureIdProto;
}

function serializeGeostoreLaneProtoLaneConnection(data: any): GeostoreLaneProtoLaneConnection {
  return {
    ...data,
    boundingMarker: data["boundingMarker"] !== undefined ? data["boundingMarker"].map((item: any) => (serializeGeostoreBoundingMarkerProto(item))) : undefined,
    segment: data["segment"] !== undefined ? serializeGeostoreFeatureIdProto(data["segment"]) : undefined,
  };
}

function deserializeGeostoreLaneProtoLaneConnection(data: any): GeostoreLaneProtoLaneConnection {
  return {
    ...data,
    boundingMarker: data["boundingMarker"] !== undefined ? data["boundingMarker"].map((item: any) => (deserializeGeostoreBoundingMarkerProto(item))) : undefined,
    segment: data["segment"] !== undefined ? deserializeGeostoreFeatureIdProto(data["segment"]) : undefined,
  };
}

/**
 * Represents a piece of text with an associated language.
 */
export interface GeostoreLanguageTaggedTextProto {
  /**
   * The external form of a Google International Identifiers Initiative (III)
   * LanguageCode object. See google3/i18n/identifiers/languagecode.h for
   * details. We place extra restrictions on languages in addition to what the
   * III library requires. See
   * http://go/geo-schema-reference/feature-properties/languages.md
   */
  language?: string;
  /**
   * The text (UTF-8 encoding).
   */
  text?: string;
}

/**
 * A feature used to represent a logical level, e.g. floor. A feature belonging
 * to a given level should point to the level feature using relation
 * RELATION_ON_LEVEL. The standard feature properties are interpreted as
 * follows: name - Levels should have names according to the following: * Short,
 * elevator-style names, such as "L" for "Lobby" and "2" for "Second floor",
 * must be included and must be tagged with FLAG_ABBREVIATED. There must be an
 * unambiguous "best" abbreviated name. * Longer names such as "Ticketing" or
 * "Upper Level" may be present when the level has a specific name. *
 * Non-abbreviated names should only be added if they are known to meaningfully
 * expand upon the abbreviated name. For example, the long name "Observation
 * Deck 2" for the abbreviated name "OD2" is a good additional name. In
 * contrast, the name "Level 2" for the abbreviated name "2" is not desired.
 * address - This should always be empty. point, polyline, polygon, center -
 * These should never be set (since we are representing a logical entity).
 * preferred_viewport - This should be the approximate extent of the level.
 * child - This should always be empty.
 */
export interface GeostoreLevelProto {
  /**
   * The building(s) to which this level belongs. A level will typically belong
   * to a single building, but it is valid for a single level to be shared by
   * multiple buildings (for example, a large underground parking lot). These
   * buildings refer back to the level via another strong reference (the
   * BuildingProto.level field).
   */
  building?: GeostoreFeatureIdProto[];
  /**
   * The elevation of this level relative to the ground level, in levels. 0 =
   * ground floor (even in locales that call the ground floor "1st floor"); 0.5
   * = between ground and first floor, eg mezzanine; 1 = first floor (one level
   * above ground floor); -3 = three levels below ground floor.
   */
  number?: number;
}

function serializeGeostoreLevelProto(data: any): GeostoreLevelProto {
  return {
    ...data,
    building: data["building"] !== undefined ? data["building"].map((item: any) => (serializeGeostoreFeatureIdProto(item))) : undefined,
  };
}

function deserializeGeostoreLevelProto(data: any): GeostoreLevelProto {
  return {
    ...data,
    building: data["building"] !== undefined ? data["building"].map((item: any) => (deserializeGeostoreFeatureIdProto(item))) : undefined,
  };
}

export interface GeostoreLinearStripePatternProto {
  /**
   * A linear marker may consist of one or more parallel physical lines. These
   * are ordered left to right along the direction of the marker core polyline.
   */
  line?: GeostorePhysicalLineProto[];
}

/**
 * This message describes the details of a single language within a locale.
 */
export interface GeostoreLocaleLanguageProto {
  /**
   * The language associated with this preference. The external form of a
   * Google International Identifiers Initiative (III) LanguageCode object. See
   * google3/i18n/identifiers/languagecode.h for details. We place extra
   * restrictions on languages in addition to what the III library requires. See
   * http://go/geo-schema-reference/feature-properties/languages.md
   */
  language?: string;
  /**
   * Flag to indicate if the associated language is "official" within a locale.
   */
  official?: boolean;
  /**
   * This value represents the preference of the associated language within a
   * locale. It must be between 0.0 and 1.0.
   */
  preference?: number;
  /**
   * Percentage of population that can speak the associated language within a
   * locale. It must be between 0 and 100.
   */
  speakingPercent?: number;
  /**
   * Percentage of population that can write the associated language within a
   * locale. It must be between 0 and 100.
   */
  writingPercent?: number;
}

/**
 * A locale is a meta-feature that describes the geographic extent of
 * localization preferences such as the local language, and formatting
 * conventions for numbers, dates and monetary values. Multilingual areas may be
 * contained by multiple locales. We try to model locales fine-grained enough
 * for deciding which languages are typically used within a city. For example,
 * while French is an official language for all of Switzerland, we would prefer
 * to have Zurich contained by a separate (more fine-grained) Swiss-German
 * locale indicating that German, not French, is the predominantly spoken
 * language in this city. Note that language borders are frequently considered a
 * political question and often don't have clearly defined extents. For example,
 * California has a significant Spanish-speaking population, but Spanish is not
 * an official language of California.
 */
export interface GeostoreLocaleProto {
  /**
   * This holds the list of languages spoken within a locale.
   */
  language?: GeostoreLocaleLanguageProto[];
  /**
   * The ID of the localization policy (from
   * googledata/geostore/localization/localization_policies.textpb) to apply to
   * features that have this locale as their best match locale. Localization
   * policy IDs are arbitrary identifiers that uniquely distinguish a set of
   * language-selection rules.
   */
  localizationPolicyId?: string;
}

/**
 * A logical border is a grouping of border features, which together model a
 * divide between two regions. The borders within this grouping share common
 * attributes, such as the regions they divide, and may represent a conceptual
 * group of borders, of which may be wholly disputed, wholly undisputed, or a
 * mixture of disputed and undisputed. Note that any borders within this group
 * may be part of multiple logical borders. A logical border is required to have
 * a name describing what the grouping represents (e.g. "US - Mexico Border",
 * "Kosovo - Serbia Border (Disputed)").
 */
export interface GeostoreLogicalBorderProto {
  /**
   * All the border segments which make up this logical border. Border segments
   * must be TYPE_BORDER features which have the same left/right features. This
   * is a many-to-many bidirectional relationship, so any border segment within
   * this list might be part of another logical border.
   */
  borderSegment?: GeostoreFeatureIdProto[];
  /**
   * The logical border status identifies its legal status. This is similar to
   * the BorderStatus present within border segments, but applies to the group
   * as a whole.
   */
  status?:  | "STATUS_UNSPECIFIED" | "STATUS_NORMAL" | "STATUS_DISPUTED";
}

function serializeGeostoreLogicalBorderProto(data: any): GeostoreLogicalBorderProto {
  return {
    ...data,
    borderSegment: data["borderSegment"] !== undefined ? data["borderSegment"].map((item: any) => (serializeGeostoreFeatureIdProto(item))) : undefined,
  };
}

function deserializeGeostoreLogicalBorderProto(data: any): GeostoreLogicalBorderProto {
  return {
    ...data,
    borderSegment: data["borderSegment"] !== undefined ? data["borderSegment"].map((item: any) => (deserializeGeostoreFeatureIdProto(item))) : undefined,
  };
}

/**
 * Media item attached to an element of price list.
 */
export interface GeostoreMediaItemProto {
  /**
   * The FIFE url associated with the media. NOTE: This FIFE URL must be
   * PII-free, see go/product-catalogue-photo-storage
   */
  googleUrl?: string;
  mediaFormat?:  | "MEDIA_FORMAT_UNSPECIFIED" | "MEDIA_FORMAT_PHOTO";
  /**
   * The mediaKey associated with the media. NOTE: This media key must be
   * PII-free, see go/product-catalogue-photo-storage
   */
  mediaKey?: string;
  mediaSize?: GeostoreMediaItemProtoMediaSize;
}

/**
 * Width and height of the original photo in pixels.
 */
export interface GeostoreMediaItemProtoMediaSize {
  originalHeightPx?: number;
  originalWidthPx?: number;
}

/**
 * A name for a Feature (street name, point of interest, city, building, etc).
 * We currently use NameProto for two essentially disjoint purposes: 1. Common
 * names, which can be language-specific, or have other kinds of variations. 2.
 * Opaque IDs, such as postal codes, which only have the `text` field set, and
 * potentially some flags. This includes internal-only features like template
 * ids. Each NameProto representing a common name corresponds to an assertion
 * that a fluent speaker or writer of a language would recognize NameProto.text
 * to name the given feature in that language. As such, NameProtos are stored in
 * a repeated field, often having: 1. multiple names with the same text and
 * varying languages, and 2. multiple names with the same language and varying
 * texts.
 */
export interface GeostoreNameProto {
  /**
   * clang-format on The set of flags that apply to this name.
   */
  flag?:  | "FLAG_ANY" | "FLAG_IN_LOCAL_LANGUAGE" | "FLAG_PREFERRED" | "FLAG_OFFICIAL" | "FLAG_OBSCURE" | "FLAG_ON_SIGNS" | "FLAG_EXIT_NAME_NUMBER" | "FLAG_EXIT_NAME" | "FLAG_INTERCHANGE_NAME" | "FLAG_EXIT_NUMBER" | "FLAG_INTERCHANGE_NUMBER" | "FLAG_TRANSIT_HEADSIGN" | "FLAG_CONNECTS_DIRECTLY" | "FLAG_CONNECTS_INDIRECTLY" | "FLAG_INTERSECTION_NAME" | "FLAG_VANITY" | "FLAG_ROUTE_NUMBER" | "FLAG_COUNTRY_CODE_2" | "FLAG_ABBREVIATED" | "FLAG_ID" | "FLAG_DESIGNATED_MARKET_AREA_ID" | "FLAG_IATA_ID" | "FLAG_ICAO_ID" | "FLAG_ISO_3166_2" | "FLAG_COUNTRY_SPECIFIC_ID" | "FLAG_LANGUAGE_CODE" | "FLAG_TIMEZONE_ID" | "FLAG_PHONE_NUMBER_PREFIX" | "FLAG_PHONE_NUMBER_AREA_CODE" | "FLAG_TRANSLITERATED" | "FLAG_NOT_ON_SIGNS" | "FLAG_NOT_IN_LOCAL_LANGUAGE" | "FLAG_ROUNDABOUT_ROUTE" | "FLAG_NEVER_DISPLAY" | "FLAG_BICYCLE_ROUTE" | "FLAG_MACHINE_GENERATED" | "FLAG_SUSPICIOUS"[];
  /**
   * The external form of a Google International Identifiers Initiative (III)
   * LanguageCode object. See google3/i18n/identifiers/languagecode.h for
   * details. These strings should be treated as opaque blobs. You can use
   * LanguageCodeConverter::FromOther to convert the string to a LanguageCode
   * reference. You can then call methods on the LanguageCode class to extract
   * language/script/region subtags (if any). See also
   * http://g3doc/i18n/identifiers/g3doc/using-iii. We place extra restrictions
   * on languages in addition to what the III library requires. See
   * go/geo-schema-reference/feature-properties/languages. This field may be
   * missing if the name does not have a concept of language but should be set
   * if the language is unknown.
   */
  language?: string;
  /**
   * Field-level metadata for this name. NOTE: there are multiple NameProto
   * fields in the Geo Schema. Metadata here is only expected to be present on
   * FeatureProto.name[].
   */
  metadata?: GeostoreFieldMetadataProto;
  /**
   * ** DEPRECATED ** The name text provided in the original source data (UTF-8
   * encoding). This is the text provided in the source data unmodified with the
   * exception of being converted to UTF-8 and stripping extra leading, trailing
   * and duplicate whitespaces (if necessary).
   */
  rawText?: string;
  /**
   * The short name text (UTF-8 encoding). Acronyms/abbreviations should be
   * consistently used, for example "NE 57th St" rather than "Northeast 57th
   * Street", "N.E 57th St." or some other variant. This field should be
   * populated with the chosen canonical version of the shortened name, based on
   * per-term transformations. For feature specific abbreviations (such as 'CA'
   * for 'California'), one should define a separate name with FLAG_ABBREVIATED
   * set. For other variants of the shortened name that are not the canonical
   * one, devise client based logic (ex: query rewriting rules).
   */
  shortText?: string;
  /**
   * A place for clients to attach arbitrary data to a name. Never set in
   * MapFacts.
   */
  temporaryData?: Proto2BridgeMessageSet;
  /**
   * The name text (UTF-8 encoding). Acronyms/abbreviations should be fully
   * expanded, for example "Northeast 57th Street" rather than "NE 57th St".
   * They can be shortened at display or geocode time. This decision prevents
   * ambiguity over such issues as whether "St" represents "Street" or "Saint".
   * However, it pushes language-specific knowledge into code. We will have
   * libraries and data files to contract acronyms/abbreviations at run-time.
   */
  text?: string;
}

/**
 * The container for all GConceptInstances associated with a feature.
 */
export interface GeostoreOntologyRawGConceptInstanceContainerProto {
  instance?: GeostoreOntologyRawGConceptInstanceProto[];
}

/**
 * A RawGConceptInstanceProto contains all data required by both internal and
 * external clients. We store the 'public' data in a GConceptInstanceProto and
 * the 'private' data inside of RawGConceptInstanceProto. NOTE: this doesn't
 * really match the design we want anymore. Please talk to the Geo Schema team
 * if you are planning to make use of the "private" fields below.
 */
export interface GeostoreOntologyRawGConceptInstanceProto {
  /**
   * This is the 'public' section of the GConceptInstance.
   */
  instance?: GeostoreGConceptInstanceProto;
  /**
   * ** DEPRECATED ** Was this GConcept explicitly added by an edit? Examples
   * of gconcepts not added by edits include those inferred through geo ontology
   * and those mapped from legacy category forms by the feature updater. Note
   * that it is possible for both is_added_by_edit and is_inferred to be true -
   * it means this gconcept is added by an edit and there is also another more
   * fine-grained gconcept added by an edit.
   */
  isAddedByEdit?: boolean;
  /**
   * RESERVED
   */
  isInferred?: boolean;
  /**
   * ** DEPRECATED ** These two fields combined describe the source of a
   * GConceptInstance. They are based on
   * geostore/base/proto/datasourceprovider.proto. Their use has been
   * deprecated. Use the FieldMetadataProto inside instance instead.
   */
  provider?:  | "PROVIDER_ANY" | "PROVIDER_UNKNOWN" | "PROVIDER_NAVTEQ" | "PROVIDER_TELE_ATLAS" | "PROVIDER_TELE_ATLAS_MULTINET" | "PROVIDER_TELE_ATLAS_CODEPOINT" | "PROVIDER_TELE_ATLAS_GEOPOST" | "PROVIDER_TELE_ATLAS_DATAGEO" | "PROVIDER_TELE_ATLAS_ADDRESS_POINTS" | "PROVIDER_TELCONTAR" | "PROVIDER_EUROPA" | "PROVIDER_ROYAL_MAIL" | "PROVIDER_GOOGLE" | "PROVIDER_GOOGLE_HAND_EDIT" | "PROVIDER_GOOGLE_BORDERS" | "PROVIDER_GOOGLE_SUBRANGE" | "PROVIDER_GOOGLE_GT_FUSION" | "PROVIDER_GOOGLE_ZAGAT_CMS" | "PROVIDER_GOOGLE_PLACE_NAVBOOST" | "PROVIDER_GOOGLE_FOOTPRINT" | "PROVIDER_GOOGLE_PRODUCT_TERMS" | "PROVIDER_GOOGLE_POINTCARDS" | "PROVIDER_GOOGLE_BUSINESS_CHAINS" | "PROVIDER_GOOGLE_LOCAL_SUMMARIZATION" | "PROVIDER_GOOGLE_PRONUNCIATIONS" | "PROVIDER_GOOGLE_DUMPLING" | "PROVIDER_GOOGLE_DISTILLERY" | "PROVIDER_GOOGLE_LOCAL_ATTRIBUTE_SUMMARIZATION" | "PROVIDER_GOOGLE_RELATION_MINER" | "PROVIDER_GOOGLE_MAPSPAM" | "PROVIDER_GOOGLE_ROSE" | "PROVIDER_GOOGLE_LOCAL_PLACE_RATINGS" | "PROVIDER_GOOGLE_WIPEOUT" | "PROVIDER_GOOGLE_KNOWLEDGE_GRAPH" | "PROVIDER_GOOGLE_BEEGEES" | "PROVIDER_GOOGLE_REVIEW_SUMMARIZATION" | "PROVIDER_GOOGLE_OFFLINE_NON_CORE_ATTRIBUTE_SUMMARIZATION" | "PROVIDER_GOOGLE_GEO_WORLDMAPS" | "PROVIDER_GOOGLE_GEO_MODERATION" | "PROVIDER_GOOGLE_OYSTER_AUTO_EDITS" | "PROVIDER_GOOGLE_LOCAL_ALCHEMY" | "PROVIDER_GOOGLE_KEROUAC" | "PROVIDER_GOOGLE_MOBRANK" | "PROVIDER_GOOGLE_RAPTURE" | "PROVIDER_GOOGLE_CULTURAL_INSTITUTE" | "PROVIDER_GOOGLE_GEOCODES_FROM_LOCAL_FEEDS" | "PROVIDER_GOOGLE_ATTRIBUTES_FROM_CRAWLED_CHAINS" | "PROVIDER_GOOGLE_TACTILE_MAPS" | "PROVIDER_GOOGLE_MAPS_FOR_MOBILE" | "PROVIDER_GOOGLE_GEO_REALTIME" | "PROVIDER_GOOGLE_PROMINENT_PLACES" | "PROVIDER_GOOGLE_PLACE_ACTIONS" | "PROVIDER_GOOGLE_GT_AUTO_EDITS" | "PROVIDER_GOOGLE_WAZE" | "PROVIDER_GOOGLE_ONTHEGO" | "PROVIDER_GOOGLE_GT_IMPORT" | "PROVIDER_GOOGLE_STRUCTURED_DATA" | "PROVIDER_GOOGLE_HELICOPTER" | "PROVIDER_GOOGLE_ROLLBACK" | "PROVIDER_GOOGLE_RIGHTS_REPAIR" | "PROVIDER_GOOGLE_PERFUME" | "PROVIDER_GOOGLE_MAPS_TRANSLATION" | "PROVIDER_GOOGLE_CALL_ME_MAYBE" | "PROVIDER_GOOGLE_LOCAL_UNIVERSAL" | "PROVIDER_GOOGLE_CROUPIER" | "PROVIDER_GOOGLE_SKYSMART" | "PROVIDER_GOOGLE_RIDDLER" | "PROVIDER_GOOGLE_ROADCLOSURES" | "PROVIDER_GOOGLE_SPORE" | "PROVIDER_GOOGLE_LOCALIZATION" | "PROVIDER_GOOGLE_CATTERMS" | "PROVIDER_GOOGLE_GT_FIELD_OPS" | "PROVIDER_GOOGLE_MATCHMAKER" | "PROVIDER_GOOGLE_ARBITRATION" | "PROVIDER_GOOGLE_BIZBUILDER_OPS" | "PROVIDER_GOOGLE_LOCAL_INVENTORY_ADS" | "PROVIDER_GOOGLE_GT_DRAFTY" | "PROVIDER_GOOGLE_HOTELADS_OPS" | "PROVIDER_GOOGLE_MARKERS" | "PROVIDER_GOOGLE_STATE_MACHINE" | "PROVIDER_GOOGLE_ATTRIBUTES_INFERENCE" | "PROVIDER_GOOGLE_BIKESHARE" | "PROVIDER_GOOGLE_GHOSTWRITER" | "PROVIDER_GOOGLE_EDIT_PLATFORM" | "PROVIDER_GOOGLE_BLUE_GINGER" | "PROVIDER_GOOGLE_GEO_TIGER" | "PROVIDER_GOOGLE_HYADES" | "PROVIDER_GOOGLE_WEBQUARRY" | "PROVIDER_GOOGLE_GEO_MADDEN" | "PROVIDER_GOOGLE_ANDROID_PAY" | "PROVIDER_GOOGLE_OPENING_HOURS_TEAM" | "PROVIDER_GOOGLE_LOCAL_DISCOVERY" | "PROVIDER_GOOGLE_LOCAL_HEALTH" | "PROVIDER_GOOGLE_UGC_MAPS" | "PROVIDER_GOOGLE_FIBER" | "PROVIDER_GOOGLE_REVGEO" | "PROVIDER_GOOGLE_HOTELADS_PARTNER_FRONT_END" | "PROVIDER_GOOGLE_GEO_UGC_TASKS" | "PROVIDER_GOOGLE_GEOCODING" | "PROVIDER_GOOGLE_SPYGLASS" | "PROVIDER_GOOGLE_PLUS_CODES_AS_ADDRESSES" | "PROVIDER_GOOGLE_GEO_CHANGES" | "PROVIDER_GOOGLE_HUME" | "PROVIDER_GOOGLE_MEGAMIND" | "PROVIDER_GOOGLE_GT_ROADSYNTH" | "PROVIDER_GOOGLE_FIREBOLT" | "PROVIDER_GOOGLE_LOCAL_PLACE_OFFERINGS" | "PROVIDER_GOOGLE_UGC_SERVICES" | "PROVIDER_GOOGLE_GEOALIGN" | "PROVIDER_GOOGLE_GT_COMPOUNDS" | "PROVIDER_GOOGLE_FOOD_ORDERING" | "PROVIDER_GOOGLE_HOTEL_KNOWLEDGE_OPS" | "PROVIDER_GOOGLE_URAW" | "PROVIDER_GOOGLE_FLYEYE" | "PROVIDER_GOOGLE_YOUKE" | "PROVIDER_GOOGLE_GT_ZEPHYR" | "PROVIDER_GOOGLE_USER_SAFETY" | "PROVIDER_GOOGLE_ADDRESS_MAKER" | "PROVIDER_GOOGLE_UGC_PHOTOS" | "PROVIDER_GOOGLE_GT_WINDCHIME" | "PROVIDER_GOOGLE_SNAG_FIXER" | "PROVIDER_GOOGLE_GEO_DEALS" | "PROVIDER_GOOGLE_LOCAL_PLACE_TOPICS" | "PROVIDER_GOOGLE_PROPERTY_INSIGHTS" | "PROVIDER_GOOGLE_GEO_CONSUMER_MERCHANT_EXPERIMENTS" | "PROVIDER_GOOGLE_GEO_PORTKEY" | "PROVIDER_GOOGLE_ROAD_MAPPER" | "PROVIDER_GOOGLE_LOCATION_PLATFORM" | "PROVIDER_GOOGLE_POSTTRIP" | "PROVIDER_GOOGLE_TRAVEL_DESTINATION" | "PROVIDER_GOOGLE_GEO_DATA_UPLOAD" | "PROVIDER_GOOGLE_BIZBUILDER_CLEANUP" | "PROVIDER_GOOGLE_USER" | "PROVIDER_GOOGLE_STATION" | "PROVIDER_GOOGLE_GEO_FOOD" | "PROVIDER_GOOGLE_GEO_AR" | "PROVIDER_GOOGLE_GEO_TEMPORAL" | "PROVIDER_GOOGLE_SERVICES_MARKETPLACE" | "PROVIDER_GOOGLE_IMT_CLEANUP" | "PROVIDER_GOOGLE_GEO_FOOD_MENU" | "PROVIDER_GOOGLE_CARENAV" | "PROVIDER_GOOGLE_DRIVING_FEEDS" | "PROVIDER_GOOGLE_DRIVING_UGC" | "PROVIDER_GOOGLE_POLAR" | "PROVIDER_GOOGLE_TRIWILD" | "PROVIDER_GOOGLE_CROWD_COMPUTE_OPS" | "PROVIDER_GOOGLE_SA_FROM_WEB" | "PROVIDER_GOOGLE_POI_ALIGNMENT" | "PROVIDER_GOOGLE_SA_FROM_HULK" | "PROVIDER_GOOGLE_SERVICES_INTERACTIONS" | "PROVIDER_GOOGLE_ROADS_UGC_EDITOR" | "PROVIDER_GOOGLE_SA_FROM_NG_INFERENCE" | "PROVIDER_GOOGLE_GEO_DRIVING_VIZ" | "PROVIDER_GOOGLE_GEO_TASKING" | "PROVIDER_GOOGLE_CROWDTASK_DATACOMPUTE" | "PROVIDER_GOOGLE_CROWDTASK_TASKADS" | "PROVIDER_GOOGLE_CROWDTASK_TASKMATE" | "PROVIDER_GOOGLE_CROWDTASK_FURBALL" | "PROVIDER_GOOGLE_CROWDTASK_ADAP" | "PROVIDER_GOOGLE_GPAY" | "PROVIDER_GOOGLE_GEO_UGC_TRUSTED_USERS" | "PROVIDER_GOOGLE_THIRD_PARTY_DATA_PRODUCTION" | "PROVIDER_GOOGLE_GEOTRACKER" | "PROVIDER_GOOGLE_LOCAL_LANDMARK_INFERENCE" | "PROVIDER_GOOGLE_GEO_CLOSED_LOOP" | "PROVIDER_GOOGLE_SA_FROM_MERCHANT_POSTS" | "PROVIDER_GOOGLE_CORE_DATA_RIGHTS" | "PROVIDER_GOOGLE_SA_FROM_USER_REVIEWS" | "PROVIDER_GOOGLE_GEO_CONTENT_FIXER" | "PROVIDER_GOOGLE_POLYGON_REFINEMENT" | "PROVIDER_GOOGLE_HANASU" | "PROVIDER_GOOGLE_FULLRIGHTS_GEO_DATA_UPLOAD" | "PROVIDER_GOOGLE_FULLRIGHTS_3P_OUTREACH_UPLOAD" | "PROVIDER_GOOGLE_ATTRIBUTION_3P_OUTREACH_UPLOAD" | "PROVIDER_GOOGLE_SA_FROM_FOOD_MENUS" | "PROVIDER_GOOGLE_GT_CONSISTENCY_EDITS" | "PROVIDER_GOOGLE_SA_QUALITY" | "PROVIDER_GOOGLE_GDCE_CLEANUP" | "PROVIDER_GOOGLE_UGC_QUALITY_CHAINS" | "PROVIDER_GOOGLE_ATTRIBUTES_DISCOVERY" | "PROVIDER_GOOGLE_GEO_LDE" | "PROVIDER_GOOGLE_GEO_SIGNAL_TRACKING" | "PROVIDER_GOOGLE_UGC_AGGREGATION" | "PROVIDER_GOOGLE_3D_BASEMAP" | "PROVIDER_GOOGLE_MAPFACTS_PRIVACY" | "PROVIDER_GOOGLE_GT_ALF" | "PROVIDER_GOOGLE_GT_OPERATOR_PROVENANCE" | "PROVIDER_GOOGLE_LOCAL_SERVICES_ADS" | "PROVIDER_GOOGLE_LOCALSEARCH" | "PROVIDER_GOOGLE_TRANSIT" | "PROVIDER_GOOGLE_GEOWIKI" | "PROVIDER_GOOGLE_CHINA_LOCAL_TEAM" | "PROVIDER_GOOGLE_SYNTHESIZED" | "PROVIDER_GOOGLE_INTERNAL_TEST" | "PROVIDER_GOOGLE_DISPUTED_AREAS" | "PROVIDER_GOOGLE_3DWAREHOUSE" | "PROVIDER_GOOGLE_GROUNDS_BUILDER" | "PROVIDER_GOOGLE_SESAME" | "PROVIDER_GOOGLE_GT" | "PROVIDER_GOOGLE_GT_BASEMAP_UPLOAD" | "PROVIDER_GOOGLE_ADSDB" | "PROVIDER_GOOGLE_MACHINE_TRANSLITERATION" | "PROVIDER_GOOGLE_TRAVELSEARCH" | "PROVIDER_GOOGLE_PANORAMIO" | "PROVIDER_GOOGLE_YOUTUBE" | "PROVIDER_GOOGLE_OLD" | "PROVIDER_GOOGLE_STREETVIEW" | "PROVIDER_GOOGLE_STREETVIEW_BIZVIEW" | "PROVIDER_GOOGLE_ZIPIT" | "PROVIDER_GOOGLE_OYSTER_CONNECT_ROUTES" | "PROVIDER_GOOGLE_GOLDEN" | "PROVIDER_GOOGLE_INNERSPACE" | "PROVIDER_GOOGLE_MAPSEARCH" | "PROVIDER_GOOGLE_CATEGORIES_TEAM" | "PROVIDER_GOOGLE_CROWDSENSUS" | "PROVIDER_GOOGLE_LOCAL_ALGORITHMIC_IDENTITY" | "PROVIDER_GOOGLE_FREEBASE" | "PROVIDER_GOOGLE_HOTELADS" | "PROVIDER_GOOGLE_AUTHORITY_PAGES" | "PROVIDER_GOOGLE_PLACES_API" | "PROVIDER_GOOGLE_NAMEHEATMAP" | "PROVIDER_GOOGLE_MAPMAKER" | "PROVIDER_GOOGLE_MAPMAKER_MOBILE" | "PROVIDER_GOOGLE_MAPMAKER_PANCAKE" | "PROVIDER_GOOGLE_MAPMAKER_V2" | "PROVIDER_GOOGLE_LOCAL_CLUSTERING_OPERATOR_OVERRIDE" | "PROVIDER_GOOGLE_SERVED_ON_MAPMAKER" | "PROVIDER_GOOGLE_GT_LOCAL" | "PROVIDER_GOOGLE_GT_LOCAL_WITH_RIGHTS" | "PROVIDER_GOOGLE_LOGS_RANKING_SIGNALS" | "PROVIDER_GOOGLE_ENTITY_NAVBOOST" | "PROVIDER_GOOGLE_RELATED_PLACES" | "PROVIDER_GOOGLE_KNOWN_FOR_TERMS" | "PROVIDER_GOOGLE_SYNTHETIC_AREAS" | "PROVIDER_GOOGLE_AUTHORITY_PAGE_PHOTOS" | "PROVIDER_GOOGLE_CROSS_STREETS" | "PROVIDER_GOOGLE_CORRIDORS" | "PROVIDER_GOOGLE_BICYCLE_RENTAL" | "PROVIDER_GOOGLE_CONCRETE_URLS" | "PROVIDER_GOOGLE_LEANBACK" | "PROVIDER_GOOGLE_LOCKED_LISTINGS" | "PROVIDER_GOOGLE_MONITORING" | "PROVIDER_GOOGLE_SPROUT" | "PROVIDER_GOOGLE_LOCAL_SEARCH_QUALITY" | "PROVIDER_GOOGLE_GOBY" | "PROVIDER_GOOGLE_PROBLEM_REPORT" | "PROVIDER_GOOGLE_CANDID" | "PROVIDER_GOOGLE_BIZBUILDER" | "PROVIDER_AUTOMOTIVE_NAVIGATION_DATA" | "PROVIDER_MAPDATA_SCIENCES" | "PROVIDER_MAPONICS" | "PROVIDER_SKI_RESORTS" | "PROVIDER_ZENRIN" | "PROVIDER_SANBORN" | "PROVIDER_URBAN_MAPPING" | "PROVIDER_US_GOVERNMENT" | "PROVIDER_US_CENSUS" | "PROVIDER_US_POSTAL_SERVICE" | "PROVIDER_US_GEOLOGICAL_SURVEY" | "PROVIDER_US_GNIS" | "PROVIDER_US_LANDSAT" | "PROVIDER_US_NATIONAL_GEOSPATIAL_INTELLIGENCE_AGENCY" | "PROVIDER_US_NGA_GNS" | "PROVIDER_US_SSIBL" | "PROVIDER_US_BUREAU_OF_TRANSPORTATION_STATISTICS" | "PROVIDER_US_NATIONAL_OCEANIC_AND_ATMOSPHERIC_ADMINISTRATION" | "PROVIDER_US_POLAR_GEOSPATIAL_CENTER" | "PROVIDER_US_DEPARTMENT_OF_AGRICULTURE" | "PROVIDER_US_NPI_REGISTRY" | "PROVIDER_US_BUREAU_OF_INDIAN_AFFAIRS" | "PROVIDER_DMTI_SPATIAL" | "PROVIDER_INTERNATIONAL_HYDROGRAPHIC_ORGANIZATION" | "PROVIDER_MAPLINK" | "PROVIDER_KINGWAY" | "PROVIDER_GEOCENTRE" | "PROVIDER_CN_NATIONAL_FOUNDAMENTAL_GIS" | "PROVIDER_CN_MAPABC" | "PROVIDER_SMITHSONIAN_INSTITUTE" | "PROVIDER_TRACKS_FOR_AFRICA" | "PROVIDER_PPWK" | "PROVIDER_LEADDOG" | "PROVIDER_CENTRE_DONNEES_ASTRONOMIQUES_STRASBOURG" | "PROVIDER_GISRAEL" | "PROVIDER_BASARSOFT" | "PROVIDER_MAPINFO" | "PROVIDER_MAPIT" | "PROVIDER_GEOBASE" | "PROVIDER_ORION" | "PROVIDER_CENTRAL_EUROPEAN_DATA_AGENCY" | "PROVIDER_ANASAT" | "PROVIDER_MINED_POSTCODES" | "PROVIDER_DMAPAS" | "PROVIDER_COMMON_LOCALE_DATA_REPOSITORY" | "PROVIDER_CH_SBB" | "PROVIDER_SKENERGY" | "PROVIDER_GBRMPA" | "PROVIDER_KOREA_POST" | "PROVIDER_CN_AUTONAVI" | "PROVIDER_MINED_POI" | "PROVIDER_ML_INFOMAP" | "PROVIDER_SNOOPER" | "PROVIDER_GEOSISTEMAS" | "PROVIDER_AFRIGIS" | "PROVIDER_TRANSNAVICOM" | "PROVIDER_EASYCONNECT" | "PROVIDER_LANTMATERIET" | "PROVIDER_LOGICA" | "PROVIDER_MAPKING" | "PROVIDER_DIANPING" | "PROVIDER_GEONAV" | "PROVIDER_HEIBONSHA" | "PROVIDER_DEUTSCHE_TELEKOM" | "PROVIDER_LINGUISTIC_DATA_CONSORTIUM" | "PROVIDER_ACXIOM" | "PROVIDER_DUN_AND_BRADSTREET" | "PROVIDER_FEDERAL_AVIATION_ADMINISTRATION" | "PROVIDER_INFOUSA" | "PROVIDER_INFOUSA_NIXIE" | "PROVIDER_THOMSON_LOCAL" | "PROVIDER_TELEFONICA_PUBLICIDAD_E_INFORMACION" | "PROVIDER_WIKIPEDIA" | "PROVIDER_INFOBEL" | "PROVIDER_MX_GOVERNMENT" | "PROVIDER_MX_NATIONAL_INSTITUTE_STATISTICS_GEOGRAPHY" | "PROVIDER_MX_SERVICIO_POSTAL_MEXICANO" | "PROVIDER_TELEGATE" | "PROVIDER_TELELISTAS" | "PROVIDER_MAPCITY" | "PROVIDER_EXPLAINER_DC" | "PROVIDER_DAIKEI" | "PROVIDER_NL_CHAMBER_OF_COMMERCE" | "PROVIDER_KOREA_INFO_SERVICE" | "PROVIDER_WIKITRAVEL" | "PROVIDER_FLICKR" | "PROVIDER_DIANCO" | "PROVIDER_VOLT_DELTA" | "PROVIDER_SG_GOVERNMENT" | "PROVIDER_SG_LAND_TRANSPORT_AUTHORITY" | "PROVIDER_MAPBAR" | "PROVIDER_LONGTU" | "PROVIDER_SA_GOVERNMENT" | "PROVIDER_SA_SAUDI_POST" | "PROVIDER_PEAKLIST" | "PROVIDER_LOCAL_BUSINESS_CENTER" | "PROVIDER_LOCAL_FEED_XML" | "PROVIDER_WEB" | "PROVIDER_RAILS_TO_TRAILS" | "PROVIDER_INDIACOM" | "PROVIDER_INFOMEDIA" | "PROVIDER_PICASA" | "PROVIDER_AT_GOVERNMENT" | "PROVIDER_AT_BUNDESAMT_FUR_EICH_UND_VERMESSUNGSWESEN" | "PROVIDER_AT_NATIONAL_TOURIST_OFFICE" | "PROVIDER_AT_AUSTRIA_POST" | "PROVIDER_NO_GOVERNMENT" | "PROVIDER_NO_NORSK_EIENDOMSINFORMASJON" | "PROVIDER_NO_POSTEN_NORGE_AS" | "PROVIDER_CH_GOVERNMENT" | "PROVIDER_CH_SWISS_POST" | "PROVIDER_CH_SWISSTOPO" | "PROVIDER_CH_SWISS_NATIONAL_PARK" | "PROVIDER_NAVIT" | "PROVIDER_GEOSEARCH" | "PROVIDER_DE_GOVERNMENT" | "PROVIDER_BUNDESAMT_KARTOGRAPHIE_UND_GEODASIE" | "PROVIDER_BUNDESNETZAGENTUR" | "PROVIDER_SCHOBER_GROUP" | "PROVIDER_MIREO" | "PROVIDER_PUBLIC_MUNICIPALITY" | "PROVIDER_US_PUBLIC_MUNICIPALITY" | "PROVIDER_US_PUBLIC_MUNICIPALITY_WEBSTER_TEXAS" | "PROVIDER_US_PUBLIC_MUNICIPALITY_AMHERST_MASSACHUSETTS" | "PROVIDER_US_PUBLIC_MUNICIPALITY_BLOOMINGTON_INDIANA" | "PROVIDER_US_PUBLIC_MUNICIPALITY_PASADENA_CALIFORNIA" | "PROVIDER_US_PUBLIC_MUNICIPALITY_CHULA_VISTA_CALIFORNIA" | "PROVIDER_US_PUBLIC_MUNICIPALITY_TEMPE_ARIZONA" | "PROVIDER_US_PUBLIC_MUNICIPALITY_COLUMBUS_OHIO" | "PROVIDER_US_PUBLIC_MUNICIPALITY_PORTAGE_MICHIGAN" | "PROVIDER_US_PUBLIC_MUNICIPALITY_GEORGETOWN_KENTUCKY" | "PROVIDER_US_PUBLIC_MUNICIPALITY_GREENVILLE_SOUTH_CAROLINA" | "PROVIDER_US_PUBLIC_MUNICIPALITY_NASHVILLE_TENNESSEE" | "PROVIDER_US_PUBLIC_MUNICIPALITY_WASHINGTON_DISTRICT_OF_COLUMBIA" | "PROVIDER_US_PUBLIC_MUNICIPALITY_BOULDER_COLORADO" | "PROVIDER_NZ_PUBLIC_MUNICIPALITY" | "PROVIDER_NZ_PUBLIC_MUNICIPALITY_ENVIRONMENT_BAY" | "PROVIDER_PL_PUBLIC_MUNICIPALITY" | "PROVIDER_PL_PUBLIC_MUNICIPALITY_BIELSKO_BIALA" | "PROVIDER_DE_PUBLIC_MUNICIPALITY" | "PROVIDER_DE_PUBLIC_MUNICIPALITY_FRANKFURT" | "PROVIDER_DE_PUBLIC_MUNICIPALITY_HAMBURG" | "PROVIDER_DE_PUBLIC_MUNICIPALITY_KARLSRUHE" | "PROVIDER_PT_PUBLIC_MUNICIPALITY" | "PROVIDER_PT_PUBLIC_MUNICIPALITY_SANTA_CRUZ" | "PROVIDER_AT_PUBLIC_MUNICIPALITY" | "PROVIDER_AT_PUBLIC_MUNICIPALITY_KLAGENFURT" | "PROVIDER_AT_PUBLIC_MUNICIPALITY_LINZ" | "PROVIDER_ES_PUBLIC_MUNICIPALITY" | "PROVIDER_ES_PUBLIC_MUNICIPALITY_AZKOITIA" | "PROVIDER_ES_PUBLIC_MUNICIPALITY_BEASAIN" | "PROVIDER_ES_PUBLIC_MUNICIPALITY_GIRONA" | "PROVIDER_ES_PUBLIC_MUNICIPALITY_SAN_SEBASTIAN" | "PROVIDER_ES_PUBLIC_MUNICIPALITY_CATALUNYA" | "PROVIDER_ES_PUBLIC_MUNICIPALITY_HONDARRIBIA" | "PROVIDER_AU_PUBLIC_MUNICIPALITY" | "PROVIDER_AU_PUBLIC_MUNICIPALITY_LAUNCESTON_TASMANIA" | "PROVIDER_IS_PUBLIC_MUNICIPALITY" | "PROVIDER_IS_PUBLIC_MUNICIPALITY_REYKJAVIK" | "PROVIDER_NL_PUBLIC_MUNICIPALITY" | "PROVIDER_NL_PUBLIC_MUNICIPALITY_AMELSTEVEEN" | "PROVIDER_BE_PUBLIC_MUNICIPALITY" | "PROVIDER_BE_PUBLIC_MUNICIPALITY_ANTWERPEN" | "PROVIDER_CA_PUBLIC_MUNICIPALITY" | "PROVIDER_CA_PUBLIC_MUNICIPALITY_FREDERICTON_NEW_BRUNSWICK" | "PROVIDER_CA_PUBLIC_MUNICIPALITY_KAMLOOPS_BRITISH_COLUMBIA" | "PROVIDER_CA_PUBLIC_MUNICIPALITY_NANAIMO_BRITISH_COLUMBIA" | "PROVIDER_CA_PUBLIC_MUNICIPALITY_BANFF_ALBERTA" | "PROVIDER_CA_PUBLIC_MUNICIPALITY_CALGARY_ALBERTA" | "PROVIDER_CA_PUBLIC_MUNICIPALITY_TORONTO_ONTARIO" | "PROVIDER_SE_PUBLIC_MUNICIPALITY" | "PROVIDER_SE_PUBLIC_MUNICIPALITY_UMEA" | "PROVIDER_UA_PUBLIC_MUNICIPALITY" | "PROVIDER_UA_PUBLIC_MUNICIPALITY_KHARKIV" | "PROVIDER_OTHER_PUBLIC_MUNICIPALITY" | "PROVIDER_OTHER_PUBLIC_MUNICIPALITY_AQUA_CALIENTE_CAHUILLA_INDIANS" | "PROVIDER_FR_PUBLIC_MUNICIPALITY" | "PROVIDER_FR_PUBLIC_MUNICIPALITY_PONT_AUDEMER" | "PROVIDER_FR_PUBLIC_MUNICIPALITY_BORDEAUX" | "PROVIDER_SG_PUBLIC_MUNICIPALITY" | "PROVIDER_BR_PUBLIC_MUNICIPALITY" | "PROVIDER_BR_PUBLIC_MUNICIPALITY_RIO_DE_JANEIRO" | "PROVIDER_MAPCUBE" | "PROVIDER_3D_REALITYMAPS" | "PROVIDER_DEUTSCHES_ZENTRUM_FUR_LUFT_UND_RAUMFAHRT" | "PROVIDER_3D_CITIES_SOCIEDADE_ANONIMA" | "PROVIDER_DISNEY" | "PROVIDER_CYBERCITY" | "PROVIDER_PRECISION_LIGHTWORKS_MODELWORKS" | "PROVIDER_VIRTUAL_HUNGARY_LIMITED" | "PROVIDER_VIRTUEL_CITY" | "PROVIDER_SCREAMPOINT_INTERNATIONAL" | "PROVIDER_AGENTSCHAP_VOOR_GEOGRAFISCHE_INFORMATIE_VLAANDEREN" | "PROVIDER_FR_GOVERNMENT" | "PROVIDER_FR_INSTITUT_GEOGRAPHIQUE_NATIONAL" | "PROVIDER_FR_CADASTRE" | "PROVIDER_DIADIEM" | "PROVIDER_THE_WEATHER_CHANNEL" | "PROVIDER_COWI" | "PROVIDER_FALKPLAN_ANDES" | "PROVIDER_NL_GOVERNMENT" | "PROVIDER_NL_KADASTER" | "PROVIDER_NL_BOARD_OF_TOURISM_AND_CONVENTIONS" | "PROVIDER_DIGITAL_MAP_PRODUCTS" | "PROVIDER_SILICE_DIGITAL" | "PROVIDER_TYDAC" | "PROVIDER_ALBRECHT_GOLF" | "PROVIDER_HEALTH_CH" | "PROVIDER_VISITDENMARK" | "PROVIDER_FLYHERE" | "PROVIDER_DIGITAL_DATA_SERVICES" | "PROVIDER_MECOMO" | "PROVIDER_ZA_GOVERNMENT" | "PROVIDER_ZA_RURAL_DEVELOPMENT_LAND_REFORM" | "PROVIDER_SENSIS" | "PROVIDER_JJCONNECT" | "PROVIDER_OPPLYSNINGEN" | "PROVIDER_TELLUS" | "PROVIDER_IQONIA" | "PROVIDER_BE_GOVERNMENT" | "PROVIDER_BE_NATIONAAL_GEOGRAFISCH_INSTITUUT" | "PROVIDER_BE_BRUSSELS_MOBILITY" | "PROVIDER_YELLOWMAP_AG" | "PROVIDER_STIFTUNG_GESUNDHEIT" | "PROVIDER_GIATA" | "PROVIDER_SANPARKS" | "PROVIDER_CENTRE_DINFORMATIQUE_POUR_LA_REGION_BRUXELLOISE" | "PROVIDER_INFOPORTUGAL" | "PROVIDER_NEGOCIOS_DE_TELECOMUNICACOES_E_SISTEMAS_DE_INFORMACAO" | "PROVIDER_COLLINS_BARTHOLOMEW" | "PROVIDER_PROTECT_PLANET_OCEAN" | "PROVIDER_KARTTAKESKUS" | "PROVIDER_FI_GOVERNMENT" | "PROVIDER_FI_NATIONAL_ROAD_ADMINISTRATION" | "PROVIDER_FI_NATIONAL_LAND_SURVEY" | "PROVIDER_FI_STATISTICS_FINLAND" | "PROVIDER_GB_GOVERNMENT" | "PROVIDER_GB_ORDNANCE_SURVEY" | "PROVIDER_NATURAL_ENGLAND" | "PROVIDER_WELSH_GOVERNMENT" | "PROVIDER_GB_OFFICE_FOR_NATIONAL_STATISTICS" | "PROVIDER_EPSILON" | "PROVIDER_PARTNER_FRONT_END" | "PROVIDER_CARTESIA" | "PROVIDER_SE_GOVERNMENT" | "PROVIDER_SE_TRAFIKVERKET" | "PROVIDER_SE_NATURVARDSVERKET" | "PROVIDER_IE_GOVERNMENT" | "PROVIDER_IE_ORDNANCE_SURVEY_IRELAND" | "PROVIDER_LU_GOVERNMENT" | "PROVIDER_LU_P_AND_T_LUXEMBOURG" | "PROVIDER_LU_ADMINISTRATION_DU_CADASTRE_ET_DE_LA_TOPOGRAPHIE" | "PROVIDER_LU_NATIONAL_TOURIST_OFFICE" | "PROVIDER_MAPFLOW" | "PROVIDER_TKARTOR" | "PROVIDER_JUMPSTART" | "PROVIDER_EPTISA" | "PROVIDER_MC_GOVERNMENT" | "PROVIDER_MC_PRINCIPAUTE_DE_MONACO" | "PROVIDER_MONOLIT" | "PROVIDER_ENVIRONMENTAL_SYSTEMS_RESEARCH_INSTITUTE" | "PROVIDER_MODIS" | "PROVIDER_GEOX" | "PROVIDER_GEODIRECTORY" | "PROVIDER_GEOPLAN" | "PROVIDER_INFODIREKT" | "PROVIDER_GEOGLOBAL" | "PROVIDER_DEUTSCHE_POST" | "PROVIDER_TRACASA" | "PROVIDER_CORREOS" | "PROVIDER_ES_GOVERNMENT" | "PROVIDER_ES_CENTRO_NACIONAL_DE_INFORMACION_GEOGRAFICA" | "PROVIDER_EDIMAP" | "PROVIDER_VERIZON" | "PROVIDER_NATIONAL_GEOGRAPHIC_MAPS" | "PROVIDER_PROMAPS" | "PROVIDER_CONSODATA" | "PROVIDER_DE_AGOSTINI" | "PROVIDER_FEDERPARCHI" | "PROVIDER_NAVIGO" | "PROVIDER_ITALIAMAPPE" | "PROVIDER_CZECOT" | "PROVIDER_NATURAL_EARTH" | "PROVIDER_REGIO" | "PROVIDER_SHIPWRECK_CENTRAL" | "PROVIDER_RUTGERS_STATE_UNIVERSITY" | "PROVIDER_TWINICE" | "PROVIDER_NORTHERN_IRELAND_TOURIST_BOARD" | "PROVIDER_INFOGROUP" | "PROVIDER_TNET" | "PROVIDER_CTT_CORREIOS_DE_PORTUGAL" | "PROVIDER_EUROPARC" | "PROVIDER_IUPPITER" | "PROVIDER_MICHAEL_BAUER_INTERNATIONAL" | "PROVIDER_LEPTON" | "PROVIDER_MAPPOINT" | "PROVIDER_GEODATA" | "PROVIDER_RU_GOVERNMENT" | "PROVIDER_RU_FNS_KLADR" | "PROVIDER_BR_GOVERNMENT" | "PROVIDER_BR_INSTITUTO_BRASILEIRO_DO_MEIO_AMBIENTE_E_DOS_RECURSOS_NATURAIS_RENOVAVEIS" | "PROVIDER_BR_MINISTERIO_DO_MEIO_AMBIENTE" | "PROVIDER_BR_AGENCIA_NACIONAL_DE_AGUAS" | "PROVIDER_BR_INSTITUTO_BRASILEIRO_DE_GEOGRAFIA_E_ESTATISTICA" | "PROVIDER_BR_FUNDACAO_NACIONAL_DO_INDIO" | "PROVIDER_BR_DEPARTAMENTO_NACIONAL_DE_INFRAESTRUTURA_DE_TRANSPORTES" | "PROVIDER_AZAVEA" | "PROVIDER_NORTHSTAR" | "PROVIDER_COMMEDI" | "PROVIDER_NEXUS_GEOGRAFICS" | "PROVIDER_INFOERA" | "PROVIDER_AD_GOVERNMENT" | "PROVIDER_AD_AREA_DE_CARTOGRAFIA" | "PROVIDER_MAXXIMA" | "PROVIDER_SI_GOVERNMENT" | "PROVIDER_SI_AGENCY_FOR_ENVIRONMENT" | "PROVIDER_TRANSPORT_HI_TECH_CONSULTANTS" | "PROVIDER_L1_TECHNOLOGIES" | "PROVIDER_TELEMEDIA" | "PROVIDER_CDCOM_PROGOROD" | "PROVIDER_MIT_CITYGUIDE" | "PROVIDER_SUNCART" | "PROVIDER_MICROMAPPER" | "PROVIDER_RICHI" | "PROVIDER_FORUM44" | "PROVIDER_SEAT" | "PROVIDER_VALASSIS" | "PROVIDER_NAVICOM" | "PROVIDER_COLTRACK" | "PROVIDER_PSMA_AUSTRALIA" | "PROVIDER_PT_DUTA_ASTAKONA_GIRINDA" | "PROVIDER_CA_GOVERNMENT" | "PROVIDER_STATISTICS_CANADA" | "PROVIDER_TOCTOC" | "PROVIDER_RMSI" | "PROVIDER_TRUE_TECHNOLOGY" | "PROVIDER_INCREMENT_P_CORPORATION" | "PROVIDER_GOJAVAS" | "PROVIDER_GEOINFORMATION_GROUP" | "PROVIDER_CYBERSOFT" | "PROVIDER_TSENTR_EFFEKTIVNYKH_TEKHNOLOGIY" | "PROVIDER_EE_GOVERNMENT" | "PROVIDER_EE_MAA_AMET" | "PROVIDER_GASBUDDY" | "PROVIDER_DK_GOVERNMENT" | "PROVIDER_DK_GEODATASTYRELSEN" | "PROVIDER_MURCIA_REGION_GOVERNMENT" | "PROVIDER_CORREIOS" | "PROVIDER_WEST_WORLD_MEDIA" | "PROVIDER_INTERNATIONAL_MAPPING_ASSOCIATION" | "PROVIDER_MEDICARE" | "PROVIDER_POLARIS" | "PROVIDER_TW_GOVERNMENT" | "PROVIDER_TW_MINISTRY_OF_THE_INTERIOR_SURVEYING_AND_MAPPING_CENTER" | "PROVIDER_NORDECA" | "PROVIDER_AFRIMAPPING" | "PROVIDER_OVERDRIVE" | "PROVIDER_PROVIDER_NETWORK_DIRECTORIES" | "PROVIDER_BR_MINISTERIO_DA_SAUDE" | "PROVIDER_DIGITAL_EGYPT" | "PROVIDER_INRIX" | "PROVIDER_ARPINDO" | "PROVIDER_IT_GOVERNMENT" | "PROVIDER_ISTITUTO_GEOGRAFICO_MILITARE" | "PROVIDER_EAST_END_GROUP" | "PROVIDER_INGEOLAN" | "PROVIDER_SEMACONNECT" | "PROVIDER_BLINK" | "PROVIDER_EVGO" | "PROVIDER_CHARGEPOINT" | "PROVIDER_TPL_TRAKKER" | "PROVIDER_OI" | "PROVIDER_MAPARADAR" | "PROVIDER_SINGAPORE_POST" | "PROVIDER_CHARGEMASTER" | "PROVIDER_TESLA" | "PROVIDER_VISICOM" | "PROVIDER_GEOLYSIS" | "PROVIDER_ZEPHEIRA" | "PROVIDER_HUBJECT" | "PROVIDER_PODPOINT" | "PROVIDER_CHARGEFOX" | "PROVIDER_KR_GOVERNMENT" | "PROVIDER_KR_MOLIT" | "PROVIDER_KR_MINISTRY_OF_THE_INTERIOR_AND_SAFETY" | "PROVIDER_CRITCHLOW" | "PROVIDER_EIFRIG" | "PROVIDER_GIREVE" | "PROVIDER_CN_NAVINFO" | "PROVIDER_JAPAN_CHARGE_NETWORK" | "PROVIDER_NOBIL" | "PROVIDER_INDIA_BANKS" | "PROVIDER_INDONESIA_ELECTION_KPU" | "PROVIDER_CAREERS360" | "PROVIDER_SOURCE_LONDON" | "PROVIDER_EVBOX" | "PROVIDER_JP_GOVERNMENT" | "PROVIDER_JP_MINISTRY_OF_THE_ENVIRONMENT" | "PROVIDER_YUMYUM" | "PROVIDER_HWW_AUSTRALIA" | "PROVIDER_CINERGY" | "PROVIDER_MTIME" | "PROVIDER_KULTUNAUT" | "PROVIDER_BLITZ" | "PROVIDER_PIA" | "PROVIDER_INTERPARK" | "PROVIDER_CINEMA_ONLINE" | "PROVIDER_BELBIOS" | "PROVIDER_MOVIESEER" | "PROVIDER_SODAMEDYA" | "PROVIDER_ATMOVIES" | "PROVIDER_HOTELBEDS" | "PROVIDER_VERICRED" | "PROVIDER_CIRRANTIC" | "PROVIDER_GOGO_LABS" | "PROVIDER_ELECTRIFY_AMERICA" | "PROVIDER_CMS_MPPUF" | "PROVIDER_DIGIROAD" | "PROVIDER_KONTEX_GEOMATICS" | "PROVIDER_NZ_GOVERNMENT" | "PROVIDER_NZ_LINZ" | "PROVIDER_NZ_DOC" | "PROVIDER_FASTNED" | "PROVIDER_DESTINY_CS" | "PROVIDER_IONITY" | "PROVIDER_EV_CONNECT" | "PROVIDER_PANPAGES" | "PROVIDER_ETECNIC" | "PROVIDER_VOLTA" | "PROVIDER_NISSAN_MEXICO" | "PROVIDER_BMW_GROUP_LATIN_AMERICA" | "PROVIDER_FEDERAL_ELECTRICITY_COMMISSION_MEXICO" | "PROVIDER_VOLVO_CARS_BRASIL" | "PROVIDER_CHARGE_AND_PARKING" | "PROVIDER_DEDUCE_TECHNOLOGIES" | "PROVIDER_SK_TELECOM" | "PROVIDER_ECO_MOVEMENT" | "PROVIDER_GOOGLE_GMS" | "PROVIDER_EASYWAY" | "PROVIDER_PHYSICIAN_COMPARE" | "PROVIDER_HOSPITAL_COMPARE" | "PROVIDER_ENDOLLA_BARCELONA" | "PROVIDER_BE_CHARGE" | "PROVIDER_ONE_NETWORK" | "PROVIDER_CARENAV_DUPLEX" | "PROVIDER_CARENAV_POI" | "PROVIDER_IN_GOVERNMENT" | "PROVIDER_SURVEY_OF_INDIA" | "PROVIDER_E_ON" | "PROVIDER_ELECTRIFY_CANADA" | "PROVIDER_GRIDCARS" | "PROVIDER_DRIVECO" | "PROVIDER_GREEN_ACTION_STUDIOS" | "PROVIDER_GREEN_ACTION_STUDIO" | "PROVIDER_EVINY" | "PROVIDER_MASTERCARD" | "PROVIDER_VATTENFALL" | "PROVIDER_VIETGIS" | "PROVIDER_UNITE" | "PROVIDER_NEOGY" | "PROVIDER_AMPUP" | "PROVIDER_LOOP" | "PROVIDER_ZEST" | "PROVIDER_EZVOLT";
  sourceDataset?: string;
}

/**
 * Message to represent opening hours including regular weekly hours and a set
 * of exceptions.
 */
export interface GeostoreOpeningHoursProto {
  /**
   * Date delimited exceptions to the typical recurring opening hours. May only
   * be present if regular weekly hours are also specified.
   */
  exception?: GeostoreExceptionalHoursProto[];
  /**
   * Typical recurring opening hours, expressed as a weekly schedule. NOTE:
   * this field was introduced to have a more client-friendly format for
   * representing weekly hours but, as of November 2018, it's not used for the
   * main opening hours of TYPE_ESTABLISHMENT features (instead, the data is
   * stored in the `EstablishmentProto.hours` field, see b/23105782 tracking the
   * possible schema migration). It is however used in other contexts where
   * `OpeningHoursProto` appears in the Geo Schema. In openinghours.h there is a
   * utility function `GetOpeningHoursFromFeature` that merges
   * `EstablishmentProto.hours` into this proto.
   */
  regularHours?: GeostoreBusinessHoursProto;
}

/**
 * Information about a feature's operations, e.g. when the feature is
 * temporarily closed.
 */
export interface GeostoreOperationsProto {
  /**
   * Records temporary status change of the feature, such as remodel, vacation,
   * etc.: the feature is temporarily (but not permanently) unavailable. This
   * prevents users from going to the feature. Supports an arbitrary number of
   * past, present, and future temporary closures, with the feature's data owner
   * choosing which range of past and future closures to permit or guarantee to
   * keep. All start and end dates must be unique from each other. If two
   * consecutive dates are a start and an end of a TemporaryClosureProto, then
   * the two dates must be from the same TemporaryClosureProto. Otherwise, exact
   * dates may be missing so long as there exist a possible sequence of
   * temporary closures with both exact start_date and end_date that keeps any
   * known exact start_date and end_date. The earliest temporary closure must
   * begin after whenever initial operations begin. Likewise, the latest
   * temporary closure must end before whenever the permanent closure begins.
   * NOTE: does *not* guarantee chronological order.
   */
  temporaryClosure?: GeostoreTemporaryClosureProto[];
}

/**
 * This message captures a border status override. For instance, if the
 * TYPE_BORDER feature between China and Hong Kong must be hidden on
 * ditu.google.cn (the Chinese domain for Google Maps) but may be displayed on
 * other domains, we will have a country override border status for "CN" set to
 * STATUS_NEVER_DISPLAY. At least one override restriction must be defined.
 * Currently the only supported restriction is by country code.
 */
export interface GeostoreOverrideBorderStatusProto {
  /**
   * The two-letter ISO 3166-1 country code corresponding to the domain this
   * status override applies to, when rendering the border polyline.
   */
  countryCode?: string;
  /**
   * The override status, from the BorderStatus enumeration. The value here
   * must be different from the main status (otherwise there's no point in
   * providing the override).
   */
  status?:  | "STATUS_NORMAL" | "STATUS_DISPUTED" | "STATUS_UNSURVEYED" | "STATUS_INTERNATIONAL_WATER" | "STATUS_NEVER_DISPLAY" | "STATUS_TREATY" | "STATUS_PROVISIONAL" | "STATUS_NO_LABEL";
}

/**
 * Painted element logical color. Most legal definitions only specify a color
 * category (like "yellow") and don't specify an exact hue, rather stating that
 * the colors must be distinguishable from each other. We refer to this as the
 * "logical" color.
 */
export interface GeostorePaintedElementLogicalColorProto {
  color?:  | "UNKNOWN_LOGICAL_COLOR" | "WHITE" | "YELLOW" | "RED" | "GREEN" | "BLUE" | "BLACK" | "GREY" | "ORANGE";
}

/**
 * Describes the parking allowances for a feature, or the situations and
 * requirements under which one may be permitted to park, such as certain
 * vehicle types, valet parking, and permit parking. Also describes the cost of
 * parking, which may vary based on the time and duration parked. Includes
 * vehicle type, any other conditions for eligibility, and the cost of parking,
 * which may vary based on the time and duration parked. If is_discount is set
 * to true on a given allowance, that allowance represents a discount that can
 * be applied to lower the cost of non-discount allowances specified on feature
 * via parking_provider_feature. In this way, allowances can be 'layered,' i.e.
 * appended, onto each other when denormalizing references via
 * parking_provider_feature.
 */
export interface GeostoreParkingAllowanceProto {
  /**
   * The type of parking for this allowance. Allowance details only apply to
   * the type of parking specified.
   */
  allowanceType?:  | "STANDARD" | "VALET" | "PERMIT" | "PICKUP_GOODS" | "PICKUP_PASSENGERS";
  /**
   * If true, this allowance represents a discount rather than an individual
   * rate; any rate values specified in this allowance describe a discount to be
   * applied to the non-discount allowances in the ParkingProto.
   */
  isDiscount?: boolean;
  /**
   * If this rate requires validation, this expresses the minimum purchase
   * required for validation in each applicable currency. Should have an ID of
   * /measurement_unit/money_value and consist of two properties: one with an ID
   * of /measurement_unit/money_value/amount and a float value with the amount,
   * and another with the ID /measurement_unit/money_value/currency and an ID
   * value with the MID of the proper currency (from the /finance/currency
   * type). A value of 0 suggests that no purchase is required. If empty, this
   * suggests that no validation is required for this rate.
   */
  minPurchaseForValidation?: FreebaseTopic[];
  /**
   * Any additional details about the permit type; e.g. Zone A. In any local
   * languages. Should only be set if allowance_type is PERMIT.
   */
  permitType?: GeostoreLanguageTaggedTextProto[];
  /**
   * The types of services that this parking allowance applies to. For
   * instance, some cities have streets that only allow traditional taxis to
   * pick up passengers.
   */
  serviceType?:  | "SERVICE_ALL" | "SERVICE_GENERAL_DRIVER" | "SERVICE_RIDESHARE" | "SERVICE_TAXI" | "SERVICE_COMMERCIAL"[];
  /**
   * Describes the rate structures. Each TimeBasedRateProto defines a rate
   * which may apply based on a particular arrival, departure or utilization
   * time; for example, one rate might apply if arriving before 9am, and another
   * might apply regardless of arrival or departure time.
   */
  timeBasedRate?: GeostoreTimeBasedRateProto[];
  /**
   * Restrictions on which vehicle type(s) the allowance applies to. By
   * default, the allowance applies to any vehicle types.
   */
  vehicleType?:  | "ANY" | "CAR" | "MOTORCYCLE" | "TRUCK";
}

function serializeGeostoreParkingAllowanceProto(data: any): GeostoreParkingAllowanceProto {
  return {
    ...data,
    minPurchaseForValidation: data["minPurchaseForValidation"] !== undefined ? data["minPurchaseForValidation"].map((item: any) => (serializeFreebaseTopic(item))) : undefined,
    timeBasedRate: data["timeBasedRate"] !== undefined ? data["timeBasedRate"].map((item: any) => (serializeGeostoreTimeBasedRateProto(item))) : undefined,
  };
}

function deserializeGeostoreParkingAllowanceProto(data: any): GeostoreParkingAllowanceProto {
  return {
    ...data,
    minPurchaseForValidation: data["minPurchaseForValidation"] !== undefined ? data["minPurchaseForValidation"].map((item: any) => (deserializeFreebaseTopic(item))) : undefined,
    timeBasedRate: data["timeBasedRate"] !== undefined ? data["timeBasedRate"].map((item: any) => (deserializeGeostoreTimeBasedRateProto(item))) : undefined,
  };
}

/**
 * Used to describe the parking facilities provided by or available to a
 * feature. Features of TYPE_ROAD or TYPE_COMPOUND can have a ParkingProto (with
 * parking_provider_feature unset) that describes the parking facilities
 * provided by that feature. Features of TYPE_COMPOUND or TYPE_ESTABLISHMENT_POI
 * can have a ParkingProto (with parking_provider_feature set) to indicate that
 * the feature has dedicated parking and provide details about it, and defer
 * some details of the parking facilities to the referent feature(s).
 * ParkingProto is maintained by the Harbor Pilot team (go/harbor-pilot).
 * Detailed modeling information is described at go/parking-schema.
 */
export interface GeostoreParkingProto {
  /**
   * Describes the parking allowances for the feature, which are the situations
   * and requirements under which one is permitted to park at the features
   * parking facilities, or discounts that a user may be eligible for.
   */
  allowance?: GeostoreParkingAllowanceProto[];
  /**
   * Hours in which the parking facility is open; that is, permits both
   * arrivals and departures of the facility. Should only be set on compounds
   * (i.e. parking lots or garages); roads are considered to always be open,
   * though parking at certain times may be prohibited via restrictions. If
   * unset on a compound, this suggests we dont know the opening hours, or they
   * are the same as the hours of the entity for which this feature offers
   * parking facilities.
   */
  openingHours?: GeostoreOpeningHoursProto;
  /**
   * Indicates whether long-term parking is available at the feature; if true,
   * long-term parking is available at the feature and parking allowances may be
   * present on this feature, or parking_provider_feature may indicate defered
   * parking feature(s). If false, this is an explicit statement that there is
   * no long-term parking associated with this feature. If unset, we don't know
   * whether there is long-term parking associated with this feature. If false
   * or unset, only additional restrictions or short-term allowances will be
   * populated.
   */
  parkingAvailable?: boolean;
  /**
   * If empty, indicates that the feature containing this ParkingProto provides
   * parking facilities, which are described by this proto. If nonempty,
   * indicates that the feature with this ParkingProto does not contain parking
   * facilities itself, but visitors of this feature may use the parking
   * available to the referent feature(s). The referent feature(s) may
   * themselves contain parking facilities or defer to other features. A
   * ParkingProto may defer parking details to another feature, but still
   * include its own data. This suggests that a visitor of the referrer feature
   * is eligible for different rates or discounts. The data in these fields
   * applies transitively, and any fields in a referrer may be applied to the
   * referent (for a visitor of the referrer).
   */
  parkingProviderFeature?: GeostoreFeatureIdProto[];
  /**
   * Describes any parking restrictions that apply to this feature. Should only
   * be set on road segments for which parking is explicitly prohibited for some
   * or all times; for roads which do not prohibit parking and for all other
   * facilities, the ability to park should be expressed using allowances. In
   * the instance that both a restriction and an allowance applies at a given
   * time, restrictions always have precedence over the same parking allowances.
   * However, explicit short-term allowances (PICKUP_GOODS, PICKUP_PASSENGERS)
   * take precedence over general NO_PARKING, NO_STANDING, or NO_STOPPING
   * restrictions.
   */
  restriction?: GeostoreParkingRestrictionProto[];
}

function serializeGeostoreParkingProto(data: any): GeostoreParkingProto {
  return {
    ...data,
    allowance: data["allowance"] !== undefined ? data["allowance"].map((item: any) => (serializeGeostoreParkingAllowanceProto(item))) : undefined,
    parkingProviderFeature: data["parkingProviderFeature"] !== undefined ? data["parkingProviderFeature"].map((item: any) => (serializeGeostoreFeatureIdProto(item))) : undefined,
  };
}

function deserializeGeostoreParkingProto(data: any): GeostoreParkingProto {
  return {
    ...data,
    allowance: data["allowance"] !== undefined ? data["allowance"].map((item: any) => (deserializeGeostoreParkingAllowanceProto(item))) : undefined,
    parkingProviderFeature: data["parkingProviderFeature"] !== undefined ? data["parkingProviderFeature"].map((item: any) => (deserializeGeostoreFeatureIdProto(item))) : undefined,
  };
}

/**
 * Expresses a parking restriction on a road; i.e. times at which parking on
 * the road is prohibited.
 */
export interface GeostoreParkingRestrictionProto {
  /**
   * Times at which parking is prohibited.
   */
  restrictedHours?: GeostoreTimeScheduleProto;
  /**
   * clang-format on The type of restriction that applies at this time.
   */
  restrictionType?:  | "RESTRICTION_UNKNOWN" | "RESTRICTION_PARKING" | "RESTRICTION_STANDING" | "RESTRICTION_STOPPING" | "RESTRICTION_PICKUP_GOODS" | "RESTRICTION_PICKUP_PASSENGERS";
  /**
   * The types of services that this parking restriction applies to. We expect
   * most parking restrictions to apply to all services, but some airports have
   * specific rideshare parking or taxi parking zones.
   */
  serviceType?:  | "SERVICE_ALL" | "SERVICE_GENERAL_DRIVER" | "SERVICE_RIDESHARE" | "SERVICE_TAXI" | "SERVICE_COMMERCIAL"[];
  /**
   * The types of vehicles that this parking restriction applies to. For
   * instance, some streets may allow motorcycles to park but not automobiles or
   * trucks.
   */
  vehicleType?:  | "ANY" | "CAR" | "MOTORCYCLE" | "TRUCK"[];
}

/**
 * This protocol buffer holds related data for features of type TYPE_PEAK and
 * TYPE_VOLCANO.
 */
export interface GeostorePeakProto {
  /**
   * Topographic prominence in meters: the height of the peaks summit above
   * the lowest contour line encircling it and no higher summit.
   */
  prominenceMeters?: number;
}

/**
 * A crossing describes a path from the end point of a segment to the start
 * point of its sibling. Each individual crossing should uniquely represent a
 * physically distinct crossing in the real world. Pedestrian crossings are
 * bidirectional. This proto represents "simple" crossings. More complicated
 * crossings (such as the diagonal crosswalk at Shibuya Station in Tokyo) will
 * be represented using a separate pedestrian network. Example 1: Standard four
 * way crossing. Assume each road (A/B/C) has a crosswalk (denoted by a '-')
 * right before intersection X. Assume crossing at D is prohibited (denoted by a
 * '%'). Assume "prime" roads (A',B',...) are OUT segments relative to X. A\\A'
 * B//B' \\ // \\ // - - X - % // \\ // \\ C'//C D'\\D * A CROSSABLE
 * PedestrianCrossing should be added to A, B and C. * An UNCROSSABLE
 * PedestrianCrossing should be added to D. Example 2: Simple intersection with
 * one crossing. Assume intersection X was added to accommodate the crosswalk
 * (through X, denoted by '-'). Assume "prime" roads (A',B',...) are OUT
 * segments relative to X. A\\A' \\ \\ -X- \\ \\ B'\\B * A CROSSABLE
 * PedestrianCrossing must be added to either A or B, but not both because each
 * real-world crossing should be represented exactly once. Duplicative crossings
 * may be arbitrarily removed.
 */
export interface GeostorePedestrianCrossingProto {
  /**
   * This value specifies the angle of the crosswalk. Zero degrees represents a
   * crosswalk perpendicular to the direction of travel, towards the right side
   * of the segment. The crosswalk angle, winds clockwise. Range [-90, 90]. The
   * following crosswalk would have a 15 degree angle: / /
   * <--/-------------------------------- / /
   */
  angleDegrees?: number;
  /**
   * This value enables crossing anywhere (not just at the segments endpoint),
   * typically used on long, low-traffic residential streets. This attribute is
   * only respected for trivial segment -> sibling routes. All other routes can
   * cross at a MapFacts intersection.
   */
  crossAnywhere?: boolean;
  /**
   * Crossing type is used as a restriction and can also be used for rendering.
   */
  crossingType?:  | "UNKNOWN" | "CROSSABLE" | "UNMARKED_CROSSING" | "MARKED_CROSSING" | "UNCROSSABLE";
  /**
   * The crossing offset defines a fraction between the distance from the
   * segment endpoint to the centerline of the crosswalk and the length of the
   * segment. For example, the segment length is 20 meters and the distance from
   * segment end to center of crosswalk is 2 meters, the value of offset will be
   * 0.1.
   */
  offset?: number;
  /**
   * Restrictions for this crossing (such as constructions on the crosswalk).
   * They must not have subpath or travel_mode.
   */
  restriction?: GeostoreRestrictionProto[];
  /**
   * This value defines the full width of the crossing in the direction
   * perpendicular to the direction which pedestrians walk on the crossing (in
   * meters). The crossing is allowed to "spill" into the next segment (0.5 *
   * width can be greater than the offset). Cannot be a negative value.
   */
  width?: number;
}

function serializeGeostorePedestrianCrossingProto(data: any): GeostorePedestrianCrossingProto {
  return {
    ...data,
    restriction: data["restriction"] !== undefined ? data["restriction"].map((item: any) => (serializeGeostoreRestrictionProto(item))) : undefined,
  };
}

function deserializeGeostorePedestrianCrossingProto(data: any): GeostorePedestrianCrossingProto {
  return {
    ...data,
    restriction: data["restriction"] !== undefined ? data["restriction"].map((item: any) => (deserializeGeostoreRestrictionProto(item))) : undefined,
  };
}

/**
 * Describes a single physical marker line.
 */
export interface GeostorePhysicalLineProto {
  /**
   * Applicable for DASHED and DOTTED_DASHED lines.
   */
  dashLengthMeters?: number;
  /**
   * This should be rarely needed, but can represent patterns of alternating
   * colors.
   */
  gapColor?: GeostorePaintedElementLogicalColorProto;
  /**
   * Applicable for DASHED, DOTTED, and DOTTED_DASHED lines.
   */
  gapLengthMeters?: number;
  material?:  | "UNKNOWN_STRIPE_MATERIAL" | "PAINT_STRIPE" | "ROUND_DOT" | "SQUARE_DOT"[];
  /**
   * Color for the painted elements. Applicable to all types.
   */
  paintColor?: GeostorePaintedElementLogicalColorProto;
  pattern?:  | "UNKNOWN_DASH_PATTERN" | "SOLID" | "DASHED" | "DOTTED" | "DOTTED_DASHED";
  /**
   * A token that can be used to identify the version of the data about this
   * marker line.
   */
  physicalLineToken?: string;
}

export interface GeostorePointProto {
  latE7?: number;
  lngE7?: number;
  /**
   * NOTE: If removing metadata, remove 'option objc_class_prefix = "GS";'
   * together. See cl/189921100. Field-level metadata for this point. NOTE:
   * there are multiple PointProto fields in the Geo Schema. Metadata here is
   * only expected to be present on FeatureProto.point[] and
   * FeatureProto.center.
   */
  metadata?: GeostoreFieldMetadataProto;
  /**
   * A place for clients to attach arbitrary data to a point. Never set in
   * MapFacts.
   */
  temporaryData?: Proto2BridgeMessageSet;
}

/**
 * PointWithHeightProto encodes lat/lng through PointProto and contains
 * altitude information.
 */
export interface GeostorePointWithHeightProto {
  /**
   * Altitude of this point is assumed to be relative to the ground level.
   */
  altitudeMeters?: number;
  point?: GeostorePointProto;
}

/**
 * This protocol buffer is included from feature.proto as an optional message.
 * Political features represent the different ways that people are divided into
 * geographical regions.
 */
export interface GeostorePoliticalProto {
  /**
   * Many political regions have a conceptual center (capitals of a country or
   * a top-level division are examples). If set, the target feature must be a
   * TYPE_LOCALITY feature.
   */
  capital?: GeostoreFeatureIdProto;
  /**
   * The Gross Domestic Product of the political region measured in millions of
   * current United States dollars. It must not be negative.
   */
  grossDomesticProductUsdMillions?: number;
  /**
   * Percentage of population that are literate within a political region. It
   * must be between 0 and 100.
   */
  literacyPercent?: number;
  /**
   * The number of people in this political region. This field is intended to
   * store accurate population, not an estimation such as representative value
   * for population range. It must not be negative.
   */
  population?: bigint;
}

function serializeGeostorePoliticalProto(data: any): GeostorePoliticalProto {
  return {
    ...data,
    capital: data["capital"] !== undefined ? serializeGeostoreFeatureIdProto(data["capital"]) : undefined,
    population: data["population"] !== undefined ? String(data["population"]) : undefined,
  };
}

function deserializeGeostorePoliticalProto(data: any): GeostorePoliticalProto {
  return {
    ...data,
    capital: data["capital"] !== undefined ? deserializeGeostoreFeatureIdProto(data["capital"]) : undefined,
    population: data["population"] !== undefined ? BigInt(data["population"]) : undefined,
  };
}

/**
 * A general non-self-intersecting spherical polygon, consisting of one or more
 * loops defining multiple disconnected regions possibly with holes. All loops
 * should be oriented CCW around the region they define. This applies to the
 * exterior loop(s) as well as any holes. Within MapFacts (and underlying
 * infrastructure) the data fields may be replaced by a single shape_id; see
 * comments on shape_id below. Any such PolygonProtos shouldn't be expected to
 * work with public functions in //geostore/base/public/polygon.h.
 */
export interface GeostorePolygonProto {
  /**
   * The polygon loops above are basically flat: each point has a latitude and
   * a longitude but no altitude. We don't want to build real 3D models here,
   * but we do want to be able to generate 2.5D models. A 2.5D model is built by
   * translating the flat polygon upward some distance (base) then extruding it
   * upward some additional distance (height). The elevation of the bottom of
   * the extruded polygon (above ground level).
   */
  baseMeters?: number;
  /**
   * ** DEPRECATED ** This is part of a splitting strategy for large polygons,
   * which was never fully launched and we decided not to pursue. For features
   * with very complex polygonal geometry, we break up the polygon into pieces
   * that align with S2 cells at various levels. We do this for performance
   * reasons as some geometry operations have quadratic complexity with regards
   * to the total number of vertices. In these cases, we store the S2 cell ID
   * corresponding to the piece of the overall polygon that is described by this
   * specific PolygonProto message. Each polygon piece is expected to be fully
   * contained by the S2 cell corresponding to this cell ID. However, note that
   * the S2 cell ID is not required to correspond to the smallest S2 cell that
   * fully contains the polygon (and often won't be). In addition, polygon
   * pieces are required to not have any overlap (which translates to having
   * entirely disjoint S2 cell IDs, i.e. one can not be parent (or grand parent,
   * etc.) of another).
   */
  cellId?: bigint;
  /**
   * Encoding of the polygon using S2Polygon::Encode()'s compressed
   * representation.
   */
  encoded?: Uint8Array;
  /**
   * The distance from the bottom of the extruded polygon to the top.
   */
  heightMeters?: number;
  /**
   * ** DEPRECATED ** We have switched to using exclusively the encoded form in
   * the wire format to and from MapFacts, so this field should never be
   * populated there. See go/encoded-polygons for more info. "Classic" polygon
   * representation, defined by one or more loops. The last vertex of each
   * polyline is implicitly connected to the first vertex. All loops should be
   * specified in CCW order.
   */
  loop?: GeostorePolyLineProto[];
  /**
   * Field-level metadata for this polygon.
   */
  metadata?: GeostoreFieldMetadataProto;
  /**
   * A unique identifier for this polygon's data which is being held externally
   * in Shapestore (see go/shapestore). This is only ever set internally within
   * MapFacts or underlying infrastructure and if set is set in lieu of other
   * fields. Clients of MapFacts (or anyone downstream of them) can rely on the
   * guarantee that this field will never be set and that the actual data for
   * the polygon will be present instead. This field has been deprecated in
   * favor of FeatureProto.internal.polygon_shape_id
   */
  shapeId?: string;
  /**
   * A place for clients to attach arbitrary data to a polygon. Never set in
   * MapFacts.
   */
  temporaryData?: Proto2BridgeMessageSet;
  /**
   * Some polygons are known to be rough proxies for a feature's "real"
   * polygonal representation. Such polygons are generally unsuitable for
   * display. Rendering clients should not show these in most cases. Polygons
   * unsuitable for display do have other uses, such as user location or
   * containment analysis, or as an input to learning algorithms. This is an
   * orthogonal concept to FeatureProto.synthetic_geometry, which only pertains
   * to the method by which a polygon was created, rather than its fidelity to
   * ground truth. For features that have multiple polygons, this bit should be
   * consistently set to the same value on all polygons.
   */
  unsuitableForDisplay?: boolean;
}

function serializeGeostorePolygonProto(data: any): GeostorePolygonProto {
  return {
    ...data,
    cellId: data["cellId"] !== undefined ? String(data["cellId"]) : undefined,
    encoded: data["encoded"] !== undefined ? encodeBase64(data["encoded"]) : undefined,
  };
}

function deserializeGeostorePolygonProto(data: any): GeostorePolygonProto {
  return {
    ...data,
    cellId: data["cellId"] !== undefined ? BigInt(data["cellId"]) : undefined,
    encoded: data["encoded"] !== undefined ? decodeBase64(data["encoded"] as string) : undefined,
  };
}

export interface GeostorePolyLineProto {
  /**
   * Field-level metadata for this polyline. NOTE: there are multiple
   * PolyLineProto fields in the Geo Schema. Metadata here is only expected to
   * be present on FeatureProto.polyline[].
   */
  metadata?: GeostoreFieldMetadataProto;
  /**
   * A place for clients to attach arbitrary data to a polyline. Never set in
   * MapFacts.
   */
  temporaryData?: Proto2BridgeMessageSet;
  /**
   * A sequence of vertices connected by geodesics (the equivalent of straight
   * lines on the sphere). Adjacent vertices are connected by the shorter of the
   * two geodesics that connect them, i.e. all edges are 180 degrees or less.
   * Note that the edge definition becomes numerically unstable as the arc
   * length approaches 180 degrees. Polylines are generally expected to be
   * non-self-intersecting, but any such restriction is imposed by the user of
   * the polyline rather than the polyline itself.
   */
  vertex?: GeostorePointProto[];
}

/**
 * A pose is an object's position in space, as well as its orientation. All
 * fields except lat and lng are optional. All fields are in the WGS-84
 * ellipsoid, and rotations are right-hand rule (i.e. if the right hand thumb
 * points along a vector, curled fingers indicate positive rotation direction).
 * An un-rotated pose would be pointing due North, along the surface of the
 * ellipsoid. Rotations are applied in the order: yaw, pitch, roll. Note that
 * the rotation axes are rotated along with the model for each rotation step.
 * WARNING: This proto is not meant to be used directly. Please use the provided
 * libraries: //geostore/base/public/pose.h
 * //java/com/google/geostore/base/Pose.java
 */
export interface GeostorePoseProto {
  /**
   * The height of the pose. A positive height is above the WGS-84 ellipsoid in
   * meters; negative is below.
   */
  altitude?: number;
  /**
   * The index of the PoseProto in a list of PoseProtos.
   */
  index?: number;
  /**
   * The latitude of the pose in degrees [-90, 90].
   */
  lat?: number;
  /**
   * The longitude of the pose in degrees (-180,180].
   */
  lng?: number;
  /**
   * The rotation around the longitude line East tangent in degrees [-90, 90].
   */
  pitch?: number;
  /**
   * The rotation around the latitude line North tangent in degrees (-180,
   * 180].
   */
  roll?: number;
  /**
   * The rotation around the Up vector, from North, in degrees (-180, 180].
   */
  yaw?: number;
}

/**
 * This message represents nutrition facts for a food dish.
 */
export interface GeostorePriceInfoFoodNutritionFacts {
  calories?: GeostorePriceInfoFoodNutritionFactsCaloriesFact;
  /**
   * Cholesterol information for a given food dish.
   */
  cholesterol?: GeostorePriceInfoFoodNutritionFactsNutritionFact;
  /**
   * Protein information for a given food dish.
   */
  protein?: GeostorePriceInfoFoodNutritionFactsNutritionFact;
  /**
   * Sodium information for a given food dish.
   */
  sodium?: GeostorePriceInfoFoodNutritionFactsNutritionFact;
  /**
   * Carbohydrate information for a given food dish.
   */
  totalCarbohydrate?: GeostorePriceInfoFoodNutritionFactsNutritionFact;
  /**
   * Fat information for a given food dish.
   */
  totalFat?: GeostorePriceInfoFoodNutritionFactsNutritionFact;
}

/**
 * This message denotes calories information with an upper bound and lower
 * bound range.
 */
export interface GeostorePriceInfoFoodNutritionFactsCaloriesFact {
  lowerAmount?: number;
  /**
   * Unit of the given calories information.
   */
  unit?:  | "UNDEFINED_ENERGY_UNIT" | "CALORIE" | "JOULE";
  upperAmount?: number;
}

/**
 * This message denotes nutrition information with an upper bound and lower
 * bound range and can be represented by mass unit.
 */
export interface GeostorePriceInfoFoodNutritionFactsNutritionFact {
  lowerAmount?: number;
  /**
   * Unit of the given nutrition information.
   */
  unit?:  | "UNDEFINED_MASS_UNIT" | "GRAM" | "MILLIGRAM";
  upperAmount?: number;
}

export interface GeostorePriceInfoProto {
  /**
   * The actual food menus. This is a repeated field because a restaurant may
   * offer multiple menus, e.g. for different language or for different
   * available time, such as holidays vs non-holidays.
   */
  priceList?: GeostorePriceListProto[];
  /**
   * All URLs that give price list information for this establishment. For food
   * menus, this would represent menu_urls. Note that this field is a repeated
   * list of UrlListProtos. Each UrlListProto instance in the list is intended
   * to hold lists of URLs that are translations of the same URL.
   */
  priceListUrl?: GeostoreUrlListProto[];
  /**
   * Message containing metadata about the verified status of the PriceInfo.
   * Only verified listings should be displayed.
   */
  status?: GeostorePriceInfoStatus;
}

function serializeGeostorePriceInfoProto(data: any): GeostorePriceInfoProto {
  return {
    ...data,
    priceList: data["priceList"] !== undefined ? data["priceList"].map((item: any) => (serializeGeostorePriceListProto(item))) : undefined,
  };
}

function deserializeGeostorePriceInfoProto(data: any): GeostorePriceInfoProto {
  return {
    ...data,
    priceList: data["priceList"] !== undefined ? data["priceList"].map((item: any) => (deserializeGeostorePriceListProto(item))) : undefined,
  };
}

/**
 * Providers of PriceInfo (e.g. SinglePlatform, YEXT) send verified and
 * unverified listings. PriceInfoStatus is used to encapsulate this information.
 */
export interface GeostorePriceInfoStatus {
  isVerified?: boolean;
}

/**
 * A PriceListNameInfoProto is used by PriceListProto and fields and messages
 * contained in it for storing names, descriptions, languages, and IDs. The name
 * field and the description field must be in the same language, as specified by
 * the language field. None of the fields in this proto is required, although it
 * is not expected to have the language field set unless there is a name or
 * description. When the language field is not set, it is understood to be the
 * preferred language of the locale where the establishment is located. An empty
 * string for any of the fields is not allowed (as enforced by lints).
 */
export interface GeostorePriceListNameInfoProto {
  description?: string;
  /**
   * IDs are intended to be unique identifiers of PriceInfoLists, Sections, and
   * Menu items. This is enforced by the ID_DUPLICATE_PRICE_LIST_ID lint.
   */
  id?: string;
  /**
   * The external form of a Google International Identifiers Initiative (III)
   * LanguageCode object. See google3/i18n/identifiers/languagecode.h for
   * details. We place extra restrictions on languages in addition to what the
   * III library requires. See
   * go/geo-schema-reference/feature-properties/languages.
   */
  language?: string;
  name?: string;
}

/**
 * A PriceListProto can be used to represent any type of price lists, one of
 * which is a menu of food and drinks. It contains names and descriptions,
 * together with its source URL list if it is extracted or attributed to that
 * URL. The names and descriptions are represented using repeated
 * PriceListNameInfo fields to allow versions in different languages. A
 * PriceListProto may contain multiple sections; in the context of a food menu,
 * this would be multiple menu sections, e.g. for breakfast, lunch, dinner, prix
 * fixe, or dinner for two, etc. At least one menu section must be present. Each
 * section contains a number of items; for food menus, it may be FoodMenuItems
 * defined below. At least one item must be present in each section.
 */
export interface GeostorePriceListProto {
  /**
   * For third party lists, represents the ID of the aggregator which provided
   * this data. Optional.
   */
  aggregatorId?: bigint;
  /**
   * The time period when this price list is available. Establishments are not
   * required to give available_time for any given price list, however, when
   * this field is not set, the price list is understood as available any time
   * the establishment is open.
   */
  availableTime?: GeostoreTimeScheduleProto;
  /**
   * Cuisine information if the location the price lists attached to is an
   * eligible feature for a food menu price list. Cuisine information should
   * also only show up in a food price list.
   */
  cuisines?:  | "CUISINE_UNDEFINED" | "FAST_FOOD" | "AMERICAN" | "JAPANESE" | "BREAK_FAST" | "PIZZA" | "HAMBURGER" | "ITALIAN" | "SEAFOOD" | "FAMILY" | "MEXICAN" | "CHINESE" | "VEGETARIAN" | "SUSHI" | "CHICKEN" | "INDIAN" | "ASIAN" | "MEDITERRANEAN" | "FRENCH" | "BRUNCH" | "KOREAN" | "THAI" | "SPANISH" | "VIETNAMESE" | "LATIN_AMERICAN" | "INDONESIAN" | "GREEK" | "GERMAN" | "TURKISH" | "BRAZILIAN" | "PAKISTANI" | "OTHER_CUISINE"[];
  /**
   * The repeated name_info field is for price lists listed in multiple
   * languages. When a price list has no names or descriptions, the size of the
   * repeated field name_info may be 0. There should be at most one name_info
   * for any given language.
   */
  nameInfo?: GeostorePriceListNameInfoProto[];
  /**
   * Each price list may have multiple sections. Note that these sections
   * within the same price list should most times contain only the same type of
   * items for sale, e.g. all sections should usually contain only food items if
   * the enclosing price list is representing food menu. However, sometimes such
   * a requirement may be wrong, for example, McDonald's may sell burgers as
   * well as toys, and the toys may be in its own section. Thus we don't enforce
   * any requirement that all sections contain only the same type of items.
   */
  section?: GeostorePriceListSectionProto[];
  /**
   * Where this price list comes from. If set, this must also be a member of
   * the price_list_url field, and represents translations of a single URL.
   */
  sourceUrl?: GeostoreUrlListProto;
}

function serializeGeostorePriceListProto(data: any): GeostorePriceListProto {
  return {
    ...data,
    aggregatorId: data["aggregatorId"] !== undefined ? String(data["aggregatorId"]) : undefined,
    section: data["section"] !== undefined ? data["section"].map((item: any) => (serializeGeostorePriceListSectionProto(item))) : undefined,
  };
}

function deserializeGeostorePriceListProto(data: any): GeostorePriceListProto {
  return {
    ...data,
    aggregatorId: data["aggregatorId"] !== undefined ? BigInt(data["aggregatorId"]) : undefined,
    section: data["section"] !== undefined ? data["section"].map((item: any) => (deserializeGeostorePriceListSectionProto(item))) : undefined,
  };
}

/**
 * A PriceListSectionProto is used to store a section of a PriceListProto. For
 * example, for a PriceListProto representing a food menu, a
 * PriceListSectionProto represents a menu section. Each PriceListSectionProto
 * contains a repeated list of items for sale; these items can be products or
 * services. Right now every section should contain items of one type.
 */
export interface GeostorePriceListSectionProto {
  /**
   * Call to action for the section.
   */
  callToAction?: GeostoreCallToActionProto;
  /**
   * To store food and drink items when the containing PriceListSectionProto is
   * a food menu section.
   */
  foodItem?: GeostoreFoodMenuItemProto[];
  /**
   * To store any items when the containing PriceListSectionProto is not food /
   * legacy services.
   */
  item?: GeostoreComposableItemProto[];
  /**
   * This has to have at most one value.
   */
  itemType?:  | "TYPE_ANY" | "TYPE_FOOD" | "TYPE_SERVICE" | "TYPE_PRODUCT" | "TYPE_JOB" | "TYPE_3P_JOB"[];
  /**
   * The external form of a Google International Identifiers Initiative (III)
   * LanguageCode object. See google3/i18n/identifiers/languagecode.h for
   * details. We place extra restrictions on languages in addition to what the
   * III library requires. See
   * go/geo-schema-reference/feature-properties/languages. When set, represents
   * the language of the section and its items. Any section and item level name
   * infos must match this language. Optional.
   */
  language?: string;
  /**
   * One or more media items (photos, videos, etc.) describing this section /
   * category.
   */
  media?: GeostoreMediaItemProto[];
  /**
   * The repeated name_info field is for price list sections listed in multiple
   * languages. When a price list section has no names or descriptions, the size
   * of the repeated field name_info may be 0. There should be at most one
   * name_info for any given language.
   */
  nameInfo?: GeostorePriceListNameInfoProto[];
}

function serializeGeostorePriceListSectionProto(data: any): GeostorePriceListSectionProto {
  return {
    ...data,
    item: data["item"] !== undefined ? data["item"].map((item: any) => (serializeGeostoreComposableItemProto(item))) : undefined,
  };
}

function deserializeGeostorePriceListSectionProto(data: any): GeostorePriceListSectionProto {
  return {
    ...data,
    item: data["item"] !== undefined ? data["item"].map((item: any) => (deserializeGeostoreComposableItemProto(item))) : undefined,
  };
}

/**
 * This message represents a price range of an attribute. The meaning of the
 * price bounds is domain specific. But mainly they are soft bounds for a normal
 * usage. E.g. "restaurant prices" are subject to an higher level of "soft"
 * bounds than "museum admission price"
 */
export interface GeostorePriceRangeProto {
  /**
   * Currency code for the price range: a valid currency code from
   * i18n/identifiers/currencycode.h. Lower and upper price are both assumed to
   * use the same currency.
   */
  currency?: string;
  /**
   * This message allows unbounded price ranges. e.g. Lower_price is undefined.
   * At least one of the two prices must be set for the price range to be
   * meaningful.
   */
  lowerPrice?: number;
  /**
   * clang-format on
   */
  units?:  | "ANY_UNITS" | "PER_USE" | "PER_PHONE_CALL" | "PER_RIDE" | "PER_TIME_UNIT" | "PER_SECOND" | "PER_MINUTE" | "PER_HOUR" | "PER_DAY" | "PER_NIGHT" | "PER_WEEK" | "PER_MONTH" | "PER_YEAR" | "PER_VOLUME_UNIT" | "PER_LITER" | "PER_GLASS" | "PER_BOTTLE" | "PER_POT" | "PER_LENGTH_UNIT" | "PER_CENTIMETER" | "PER_METER" | "PER_KILOMETER" | "PER_MASS_UNIT" | "PER_GRAM" | "PER_KILOGRAM" | "PER_OUNCE" | "PER_POUND";
  upperPrice?: number;
}

/**
 * PropertyValueStatusProto specifies what we know about a field corresponding
 * to FeaturePropertyId's value in the absence of any specific value. For now,
 * it just indicates when we know that there is no value. Eventually it might
 * also indicate that we know it has value, just not what it is, etc.
 */
export interface GeostorePropertyValueStatusProto {
  /**
   * The property ID whose value status is defined by this proto.
   */
  propertyId?: GeostoreFeaturePropertyIdProto;
  /**
   * `value_status` specifies whether the feature has a value for the property.
   * This should always be set to something other than the default value
   * (`PROPERTY_VALUE_STATUS_UNSPECIFIED`).
   */
  valueStatus?:  | "PROPERTY_VALUE_STATUS_UNSPECIFIED" | "HAS_NO_VALUE" | "HAS_UNKNOWN_VALUE";
}

function serializeGeostorePropertyValueStatusProto(data: any): GeostorePropertyValueStatusProto {
  return {
    ...data,
    propertyId: data["propertyId"] !== undefined ? serializeGeostoreFeaturePropertyIdProto(data["propertyId"]) : undefined,
  };
}

function deserializeGeostorePropertyValueStatusProto(data: any): GeostorePropertyValueStatusProto {
  return {
    ...data,
    propertyId: data["propertyId"] !== undefined ? deserializeGeostoreFeaturePropertyIdProto(data["propertyId"]) : undefined,
  };
}

/**
 * This is a minimal version of SourceInfoProto.
 */
export interface GeostoreProvenanceProto {
  /**
   * The dataset from which this the referenced data was created. The content
   * of this string will be determined by the data provider, and may encode
   * extra information, such as data confidence.
   */
  dataset?: string;
  /**
   * The data provider from which the referenced data was generated.
   */
  provider?:  | "PROVIDER_ANY" | "PROVIDER_UNKNOWN" | "PROVIDER_NAVTEQ" | "PROVIDER_TELE_ATLAS" | "PROVIDER_TELE_ATLAS_MULTINET" | "PROVIDER_TELE_ATLAS_CODEPOINT" | "PROVIDER_TELE_ATLAS_GEOPOST" | "PROVIDER_TELE_ATLAS_DATAGEO" | "PROVIDER_TELE_ATLAS_ADDRESS_POINTS" | "PROVIDER_TELCONTAR" | "PROVIDER_EUROPA" | "PROVIDER_ROYAL_MAIL" | "PROVIDER_GOOGLE" | "PROVIDER_GOOGLE_HAND_EDIT" | "PROVIDER_GOOGLE_BORDERS" | "PROVIDER_GOOGLE_SUBRANGE" | "PROVIDER_GOOGLE_GT_FUSION" | "PROVIDER_GOOGLE_ZAGAT_CMS" | "PROVIDER_GOOGLE_PLACE_NAVBOOST" | "PROVIDER_GOOGLE_FOOTPRINT" | "PROVIDER_GOOGLE_PRODUCT_TERMS" | "PROVIDER_GOOGLE_POINTCARDS" | "PROVIDER_GOOGLE_BUSINESS_CHAINS" | "PROVIDER_GOOGLE_LOCAL_SUMMARIZATION" | "PROVIDER_GOOGLE_PRONUNCIATIONS" | "PROVIDER_GOOGLE_DUMPLING" | "PROVIDER_GOOGLE_DISTILLERY" | "PROVIDER_GOOGLE_LOCAL_ATTRIBUTE_SUMMARIZATION" | "PROVIDER_GOOGLE_RELATION_MINER" | "PROVIDER_GOOGLE_MAPSPAM" | "PROVIDER_GOOGLE_ROSE" | "PROVIDER_GOOGLE_LOCAL_PLACE_RATINGS" | "PROVIDER_GOOGLE_WIPEOUT" | "PROVIDER_GOOGLE_KNOWLEDGE_GRAPH" | "PROVIDER_GOOGLE_BEEGEES" | "PROVIDER_GOOGLE_REVIEW_SUMMARIZATION" | "PROVIDER_GOOGLE_OFFLINE_NON_CORE_ATTRIBUTE_SUMMARIZATION" | "PROVIDER_GOOGLE_GEO_WORLDMAPS" | "PROVIDER_GOOGLE_GEO_MODERATION" | "PROVIDER_GOOGLE_OYSTER_AUTO_EDITS" | "PROVIDER_GOOGLE_LOCAL_ALCHEMY" | "PROVIDER_GOOGLE_KEROUAC" | "PROVIDER_GOOGLE_MOBRANK" | "PROVIDER_GOOGLE_RAPTURE" | "PROVIDER_GOOGLE_CULTURAL_INSTITUTE" | "PROVIDER_GOOGLE_GEOCODES_FROM_LOCAL_FEEDS" | "PROVIDER_GOOGLE_ATTRIBUTES_FROM_CRAWLED_CHAINS" | "PROVIDER_GOOGLE_TACTILE_MAPS" | "PROVIDER_GOOGLE_MAPS_FOR_MOBILE" | "PROVIDER_GOOGLE_GEO_REALTIME" | "PROVIDER_GOOGLE_PROMINENT_PLACES" | "PROVIDER_GOOGLE_PLACE_ACTIONS" | "PROVIDER_GOOGLE_GT_AUTO_EDITS" | "PROVIDER_GOOGLE_WAZE" | "PROVIDER_GOOGLE_ONTHEGO" | "PROVIDER_GOOGLE_GT_IMPORT" | "PROVIDER_GOOGLE_STRUCTURED_DATA" | "PROVIDER_GOOGLE_HELICOPTER" | "PROVIDER_GOOGLE_ROLLBACK" | "PROVIDER_GOOGLE_RIGHTS_REPAIR" | "PROVIDER_GOOGLE_PERFUME" | "PROVIDER_GOOGLE_MAPS_TRANSLATION" | "PROVIDER_GOOGLE_CALL_ME_MAYBE" | "PROVIDER_GOOGLE_LOCAL_UNIVERSAL" | "PROVIDER_GOOGLE_CROUPIER" | "PROVIDER_GOOGLE_SKYSMART" | "PROVIDER_GOOGLE_RIDDLER" | "PROVIDER_GOOGLE_ROADCLOSURES" | "PROVIDER_GOOGLE_SPORE" | "PROVIDER_GOOGLE_LOCALIZATION" | "PROVIDER_GOOGLE_CATTERMS" | "PROVIDER_GOOGLE_GT_FIELD_OPS" | "PROVIDER_GOOGLE_MATCHMAKER" | "PROVIDER_GOOGLE_ARBITRATION" | "PROVIDER_GOOGLE_BIZBUILDER_OPS" | "PROVIDER_GOOGLE_LOCAL_INVENTORY_ADS" | "PROVIDER_GOOGLE_GT_DRAFTY" | "PROVIDER_GOOGLE_HOTELADS_OPS" | "PROVIDER_GOOGLE_MARKERS" | "PROVIDER_GOOGLE_STATE_MACHINE" | "PROVIDER_GOOGLE_ATTRIBUTES_INFERENCE" | "PROVIDER_GOOGLE_BIKESHARE" | "PROVIDER_GOOGLE_GHOSTWRITER" | "PROVIDER_GOOGLE_EDIT_PLATFORM" | "PROVIDER_GOOGLE_BLUE_GINGER" | "PROVIDER_GOOGLE_GEO_TIGER" | "PROVIDER_GOOGLE_HYADES" | "PROVIDER_GOOGLE_WEBQUARRY" | "PROVIDER_GOOGLE_GEO_MADDEN" | "PROVIDER_GOOGLE_ANDROID_PAY" | "PROVIDER_GOOGLE_OPENING_HOURS_TEAM" | "PROVIDER_GOOGLE_LOCAL_DISCOVERY" | "PROVIDER_GOOGLE_LOCAL_HEALTH" | "PROVIDER_GOOGLE_UGC_MAPS" | "PROVIDER_GOOGLE_FIBER" | "PROVIDER_GOOGLE_REVGEO" | "PROVIDER_GOOGLE_HOTELADS_PARTNER_FRONT_END" | "PROVIDER_GOOGLE_GEO_UGC_TASKS" | "PROVIDER_GOOGLE_GEOCODING" | "PROVIDER_GOOGLE_SPYGLASS" | "PROVIDER_GOOGLE_PLUS_CODES_AS_ADDRESSES" | "PROVIDER_GOOGLE_GEO_CHANGES" | "PROVIDER_GOOGLE_HUME" | "PROVIDER_GOOGLE_MEGAMIND" | "PROVIDER_GOOGLE_GT_ROADSYNTH" | "PROVIDER_GOOGLE_FIREBOLT" | "PROVIDER_GOOGLE_LOCAL_PLACE_OFFERINGS" | "PROVIDER_GOOGLE_UGC_SERVICES" | "PROVIDER_GOOGLE_GEOALIGN" | "PROVIDER_GOOGLE_GT_COMPOUNDS" | "PROVIDER_GOOGLE_FOOD_ORDERING" | "PROVIDER_GOOGLE_HOTEL_KNOWLEDGE_OPS" | "PROVIDER_GOOGLE_URAW" | "PROVIDER_GOOGLE_FLYEYE" | "PROVIDER_GOOGLE_YOUKE" | "PROVIDER_GOOGLE_GT_ZEPHYR" | "PROVIDER_GOOGLE_USER_SAFETY" | "PROVIDER_GOOGLE_ADDRESS_MAKER" | "PROVIDER_GOOGLE_UGC_PHOTOS" | "PROVIDER_GOOGLE_GT_WINDCHIME" | "PROVIDER_GOOGLE_SNAG_FIXER" | "PROVIDER_GOOGLE_GEO_DEALS" | "PROVIDER_GOOGLE_LOCAL_PLACE_TOPICS" | "PROVIDER_GOOGLE_PROPERTY_INSIGHTS" | "PROVIDER_GOOGLE_GEO_CONSUMER_MERCHANT_EXPERIMENTS" | "PROVIDER_GOOGLE_GEO_PORTKEY" | "PROVIDER_GOOGLE_ROAD_MAPPER" | "PROVIDER_GOOGLE_LOCATION_PLATFORM" | "PROVIDER_GOOGLE_POSTTRIP" | "PROVIDER_GOOGLE_TRAVEL_DESTINATION" | "PROVIDER_GOOGLE_GEO_DATA_UPLOAD" | "PROVIDER_GOOGLE_BIZBUILDER_CLEANUP" | "PROVIDER_GOOGLE_USER" | "PROVIDER_GOOGLE_STATION" | "PROVIDER_GOOGLE_GEO_FOOD" | "PROVIDER_GOOGLE_GEO_AR" | "PROVIDER_GOOGLE_GEO_TEMPORAL" | "PROVIDER_GOOGLE_SERVICES_MARKETPLACE" | "PROVIDER_GOOGLE_IMT_CLEANUP" | "PROVIDER_GOOGLE_GEO_FOOD_MENU" | "PROVIDER_GOOGLE_CARENAV" | "PROVIDER_GOOGLE_DRIVING_FEEDS" | "PROVIDER_GOOGLE_DRIVING_UGC" | "PROVIDER_GOOGLE_POLAR" | "PROVIDER_GOOGLE_TRIWILD" | "PROVIDER_GOOGLE_CROWD_COMPUTE_OPS" | "PROVIDER_GOOGLE_SA_FROM_WEB" | "PROVIDER_GOOGLE_POI_ALIGNMENT" | "PROVIDER_GOOGLE_SA_FROM_HULK" | "PROVIDER_GOOGLE_SERVICES_INTERACTIONS" | "PROVIDER_GOOGLE_ROADS_UGC_EDITOR" | "PROVIDER_GOOGLE_SA_FROM_NG_INFERENCE" | "PROVIDER_GOOGLE_GEO_DRIVING_VIZ" | "PROVIDER_GOOGLE_GEO_TASKING" | "PROVIDER_GOOGLE_CROWDTASK_DATACOMPUTE" | "PROVIDER_GOOGLE_CROWDTASK_TASKADS" | "PROVIDER_GOOGLE_CROWDTASK_TASKMATE" | "PROVIDER_GOOGLE_CROWDTASK_FURBALL" | "PROVIDER_GOOGLE_CROWDTASK_ADAP" | "PROVIDER_GOOGLE_GPAY" | "PROVIDER_GOOGLE_GEO_UGC_TRUSTED_USERS" | "PROVIDER_GOOGLE_THIRD_PARTY_DATA_PRODUCTION" | "PROVIDER_GOOGLE_GEOTRACKER" | "PROVIDER_GOOGLE_LOCAL_LANDMARK_INFERENCE" | "PROVIDER_GOOGLE_GEO_CLOSED_LOOP" | "PROVIDER_GOOGLE_SA_FROM_MERCHANT_POSTS" | "PROVIDER_GOOGLE_CORE_DATA_RIGHTS" | "PROVIDER_GOOGLE_SA_FROM_USER_REVIEWS" | "PROVIDER_GOOGLE_GEO_CONTENT_FIXER" | "PROVIDER_GOOGLE_POLYGON_REFINEMENT" | "PROVIDER_GOOGLE_HANASU" | "PROVIDER_GOOGLE_FULLRIGHTS_GEO_DATA_UPLOAD" | "PROVIDER_GOOGLE_FULLRIGHTS_3P_OUTREACH_UPLOAD" | "PROVIDER_GOOGLE_ATTRIBUTION_3P_OUTREACH_UPLOAD" | "PROVIDER_GOOGLE_SA_FROM_FOOD_MENUS" | "PROVIDER_GOOGLE_GT_CONSISTENCY_EDITS" | "PROVIDER_GOOGLE_SA_QUALITY" | "PROVIDER_GOOGLE_GDCE_CLEANUP" | "PROVIDER_GOOGLE_UGC_QUALITY_CHAINS" | "PROVIDER_GOOGLE_ATTRIBUTES_DISCOVERY" | "PROVIDER_GOOGLE_GEO_LDE" | "PROVIDER_GOOGLE_GEO_SIGNAL_TRACKING" | "PROVIDER_GOOGLE_UGC_AGGREGATION" | "PROVIDER_GOOGLE_3D_BASEMAP" | "PROVIDER_GOOGLE_MAPFACTS_PRIVACY" | "PROVIDER_GOOGLE_GT_ALF" | "PROVIDER_GOOGLE_GT_OPERATOR_PROVENANCE" | "PROVIDER_GOOGLE_LOCAL_SERVICES_ADS" | "PROVIDER_GOOGLE_LOCALSEARCH" | "PROVIDER_GOOGLE_TRANSIT" | "PROVIDER_GOOGLE_GEOWIKI" | "PROVIDER_GOOGLE_CHINA_LOCAL_TEAM" | "PROVIDER_GOOGLE_SYNTHESIZED" | "PROVIDER_GOOGLE_INTERNAL_TEST" | "PROVIDER_GOOGLE_DISPUTED_AREAS" | "PROVIDER_GOOGLE_3DWAREHOUSE" | "PROVIDER_GOOGLE_GROUNDS_BUILDER" | "PROVIDER_GOOGLE_SESAME" | "PROVIDER_GOOGLE_GT" | "PROVIDER_GOOGLE_GT_BASEMAP_UPLOAD" | "PROVIDER_GOOGLE_ADSDB" | "PROVIDER_GOOGLE_MACHINE_TRANSLITERATION" | "PROVIDER_GOOGLE_TRAVELSEARCH" | "PROVIDER_GOOGLE_PANORAMIO" | "PROVIDER_GOOGLE_YOUTUBE" | "PROVIDER_GOOGLE_OLD" | "PROVIDER_GOOGLE_STREETVIEW" | "PROVIDER_GOOGLE_STREETVIEW_BIZVIEW" | "PROVIDER_GOOGLE_ZIPIT" | "PROVIDER_GOOGLE_OYSTER_CONNECT_ROUTES" | "PROVIDER_GOOGLE_GOLDEN" | "PROVIDER_GOOGLE_INNERSPACE" | "PROVIDER_GOOGLE_MAPSEARCH" | "PROVIDER_GOOGLE_CATEGORIES_TEAM" | "PROVIDER_GOOGLE_CROWDSENSUS" | "PROVIDER_GOOGLE_LOCAL_ALGORITHMIC_IDENTITY" | "PROVIDER_GOOGLE_FREEBASE" | "PROVIDER_GOOGLE_HOTELADS" | "PROVIDER_GOOGLE_AUTHORITY_PAGES" | "PROVIDER_GOOGLE_PLACES_API" | "PROVIDER_GOOGLE_NAMEHEATMAP" | "PROVIDER_GOOGLE_MAPMAKER" | "PROVIDER_GOOGLE_MAPMAKER_MOBILE" | "PROVIDER_GOOGLE_MAPMAKER_PANCAKE" | "PROVIDER_GOOGLE_MAPMAKER_V2" | "PROVIDER_GOOGLE_LOCAL_CLUSTERING_OPERATOR_OVERRIDE" | "PROVIDER_GOOGLE_SERVED_ON_MAPMAKER" | "PROVIDER_GOOGLE_GT_LOCAL" | "PROVIDER_GOOGLE_GT_LOCAL_WITH_RIGHTS" | "PROVIDER_GOOGLE_LOGS_RANKING_SIGNALS" | "PROVIDER_GOOGLE_ENTITY_NAVBOOST" | "PROVIDER_GOOGLE_RELATED_PLACES" | "PROVIDER_GOOGLE_KNOWN_FOR_TERMS" | "PROVIDER_GOOGLE_SYNTHETIC_AREAS" | "PROVIDER_GOOGLE_AUTHORITY_PAGE_PHOTOS" | "PROVIDER_GOOGLE_CROSS_STREETS" | "PROVIDER_GOOGLE_CORRIDORS" | "PROVIDER_GOOGLE_BICYCLE_RENTAL" | "PROVIDER_GOOGLE_CONCRETE_URLS" | "PROVIDER_GOOGLE_LEANBACK" | "PROVIDER_GOOGLE_LOCKED_LISTINGS" | "PROVIDER_GOOGLE_MONITORING" | "PROVIDER_GOOGLE_SPROUT" | "PROVIDER_GOOGLE_LOCAL_SEARCH_QUALITY" | "PROVIDER_GOOGLE_GOBY" | "PROVIDER_GOOGLE_PROBLEM_REPORT" | "PROVIDER_GOOGLE_CANDID" | "PROVIDER_GOOGLE_BIZBUILDER" | "PROVIDER_AUTOMOTIVE_NAVIGATION_DATA" | "PROVIDER_MAPDATA_SCIENCES" | "PROVIDER_MAPONICS" | "PROVIDER_SKI_RESORTS" | "PROVIDER_ZENRIN" | "PROVIDER_SANBORN" | "PROVIDER_URBAN_MAPPING" | "PROVIDER_US_GOVERNMENT" | "PROVIDER_US_CENSUS" | "PROVIDER_US_POSTAL_SERVICE" | "PROVIDER_US_GEOLOGICAL_SURVEY" | "PROVIDER_US_GNIS" | "PROVIDER_US_LANDSAT" | "PROVIDER_US_NATIONAL_GEOSPATIAL_INTELLIGENCE_AGENCY" | "PROVIDER_US_NGA_GNS" | "PROVIDER_US_SSIBL" | "PROVIDER_US_BUREAU_OF_TRANSPORTATION_STATISTICS" | "PROVIDER_US_NATIONAL_OCEANIC_AND_ATMOSPHERIC_ADMINISTRATION" | "PROVIDER_US_POLAR_GEOSPATIAL_CENTER" | "PROVIDER_US_DEPARTMENT_OF_AGRICULTURE" | "PROVIDER_US_NPI_REGISTRY" | "PROVIDER_US_BUREAU_OF_INDIAN_AFFAIRS" | "PROVIDER_DMTI_SPATIAL" | "PROVIDER_INTERNATIONAL_HYDROGRAPHIC_ORGANIZATION" | "PROVIDER_MAPLINK" | "PROVIDER_KINGWAY" | "PROVIDER_GEOCENTRE" | "PROVIDER_CN_NATIONAL_FOUNDAMENTAL_GIS" | "PROVIDER_CN_MAPABC" | "PROVIDER_SMITHSONIAN_INSTITUTE" | "PROVIDER_TRACKS_FOR_AFRICA" | "PROVIDER_PPWK" | "PROVIDER_LEADDOG" | "PROVIDER_CENTRE_DONNEES_ASTRONOMIQUES_STRASBOURG" | "PROVIDER_GISRAEL" | "PROVIDER_BASARSOFT" | "PROVIDER_MAPINFO" | "PROVIDER_MAPIT" | "PROVIDER_GEOBASE" | "PROVIDER_ORION" | "PROVIDER_CENTRAL_EUROPEAN_DATA_AGENCY" | "PROVIDER_ANASAT" | "PROVIDER_MINED_POSTCODES" | "PROVIDER_DMAPAS" | "PROVIDER_COMMON_LOCALE_DATA_REPOSITORY" | "PROVIDER_CH_SBB" | "PROVIDER_SKENERGY" | "PROVIDER_GBRMPA" | "PROVIDER_KOREA_POST" | "PROVIDER_CN_AUTONAVI" | "PROVIDER_MINED_POI" | "PROVIDER_ML_INFOMAP" | "PROVIDER_SNOOPER" | "PROVIDER_GEOSISTEMAS" | "PROVIDER_AFRIGIS" | "PROVIDER_TRANSNAVICOM" | "PROVIDER_EASYCONNECT" | "PROVIDER_LANTMATERIET" | "PROVIDER_LOGICA" | "PROVIDER_MAPKING" | "PROVIDER_DIANPING" | "PROVIDER_GEONAV" | "PROVIDER_HEIBONSHA" | "PROVIDER_DEUTSCHE_TELEKOM" | "PROVIDER_LINGUISTIC_DATA_CONSORTIUM" | "PROVIDER_ACXIOM" | "PROVIDER_DUN_AND_BRADSTREET" | "PROVIDER_FEDERAL_AVIATION_ADMINISTRATION" | "PROVIDER_INFOUSA" | "PROVIDER_INFOUSA_NIXIE" | "PROVIDER_THOMSON_LOCAL" | "PROVIDER_TELEFONICA_PUBLICIDAD_E_INFORMACION" | "PROVIDER_WIKIPEDIA" | "PROVIDER_INFOBEL" | "PROVIDER_MX_GOVERNMENT" | "PROVIDER_MX_NATIONAL_INSTITUTE_STATISTICS_GEOGRAPHY" | "PROVIDER_MX_SERVICIO_POSTAL_MEXICANO" | "PROVIDER_TELEGATE" | "PROVIDER_TELELISTAS" | "PROVIDER_MAPCITY" | "PROVIDER_EXPLAINER_DC" | "PROVIDER_DAIKEI" | "PROVIDER_NL_CHAMBER_OF_COMMERCE" | "PROVIDER_KOREA_INFO_SERVICE" | "PROVIDER_WIKITRAVEL" | "PROVIDER_FLICKR" | "PROVIDER_DIANCO" | "PROVIDER_VOLT_DELTA" | "PROVIDER_SG_GOVERNMENT" | "PROVIDER_SG_LAND_TRANSPORT_AUTHORITY" | "PROVIDER_MAPBAR" | "PROVIDER_LONGTU" | "PROVIDER_SA_GOVERNMENT" | "PROVIDER_SA_SAUDI_POST" | "PROVIDER_PEAKLIST" | "PROVIDER_LOCAL_BUSINESS_CENTER" | "PROVIDER_LOCAL_FEED_XML" | "PROVIDER_WEB" | "PROVIDER_RAILS_TO_TRAILS" | "PROVIDER_INDIACOM" | "PROVIDER_INFOMEDIA" | "PROVIDER_PICASA" | "PROVIDER_AT_GOVERNMENT" | "PROVIDER_AT_BUNDESAMT_FUR_EICH_UND_VERMESSUNGSWESEN" | "PROVIDER_AT_NATIONAL_TOURIST_OFFICE" | "PROVIDER_AT_AUSTRIA_POST" | "PROVIDER_NO_GOVERNMENT" | "PROVIDER_NO_NORSK_EIENDOMSINFORMASJON" | "PROVIDER_NO_POSTEN_NORGE_AS" | "PROVIDER_CH_GOVERNMENT" | "PROVIDER_CH_SWISS_POST" | "PROVIDER_CH_SWISSTOPO" | "PROVIDER_CH_SWISS_NATIONAL_PARK" | "PROVIDER_NAVIT" | "PROVIDER_GEOSEARCH" | "PROVIDER_DE_GOVERNMENT" | "PROVIDER_BUNDESAMT_KARTOGRAPHIE_UND_GEODASIE" | "PROVIDER_BUNDESNETZAGENTUR" | "PROVIDER_SCHOBER_GROUP" | "PROVIDER_MIREO" | "PROVIDER_PUBLIC_MUNICIPALITY" | "PROVIDER_US_PUBLIC_MUNICIPALITY" | "PROVIDER_US_PUBLIC_MUNICIPALITY_WEBSTER_TEXAS" | "PROVIDER_US_PUBLIC_MUNICIPALITY_AMHERST_MASSACHUSETTS" | "PROVIDER_US_PUBLIC_MUNICIPALITY_BLOOMINGTON_INDIANA" | "PROVIDER_US_PUBLIC_MUNICIPALITY_PASADENA_CALIFORNIA" | "PROVIDER_US_PUBLIC_MUNICIPALITY_CHULA_VISTA_CALIFORNIA" | "PROVIDER_US_PUBLIC_MUNICIPALITY_TEMPE_ARIZONA" | "PROVIDER_US_PUBLIC_MUNICIPALITY_COLUMBUS_OHIO" | "PROVIDER_US_PUBLIC_MUNICIPALITY_PORTAGE_MICHIGAN" | "PROVIDER_US_PUBLIC_MUNICIPALITY_GEORGETOWN_KENTUCKY" | "PROVIDER_US_PUBLIC_MUNICIPALITY_GREENVILLE_SOUTH_CAROLINA" | "PROVIDER_US_PUBLIC_MUNICIPALITY_NASHVILLE_TENNESSEE" | "PROVIDER_US_PUBLIC_MUNICIPALITY_WASHINGTON_DISTRICT_OF_COLUMBIA" | "PROVIDER_US_PUBLIC_MUNICIPALITY_BOULDER_COLORADO" | "PROVIDER_NZ_PUBLIC_MUNICIPALITY" | "PROVIDER_NZ_PUBLIC_MUNICIPALITY_ENVIRONMENT_BAY" | "PROVIDER_PL_PUBLIC_MUNICIPALITY" | "PROVIDER_PL_PUBLIC_MUNICIPALITY_BIELSKO_BIALA" | "PROVIDER_DE_PUBLIC_MUNICIPALITY" | "PROVIDER_DE_PUBLIC_MUNICIPALITY_FRANKFURT" | "PROVIDER_DE_PUBLIC_MUNICIPALITY_HAMBURG" | "PROVIDER_DE_PUBLIC_MUNICIPALITY_KARLSRUHE" | "PROVIDER_PT_PUBLIC_MUNICIPALITY" | "PROVIDER_PT_PUBLIC_MUNICIPALITY_SANTA_CRUZ" | "PROVIDER_AT_PUBLIC_MUNICIPALITY" | "PROVIDER_AT_PUBLIC_MUNICIPALITY_KLAGENFURT" | "PROVIDER_AT_PUBLIC_MUNICIPALITY_LINZ" | "PROVIDER_ES_PUBLIC_MUNICIPALITY" | "PROVIDER_ES_PUBLIC_MUNICIPALITY_AZKOITIA" | "PROVIDER_ES_PUBLIC_MUNICIPALITY_BEASAIN" | "PROVIDER_ES_PUBLIC_MUNICIPALITY_GIRONA" | "PROVIDER_ES_PUBLIC_MUNICIPALITY_SAN_SEBASTIAN" | "PROVIDER_ES_PUBLIC_MUNICIPALITY_CATALUNYA" | "PROVIDER_ES_PUBLIC_MUNICIPALITY_HONDARRIBIA" | "PROVIDER_AU_PUBLIC_MUNICIPALITY" | "PROVIDER_AU_PUBLIC_MUNICIPALITY_LAUNCESTON_TASMANIA" | "PROVIDER_IS_PUBLIC_MUNICIPALITY" | "PROVIDER_IS_PUBLIC_MUNICIPALITY_REYKJAVIK" | "PROVIDER_NL_PUBLIC_MUNICIPALITY" | "PROVIDER_NL_PUBLIC_MUNICIPALITY_AMELSTEVEEN" | "PROVIDER_BE_PUBLIC_MUNICIPALITY" | "PROVIDER_BE_PUBLIC_MUNICIPALITY_ANTWERPEN" | "PROVIDER_CA_PUBLIC_MUNICIPALITY" | "PROVIDER_CA_PUBLIC_MUNICIPALITY_FREDERICTON_NEW_BRUNSWICK" | "PROVIDER_CA_PUBLIC_MUNICIPALITY_KAMLOOPS_BRITISH_COLUMBIA" | "PROVIDER_CA_PUBLIC_MUNICIPALITY_NANAIMO_BRITISH_COLUMBIA" | "PROVIDER_CA_PUBLIC_MUNICIPALITY_BANFF_ALBERTA" | "PROVIDER_CA_PUBLIC_MUNICIPALITY_CALGARY_ALBERTA" | "PROVIDER_CA_PUBLIC_MUNICIPALITY_TORONTO_ONTARIO" | "PROVIDER_SE_PUBLIC_MUNICIPALITY" | "PROVIDER_SE_PUBLIC_MUNICIPALITY_UMEA" | "PROVIDER_UA_PUBLIC_MUNICIPALITY" | "PROVIDER_UA_PUBLIC_MUNICIPALITY_KHARKIV" | "PROVIDER_OTHER_PUBLIC_MUNICIPALITY" | "PROVIDER_OTHER_PUBLIC_MUNICIPALITY_AQUA_CALIENTE_CAHUILLA_INDIANS" | "PROVIDER_FR_PUBLIC_MUNICIPALITY" | "PROVIDER_FR_PUBLIC_MUNICIPALITY_PONT_AUDEMER" | "PROVIDER_FR_PUBLIC_MUNICIPALITY_BORDEAUX" | "PROVIDER_SG_PUBLIC_MUNICIPALITY" | "PROVIDER_BR_PUBLIC_MUNICIPALITY" | "PROVIDER_BR_PUBLIC_MUNICIPALITY_RIO_DE_JANEIRO" | "PROVIDER_MAPCUBE" | "PROVIDER_3D_REALITYMAPS" | "PROVIDER_DEUTSCHES_ZENTRUM_FUR_LUFT_UND_RAUMFAHRT" | "PROVIDER_3D_CITIES_SOCIEDADE_ANONIMA" | "PROVIDER_DISNEY" | "PROVIDER_CYBERCITY" | "PROVIDER_PRECISION_LIGHTWORKS_MODELWORKS" | "PROVIDER_VIRTUAL_HUNGARY_LIMITED" | "PROVIDER_VIRTUEL_CITY" | "PROVIDER_SCREAMPOINT_INTERNATIONAL" | "PROVIDER_AGENTSCHAP_VOOR_GEOGRAFISCHE_INFORMATIE_VLAANDEREN" | "PROVIDER_FR_GOVERNMENT" | "PROVIDER_FR_INSTITUT_GEOGRAPHIQUE_NATIONAL" | "PROVIDER_FR_CADASTRE" | "PROVIDER_DIADIEM" | "PROVIDER_THE_WEATHER_CHANNEL" | "PROVIDER_COWI" | "PROVIDER_FALKPLAN_ANDES" | "PROVIDER_NL_GOVERNMENT" | "PROVIDER_NL_KADASTER" | "PROVIDER_NL_BOARD_OF_TOURISM_AND_CONVENTIONS" | "PROVIDER_DIGITAL_MAP_PRODUCTS" | "PROVIDER_SILICE_DIGITAL" | "PROVIDER_TYDAC" | "PROVIDER_ALBRECHT_GOLF" | "PROVIDER_HEALTH_CH" | "PROVIDER_VISITDENMARK" | "PROVIDER_FLYHERE" | "PROVIDER_DIGITAL_DATA_SERVICES" | "PROVIDER_MECOMO" | "PROVIDER_ZA_GOVERNMENT" | "PROVIDER_ZA_RURAL_DEVELOPMENT_LAND_REFORM" | "PROVIDER_SENSIS" | "PROVIDER_JJCONNECT" | "PROVIDER_OPPLYSNINGEN" | "PROVIDER_TELLUS" | "PROVIDER_IQONIA" | "PROVIDER_BE_GOVERNMENT" | "PROVIDER_BE_NATIONAAL_GEOGRAFISCH_INSTITUUT" | "PROVIDER_BE_BRUSSELS_MOBILITY" | "PROVIDER_YELLOWMAP_AG" | "PROVIDER_STIFTUNG_GESUNDHEIT" | "PROVIDER_GIATA" | "PROVIDER_SANPARKS" | "PROVIDER_CENTRE_DINFORMATIQUE_POUR_LA_REGION_BRUXELLOISE" | "PROVIDER_INFOPORTUGAL" | "PROVIDER_NEGOCIOS_DE_TELECOMUNICACOES_E_SISTEMAS_DE_INFORMACAO" | "PROVIDER_COLLINS_BARTHOLOMEW" | "PROVIDER_PROTECT_PLANET_OCEAN" | "PROVIDER_KARTTAKESKUS" | "PROVIDER_FI_GOVERNMENT" | "PROVIDER_FI_NATIONAL_ROAD_ADMINISTRATION" | "PROVIDER_FI_NATIONAL_LAND_SURVEY" | "PROVIDER_FI_STATISTICS_FINLAND" | "PROVIDER_GB_GOVERNMENT" | "PROVIDER_GB_ORDNANCE_SURVEY" | "PROVIDER_NATURAL_ENGLAND" | "PROVIDER_WELSH_GOVERNMENT" | "PROVIDER_GB_OFFICE_FOR_NATIONAL_STATISTICS" | "PROVIDER_EPSILON" | "PROVIDER_PARTNER_FRONT_END" | "PROVIDER_CARTESIA" | "PROVIDER_SE_GOVERNMENT" | "PROVIDER_SE_TRAFIKVERKET" | "PROVIDER_SE_NATURVARDSVERKET" | "PROVIDER_IE_GOVERNMENT" | "PROVIDER_IE_ORDNANCE_SURVEY_IRELAND" | "PROVIDER_LU_GOVERNMENT" | "PROVIDER_LU_P_AND_T_LUXEMBOURG" | "PROVIDER_LU_ADMINISTRATION_DU_CADASTRE_ET_DE_LA_TOPOGRAPHIE" | "PROVIDER_LU_NATIONAL_TOURIST_OFFICE" | "PROVIDER_MAPFLOW" | "PROVIDER_TKARTOR" | "PROVIDER_JUMPSTART" | "PROVIDER_EPTISA" | "PROVIDER_MC_GOVERNMENT" | "PROVIDER_MC_PRINCIPAUTE_DE_MONACO" | "PROVIDER_MONOLIT" | "PROVIDER_ENVIRONMENTAL_SYSTEMS_RESEARCH_INSTITUTE" | "PROVIDER_MODIS" | "PROVIDER_GEOX" | "PROVIDER_GEODIRECTORY" | "PROVIDER_GEOPLAN" | "PROVIDER_INFODIREKT" | "PROVIDER_GEOGLOBAL" | "PROVIDER_DEUTSCHE_POST" | "PROVIDER_TRACASA" | "PROVIDER_CORREOS" | "PROVIDER_ES_GOVERNMENT" | "PROVIDER_ES_CENTRO_NACIONAL_DE_INFORMACION_GEOGRAFICA" | "PROVIDER_EDIMAP" | "PROVIDER_VERIZON" | "PROVIDER_NATIONAL_GEOGRAPHIC_MAPS" | "PROVIDER_PROMAPS" | "PROVIDER_CONSODATA" | "PROVIDER_DE_AGOSTINI" | "PROVIDER_FEDERPARCHI" | "PROVIDER_NAVIGO" | "PROVIDER_ITALIAMAPPE" | "PROVIDER_CZECOT" | "PROVIDER_NATURAL_EARTH" | "PROVIDER_REGIO" | "PROVIDER_SHIPWRECK_CENTRAL" | "PROVIDER_RUTGERS_STATE_UNIVERSITY" | "PROVIDER_TWINICE" | "PROVIDER_NORTHERN_IRELAND_TOURIST_BOARD" | "PROVIDER_INFOGROUP" | "PROVIDER_TNET" | "PROVIDER_CTT_CORREIOS_DE_PORTUGAL" | "PROVIDER_EUROPARC" | "PROVIDER_IUPPITER" | "PROVIDER_MICHAEL_BAUER_INTERNATIONAL" | "PROVIDER_LEPTON" | "PROVIDER_MAPPOINT" | "PROVIDER_GEODATA" | "PROVIDER_RU_GOVERNMENT" | "PROVIDER_RU_FNS_KLADR" | "PROVIDER_BR_GOVERNMENT" | "PROVIDER_BR_INSTITUTO_BRASILEIRO_DO_MEIO_AMBIENTE_E_DOS_RECURSOS_NATURAIS_RENOVAVEIS" | "PROVIDER_BR_MINISTERIO_DO_MEIO_AMBIENTE" | "PROVIDER_BR_AGENCIA_NACIONAL_DE_AGUAS" | "PROVIDER_BR_INSTITUTO_BRASILEIRO_DE_GEOGRAFIA_E_ESTATISTICA" | "PROVIDER_BR_FUNDACAO_NACIONAL_DO_INDIO" | "PROVIDER_BR_DEPARTAMENTO_NACIONAL_DE_INFRAESTRUTURA_DE_TRANSPORTES" | "PROVIDER_AZAVEA" | "PROVIDER_NORTHSTAR" | "PROVIDER_COMMEDI" | "PROVIDER_NEXUS_GEOGRAFICS" | "PROVIDER_INFOERA" | "PROVIDER_AD_GOVERNMENT" | "PROVIDER_AD_AREA_DE_CARTOGRAFIA" | "PROVIDER_MAXXIMA" | "PROVIDER_SI_GOVERNMENT" | "PROVIDER_SI_AGENCY_FOR_ENVIRONMENT" | "PROVIDER_TRANSPORT_HI_TECH_CONSULTANTS" | "PROVIDER_L1_TECHNOLOGIES" | "PROVIDER_TELEMEDIA" | "PROVIDER_CDCOM_PROGOROD" | "PROVIDER_MIT_CITYGUIDE" | "PROVIDER_SUNCART" | "PROVIDER_MICROMAPPER" | "PROVIDER_RICHI" | "PROVIDER_FORUM44" | "PROVIDER_SEAT" | "PROVIDER_VALASSIS" | "PROVIDER_NAVICOM" | "PROVIDER_COLTRACK" | "PROVIDER_PSMA_AUSTRALIA" | "PROVIDER_PT_DUTA_ASTAKONA_GIRINDA" | "PROVIDER_CA_GOVERNMENT" | "PROVIDER_STATISTICS_CANADA" | "PROVIDER_TOCTOC" | "PROVIDER_RMSI" | "PROVIDER_TRUE_TECHNOLOGY" | "PROVIDER_INCREMENT_P_CORPORATION" | "PROVIDER_GOJAVAS" | "PROVIDER_GEOINFORMATION_GROUP" | "PROVIDER_CYBERSOFT" | "PROVIDER_TSENTR_EFFEKTIVNYKH_TEKHNOLOGIY" | "PROVIDER_EE_GOVERNMENT" | "PROVIDER_EE_MAA_AMET" | "PROVIDER_GASBUDDY" | "PROVIDER_DK_GOVERNMENT" | "PROVIDER_DK_GEODATASTYRELSEN" | "PROVIDER_MURCIA_REGION_GOVERNMENT" | "PROVIDER_CORREIOS" | "PROVIDER_WEST_WORLD_MEDIA" | "PROVIDER_INTERNATIONAL_MAPPING_ASSOCIATION" | "PROVIDER_MEDICARE" | "PROVIDER_POLARIS" | "PROVIDER_TW_GOVERNMENT" | "PROVIDER_TW_MINISTRY_OF_THE_INTERIOR_SURVEYING_AND_MAPPING_CENTER" | "PROVIDER_NORDECA" | "PROVIDER_AFRIMAPPING" | "PROVIDER_OVERDRIVE" | "PROVIDER_PROVIDER_NETWORK_DIRECTORIES" | "PROVIDER_BR_MINISTERIO_DA_SAUDE" | "PROVIDER_DIGITAL_EGYPT" | "PROVIDER_INRIX" | "PROVIDER_ARPINDO" | "PROVIDER_IT_GOVERNMENT" | "PROVIDER_ISTITUTO_GEOGRAFICO_MILITARE" | "PROVIDER_EAST_END_GROUP" | "PROVIDER_INGEOLAN" | "PROVIDER_SEMACONNECT" | "PROVIDER_BLINK" | "PROVIDER_EVGO" | "PROVIDER_CHARGEPOINT" | "PROVIDER_TPL_TRAKKER" | "PROVIDER_OI" | "PROVIDER_MAPARADAR" | "PROVIDER_SINGAPORE_POST" | "PROVIDER_CHARGEMASTER" | "PROVIDER_TESLA" | "PROVIDER_VISICOM" | "PROVIDER_GEOLYSIS" | "PROVIDER_ZEPHEIRA" | "PROVIDER_HUBJECT" | "PROVIDER_PODPOINT" | "PROVIDER_CHARGEFOX" | "PROVIDER_KR_GOVERNMENT" | "PROVIDER_KR_MOLIT" | "PROVIDER_KR_MINISTRY_OF_THE_INTERIOR_AND_SAFETY" | "PROVIDER_CRITCHLOW" | "PROVIDER_EIFRIG" | "PROVIDER_GIREVE" | "PROVIDER_CN_NAVINFO" | "PROVIDER_JAPAN_CHARGE_NETWORK" | "PROVIDER_NOBIL" | "PROVIDER_INDIA_BANKS" | "PROVIDER_INDONESIA_ELECTION_KPU" | "PROVIDER_CAREERS360" | "PROVIDER_SOURCE_LONDON" | "PROVIDER_EVBOX" | "PROVIDER_JP_GOVERNMENT" | "PROVIDER_JP_MINISTRY_OF_THE_ENVIRONMENT" | "PROVIDER_YUMYUM" | "PROVIDER_HWW_AUSTRALIA" | "PROVIDER_CINERGY" | "PROVIDER_MTIME" | "PROVIDER_KULTUNAUT" | "PROVIDER_BLITZ" | "PROVIDER_PIA" | "PROVIDER_INTERPARK" | "PROVIDER_CINEMA_ONLINE" | "PROVIDER_BELBIOS" | "PROVIDER_MOVIESEER" | "PROVIDER_SODAMEDYA" | "PROVIDER_ATMOVIES" | "PROVIDER_HOTELBEDS" | "PROVIDER_VERICRED" | "PROVIDER_CIRRANTIC" | "PROVIDER_GOGO_LABS" | "PROVIDER_ELECTRIFY_AMERICA" | "PROVIDER_CMS_MPPUF" | "PROVIDER_DIGIROAD" | "PROVIDER_KONTEX_GEOMATICS" | "PROVIDER_NZ_GOVERNMENT" | "PROVIDER_NZ_LINZ" | "PROVIDER_NZ_DOC" | "PROVIDER_FASTNED" | "PROVIDER_DESTINY_CS" | "PROVIDER_IONITY" | "PROVIDER_EV_CONNECT" | "PROVIDER_PANPAGES" | "PROVIDER_ETECNIC" | "PROVIDER_VOLTA" | "PROVIDER_NISSAN_MEXICO" | "PROVIDER_BMW_GROUP_LATIN_AMERICA" | "PROVIDER_FEDERAL_ELECTRICITY_COMMISSION_MEXICO" | "PROVIDER_VOLVO_CARS_BRASIL" | "PROVIDER_CHARGE_AND_PARKING" | "PROVIDER_DEDUCE_TECHNOLOGIES" | "PROVIDER_SK_TELECOM" | "PROVIDER_ECO_MOVEMENT" | "PROVIDER_GOOGLE_GMS" | "PROVIDER_EASYWAY" | "PROVIDER_PHYSICIAN_COMPARE" | "PROVIDER_HOSPITAL_COMPARE" | "PROVIDER_ENDOLLA_BARCELONA" | "PROVIDER_BE_CHARGE" | "PROVIDER_ONE_NETWORK" | "PROVIDER_CARENAV_DUPLEX" | "PROVIDER_CARENAV_POI" | "PROVIDER_IN_GOVERNMENT" | "PROVIDER_SURVEY_OF_INDIA" | "PROVIDER_E_ON" | "PROVIDER_ELECTRIFY_CANADA" | "PROVIDER_GRIDCARS" | "PROVIDER_DRIVECO" | "PROVIDER_GREEN_ACTION_STUDIOS" | "PROVIDER_GREEN_ACTION_STUDIO" | "PROVIDER_EVINY" | "PROVIDER_MASTERCARD" | "PROVIDER_VATTENFALL" | "PROVIDER_VIETGIS" | "PROVIDER_UNITE" | "PROVIDER_NEOGY" | "PROVIDER_AMPUP" | "PROVIDER_LOOP" | "PROVIDER_ZEST" | "PROVIDER_EZVOLT";
}

/**
 * This message is embedded within a FeatureProto. It has rank calculation
 * details such as available rank signals and rank signal mixer used to compute
 * final rank. For more details, see the Oyster Rank wiki page:
 * http://wiki.corp.google.com/twiki/bin/view/Main/OysterRank
 */
export interface GeostoreRankDetailsProto {
  /**
   * A list of signals. Each one is extracted separately by a SignalExtractor.
   */
  signal?: GeostoreRankSignalProto[];
  /**
   * The signal mixer that was used to calculate the rank.
   */
  signalMixerType?:  | "MIXER_INVALID" | "MIXER_MISSING" | "MIXER_ADDRESS_AREA" | "MIXER_ROUTE_SEGMENT_INTERSECTION" | "MIXER_POLITICAL_EUROPA" | "MIXER_POLITICAL_AREA" | "MIXER_POLITICAL" | "MIXER_COUNTRY_EUROPA" | "MIXER_COUNTRY_AREA" | "MIXER_COUNTRY" | "MIXER_LOCALITY" | "MIXER_LOCALITY_GEOWIKI" | "MIXER_LOCALITY_EUROPA" | "MIXER_LOCALITY_AREA" | "MIXER_RIVER" | "MIXER_LENGTH_WEBSCORE" | "MIXER_SKENERGY" | "MIXER_GEOCENTRE_GEOCODED_ADDRESS" | "MIXER_PLACERANK" | "MIXER_TRANSIT" | "MIXER_LOCALITY_EUROPA_AREA" | "MIXER_WEBSCORE" | "MIXER_LOCALITY_MAPDATA_SCIENCES" | "MIXER_SUBLOCALITY_MAPDATA_SCIENCES" | "MIXER_PEAK" | "MIXER_BUILDING" | "MIXER_RESERVATION" | "MIXER_AIRPORT" | "MIXER_AREA" | "MIXER_MANAGER" | "MIXER_TEST_1" | "MIXER_TEST_2" | "MIXER_TEST_3" | "MIXER_TEST_4" | "MIXER_TEST_5";
}

/**
 * This message is embedded in the RankDetailsProto (below). It represents one
 * rank signal, which is a floating point value estimating the Oyster Rank of
 * the feature.
 */
export interface GeostoreRankSignalProto {
  /**
   * Field-level metadata for this signal.
   */
  metadata?: GeostoreFieldMetadataProto;
  /**
   * A value in the range [0, 1] estimating Oyster Rank according to this
   * signal. Non-provider specific signals (e.g. SIGNAL_POPULATION) are
   * interpreted by some common code in the ranking pipeline. Because of that,
   * data providers should leave this field empty when setting such signals (so
   * that the rank assignment can be uniform across all features regardless of
   * contributing data providers). On the other hand, provider-specific signals
   * (e.g. SIGNAL_ZENRIN_CITY_CATEGORY) are required to specify the rank field
   * (it is not optional for them). That is because no code other than that of
   * the provider itself will be able to fill in a meaningful value later on. We
   * don't want clients to be reading from the raw_scalar / raw_string fields to
   * interpret the data.
   */
  rank?: number;
  /**
   * The raw scalar value that was used to compute 'rank' above. The meaning of
   * this attribute changes depending on the signal type.
   */
  rawScalar?: number;
  /**
   * The raw string value that was used to compute 'rank' above. The meaning of
   * this attribute changes depending on the signal type.
   */
  rawString?: string;
  type?:  | "SIGNAL_UNKNOWN" | "SIGNAL_LENGTH" | "SIGNAL_AREA" | "SIGNAL_ADDRESS" | "SIGNAL_LISTING" | "SIGNAL_ROAD_PRIORITY" | "SIGNAL_POI_COUNT" | "SIGNAL_WEBSCORE" | "SIGNAL_PATHRADIUS_LENGTH_METERS" | "SIGNAL_PATHRADIUS_LENGTH_SEGMENTS" | "SIGNAL_PATHRADIUS_POPULARITY" | "SIGNAL_PEAK_ELEVATION_PROMINENCE" | "SIGNAL_ROAD_SEGMENT_COUNT" | "SIGNAL_POI_SCORE" | "SIGNAL_ATTRACTIONS_SCORE" | "SIGNAL_HAND_RANKED_LOCALITY_PROMINENCE" | "SIGNAL_POPULATION" | "SIGNAL_GDP" | "SIGNAL_EUROPA_CLASS" | "SIGNAL_RMF_SOURCE_RANK" | "SIGNAL_MDS_SOURCE_RANK" | "SIGNAL_MULTINET_SOURCE_RANK" | "SIGNAL_LOCALXML_MANUAL_RANK" | "SIGNAL_TRANSIT_LINE" | "SIGNAL_TRANSIT_TRAIN_DEPARTURE_COUNT" | "SIGNAL_TRANSIT_METRO_DEPARTURE_COUNT" | "SIGNAL_TRANSIT_BUS_DEPARTURE_COUNT" | "SIGNAL_TRANSIT_OTHER_DEPARTURE_COUNT" | "SIGNAL_TRANSIT_TRAIN_LINE_COUNT" | "SIGNAL_TRANSIT_METRO_LINE_COUNT" | "SIGNAL_TRANSIT_BUS_LINE_COUNT" | "SIGNAL_TRANSIT_OTHER_LINE_COUNT" | "SIGNAL_TRANSIT_STATION_LOCAL_RANK" | "SIGNAL_TRANSIT_STATION_GLOBAL_RANK" | "SIGNAL_ORION_LEVEL" | "SIGNAL_GEOCENTRE_ADDRESS_RANK" | "SIGNAL_GOOGLE_3DWAREHOUSE_RANK" | "SIGNAL_SKENERGY_CATEGORY" | "SIGNAL_GOOGLE_GEOWIKI_USER_RANK" | "SIGNAL_WIKIPEDIA_ARTICLES" | "SIGNAL_WIKIPEDIA_ARTICLES_IN_OFFICIAL_LANGUAGE" | "SIGNAL_KML_PLACEMARKS" | "SIGNAL_KML_SOURCES" | "SIGNAL_PANORAMIO_USERS" | "SIGNAL_GOOGLE_MAPSHOP_USERS" | "SIGNAL_GOOGLE_LOCALSEARCH_DIRECTORY_INFOS" | "SIGNAL_GOOGLE_MAPS_NAVBOOST_CLICKS" | "SIGNAL_GOOGLE_MAPS_NAVBOOST_CLICKTHROUGH_RATE" | "SIGNAL_GOOGLE_RBL_CLICKS" | "SIGNAL_GOOGLE_RBL_CLICK_FRACTION" | "SIGNAL_GOOGLE_AUTHORITYPAGE_PAGERANK" | "SIGNAL_GOOGLE_AUTHORITYPAGE_PAGERANK_CONFIDENCE" | "SIGNAL_GOOGLE_REVIEWS" | "SIGNAL_GOOGLE_WEB_QUERYVOL" | "SIGNAL_GOOGLE_WEBPAGE_REFERENCE_DOMAINS" | "SIGNAL_GOOGLE_LISTING_IMPRESSIONS" | "SIGNAL_GOOGLE_INFOWINDOW_VIEWS" | "SIGNAL_GOOGLE_DIRECTION_REQUESTS" | "SIGNAL_GOOGLE_HOMEPAGE_CLICKS" | "SIGNAL_GOOGLE_CHAIN_STORES" | "SIGNAL_FLICKR_USERS" | "SIGNAL_GOOGLE_LEANBACK_TOURS" | "SIGNAL_GOOGLE_LOCALSEARCH_PLACERANK" | "SIGNAL_WIKIPEDIA_WIKI_SCORE" | "SIGNAL_ZENRIN_CITY_CATEGORY" | "SIGNAL_ZENRIN_BUILDING_CLASS" | "SIGNAL_ZENRIN_PEAK_CLASS" | "SIGNAL_PLACE_INSIGHTS_LANDMARK" | "SIGNAL_PLACE_INSIGHTS_POPULARITY" | "SIGNAL_PLACE_INSIGHTS_PROMINENCE" | "SIGNAL_PLACE_INSIGHTS_APPROACHABILITY" | "SIGNAL_PLACE_INSIGHTS_TOTAL_ROAD_SEGMENT_USAGE";
}

/**
 * A RawDataProto is a key-value pair that represents arbitrary source data
 * from a particular provider. Raw data can be attached to features using their
 * source_info field.
 */
export interface GeostoreRawDataProto {
  /**
   * The key associated with this data item. For source data in shape file
   * format, this will typically be a column name. Keys need to be unique with
   * respect to a particular data source (see DataSourceProto), but they do not
   * need to be globally unique. You can look up the documentation for a key
   * (e.g. a longer label and description) by following the source_id link of
   * the parent SourceInfoProto, which takes you to a TYPE_DATA_SOURCE feature,
   * and then looking up the corresponding RawMetadataProto object for this key
   * in that feature's optional data_source field.
   */
  key?: string;
  /**
   * All data items are represented as strings, the logic being that it is easy
   * to convert other data types to strings, and there is no need to access this
   * data efficiently.
   */
  valueString?: string;
}

export interface GeostoreRawMetadataProto {
  /**
   * Method to use when conflating together RawDataProto values at the same key
   * NB: If you add a new ConflationMethod, then you must add the corresponding
   * logic to MergeRawData to conflate the RawDataProto values using this
   * method.
   */
  conflationMethod?:  | "CONFLATION_PICK_FIRST_VALUE" | "CONFLATION_UNION_CSV" | "CONFLATION_SUM";
  /**
   * Self-contained documentation about what this field represents and how its
   * values are encoded.
   */
  description?: string;
  /**
   * The key being described.
   */
  key?: string;
  /**
   * A longer, human-readable name associated with this key. The label might be
   * used in a data explorer tool, for example.
   */
  label?: string;
}

/**
 * A latitude-longitude rectangle, represented as two diagonally opposite
 * points "lo" and "hi". The rectangle is considered to be a closed region, i.e.
 * it includes its boundary. The latitude bounds must be in the range -90 to 90
 * degrees inclusive, and the longitude bounds must be in the range -180 to 180
 * degrees inclusive. Various cases include: - If lo == hi, the rectangle
 * consists of a single point. - If lo.longitude > hi.longitude, the longitude
 * range is "inverted" (the rectangle crosses the 180 degree longitude line). -
 * If lo.longitude == -180 degrees and hi.longitude = 180 degrees, the rectangle
 * includes all longitudes. - If lo.longitude = 180 degrees and hi.longitude =
 * -180 degrees, the longitude range is empty. - If lo.latitude > hi.latitude,
 * the latitude range is empty.
 */
export interface GeostoreRectProto {
  hi?: GeostorePointProto;
  lo?: GeostorePointProto;
}

/**
 * A collection of information that applies to a polygonal area.
 */
export interface GeostoreRegulatedAreaProto {
  /**
   * The set of restrictions that apply to a zone. These restrictions may limit
   * the routability of every segment contained within the defined
   * feature.polygon. Repeated restrictions are treated collectively as an OR
   * meaning that segments in the zone are only routable if none of the
   * restrictions apply. If any segments within the defined polygon should not
   * have these restrictions applied, they must list this regulated area's
   * feature id in their feature.exempt_regulated_area field.
   */
  restriction?: GeostoreRestrictionProto[];
}

function serializeGeostoreRegulatedAreaProto(data: any): GeostoreRegulatedAreaProto {
  return {
    ...data,
    restriction: data["restriction"] !== undefined ? data["restriction"].map((item: any) => (serializeGeostoreRestrictionProto(item))) : undefined,
  };
}

function deserializeGeostoreRegulatedAreaProto(data: any): GeostoreRegulatedAreaProto {
  return {
    ...data,
    restriction: data["restriction"] !== undefined ? data["restriction"].map((item: any) => (deserializeGeostoreRestrictionProto(item))) : undefined,
  };
}

/**
 * This message is embedded within a FeatureProto, and represents a geographic
 * or logical relationship of that feature to some other feature. Note that some
 * relation types are there purely for the purpose of grouping together other
 * relation types. They are noted as ABSTRACT in comments. Other relation types
 * are no longer supported / in use. They are noted as DEPRECATED in comments
 * (and marked with the standard deprecated option, too). Other relation types
 * are reserved for future use or just not intended for use at all, for various
 * internal reasons. They are noted as RESERVED in comments. WARNING: Updates to
 * this proto within a FeatureProto's related_feature field handled by
 * standalone pipelines and are NOT atomic with regard to updates to the
 * features being referenced; we do not guarantee that a given MapFacts snapshot
 * will be consistent between this field and the related features.
 */
export interface GeostoreRelationProto {
  /**
   * Field-level metadata for this relation.
   */
  metadata?: GeostoreFieldMetadataProto;
  /**
   * If and only if the other feature is of TYPE_COUNTRY, the 2-letter country
   * code. This is the FLAG_COUNTRY_CODE_2 name of the country component.
   */
  otherFeatureCountryCode?: string;
  /**
   * The feature ID of the feature to which we're relating. WARNING: the
   * related feature does not necessarily have a bound that encloses this
   * feature, so in a bucketing MapReduce, you may not be able to follow all
   * relationships. Relations that use strong references are annotated above but
   * you can also refer to IsRelationStrong() in
   * geostore/base/public/relation.h.
   */
  otherFeatureId?: GeostoreFeatureIdProto;
  /**
   * RESERVED
   */
  otherFeatureName?: GeostoreNameProto[];
  /**
   * If and only if the other feature is of TYPE_DISPUTED_AREA, the territorial
   * administrator found in its GeopoliticalAttachmentProto.administered_by
   * field, if any. Since this string is copied exactly, it may be a 2-letter
   * country code or another type of descriptive string.
   */
  otherFeatureTerritorialAdministrator?: string;
  /**
   * The type of the feature to which we're relating.
   */
  otherFeatureType?: number;
  /**
   * ** DEPRECATED ** If relation is exactly RELATION_OVERLAPS but not any of
   * its subcategories, overlap_fraction contains an estimate of the fraction of
   * the geometry of this feature that intersects with the other feature,
   * ranging from 0.0 to 1.0. Note that this is a rough estimate based on cell
   * coverings, and may not be very accurate. In particular, values of 0.0 and
   * 1.0 are possible, even though in principle they should not be.
   */
  overlapFraction?: number;
  /**
   * The relationship of the feature that contains this RelationProto to the
   * feature other_feature_id. Note the relation_is_reversed field below. Some
   * relations imply weak references, other strong ones. Strong references are
   * annotated above but you can also refer to IsRelationStrong() in
   * geostore/base/public/relation.h.
   */
  relation?:  | "RELATION_OVERLAPS" | "RELATION_CONTAINED_BY" | "RELATION_EQUAL_TO" | "RELATION_POLITICAL_DEPRECATED" | "RELATION_CAPITAL_OF" | "RELATION_DISAMBIGUATED_BY" | "RELATION_NEIGHBOR_OF" | "RELATION_OPPOSITE_TO" | "RELATION_NEXT_TO" | "RELATION_RIGHT_OF" | "RELATION_LEFT_OF" | "RELATION_BEHIND" | "RELATION_IN_FRONT_OF" | "RELATION_SAME_BUILDING" | "RELATION_ABOVE" | "RELATION_BELOW" | "RELATION_NEAR" | "RELATION_ORGANIZATIONALLY_PART_OF" | "RELATION_DEPARTMENT_OF" | "RELATION_WORKS_AT" | "RELATION_INDEPENDENT_ESTABLISHMENT_IN" | "RELATION_ON_LEVEL" | "RELATION_OCCUPIES" | "RELATION_BUSINESS_LIFE_CYCLE" | "RELATION_BUSINESS_MOVED" | "RELATION_BUSINESS_REBRANDED" | "RELATION_MEMBER_OF_CHAIN" | "RELATION_AUTHORIZED_DEALER_FOR_CHAIN" | "RELATION_SUBSIDIARY_OF" | "RELATION_PRIMARILY_OCCUPIED_BY" | "RELATION_VARIATION" | "RELATION_HAS_VARIANT" | "RELATION_VARIANT_OF" | "RELATION_VARIANT_SIBLING" | "RELATION_CLIENT_DEFINED";
  /**
   * RESERVED
   */
  relationIsReversed?: boolean;
  /**
   * A place for clients to attach arbitrary data to a relation. Never set in
   * MapFacts.
   */
  temporaryData?: Proto2BridgeMessageSet;
}

function serializeGeostoreRelationProto(data: any): GeostoreRelationProto {
  return {
    ...data,
    otherFeatureId: data["otherFeatureId"] !== undefined ? serializeGeostoreFeatureIdProto(data["otherFeatureId"]) : undefined,
  };
}

function deserializeGeostoreRelationProto(data: any): GeostoreRelationProto {
  return {
    ...data,
    otherFeatureId: data["otherFeatureId"] !== undefined ? deserializeGeostoreFeatureIdProto(data["otherFeatureId"]) : undefined,
  };
}

/**
 * A restriction group represents common properties of a set of restrictions on
 * segments that are associated with the same underlying cause across a
 * geographic region. Every segment referenced by this restriction group should
 * have at least one restriction that refers backs to this restriction group.
 * The standard feature properties have the following interpretations: name - A
 * name that represents the name for this restriction group. kg_property - A
 * reference back to a KG event in case this restriction group belongs to an
 * event in KG. /geo/type/restriction_group/associated_event contains a mid to
 * the associated event.
 */
export interface GeostoreRestrictionGroupProto {
  /**
   * Field-level metadata for this restriction group.
   */
  metadata?: GeostoreFieldMetadataProto;
  /**
   * FeatureId of all segments that have a RestrictionProto referring back to
   * this RestrictionGroup.
   */
  segment?: GeostoreFeatureIdProto[];
}

function serializeGeostoreRestrictionGroupProto(data: any): GeostoreRestrictionGroupProto {
  return {
    ...data,
    segment: data["segment"] !== undefined ? data["segment"].map((item: any) => (serializeGeostoreFeatureIdProto(item))) : undefined,
  };
}

function deserializeGeostoreRestrictionGroupProto(data: any): GeostoreRestrictionGroupProto {
  return {
    ...data,
    segment: data["segment"] !== undefined ? data["segment"].map((item: any) => (deserializeGeostoreFeatureIdProto(item))) : undefined,
  };
}

/**
 * A restriction is an expression that limits when an action can be taken. Each
 * restriction has a set of conditions. If all of the conditions are true, then
 * the restriction applies and the action cannot be taken. For example, the
 * restriction "no turns 3-5pm except buses" would have two conditions: "time is
 * 3-5pm" and "vehicle is not a bus". If both of these conditions apply, the
 * restriction is true, and the turn is prohibited. Multiple restrictions may
 * apply to the same action. Clients handle this by always declaring
 * RestrictionProto as a "repeated" element. The semantics of having multiple
 * restrictions are that if any restriction applies, then the action cannot be
 * taken. In other words, restrictions are OR-ed together. Putting all of this
 * together, a set of RestrictionProtos can be interpreted as an bool expression
 * in disjunctive normal form: (A and B) or (D and E and F) or (G and H) The
 * action is prohibited if this expression is true. Note that a restriction with
 * no conditions is always true, i.e. its action is always prohibited.
 */
export interface GeostoreRestrictionProto {
  /**
   * The restriction only applies in these specific autonomous driving product
   * scenarios. NOTE: This should only be set on restrictions with
   * TRAVEL_AUTONOMOUS_VEHICLE travel mode.
   */
  autonomousDrivingProducts?:  | "UNKNOWN" | "HD_L4" | "HD_L2" | "ADAS" | "AUTO_DRIVING_EXPERIENCE"[];
  /**
   * Actually *required* if style=STYLE_IN_OUT, otherwise forbidden. Typically
   * the intersection group type is artifact, but either artifact or logical
   * groups can be used for STYLE_IN_OUT restrictions.
   */
  intersectionGroup?: GeostoreFeatureIdProto;
  /**
   * Field-level metadata for this restriction.
   */
  metadata?: GeostoreFieldMetadataProto;
  /**
   * Restriction group this restriction belongs to.
   */
  restrictionGroup?: GeostoreFeatureIdProto;
  /**
   * When specified, restriction applies only at particular times (operating
   * hours or times of the year: reversing lanes, seasonal roads, no left turns
   * from 3-5pm Mon-Fri except holidays). Otherwise, restriction is in effect at
   * all times.
   */
  schedule?: GeostoreTimeScheduleProto;
  /**
   * The scope that the restriction applies to. - SCOPE_DIRECTION means the
   * segment/sibling pair is restricted in the direction of the segment that
   * contains this RestrictionProto. For segment/sibling pairs with pedestrian
   * facilities (and thus side-of-road routing) the RestrictionProto restricts
   * both facilities in the direction of the segment (assuming that the
   * restriction applies to travel mode TRAVEL_PEDESTRIAN). - SCOPE_SIDE means
   * the RestrictionProto applies only to the side of road that the containing
   * segment represents. That sibling's pedestrian facility is restricted in
   * both directions. Schema constraints: - SCOPE_SIDE must be set if and only
   * if travel_mode == [TRAVEL_PEDESTRIAN] and the segment containing the
   * restriction has PEDESTRIAN_FACILITY_PRESENT. Such restrictions must have no
   * subpath. - All other restrictions must have this field set to
   * SCOPE_DIRECTION (whether explicitly or implicitly). This distinction is
   * necessary for cases such as pedestrian facility on one-way segment/sibling
   * roads.
   */
  scope?:  | "SCOPE_DIRECTION" | "SCOPE_SIDE";
  /**
   * Restriction Style defines the semantics of the subpath field, as defined
   * above in the documentation of subpath.
   */
  style?:  | "STYLE_CONTIGUOUS" | "STYLE_SINGLE" | "STYLE_TURN" | "STYLE_IN_OUT";
  /**
   * "subpath" specifies the GeoStore segments that this restriction applies
   * to, according to the restriction_style field below. Segments that are
   * referenced by this subpath field also refer to this feature back via the
   * same subpath field. For all styles of restriction, all segments in the
   * subpath must have identical copies of the restriction. In other words,
   * restrictions are duplicated along every segment in the subpath. Note that
   * subpaths of length 1 do not have any purpose and are disallowed. Note that
   * it is possible to represent restrictions either using STYLE_CONTIGUOUS, or
   * depending on the length of the subpath, one of the more specific
   * STYLE_SINGLE, STYLE_TURN, or STYLE_IN_OUT. New code should use the more
   * specific alternatives if possible, as they support instant updates. For
   * restriction_style == STYLE_CONTIGUOUS (the default): "subpath" can either
   * be empty, for a single-segment restriction, or it specifies exactly the
   * sequence of segments which this restriction applies to. The subpath may be
   * used to specify a turn restriction (a subpath of length 2) or to prohibit
   * more complex maneuvers. For example, when merging onto a road from the
   * right-hand side it may not be possible to make an immediate left turn due
   * to insufficient time to cross the intervening lanes or the presence of a
   * physical barrier. This would be indicated by a subpath restriction of
   * length 3 or more. For restriction_style == STYLE_SINGLE: The subpath field
   * of the Restriction must be empty. The restriction applies only to the
   * segment it is attached to. There must not be an intersection group
   * specified. For restriction_style == STYLE_TURN: The subpath field of the
   * Restriction must contain exactly two segments. The first is called the
   * "in_segment", the second is the "out_segment". They must be contiguous,
   * i.e. the end intersection of the in_segment is the start intersection of
   * the out_segment. The restriction applies only to a direct maneuver from the
   * in_segment to the out_segment. Other paths from the in_segment to the
   * out_segment are not restricted. There must not be an intersection group
   * specified. For restriction_style == STYLE_IN_OUT: The subpath field of the
   * Restriction must contain exactly two segments. The first is called the
   * "in_segment", the second is the "out_segment". Note that the two segments
   * define paths, but may not actually be one. The end intersection of the
   * in_segment must be in an intersection group which also contains the start
   * intersection of the out_segment. The in- and out-segments are not required
   * to be adjacent, but may be. Either way, the restriction applies to any path
   * from the in_segment to the out_segment through the intersection group, not
   * just direct turns. The intersection_group must be specified. Note that
   * clients which read restrictions and need to know which paths are restricted
   * by a given IN_OUT restriction must expand the IN_OUT restriction by finding
   * all paths through the intersection group from the in_segment to the
   * out_segment.
   */
  subpath?: GeostoreFeatureIdProto[];
  /**
   * A place for clients to attach arbitrary data to a restriction. Never set
   * in MapFacts.
   */
  temporaryData?: Proto2BridgeMessageSet;
  /**
   * Restriction applies only to the given travel modes. This field should
   * always be set, but may be missing in old data. WARNING: Restrictions with
   * no travel modes are DEPRECATED. Historically, no travel modes has meant
   * "all travel modes", except they didn't really even mean that, because
   * Pathfinder would use a complex set of heuristics to interpret the "correct"
   * travel modes. Pathfinder currently (last updated August 2013) has
   * heuristics to cope with incomplete data that reduce or extend application
   * of the specified restrictions to pedestrians or bicycles. We are actively
   * working to remove these heuristics and replace them with explicit, correct
   * travel modes in the data. See b/8746491.
   */
  travelMode?:  | "TRAVEL_ANY" | "TRAVEL_MOTOR_VEHICLE" | "TRAVEL_AUTO" | "TRAVEL_CARPOOL" | "TRAVEL_MOTORCYCLE" | "TRAVEL_BUS" | "TRAVEL_TRUCK" | "TRAVEL_DELIVERY" | "TRAVEL_TAXI" | "TRAVEL_EMERGENCY" | "TRAVEL_THROUGH_TRAFFIC" | "TRAVEL_AUTONOMOUS_VEHICLE" | "TRAVEL_PEDESTRIAN" | "TRAVEL_BICYCLE"[];
  /**
   * clang-format on The type of restriction. This is not a condition, but
   * rather tells you what kind of restriction it is. This field should always
   * be set.
   */
  type?:  | "RESTRICTION_TRAVEL_RESTRICTED" | "RESTRICTION_ILLEGAL" | "RESTRICTION_PHYSICAL" | "RESTRICTION_LOGICAL" | "RESTRICTION_GATE" | "RESTRICTION_CONSTRUCTION" | "RESTRICTION_SEASONAL_CLOSURE" | "RESTRICTION_PRIVATE" | "RESTRICTION_WRONG_WAY" | "RESTRICTION_TERMINAL" | "RESTRICTION_PAYMENT_REQUIRED" | "RESTRICTION_TOLL_BOOTH" | "RESTRICTION_USAGE_FEE_REQUIRED" | "RESTRICTION_ENTRANCE_FEE_REQUIRED" | "RESTRICTION_ADVISORY" | "RESTRICTION_HIGH_CRIME" | "RESTRICTION_POLITICALLY_SENSITIVE" | "RESTRICTION_DISTURBED_BY_MAINTENANCE" | "RESTRICTION_CHECKPOINT" | "RESTRICTION_REGION_SPECIFIC";
  /**
   * The restriction only applies to vehicles that meet all of the attributes
   * defined here. If this is empty, it does not affect the scope of the
   * restriction.
   */
  vehicleAttributeFilter?: GeostoreVehicleAttributeFilterProto;
}

function serializeGeostoreRestrictionProto(data: any): GeostoreRestrictionProto {
  return {
    ...data,
    intersectionGroup: data["intersectionGroup"] !== undefined ? serializeGeostoreFeatureIdProto(data["intersectionGroup"]) : undefined,
    restrictionGroup: data["restrictionGroup"] !== undefined ? serializeGeostoreFeatureIdProto(data["restrictionGroup"]) : undefined,
    subpath: data["subpath"] !== undefined ? data["subpath"].map((item: any) => (serializeGeostoreFeatureIdProto(item))) : undefined,
  };
}

function deserializeGeostoreRestrictionProto(data: any): GeostoreRestrictionProto {
  return {
    ...data,
    intersectionGroup: data["intersectionGroup"] !== undefined ? deserializeGeostoreFeatureIdProto(data["intersectionGroup"]) : undefined,
    restrictionGroup: data["restrictionGroup"] !== undefined ? deserializeGeostoreFeatureIdProto(data["restrictionGroup"]) : undefined,
    subpath: data["subpath"] !== undefined ? data["subpath"].map((item: any) => (deserializeGeostoreFeatureIdProto(item))) : undefined,
  };
}

/**
 * Proto used to represent rights for FeatureProto. See go/geo-rights for more
 * details. NOTE: Use google3/geostore/provenance/public/rights.h or
 * google3/java/com/google/geostore/provenance/rights/Rights.java instead of
 * accessing this proto directly.
 */
export interface GeostoreRightsStatusProto {
  fieldWithRights?: GeostoreFieldWithRightsProto[];
}

function serializeGeostoreRightsStatusProto(data: any): GeostoreRightsStatusProto {
  return {
    ...data,
    fieldWithRights: data["fieldWithRights"] !== undefined ? data["fieldWithRights"].map((item: any) => (serializeGeostoreFieldWithRightsProto(item))) : undefined,
  };
}

function deserializeGeostoreRightsStatusProto(data: any): GeostoreRightsStatusProto {
  return {
    ...data,
    fieldWithRights: data["fieldWithRights"] !== undefined ? data["fieldWithRights"].map((item: any) => (deserializeGeostoreFieldWithRightsProto(item))) : undefined,
  };
}

/**
 * A RoadConditionalProto defines conditions that affect when the road
 * traversal information is applicable.
 */
export interface GeostoreRoadConditionalProto {
  /**
   * Specifies what times the information is applicable. This can be specific
   * times (3-5 PM) or days of the week (Mon - Fri), as well as more general
   * times like school hours, dusk to dawn, etc. If no value is set, the
   * restriction is applicable at all times.
   */
  timeSchedule?: GeostoreTimeScheduleProto;
  /**
   * Additional attributes that apply to the applied vehicle types.
   */
  vehicleAttribute?: GeostoreVehicleAttributeFilterProto;
  /**
   * Restrictions applying to specific types of vehicles.
   */
  vehicleType?:  | "UNKNOWN" | "ANY" | "CAR" | "MOTORCYCLE" | "TRUCK" | "BUS"[];
}

/**
 * A road monitor is a device that observes traffic for road violations like
 * speeding or running a red light. These are modeled within MapFacts so that
 * navigation services can warn users when they drive along road segments that
 * are monitored.
 */
export interface GeostoreRoadMonitorProto {
  /**
   * The TYPE_ROAD segment features that this road monitor may observe.
   */
  monitoredRoad?: GeostoreFeatureIdProto[];
}

function serializeGeostoreRoadMonitorProto(data: any): GeostoreRoadMonitorProto {
  return {
    ...data,
    monitoredRoad: data["monitoredRoad"] !== undefined ? data["monitoredRoad"].map((item: any) => (serializeGeostoreFeatureIdProto(item))) : undefined,
  };
}

function deserializeGeostoreRoadMonitorProto(data: any): GeostoreRoadMonitorProto {
  return {
    ...data,
    monitoredRoad: data["monitoredRoad"] !== undefined ? data["monitoredRoad"].map((item: any) => (deserializeGeostoreFeatureIdProto(item))) : undefined,
  };
}

/**
 * Below is some horrible ASCII art and a description of the components of a
 * road sign. +-------------------+ | A11 E50 Paris | | Chartres |
 * +-------------------+ This sign would be composed of four components (all of
 * them text components, the only option we support for now). The three in the
 * first row would all have a "major_position" of zero. Their "minor_position"
 * values would be zero for "A11", one for "E50", and two for "Paris". The
 * component in the second row would have "major_position" value of one. This
 * message provides the details of a single component of a road sign. A
 * component defines its position within a sign, its type, and its content.
 */
export interface GeostoreRoadSignComponentProto {
  /**
   * The id of the feature referred to by this component, typically the route
   * or locality feature this sign points towards. In the ASCII art example
   * above, this field would contain the id for the routes A11 and E50 and the
   * localities Chartres and Paris in the corresponding component.
   */
  featureId?: GeostoreFeatureIdProto;
  /**
   * The type of the feature referred to by this component. If feature_id is
   * specified type of that feature should be the same as this field.
   */
  featureType?: number;
  /**
   * This is the "major" position of this component within the set of
   * components that make up a sign. This number can be thought of as the "row"
   * of the sign on which the component appears, but no guarantees are made that
   * there is a one-to-one mapping between "major_position" and the rows of
   * information on the actual sign being modeled. A "major_position" value of
   * zero would indicate that the component is near the top of the sign.
   */
  majorPosition?: number;
  /**
   * This is the position of a component within the components of a sign that
   * share a common "major_position". It can be though of as the "column" of the
   * component, but like "major_position", no guarantees are made regarding its
   * mapping to reality. For data sources that don't provide enough information
   * to determine a component's major and minor positions, major position should
   * be populated and minor position should not be present. A "minor_position"
   * value of zero would indicate that the component is near the "beginning" of
   * the sign. In countries where signs are read from left to right,
   * "minor_position" zero would be near the left side of the sign.
   */
  minorPosition?: number;
  /**
   * The direction of traffic for the referenced TYPE_ROUTE feature.
   */
  routeDirection?:  | "DIRECTION_NONE" | "DIRECTION_NORTH" | "DIRECTION_EAST" | "DIRECTION_SOUTH" | "DIRECTION_WEST" | "DIRECTION_NORTHEAST" | "DIRECTION_NORTHWEST" | "DIRECTION_SOUTHEAST" | "DIRECTION_SOUTHWEST" | "DIRECTION_INNER" | "DIRECTION_OUTER";
  /**
   * If this sign component is of type "TYPE_TEXT", this field contains the
   * text of the component. A NameProto is used to allow language and flags to
   * be associated with the text.
   */
  text?: GeostoreNameProto;
  /**
   * This type of content represented by this sign component.
   */
  type?:  | "TYPE_TEXT";
}

function serializeGeostoreRoadSignComponentProto(data: any): GeostoreRoadSignComponentProto {
  return {
    ...data,
    featureId: data["featureId"] !== undefined ? serializeGeostoreFeatureIdProto(data["featureId"]) : undefined,
  };
}

function deserializeGeostoreRoadSignComponentProto(data: any): GeostoreRoadSignComponentProto {
  return {
    ...data,
    featureId: data["featureId"] !== undefined ? deserializeGeostoreFeatureIdProto(data["featureId"]) : undefined,
  };
}

/**
 * A RoadSignProto holds the details of a road sign. Currently this is simply a
 * list of the items that appear on the sign and their relative position.
 */
export interface GeostoreRoadSignProto {
  /**
   * The list of components for a single road sign. A sign may be composed of
   * multiple components, each with its own position and content.
   */
  component?: GeostoreRoadSignComponentProto[];
}

function serializeGeostoreRoadSignProto(data: any): GeostoreRoadSignProto {
  return {
    ...data,
    component: data["component"] !== undefined ? data["component"].map((item: any) => (serializeGeostoreRoadSignComponentProto(item))) : undefined,
  };
}

function deserializeGeostoreRoadSignProto(data: any): GeostoreRoadSignProto {
  return {
    ...data,
    component: data["component"] !== undefined ? data["component"].map((item: any) => (deserializeGeostoreRoadSignComponentProto(item))) : undefined,
  };
}

/**
 * This protocol buffer holds metadata about the association between a segment
 * and a route.
 */
export interface GeostoreRouteAssociationProto {
  /**
   * clang-format on
   */
  displayPreference?:  | "DISPLAY_PREFERRED" | "DISPLAY_BEST" | "DISPLAY_OK" | "DISPLAY_HIDE";
  /**
   * Field-level metadata for the route association.
   */
  metadata?: GeostoreFieldMetadataProto;
  /**
   * Identifies the route feature to which this metadata applies. This is one
   * of the routes the segment refers to via the SegmentProto.route field.
   */
  route?: GeostoreFeatureIdProto;
  /**
   * The direction of the TYPE_ROUTE feature in this route association. A small
   * number of countries (mostly just the United States, Mexico, and Canada) use
   * directional routes. For example, in the United States highway US-1 is
   * referred to as US-1 North or US-1 South on the sides where flow of traffic
   * moves in those directions.
   */
  routeDirection?:  | "DIRECTION_NONE" | "DIRECTION_NORTH" | "DIRECTION_EAST" | "DIRECTION_SOUTH" | "DIRECTION_WEST" | "DIRECTION_NORTHEAST" | "DIRECTION_NORTHWEST" | "DIRECTION_SOUTHEAST" | "DIRECTION_SOUTHWEST" | "DIRECTION_INNER" | "DIRECTION_OUTER";
}

function serializeGeostoreRouteAssociationProto(data: any): GeostoreRouteAssociationProto {
  return {
    ...data,
    route: data["route"] !== undefined ? serializeGeostoreFeatureIdProto(data["route"]) : undefined,
  };
}

function deserializeGeostoreRouteAssociationProto(data: any): GeostoreRouteAssociationProto {
  return {
    ...data,
    route: data["route"] !== undefined ? deserializeGeostoreFeatureIdProto(data["route"]) : undefined,
  };
}

/**
 * A route is a collection of segments that forms a logical group - usually a
 * named road or highway. Segments can belong to more than one route, and the
 * segments of one route may be a subset of the segments of another route (e.g.
 * I-5 N is a subset of I-5). Segments in the collection that define the route
 * do not need to constitute a single uninterrupted line, there can be
 * disconnects. The standard feature properties are interpreted as follows: name
 * - Routes should have one or more names. (While unnamed roads certainly exist
 * in the real world, we choose not to create route features for such roads.
 * Instead, the unnamed segments are merely not part of any route.) address -
 * This should always be empty. type - Specifies a particular route subtype, see
 * feature.proto. point - This should always be empty. polyline - This should
 * always be empty. polygon - This should always be empty. child - The pairs of
 * segments that belong to this route (a given route should always reference
 * segments in both travel directions).
 */
export interface GeostoreRouteProto {
  /**
   * The feature type of the route children. Should be set if and only if all
   * children are of the same feature type.
   */
  childType?: number;
}

/**
 * This protocol buffer holds school district specific attributes for features
 * of TYPE_SCHOOL_DISTRICT.
 */
export interface GeostoreSchoolDistrictProto {
  type?:  | "TYPE_UNIFIED" | "TYPE_ELEMENTARY" | "TYPE_SECONDARY";
}

/**
 * A segment path describes a path through a short set of segments. The segment
 * path can be used for any purpose. At the moment, only TYPE_ROAD_SIGN features
 * can have associated segment paths: The segment path lists the segments that
 * refer to the sign. These are the segments for which the sign is applicable.
 * The sign's physical location is independent of the segments in the path.
 */
export interface GeostoreSegmentPathProto {
  /**
   * Specifies a sequence of feature ids of GeoStore segments. The feature ids
   * are ordered. The path "AB" is not the same as the path "BA". The segments
   * along the path are assumed to be connected via the appropriate
   * intersections. The segment features that are referenced by this subpath
   * refer to this feature back via the road_sign field in segment proto
   * extension.
   */
  subpath?: GeostoreFeatureIdProto[];
}

function serializeGeostoreSegmentPathProto(data: any): GeostoreSegmentPathProto {
  return {
    ...data,
    subpath: data["subpath"] !== undefined ? data["subpath"].map((item: any) => (serializeGeostoreFeatureIdProto(item))) : undefined,
  };
}

function deserializeGeostoreSegmentPathProto(data: any): GeostoreSegmentPathProto {
  return {
    ...data,
    subpath: data["subpath"] !== undefined ? data["subpath"].map((item: any) => (deserializeGeostoreFeatureIdProto(item))) : undefined,
  };
}

/**
 * ---------------------------------------------------------------------------
 * WARNING - if you add new fields to SegmentProto (or to other protos used by
 * SegmentProto), you need to: - ensure that the ShortSegmentsMerger class (in
 * geostore/tools/internal/mr-mergesegments.cc) is aware of them, otherwise the
 * new fields will be discarded randomly. - consider whether they should be
 * cleared in the ClearFeature() function (in
 * maps/render/process-high-priority-roads.cc) if they are irrelevant for
 * rendering high priority roads at far-out zoom levels. - update the test cases
 * that ensure these two packages know all the SegmentProto fields in both
 * mr-mergesegments_test.cc and maps/render/process-high-priority-roads_test.cc
 * or you will break the VersaTile build.
 * ---------------------------------------------------------------------------
 */
export interface GeostoreSegmentProto {
  advisoryMaximumSpeed?: GeostoreAppliedSpeedLimitProto[];
  /**
   * RESERVED
   */
  altitude?: number[];
  /**
   * The average speed that should be expected along this route under normal
   * conditions, in kilometers per hour. (Hopefully we'll replace this with
   * something a lot more sophisticated.)
   */
  avgSpeedKph?: number;
  /**
   * Field-level metadata for the average speed.
   */
  avgSpeedKphMetadata?: GeostoreFieldMetadataProto;
  /**
   * clang-format on
   */
  barrier?:  | "BARRIER_NONE" | "BARRIER_PRESENT" | "BARRIER_LEGAL" | "BARRIER_PHYSICAL";
  /**
   * Field-level metadata for the barrier.
   */
  barrierMetadata?: GeostoreFieldMetadataProto;
  /**
   * clang-format on
   */
  bicycleFacility?:  | "BICYCLE_FACILITY_SEPARATE_TRAIL" | "BICYCLE_FACILITY_PEDESTRIAN_PATH" | "BICYCLE_FACILITY_WIDE_PEDESTRIAN_PATH" | "BICYCLE_FACILITY_SHARED_ROAD" | "BICYCLE_FACILITY_BIKE_LANE" | "BICYCLE_FACILITY_BIKE_LANE_WITH_PEDESTRIAN_PATH" | "BICYCLE_FACILITY_WIDE_SHOULDER" | "BICYCLE_FACILITY_SHARROW" | "BICYCLE_FACILITY_SHARED_ROAD_WITH_PEDESTRIAN_PATH";
  bicycleSafety?:  | "BICYCLE_SAFETY_RECOMMENDED" | "BICYCLE_SAFETY_NEUTRAL" | "BICYCLE_SAFETY_CAUTION";
  condition?:  | "CONDITION_GOOD" | "CONDITION_POOR";
  /**
   * Field-level metadata for the condition.
   */
  conditionMetadata?: GeostoreFieldMetadataProto;
  /**
   * If known, the date that construction is scheduled to begin.
   */
  constructionBeginDate?: GeostoreDateTimeProto;
  /**
   * If known, the date that construction is scheduled to end.
   */
  constructionEndDate?: GeostoreDateTimeProto;
  constructionStatus?:  | "CONSTRUCTION_PLANNED" | "CONSTRUCTION_STARTED" | "CONSTRUCTION_COMPLETE" | "CONSTRUCTION_CLOSED_FOR_MAINTENANCE" | "CONSTRUCTION_DISTURBED_BY_MAINTENANCE";
  /**
   * Field-level metadata for the construction status.
   */
  constructionStatusMetadata?: GeostoreFieldMetadataProto;
  /**
   * Whether the segment is covered by a roof etc. If this field is missing,
   * the status is unknown.
   */
  covered?: boolean;
  /**
   * Average distance between the segment's polyline and edge of the road on
   * this side in meters. It need not be equal to the sum of width of all lanes
   * in this direction. This width includes on-street bicycle lanes but excludes
   * off-street lanes such as sidewalks. The edge of the road is the rightmost
   * edge for segments in right side driving countries and leftmost edge for
   * left side driving countries. Width of the road is sum of this and sibling's
   * distance_to_edge.
   */
  distanceToEdge?: number;
  /**
   * Field-level metadata for distance_to_edge.
   */
  distanceToEdgeMetadata?: GeostoreFieldMetadataProto;
  /**
   * These indicate for what portion of the segment does the outer curb of the
   * segment follow the segment polyline - i.e., where do the sweep curves
   * connect along the outer curb. If unspecified, may be assumed to be equal to
   * lane retraction, preferring outermost lane.
   */
  edgeFollowsSegmentBeginFraction?: number;
  edgeFollowsSegmentEndFraction?: number;
  /**
   * clang-format on
   */
  elevation?:  | "ELEVATION_NORMAL" | "ELEVATION_BRIDGE" | "ELEVATION_TUNNEL" | "ELEVATION_SKYWAY" | "ELEVATION_STAIRWAY" | "ELEVATION_ESCALATOR" | "ELEVATION_ELEVATOR" | "ELEVATION_SLOPEWAY" | "ELEVATION_MOVING_WALKWAY";
  /**
   * Field-level metadata for the elevation.
   */
  elevationMetadata?: GeostoreFieldMetadataProto;
  /**
   * clang-format on
   */
  endpoint?:  | "ENDPOINT_UNKNOWN" | "ENDPOINT_UNRESTRICTED" | "ENDPOINT_UNCONTROLLED" | "ENDPOINT_STOP_SIGN" | "ENDPOINT_ALL_WAY_STOP" | "ENDPOINT_TRAFFIC_LIGHT" | "ENDPOINT_THREE_WAY" | "ENDPOINT_FLASHING_RED" | "ENDPOINT_FLASHING_YELLOW" | "ENDPOINT_YIELD" | "ENDPOINT_MERGE" | "ENDPOINT_ROUNDABOUT" | "ENDPOINT_RAILROAD_CROSSING" | "ENDPOINT_NO_EXIT" | "ENDPOINT_WRONG_WAY" | "ENDPOINT_TOLL_BOOTH";
  /**
   * Field-level metadata for the endpoint.
   */
  endpointMetadata?: GeostoreFieldMetadataProto;
  /**
   * Detailed information about grade levels along the segment. If a
   * GradeLevelProto is not present for any point (index) along the segment, the
   * default grade level is zero. In between two points (indexes), the grade
   * level of the segment is taken to be the max of the grade levels on either
   * side of it. See gradelevel.proto for semantics of repeated indexes.
   */
  gradeLevel?: GeostoreGradeLevelProto[];
  /**
   * Internal-only data.
   */
  internal?: GeostoreInternalSegmentProto;
  /**
   * If specified, the perpendicular offset in meters from a road segment to an
   * interpolated address along that road segment. See
   * go/synthetic-address-positions.
   */
  interpolationOffsetMeters?: number;
  /**
   * The intersection feature corresponding to the destination of this segment.
   * Intersections are used to represent the connectivity between segments. Each
   * intersection stores the segment ids of all the incoming and outgoing
   * segments that meet at that intersection. Turns can be made from this
   * segment to any of the outgoing segments of its intersection, unless there
   * is a restriction that explicitly disallows the turn (see below). Every
   * segment has an intersection object, even if there are no other segments to
   * connect to (i.e., a cul-de-sac or dead end).
   */
  intersection?: GeostoreFeatureIdProto;
  /**
   * Specifies whether the max_permitted_speed_kph was derived from a heuristic
   * as opposed to coming from an authoritative source.
   */
  isMaxPermittedSpeedDerived?: boolean;
  /**
   * Detailed information about each lane in this direction, if available.
   * Lanes are numbered from inside of the road outward, i.e. the lane next to
   * the center line is lane 0. Note that lanes that are valid for travel in
   * both directions appear in both segments of a segment pair (left turn lanes,
   * one-lane roads, some passing lanes, reversing lanes). Some lanes may not be
   * usable by cars, such as bike lanes. Also, some lanes may not exist along
   * the entire segment, e.g. left- or right-turn lanes that appear just before
   * the intersection.
   */
  lane?: GeostoreLaneProto[];
  /**
   * The legal maximum, legal minimum, and advisory (recommended but
   * non-legally binding) maximum speed limits that are permitted on this
   * segment. These should be the segment's legal limits; however, note that it
   * may contain estimated values based on country-wide defaults and other
   * heuristics (see 'AppliedSpeedLimitProto.trust_level'). Before exposing
   * these fields to users as the legal speed limit please consult with Google
   * lawyers.
   */
  legalMaximumSpeed?: GeostoreAppliedSpeedLimitProto[];
  legalMinimumSpeed?: GeostoreAppliedSpeedLimitProto[];
  /**
   * The maximum speed that is permitted on this segment, in kilometers per
   * hour. This should be the segment's legal speed limit; however, note that it
   * may contain estimated values based on country-wide defaults and other
   * heuristics (see 'is_max_permitted_speed_derived' below). Before exposing
   * this field to users as the legal speed limit please consult with Google
   * lawyers.
   */
  maxPermittedSpeedKph?: number;
  /**
   * Field-level metadata for the maximum permitted speed.
   */
  maxPermittedSpeedKphMetadata?: GeostoreFieldMetadataProto;
  /**
   * Specifies whether this segment carries right-hand traffic (cars keep to
   * the right side of the road) instead of left-hand traffic (cars keep to the
   * left side). This is true for US roads and false for UK roads, for example.
   * See go/wikip/Left-_and_right-hand_traffic.
   */
  onRight?: boolean;
  /**
   * Defines the pedestrian crossing(s) between the end point of this segment
   * and the start point of this segment's sibling.
   */
  pedestrianCrossing?: GeostorePedestrianCrossingProto;
  /**
   * clang-format on
   */
  pedestrianFacility?:  | "PEDESTRIAN_FACILITY_UNKNOWN" | "PEDESTRIAN_FACILITY_NONE" | "PEDESTRIAN_FACILITY_PRESENT" | "PEDESTRIAN_FACILITY_SIDEWALK" | "PEDESTRIAN_FACILITY_WIDE_SHOULDER";
  pedestrianGrade?:  | "PEDESTRIAN_GRADE_FLAT" | "PEDESTRIAN_GRADE_UP" | "PEDESTRIAN_GRADE_DOWN";
  /**
   * 
   * LINT.ThenChange(//depot/google3/maps/pathfinder/pgraph/pgraph-segment-categories.cc)
   */
  priority?:  | "PRIORITY_UNKNOWN" | "PRIORITY_NON_TRAFFIC" | "PRIORITY_TERMINAL" | "PRIORITY_LOCAL" | "PRIORITY_MINOR_ARTERIAL" | "PRIORITY_MAJOR_ARTERIAL" | "PRIORITY_SECONDARY_ROAD" | "PRIORITY_PRIMARY_HIGHWAY" | "PRIORITY_LIMITED_ACCESS" | "PRIORITY_CONTROLLED_ACCESS";
  /**
   * Field-level metadata for the priority.
   */
  priorityMetadata?: GeostoreFieldMetadataProto;
  /**
   * The set of restrictions that apply to this segment. Restrictions may make
   * a single segment, turn, or more complex maneuver along a set of segments
   * unroutable for the specified travel modes, or may only add penalties or
   * warnings, depending on the restriction type. Turn restrictions are one
   * example of a restriction. By default, turns are allowed onto all outgoing
   * segments from this segment's intersection (including the sibling of this
   * segment, i.e. U-turns are allowed by default). If any of these turns are
   * disallowed they will be listed as "subpath restrictions". A subpath
   * restriction disallows travel on given sequence of segments. In the case of
   * a disallowed turn, the subpath simply consists of the source and
   * destination feature ids. There may also be restrictions that apply to all
   * travel on this segment (e.g. chains required, or closed in winter), or
   * restrictions that just apply to certain lanes (e.g. high occupancy vehicle
   * lanes).
   */
  restriction?: GeostoreRestrictionProto[];
  /**
   * The road monitors that monitor this segment for traffic violations.
   */
  roadMonitor?: GeostoreFeatureIdProto[];
  /**
   * The road sign(s) which this segment refers to. These are features of
   * TYPE_ROAD_SIGN that are applicable to this segment. For example, a sign
   * that says "TO KIRKLAND" might apply to several segments on a freeway
   * off-ramp (until the end of the ramp). Note that this field makes it easy to
   * find the signs for a given road segment. The feature for the sign lists the
   * segments that refer to it.
   */
  roadSign?: GeostoreFeatureIdProto[];
  /**
   * The route(s) to which this segment belongs.
   */
  route?: GeostoreFeatureIdProto[];
  /**
   * Holds metadata about the associations between this segment and the route
   * features listed in the route field. This metadata need not be present; the
   * only consistency requirement is that every feature ID that appears inside
   * 'route_association' must also appear in the repeated 'route' field. If a
   * route does not appear in route_association, consumers should assume that it
   * has a default initialized RouteAssociationProto.
   */
  routeAssociation?: GeostoreRouteAssociationProto[];
  /**
   * Indicates whether the segment's opposing lanes of traffic are separated
   * from this segment, and hence have been represented in a separate feature.
   * This means that there are two pairs of siblings instead of one.
   */
  separatedRoadways?: boolean;
  /**
   * The other segment of this segment pair (see above). The segment that is
   * referenced by the sibling field refers to this feature back via the same
   * sibling field. Both segment and sibling should have the same properties
   * such as geometry, country code, elevation, level relation, priority etc.
   * Since routes are required to have segment and sibling at the same time, the
   * set of routes on a segment is same to that of the sibling.
   */
  sibling?: GeostoreFeatureIdProto;
  /**
   * clang-format on
   * LINT.ThenChange(//depot/google3/geostore/base/proto/lane.proto) Specific
   * lanes may override this segment-level surface type.
   */
  surface?:  | "SURFACE_UNKNOWN" | "SURFACE_PAVED" | "SURFACE_ASPHALT" | "SURFACE_CONCRETE" | "SURFACE_CHIPSEAL" | "SURFACE_BRICK" | "SURFACE_SETT" | "SURFACE_COBBLESTONE" | "SURFACE_UNPAVED" | "SURFACE_GRAVEL" | "SURFACE_DIRT" | "SURFACE_SAND";
  /**
   * Field-level metadata for the surface.
   */
  surfaceMetadata?: GeostoreFieldMetadataProto;
  /**
   * The geometric sweeps between this segment and nearby segments, used for
   * real road width rendering. A sweep describes the surface that connects to
   * segments.
   */
  sweep?: GeostoreSweepProto[];
  /**
   * If this segment is part of a toll road. It would be nice to have data
   * about the toll cost, locations of toll booths, and so forth. Sadly, we
   * don't have this data at this time.
   */
  tollRoad?: boolean;
  /**
   * clang-format on
   * LINT.ThenChange(//depot/google3/maps/pathfinder/pgraph/pgraph-segment-categories.cc)
   */
  usage?:  | "USAGE_ANY" | "USAGE_RAMP" | "USAGE_ON_RAMP" | "USAGE_OFF_RAMP" | "USAGE_ON_OFF_RAMP" | "USAGE_INTERCHANGE" | "USAGE_SPECIAL_TRAFFIC_FIGURE" | "USAGE_ROUNDABOUT" | "USAGE_ROUNDABOUT_BYPASS" | "USAGE_ROUNDABOUT_INTERNAL_BYPASS" | "USAGE_ROUNDABOUT_EXTERNAL_BYPASS" | "USAGE_ENCLOSED_TRAFFIC_AREA" | "USAGE_PEDESTRIAN_MALL" | "USAGE_MAJOR_PEDESTRIAN_MALL" | "USAGE_MINOR_PEDESTRIAN_MALL" | "USAGE_WALKWAY" | "USAGE_TRAIL" | "USAGE_STATION_PATH" | "USAGE_ACCESS_PATH" | "USAGE_CROSSING" | "USAGE_MARKED_CROSSING" | "USAGE_UNMARKED_CROSSING" | "USAGE_OVERPASS" | "USAGE_UNDERPASS" | "USAGE_HALLWAY" | "USAGE_TURN_SEGMENT" | "USAGE_INDOOR_CONNECTION_PATH";
  /**
   * A collection of landmarks that are visible when traveling along this
   * segment and useful for wayfinding to users following routes using this
   * segment. The landmark need not be on the segment. Each segment in a pair of
   * siblings specifies its landmarks independently. A landmark applicable to
   * both appears in both.
   */
  visibleLandmark?: GeostoreLandmarkReferenceProto[];
}

function serializeGeostoreSegmentProto(data: any): GeostoreSegmentProto {
  return {
    ...data,
    internal: data["internal"] !== undefined ? serializeGeostoreInternalSegmentProto(data["internal"]) : undefined,
    intersection: data["intersection"] !== undefined ? serializeGeostoreFeatureIdProto(data["intersection"]) : undefined,
    lane: data["lane"] !== undefined ? data["lane"].map((item: any) => (serializeGeostoreLaneProto(item))) : undefined,
    pedestrianCrossing: data["pedestrianCrossing"] !== undefined ? serializeGeostorePedestrianCrossingProto(data["pedestrianCrossing"]) : undefined,
    restriction: data["restriction"] !== undefined ? data["restriction"].map((item: any) => (serializeGeostoreRestrictionProto(item))) : undefined,
    roadMonitor: data["roadMonitor"] !== undefined ? data["roadMonitor"].map((item: any) => (serializeGeostoreFeatureIdProto(item))) : undefined,
    roadSign: data["roadSign"] !== undefined ? data["roadSign"].map((item: any) => (serializeGeostoreFeatureIdProto(item))) : undefined,
    route: data["route"] !== undefined ? data["route"].map((item: any) => (serializeGeostoreFeatureIdProto(item))) : undefined,
    routeAssociation: data["routeAssociation"] !== undefined ? data["routeAssociation"].map((item: any) => (serializeGeostoreRouteAssociationProto(item))) : undefined,
    sibling: data["sibling"] !== undefined ? serializeGeostoreFeatureIdProto(data["sibling"]) : undefined,
    sweep: data["sweep"] !== undefined ? data["sweep"].map((item: any) => (serializeGeostoreSweepProto(item))) : undefined,
    visibleLandmark: data["visibleLandmark"] !== undefined ? data["visibleLandmark"].map((item: any) => (serializeGeostoreLandmarkReferenceProto(item))) : undefined,
  };
}

function deserializeGeostoreSegmentProto(data: any): GeostoreSegmentProto {
  return {
    ...data,
    internal: data["internal"] !== undefined ? deserializeGeostoreInternalSegmentProto(data["internal"]) : undefined,
    intersection: data["intersection"] !== undefined ? deserializeGeostoreFeatureIdProto(data["intersection"]) : undefined,
    lane: data["lane"] !== undefined ? data["lane"].map((item: any) => (deserializeGeostoreLaneProto(item))) : undefined,
    pedestrianCrossing: data["pedestrianCrossing"] !== undefined ? deserializeGeostorePedestrianCrossingProto(data["pedestrianCrossing"]) : undefined,
    restriction: data["restriction"] !== undefined ? data["restriction"].map((item: any) => (deserializeGeostoreRestrictionProto(item))) : undefined,
    roadMonitor: data["roadMonitor"] !== undefined ? data["roadMonitor"].map((item: any) => (deserializeGeostoreFeatureIdProto(item))) : undefined,
    roadSign: data["roadSign"] !== undefined ? data["roadSign"].map((item: any) => (deserializeGeostoreFeatureIdProto(item))) : undefined,
    route: data["route"] !== undefined ? data["route"].map((item: any) => (deserializeGeostoreFeatureIdProto(item))) : undefined,
    routeAssociation: data["routeAssociation"] !== undefined ? data["routeAssociation"].map((item: any) => (deserializeGeostoreRouteAssociationProto(item))) : undefined,
    sibling: data["sibling"] !== undefined ? deserializeGeostoreFeatureIdProto(data["sibling"]) : undefined,
    sweep: data["sweep"] !== undefined ? data["sweep"].map((item: any) => (deserializeGeostoreSweepProto(item))) : undefined,
    visibleLandmark: data["visibleLandmark"] !== undefined ? data["visibleLandmark"].map((item: any) => (deserializeGeostoreLandmarkReferenceProto(item))) : undefined,
  };
}

/**
 * This proto represents the geographic area served by an establishment.
 * WARNING: This proto is not meant to be used directly. Please use the provided
 * libraries. http://google3/geostore/base/public/service_area.h
 * http://google3/java/com/google/geostore/base/ServiceArea.java
 */
export interface GeostoreServiceAreaProto {
  /**
   * The features that make up the service area for this establishment. These
   * features are subject to the following constraints applied by editing
   * middleware (notably, not strictly enforced by lints in storage): 1. The
   * following feature types (and their subtypes) may be used: + TYPE_ISLAND +
   * TYPE_POLITICAL, except the following prohibited subtypes: -
   * TYPE_CONSTITUENCY - TYPE_LAND_PARCEL + TYPE_POSTAL 2. There is a maximum
   * limit (currently 20) to the number of areas which may be provided. This is
   * due to serving efficiency limitations. 3. There are no additional geometry
   * requirements for these features beyond the requirements based on the
   * feature types above. In practice this means that these features will either
   * have polygonal or point-based geometries. 4. These referenced features are
   * generally required to have names, though this is not strictly enforced.
   */
  servedFeature?: GeostoreFeatureIdProto[];
}

function serializeGeostoreServiceAreaProto(data: any): GeostoreServiceAreaProto {
  return {
    ...data,
    servedFeature: data["servedFeature"] !== undefined ? data["servedFeature"].map((item: any) => (serializeGeostoreFeatureIdProto(item))) : undefined,
  };
}

function deserializeGeostoreServiceAreaProto(data: any): GeostoreServiceAreaProto {
  return {
    ...data,
    servedFeature: data["servedFeature"] !== undefined ? data["servedFeature"].map((item: any) => (deserializeGeostoreFeatureIdProto(item))) : undefined,
  };
}

/**
 * Defines an ordered reference to a line variants stop.
 */
export interface GeostoreServicedStopProto {
  /**
   * Reference to a Transit POI feature (gcid:transit_station) or platform
   * compound section (gcid:railway_platform) serviced by the line variant.
   */
  id?: GeostoreFeatureIdProto;
  /**
   * An index representing the order in which the above station is serviced by
   * the line variant.
   */
  index?: number;
}

function serializeGeostoreServicedStopProto(data: any): GeostoreServicedStopProto {
  return {
    ...data,
    id: data["id"] !== undefined ? serializeGeostoreFeatureIdProto(data["id"]) : undefined,
  };
}

function deserializeGeostoreServicedStopProto(data: any): GeostoreServicedStopProto {
  return {
    ...data,
    id: data["id"] !== undefined ? deserializeGeostoreFeatureIdProto(data["id"]) : undefined,
  };
}

/**
 * This protocol buffer holds attributes for features of TYPE_SKI_BOUNDARY.
 */
export interface GeostoreSkiBoundaryProto {
  type?:  | "TYPE_ANY" | "TYPE_DANGER" | "TYPE_SKI_AREA" | "TYPE_SLOW_ZONE";
}

/**
 * This protocol buffer holds attributes for features of TYPE_SKI_LIFT.
 */
export interface GeostoreSkiLiftProto {
  /**
   * clang-format on
   */
  type?:  | "TYPE_ANY" | "TYPE_SURFACE" | "TYPE_T_BAR" | "TYPE_J_BAR" | "TYPE_ROPE_TOW" | "TYPE_POMA" | "TYPE_CARPET" | "TYPE_FUNICULAR" | "TYPE_GONDOLA" | "TYPE_CHAIR" | "TYPE_AERIAL" | "TYPE_TRAM";
}

/**
 * This protocol buffer holds attributes for features of TYPE_SKI_TRAIL.
 */
export interface GeostoreSkiTrailProto {
  difficulty?:  | "DIFFICULTY_EASIEST" | "DIFFICULTY_EASY" | "DIFFICULTY_INTERMEDIATE" | "DIFFICULTY_ADVANCED_INTERMEDIATE" | "DIFFICULTY_DIFFICULT" | "DIFFICULTY_ADVANCED_DIFFICULT";
  type?:  | "TYPE_ANY" | "TYPE_GLADE" | "TYPE_TRAIL_TERRAIN" | "TYPE_TRAIL" | "TYPE_RACE_COURSE" | "TYPE_BOWL";
}

/**
 * MapFacts GAIA ID assigned to this feature. These values are virtual GAIA IDs
 * from MapFacts, and as such are not stored in Focus.
 */
export interface GeostoreSocialReferenceProto {
  /**
   * WARNING: Please do NOT introduce new uses; treat this field as if it were
   * deprecated.
   */
  baseGaiaId?: bigint;
  /**
   * GAIA ID used when a business has been claimed. This value is a robot GAIA
   * ID. Robots are a special type of GAIA account used to denote identity for a
   * user or a group of users, but are not logged-in directly by a user.
   */
  claimedGaiaId?: bigint;
  /**
   * WARNING: Please do NOT introduce new uses; treat this field as if it were
   * deprecated.
   */
  gaiaIdForDisplay?: bigint;
}

function serializeGeostoreSocialReferenceProto(data: any): GeostoreSocialReferenceProto {
  return {
    ...data,
    baseGaiaId: data["baseGaiaId"] !== undefined ? String(data["baseGaiaId"]) : undefined,
    claimedGaiaId: data["claimedGaiaId"] !== undefined ? String(data["claimedGaiaId"]) : undefined,
    gaiaIdForDisplay: data["gaiaIdForDisplay"] !== undefined ? String(data["gaiaIdForDisplay"]) : undefined,
  };
}

function deserializeGeostoreSocialReferenceProto(data: any): GeostoreSocialReferenceProto {
  return {
    ...data,
    baseGaiaId: data["baseGaiaId"] !== undefined ? BigInt(data["baseGaiaId"]) : undefined,
    claimedGaiaId: data["claimedGaiaId"] !== undefined ? BigInt(data["claimedGaiaId"]) : undefined,
    gaiaIdForDisplay: data["gaiaIdForDisplay"] !== undefined ? BigInt(data["gaiaIdForDisplay"]) : undefined,
  };
}

/**
 * Source infos are the canonical way to establish data provenance. They can
 * currently be set on features, edits, and issues. Every feature has a repeated
 * list of SourceInfoProto messages to describe the source data that was used in
 * building this feature. The data includes a feature id that points to
 * additional data about the data source (version, copyright notice, etc), and
 * optional "raw data" that is taken directly from the provider's format and has
 * not been converted to a canonical form.
 */
export interface GeostoreSourceInfoProto {
  /**
   * This is the URL of a page representing all the data from this source in
   * this feature. It may have be the ultimate source of the data (in case of
   * scraping) or merely the same data styled according the provider's taste.
   * There is a similar field in DataSourceProto which is NOT cached in this
   * field, since it has a different meaning.
   */
  attributionUrl?: GeostoreUrlProto[];
  /**
   * The time that this particular piece of data was collected. If different
   * attributes were collected on different dates, this is the date of the most
   * recent edit.
   */
  collectionDate?: GeostoreDateTimeProto;
  /**
   * A source info may have a magic cookie whose content and semantics are
   * defined by the specific import process or third-party feed. For feeds that
   * are processed by Distillery, the cookie, when set, should contain the
   * unique identifier for the feature as provided by the feed.
   */
  cookie?: string;
  /**
   * The dataset from which this SourceInfoProto was created. The content of
   * this string will be determined by the data provider (e.g. for MultiNet
   * data, "fra" would indicate the dataset for France). This field is
   * unnecessary for providers that deliver a single dataset per release (e.g.
   * Basarsoft).
   */
  dataset?: string;
  /**
   * The Gaia ID of the user who provided us with this data. This field should
   * never be set on source infos present on features, but may be set on source
   * infos present on edits. DEPRECATED: Most clients should use the "user"
   * field instead where Gaia IDs are encrypted.
   */
  gaiaId?: bigint;
  /**
   * Information about an internal user or system that is operating on behalf
   * of `user` by way of impersonation.
   */
  impersonationUser?: GeostoreUserProto;
  /**
   * The name of the layer from which this SourceInfoProto was created.
   */
  layer?: string;
  /**
   * The OGR feature identifier from which this SourceInfoProto was created.
   * This is an internal OGR record identifier and has nothing to do with any of
   * the feature's fields or the FeatureIdProto for the FeatureProto containing
   * this SourceInfoProto. This field is present only for debugging purposes and
   * possible use in the match pattern of a FeatureChangeProto designed to fix
   * bad source data very early in the importing process.
   */
  ogrFid?: bigint;
  /**
   * The data provider from which this source info was generated. The value
   * must be equal to the one on the TYPE_DATA_SOURCE feature referenced by this
   * source info via the source_id reference (see above).
   */
  provider?: number;
  /**
   * A source info may optionally have a set of key-value pairs that provide
   * "raw data" specific to that source. The types of raw data available will
   * vary from one provider to another and should not be used in production
   * code. Instead, new fields and/or protocol buffers should be defined to
   * represent this information in a canonical form, and the relevant importers
   * should be modified to populate these new fields.
   */
  rawData?: GeostoreRawDataProto[];
  /**
   * The data release from which this SourceInfoProto was created. The format
   * for this string is provider-dependent (e.g. a MultiNet release would look
   * like "2008.01").
   */
  release?: string;
  /**
   * A source info may have a corresponding TYPE_DATA_SOURCE feature that
   * describes it (provider, copyright information, date of release, etc). In
   * the context of edits and issues, this field should not be set.
   */
  sourceId?: GeostoreFeatureIdProto;
  /**
   * A place for clients to attach arbitrary data to a source info. Never set
   * in MapFacts.
   */
  temporaryData?: Proto2BridgeMessageSet;
  /**
   * RESERVED
   */
  user?: GeostoreUserProto;
}

function serializeGeostoreSourceInfoProto(data: any): GeostoreSourceInfoProto {
  return {
    ...data,
    gaiaId: data["gaiaId"] !== undefined ? String(data["gaiaId"]) : undefined,
    impersonationUser: data["impersonationUser"] !== undefined ? serializeGeostoreUserProto(data["impersonationUser"]) : undefined,
    ogrFid: data["ogrFid"] !== undefined ? String(data["ogrFid"]) : undefined,
    sourceId: data["sourceId"] !== undefined ? serializeGeostoreFeatureIdProto(data["sourceId"]) : undefined,
    user: data["user"] !== undefined ? serializeGeostoreUserProto(data["user"]) : undefined,
  };
}

function deserializeGeostoreSourceInfoProto(data: any): GeostoreSourceInfoProto {
  return {
    ...data,
    gaiaId: data["gaiaId"] !== undefined ? BigInt(data["gaiaId"]) : undefined,
    impersonationUser: data["impersonationUser"] !== undefined ? deserializeGeostoreUserProto(data["impersonationUser"]) : undefined,
    ogrFid: data["ogrFid"] !== undefined ? BigInt(data["ogrFid"]) : undefined,
    sourceId: data["sourceId"] !== undefined ? deserializeGeostoreFeatureIdProto(data["sourceId"]) : undefined,
    user: data["user"] !== undefined ? deserializeGeostoreUserProto(data["user"]) : undefined,
  };
}

/**
 * Trust related information about the input source (feed or user) to help
 * feature summarization. Typically, the values in this proto are either based
 * on source's previous observations (e.g., a blocked LBC user or a trusted
 * feed) or their status (Google hired operator or admin user). The proto can
 * later contain a more granular trust score or correctness probabilities. A
 * higher enum value indicates a more trusted source. Leaving room in the value
 * space for adding more granular enums, if they become necessary later.
 */
export interface GeostoreSourceTrustProto {
  /**
   * The level of trust for the source of the observation.
   */
  level?:  | "UNKNOWN" | "BLOCKED" | "NOT_TRUSTED" | "YP_FEEDS" | "TRUSTED" | "SUPER_TRUSTED";
}

/**
 * A speed limit, containing both the limit and the conditions in which it
 * applies.
 */
export interface GeostoreSpeedLimitProto {
  /**
   * The type of speed limit.
   */
  category?:  | "SPEED_LIMIT_CATEGORY_UNKNOWN" | "NONE" | "SCHOOL" | "CONSTRUCTION";
  /**
   * The conditions under which this speed limit is applicable. If multiple
   * conditions are set, at least one of them must be true.
   */
  condition?: GeostoreRoadConditionalProto[];
  /**
   * RESERVED
   */
  sourceType?:  | "SPEED_LIMIT_SOURCE_TYPE_UNKNOWN" | "EXPLICIT" | "IMPLICIT";
  /**
   * A constant speed limit.
   */
  speedWithUnit?: GeostoreSpeedProto;
  /**
   * A speed limit with no limit value. When there is no speed limit in place.
   */
  unlimitedSpeed?: GeostoreUnlimitedSpeedProto;
  /**
   * A dynamic speed limit that can vary within a range of values based on road
   * conditions.
   */
  variableSpeed?: GeostoreVariableSpeedProto;
}

/**
 * A speed value and unit.
 */
export interface GeostoreSpeedProto {
  speed?: number;
  unit?:  | "UNIT_UNKNOWN" | "MILES_PER_HOUR" | "KILOMETERS_PER_HOUR";
}

/**
 * Represents a way to traverse nested fields by referencing their token
 * fields. Everything starts relative to a known root message, specified
 * externally. E.g., suppose we have a feature proto that has a lane with token
 * 0x123 which in turn has a lane connection with token 0x456 for which we want
 * to assert something about flowline altitudes. The field path in that case
 * will look like: field_path: { field_num: 31 # segment } field_path: {
 * field_num: 6 # lane version_token: "0x123" } field_path: { field_num: 8 #
 * lane_connection version_token: "0x456" } field_path: { field_num: 3 # flow }
 * field_path: { field_num: 1 # track } field_path: { # Note: pose is repeated.
 * By not specifying a token we refer to all poses # in a track. field_num: 2 #
 * pose } field_path: { field_num: 4 # altitude } This path could also be
 * represented succinctly in a more human-friendly form as something like:
 * segment.lane[@0x123].lane_connection[@0x456].flow.track.pose[*].altitude
 */
export interface GeostoreStableFieldPathProto {
  /**
   * A sequence of field selectors to be traversed starting from the root
   * message.
   */
  fieldPath?: GeostoreStableFieldPathProtoStableFieldSelector[];
}

export interface GeostoreStableFieldPathProtoStableFieldSelector {
  /**
   * Field number to select.
   */
  fieldNum?: number;
  /**
   * Select repeated field entry by its version token. If this is used, then
   * the message referenced by field_num must have a token field annotated with
   * the (version_token) field option. Must be omitted for leaf non-repeated
   * fields. If unset for a repeated field, we consider this selector to apply
   * equally to all descendants.
   */
  versionToken?: string;
}

/**
 * This protocol buffer represents the 2D polygon connecting two segments at an
 * intersection. Collectively, sweep polygons represent intersections for real
 * road width rendering. Notes: - Sweeps represent geometry between the *end* of
 * one segment and the *end* of the other segment (modulo retraction values). -
 * Sweeps are strongly referenced, meaning geometry is stored on both segments
 * involved in the sweep. For example, in the diagram below, the sweep between A
 * and B would be stored on both segment A and segment B. | B | v --A--> -
 * Sweeps are not strictly stored on adjacent segments. Disconnected segments
 * (e.g., segments separated by an intersection group) may also contain sweeps.
 */
export interface GeostoreSweepProto {
  /**
   * The segment feature connected to this segment via the sweep geometry.
   */
  otherSegmentFeatureId?: GeostoreFeatureIdProto;
  /**
   * Polygonal geometry representing the area between this segment and the
   * other segment.
   */
  polygon?: GeostorePolygonProto;
  /**
   * Describes parameters for generating the edge of this sweep that starts at
   * edge_follows_segment_end_fraction. The other side of the sweep should be
   * described on the sweep present on the sibling pair.
   */
  sweepCurve?: GeostoreCurveConnectionProto;
  /**
   * A token that can be used to identify the version of the data about this
   * sweep.
   */
  sweepToken?: string;
}

function serializeGeostoreSweepProto(data: any): GeostoreSweepProto {
  return {
    ...data,
    otherSegmentFeatureId: data["otherSegmentFeatureId"] !== undefined ? serializeGeostoreFeatureIdProto(data["otherSegmentFeatureId"]) : undefined,
    polygon: data["polygon"] !== undefined ? serializeGeostorePolygonProto(data["polygon"]) : undefined,
  };
}

function deserializeGeostoreSweepProto(data: any): GeostoreSweepProto {
  return {
    ...data,
    otherSegmentFeatureId: data["otherSegmentFeatureId"] !== undefined ? deserializeGeostoreFeatureIdProto(data["otherSegmentFeatureId"]) : undefined,
    polygon: data["polygon"] !== undefined ? deserializeGeostorePolygonProto(data["polygon"]) : undefined,
  };
}

/**
 * This protocol buffer is used to represent telephone numbers and related
 * information.
 */
export interface GeostoreTelephoneProto {
  /**
   * RESERVED
   */
  callRate?: GeostorePriceRangeProto[];
  /**
   * Disambiguates between the types of information or service a caller might
   * seek when contacting this phone number.
   */
  contactCategory?:  | "CONTACT_CATEGORY_UNSPECIFIED" | "CUSTOMER_SERVICE" | "RESERVATIONS" | "SALES";
  flag?:  | "FLAG_NO_COLD_CALLS" | "FLAG_PREFERRED"[];
  /**
   * True if this phone number is not unique to this establishment and might be
   * shared with other features. In case an establishment shares a phone number
   * with a business chain of which it is a member, and the number canonically
   * belongs to that chain, it should be marked as shared for the establishment
   * but not shared for the chain.
   */
  isSharedNumber?: boolean;
  /**
   * RESERVED
   */
  label?: GeostoreNameProto[];
  /**
   * RESERVED
   */
  language?: string[];
  /**
   * Field-level metadata for this telephone number.
   */
  metadata?: GeostoreFieldMetadataProto;
  /**
   * ** DEPRECATED ** This is deprecated in favor of phone_number below. An
   * internationalized representation of a phone number. See
   * //location/country/telephonenumber.proto
   */
  number?: TelephoneNumber;
  /**
   * An internationalized representation of a phone number. See
   * //java/com/google/i18n/phonenumbers/phonenumber.proto
   */
  phoneNumber?: I18nPhonenumbersPhoneNumber;
  /**
   * The features from which this phone number can be called from. For
   * instance, if a phone number can only be called from Europe, this field will
   * contain a reference to the TYPE_CONTINENT feature of Europe. This field is
   * analogous to http://kg/schema/common/phone_number/service_location. The
   * only valid destination feature types are TYPE_CONTINENT and TYPE_POLITICAL.
   * If empty, this phone number can be called from anywhere in Earth (this is
   * the case for the majority of phones).
   */
  serviceLocationFeature?: GeostoreFeatureIdProto[];
  type?:  | "VOICE" | "FAX" | "TDD" | "DATA" | "MOBILE" | "MESSAGING";
}

function serializeGeostoreTelephoneProto(data: any): GeostoreTelephoneProto {
  return {
    ...data,
    phoneNumber: data["phoneNumber"] !== undefined ? serializeI18nPhonenumbersPhoneNumber(data["phoneNumber"]) : undefined,
    serviceLocationFeature: data["serviceLocationFeature"] !== undefined ? data["serviceLocationFeature"].map((item: any) => (serializeGeostoreFeatureIdProto(item))) : undefined,
  };
}

function deserializeGeostoreTelephoneProto(data: any): GeostoreTelephoneProto {
  return {
    ...data,
    phoneNumber: data["phoneNumber"] !== undefined ? deserializeI18nPhonenumbersPhoneNumber(data["phoneNumber"]) : undefined,
    serviceLocationFeature: data["serviceLocationFeature"] !== undefined ? data["serviceLocationFeature"].map((item: any) => (deserializeGeostoreFeatureIdProto(item))) : undefined,
  };
}

/**
 * This protocol buffer stores information related to temporary closure of a
 * feature. The only allowed precisions for a date is PRECISION_DAY.
 * DateTimeProto.seconds should have the lowest legal value for the desired
 * date/time and precision. E.g. for PRECISION_MONTH, 2019-02-15 21:10:30 is not
 * valid, it should be 2019-02-01 00:00:00 instead. NOTE: Each date is stored in
 * UTC but should be interpreted as being in the local timezone. So clients
 * should convert the DateTimeProto to local (civil) time using UTC+0, and then
 * treat the result as local to the feature.
 */
export interface GeostoreTemporaryClosureProto {
  /**
   * The latest when this closure may end, if the exact date is unknown. If
   * set, the feature is operational again no later than this date.
   */
  endAsOfDate?: GeostoreDateTimeProto;
  /**
   * RESERVED
   */
  endDate?: GeostoreDateTimeProto;
  /**
   * The latest when this closure may start, if the exact date is unknown. If
   * set, the feature is temporarily closed starting no later than this date.
   */
  startAsOfDate?: GeostoreDateTimeProto;
  /**
   * RESERVED
   */
  startDate?: GeostoreDateTimeProto;
}

/**
 * Represents text (with an associated language) that is affixed to the
 * beginning and/or end of a primary text.
 */
export interface GeostoreTextAffixProto {
  /**
   * The external form of a Google International Identifiers Initiative (III)
   * LanguageCode object. See google3/i18n/identifiers/languagecode.h for
   * details. These strings should be treated as opaque blobs. You can use
   * LanguageCodeConverter::FromOther to convert the string to a LanguageCode
   * reference. You can then call methods on the LanguageCode class to extract
   * language/script/region subtags (if any). See also
   * http://g3doc/i18n/identifiers/g3doc/using-iii. We place extra restrictions
   * on languages in addition to what the III library requires. See
   * http://go/geo-schema-reference/feature-properties/languages.md
   */
  language?: string;
  /**
   * Text to prepend to the primary text, including any necessary trailing
   * whitespace. At least one of prefix or suffix is required.
   */
  prefix?: string;
  /**
   * Text to append to the end of the primary text, including any necessary
   * leading whitespace. At least one of prefix or suffix is required.
   */
  suffix?: string;
}

export interface GeostoreThreeDimensionalModelProto {
  /**
   * Triangle vertex indices, each triple defines a triangle.
   */
  pointIndices?: number[];
  /**
   * We store a triangular mesh in indexed format. Points array.
   */
  points?: GeostorePointWithHeightProto[];
}

/**
 * A rate which applies based on the precise times of utilization. Defines a
 * rate, as well as restrictions on the start and end times which must be
 * satisfied in order to be eligible for the rate. See go/rate-schema for more
 * details.
 */
export interface GeostoreTimeBasedRateProto {
  /**
   * The rates for this rule. Each duration_based_rate defines the costs
   * associated with a particular duration of a stay. There must be at least one
   * rate with range_start_seconds set to 0 and there cannot be gaps between
   * durations (i.e. there should be no interval uncovered between 0 and the
   * largest range_end_seconds of any duration-based rate).
   */
  durationBasedRate?: GeostoreDurationBasedRateProto[];
  /**
   * If true, tax is included in the prices in this rate. If false, additional
   * taxes may apply.
   */
  taxIncluded?: boolean;
  validEndWithin?: GeostoreTimeScheduleProto;
  /**
   * Time period during which utilization of this rate must start in order to
   * be eligible for the rate. If not set, there is no restriction on the time
   * when the utilization starts.
   */
  validStartWithin?: GeostoreTimeScheduleProto;
}

function serializeGeostoreTimeBasedRateProto(data: any): GeostoreTimeBasedRateProto {
  return {
    ...data,
    durationBasedRate: data["durationBasedRate"] !== undefined ? data["durationBasedRate"].map((item: any) => (serializeGeostoreDurationBasedRateProto(item))) : undefined,
  };
}

function deserializeGeostoreTimeBasedRateProto(data: any): GeostoreTimeBasedRateProto {
  return {
    ...data,
    durationBasedRate: data["durationBasedRate"] !== undefined ? data["durationBasedRate"].map((item: any) => (deserializeGeostoreDurationBasedRateProto(item))) : undefined,
  };
}

export interface GeostoreTimeComponentProto {
  componentType?:  | "COMPONENT_TYPE_POSITIVE" | "COMPONENT_TYPE_MISSING_DATA";
  /**
   * The time component is the intersection of these intervals
   */
  interval?: GeostoreTimeIntervalProto[];
}

/**
 * Not all combinations of optional fields in TimeEndpointProto are allowed.
 * The granularity of time is a path along the directed graph with these edges:
 * second -> minute minute -> hour hour -> day of week hour -> day of month hour
 * -> day of year day of week -> week of month day of week -> week of year day
 * of month -> month day of year -> year week of month -> month week of year ->
 * year month -> year A TimeEndpointProto may not specify two fields that are
 * unordered with respect to each other ("day of year" and "day of week", for
 * instance). The absence of fields larger than any specified field indicates
 * repetition (e.g. no year indicates that the interval occurs every year). The
 * absence of units that are "smaller" than the largest specified unit indicates
 * a default lowest value (no hour means midnight (0)). When intersecting time
 * intervals, "smaller" units repeat within the "larger" unit as many times as
 * necessary. For example, the intersection of the interval from hour 0 to hour
 * 24 with the interval from second 0 to second 1 is equivalent to the union of
 * the set of intervals which represents the first second of every minute of
 * every hour of every day.
 * -----------------------------------------------------------------------------
 * WARNING - if you add new fields to TimeEndpointProto you need to: - ensure
 * AreTimeEndpointsEquivalent considers the new fields (and update the
 * corresponding tests)
 * -----------------------------------------------------------------------------
 */
export interface GeostoreTimeEndpointProto {
  /**
   * Valid ranges are 0-7, 1-31, and 1-366 (see day_type below)
   */
  day?: number;
  dayType?:  | "DAY_OF_WEEK" | "DAY_OF_MONTH" | "DAY_OF_YEAR";
  /**
   * Valid range is 0-24. Because it could be unclear what wrapping hours mean
   * in relation to days, 24 is used to denote midnight at the end of a day.
   */
  hour?: number;
  /**
   * Valid range is 0-59, except when a repetitive minute interval ends at the
   * end of an hour, in which case 60 is a legal end value.
   */
  minute?: number;
  month?:  | "JANUARY" | "FEBRUARY" | "MARCH" | "APRIL" | "MAY" | "JUNE" | "JULY" | "AUGUST" | "SEPTEMBER" | "OCTOBER" | "NOVEMBER" | "DECEMBER" | "NEXT_JANUARY";
  /**
   * Valid range is 0-59, except when a repetitive second interval ends at the
   * end of a minute, in which case 60 is a legal end value.
   */
  second?: number;
  /**
   * Valid ranges are 0-5 and 1-53 (depending on the value of week_type, see
   * below).
   */
  week?: number;
  weekType?:  | "WEEK_OF_MONTH" | "WEEK_OF_YEAR";
  year?: number;
}

export interface GeostoreTimeIntervalProto {
  /**
   * Begin and end are used to specify a range of times: [begin, end). If one
   * is present, the other must be present as well. Additionally, both must have
   * matching time granularities - all fields specified in the begin
   * TimeEndpointProto must be present in the end TimeEndpointProto and
   * vice-versa. Hours are not allowed to wrap (begin.hour() <= end.hour()).
   */
  begin?: GeostoreTimeEndpointProto;
  end?: GeostoreTimeEndpointProto;
  /**
   * If true, then this interval actually encodes the complement of the
   * specified occasion or range. For example, the following TimeIntervalProto
   * encodes all times other than the month of May. TimeIntervalProto[ type =
   * TYPE_RANGE inverted = true begin = TimeEndpointProto[ month = MAY ] end =
   * TimeEndpointProto[ month = JUNE ] ]
   */
  inverted?: boolean;
  /**
   * clang-format on
   */
  occasion?:  | "OCCASION_SEASON" | "OCCASION_SEASON_WINTER" | "OCCASION_SEASON_SUMMER" | "OCCASION_DAYS" | "OCCASION_DAYS_SCHOOL" | "OCCASION_DAYS_HOLIDAY" | "OCCASION_DAYS_PRE_HOLIDAY" | "OCCASION_HOURS" | "OCCASION_HOURS_PEAK" | "OCCASION_HOURS_SCHOOL" | "OCCASION_HOURS_MARKET" | "OCCASION_HOURS_BUSINESS" | "OCCASION_HOURS_DUSK_TO_DAWN" | "OCCASION_HOURS_HIGH_TIDE" | "OCCASION_CONDITIONS" | "OCCASION_CONDITIONS_HIGH_WATER" | "OCCASION_CONDITIONS_ADVERSE" | "OCCASION_CONDITIONS_ADVERSE_RAIN" | "OCCASION_CONDITIONS_ADVERSE_WET" | "OCCASION_CONDITIONS_ADVERSE_FOG" | "OCCASION_CONDITIONS_WINTERY" | "OCCASION_CONDITIONS_WINTERY_AVALANCHE" | "OCCASION_CONDITIONS_WINTERY_SNOW" | "OCCASION_CONDITIONS_WINTERY_ICE" | "OCCASION_CONDITIONS_EVENT" | "OCCASION_CONDITIONS_POLLUTION" | "OCCASION_CONDITIONS_LOW_WATER" | "OCCASION_UNDEFINED" | "OCCASION_UNDEFINED_REGULAR" | "OCCASION_UNDEFINED_SELDOM";
  type?:  | "TYPE_OCCASION" | "TYPE_RANGE";
}

export interface GeostoreTimeScheduleProto {
  /**
   * The schedule is the union of these components.
   */
  component?: GeostoreTimeComponentProto[];
}

/**
 * A TimezoneProto holds information about a feature's related time zone.
 */
export interface GeostoreTimezoneProto {
  /**
   * i18n recognized time zone identifier. For the full list of identifiers,
   * see google3/i18n/identifiers/data/timezones.txt.
   */
  id?: string;
  /**
   * Field-level metadata for this relation.
   */
  metadata?: GeostoreFieldMetadataProto;
}

/**
 * A collection of information that applies to a toll cluster.
 */
export interface GeostoreTollClusterProto {
  /**
   * The list of TYPE_INTERSECTION features that are toll points and form this
   * toll cluster. A toll cluser can consist of either a single or a group of
   * intersection points called toll points at the end of various road segments
   * in MapFacts that represent one or more lanes passing through a toll fixture
   * that all go to the same routing destination. This relationship is
   * reciprocal, as a toll point intersection also stores a reference to the
   * toll cluster it belongs to. A toll cluster must have reference to one or
   * more toll points i.e. toll_cluster.intersection should always be populated.
   */
  intersection?: GeostoreFeatureIdProto[];
}

function serializeGeostoreTollClusterProto(data: any): GeostoreTollClusterProto {
  return {
    ...data,
    intersection: data["intersection"] !== undefined ? data["intersection"].map((item: any) => (serializeGeostoreFeatureIdProto(item))) : undefined,
  };
}

function deserializeGeostoreTollClusterProto(data: any): GeostoreTollClusterProto {
  return {
    ...data,
    intersection: data["intersection"] !== undefined ? data["intersection"].map((item: any) => (deserializeGeostoreFeatureIdProto(item))) : undefined,
  };
}

export interface GeostoreTrackProto {
  /**
   * The index of this TrackProto in a list of TrackProtos.
   */
  index?: number;
  /**
   * The instantaneous pose of points along this track. The fields set inside
   * each pose must be set consistently along the track.
   */
  pose?: GeostorePoseProto[];
}

/**
 * A transit line is a named set of transit trips that are advertised to
 * passengers under a common name, and a number of attributes that are true for
 * all those trips. There is no requirement for each trip to travel through the
 * same list of stops or use the same legs, so a line can contain trips in
 * opposite directions or with variations in the sequence of stops. See
 * go/oysterpedia for an overview of the transit feature types. The standard
 * feature properties are interpreted as follows: name - The names of this line,
 * including both long and short names, if available. Short names like "10" or
 * "Blue" should carry the FLAG_ABBREVIATED, long names like "Dublin/Pleasanton
 * line" should not. The preferred name (one per language) for displaying the
 * line on its own (e.g., as a search result for the line) should carry the
 * FLAG_PREFERRED. website - The official web page describing this line.
 * Repeated if multilingual. Line features have no geometry (neither points nor
 * polylines nor polygons). Within Transit Oyster, geometry can be found in
 * legs. Additional data only in Transit Oyster: child - The legs of this line,
 * in no particular order. source_info - Specifies the GTFS routes that match
 * this feature. Each is given as a PROVIDER_GOOGLE_TRANSIT source_info where
 * dataset is the feed name and cookie is the route_id.
 */
export interface GeostoreTransitLineProto {
  /**
   * The transit agencies responsible for operating this line. All lines should
   * have at least one agency, and most will have exactly one. The following
   * cases are reasons for multiple agencies: - Code share: Two or more agencies
   * share trips - Alternations: Each trip is run by one of multiple agencies -
   * Additional: All trips run by one agency, but a second one sells tickets In
   * all cases the order has no meaning. Clarification comes from the trips.
   */
  agency?: GeostoreFeatureIdProto[];
  /**
   * The background color of labels for that transit line. The encoding is like
   * in HTML or CSS, eg. 0x11ff00 means a bit of red, full green, no blue, in
   * sRGB color space. The most significant byte must be zero, i.e. no
   * transparency.
   */
  labelBackgroundColor?: number;
  /**
   * The text color of labels for that transit line. Encoding like
   * label_background_color.
   */
  labelTextColor?: number;
  /**
   * The transit stations (establishment POIs with gcid:transit_station) which
   * this transit line can go through, in no particular order. Usage note: The
   * source of truth are the transit leg features in Transit Oyster. In
   * MapFacts, that information is cached in two locations: in this field, and
   * in transit station attachments on POIs. Do not assume these locations are
   * always up to date and/or synchronized with each other.
   */
  stations?: GeostoreFeatureIdProto[];
  /**
   * The type of vehicle that applies to all trips that use this line.
   */
  vehicleType?:  | "VEHICLE_TYPE_ANY" | "VEHICLE_TYPE_RAIL" | "VEHICLE_TYPE_METRO_RAIL" | "VEHICLE_TYPE_SUBWAY" | "VEHICLE_TYPE_TRAM" | "VEHICLE_TYPE_MONORAIL" | "VEHICLE_TYPE_HEAVY_RAIL" | "VEHICLE_TYPE_COMMUTER_TRAIN" | "VEHICLE_TYPE_HIGH_SPEED_TRAIN" | "VEHICLE_TYPE_LONG_DISTANCE_TRAIN" | "VEHICLE_TYPE_BUS" | "VEHICLE_TYPE_INTERCITY_BUS" | "VEHICLE_TYPE_TROLLEYBUS" | "VEHICLE_TYPE_SHARE_TAXI" | "VEHICLE_TYPE_FERRY" | "VEHICLE_TYPE_CABLE_CAR" | "VEHICLE_TYPE_GONDOLA_LIFT" | "VEHICLE_TYPE_FUNICULAR" | "VEHICLE_TYPE_SPECIAL" | "VEHICLE_TYPE_HORSE_CARRIAGE" | "VEHICLE_TYPE_AIRPLANE";
}

function serializeGeostoreTransitLineProto(data: any): GeostoreTransitLineProto {
  return {
    ...data,
    agency: data["agency"] !== undefined ? data["agency"].map((item: any) => (serializeGeostoreFeatureIdProto(item))) : undefined,
    stations: data["stations"] !== undefined ? data["stations"].map((item: any) => (serializeGeostoreFeatureIdProto(item))) : undefined,
  };
}

function deserializeGeostoreTransitLineProto(data: any): GeostoreTransitLineProto {
  return {
    ...data,
    agency: data["agency"] !== undefined ? data["agency"].map((item: any) => (deserializeGeostoreFeatureIdProto(item))) : undefined,
    stations: data["stations"] !== undefined ? data["stations"].map((item: any) => (deserializeGeostoreFeatureIdProto(item))) : undefined,
  };
}

/**
 * A line variant is a specific instantiation of a line concept, denoted by the
 * ordered set of stops and collection of segments that it traverses. Line
 * variants are modeled as TYPE_ROUTE features with gcid:transit_line_variant.
 * This proto stores line-variant-specific information that is not generally
 * applicable to all routes. Schema Design Doc:
 * go/transit-line-concepts-and-variants
 */
export interface GeostoreTransitLineVariantProto {
  /**
   * Reference to the line variants line concept.
   */
  lineConcept?: GeostoreFeatureIdProto;
  /**
   * Ordered list of stations or platforms serviced by this line variant. The
   * order is captured by the ServicedStopProto.index field.
   */
  stops?: GeostoreServicedStopProto[];
}

function serializeGeostoreTransitLineVariantProto(data: any): GeostoreTransitLineVariantProto {
  return {
    ...data,
    lineConcept: data["lineConcept"] !== undefined ? serializeGeostoreFeatureIdProto(data["lineConcept"]) : undefined,
    stops: data["stops"] !== undefined ? data["stops"].map((item: any) => (serializeGeostoreServicedStopProto(item))) : undefined,
  };
}

function deserializeGeostoreTransitLineVariantProto(data: any): GeostoreTransitLineVariantProto {
  return {
    ...data,
    lineConcept: data["lineConcept"] !== undefined ? deserializeGeostoreFeatureIdProto(data["lineConcept"]) : undefined,
    stops: data["stops"] !== undefined ? data["stops"].map((item: any) => (deserializeGeostoreServicedStopProto(item))) : undefined,
  };
}

/**
 * Encapsulates information related to an individual transit station.
 */
export interface GeostoreTransitStationProto {
  /**
   * Transit agencies which service this transit station. A station can be
   * serviced by one or more transit agencies. See
   * go/transit-agency-relation-migration for more information.
   */
  agencies?: GeostoreFeatureIdProto[];
}

function serializeGeostoreTransitStationProto(data: any): GeostoreTransitStationProto {
  return {
    ...data,
    agencies: data["agencies"] !== undefined ? data["agencies"].map((item: any) => (serializeGeostoreFeatureIdProto(item))) : undefined,
  };
}

function deserializeGeostoreTransitStationProto(data: any): GeostoreTransitStationProto {
  return {
    ...data,
    agencies: data["agencies"] !== undefined ? data["agencies"].map((item: any) => (deserializeGeostoreFeatureIdProto(item))) : undefined,
  };
}

export interface GeostoreTrustSignalsProto {
  /**
   * Trust signals for the source of a given observation, typically based on
   * historical evidences or status (like internal Google operator).
   */
  sourceTrust?: GeostoreSourceTrustProto;
}

/**
 * A speed limit without a limit value. Used to indicate the absence of a speed
 * limit.
 */
export interface GeostoreUnlimitedSpeedProto {
}

/**
 * Hold a list of URLs, usually to contain translations of a single URL.
 */
export interface GeostoreUrlListProto {
  url?: GeostoreUrlProto[];
}

/**
 * A web location for a Feature. URLs should always be stored in repeated
 * fields because some objects (eg. transit schedules in Brussels) have
 * different URLs for different languages.
 */
export interface GeostoreUrlProto {
  /**
   * The external form of a Google International Identifiers Initiative (III)
   * LanguageCode object. See google3/i18n/identifiers/languagecode.h for
   * details. We place extra restrictions on languages in addition to what the
   * III library requires. See
   * http://go/geo-schema-reference/feature-properties/languages.md This field
   * represents the language of the content of the web site. It may be missing
   * if the web site is language-independent or if the language is unknown.
   */
  language?: string;
  /**
   * Field-level metadata for this URL. NOTE: there are multiple UrlProto
   * fields in the Geo Schema. Metadata here is only expected to be present on
   * FeatureProto.website[].
   */
  metadata?: GeostoreFieldMetadataProto;
  /**
   * ** DEPRECATED ** The pagerank of this URL. Valid values [0, 65535] See
   * http://wiki/Main/NearestSeeds for more information.
   */
  pagerank?: number;
  /**
   * The URL.
   */
  url?: string;
}

/**
 * UserProto identifies a (human) user of Geo Data. Its primary use is in
 * describing the source of pieces of data (e.g. edits). It could be a simple
 * identifier, but isn't so that we can store it in the clear while still
 * preventing correlation between a user's contribution.
 */
export interface GeostoreUserProto {
  /**
   * The user Gaia ID in encrypted form. Wipeout ids take value of "" in bytes.
   */
  encryptedGaiaId?: Uint8Array;
  /**
   * Required. The name of the key used to encrypt the Gaia ID.
   */
  encryptionKeyName?: string;
  /**
   * Required (valid default provided). The config ID of the owner of the above
   * encryption_key_name. This field must be set if the encryption key name is
   * *not* "mapfacts_gaia_id_encryption_key".
   */
  keystoreConfigId?: number;
  /**
   * If possible, writers should set this to a full user email, including the
   * domain. Readers should not assume that this is a well-formed email address.
   * This field may only be set by Atlas, Pushpin and OneRing because they are
   * internal tools which have a PWG exception to store textual usernames in the
   * clear.
   */
  username?: string;
}

function serializeGeostoreUserProto(data: any): GeostoreUserProto {
  return {
    ...data,
    encryptedGaiaId: data["encryptedGaiaId"] !== undefined ? encodeBase64(data["encryptedGaiaId"]) : undefined,
  };
}

function deserializeGeostoreUserProto(data: any): GeostoreUserProto {
  return {
    ...data,
    encryptedGaiaId: data["encryptedGaiaId"] !== undefined ? decodeBase64(data["encryptedGaiaId"] as string) : undefined,
  };
}

/**
 * A speed limit whose value can change based on road, traffic, and weather
 * conditions.
 */
export interface GeostoreVariableSpeedProto {
}

/**
 * A set of vehicle attribute conditionals (ex: weight >= 20T && num_trailers =
 * 2) used to define a slice of all possible vehicles. This can be useful for
 * filtering one or more vehicles by a predicate.
 */
export interface GeostoreVehicleAttributeFilterProto {
  /**
   * A repeated value here is treated as an AND operation. This allows for
   * ranges to be represented by two values (ex: "count < 4" AND "count >= 2"
   * means "2 <= count < 4").
   */
  axleCount?: GeostoreCountComparisonProto[];
  /**
   * Whether the applied vehicle types have a trailer attached to them.
   */
  hasTrailer?: boolean;
  /**
   * List of prohibited hazardous goods for a vehicle to carry. A repeated
   * value here is treated as an OR operation, meaning that they may not carry
   * ANY of the goods listed.
   */
  hazardousGoods?:  | "HAZARDOUS_GOODS_TYPE_UNSPECIFIED" | "EXPLOSIVES" | "GASES" | "FLAMMABLE" | "COMBUSTIBLE" | "ORGANIC" | "POISON" | "RADIOACTIVE" | "CORROSIVE" | "ASPIRATION_HAZARD" | "ENVIRONMENTAL_HAZARD" | "OTHER"[];
  /**
   * A repeated value here is treated as an AND operation. This allows for
   * ranges to be represented by two values (ex: "count <= 4" AND "count > 2"
   * means "2 < count <= 4").
   */
  numTrailers?: GeostoreCountComparisonProto[];
  /**
   * A repeated value here is treated as an AND operation. This allows for
   * ranges to be represented by two values (ex: "length <= 53ft" AND "length >
   * 48ft" means "48ft < length <= 53ft").
   */
  trailerLength?: GeostoreDimensionComparisonProto[];
  /**
   * A repeated value here is treated as an AND operation. This allows for
   * ranges to be represented by two values (ex: "height > 3m" AND "height <=
   * 5m" means "3m < height <= 5m").
   */
  vehicleHeight?: GeostoreDimensionComparisonProto[];
  /**
   * A repeated value here is treated as an AND operation. This allows for
   * ranges to be represented by two values (ex: "length <= 40m" AND "length >
   * 35m" means "35m < length <= 40m").
   */
  vehicleLength?: GeostoreDimensionComparisonProto[];
  /**
   * A repeated value here is treated as an AND operation. This allows for
   * ranges to be represented by two values (ex: "weight < 8T" AND "weight >=
   * 3T" means "3T <= weight < 8T").
   */
  vehicleWeight?: GeostoreWeightComparisonProto[];
  /**
   * A repeated value here is treated as an AND operation. This allows for
   * ranges to be represented by two values (ex: "width < 4m" AND "width >= 2m"
   * means "2m <= width < 4m").
   */
  vehicleWidth?: GeostoreDimensionComparisonProto[];
}

/**
 * A proto representing a vertical ordering of a feature. NOTE: This shouldnt
 * be used if a more specific field can be used instead. E.g., for TYPE_SEGMENT
 * features grade_level field should be preferred. For indoor features
 * RELATION_ON_LEVEL should be preferred. See go/aboutgrades for comparison of
 * various types of levels available.
 */
export interface GeostoreVerticalOrderingProto {
  /**
   * The level represents the relative vertical ordering of a feature among all
   * overlapping features. For example, we may have features along freeway
   * surface have level = 0, and features on an overpass have level = 1. NOTE:
   * Its assumed that all features have level 0 by default, so that its not
   * necessary for all overlapping features to have this set.
   */
  level?: number;
}

/**
 * A weight value tagged with a comparison operator.
 */
export interface GeostoreWeightComparisonProto {
  comparison?:  | "COMPARISONOPERATOR_UNKNOWN" | "LESS_THAN" | "GREATER_THAN";
  comparisonOperator?:  | "UNSPECIFIED" | "EQUAL" | "LESS_THAN" | "LESS_THAN_OR_EQUAL" | "GREATER_THAN" | "GREATER_THAN_OR_EQUAL";
  weightWithUnit?: GeostoreWeightProto;
}

/**
 * A weight with a numerical value and unit.
 */
export interface GeostoreWeightProto {
  unit?:  | "UNIT_UNKNOWN" | "METRIC_TON" | "LONG_TON" | "SHORT_TON" | "POUND" | "KILOGRAM";
  weight?: number;
}

/**
 * An anchor label can be attached to any element to give it a reference
 * address. LogicalEntity links (see goodoc-semantics.proto) may use anchor
 * labels to point to goodoc elements (they may also use indices to locate the
 * element, but the indices could become invalid if the goodocs are allowed to
 * mutate). Multiple elements may have the same anchor.
 */
export interface GoodocAnchorLabel {
  /**
   * There is a generic method for composing such strings. Please take a look
   * at GoodocUtils::GenerateUniqueAnchorName(...) in ocr/goodoc/goodoc-utils.h.
   */
  Anchor?: string;
  anchorScope?: number;
}

/**
 * Bounding box for page structural elements: pictures, paragraphs, characters,
 * etc.
 */
export interface GoodocBoundingBox {
  Height?: number;
  /**
   * Optional magic label, so objects can be sorted on bounding box dimensions
   * easily
   */
  Label?: number;
  /**
   * BoundingBox coordinates and sizes are expressed in pixels
   */
  Left?: number;
  Top?: number;
  Width?: number;
}

/**
 * A way to specify a simple partitioning of a BoundingBox into a sequence of
 * sub-boxes. +----------------------------------------------------+ | | | | | |
 * | span(0) | (1) | (2) | (3) | (4) | | | | | | |
 * +----------------------------------------------------+ This representation
 * can, for example, be used to store coarse Symbol boundaries within a Word
 * (see Word.CompactSymbolBoxes below) instead of per-Symbol BoundingBoxes, for
 * saving space.
 */
export interface GoodocBoxPartitions {
  direction?: number;
  /**
   * "span" is width or height, determined by "direction". If there are k
   * partitions, then there are k - 1 "span" values, one for each except the
   * last symbol (which is redundant).
   */
  span?: number[];
}

/**
 * Break label
 */
export interface GoodocBreakLabel {
  BreakLabelType?: number;
  /**
   * True if break prepends the element
   */
  isPrefix?: boolean;
}

/**
 * Font label
 */
export interface GoodocCharLabel {
  /**
   * The shift of a character from the base line of the string in pixels
   */
  BaseLine?: number;
  /**
   * Height of small characters in pixels on the source image
   */
  CharacterHeight?: number;
  /**
   * The foreground color of the symbol; the default color is 0 (black)
   */
  Color?: number;
  /**
   * Symbol recognition confidence from OCR. Range depends upon OCR Engine.
   */
  Confidence?: number;
  /**
   * The font ID refers to the fonts table in the document header
   */
  FontId?: number;
  /**
   * Size in points (JFYI: point is 1/72"). This is rounded to the nearest
   * whole number.
   */
  FontSize?: number;
  /**
   * Size in points represented as float.
   */
  FontSizeFloat?: number;
  FontType?: number;
  /**
   * If CharacterHeight is defined uncertainly
   */
  HasUncertainHeight?: boolean;
  /**
   * The horizontal scaling for a character, in percents. The default value for
   * this property is 100, which corresponds to no scaling.
   */
  HorizontalScale?: number;
  IsBold?: boolean;
  IsItalic?: boolean;
  IsSmallCaps?: boolean;
  IsStrikeout?: boolean;
  IsSubscript?: boolean;
  IsSuperscript?: boolean;
  /**
   * If OCR Engine marked the character as "suspicious" (this character is
   * likely to be recognized incorrectly).
   */
  IsSuspicious?: boolean;
  IsUnderlined?: boolean;
  /**
   * True if a QA operator has marked this as not OCRable. This is used for
   * complex equations, scripts that the operator can't type, or handwriting.
   */
  NotOcrablePerQA?: boolean;
  /**
   * Symbol-level penalty from the garbage text detector. Lower is better;
   * range = [0,100].
   */
  Penalty?: number;
  /**
   * The probability that a character is written with a Serif font
   */
  SerifProbability?: number;
}

/**
 * Top-level representation of OCRed document
 */
export interface GoodocDocument {
  /**
   * Debug info, recording the history of any editing done through the
   * interface in goodoc-editing.h. The strings look like
   * "MoveParagraph(page_index = 0, source_block_index = 3, ...);
   */
  EditingHistory?: string[];
  header?: GoodocDocumentHeader;
  /**
   * Logical entities are stored as blobs. Depending on the kind of thing this
   * is a goodoc of, a separate .proto file is expected to define the logical
   * entity structure. Hence we can still parse this as a goodoc for people who
   * dont care about this, and people who care about this can parse it
   * specifically. ocr/goodoc/logical-entity-utils.h has methods to read and
   * write these. See Goodoc++ doc
   */
  LogicalEntity?: Uint8Array[];
  /**
   * The names of the proto messages serialized in LogicalEntity, one for each
   * LogicalEntity. The repetitions should number 0 to leave this unspecified,
   * or they should equal the number of LogicalEntity strings.
   */
  LogicalEntityMessageName?: string[];
  page?: GoodocDocumentPage[];
  /**
   * For multi-goodoc documents
   */
  SubDocuments?: GoodocDocument[];
}

function serializeGoodocDocument(data: any): GoodocDocument {
  return {
    ...data,
    LogicalEntity: data["LogicalEntity"] !== undefined ? data["LogicalEntity"].map((item: any) => (encodeBase64(item))) : undefined,
    SubDocuments: data["SubDocuments"] !== undefined ? data["SubDocuments"].map((item: any) => (serializeGoodocDocument(item))) : undefined,
  };
}

function deserializeGoodocDocument(data: any): GoodocDocument {
  return {
    ...data,
    LogicalEntity: data["LogicalEntity"] !== undefined ? data["LogicalEntity"].map((item: any) => (decodeBase64(item as string))) : undefined,
    SubDocuments: data["SubDocuments"] !== undefined ? data["SubDocuments"].map((item: any) => (deserializeGoodocDocument(item))) : undefined,
  };
}

export interface GoodocDocumentHeader {
  font?: GoodocDocumentHeaderFont[];
  OcrEngineId?: string;
  OcrEngineVersion?: string;
}

export interface GoodocDocumentHeaderFont {
  FontId?: number;
  FontName?: string;
}

export interface GoodocDocumentPage {
  block?: GoodocDocumentPageBlock[];
  /**
   * If the garbage text detector was run, the changelist that the binary was
   * sync'ed to (or -1 if unknown), and whether the settings had their
   * production values (or false if unknown).
   */
  GarbageDetectorChangeList?: number;
  GarbageDetectorWasProduction?: boolean;
  /**
   * Height in pixels
   */
  Height?: number;
  /**
   * Horizontal resolution in DPI.
   */
  HorizontalDpi?: number;
  Label?: GoodocLabel;
  mergedpageinfo?: GoodocDocumentPageMergedPageInfo[];
  /**
   * Score of porn classifier from analyzing images on page. Note: This should
   * be named porn_score, but we use PornScore as the name in order to be
   * consistent with the rest of this proto.
   */
  PornScore?: number;
  /**
   * Whether page-level text confidences and other summary data were computed
   * by PostOcrUtils instead of the now-obsolete GarbageTextDetector
   */
  postOcrConfidence?: boolean;
  /**
   * Page level stats (font size, line spacing, etc.)
   */
  stats?: GoodocSummaryStats;
  /**
   * Page text recognition confidence. Range depends on the algorithm but
   * should be consistent in a given volume. 0 is bad, 100 is good.
   */
  TextConfidence?: number;
  /**
   * Vertical resolution in DPI.
   */
  VerticalDpi?: number;
  /**
   * Width in pixels
   */
  Width?: number;
}

export interface GoodocDocumentPageBlock {
  BlockType?: number;
  Box?: GoodocBoundingBox;
  Label?: GoodocLabel;
  /**
   * Which way is upright for this block, and what is the reading order
   * (applicable if there is text here).
   */
  OrientationLabel?: GoodocOrientationLabel;
  Paragraph?: GoodocParagraph[];
  /**
   * If RotatedBox is set, Box must be set as well. See RotatedBoundingBox.
   */
  RotatedBox?: GoodocRotatedBoundingBox;
  /**
   * Block text recognition confidence. Range depends on the algorithm but
   * should be consistent in a given volume. 0 is bad, 100 is good.
   */
  TextConfidence?: number;
}

/**
 * If we have merged text from another goodoc into this one (for example, from
 * a PDF text layer goodoc into an OCR'd goodoc), we record some source goodoc
 * info here.
 */
export interface GoodocDocumentPageMergedPageInfo {
  OcrEngineId?: string;
  OcrEngineVersion?: string;
}

/**
 * Statistics about a particular font size (from CharLabel.FontSize) aggregated
 * over a range of symbols
 */
export interface GoodocFontSizeStats {
  /**
   * CharLabel.FontId and FontSize
   */
  fontId?: number;
  fontSize?: number;
  /**
   * The measurements are in pixels
   */
  medianHeight?: number;
  /**
   * top to bottom
   */
  medianLineHeight?: number;
  /**
   * bottom to next top in para
   */
  medianLineSpace?: number;
  /**
   * top to next top in para
   */
  medianLineSpan?: number;
  medianWidth?: number;
  /**
   * Line stats for this font. "top" corresponds to the highest ascender and
   * "bottom" to the lowest descender. num_lines = # lines with > 50% symbols
   * having this font
   */
  numLines?: number;
  /**
   * Lines (out of num_lines) that have a successor line within their para
   */
  numLineSpaces?: number;
  numSymbols?: number;
}

/**
 * Label aggregates all kinds of optional characteristics of page elements.
 */
export interface GoodocLabel {
  /**
   * AnchorLabel identifies a link target.
   */
  AnchorLabel?: GoodocAnchorLabel[];
  BreakLabel?: GoodocBreakLabel;
  /**
   * CharLabel is specifically intended for symbols
   */
  CharLabel?: GoodocCharLabel;
  /**
   * Languages used in the element (page, block, paragraph or word). Ordered by
   * dominant-language first. Note: content scanjobs processed by the
   * garbage_text_detector before CL 9223538 (Dec. 2008) have LanguageLabels in
   * arbitrary order (within Page and Block elements) -- the confidence value
   * should be inspected to find the dominant language guess for these, rather
   * than just taking the first.
   */
  LanguageLabel?: GoodocLanguageLabel[];
  /**
   * SemanticLabel is defined in goodoc-semantics.proto, it allows rich
   * annotation of content, identifying the nature of page elements.
   */
  SemanticLabel?: GoodocSemanticLabel;
}

/**
 * Weighted language
 */
export interface GoodocLanguageCombinationLanguage {
  /**
   * Bcp47 language code. Note, this is not the same as OceanCode used by
   * goodoc::Document.
   */
  bcp47Tag?: string;
  /**
   * Weight of language. This specifies how likely it is to see the language in
   * the input text. The values don't have to add up to 1.
   */
  weight?: number;
}

/**
 * Language label
 */
export interface GoodocLanguageLabel {
  /**
   * Closest id from i18n/languages/proto/languages.proto; caveat: may not
   * accurately capture the language. GoodocLanguageCodeToLanguage() declared in
   * ocr/goodoc/goodoc-utils.h may be used to convert a Language enum
   * (i18n/languages/proto/languages.proto) to a string suitable for this field.
   */
  ClosestLanguageId?: number;
  /**
   * Confidence level on that language, between 0 and 100
   */
  Confidence?: number;
  /**
   * Old (Ocean) Language Code Usage: The language code is inferred during the
   * running of the Garbage Text Detector and gets set at the paragraph, block
   * and page level. Language code is a string of 3 or more characters. The
   * first 3 letters specify the language, according to ISO 639. Optionally, the
   * 3-letter code can be extended with an underscore and a language variant
   * specifier. Specifiers exist for regional variants or for different forms of
   * language spelling. The regional variants are specified as 2-letter country
   * code, according to ISO 3166. Some examples: Standard "por" - Portuguese,
   * standard "rus" - Russian, standard Regional variants: "por_br" -
   * Portuguese, Brazilian "eng_us" - English, United States Variants of
   * spelling: "rus_old" - Russian, old spelling "chi_tra" - Chinese,
   * traditional "ger_new" - German, new spelling LanguageToGoodocLanguageCode()
   * declared in ocr/goodoc/goodoc-utils.h may be used to convert a Language
   * enum (i18n/languages/proto/languages.proto) to a string suitable for this
   * field. New Language Code Usage: Most of the usages described above were
   * standardized in BCP 47, and these codes are the new stanadard to be used in
   * this field. To load either new or old language codes to form LanguageCode
   * objects, use the function FromOceanCode() in ocr/quality/lang_util.h Note
   * that the function ocr::FromOceanCode is capable of transforming either
   * version of the LanguageCode to a C++ i18n_identifiers::LanguageCode.
   */
  LanguageCode?: string;
}

/**
 * A logical entity in the abstract is just a group of links to the goodoc.
 * Depending on the kind of item, a separate proto file should extend this to
 * define the logical structure for that kind. For example. newspapers.proto
 * defines the logical entity for newspapers. LogicalEntity is also used within
 * some SemanticLabels, for example, for a table-of-contents link.
 */
export interface GoodocLogicalEntity {
  link?: GoodocLogicalEntityLink[];
  Metadata?: string;
}

/**
 * NOTE(gponcin) 2008/11 This is repeated for articles where we may have
 * multiple links in one entity. From Vivek (Atlantis): "The block segmenter
 * outputs a list of headlines on a page as a single logical entity that we
 * attach to the logicalentity(1) for the goodoc."
 */
export interface GoodocLogicalEntityLink {
  /**
   * The preferred way to link to an element is to create an AnchorLabel in the
   * target element and name it here. Multiple elements may contain the same
   * Anchor string.
   */
  Anchor?: string;
  BlockId?: number;
  /**
   * Links may also specifically locate the target element with the following
   * indices. Note that during the course of layout analysis, goodoc elements
   * may move around, so such hard links should be created only very late (or
   * not at all -- Anchors would be more reliable target addresses).
   */
  DocId?: number;
  PageId?: number;
  ParagraphId?: number;
  RouteId?: number;
  SymbolId?: number;
  /**
   * If not defined, link points to the current doc
   */
  Url?: string;
  WordId?: number;
}

/**
 * An Ordinal message represents a single ordinal component of a page number.
 * It encodes the printed or inferred numbering style (Roman, ASCII, etc.) and
 * the ordinal value of the component. An optional set of variable is defined in
 * order to express a sectioned ordinal. A sectioned ordinal may appear in
 * certain page numbering styles, for example "12-1" where "12" identifies a
 * chapter and "1" identifies the page within it. This case will be encoded with
 * value 1 and section_value 12 both of type ASCII.
 */
export interface GoodocOrdinal {
  implicit?:  | "UNKNOWN_IMPLICIT" | "IMPLICIT" | "EXPLICIT";
  sectionStringValue?: string;
  sectionValue?: number;
  /**
   * The following vars describe the section component of an ordinal (if
   * exists). They are used to express situation where a page number has a
   * section component, usually denoating the chapter number. For example pages
   * 5-14, 5-15 will both have the common section 5. (If exists). The semantcis
   * of the section variables correspond to that of the primary part of the
   * ordinal. (Described above).
   */
  sectionValueType?:  | "UNKNOWN_VALUE_TYPE" | "LEGACY_PRE_VALUE" | "ROMAN" | "ASCII" | "ALPHA" | "LEGACY_POST_VALUE" | "UNDEFINED_VALUE_TYPE" | "CHINESE" | "JAPANESE" | "KOREAN" | "ARABIC_ARABIC";
  /**
   * The string page value.
   */
  stringValue?: string;
  /**
   * The numeric page value.
   */
  value?: number;
  /**
   * The delta in which the value increases between pages.
   */
  valueDelta?:  | "DELTA_HALF" | "DELTA_ONE" | "DELTA_TWO";
  /**
   * A value type from the Type enum above.
   */
  valueType?:  | "UNKNOWN_VALUE_TYPE" | "LEGACY_PRE_VALUE" | "ROMAN" | "ASCII" | "ALPHA" | "LEGACY_POST_VALUE" | "UNDEFINED_VALUE_TYPE" | "CHINESE" | "JAPANESE" | "KOREAN" | "ARABIC_ARABIC";
}

/**
 * OrientationLabel groups the details about orientation and reading order.
 */
export interface GoodocOrientationLabel {
  /**
   * After rotating so that the text orientation is upright, how many radians
   * does one have to rotate the block anti-clockwise for it to be level? We
   * guarantee: -Pi/4 <= deskew_angle <= Pi/4
   */
  deskewAngle?: number;
  /**
   * Whether a text line is mirrored (e.g. reflected in a shiny surface or seen
   * through the opposite side of a storefront window). The intent is that this
   * is a quality of the text line image. It needs to be reflected according to
   * a vertical axis along the direction of upright characters to make it
   * readable. This does not affect the shape of the bounding box. A mirrored
   * line with top to bottom writing remains top to bottom. A mirrored
   * horizontal line will flip left to right. However any child entities
   * (symbols) will remain in the same order, and the writing direction imposed
   * by the language (ltr or rtl) will remain the same.
   */
  mirrored?: boolean;
  orientation?:  | "ORIENTATION_PAGE_UP" | "ORIENTATION_PAGE_RIGHT" | "ORIENTATION_PAGE_DOWN" | "ORIENTATION_PAGE_LEFT";
  textlineOrder?:  | "TEXTLINE_ORDER_LEFT_TO_RIGHT" | "TEXTLINE_ORDER_RIGHT_TO_LEFT" | "TEXTLINE_ORDER_TOP_TO_BOTTOM";
  writingDirection?:  | "WRITING_DIRECTION_LEFT_TO_RIGHT" | "WRITING_DIRECTION_RIGHT_TO_LEFT" | "WRITING_DIRECTION_TOP_TO_BOTTOM";
}

/**
 * This message specifies structure "overrides" to apply: it can be used to
 * force certain kinds of GoodocToHTML renderings of elements.
 */
export interface GoodocOverrides {
  /**
   * For text blocks only: do not allow this block to be turned into an image
   * when rendering, even if your algorithms want to do so:
   */
  blockImagination?:  | "LEAVE_ALONE" | "FORCE_TRUE" | "FORCE_FALSE";
  /**
   * For graphic blocks, we often expand the block a bit for rendering, to
   * compensate for bad image segmentation. do_not_expand_graphic_box forces
   * this behavior to be turned off.
   */
  doNotExpandGraphicBox?: boolean;
  /**
   * For Pages only: explicitly specify whether or not this page should be
   * rendered fully as an image
   */
  fullPageAsImage?:  | "LEAVE_ALONE" | "FORCE_TRUE" | "FORCE_FALSE";
  /**
   * For Pages only: explicitly specify whether or not all text on this page
   * should be treated as "LINEATED"
   */
  fullPageLineated?:  | "LEAVE_ALONE" | "FORCE_TRUE" | "FORCE_FALSE";
  /**
   * For Pages only: explicitly specify whether or not this page should be
   * skipped.
   */
  fullPageSkipped?:  | "LEAVE_ALONE" | "FORCE_TRUE" | "FORCE_FALSE";
  /**
   * This GRAPHIC block's image can be shown even when
   * GoodocToHTMLOptions.suppress_photos_with_this is specified.
   */
  needNotSuppressPhoto?: boolean;
  /**
   * For blocks: explicitly specify whether or not this block should get a
   * page-break before it.
   */
  pageBreakBefore?:  | "LEAVE_ALONE" | "FORCE_TRUE" | "FORCE_FALSE";
  style?: GoodocOverridesStyle[];
  /**
   * For Words only: replace the rendered HTML by this:
   */
  wordHtml?: string;
}

/**
 * Extra css styles to apply
 */
export interface GoodocOverridesStyle {
  /**
   * css attribute name: "margin-left", for eg.
   */
  name?: string;
  /**
   * css attribute vale: "1em", for eg.
   */
  value?: string;
}

/**
 * Represents a paragraph of text in OCRed content.
 */
export interface GoodocParagraph {
  alignment?: number;
  Box?: GoodocBoundingBox;
  droppedcap?: GoodocParagraphDroppedCap;
  FirstLineIndent?: number;
  Label?: GoodocLabel;
  LeftIndent?: number;
  LineSpacing?: number;
  /**
   * Which way is upright for this paragraph and what is the dominant reading
   * order?
   */
  OrientationLabel?: GoodocOrientationLabel;
  RightIndent?: number;
  /**
   * If RotatedBox is set, Box must be set as well. See RotatedBoundingBox.
   */
  RotatedBox?: GoodocRotatedBoundingBox;
  route?: GoodocParagraphRoute[];
  SpaceAfter?: number;
  SpaceBefore?: number;
  /**
   * If we merge any paragraphs into this one (through the
   * MergeParagraphWithNext() interface in goodoc-editing.h), then we append the
   * properties of the merged paragraph here, for debugging and to avoid losing
   * any info. Note that the SubsumedParagraphProperties Paragraphs do not
   * contain Routes.
   */
  SubsumedParagraphProperties?: GoodocParagraph[];
  /**
   * Paragraph text recognition confidence. Range depends on the algorithm but
   * should be consistent in a given volume. 0 is bad, 100 is good.
   */
  TextConfidence?: number;
  Width?: number;
}

/**
 * Information about the paragraph's dropped capital letter
 */
export interface GoodocParagraphDroppedCap {
  Box?: GoodocBoundingBox;
  LettersCount?: number;
}

export interface GoodocParagraphRoute {
  /**
   * Route end point
   */
  EndPoint?: GoodocRoutePoint;
  /**
   * Route start point
   */
  StartPoint?: GoodocRoutePoint;
  /**
   * Route weight, i.e. route
   */
  Weight?: number;
  /**
   * The array of words on this route
   */
  Word?: GoodocWord[];
}

/**
 * Similar to goodoc.BoundingBox, but containing an angle of rotation, thus
 * able to represent non-axis-aligned boxes. RotatedBoundingBox can be used in
 * combination with BoundingBox to better represent non-axis-aligned page
 * structural elements. In such case, two bounding boxes can be used per
 * element. A RotatedBoundingBox that is rotated to tightly encompass the
 * element; embedded (as tightly as possible) inside an axis-aligned
 * BoundingBox. Note that there is some amount of ambiguity regarding what angle
 * and vertex to use. Consider a square with axis-aligned diagonals: B / \ A C \
 * / D This can either be represented as a -45 degree rotation around A, a 45
 * degree rotation around B, a 135 degree rotation around C, or a -135 degree
 * rotation around D. Which one you use depends on your use case, but one
 * recommendation is to use the vertex that would be top left if the reader was
 * reading it in the 'natural' orientation.
 */
export interface GoodocRotatedBoundingBox {
  /**
   * Angle of rotation of the original non-rotated box around the top left
   * corner of the original non-rotated box, in clockwise degrees from the
   * horizontal.
   */
  Angle?: number;
  Height?: number;
  /**
   * Coordinates and sizes are expressed in pixels, where the top-left pixel is
   * (0, 0). The coordinates refer to the corner of the top-left vertex of the
   * unrotated version of the box.
   */
  Left?: number;
  Top?: number;
  Width?: number;
}

export interface GoodocRoutePoint {
  /**
   * The sequential route number, starts at 0
   */
  RouteIndex?: number;
  /**
   * The sequential word number, starts at 0
   */
  WordIndex?: number;
}

/**
 * Label identifying a logical part of the page content. This applies mostly at
 * Block level or Paragraph level (but can apply to Words or to arbitrary spans
 * if needed).
 */
export interface GoodocSemanticLabel {
  /**
   * Alternate text for a sequence of the Goodoc, just for the element
   * containing this label, or for a sequence starting from this element to the
   * EndOfSpanningLabel. Typically this is inserted by automatic or manual OCR
   * correction. We use text instead of editing the Goodoc directly since we
   * dont usually have accurate symbol level bboxes for the alternate text. Also
   * the original values from OCR are preserved. It is upto the application to
   * do anything more intelligent like mapping words and finding potential
   * symbol/word bboxes.
   */
  AlternateText?: string;
  appearance?: number;
  /**
   * Page elements can be given Attributes refining meaning/role. We keep this
   * flexible by using strings instead of pre-determined enum values. But it is
   * useful to list all such Attributes in use in
   * ocr/goodoc/goodoc-semantics-attributes.h
   */
  Attribute?: string[];
  /**
   * Blocks that are at the beginning of chapters have this set:
   */
  ChapterStart?: boolean;
  CleanupAnnotation?: number[];
  columndetails?: GoodocSemanticLabelColumnDetails;
  contentlink?: GoodocSemanticLabelContentLink;
  ContinuesFromPreviousPage?: boolean;
  /**
   * When ContinuesFromPreviousPage=true, this bit can be set to note that the
   * word fragment on the previous page ends in a hyphen.
   */
  ContinuesFromPreviousPageHyphenated?: boolean;
  /**
   * Paragraphs that span across pages can be identified with the following
   * flags. Note that flows just connect Blocks across pages. These continuation
   * flags imply something more specific -- the case of a single logical
   * paragraph split over pages. Only the last Paragraph in the last Block
   * within a given FlowThread() on a page can have ContinuesOnNextPage set.
   * Similarly, only the first Paragraph in the first Block with a given
   * FlowThread() on a page may have ContinuesFromPreviousPage set.
   */
  ContinuesOnNextPage?: boolean;
  editcorrectioncandidate?: GoodocSemanticLabelEditCorrectionCandidate[];
  /**
   * Normally, a SemanticLabel applies exactly to the goodoc element that it is
   * contained in (usually Block or Paragraph, sometimes Word). Occasionally, we
   * need a SemanticLabel to span across the boundary or end before the
   * boundary. For example, a URL may just be a few words within a Paragraph. In
   * such cases, the SemanticLabel is added to the first element of the span and
   * contains this LogicalEntity pointing to the last element of the span:
   */
  EndOfSpanningLabel?: GoodocLogicalEntity;
  /**
   * Message set for experimental algorithm data. Use case: We keep a set of
   * features that was computed for the unsupervised caption extraction and
   * store it here. Agora question producer will consume this message set to be
   * embedded in a question. The experimental feature set can then be used later
   * to pair up with ground truth labels for designing a supervised algorithm.
   * Currently holding: o ocean/analysis/content/caption_data.proto's
   * TextualElement
   */
  ExperimentalData?: Proto2BridgeMessageSet;
  /**
   * Flow identifies a single sequential unit of text (or other content). It is
   * only set on Blocks -- a flow identifies a sequence of Blocks. The default,
   * main flow is just the empty string. The "FlowThread" of a block is the flow
   * (if non-empty), suffixed with the block appearance. This is computed by
   * GoodocUtils::FlowThread(). Paragraphs may be split over blocks in the same
   * FlowThread, across pages. The following table shows how FlowThread gets
   * computed: ## Flow Appearance FlowThread (empty) UNSPECIFIED "UNSPECIFIED"
   * foo BODY "foo:BODY" Please use lower-case strings for flows (such as
   * article-33-box). One useful way to think of flows is this: A logical unit
   * of interest in a a Document (for example, an article) would be identified
   * by a starting block, an ending block, and a list of flows of interest
   * within the [start, end) span. message Article { (page#, block#):
   * article_start; (page#, block#): article_end; repeated string flows; } The
   * reading order of blocks, paragraphs/etc within this article would be the
   * same order as present in the goodoc itself. Some applications (such as
   * rendering) may want to process the article by running over all the flows
   * together, others (such as indexing) may want to deal with the FlowThreads
   * one after the other.
   */
  Flow?: string;
  /**
   * This field can be used to record the steps by which AlternateText for a
   * sequence of the Goodoc is generated.
   */
  ModificationRecord?: string;
  /**
   * Structure overrides: typically manual corrections to goodoc renderings.
   */
  overrides?: GoodocOverrides;
  /**
   * If Appearence is PAGE_NUMBER:
   */
  PageNumberOrdinal?: GoodocOrdinal;
  snippetfilter?: GoodocSemanticLabelSnippetFilter[];
  tablecelldetails?: GoodocSemanticLabelTableCellDetails;
  tabledetails?: GoodocSemanticLabelTableDetails;
}

/**
 * If Appearance is COLUMN:
 */
export interface GoodocSemanticLabelColumnDetails {
  Column?: number;
  Columns?: number;
}

/**
 * If the label is for something that links to another piece of content (in
 * this volume, outside, a url, a citation, etc.).
 */
export interface GoodocSemanticLabelContentLink {
  citationtarget?: GoodocSemanticLabelContentLinkCitationTarget;
  involumetarget?: GoodocSemanticLabelContentLinkInVolumeTarget;
  /**
   * For URL labels, we note the url here directly (it's also available by
   * grabbing all text symbols within the labeled span). SCHOLARLY_CITATION
   * labels or even CAPTION labels may occasionally contain URLs.
   */
  UrlTarget?: string;
}

/**
 * For SCHOLARLY_CITATION labels:
 */
export interface GoodocSemanticLabelContentLinkCitationTarget {
  /**
   * separated by semicolons
   */
  Authors?: string;
  BibKey?: string;
  Confidence?: number;
  Title?: string;
  Year?: number;
}

/**
 * For CAPTION or FOOTNOTE_POINTER or TOC_ENTRY or INDEX_ENTRY or CONTINUATION
 * labels:
 */
export interface GoodocSemanticLabelContentLinkInVolumeTarget {
  Confidence?: number;
  /**
   * The CAPTION label typically targets the previous or the next Block. The
   * FOOTNOTE_POINTER label typically targets a paragraph in a FOOTNOTE Block.
   * TOC_ENTRY and INDEX_ENTRY labels are links that point to a different page
   * within the volume. CONTINUATION labels also are links that point to a
   * different page within the volume, or maybe even a particular block or
   * paragraph.
   */
  LogicalEntity?: GoodocLogicalEntity;
}

/**
 * If there is more than one edit correction candidate, store all the
 * candidates here. This helps a manual correction utility fire the right kind
 * of question with the relevant options.
 */
export interface GoodocSemanticLabelEditCorrectionCandidate {
  EditedWord?: string;
  Probability?: number;
}

/**
 * Recording the output of the snippet filter. We run through a series of
 * snippet filters and store all the conditions that this article passed. A
 * condition is denoted by the "badword_fraction_allowed" in a running window of
 * size - "window_size". If ARTICLE_SNIPPET_NOT_CLEAN annotation is set, this
 * group has 0 items. It can be a part of article logicalentity, but keeping it
 * here for consistency and coherence as SemanticLabel holds all other article
 * metadata.
 */
export interface GoodocSemanticLabelSnippetFilter {
  badwordFraction?: number;
  windowSize?: number;
}

/**
 * If Appearance is TABLE_CELL:
 */
export interface GoodocSemanticLabelTableCellDetails {
  Column?: number;
  ColumnSpan?: number;
  /**
   * Row and Column are 0-based
   */
  Row?: number;
  RowSpan?: number;
}

/**
 * If Appearance is TABLE:
 */
export interface GoodocSemanticLabelTableDetails {
  Columns?: number;
  Rows?: number;
}

/**
 * Goodoc stats for a range of elements, such as one page or a whole book.
 * These stats can be computed using the SummaryStatsCollector class. Some range
 * stats are pre-computed and stored in goodocs/volumes (eg., Page.stats below,
 * and Ocean's CA_VolumeResult.goodoc_stats).
 */
export interface GoodocSummaryStats {
  /**
   * This flag is set if the histogram above has been derived by estimating
   * font sizes from CharLabel.CharacterHeight; that happens if the FontSize
   * field is constant, as has happened with Abbyy 9.
   */
  estimatedFontSizes?: boolean;
  /**
   * Symbol counts (and other attributes) for each distinct CharLabel.FontId
   * and FontSize; histogram is in decreasing order of symbol count
   */
  fontSizeHistogram?: GoodocFontSizeStats[];
  meanSymbolsPerBlock?: number;
  meanSymbolsPerLine?: number;
  meanSymbolsPerParagraph?: number;
  meanSymbolsPerWord?: number;
  meanWordsPerBlock?: number;
  meanWordsPerLine?: number;
  meanWordsPerParagraph?: number;
  /**
   * bottom to next top in flow on page
   */
  medianBlockSpace?: number;
  /**
   * 0,2,4..
   */
  medianEvenPrintedBox?: GoodocBoundingBox;
  medianFullEvenPrintedBox?: GoodocBoundingBox;
  medianFullOddPrintedBox?: GoodocBoundingBox;
  /**
   * Each median_full*_printed_box includes page header/footer but still
   * excludes all graphic blocks
   */
  medianFullPrintedBox?: GoodocBoundingBox;
  medianHeight?: number;
  medianHorizontalDpi?: number;
  /**
   * top to bottom
   */
  medianLineHeight?: number;
  /**
   * bottom to next top in para
   */
  medianLineSpace?: number;
  /**
   * top to next top in para
   */
  medianLineSpan?: number;
  /**
   * 1,3,5..
   */
  medianOddPrintedBox?: GoodocBoundingBox;
  /**
   * leading space on first line
   */
  medianParagraphIndent?: number;
  /**
   * bottom to next top in block
   */
  medianParagraphSpace?: number;
  /**
   * Each median*_printed_box excludes page header/footer and all graphic
   * blocks
   */
  medianPrintedBox?: GoodocBoundingBox;
  medianSymbolsPerBlock?: number;
  medianSymbolsPerLine?: number;
  medianSymbolsPerParagraph?: number;
  medianSymbolsPerWord?: number;
  medianVerticalDpi?: number;
  medianWidth?: number;
  medianWordsPerBlock?: number;
  medianWordsPerLine?: number;
  medianWordsPerParagraph?: number;
  /**
   * ------ Block stats Median symbols and words omit junk, header and footer
   * blocks; they are intended to be a measure of the typical "content" block.
   * There can still be substantial differences between means and medians;
   * however, block values will generally exceed paragraph values (not the case
   * when headers and footers are included).
   */
  numBlocks?: number;
  /**
   * blocks that have a successor block within their flow on their page
   */
  numBlockSpaces?: number;
  /**
   * ------ Line stats "top" corresponds to the highest ascender and "bottom"
   * to the lowest descender.
   */
  numLines?: number;
  /**
   * Lines (out of num_lines) that have a successor line within their para
   */
  numLineSpaces?: number;
  numNonGraphicBlocks?: number;
  /**
   * ------ Page stats.
   */
  numPages?: number;
  /**
   * ------ Paragraph stats Median symbols and words omit junk, header and
   * footer blocks; they are intended to be a measure of the typical "content"
   * paragraph. There can still be substantial differences between means and
   * medians, particularly if a table is present (every cell is a paragraph).
   */
  numParagraphs?: number;
  /**
   * paras that have a successor para within their block
   */
  numParagraphSpaces?: number;
  /**
   * ------ Symbol stats
   */
  numSymbols?: number;
  /**
   * ------ Word stats
   */
  numWords?: number;
}

/**
 * A single symbol representation
 */
export interface GoodocSymbol {
  Box?: GoodocBoundingBox;
  /**
   * The unicode character code in UTF-32
   */
  Code?: number;
  Label?: GoodocLabel;
  /**
   * If RotatedBox is set, Box must be set as well. See RotatedBoundingBox.
   */
  RotatedBox?: GoodocRotatedBoundingBox;
  symbolvariant?: GoodocSymbolSymbolVariant[];
}

export interface GoodocSymbolSymbolVariant {
  Code?: number;
  Confidence?: number;
}

/**
 * A word representation
 */
export interface GoodocWord {
  alternates?: GoodocWordAlternates;
  /**
   * The baseline's y-axis offset from the bottom of the word's bounding box,
   * given in pixels. (A value of 2, for instance, indicates the baseline is 2px
   * above the bottom of the box.)
   */
  Baseline?: number;
  Box?: GoodocBoundingBox;
  /**
   * The capline is the y-axis offset from the top of the word bounding box. A
   * positive value n indicates that capline is n-pixels above the top of this
   * word.
   */
  Capline?: number;
  /**
   * For space efficiency, we sometimes skip the detailed per-symbol bounding
   * boxes in Symbol.Box, and use this coarser representation instead, where we
   * just store Symbol boundaries within the Word box. Most client code should
   * not have to worry directly about this, it should be handled in the deepest
   * layers of writing/reading goodocs (for example, see Compress() and
   * Uncompress() in ocean/goodoc/goovols-bigtable-volume.h). Note(viresh): I
   * experimented with this compression, and here are some numbers for
   * reference. If the zlib-compressed page goodoc string size was 100 to start
   * with, then this compaction makes it 65. As a possible future relaxation to
   * consider: if we add in, for each symbol, a "top" and "bottom" box offset
   * then the size would be 75 (that's with "repeated int32 top/bottom_offset"
   * fields inside BoxPartitions, instead of inside each symbol).
   */
  CompactSymbolBoxes?: GoodocBoxPartitions;
  /**
   * Word recognition confidence. Range depends upon OCR Engine.
   */
  Confidence?: number;
  /**
   * word. The meaning and range depends on the OCR engine or subsequent
   * processing. Specifies whether the word was found
   */
  IsFromDictionary?: boolean;
  /**
   * a number True if word represents
   */
  IsIdentifier?: boolean;
  /**
   * True if the word is the last word in any sub-paragraph unit that functions
   * at the same level of granularity as a sentence. Examples: "She hit the
   * ball." (regular sentence) "Dewey defeats Truman" (heading) "The more, the
   * merrier." (no verb) Note: not currently used. Code to set this was
   * introduced in CL 7038338 and removed in OCL=10678722.
   */
  IsLastInSentence?: boolean;
  /**
   * in the dictionary True if the word represents
   */
  IsNumeric?: boolean;
  Label?: GoodocLabel;
  /**
   * Penalty for discordance of characters in a
   */
  Penalty?: number;
  /**
   * If RotatedBox is set, Box must be set as well. See RotatedBoundingBox.
   */
  RotatedBox?: GoodocRotatedBoundingBox;
  /**
   * Word characters, the text may
   */
  Symbol?: GoodocSymbol[];
  /**
   * As a shortcut, the content API provides the text of words instead of
   * individual symbols (NOTE: this is experimental). This is UTF8. And the main
   * font for the word is stored in Label.CharLabel.
   */
  text?: string;
  /**
   * Writing direction for this word.
   */
  writingDirection?:  | "WRITING_DIRECTION_LEFT_TO_RIGHT" | "WRITING_DIRECTION_RIGHT_TO_LEFT" | "WRITING_DIRECTION_TOP_TO_BOTTOM";
}

/**
 * Alternate OCR words for Ptolemy OCR Correction. This is the output of the
 * Ptolemy error estimator. See http://go/Ptolemy.
 */
export interface GoodocWordAlternates {
  alternate?: GoodocWordAlternatesAlternate[];
  /**
   * The probability that the main OCR engine (Abbyy) string is incorrect;
   * range is 0 (definitely correct) to 100 (definitely incorrect).
   */
  ErrorProbability?: number;
}

/**
 * An alternate word provided by another OCR engine, used for OCR Correction.
 * This iteration only supports simple substitution errors (exhanging one word
 * for another), but with minor modifications (e.g. adding a word count for each
 * alternate), it could support repairing word segmentation and text detection
 * errors.
 */
export interface GoodocWordAlternatesAlternate {
  /**
   * See Document.Header
   */
  OcrEngineId?: string;
  /**
   * See Document.Header
   */
  OcrEngineVersion?: string;
  /**
   * In order to compile, this recursive message needs to be optional, even
   * though it's within an optional group.
   */
  Word?: GoodocWord;
}

/**
 * Specifies the desired format for the server to use when it returns
 * `audio_out` messages.
 */
export interface GoogleAssistantAccessoryV1AudioOutConfig {
  /**
   * Current audio mode on the device while issuing the query.
   */
  audioMode?:  | "AUDIO_MODE_UNSPECIFIED" | "MUTED" | "SILENT" | "PLAYING";
  /**
   * Current audio routing on the device while issuing the query.
   */
  audioRoutingMode?:  | "AUDIO_ROUTING_MODE_UNSPECIFIED" | "BLUETOOTH_HEADPHONES";
  /**
   * *Required* The encoding of audio data to be returned in all `audio_out`
   * messages.
   */
  encoding?:  | "ENCODING_UNSPECIFIED" | "LINEAR16" | "MP3" | "OGG_OPUS" | "MULAW" | "OPUS_CONTAINERLESS";
  /**
   * *Optional* Specifies preferred encoding bitrate (bits-per-second).
   * Currently this is only implemented for OGG_OPUS for bitrates of 12000,
   * 16000, 24000, 32000. If not specified, OGG_OPUS defaults to 32000.
   */
  preferredBitrateBps?: number;
}

/**
 * *Required* Fields that identify the device to the Assistant. See also: *
 * [Register a Device - REST API](https:
 * //developers.google.com/assistant/sdk/re //
 * ference/device-registration/register-device-manual) * [Device Model and
 * Instance Schemas](https: //developers.google.com/assistant/sdk/re //
 * ference/device-registration/model-and-instance-schemas) * [Device
 * Proto](https: //developers.google.com/assistant/sdk/re //
 * ference/rpc/google.assistant.devices.v1#device)
 */
export interface GoogleAssistantAccessoryV1DeviceConfig {
  /**
   * *Required* Identifier for the device which sent the request.
   */
  deviceBuild?: GoogleAssistantEmbeddedV1DeviceBuild;
  /**
   * Device model capabilities from client to override capabilities in the
   * primary device model.
   */
  deviceModelCapabilitiesOverride?: GoogleAssistantEmbeddedV1DeviceModelCapabilitiesOverride;
  /**
   * *Optional* An encrypted heterodyne_experiment_token containing the list of
   * experiment_ids (go/ph-server-tokens).
   */
  heterodyneToken?: string;
}

function serializeGoogleAssistantAccessoryV1DeviceConfig(data: any): GoogleAssistantAccessoryV1DeviceConfig {
  return {
    ...data,
    deviceModelCapabilitiesOverride: data["deviceModelCapabilitiesOverride"] !== undefined ? serializeGoogleAssistantEmbeddedV1DeviceModelCapabilitiesOverride(data["deviceModelCapabilitiesOverride"]) : undefined,
  };
}

function deserializeGoogleAssistantAccessoryV1DeviceConfig(data: any): GoogleAssistantAccessoryV1DeviceConfig {
  return {
    ...data,
    deviceModelCapabilitiesOverride: data["deviceModelCapabilitiesOverride"] !== undefined ? deserializeGoogleAssistantEmbeddedV1DeviceModelCapabilitiesOverride(data["deviceModelCapabilitiesOverride"]) : undefined,
  };
}

/**
 * Information about the state of the device. This contains any state that
 * Assistant may need to know about in order to fulfill requests, for example
 * which timers and alarms are set. Next ID: 9
 */
export interface GoogleAssistantAccessoryV1DeviceState {
  /**
   * *Optional* Information about on-device alarms. For devices that support
   * alarms, all on-device alarms must be sent up with the DeviceState in order
   * for Assistant Server to be able to perform operations on them.
   */
  alarmState?: GoogleAssistantEmbeddedV1Alarms;
  /**
   * Other context params to be sent to Assistant. This is a
   * assistant.embedded.v1.ContextParams message in serialized binary proto
   * format.
   */
  contextParams?: Uint8Array;
  /**
   * A timestamp of the current device time when the request was made. This
   * field is required if your device supports alarms or timers. This ensures
   * that requests are fulfilled relative to the current device time and
   * regardless of any clock skew between the client and the server.
   */
  deviceTime?: Date;
  /**
   * The time zone where the device is currently located. This helps the
   * Assistant answer time-related queries relative to the device's time zone.
   * Generally speaking, mobile devices that support alarms or timers should
   * supply device_time_zone. This field is required if your device supports
   * alarms or timers and the device's location cannot reliably be determined.
   * (See the comment above google.assistant.embedded.v1.DeviceLocation for a
   * description of how the device's location is determined.) If the time zone
   * cannot be determined, some queries for creating or modifying timers or
   * alarms may fail with a generic error such as, "Sorry, I don't know how to
   * help with that."
   */
  deviceTimeZone?: GoogleTypeTimeZone;
  /**
   * Indicate whether do not disturb mode is turned on.
   */
  doNotDisturb?: boolean;
  /**
   * Information about on-device fitness activities. For devices that support
   * fitness activities, all on-device fitness activities must be sent up with
   * the DeviceState in order for Assistant Server to be able to perform
   * operations on them.
   */
  fitnessActivitiesState?: GoogleAssistantEmbeddedV1FitnessActivities;
  /**
   * *Optional* Information about on-device timers. For devices that support
   * timers, all on-device timers must be sent up with the DeviceState in order
   * for Assistant Server to be able to perform operations on them.
   */
  timerState?: GoogleAssistantEmbeddedV1Timers;
}

function serializeGoogleAssistantAccessoryV1DeviceState(data: any): GoogleAssistantAccessoryV1DeviceState {
  return {
    ...data,
    alarmState: data["alarmState"] !== undefined ? serializeGoogleAssistantEmbeddedV1Alarms(data["alarmState"]) : undefined,
    contextParams: data["contextParams"] !== undefined ? encodeBase64(data["contextParams"]) : undefined,
    deviceTime: data["deviceTime"] !== undefined ? data["deviceTime"].toISOString() : undefined,
    fitnessActivitiesState: data["fitnessActivitiesState"] !== undefined ? serializeGoogleAssistantEmbeddedV1FitnessActivities(data["fitnessActivitiesState"]) : undefined,
    timerState: data["timerState"] !== undefined ? serializeGoogleAssistantEmbeddedV1Timers(data["timerState"]) : undefined,
  };
}

function deserializeGoogleAssistantAccessoryV1DeviceState(data: any): GoogleAssistantAccessoryV1DeviceState {
  return {
    ...data,
    alarmState: data["alarmState"] !== undefined ? deserializeGoogleAssistantEmbeddedV1Alarms(data["alarmState"]) : undefined,
    contextParams: data["contextParams"] !== undefined ? decodeBase64(data["contextParams"] as string) : undefined,
    deviceTime: data["deviceTime"] !== undefined ? new Date(data["deviceTime"]) : undefined,
    fitnessActivitiesState: data["fitnessActivitiesState"] !== undefined ? deserializeGoogleAssistantEmbeddedV1FitnessActivities(data["fitnessActivitiesState"]) : undefined,
    timerState: data["timerState"] !== undefined ? deserializeGoogleAssistantEmbeddedV1Timers(data["timerState"]) : undefined,
  };
}

/**
 * Configuration for the response. Next Id: 11
 */
export interface GoogleAssistantAccessoryV1ResponseConfig {
  /**
   * Specifies the current audio mode on the device.
   */
  audioOutConfig?: GoogleAssistantAccessoryV1AudioOutConfig;
  /**
   * Configuration related to a specific device.
   */
  deviceConfig?: GoogleAssistantAccessoryV1DeviceConfig;
  /**
   * The client interaction to be sent to Assistant. This is a
   * assistant.embedded.v1.DeviceInteraction message in serialized binary proto
   * format.
   */
  deviceInteraction?: Uint8Array;
  /**
   * Device state to pass to the Assistant server to use in calculating the
   * response.
   */
  deviceState?: GoogleAssistantAccessoryV1DeviceState;
  /**
   * Specifies the initial bytes of TTS audio to send.
   */
  initialAudioBytes?: number;
  /**
   * If true, the server will treat the request as a new conversation and not
   * use state from the prior request. Set this field to true when the
   * conversation should be restarted, such as after a device reboot, or after a
   * significant lapse of time since the prior query.
   */
  isNewConversation?: boolean;
  /**
   * Specifies the desired audio sample rate of the output TTS stream in Hz.
   */
  outputSampleRateHz?: number;
  /**
   * Specifies the requested response type.
   */
  responseType?:  | "RESPONSE_TYPE_UNSPECIFIED" | "TEXT" | "TRANSCRIPTION";
  /**
   * Specifies the desired format to use when server returns a visual screen
   * response.
   */
  screenOutConfig?: GoogleAssistantAccessoryV1ScreenOutConfig;
}

function serializeGoogleAssistantAccessoryV1ResponseConfig(data: any): GoogleAssistantAccessoryV1ResponseConfig {
  return {
    ...data,
    deviceConfig: data["deviceConfig"] !== undefined ? serializeGoogleAssistantAccessoryV1DeviceConfig(data["deviceConfig"]) : undefined,
    deviceInteraction: data["deviceInteraction"] !== undefined ? encodeBase64(data["deviceInteraction"]) : undefined,
    deviceState: data["deviceState"] !== undefined ? serializeGoogleAssistantAccessoryV1DeviceState(data["deviceState"]) : undefined,
  };
}

function deserializeGoogleAssistantAccessoryV1ResponseConfig(data: any): GoogleAssistantAccessoryV1ResponseConfig {
  return {
    ...data,
    deviceConfig: data["deviceConfig"] !== undefined ? deserializeGoogleAssistantAccessoryV1DeviceConfig(data["deviceConfig"]) : undefined,
    deviceInteraction: data["deviceInteraction"] !== undefined ? decodeBase64(data["deviceInteraction"] as string) : undefined,
    deviceState: data["deviceState"] !== undefined ? deserializeGoogleAssistantAccessoryV1DeviceState(data["deviceState"]) : undefined,
  };
}

/**
 * Specifies the desired format for the server to use when it returns
 * `screen_out` response.
 */
export interface GoogleAssistantAccessoryV1ScreenOutConfig {
  /**
   * Device dimensions.
   */
  dimensions?: GoogleAssistantAccessoryV1ScreenOutConfigDimensions;
  /**
   * The scale factor used to convert Scalable Pixel (SP) units to
   * Density-independent Pixel (DP) units (DP = SP * scale factor). Fonts are
   * measured in units of SP, and on some platforms such as Android the SP to DP
   * scale factor can be affected by the font size a user selects in
   * accessibility settings.
   */
  fontScaleFactor?: number;
}

/**
 * This contains physical and logical characteristics about the device (e.g.
 * screen size and DPI, etc).
 */
export interface GoogleAssistantAccessoryV1ScreenOutConfigDimensions {
  /**
   * Dots (pixels) per inch of the screen.
   */
  screenDpi?: number;
  /**
   * Height of the device's screen in pixels. If 0 or not specified, it's
   * assumed to be the same as screen_width_px. For a square or round screen,
   * it's recommended to leave this field empty as a bandwidth optimization.
   */
  screenHeightPx?: number;
  /**
   * The shape of the device's screen
   */
  screenShape?:  | "SCREEN_SHAPE_UNSPECIFIED" | "SCREEN_SHAPE_OVAL" | "SCREEN_SHAPE_RECT";
  /**
   * Width of the device's screen in pixels.
   */
  screenWidthPx?: number;
}

/**
 * Alarms are clocks that ring at a specified time on one or more days. The
 * client schedules a time to ring based on the date/time pattern. When it
 * rings, it may be rescheduled off the original time by snoozing or it may be
 * replaced by the next occurrence.
 */
export interface GoogleAssistantEmbeddedV1Alarm {
  /**
   * A string key used as an identifier to this alarm. This key needs to be
   * unique amongst all alarms on the device. The client can choose a mechanism
   * of its choice to ensure this. If the server suggests an alarm_id, the
   * client can either use the suggestion or create a new unique alarm_id of its
   * choosing.
   */
  alarmId?: string;
  /**
   * For single alarms: the one date the alarm should next be scheduled for.
   */
  datePattern?: GoogleTypeDate;
  /**
   * A user-provided name for this alarm.
   */
  label?: string;
  /**
   * For recurring alarms: a description of the dates when the alarm should
   * recur.
   */
  recurrencePattern?: GoogleAssistantEmbeddedV1AlarmRecurrence;
  /**
   * When SCHEDULED or SNOOZED, the absolute time the alarm will fire next.
   * When SNOOZED, this time includes the additional time added by snoozing the
   * alarm. When FIRING, the absolute time the alarm had been scheduled to fire.
   * When DISABLED, this field is undefined and should be ignored.
   */
  scheduledTime?: Date;
  /**
   * Describes the part of the lifecycle that an alarm is in.
   */
  status?:  | "ALARM_STATUS_UNSPECIFIED" | "SCHEDULED" | "FIRING" | "SNOOZED" | "DISABLED";
  /**
   * The time of day the alarm should be scheduled for. This value does not
   * change when an alarm enters the SNOOZED state; instead the scheduled_time
   * field should be adjusted to the new alarm time.
   */
  timePattern?: GoogleTypeTimeOfDay;
}

function serializeGoogleAssistantEmbeddedV1Alarm(data: any): GoogleAssistantEmbeddedV1Alarm {
  return {
    ...data,
    scheduledTime: data["scheduledTime"] !== undefined ? data["scheduledTime"].toISOString() : undefined,
  };
}

function deserializeGoogleAssistantEmbeddedV1Alarm(data: any): GoogleAssistantEmbeddedV1Alarm {
  return {
    ...data,
    scheduledTime: data["scheduledTime"] !== undefined ? new Date(data["scheduledTime"]) : undefined,
  };
}

/**
 * A description of the dates when an alarm should recur.
 */
export interface GoogleAssistantEmbeddedV1AlarmRecurrence {
  /**
   * Specifies a weekly or daily recurrence. Constraint: The date falls on one
   * of these days of the week, in 0...6 (Sunday...Saturday). Should not be
   * empty.
   */
  dayOfWeek?:  | "DAY_OF_WEEK_UNSPECIFIED" | "MONDAY" | "TUESDAY" | "WEDNESDAY" | "THURSDAY" | "FRIDAY" | "SATURDAY" | "SUNDAY"[];
}

/**
 * Contains information about on-device alarms for devices that support alarms.
 */
export interface GoogleAssistantEmbeddedV1Alarms {
  /**
   * Information about all on-device alarms.
   */
  alarms?: GoogleAssistantEmbeddedV1Alarm[];
  /**
   * The amount of time for which alarms should be snoozed. If not specified,
   * the productivity vertical applies a default snooze duration, which may be
   * seen here:
   * http://google3/assistant/verticals/productivity/utils/alarm_utils.cc;l=2734;rcl=415933085
   */
  snoozeDuration?: number /* Duration */;
  /**
   * Indicates if an error occurred while fetching alarm state. If this value
   * is missing, it can be assumed that the state fetch was successful.
   */
  stateFetchError?:  | "STATE_FETCH_ERROR_UNSPECIFIED" | "STATE_FETCH_ERROR_TIMEOUT";
}

function serializeGoogleAssistantEmbeddedV1Alarms(data: any): GoogleAssistantEmbeddedV1Alarms {
  return {
    ...data,
    alarms: data["alarms"] !== undefined ? data["alarms"].map((item: any) => (serializeGoogleAssistantEmbeddedV1Alarm(item))) : undefined,
    snoozeDuration: data["snoozeDuration"] !== undefined ? data["snoozeDuration"] : undefined,
  };
}

function deserializeGoogleAssistantEmbeddedV1Alarms(data: any): GoogleAssistantEmbeddedV1Alarms {
  return {
    ...data,
    alarms: data["alarms"] !== undefined ? data["alarms"].map((item: any) => (deserializeGoogleAssistantEmbeddedV1Alarm(item))) : undefined,
    snoozeDuration: data["snoozeDuration"] !== undefined ? data["snoozeDuration"] : undefined,
  };
}

/**
 * Contains fields to identify the device which sent the request.
 */
export interface GoogleAssistantEmbeddedV1DeviceBuild {
  /**
   * * Fully formed user agent suffix string.
   */
  userAgentSuffix?: string;
}

/**
 * Device model capabilities override from client.
 */
export interface GoogleAssistantEmbeddedV1DeviceModelCapabilitiesOverride {
  /**
   * Device model capabilities from client.
   */
  deviceModelCapabilities?: Uint8Array;
  /**
   * If present, overrides only fields specified in the mask. When doing so,
   * selected message and repeated fields will be replaced rather than merged.
   * Performs a regular proto MergeFrom if no mask is specified.
   */
  updateMask?: string /* FieldMask */;
}

function serializeGoogleAssistantEmbeddedV1DeviceModelCapabilitiesOverride(data: any): GoogleAssistantEmbeddedV1DeviceModelCapabilitiesOverride {
  return {
    ...data,
    deviceModelCapabilities: data["deviceModelCapabilities"] !== undefined ? encodeBase64(data["deviceModelCapabilities"]) : undefined,
    updateMask: data["updateMask"] !== undefined ? data["updateMask"] : undefined,
  };
}

function deserializeGoogleAssistantEmbeddedV1DeviceModelCapabilitiesOverride(data: any): GoogleAssistantEmbeddedV1DeviceModelCapabilitiesOverride {
  return {
    ...data,
    deviceModelCapabilities: data["deviceModelCapabilities"] !== undefined ? decodeBase64(data["deviceModelCapabilities"] as string) : undefined,
    updateMask: data["updateMask"] !== undefined ? data["updateMask"] : undefined,
  };
}

/**
 * Contains information about on-device fitness activities for devices that
 * support fitness.
 */
export interface GoogleAssistantEmbeddedV1FitnessActivities {
  /**
   * Information about all on-device activities.
   */
  fitnessActivities?: GoogleAssistantEmbeddedV1FitnessActivity[];
}

function serializeGoogleAssistantEmbeddedV1FitnessActivities(data: any): GoogleAssistantEmbeddedV1FitnessActivities {
  return {
    ...data,
    fitnessActivities: data["fitnessActivities"] !== undefined ? data["fitnessActivities"].map((item: any) => (serializeGoogleAssistantEmbeddedV1FitnessActivity(item))) : undefined,
  };
}

function deserializeGoogleAssistantEmbeddedV1FitnessActivities(data: any): GoogleAssistantEmbeddedV1FitnessActivities {
  return {
    ...data,
    fitnessActivities: data["fitnessActivities"] !== undefined ? data["fitnessActivities"].map((item: any) => (deserializeGoogleAssistantEmbeddedV1FitnessActivity(item))) : undefined,
  };
}

/**
 * Describes a particular fitness activity, its current state, and other data
 * fields associated with that activity (e.g. elapsed time). LINT.IfChange
 */
export interface GoogleAssistantEmbeddedV1FitnessActivity {
  /**
   * Required A string key used as an identifier for this activity. This key
   * needs to be unique amongst all activities on the device. The client can
   * choose a mechanism of its choice to ensure this. If the server suggests an
   * activity_id, the client can either use the suggestion or create a new
   * unique activity_id of its choosing.
   */
  activityId?: string;
  /**
   * DEPRECATED: The most recent time this activity was switched to the ACTIVE
   * state.
   */
  mostRecentStartTime?: Date;
  /**
   * DEPRECATED: The total amount of time this activity has spent in the ACTIVE
   * state until the most recent start time. The total time spent active may be
   * computed by summing (now - most_recent_start_time) with
   * previously_accumulated_duration.
   */
  previouslyAccumulatedDuration?: number /* Duration */;
  /**
   * The current state of this activity.
   */
  state?:  | "STATE_UNSPECIFIED" | "ACTIVE" | "PAUSED";
  /**
   * The type of activity being done.
   */
  type?:  | "TYPE_UNSPECIFIED" | "WALK" | "RUN" | "ELLIPTICAL" | "SWIM" | "WEIGHTS" | "TREADMILL" | "BIKE" | "YOGA" | "WORKOUT" | "BOOT_CAMP" | "CIRCUIT_TRAINING" | "GOLF" | "HIKING" | "INTERVAL_TRAINING" | "KICKBOXING" | "MARTIAL_ARTS" | "PILATES" | "SPINNING" | "STAIR_CLIMBING" | "TENNIS" | "AEROBICS" | "CORE_TRAINING" | "DANCING" | "HIGH_INTENSITY_INTERVAL_TRAINING" | "KAYAKING" | "ROWING" | "SKIING" | "STANDUP_PADDLEBOARDING" | "STRENGTH_TRAINING" | "SNOWBOARDING";
}

function serializeGoogleAssistantEmbeddedV1FitnessActivity(data: any): GoogleAssistantEmbeddedV1FitnessActivity {
  return {
    ...data,
    mostRecentStartTime: data["mostRecentStartTime"] !== undefined ? data["mostRecentStartTime"].toISOString() : undefined,
    previouslyAccumulatedDuration: data["previouslyAccumulatedDuration"] !== undefined ? data["previouslyAccumulatedDuration"] : undefined,
  };
}

function deserializeGoogleAssistantEmbeddedV1FitnessActivity(data: any): GoogleAssistantEmbeddedV1FitnessActivity {
  return {
    ...data,
    mostRecentStartTime: data["mostRecentStartTime"] !== undefined ? new Date(data["mostRecentStartTime"]) : undefined,
    previouslyAccumulatedDuration: data["previouslyAccumulatedDuration"] !== undefined ? data["previouslyAccumulatedDuration"] : undefined,
  };
}

/**
 * Conceptually, timers are clocks that count down from an initial duration and
 * ring when they reach 0. In practice, as a timer is running, it holds a stable
 * expiration time and computes the remaining duration using the current time.
 * When a timer is paused, it holds a stable remaining duration.
 */
export interface GoogleAssistantEmbeddedV1Timer {
  /**
   * The time the timer is scheduled to expire. google.protobuf.Timestamp is a
   * Unix epoch time with a granularity of 1 nanosecond.
   */
  expireTime?: Date;
  /**
   * A user-provided name for this timer.
   */
  label?: string;
  /**
   * The duration of the timer when it was started. For the ADD_TIME action,
   * this field contains the amount of time to add to the timer with the given
   * timer_id.
   */
  originalDuration?: number /* Duration */;
  /**
   * The remaining duration for the timer.
   */
  remainingDuration?: number /* Duration */;
  /**
   * Describes the part of the lifecycle a timer is in.
   */
  status?:  | "TIMER_STATUS_UNSPECIFIED" | "RUNNING" | "PAUSED" | "FIRING";
  /**
   * A string key used as an identifier to this timer. This key needs to be
   * unique amongst all timers on the device. The client can choose a mechanism
   * of its choice to ensure this. If the server suggests a timer_id, the client
   * can either use the suggestion or create a new unique timer_id of its
   * choosing.
   */
  timerId?: string;
}

function serializeGoogleAssistantEmbeddedV1Timer(data: any): GoogleAssistantEmbeddedV1Timer {
  return {
    ...data,
    expireTime: data["expireTime"] !== undefined ? data["expireTime"].toISOString() : undefined,
    originalDuration: data["originalDuration"] !== undefined ? data["originalDuration"] : undefined,
    remainingDuration: data["remainingDuration"] !== undefined ? data["remainingDuration"] : undefined,
  };
}

function deserializeGoogleAssistantEmbeddedV1Timer(data: any): GoogleAssistantEmbeddedV1Timer {
  return {
    ...data,
    expireTime: data["expireTime"] !== undefined ? new Date(data["expireTime"]) : undefined,
    originalDuration: data["originalDuration"] !== undefined ? data["originalDuration"] : undefined,
    remainingDuration: data["remainingDuration"] !== undefined ? data["remainingDuration"] : undefined,
  };
}

/**
 * Contains information about on-device timers for devices that support timers.
 */
export interface GoogleAssistantEmbeddedV1Timers {
  /**
   * Indicates if an error occurred while fetching timer state. If this value
   * is missing, it can be assumed that the state fetch was successful.
   */
  stateFetchError?:  | "STATE_FETCH_ERROR_UNSPECIFIED" | "STATE_FETCH_ERROR_TIMEOUT";
  /**
   * Information about all on-device timers.
   */
  timers?: GoogleAssistantEmbeddedV1Timer[];
}

function serializeGoogleAssistantEmbeddedV1Timers(data: any): GoogleAssistantEmbeddedV1Timers {
  return {
    ...data,
    timers: data["timers"] !== undefined ? data["timers"].map((item: any) => (serializeGoogleAssistantEmbeddedV1Timer(item))) : undefined,
  };
}

function deserializeGoogleAssistantEmbeddedV1Timers(data: any): GoogleAssistantEmbeddedV1Timers {
  return {
    ...data,
    timers: data["timers"] !== undefined ? data["timers"].map((item: any) => (deserializeGoogleAssistantEmbeddedV1Timer(item))) : undefined,
  };
}

/**
 * Represents the action responsible for access control list management
 * operations.
 */
export interface GoogleCloudContentwarehouseV1AccessControlAction {
  /**
   * Identifies the type of operation.
   */
  operationType?:  | "UNKNOWN" | "ADD_POLICY_BINDING" | "REMOVE_POLICY_BINDING" | "REPLACE_POLICY_BINDING";
  /**
   * Represents the new policy from which bindings are added, removed or
   * replaced based on the type of the operation. the policy is limited to a few
   * 10s of KB.
   */
  policy?: GoogleIamV1Policy;
}

function serializeGoogleCloudContentwarehouseV1AccessControlAction(data: any): GoogleCloudContentwarehouseV1AccessControlAction {
  return {
    ...data,
    policy: data["policy"] !== undefined ? serializeGoogleIamV1Policy(data["policy"]) : undefined,
  };
}

function deserializeGoogleCloudContentwarehouseV1AccessControlAction(data: any): GoogleCloudContentwarehouseV1AccessControlAction {
  return {
    ...data,
    policy: data["policy"] !== undefined ? deserializeGoogleIamV1Policy(data["policy"]) : undefined,
  };
}

/**
 * Represents the action triggered by Rule Engine when the rule is true.
 */
export interface GoogleCloudContentwarehouseV1Action {
  /**
   * Action triggering access control operations.
   */
  accessControl?: GoogleCloudContentwarehouseV1AccessControlAction;
  /**
   * ID of the action. Managed internally.
   */
  actionId?: string;
  /**
   * Action triggering create document link operation.
   */
  addToFolder?: GoogleCloudContentwarehouseV1AddToFolderAction;
  /**
   * Action triggering data update operations.
   */
  dataUpdate?: GoogleCloudContentwarehouseV1DataUpdateAction;
  /**
   * Action triggering data validation operations.
   */
  dataValidation?: GoogleCloudContentwarehouseV1DataValidationAction;
  /**
   * Action deleting the document.
   */
  deleteDocumentAction?: GoogleCloudContentwarehouseV1DeleteDocumentAction;
  /**
   * Action publish to Pub/Sub operation.
   */
  publishToPubSub?: GoogleCloudContentwarehouseV1PublishAction;
  /**
   * Action removing a document from a folder.
   */
  removeFromFolderAction?: GoogleCloudContentwarehouseV1RemoveFromFolderAction;
}

function serializeGoogleCloudContentwarehouseV1Action(data: any): GoogleCloudContentwarehouseV1Action {
  return {
    ...data,
    accessControl: data["accessControl"] !== undefined ? serializeGoogleCloudContentwarehouseV1AccessControlAction(data["accessControl"]) : undefined,
  };
}

function deserializeGoogleCloudContentwarehouseV1Action(data: any): GoogleCloudContentwarehouseV1Action {
  return {
    ...data,
    accessControl: data["accessControl"] !== undefined ? deserializeGoogleCloudContentwarehouseV1AccessControlAction(data["accessControl"]) : undefined,
  };
}

/**
 * Represents the output of the Action Executor.
 */
export interface GoogleCloudContentwarehouseV1ActionExecutorOutput {
  /**
   * List of rule and corresponding actions result.
   */
  ruleActionsPairs?: GoogleCloudContentwarehouseV1RuleActionsPair[];
}

function serializeGoogleCloudContentwarehouseV1ActionExecutorOutput(data: any): GoogleCloudContentwarehouseV1ActionExecutorOutput {
  return {
    ...data,
    ruleActionsPairs: data["ruleActionsPairs"] !== undefined ? data["ruleActionsPairs"].map((item: any) => (serializeGoogleCloudContentwarehouseV1RuleActionsPair(item))) : undefined,
  };
}

function deserializeGoogleCloudContentwarehouseV1ActionExecutorOutput(data: any): GoogleCloudContentwarehouseV1ActionExecutorOutput {
  return {
    ...data,
    ruleActionsPairs: data["ruleActionsPairs"] !== undefined ? data["ruleActionsPairs"].map((item: any) => (deserializeGoogleCloudContentwarehouseV1RuleActionsPair(item))) : undefined,
  };
}

/**
 * Represents the result of executing an action.
 */
export interface GoogleCloudContentwarehouseV1ActionOutput {
  /**
   * ID of the action.
   */
  actionId?: string;
  /**
   * State of an action.
   */
  actionState?:  | "UNKNOWN" | "ACTION_SUCCEEDED" | "ACTION_FAILED" | "ACTION_TIMED_OUT" | "ACTION_PENDING";
  /**
   * Action execution output message.
   */
  outputMessage?: string;
}

/**
 * Represents the action responsible for adding document under a folder.
 */
export interface GoogleCloudContentwarehouseV1AddToFolderAction {
  /**
   * Names of the folder under which new document is to be added. Format:
   * projects/{project_number}/locations/{location}/documents/{document_id}.
   */
  folders?: string[];
}

/**
 * Metadata object for CreateDocument request (currently empty).
 */
export interface GoogleCloudContentwarehouseV1beta1CreateDocumentMetadata {
}

/**
 * Response message for projectService.InitializeProject
 */
export interface GoogleCloudContentwarehouseV1beta1InitializeProjectResponse {
  /**
   * The message of the project initialization process.
   */
  message?: string;
  /**
   * The state of the project initialization process.
   */
  state?:  | "STATE_UNSPECIFIED" | "SUCCEEDED" | "FAILED" | "CANCELLED" | "RUNNING";
}

/**
 * Metadata object for UpdateDocument request (currently empty).
 */
export interface GoogleCloudContentwarehouseV1beta1UpdateDocumentMetadata {
}

/**
 * Request Option for processing Cloud AI Document in CW Document.
 */
export interface GoogleCloudContentwarehouseV1CloudAIDocumentOption {
  /**
   * If set, only selected entities will be converted to properties.
   */
  customizedEntitiesPropertiesConversions?: {
    [key: string]: string
  };
  /**
   * Whether to convert all the entities to properties.
   */
  enableEntitiesConversions?: boolean;
}

/**
 * Request message for DocumentLinkService.CreateDocumentLink.
 */
export interface GoogleCloudContentwarehouseV1CreateDocumentLinkRequest {
  /**
   * Required. Document links associated with the source documents
   * (source_document_id).
   */
  documentLink?: GoogleCloudContentwarehouseV1DocumentLink;
  /**
   * The meta information collected about the document creator, used to enforce
   * access control for the service.
   */
  requestMetadata?: GoogleCloudContentwarehouseV1RequestMetadata;
}

/**
 * Metadata object for CreateDocument request (currently empty).
 */
export interface GoogleCloudContentwarehouseV1CreateDocumentMetadata {
}

/**
 * Request message for DocumentService.CreateDocument.
 */
export interface GoogleCloudContentwarehouseV1CreateDocumentRequest {
  /**
   * Request Option for processing Cloud AI Document in Document Warehouse.
   * This field offers limited support for mapping entities from Cloud AI
   * Document to Warehouse Document. Please consult with product team before
   * using this field and other available options.
   */
  cloudAiDocumentOption?: GoogleCloudContentwarehouseV1CloudAIDocumentOption;
  /**
   * Field mask for creating Document fields. If mask path is empty, it means
   * all fields are masked. For the `FieldMask` definition, see
   * https://developers.google.com/protocol-buffers/docs/reference/google.protobuf#fieldmask.
   */
  createMask?: string /* FieldMask */;
  /**
   * Required. The document to create.
   */
  document?: GoogleCloudContentwarehouseV1Document;
  /**
   * Default document policy during creation. This refers to an Identity and
   * Access (IAM) policy, which specifies access controls for the Document.
   * Conditions defined in the policy will be ignored.
   */
  policy?: GoogleIamV1Policy;
  /**
   * The meta information collected about the end user, used to enforce access
   * control for the service.
   */
  requestMetadata?: GoogleCloudContentwarehouseV1RequestMetadata;
}

function serializeGoogleCloudContentwarehouseV1CreateDocumentRequest(data: any): GoogleCloudContentwarehouseV1CreateDocumentRequest {
  return {
    ...data,
    createMask: data["createMask"] !== undefined ? data["createMask"] : undefined,
    document: data["document"] !== undefined ? serializeGoogleCloudContentwarehouseV1Document(data["document"]) : undefined,
    policy: data["policy"] !== undefined ? serializeGoogleIamV1Policy(data["policy"]) : undefined,
  };
}

function deserializeGoogleCloudContentwarehouseV1CreateDocumentRequest(data: any): GoogleCloudContentwarehouseV1CreateDocumentRequest {
  return {
    ...data,
    createMask: data["createMask"] !== undefined ? data["createMask"] : undefined,
    document: data["document"] !== undefined ? deserializeGoogleCloudContentwarehouseV1Document(data["document"]) : undefined,
    policy: data["policy"] !== undefined ? deserializeGoogleIamV1Policy(data["policy"]) : undefined,
  };
}

/**
 * Response message for DocumentService.CreateDocument.
 */
export interface GoogleCloudContentwarehouseV1CreateDocumentResponse {
  /**
   * Document created after executing create request.
   */
  document?: GoogleCloudContentwarehouseV1Document;
  /**
   * post-processing LROs
   */
  longRunningOperations?: GoogleLongrunningOperation[];
  /**
   * Additional information for the API invocation, such as the request
   * tracking id.
   */
  metadata?: GoogleCloudContentwarehouseV1ResponseMetadata;
  /**
   * Output from Rule Engine recording the rule evaluator and action executor's
   * output. Refer format in: google/cloud/contentwarehouse/v1/rule_engine.proto
   */
  ruleEngineOutput?: GoogleCloudContentwarehouseV1RuleEngineOutput;
}

function serializeGoogleCloudContentwarehouseV1CreateDocumentResponse(data: any): GoogleCloudContentwarehouseV1CreateDocumentResponse {
  return {
    ...data,
    document: data["document"] !== undefined ? serializeGoogleCloudContentwarehouseV1Document(data["document"]) : undefined,
    ruleEngineOutput: data["ruleEngineOutput"] !== undefined ? serializeGoogleCloudContentwarehouseV1RuleEngineOutput(data["ruleEngineOutput"]) : undefined,
  };
}

function deserializeGoogleCloudContentwarehouseV1CreateDocumentResponse(data: any): GoogleCloudContentwarehouseV1CreateDocumentResponse {
  return {
    ...data,
    document: data["document"] !== undefined ? deserializeGoogleCloudContentwarehouseV1Document(data["document"]) : undefined,
    ruleEngineOutput: data["ruleEngineOutput"] !== undefined ? deserializeGoogleCloudContentwarehouseV1RuleEngineOutput(data["ruleEngineOutput"]) : undefined,
  };
}

/**
 * To support the custom weighting across document schemas.
 */
export interface GoogleCloudContentwarehouseV1CustomWeightsMetadata {
  /**
   * List of schema and property name. Allows a maximum of 10 schemas to be
   * specified for relevance boosting.
   */
  weightedSchemaProperties?: GoogleCloudContentwarehouseV1WeightedSchemaProperty[];
}

/**
 * Represents the action responsible for properties update operations.
 */
export interface GoogleCloudContentwarehouseV1DataUpdateAction {
  /**
   * Map of (K, V) -> (valid name of the field, new value of the field) E.g.,
   * ("age", "60") entry triggers update of field age with a value of 60. If the
   * field is not present then new entry is added. During update action
   * execution, value strings will be casted to appropriate types.
   */
  entries?: {
    [key: string]: string
  };
}

/**
 * Represents the action responsible for data validation operations.
 */
export interface GoogleCloudContentwarehouseV1DataValidationAction {
  /**
   * Map of (K, V) -> (field, string condition to be evaluated on the field)
   * E.g., ("age", "age > 18 && age < 60") entry triggers validation of field
   * age with the given condition. Map entries will be ANDed during validation.
   */
  conditions?: {
    [key: string]: string
  };
}

/**
 * DateTime values.
 */
export interface GoogleCloudContentwarehouseV1DateTimeArray {
  /**
   * List of datetime values. Both OffsetDateTime and ZonedDateTime are
   * supported.
   */
  values?: GoogleTypeDateTime[];
}

function serializeGoogleCloudContentwarehouseV1DateTimeArray(data: any): GoogleCloudContentwarehouseV1DateTimeArray {
  return {
    ...data,
    values: data["values"] !== undefined ? data["values"].map((item: any) => (serializeGoogleTypeDateTime(item))) : undefined,
  };
}

function deserializeGoogleCloudContentwarehouseV1DateTimeArray(data: any): GoogleCloudContentwarehouseV1DateTimeArray {
  return {
    ...data,
    values: data["values"] !== undefined ? data["values"].map((item: any) => (deserializeGoogleTypeDateTime(item))) : undefined,
  };
}

/**
 * Configurations for a date time property.
 */
export interface GoogleCloudContentwarehouseV1DateTimeTypeOptions {
}

/**
 * Represents the action responsible for deleting the document.
 */
export interface GoogleCloudContentwarehouseV1DeleteDocumentAction {
  /**
   * Boolean field to select between hard vs soft delete options. Set 'true'
   * for 'hard delete' and 'false' for 'soft delete'.
   */
  enableHardDelete?: boolean;
}

/**
 * Request message for DocumentLinkService.DeleteDocumentLink.
 */
export interface GoogleCloudContentwarehouseV1DeleteDocumentLinkRequest {
  /**
   * The meta information collected about the document creator, used to enforce
   * access control for the service.
   */
  requestMetadata?: GoogleCloudContentwarehouseV1RequestMetadata;
}

/**
 * Request message for DocumentService.DeleteDocument.
 */
export interface GoogleCloudContentwarehouseV1DeleteDocumentRequest {
  /**
   * The meta information collected about the end user, used to enforce access
   * control for the service.
   */
  requestMetadata?: GoogleCloudContentwarehouseV1RequestMetadata;
}

/**
 * Defines the structure for content warehouse document proto.
 */
export interface GoogleCloudContentwarehouseV1Document {
  /**
   * Document AI format to save the structured content, including OCR.
   */
  cloudAiDocument?: GoogleCloudDocumentaiV1Document;
  /**
   * Indicates the category (image, audio, video etc.) of the original content.
   */
  contentCategory?:  | "CONTENT_CATEGORY_UNSPECIFIED" | "CONTENT_CATEGORY_IMAGE" | "CONTENT_CATEGORY_AUDIO" | "CONTENT_CATEGORY_VIDEO";
  /**
   * Output only. The time when the document is created.
   */
  readonly createTime?: Date;
  /**
   * The user who creates the document.
   */
  creator?: string;
  /**
   * Required. Display name of the document given by the user. This name will
   * be displayed in the UI. Customer can populate this field with the name of
   * the document. This differs from the 'title' field as 'title' is optional
   * and stores the top heading in the document.
   */
  displayName?: string;
  /**
   * Uri to display the document, for example, in the UI.
   */
  displayUri?: string;
  /**
   * The Document schema name. Format:
   * projects/{project_number}/locations/{location}/documentSchemas/{document_schema_id}.
   */
  documentSchemaName?: string;
  /**
   * Raw document content.
   */
  inlineRawDocument?: Uint8Array;
  /**
   * The resource name of the document. Format:
   * projects/{project_number}/locations/{location}/documents/{document_id}. The
   * name is ignored when creating a document.
   */
  name?: string;
  /**
   * Other document format, such as PPTX, XLXS
   */
  plainText?: string;
  /**
   * List of values that are user supplied metadata.
   */
  properties?: GoogleCloudContentwarehouseV1Property[];
  /**
   * This is used when DocAI was not used to load the document and parsing/
   * extracting is needed for the inline_raw_document. For example, if
   * inline_raw_document is the byte representation of a PDF file, then this
   * should be set to: RAW_DOCUMENT_FILE_TYPE_PDF.
   */
  rawDocumentFileType?:  | "RAW_DOCUMENT_FILE_TYPE_UNSPECIFIED" | "RAW_DOCUMENT_FILE_TYPE_PDF" | "RAW_DOCUMENT_FILE_TYPE_DOCX" | "RAW_DOCUMENT_FILE_TYPE_XLSX" | "RAW_DOCUMENT_FILE_TYPE_PPTX" | "RAW_DOCUMENT_FILE_TYPE_TEXT" | "RAW_DOCUMENT_FILE_TYPE_TIFF";
  /**
   * Raw document file in Cloud Storage path.
   */
  rawDocumentPath?: string;
  /**
   * The reference ID set by customers. Must be unique per project and
   * location.
   */
  referenceId?: string;
  /**
   * If true, text extraction will not be performed.
   */
  textExtractionDisabled?: boolean;
  /**
   * If true, text extraction will be performed.
   */
  textExtractionEnabled?: boolean;
  /**
   * Title that describes the document. This can be the top heading or text
   * that describes the document.
   */
  title?: string;
  /**
   * The user who lastly updates the document.
   */
  updater?: string;
  /**
   * Output only. The time when the document is last updated.
   */
  readonly updateTime?: Date;
}

function serializeGoogleCloudContentwarehouseV1Document(data: any): GoogleCloudContentwarehouseV1Document {
  return {
    ...data,
    cloudAiDocument: data["cloudAiDocument"] !== undefined ? serializeGoogleCloudDocumentaiV1Document(data["cloudAiDocument"]) : undefined,
    inlineRawDocument: data["inlineRawDocument"] !== undefined ? encodeBase64(data["inlineRawDocument"]) : undefined,
    properties: data["properties"] !== undefined ? data["properties"].map((item: any) => (serializeGoogleCloudContentwarehouseV1Property(item))) : undefined,
  };
}

function deserializeGoogleCloudContentwarehouseV1Document(data: any): GoogleCloudContentwarehouseV1Document {
  return {
    ...data,
    cloudAiDocument: data["cloudAiDocument"] !== undefined ? deserializeGoogleCloudDocumentaiV1Document(data["cloudAiDocument"]) : undefined,
    createTime: data["createTime"] !== undefined ? new Date(data["createTime"]) : undefined,
    inlineRawDocument: data["inlineRawDocument"] !== undefined ? decodeBase64(data["inlineRawDocument"] as string) : undefined,
    properties: data["properties"] !== undefined ? data["properties"].map((item: any) => (deserializeGoogleCloudContentwarehouseV1Property(item))) : undefined,
    updateTime: data["updateTime"] !== undefined ? new Date(data["updateTime"]) : undefined,
  };
}

/**
 * A document-link between source and target document.
 */
export interface GoogleCloudContentwarehouseV1DocumentLink {
  /**
   * Output only. The time when the documentLink is created.
   */
  readonly createTime?: Date;
  /**
   * Description of this document-link.
   */
  description?: string;
  /**
   * Name of this document-link. It is required that the parent derived form
   * the name to be consistent with the source document reference. Otherwise an
   * exception will be thrown. Format:
   * projects/{project_number}/locations/{location}/documents/{source_document_id}/documentLinks/{document_link_id}.
   */
  name?: string;
  /**
   * Document references of the source document.
   */
  sourceDocumentReference?: GoogleCloudContentwarehouseV1DocumentReference;
  /**
   * The state of the documentlink. If target node has been deleted, the link
   * is marked as invalid. Removing a source node will result in removal of all
   * associated links.
   */
  state?:  | "STATE_UNSPECIFIED" | "ACTIVE" | "SOFT_DELETED";
  /**
   * Document references of the target document.
   */
  targetDocumentReference?: GoogleCloudContentwarehouseV1DocumentReference;
  /**
   * Output only. The time when the documentLink is last updated.
   */
  readonly updateTime?: Date;
}

export interface GoogleCloudContentwarehouseV1DocumentQuery {
  /**
   * This filter specifies a structured syntax to match against the
   * [PropertyDefinition].is_filterable marked as `true`. The syntax for this
   * expression is a subset of SQL syntax. Supported operators are: `=`, `!=`,
   * `<`, `<=`, `>`, and `>=` where the left of the operator is a property name
   * and the right of the operator is a number or a quoted string. You must
   * escape backslash (\\) and quote (\") characters. Supported functions are
   * `LOWER([property_name])` to perform a case insensitive match and
   * `EMPTY([property_name])` to filter on the existence of a key. Boolean
   * expressions (AND/OR/NOT) are supported up to 3 levels of nesting (for
   * example, "((A AND B AND C) OR NOT D) AND E"), a maximum of 100 comparisons
   * or functions are allowed in the expression. The expression must be < 6000
   * bytes in length. Sample Query: `(LOWER(driving_license)="class \"a\"" OR
   * EMPTY(driving_license)) AND driving_years > 10`
   */
  customPropertyFilter?: string;
  /**
   * To support the custom weighting across document schemas, customers need to
   * provide the properties to be used to boost the ranking in the search
   * request. For a search query with CustomWeightsMetadata specified, only the
   * RetrievalImportance for the properties in the CustomWeightsMetadata will be
   * honored.
   */
  customWeightsMetadata?: GoogleCloudContentwarehouseV1CustomWeightsMetadata;
  /**
   * The exact creator(s) of the documents to search against. If a value isn't
   * specified, documents within the search results are associated with any
   * creator. If multiple values are specified, documents within the search
   * results may be associated with any of the specified creators.
   */
  documentCreatorFilter?: string[];
  /**
   * This filter specifies the exact document schema
   * Document.document_schema_name of the documents to search against. If a
   * value isn't specified, documents within the search results are associated
   * with any schema. If multiple values are specified, documents within the
   * search results may be associated with any of the specified schemas. At most
   * 20 document schema names are allowed.
   */
  documentSchemaNames?: string[];
  /**
   * This filter specifies the types of files to return: ALL, FOLDER, or FILE.
   * If FOLDER or FILE is specified, then only either folders or files will be
   * returned, respectively. If ALL is specified, both folders and files will be
   * returned. If no value is specified, ALL files will be returned.
   */
  fileTypeFilter?: GoogleCloudContentwarehouseV1FileTypeFilter;
  /**
   * Search all the documents under this specified folder. Format:
   * projects/{project_number}/locations/{location}/documents/{document_id}.
   */
  folderNameFilter?: string;
  /**
   * Experimental, do not use. If the query is a natural language question.
   * False by default. If true, then the question-answering feature will be used
   * instead of search, and `result_count` in SearchDocumentsRequest must be
   * set. In addition, all other input fields related to search (pagination,
   * histograms, etc.) will be ignored.
   */
  isNlQuery?: boolean;
  /**
   * This filter specifies a structured syntax to match against the
   * PropertyDefinition.is_filterable marked as `true`. The relationship between
   * the PropertyFilters is OR.
   */
  propertyFilter?: GoogleCloudContentwarehouseV1PropertyFilter[];
  /**
   * The query string that matches against the full text of the document and
   * the searchable properties. The query partially supports [Google AIP style
   * syntax](https://google.aip.dev/160). Specifically, the query supports
   * literals, logical operators, negation operators, comparison operators, and
   * functions. Literals: A bare literal value (examples: "42", "Hugo") is a
   * value to be matched against. It searches over the full text of the document
   * and the searchable properties. Logical operators: "AND", "and", "OR", and
   * "or" are binary logical operators (example: "engineer OR developer").
   * Negation operators: "NOT" and "!" are negation operators (example: "NOT
   * software"). Comparison operators: support the binary comparison operators
   * =, !=, <, >, <= and >= for string, numeric, enum, boolean. Also support
   * like operator `~~` for string. It provides semantic search functionality by
   * parsing, stemming and doing synonyms expansion against the input query. To
   * specify a property in the query, the left hand side expression in the
   * comparison must be the property ID including the parent. The right hand
   * side must be literals. For example:
   * "\"projects/123/locations/us\".property_a < 1" matches results whose
   * "property_a" is less than 1 in project 123 and us location. The literals
   * and comparison expression can be connected in a single query (example:
   * "software engineer \"projects/123/locations/us\".salary > 100"). Functions:
   * supported functions are `LOWER([property_name])` to perform a case
   * insensitive match and `EMPTY([property_name])` to filter on the existence
   * of a key. Support nested expressions connected using parenthesis and
   * logical operators. The default logical operators is `AND` if there is no
   * operators between expressions. The query can be used with other filters
   * e.g. `time_filters` and `folder_name_filter`. They are connected with `AND`
   * operator under the hood. The maximum number of allowed characters is 255.
   */
  query?: string;
  /**
   * For custom synonyms. Customers provide the synonyms based on context. One
   * customer can provide multiple set of synonyms based on different context.
   * The search query will be expanded based on the custom synonyms of the query
   * context set. By default, no custom synonyms wll be applied if no query
   * context is provided. It is not supported for CMEK compliant deployment.
   */
  queryContext?: string[];
  /**
   * Documents created/updated within a range specified by this filter are
   * searched against.
   */
  timeFilters?: GoogleCloudContentwarehouseV1TimeFilter[];
}

function serializeGoogleCloudContentwarehouseV1DocumentQuery(data: any): GoogleCloudContentwarehouseV1DocumentQuery {
  return {
    ...data,
    timeFilters: data["timeFilters"] !== undefined ? data["timeFilters"].map((item: any) => (serializeGoogleCloudContentwarehouseV1TimeFilter(item))) : undefined,
  };
}

function deserializeGoogleCloudContentwarehouseV1DocumentQuery(data: any): GoogleCloudContentwarehouseV1DocumentQuery {
  return {
    ...data,
    timeFilters: data["timeFilters"] !== undefined ? data["timeFilters"].map((item: any) => (deserializeGoogleCloudContentwarehouseV1TimeFilter(item))) : undefined,
  };
}

/**
 * References to the documents.
 */
export interface GoogleCloudContentwarehouseV1DocumentReference {
  /**
   * Output only. The time when the document is created.
   */
  readonly createTime?: Date;
  /**
   * Output only. The time when the document is deleted.
   */
  readonly deleteTime?: Date;
  /**
   * display_name of the referenced document; this name does not need to be
   * consistent to the display_name in the Document proto, depending on the ACL
   * constraint.
   */
  displayName?: string;
  /**
   * The document type of the document being referenced.
   */
  documentIsFolder?: boolean;
  /**
   * Required. Name of the referenced document.
   */
  documentName?: string;
  /**
   * Stores the subset of the referenced document's content. This is useful to
   * allow user peek the information of the referenced document.
   */
  snippet?: string;
  /**
   * Output only. The time when the document is last updated.
   */
  readonly updateTime?: Date;
}

/**
 * A document schema used to define document structure.
 */
export interface GoogleCloudContentwarehouseV1DocumentSchema {
  /**
   * Output only. The time when the document schema is created.
   */
  readonly createTime?: Date;
  /**
   * Schema description.
   */
  description?: string;
  /**
   * Required. Name of the schema given by the user. Must be unique per
   * project.
   */
  displayName?: string;
  /**
   * Document Type, true refers the document is a folder, otherwise it is a
   * typical document.
   */
  documentIsFolder?: boolean;
  /**
   * The resource name of the document schema. Format:
   * projects/{project_number}/locations/{location}/documentSchemas/{document_schema_id}.
   * The name is ignored when creating a document schema.
   */
  name?: string;
  /**
   * Document details.
   */
  propertyDefinitions?: GoogleCloudContentwarehouseV1PropertyDefinition[];
  /**
   * Output only. The time when the document schema is last updated.
   */
  readonly updateTime?: Date;
}

/**
 * Enum values.
 */
export interface GoogleCloudContentwarehouseV1EnumArray {
  /**
   * List of enum values.
   */
  values?: string[];
}

/**
 * Configurations for an enum/categorical property.
 */
export interface GoogleCloudContentwarehouseV1EnumTypeOptions {
  /**
   * Required. List of possible enum values.
   */
  possibleValues?: string[];
  /**
   * Make sure the Enum property value provided in the document is in the
   * possile value list during document creation. The validation check runs by
   * default.
   */
  validationCheckDisabled?: boolean;
}

/**
 * Represents the string value of the enum field.
 */
export interface GoogleCloudContentwarehouseV1EnumValue {
  /**
   * String value of the enum field. This must match defined set of enums in
   * document schema using EnumTypeOptions.
   */
  value?: string;
}

/**
 * The configuration of exporting documents from the Document Warehouse to CDW
 * pipeline.
 */
export interface GoogleCloudContentwarehouseV1ExportToCdwPipeline {
  /**
   * The CDW dataset resource name. Format:
   * projects/{project}/locations/{location}/processors/{processor}/dataset
   */
  docAiDataset?: string;
  /**
   * The list of all the resource names of the documents to be processed.
   * Format:
   * projects/{project_number}/locations/{location}/documents/{document_id}.
   */
  documents?: string[];
  /**
   * The Cloud Storage folder path used to store the exported documents before
   * being sent to CDW. Format: gs:///.
   */
  exportFolderPath?: string;
  /**
   * Ratio of training dataset split. When importing into Document AI
   * Workbench, documents will be automatically split into training and test
   * split category with the specified ratio.
   */
  trainingSplitRatio?: number;
}

/**
 * Request message for DocumentService.FetchAcl
 */
export interface GoogleCloudContentwarehouseV1FetchAclRequest {
  /**
   * For Get Project ACL only. Authorization check for end user will be ignored
   * when project_owner=true.
   */
  projectOwner?: boolean;
  /**
   * The meta information collected about the end user, used to enforce access
   * control for the service.
   */
  requestMetadata?: GoogleCloudContentwarehouseV1RequestMetadata;
}

/**
 * Response message for DocumentService.FetchAcl.
 */
export interface GoogleCloudContentwarehouseV1FetchAclResponse {
  /**
   * Additional information for the API invocation, such as the request
   * tracking id.
   */
  metadata?: GoogleCloudContentwarehouseV1ResponseMetadata;
  /**
   * The IAM policy.
   */
  policy?: GoogleIamV1Policy;
}

function serializeGoogleCloudContentwarehouseV1FetchAclResponse(data: any): GoogleCloudContentwarehouseV1FetchAclResponse {
  return {
    ...data,
    policy: data["policy"] !== undefined ? serializeGoogleIamV1Policy(data["policy"]) : undefined,
  };
}

function deserializeGoogleCloudContentwarehouseV1FetchAclResponse(data: any): GoogleCloudContentwarehouseV1FetchAclResponse {
  return {
    ...data,
    policy: data["policy"] !== undefined ? deserializeGoogleIamV1Policy(data["policy"]) : undefined,
  };
}

/**
 * Filter for the specific types of documents returned.
 */
export interface GoogleCloudContentwarehouseV1FileTypeFilter {
  /**
   * The type of files to return.
   */
  fileType?:  | "FILE_TYPE_UNSPECIFIED" | "ALL" | "FOLDER" | "DOCUMENT";
}

/**
 * Float values.
 */
export interface GoogleCloudContentwarehouseV1FloatArray {
  /**
   * List of float values.
   */
  values?: number[];
}

/**
 * Configurations for a float property.
 */
export interface GoogleCloudContentwarehouseV1FloatTypeOptions {
}

/**
 * The configuration of the Cloud Storage ingestion pipeline.
 */
export interface GoogleCloudContentwarehouseV1GcsIngestPipeline {
  /**
   * The input Cloud Storage folder. All files under this folder will be
   * imported to Document Warehouse. Format: gs:///.
   */
  inputPath?: string;
  /**
   * The Doc AI processor type name. Only used when the format of ingested
   * files is Doc AI Document proto format. Reference:
   * https://source.corp.google.com/piper///depot/google3/cloud/ai/documentai/core/c/proto/processor.proto;l=21
   */
  processorType?: string;
  /**
   * The Document Warehouse schema resource name. All documents processed by
   * this pipeline will use this schema. Format:
   * projects/{project_number}/locations/{location}/documentSchemas/{document_schema_id}.
   */
  schemaName?: string;
}

/**
 * The configuration of the document classify/split and entity/kvp extraction
 * pipeline.
 */
export interface GoogleCloudContentwarehouseV1GcsIngestWithDocAiProcessorsPipeline {
  /**
   * The extract processors information. One matched extract processor will be
   * used to process documents based on the classify processor result. If no
   * classify processor is specificied, the first extract processor will be
   * used.
   */
  extractProcessorInfos?: GoogleCloudContentwarehouseV1ProcessorInfo[];
  /**
   * The input Cloud Storage folder. All files under this folder will be
   * imported to Document Warehouse. Format: gs:///.
   */
  inputPath?: string;
  /**
   * The Cloud Storage folder path used to store the raw results from
   * processors. Format: gs:///.
   */
  processorResultsFolderPath?: string;
  /**
   * The split and classify processor information. The split and classify
   * result will be used to find a matched extract processor.
   */
  splitClassifyProcessorInfo?: GoogleCloudContentwarehouseV1ProcessorInfo;
}

/**
 * Request message for DocumentService.GetDocument.
 */
export interface GoogleCloudContentwarehouseV1GetDocumentRequest {
  /**
   * The meta information collected about the end user, used to enforce access
   * control for the service.
   */
  requestMetadata?: GoogleCloudContentwarehouseV1RequestMetadata;
}

/**
 * The histogram request.
 */
export interface GoogleCloudContentwarehouseV1HistogramQuery {
  /**
   * Optional. Filter the result of histogram query by the property names. It
   * only works with histogram query count('FilterableProperties'). It is an
   * optional. It will perform histogram on all the property names for all the
   * document schemas. Setting this field will have a better performance.
   */
  filters?: GoogleCloudContentwarehouseV1HistogramQueryPropertyNameFilter;
  /**
   * An expression specifies a histogram request against matching documents for
   * searches. See SearchDocumentsRequest.histogram_queries for details about
   * syntax.
   */
  histogramQuery?: string;
  /**
   * Controls if the histogram query requires the return of a precise count.
   * Enable this flag may adversely impact performance. Defaults to true.
   */
  requirePreciseResultSize?: boolean;
}

export interface GoogleCloudContentwarehouseV1HistogramQueryPropertyNameFilter {
  /**
   * This filter specifies the exact document schema(s)
   * Document.document_schema_name to run histogram query against. It is
   * optional. It will perform histogram for property names for all the document
   * schemas if it is not set. At most 10 document schema names are allowed.
   * Format:
   * projects/{project_number}/locations/{location}/documentSchemas/{document_schema_id}.
   */
  documentSchemas?: string[];
  /**
   * It is optional. It will perform histogram for all the property names if it
   * is not set. The properties need to be defined with the is_filterable flag
   * set to true and the name of the property should be in the format:
   * "schemaId.propertyName". The property needs to be defined in the schema.
   * Example: the schema id is abc. Then the name of property for property
   * MORTGAGE_TYPE will be "abc.MORTGAGE_TYPE".
   */
  propertyNames?: string[];
  /**
   * By default, the y_axis is HISTOGRAM_YAXIS_DOCUMENT if this field is not
   * set.
   */
  yAxis?:  | "HISTOGRAM_YAXIS_DOCUMENT" | "HISTOGRAM_YAXIS_PROPERTY";
}

/**
 * Histogram result that matches HistogramQuery specified in searches.
 */
export interface GoogleCloudContentwarehouseV1HistogramQueryResult {
  /**
   * A map from the values of the facet associated with distinct values to the
   * number of matching entries with corresponding value. The key format is: *
   * (for string histogram) string values stored in the field.
   */
  histogram?: {
    [key: string]: bigint
  };
  /**
   * Requested histogram expression.
   */
  histogramQuery?: string;
}

function serializeGoogleCloudContentwarehouseV1HistogramQueryResult(data: any): GoogleCloudContentwarehouseV1HistogramQueryResult {
  return {
    ...data,
    histogram: data["histogram"] !== undefined ? Object.fromEntries(Object.entries(data["histogram"]).map(([k, v]: [string, any]) => ([k, String(v)]))) : undefined,
  };
}

function deserializeGoogleCloudContentwarehouseV1HistogramQueryResult(data: any): GoogleCloudContentwarehouseV1HistogramQueryResult {
  return {
    ...data,
    histogram: data["histogram"] !== undefined ? Object.fromEntries(Object.entries(data["histogram"]).map(([k, v]: [string, any]) => ([k, BigInt(v)]))) : undefined,
  };
}

/**
 * Request message for projectService.InitializeProject
 */
export interface GoogleCloudContentwarehouseV1InitializeProjectRequest {
  /**
   * Required. The access control mode for accessing the customer data
   */
  accessControlMode?:  | "ACL_MODE_UNKNOWN" | "ACL_MODE_UNIVERSAL_ACCESS" | "ACL_MODE_DOCUMENT_LEVEL_ACCESS_CONTROL_BYOID" | "ACL_MODE_DOCUMENT_LEVEL_ACCESS_CONTROL_GCI";
  /**
   * Required. The type of database used to store customer data
   */
  databaseType?:  | "DB_UNKNOWN" | "DB_INFRA_SPANNER" | "DB_CLOUD_SQL_POSTGRES";
  /**
   * Optional. The default role for the person who create a document.
   */
  documentCreatorDefaultRole?:  | "DOCUMENT_CREATOR_DEFAULT_ROLE_UNSPECIFIED" | "DOCUMENT_ADMIN" | "DOCUMENT_EDITOR" | "DOCUMENT_VIEWER";
  /**
   * Optional. The KMS key used for CMEK encryption. It is required that the
   * kms key is in the same region as the endpoint. The same key will be used
   * for all provisioned resources, if encryption is available. If the kms_key
   * is left empty, no encryption will be enforced.
   */
  kmsKey?: string;
}

/**
 * Response message for projectService.InitializeProject
 */
export interface GoogleCloudContentwarehouseV1InitializeProjectResponse {
  /**
   * The message of the project initialization process.
   */
  message?: string;
  /**
   * The state of the project initialization process.
   */
  state?:  | "STATE_UNSPECIFIED" | "SUCCEEDED" | "FAILED" | "CANCELLED" | "RUNNING";
}

/**
 * Integer values.
 */
export interface GoogleCloudContentwarehouseV1IntegerArray {
  /**
   * List of integer values.
   */
  values?: number[];
}

/**
 * Configurations for an integer property.
 */
export interface GoogleCloudContentwarehouseV1IntegerTypeOptions {
}

/**
 * A triggered rule that failed the validation check(s) after parsing.
 */
export interface GoogleCloudContentwarehouseV1InvalidRule {
  /**
   * Validation error on a parsed expression.
   */
  error?: string;
  /**
   * Triggered rule.
   */
  rule?: GoogleCloudContentwarehouseV1Rule;
}

function serializeGoogleCloudContentwarehouseV1InvalidRule(data: any): GoogleCloudContentwarehouseV1InvalidRule {
  return {
    ...data,
    rule: data["rule"] !== undefined ? serializeGoogleCloudContentwarehouseV1Rule(data["rule"]) : undefined,
  };
}

function deserializeGoogleCloudContentwarehouseV1InvalidRule(data: any): GoogleCloudContentwarehouseV1InvalidRule {
  return {
    ...data,
    rule: data["rule"] !== undefined ? deserializeGoogleCloudContentwarehouseV1Rule(data["rule"]) : undefined,
  };
}

/**
 * Response message for DocumentSchemaService.ListDocumentSchemas.
 */
export interface GoogleCloudContentwarehouseV1ListDocumentSchemasResponse {
  /**
   * The document schemas from the specified parent.
   */
  documentSchemas?: GoogleCloudContentwarehouseV1DocumentSchema[];
  /**
   * A token, which can be sent as `page_token` to retrieve the next page. If
   * this field is omitted, there are no subsequent pages.
   */
  nextPageToken?: string;
}

/**
 * Response message for DocumentLinkService.ListLinkedSources.
 */
export interface GoogleCloudContentwarehouseV1ListLinkedSourcesRequest {
  /**
   * The maximum number of document-links to return. The service may return
   * fewer than this value. If unspecified, at most 50 document-links will be
   * returned. The maximum value is 1000; values above 1000 will be coerced to
   * 1000.
   */
  pageSize?: number;
  /**
   * A page token, received from a previous `ListLinkedSources` call. Provide
   * this to retrieve the subsequent page. When paginating, all other parameters
   * provided to `ListLinkedSources` must match the call that provided the page
   * token.
   */
  pageToken?: string;
  /**
   * The meta information collected about the document creator, used to enforce
   * access control for the service.
   */
  requestMetadata?: GoogleCloudContentwarehouseV1RequestMetadata;
}

/**
 * Response message for DocumentLinkService.ListLinkedSources.
 */
export interface GoogleCloudContentwarehouseV1ListLinkedSourcesResponse {
  /**
   * Source document-links.
   */
  documentLinks?: GoogleCloudContentwarehouseV1DocumentLink[];
  /**
   * A token, which can be sent as `page_token` to retrieve the next page. If
   * this field is omitted, there are no subsequent pages.
   */
  nextPageToken?: string;
}

/**
 * Request message for DocumentLinkService.ListLinkedTargets.
 */
export interface GoogleCloudContentwarehouseV1ListLinkedTargetsRequest {
  /**
   * The meta information collected about the document creator, used to enforce
   * access control for the service.
   */
  requestMetadata?: GoogleCloudContentwarehouseV1RequestMetadata;
}

/**
 * Response message for DocumentLinkService.ListLinkedTargets.
 */
export interface GoogleCloudContentwarehouseV1ListLinkedTargetsResponse {
  /**
   * Target document-links.
   */
  documentLinks?: GoogleCloudContentwarehouseV1DocumentLink[];
  /**
   * A token, which can be sent as `page_token` to retrieve the next page. If
   * this field is omitted, there are no subsequent pages.
   */
  nextPageToken?: string;
}

/**
 * Response message for RuleSetService.ListRuleSets.
 */
export interface GoogleCloudContentwarehouseV1ListRuleSetsResponse {
  /**
   * A token, which can be sent as `page_token` to retrieve the next page. If
   * this field is omitted, there are no subsequent pages.
   */
  nextPageToken?: string;
  /**
   * The rule sets from the specified parent.
   */
  ruleSets?: GoogleCloudContentwarehouseV1RuleSet[];
}

function serializeGoogleCloudContentwarehouseV1ListRuleSetsResponse(data: any): GoogleCloudContentwarehouseV1ListRuleSetsResponse {
  return {
    ...data,
    ruleSets: data["ruleSets"] !== undefined ? data["ruleSets"].map((item: any) => (serializeGoogleCloudContentwarehouseV1RuleSet(item))) : undefined,
  };
}

function deserializeGoogleCloudContentwarehouseV1ListRuleSetsResponse(data: any): GoogleCloudContentwarehouseV1ListRuleSetsResponse {
  return {
    ...data,
    ruleSets: data["ruleSets"] !== undefined ? data["ruleSets"].map((item: any) => (deserializeGoogleCloudContentwarehouseV1RuleSet(item))) : undefined,
  };
}

/**
 * Response message for SynonymSetService.ListSynonymSets.
 */
export interface GoogleCloudContentwarehouseV1ListSynonymSetsResponse {
  /**
   * A page token, received from a previous `ListSynonymSets` call. Provide
   * this to retrieve the subsequent page.
   */
  nextPageToken?: string;
  /**
   * The synonymSets from the specified parent.
   */
  synonymSets?: GoogleCloudContentwarehouseV1SynonymSet[];
}

/**
 * Map property value. Represents a structured entries of key value pairs,
 * consisting of field names which map to dynamically typed values.
 */
export interface GoogleCloudContentwarehouseV1MapProperty {
  /**
   * Unordered map of dynamically typed values.
   */
  fields?: {
    [key: string]: GoogleCloudContentwarehouseV1Value
  };
}

function serializeGoogleCloudContentwarehouseV1MapProperty(data: any): GoogleCloudContentwarehouseV1MapProperty {
  return {
    ...data,
    fields: data["fields"] !== undefined ? Object.fromEntries(Object.entries(data["fields"]).map(([k, v]: [string, any]) => ([k, serializeGoogleCloudContentwarehouseV1Value(v)]))) : undefined,
  };
}

function deserializeGoogleCloudContentwarehouseV1MapProperty(data: any): GoogleCloudContentwarehouseV1MapProperty {
  return {
    ...data,
    fields: data["fields"] !== undefined ? Object.fromEntries(Object.entries(data["fields"]).map(([k, v]: [string, any]) => ([k, deserializeGoogleCloudContentwarehouseV1Value(v)]))) : undefined,
  };
}

/**
 * Configurations for a Map property.
 */
export interface GoogleCloudContentwarehouseV1MapTypeOptions {
}

/**
 * Options for merging updated fields.
 */
export interface GoogleCloudContentwarehouseV1MergeFieldsOptions {
  /**
   * When merging message fields, the default behavior is to merge the content
   * of two message fields together. If you instead want to use the field from
   * the source message to replace the corresponding field in the destination
   * message, set this flag to true. When this flag is set, specified submessage
   * fields that are missing in source will be cleared in destination.
   */
  replaceMessageFields?: boolean;
  /**
   * When merging repeated fields, the default behavior is to append entries
   * from the source repeated field to the destination repeated field. If you
   * instead want to keep only the entries from the source repeated field, set
   * this flag to true. If you want to replace a repeated field within a message
   * field on the destination message, you must set both replace_repeated_fields
   * and replace_message_fields to true, otherwise the repeated fields will be
   * appended.
   */
  replaceRepeatedFields?: boolean;
}

/**
 * The DocAI processor information.
 */
export interface GoogleCloudContentwarehouseV1ProcessorInfo {
  /**
   * The processor will process the documents with this document type.
   */
  documentType?: string;
  /**
   * The processor resource name. Format is
   * `projects/{project}/locations/{location}/processors/{processor}`, or
   * `projects/{project}/locations/{location}/processors/{processor}/processorVersions/{processorVersion}`
   */
  processorName?: string;
  /**
   * The Document schema resource name. All documents processed by this
   * processor will use this schema. Format:
   * projects/{project_number}/locations/{location}/documentSchemas/{document_schema_id}.
   */
  schemaName?: string;
}

/**
 * The configuration of processing documents in Document Warehouse with DocAi
 * processors pipeline.
 */
export interface GoogleCloudContentwarehouseV1ProcessWithDocAi {
  /**
   * The list of all the resource names of the documents to be processed.
   * Format:
   * projects/{project_number}/locations/{location}/documents/{document_id}.
   */
  documents?: string[];
  /**
   * The Cloud Storage folder path used to store the exported documents before
   * being sent to CDW. Format: gs:///.
   */
  exportFolderPath?: string;
  /**
   * The CDW processor information.
   */
  processorInfo?: GoogleCloudContentwarehouseV1ProcessorInfo;
  /**
   * The Cloud Storage folder path used to store the raw results from
   * processors. Format: gs:///.
   */
  processorResultsFolderPath?: string;
}

/**
 * Property of a document.
 */
export interface GoogleCloudContentwarehouseV1Property {
  /**
   * Date time property values. It is not supported by CMEK compliant
   * deployment.
   */
  dateTimeValues?: GoogleCloudContentwarehouseV1DateTimeArray;
  /**
   * Enum property values.
   */
  enumValues?: GoogleCloudContentwarehouseV1EnumArray;
  /**
   * Float property values.
   */
  floatValues?: GoogleCloudContentwarehouseV1FloatArray;
  /**
   * Integer property values.
   */
  integerValues?: GoogleCloudContentwarehouseV1IntegerArray;
  /**
   * Map property values.
   */
  mapProperty?: GoogleCloudContentwarehouseV1MapProperty;
  /**
   * Required. Must match the name of a PropertyDefinition in the
   * DocumentSchema.
   */
  name?: string;
  /**
   * Nested structured data property values.
   */
  propertyValues?: GoogleCloudContentwarehouseV1PropertyArray;
  /**
   * String/text property values.
   */
  textValues?: GoogleCloudContentwarehouseV1TextArray;
  /**
   * Timestamp property values. It is not supported by CMEK compliant
   * deployment.
   */
  timestampValues?: GoogleCloudContentwarehouseV1TimestampArray;
}

function serializeGoogleCloudContentwarehouseV1Property(data: any): GoogleCloudContentwarehouseV1Property {
  return {
    ...data,
    dateTimeValues: data["dateTimeValues"] !== undefined ? serializeGoogleCloudContentwarehouseV1DateTimeArray(data["dateTimeValues"]) : undefined,
    mapProperty: data["mapProperty"] !== undefined ? serializeGoogleCloudContentwarehouseV1MapProperty(data["mapProperty"]) : undefined,
    propertyValues: data["propertyValues"] !== undefined ? serializeGoogleCloudContentwarehouseV1PropertyArray(data["propertyValues"]) : undefined,
    timestampValues: data["timestampValues"] !== undefined ? serializeGoogleCloudContentwarehouseV1TimestampArray(data["timestampValues"]) : undefined,
  };
}

function deserializeGoogleCloudContentwarehouseV1Property(data: any): GoogleCloudContentwarehouseV1Property {
  return {
    ...data,
    dateTimeValues: data["dateTimeValues"] !== undefined ? deserializeGoogleCloudContentwarehouseV1DateTimeArray(data["dateTimeValues"]) : undefined,
    mapProperty: data["mapProperty"] !== undefined ? deserializeGoogleCloudContentwarehouseV1MapProperty(data["mapProperty"]) : undefined,
    propertyValues: data["propertyValues"] !== undefined ? deserializeGoogleCloudContentwarehouseV1PropertyArray(data["propertyValues"]) : undefined,
    timestampValues: data["timestampValues"] !== undefined ? deserializeGoogleCloudContentwarehouseV1TimestampArray(data["timestampValues"]) : undefined,
  };
}

/**
 * Property values.
 */
export interface GoogleCloudContentwarehouseV1PropertyArray {
  /**
   * List of property values.
   */
  properties?: GoogleCloudContentwarehouseV1Property[];
}

function serializeGoogleCloudContentwarehouseV1PropertyArray(data: any): GoogleCloudContentwarehouseV1PropertyArray {
  return {
    ...data,
    properties: data["properties"] !== undefined ? data["properties"].map((item: any) => (serializeGoogleCloudContentwarehouseV1Property(item))) : undefined,
  };
}

function deserializeGoogleCloudContentwarehouseV1PropertyArray(data: any): GoogleCloudContentwarehouseV1PropertyArray {
  return {
    ...data,
    properties: data["properties"] !== undefined ? data["properties"].map((item: any) => (deserializeGoogleCloudContentwarehouseV1Property(item))) : undefined,
  };
}

/**
 * Defines the metadata for a schema property.
 */
export interface GoogleCloudContentwarehouseV1PropertyDefinition {
  /**
   * Date time property. It is not supported by CMEK compliant deployment.
   */
  dateTimeTypeOptions?: GoogleCloudContentwarehouseV1DateTimeTypeOptions;
  /**
   * The display-name for the property, used for front-end.
   */
  displayName?: string;
  /**
   * Enum/categorical property.
   */
  enumTypeOptions?: GoogleCloudContentwarehouseV1EnumTypeOptions;
  /**
   * Float property.
   */
  floatTypeOptions?: GoogleCloudContentwarehouseV1FloatTypeOptions;
  /**
   * Integer property.
   */
  integerTypeOptions?: GoogleCloudContentwarehouseV1IntegerTypeOptions;
  /**
   * Whether the property can be filtered. If this is a sub-property, all the
   * parent properties must be marked filterable.
   */
  isFilterable?: boolean;
  /**
   * Whether the property is user supplied metadata. This out-of-the box
   * placeholder setting can be used to tag derived properties. Its value and
   * interpretation logic should be implemented by API user.
   */
  isMetadata?: boolean;
  /**
   * Whether the property can have multiple values.
   */
  isRepeatable?: boolean;
  /**
   * Whether the property is mandatory. Default is 'false', i.e. populating
   * property value can be skipped. If 'true' then user must populate the value
   * for this property.
   */
  isRequired?: boolean;
  /**
   * Indicates that the property should be included in a global search.
   */
  isSearchable?: boolean;
  /**
   * Map property.
   */
  mapTypeOptions?: GoogleCloudContentwarehouseV1MapTypeOptions;
  /**
   * Required. The name of the metadata property. Must be unique within a
   * document schema and is case insensitive. Names must be non-blank, start
   * with a letter, and can contain alphanumeric characters and: /, :, -, _, and
   * .
   */
  name?: string;
  /**
   * Nested structured data property.
   */
  propertyTypeOptions?: GoogleCloudContentwarehouseV1PropertyTypeOptions;
  /**
   * The retrieval importance of the property during search.
   */
  retrievalImportance?:  | "RETRIEVAL_IMPORTANCE_UNSPECIFIED" | "HIGHEST" | "HIGHER" | "HIGH" | "MEDIUM" | "LOW" | "LOWEST";
  /**
   * The mapping information between this property to another schema source.
   */
  schemaSources?: GoogleCloudContentwarehouseV1PropertyDefinitionSchemaSource[];
  /**
   * Text/string property.
   */
  textTypeOptions?: GoogleCloudContentwarehouseV1TextTypeOptions;
  /**
   * Timestamp property. It is not supported by CMEK compliant deployment.
   */
  timestampTypeOptions?: GoogleCloudContentwarehouseV1TimestampTypeOptions;
}

/**
 * The schema source information.
 */
export interface GoogleCloudContentwarehouseV1PropertyDefinitionSchemaSource {
  /**
   * The schema name in the source.
   */
  name?: string;
  /**
   * The Doc AI processor type name.
   */
  processorType?: string;
}

export interface GoogleCloudContentwarehouseV1PropertyFilter {
  /**
   * The filter condition. The syntax for this expression is a subset of SQL
   * syntax. Supported operators are: `=`, `!=`, `<`, `<=`, `>`, `>=`, and `~~`
   * where the left of the operator is a property name and the right of the
   * operator is a number or a quoted string. You must escape backslash (\\) and
   * quote (\") characters. `~~` is the LIKE operator. The right of the operator
   * must be a string. The only supported property data type for LIKE is
   * text_values. It provides semantic search functionality by parsing, stemming
   * and doing synonyms expansion against the input query. It matches if the
   * property contains semantic similar content to the query. It is not regex
   * matching or wildcard matching. For example, "property.company ~~
   * \"google\"" will match records whose property `property.compnay` have
   * values like "Google Inc.", "Google LLC" or "Google Company". Supported
   * functions are `LOWER([property_name])` to perform a case insensitive match
   * and `EMPTY([property_name])` to filter on the existence of a key. Boolean
   * expressions (AND/OR/NOT) are supported up to 3 levels of nesting (for
   * example, "((A AND B AND C) OR NOT D) AND E"), a maximum of 100 comparisons
   * or functions are allowed in the expression. The expression must be < 6000
   * bytes in length. Only properties that are marked filterable are allowed
   * (PropertyDefinition.is_filterable). Property names do not need to be
   * prefixed by the document schema id (as is the case with histograms),
   * however property names will need to be prefixed by its parent hierarchy, if
   * any. For example: top_property_name.sub_property_name. Sample Query:
   * `(LOWER(driving_license)="class \"a\"" OR EMPTY(driving_license)) AND
   * driving_years > 10` CMEK compliant deployment only supports: * Operators:
   * `=`, `<`, `<=`, `>`, and `>=`. * Boolean expressions: AND and OR.
   */
  condition?: string;
  /**
   * The Document schema name Document.document_schema_name. Format:
   * projects/{project_number}/locations/{location}/documentSchemas/{document_schema_id}.
   */
  documentSchemaName?: string;
}

/**
 * Configurations for a nested structured data property.
 */
export interface GoogleCloudContentwarehouseV1PropertyTypeOptions {
  /**
   * Required. List of property definitions.
   */
  propertyDefinitions?: GoogleCloudContentwarehouseV1PropertyDefinition[];
}

/**
 * Represents the action responsible for publishing messages to a Pub/Sub
 * topic.
 */
export interface GoogleCloudContentwarehouseV1PublishAction {
  /**
   * Messages to be published.
   */
  messages?: string[];
  /**
   * The topic id in the Pub/Sub service for which messages will be published
   * to.
   */
  topicId?: string;
}

/**
 * Additional result info for the question-answering feature.
 */
export interface GoogleCloudContentwarehouseV1QAResult {
  /**
   * The calibrated confidence score for this document, in the range [0., 1.].
   * This represents the confidence level for whether the returned document and
   * snippet answers the user's query.
   */
  confidenceScore?: number;
  /**
   * Highlighted sections in the snippet.
   */
  highlights?: GoogleCloudContentwarehouseV1QAResultHighlight[];
}

/**
 * A text span in the search text snippet that represents a highlighted section
 * (answer context, highly relevant sentence, etc.).
 */
export interface GoogleCloudContentwarehouseV1QAResultHighlight {
  /**
   * End index of the highlight, exclusive.
   */
  endIndex?: number;
  /**
   * Start index of the highlight.
   */
  startIndex?: number;
}

/**
 * Represents the action responsible for remove a document from a specific
 * folder.
 */
export interface GoogleCloudContentwarehouseV1RemoveFromFolderAction {
  /**
   * Condition of the action to be executed.
   */
  condition?: string;
  /**
   * Name of the folder under which new document is to be added. Format:
   * projects/{project_number}/locations/{location}/documents/{document_id}.
   */
  folder?: string;
}

/**
 * Meta information is used to improve the performance of the service.
 */
export interface GoogleCloudContentwarehouseV1RequestMetadata {
  /**
   * Provides user unique identification and groups information.
   */
  userInfo?: GoogleCloudContentwarehouseV1UserInfo;
}

/**
 * Additional information returned to client, such as debugging information.
 */
export interface GoogleCloudContentwarehouseV1ResponseMetadata {
  /**
   * A unique id associated with this call. This id is logged for tracking
   * purpose.
   */
  requestId?: string;
}

/**
 * Represents the rule for a content warehouse trigger.
 */
export interface GoogleCloudContentwarehouseV1Rule {
  /**
   * List of actions that are executed when the rule is satisfied.
   */
  actions?: GoogleCloudContentwarehouseV1Action[];
  /**
   * Represents the conditional expression to be evaluated. Expression should
   * evaluate to a boolean result. When the condition is true actions are
   * executed. Example: user_role = "hsbc_role_1" AND doc.salary > 20000
   */
  condition?: string;
  /**
   * Short description of the rule and its context.
   */
  description?: string;
  /**
   * ID of the rule. It has to be unique across all the examples. This is
   * managed internally.
   */
  ruleId?: string;
  /**
   * Identifies the trigger type for running the policy.
   */
  triggerType?:  | "UNKNOWN" | "ON_CREATE" | "ON_UPDATE";
}

function serializeGoogleCloudContentwarehouseV1Rule(data: any): GoogleCloudContentwarehouseV1Rule {
  return {
    ...data,
    actions: data["actions"] !== undefined ? data["actions"].map((item: any) => (serializeGoogleCloudContentwarehouseV1Action(item))) : undefined,
  };
}

function deserializeGoogleCloudContentwarehouseV1Rule(data: any): GoogleCloudContentwarehouseV1Rule {
  return {
    ...data,
    actions: data["actions"] !== undefined ? data["actions"].map((item: any) => (deserializeGoogleCloudContentwarehouseV1Action(item))) : undefined,
  };
}

/**
 * Represents a rule and outputs of associated actions.
 */
export interface GoogleCloudContentwarehouseV1RuleActionsPair {
  /**
   * Outputs of executing the actions associated with the above rule.
   */
  actionOutputs?: GoogleCloudContentwarehouseV1ActionOutput[];
  /**
   * Represents the rule.
   */
  rule?: GoogleCloudContentwarehouseV1Rule;
}

function serializeGoogleCloudContentwarehouseV1RuleActionsPair(data: any): GoogleCloudContentwarehouseV1RuleActionsPair {
  return {
    ...data,
    rule: data["rule"] !== undefined ? serializeGoogleCloudContentwarehouseV1Rule(data["rule"]) : undefined,
  };
}

function deserializeGoogleCloudContentwarehouseV1RuleActionsPair(data: any): GoogleCloudContentwarehouseV1RuleActionsPair {
  return {
    ...data,
    rule: data["rule"] !== undefined ? deserializeGoogleCloudContentwarehouseV1Rule(data["rule"]) : undefined,
  };
}

/**
 * Records the output of Rule Engine including rule evaluation and actions
 * result.
 */
export interface GoogleCloudContentwarehouseV1RuleEngineOutput {
  /**
   * Output from Action Executor containing rule and corresponding actions
   * execution result.
   */
  actionExecutorOutput?: GoogleCloudContentwarehouseV1ActionExecutorOutput;
  /**
   * Name of the document against which the rules and actions were evaluated.
   */
  documentName?: string;
  /**
   * Output from Rule Evaluator containing matched, unmatched and invalid
   * rules.
   */
  ruleEvaluatorOutput?: GoogleCloudContentwarehouseV1RuleEvaluatorOutput;
}

function serializeGoogleCloudContentwarehouseV1RuleEngineOutput(data: any): GoogleCloudContentwarehouseV1RuleEngineOutput {
  return {
    ...data,
    actionExecutorOutput: data["actionExecutorOutput"] !== undefined ? serializeGoogleCloudContentwarehouseV1ActionExecutorOutput(data["actionExecutorOutput"]) : undefined,
    ruleEvaluatorOutput: data["ruleEvaluatorOutput"] !== undefined ? serializeGoogleCloudContentwarehouseV1RuleEvaluatorOutput(data["ruleEvaluatorOutput"]) : undefined,
  };
}

function deserializeGoogleCloudContentwarehouseV1RuleEngineOutput(data: any): GoogleCloudContentwarehouseV1RuleEngineOutput {
  return {
    ...data,
    actionExecutorOutput: data["actionExecutorOutput"] !== undefined ? deserializeGoogleCloudContentwarehouseV1ActionExecutorOutput(data["actionExecutorOutput"]) : undefined,
    ruleEvaluatorOutput: data["ruleEvaluatorOutput"] !== undefined ? deserializeGoogleCloudContentwarehouseV1RuleEvaluatorOutput(data["ruleEvaluatorOutput"]) : undefined,
  };
}

/**
 * Represents the output of the Rule Evaluator.
 */
export interface GoogleCloudContentwarehouseV1RuleEvaluatorOutput {
  /**
   * A subset of triggered rules that failed the validation check(s) after
   * parsing.
   */
  invalidRules?: GoogleCloudContentwarehouseV1InvalidRule[];
  /**
   * A subset of triggered rules that are evaluated true for a given request.
   */
  matchedRules?: GoogleCloudContentwarehouseV1Rule[];
  /**
   * List of rules fetched from database for the given request trigger type.
   */
  triggeredRules?: GoogleCloudContentwarehouseV1Rule[];
}

function serializeGoogleCloudContentwarehouseV1RuleEvaluatorOutput(data: any): GoogleCloudContentwarehouseV1RuleEvaluatorOutput {
  return {
    ...data,
    invalidRules: data["invalidRules"] !== undefined ? data["invalidRules"].map((item: any) => (serializeGoogleCloudContentwarehouseV1InvalidRule(item))) : undefined,
    matchedRules: data["matchedRules"] !== undefined ? data["matchedRules"].map((item: any) => (serializeGoogleCloudContentwarehouseV1Rule(item))) : undefined,
    triggeredRules: data["triggeredRules"] !== undefined ? data["triggeredRules"].map((item: any) => (serializeGoogleCloudContentwarehouseV1Rule(item))) : undefined,
  };
}

function deserializeGoogleCloudContentwarehouseV1RuleEvaluatorOutput(data: any): GoogleCloudContentwarehouseV1RuleEvaluatorOutput {
  return {
    ...data,
    invalidRules: data["invalidRules"] !== undefined ? data["invalidRules"].map((item: any) => (deserializeGoogleCloudContentwarehouseV1InvalidRule(item))) : undefined,
    matchedRules: data["matchedRules"] !== undefined ? data["matchedRules"].map((item: any) => (deserializeGoogleCloudContentwarehouseV1Rule(item))) : undefined,
    triggeredRules: data["triggeredRules"] !== undefined ? data["triggeredRules"].map((item: any) => (deserializeGoogleCloudContentwarehouseV1Rule(item))) : undefined,
  };
}

/**
 * Represents a set of rules from a single customer.
 */
export interface GoogleCloudContentwarehouseV1RuleSet {
  /**
   * Short description of the rule-set.
   */
  description?: string;
  /**
   * The resource name of the rule set. Managed internally. Format:
   * projects/{project_number}/locations/{location}/ruleSet/{rule_set_id}. The
   * name is ignored when creating a rule set.
   */
  name?: string;
  /**
   * List of rules given by the customer.
   */
  rules?: GoogleCloudContentwarehouseV1Rule[];
  /**
   * Source of the rules i.e., customer name.
   */
  source?: string;
}

function serializeGoogleCloudContentwarehouseV1RuleSet(data: any): GoogleCloudContentwarehouseV1RuleSet {
  return {
    ...data,
    rules: data["rules"] !== undefined ? data["rules"].map((item: any) => (serializeGoogleCloudContentwarehouseV1Rule(item))) : undefined,
  };
}

function deserializeGoogleCloudContentwarehouseV1RuleSet(data: any): GoogleCloudContentwarehouseV1RuleSet {
  return {
    ...data,
    rules: data["rules"] !== undefined ? data["rules"].map((item: any) => (deserializeGoogleCloudContentwarehouseV1Rule(item))) : undefined,
  };
}

/**
 * Request message for DocumentService.RunPipeline.
 */
export interface GoogleCloudContentwarehouseV1RunPipelineRequest {
  /**
   * Export docuemnts from Document Warehouse to CDW for training purpose.
   */
  exportCdwPipeline?: GoogleCloudContentwarehouseV1ExportToCdwPipeline;
  /**
   * Cloud Storage ingestion pipeline.
   */
  gcsIngestPipeline?: GoogleCloudContentwarehouseV1GcsIngestPipeline;
  /**
   * Use DocAI processors to process documents in Cloud Storage and ingest them
   * to Document Warehouse.
   */
  gcsIngestWithDocAiProcessorsPipeline?: GoogleCloudContentwarehouseV1GcsIngestWithDocAiProcessorsPipeline;
  /**
   * Use a DocAI processor to process documents in Document Warehouse, and
   * re-ingest the updated results into Document Warehouse.
   */
  processWithDocAiPipeline?: GoogleCloudContentwarehouseV1ProcessWithDocAi;
  /**
   * The meta information collected about the end user, used to enforce access
   * control for the service.
   */
  requestMetadata?: GoogleCloudContentwarehouseV1RequestMetadata;
}

/**
 * Request message for DocumentService.SearchDocuments.
 */
export interface GoogleCloudContentwarehouseV1SearchDocumentsRequest {
  /**
   * Query used to search against documents (keyword, filters, etc.).
   */
  documentQuery?: GoogleCloudContentwarehouseV1DocumentQuery;
  /**
   * An expression specifying a histogram request against matching documents.
   * Expression syntax is an aggregation function call with histogram facets and
   * other options. The following aggregation functions are supported: *
   * `count(string_histogram_facet)`: Count the number of matching entities for
   * each distinct attribute value. Data types: * Histogram facet (aka
   * filterable properties): Facet names with format <schema id>.<facet>. Facets
   * will have the format of: `a-zA-Z`. If the facet is a child facet, then the
   * parent hierarchy needs to be specified separated by dots in the prefix
   * after the schema id. Thus, the format for a multi- level facet is: <schema
   * id>.<parent facet name>. <child facet name>. Example:
   * schema123.root_parent_facet.middle_facet.child_facet * DocumentSchemaId:
   * (with no schema id prefix) to get histograms for each document type
   * (returns the schema id path, e.g.
   * projects/12345/locations/us-west/documentSchemas/abc123). Example
   * expression: * Document type counts: count('DocumentSchemaId') * For schema
   * id, abc123, get the counts for MORTGAGE_TYPE: count('abc123.MORTGAGE_TYPE')
   */
  histogramQueries?: GoogleCloudContentwarehouseV1HistogramQuery[];
  /**
   * An integer that specifies the current offset (that is, starting result
   * location, amongst the documents deemed by the API as relevant) in search
   * results. This field is only considered if page_token is unset. The maximum
   * allowed value is 5000. Otherwise an error is thrown. For example, 0 means
   * to return results starting from the first matching document, and 10 means
   * to return from the 11th document. This can be used for pagination, (for
   * example, pageSize = 10 and offset = 10 means to return from the second
   * page).
   */
  offset?: number;
  /**
   * The criteria determining how search results are sorted. For non-empty
   * query, default is `"relevance desc"`. For empty query, default is
   * `"upload_date desc"`. Supported options are: * `"relevance desc"`: By
   * relevance descending, as determined by the API algorithms. * `"upload_date
   * desc"`: By upload date descending. * `"upload_date"`: By upload date
   * ascending. * `"update_date desc"`: By last updated date descending. *
   * `"update_date"`: By last updated date ascending. * `"retrieval_importance
   * desc"`: By retrieval importance of properties descending. This feature is
   * still under development, please do not use unless otherwise instructed to
   * do so.
   */
  orderBy?: string;
  /**
   * A limit on the number of documents returned in the search results.
   * Increasing this value above the default value of 10 can increase search
   * response time. The value can be between 1 and 100.
   */
  pageSize?: number;
  /**
   * The token specifying the current offset within search results. See
   * SearchDocumentsResponse.next_page_token for an explanation of how to obtain
   * the next set of query results.
   */
  pageToken?: string;
  /**
   * Experimental, do not use. The limit on the number of documents returned
   * for the question-answering feature. To enable the question-answering
   * feature, set [DocumentQuery].is_nl_query to true.
   */
  qaSizeLimit?: number;
  /**
   * The meta information collected about the end user, used to enforce access
   * control and improve the search quality of the service.
   */
  requestMetadata?: GoogleCloudContentwarehouseV1RequestMetadata;
  /**
   * Controls if the search document request requires the return of a total
   * size of matched documents. See SearchDocumentsResponse.total_size. Enabling
   * this flag may adversely impact performance. Hint: If this is used with
   * pagination, set this flag on the initial query but set this to false on
   * subsequent page calls (keep the total count locally). Defaults to false.
   */
  requireTotalSize?: boolean;
  /**
   * Controls if the search document request requires the return of a total
   * size of matched documents. See SearchDocumentsResponse.total_size.
   */
  totalResultSize?:  | "TOTAL_RESULT_SIZE_UNSPECIFIED" | "ESTIMATED_SIZE" | "ACTUAL_SIZE";
}

function serializeGoogleCloudContentwarehouseV1SearchDocumentsRequest(data: any): GoogleCloudContentwarehouseV1SearchDocumentsRequest {
  return {
    ...data,
    documentQuery: data["documentQuery"] !== undefined ? serializeGoogleCloudContentwarehouseV1DocumentQuery(data["documentQuery"]) : undefined,
  };
}

function deserializeGoogleCloudContentwarehouseV1SearchDocumentsRequest(data: any): GoogleCloudContentwarehouseV1SearchDocumentsRequest {
  return {
    ...data,
    documentQuery: data["documentQuery"] !== undefined ? deserializeGoogleCloudContentwarehouseV1DocumentQuery(data["documentQuery"]) : undefined,
  };
}

/**
 * Response message for DocumentService.SearchDocuments.
 */
export interface GoogleCloudContentwarehouseV1SearchDocumentsResponse {
  /**
   * The histogram results that match with the specified
   * SearchDocumentsRequest.histogram_queries.
   */
  histogramQueryResults?: GoogleCloudContentwarehouseV1HistogramQueryResult[];
  /**
   * The document entities that match the specified SearchDocumentsRequest.
   */
  matchingDocuments?: GoogleCloudContentwarehouseV1SearchDocumentsResponseMatchingDocument[];
  /**
   * Additional information for the API invocation, such as the request
   * tracking id.
   */
  metadata?: GoogleCloudContentwarehouseV1ResponseMetadata;
  /**
   * The token that specifies the starting position of the next page of
   * results. This field is empty if there are no more results.
   */
  nextPageToken?: string;
  /**
   * The total number of matched documents which is available only if the
   * client set SearchDocumentsRequest.require_total_size to `true` or set
   * SearchDocumentsRequest.total_result_size to `ESTIMATED_SIZE` or
   * `ACTUAL_SIZE`. Otherwise, the value will be `-1`. Typically a UI would
   * handle this condition by displaying "of many", for example: "Displaying 10
   * of many".
   */
  totalSize?: number;
}

function serializeGoogleCloudContentwarehouseV1SearchDocumentsResponse(data: any): GoogleCloudContentwarehouseV1SearchDocumentsResponse {
  return {
    ...data,
    histogramQueryResults: data["histogramQueryResults"] !== undefined ? data["histogramQueryResults"].map((item: any) => (serializeGoogleCloudContentwarehouseV1HistogramQueryResult(item))) : undefined,
    matchingDocuments: data["matchingDocuments"] !== undefined ? data["matchingDocuments"].map((item: any) => (serializeGoogleCloudContentwarehouseV1SearchDocumentsResponseMatchingDocument(item))) : undefined,
  };
}

function deserializeGoogleCloudContentwarehouseV1SearchDocumentsResponse(data: any): GoogleCloudContentwarehouseV1SearchDocumentsResponse {
  return {
    ...data,
    histogramQueryResults: data["histogramQueryResults"] !== undefined ? data["histogramQueryResults"].map((item: any) => (deserializeGoogleCloudContentwarehouseV1HistogramQueryResult(item))) : undefined,
    matchingDocuments: data["matchingDocuments"] !== undefined ? data["matchingDocuments"].map((item: any) => (deserializeGoogleCloudContentwarehouseV1SearchDocumentsResponseMatchingDocument(item))) : undefined,
  };
}

/**
 * Document entry with metadata inside SearchDocumentsResponse
 */
export interface GoogleCloudContentwarehouseV1SearchDocumentsResponseMatchingDocument {
  /**
   * Document that matches the specified SearchDocumentsRequest. This document
   * only contains indexed metadata information.
   */
  document?: GoogleCloudContentwarehouseV1Document;
  /**
   * Experimental. Additional result info if the question-answering feature is
   * enabled.
   */
  qaResult?: GoogleCloudContentwarehouseV1QAResult;
  /**
   * Contains snippets of text from the document full raw text that most
   * closely match a search query's keywords, if available. All HTML tags in the
   * original fields are stripped when returned in this field, and matching
   * query keywords are enclosed in HTML bold tags. If the question-answering
   * feature is enabled, this field will instead contain a snippet that answers
   * the user's natural-language query. No HTML bold tags will be present, and
   * highlights in the answer snippet can be found in QAResult.highlights.
   */
  searchTextSnippet?: string;
}

function serializeGoogleCloudContentwarehouseV1SearchDocumentsResponseMatchingDocument(data: any): GoogleCloudContentwarehouseV1SearchDocumentsResponseMatchingDocument {
  return {
    ...data,
    document: data["document"] !== undefined ? serializeGoogleCloudContentwarehouseV1Document(data["document"]) : undefined,
  };
}

function deserializeGoogleCloudContentwarehouseV1SearchDocumentsResponseMatchingDocument(data: any): GoogleCloudContentwarehouseV1SearchDocumentsResponseMatchingDocument {
  return {
    ...data,
    document: data["document"] !== undefined ? deserializeGoogleCloudContentwarehouseV1Document(data["document"]) : undefined,
  };
}

/**
 * Request message for DocumentService.SetAcl.
 */
export interface GoogleCloudContentwarehouseV1SetAclRequest {
  /**
   * Required. REQUIRED: The complete policy to be applied to the `resource`.
   * The size of the policy is limited to a few 10s of KB. This refers to an
   * Identity and Access (IAM) policy, which specifies access controls for the
   * Document. You can set ACL with condition for projects only. Supported
   * operators are: `=`, `!=`, `<`, `<=`, `>`, and `>=` where the left of the
   * operator is `DocumentSchemaId` or property name and the right of the
   * operator is a number or a quoted string. You must escape backslash (\\) and
   * quote (\") characters. Boolean expressions (AND/OR) are supported up to 3
   * levels of nesting (for example, "((A AND B AND C) OR D) AND E"), a maximum
   * of 10 comparisons are allowed in the expression. The expression must be <
   * 6000 bytes in length. Sample condition: `"DocumentSchemaId = \"some schema
   * id\" OR SchemaId.floatPropertyName >= 10"`
   */
  policy?: GoogleIamV1Policy;
  /**
   * For Set Project ACL only. Authorization check for end user will be ignored
   * when project_owner=true.
   */
  projectOwner?: boolean;
  /**
   * The meta information collected about the end user, used to enforce access
   * control for the service.
   */
  requestMetadata?: GoogleCloudContentwarehouseV1RequestMetadata;
}

function serializeGoogleCloudContentwarehouseV1SetAclRequest(data: any): GoogleCloudContentwarehouseV1SetAclRequest {
  return {
    ...data,
    policy: data["policy"] !== undefined ? serializeGoogleIamV1Policy(data["policy"]) : undefined,
  };
}

function deserializeGoogleCloudContentwarehouseV1SetAclRequest(data: any): GoogleCloudContentwarehouseV1SetAclRequest {
  return {
    ...data,
    policy: data["policy"] !== undefined ? deserializeGoogleIamV1Policy(data["policy"]) : undefined,
  };
}

/**
 * Response message for DocumentService.SetAcl.
 */
export interface GoogleCloudContentwarehouseV1SetAclResponse {
  /**
   * Additional information for the API invocation, such as the request
   * tracking id.
   */
  metadata?: GoogleCloudContentwarehouseV1ResponseMetadata;
  /**
   * The policy will be attached to a resource (e.g. projecct, document).
   */
  policy?: GoogleIamV1Policy;
}

function serializeGoogleCloudContentwarehouseV1SetAclResponse(data: any): GoogleCloudContentwarehouseV1SetAclResponse {
  return {
    ...data,
    policy: data["policy"] !== undefined ? serializeGoogleIamV1Policy(data["policy"]) : undefined,
  };
}

function deserializeGoogleCloudContentwarehouseV1SetAclResponse(data: any): GoogleCloudContentwarehouseV1SetAclResponse {
  return {
    ...data,
    policy: data["policy"] !== undefined ? deserializeGoogleIamV1Policy(data["policy"]) : undefined,
  };
}

/**
 * Represents a list of synonyms for a given context. For example a context
 * "sales" could contain: Synonym 1: sale, invoice, bill, order Synonym 2:
 * money, credit, finance, payment Synonym 3: shipping, freight, transport Each
 * SynonymSets should be disjoint
 */
export interface GoogleCloudContentwarehouseV1SynonymSet {
  /**
   * This is a freeform field. Example contexts can be "sales," "engineering,"
   * "real estate," "accounting," etc. The context can be supplied during search
   * requests.
   */
  context?: string;
  /**
   * The resource name of the SynonymSet This is mandatory for
   * google.api.resource. Format:
   * projects/{project_number}/locations/{location}/synonymSets/{context}.
   */
  name?: string;
  /**
   * List of Synonyms for the context.
   */
  synonyms?: GoogleCloudContentwarehouseV1SynonymSetSynonym[];
}

/**
 * Represents a list of words given by the customer All these words are
 * synonyms of each other.
 */
export interface GoogleCloudContentwarehouseV1SynonymSetSynonym {
  /**
   * For example: sale, invoice, bill, order
   */
  words?: string[];
}

/**
 * String/text values.
 */
export interface GoogleCloudContentwarehouseV1TextArray {
  /**
   * List of text values.
   */
  values?: string[];
}

/**
 * Configurations for a text property.
 */
export interface GoogleCloudContentwarehouseV1TextTypeOptions {
}

/**
 * Filter on create timestamp or update timestamp of documents.
 */
export interface GoogleCloudContentwarehouseV1TimeFilter {
  /**
   * Specifies which time field to filter documents on. Defaults to
   * TimeField.UPLOAD_TIME.
   */
  timeField?:  | "TIME_FIELD_UNSPECIFIED" | "CREATE_TIME" | "UPDATE_TIME";
  timeRange?: GoogleTypeInterval;
}

function serializeGoogleCloudContentwarehouseV1TimeFilter(data: any): GoogleCloudContentwarehouseV1TimeFilter {
  return {
    ...data,
    timeRange: data["timeRange"] !== undefined ? serializeGoogleTypeInterval(data["timeRange"]) : undefined,
  };
}

function deserializeGoogleCloudContentwarehouseV1TimeFilter(data: any): GoogleCloudContentwarehouseV1TimeFilter {
  return {
    ...data,
    timeRange: data["timeRange"] !== undefined ? deserializeGoogleTypeInterval(data["timeRange"]) : undefined,
  };
}

/**
 * Timestamp values.
 */
export interface GoogleCloudContentwarehouseV1TimestampArray {
  /**
   * List of timestamp values.
   */
  values?: GoogleCloudContentwarehouseV1TimestampValue[];
}

function serializeGoogleCloudContentwarehouseV1TimestampArray(data: any): GoogleCloudContentwarehouseV1TimestampArray {
  return {
    ...data,
    values: data["values"] !== undefined ? data["values"].map((item: any) => (serializeGoogleCloudContentwarehouseV1TimestampValue(item))) : undefined,
  };
}

function deserializeGoogleCloudContentwarehouseV1TimestampArray(data: any): GoogleCloudContentwarehouseV1TimestampArray {
  return {
    ...data,
    values: data["values"] !== undefined ? data["values"].map((item: any) => (deserializeGoogleCloudContentwarehouseV1TimestampValue(item))) : undefined,
  };
}

/**
 * Configurations for a timestamp property.
 */
export interface GoogleCloudContentwarehouseV1TimestampTypeOptions {
}

/**
 * Timestamp value type.
 */
export interface GoogleCloudContentwarehouseV1TimestampValue {
  /**
   * The string must represent a valid instant in UTC and is parsed using
   * java.time.format.DateTimeFormatter.ISO_INSTANT. e.g. "2013-09-29T18:46:19Z"
   */
  textValue?: string;
  /**
   * Timestamp value
   */
  timestampValue?: Date;
}

function serializeGoogleCloudContentwarehouseV1TimestampValue(data: any): GoogleCloudContentwarehouseV1TimestampValue {
  return {
    ...data,
    timestampValue: data["timestampValue"] !== undefined ? data["timestampValue"].toISOString() : undefined,
  };
}

function deserializeGoogleCloudContentwarehouseV1TimestampValue(data: any): GoogleCloudContentwarehouseV1TimestampValue {
  return {
    ...data,
    timestampValue: data["timestampValue"] !== undefined ? new Date(data["timestampValue"]) : undefined,
  };
}

/**
 * Metadata object for UpdateDocument request (currently empty).
 */
export interface GoogleCloudContentwarehouseV1UpdateDocumentMetadata {
}

/**
 * Request message for DocumentService.UpdateDocument.
 */
export interface GoogleCloudContentwarehouseV1UpdateDocumentRequest {
  /**
   * Request Option for processing Cloud AI Document in Document Warehouse.
   * This field offers limited support for mapping entities from Cloud AI
   * Document to Warehouse Document. Please consult with product team before
   * using this field and other available options.
   */
  cloudAiDocumentOption?: GoogleCloudContentwarehouseV1CloudAIDocumentOption;
  /**
   * Required. The document to update.
   */
  document?: GoogleCloudContentwarehouseV1Document;
  /**
   * The meta information collected about the end user, used to enforce access
   * control for the service.
   */
  requestMetadata?: GoogleCloudContentwarehouseV1RequestMetadata;
  /**
   * Options for the update operation.
   */
  updateOptions?: GoogleCloudContentwarehouseV1UpdateOptions;
}

function serializeGoogleCloudContentwarehouseV1UpdateDocumentRequest(data: any): GoogleCloudContentwarehouseV1UpdateDocumentRequest {
  return {
    ...data,
    document: data["document"] !== undefined ? serializeGoogleCloudContentwarehouseV1Document(data["document"]) : undefined,
    updateOptions: data["updateOptions"] !== undefined ? serializeGoogleCloudContentwarehouseV1UpdateOptions(data["updateOptions"]) : undefined,
  };
}

function deserializeGoogleCloudContentwarehouseV1UpdateDocumentRequest(data: any): GoogleCloudContentwarehouseV1UpdateDocumentRequest {
  return {
    ...data,
    document: data["document"] !== undefined ? deserializeGoogleCloudContentwarehouseV1Document(data["document"]) : undefined,
    updateOptions: data["updateOptions"] !== undefined ? deserializeGoogleCloudContentwarehouseV1UpdateOptions(data["updateOptions"]) : undefined,
  };
}

/**
 * Response message for DocumentService.UpdateDocument.
 */
export interface GoogleCloudContentwarehouseV1UpdateDocumentResponse {
  /**
   * Updated document after executing update request.
   */
  document?: GoogleCloudContentwarehouseV1Document;
  /**
   * Additional information for the API invocation, such as the request
   * tracking id.
   */
  metadata?: GoogleCloudContentwarehouseV1ResponseMetadata;
  /**
   * Output from Rule Engine recording the rule evaluator and action executor's
   * output. Refer format in: google/cloud/contentwarehouse/v1/rule_engine.proto
   */
  ruleEngineOutput?: GoogleCloudContentwarehouseV1RuleEngineOutput;
}

function serializeGoogleCloudContentwarehouseV1UpdateDocumentResponse(data: any): GoogleCloudContentwarehouseV1UpdateDocumentResponse {
  return {
    ...data,
    document: data["document"] !== undefined ? serializeGoogleCloudContentwarehouseV1Document(data["document"]) : undefined,
    ruleEngineOutput: data["ruleEngineOutput"] !== undefined ? serializeGoogleCloudContentwarehouseV1RuleEngineOutput(data["ruleEngineOutput"]) : undefined,
  };
}

function deserializeGoogleCloudContentwarehouseV1UpdateDocumentResponse(data: any): GoogleCloudContentwarehouseV1UpdateDocumentResponse {
  return {
    ...data,
    document: data["document"] !== undefined ? deserializeGoogleCloudContentwarehouseV1Document(data["document"]) : undefined,
    ruleEngineOutput: data["ruleEngineOutput"] !== undefined ? deserializeGoogleCloudContentwarehouseV1RuleEngineOutput(data["ruleEngineOutput"]) : undefined,
  };
}

/**
 * Request message for DocumentSchemaService.UpdateDocumentSchema.
 */
export interface GoogleCloudContentwarehouseV1UpdateDocumentSchemaRequest {
  /**
   * Required. The document schema to update with.
   */
  documentSchema?: GoogleCloudContentwarehouseV1DocumentSchema;
}

/**
 * Options for Update operations.
 */
export interface GoogleCloudContentwarehouseV1UpdateOptions {
  /**
   * Options for merging.
   */
  mergeFieldsOptions?: GoogleCloudContentwarehouseV1MergeFieldsOptions;
  /**
   * Field mask for merging Document fields. For the `FieldMask` definition,
   * see
   * https://developers.google.com/protocol-buffers/docs/reference/google.protobuf#fieldmask
   */
  updateMask?: string /* FieldMask */;
  /**
   * Type for update.
   */
  updateType?:  | "UPDATE_TYPE_UNSPECIFIED" | "UPDATE_TYPE_REPLACE" | "UPDATE_TYPE_MERGE" | "UPDATE_TYPE_INSERT_PROPERTIES_BY_NAMES" | "UPDATE_TYPE_REPLACE_PROPERTIES_BY_NAMES" | "UPDATE_TYPE_DELETE_PROPERTIES_BY_NAMES" | "UPDATE_TYPE_REPLACE_OR_INSERT_PROPERTIES_BY_NAMES";
}

function serializeGoogleCloudContentwarehouseV1UpdateOptions(data: any): GoogleCloudContentwarehouseV1UpdateOptions {
  return {
    ...data,
    updateMask: data["updateMask"] !== undefined ? data["updateMask"] : undefined,
  };
}

function deserializeGoogleCloudContentwarehouseV1UpdateOptions(data: any): GoogleCloudContentwarehouseV1UpdateOptions {
  return {
    ...data,
    updateMask: data["updateMask"] !== undefined ? data["updateMask"] : undefined,
  };
}

/**
 * Request message for RuleSetService.UpdateRuleSet.
 */
export interface GoogleCloudContentwarehouseV1UpdateRuleSetRequest {
  /**
   * Required. The rule set to update.
   */
  ruleSet?: GoogleCloudContentwarehouseV1RuleSet;
}

function serializeGoogleCloudContentwarehouseV1UpdateRuleSetRequest(data: any): GoogleCloudContentwarehouseV1UpdateRuleSetRequest {
  return {
    ...data,
    ruleSet: data["ruleSet"] !== undefined ? serializeGoogleCloudContentwarehouseV1RuleSet(data["ruleSet"]) : undefined,
  };
}

function deserializeGoogleCloudContentwarehouseV1UpdateRuleSetRequest(data: any): GoogleCloudContentwarehouseV1UpdateRuleSetRequest {
  return {
    ...data,
    ruleSet: data["ruleSet"] !== undefined ? deserializeGoogleCloudContentwarehouseV1RuleSet(data["ruleSet"]) : undefined,
  };
}

/**
 * The user information.
 */
export interface GoogleCloudContentwarehouseV1UserInfo {
  /**
   * The unique group identifications which the user is belong to. The format
   * is "group:yyyy@example.com";
   */
  groupIds?: string[];
  /**
   * A unique user identification string, as determined by the client. The
   * maximum number of allowed characters is 255. Allowed characters include
   * numbers 0 to 9, uppercase and lowercase letters, and restricted special
   * symbols (:, @, +, -, _, ~) The format is "user:xxxx@example.com";
   */
  id?: string;
}

/**
 * `Value` represents a dynamically typed value which can be either be a float,
 * a integer, a string, or a datetime value. A producer of value is expected to
 * set one of these variants. Absence of any variant indicates an error.
 */
export interface GoogleCloudContentwarehouseV1Value {
  /**
   * Represents a boolean value.
   */
  booleanValue?: boolean;
  /**
   * Represents a datetime value.
   */
  datetimeValue?: GoogleTypeDateTime;
  /**
   * Represents an enum value.
   */
  enumValue?: GoogleCloudContentwarehouseV1EnumValue;
  /**
   * Represents a float value.
   */
  floatValue?: number;
  /**
   * Represents a integer value.
   */
  intValue?: number;
  /**
   * Represents a string value.
   */
  stringValue?: string;
  /**
   * Represents a timestamp value.
   */
  timestampValue?: GoogleCloudContentwarehouseV1TimestampValue;
}

function serializeGoogleCloudContentwarehouseV1Value(data: any): GoogleCloudContentwarehouseV1Value {
  return {
    ...data,
    datetimeValue: data["datetimeValue"] !== undefined ? serializeGoogleTypeDateTime(data["datetimeValue"]) : undefined,
    timestampValue: data["timestampValue"] !== undefined ? serializeGoogleCloudContentwarehouseV1TimestampValue(data["timestampValue"]) : undefined,
  };
}

function deserializeGoogleCloudContentwarehouseV1Value(data: any): GoogleCloudContentwarehouseV1Value {
  return {
    ...data,
    datetimeValue: data["datetimeValue"] !== undefined ? deserializeGoogleTypeDateTime(data["datetimeValue"]) : undefined,
    timestampValue: data["timestampValue"] !== undefined ? deserializeGoogleCloudContentwarehouseV1TimestampValue(data["timestampValue"]) : undefined,
  };
}

/**
 * Specifies the schema property name.
 */
export interface GoogleCloudContentwarehouseV1WeightedSchemaProperty {
  /**
   * The document schema name.
   */
  documentSchemaName?: string;
  /**
   * The property definition names in the schema.
   */
  propertyNames?: string[];
}

/**
 * Encodes the detailed information of a barcode.
 */
export interface GoogleCloudDocumentaiV1Barcode {
  /**
   * Format of a barcode. The supported formats are: - `CODE_128`: Code 128
   * type. - `CODE_39`: Code 39 type. - `CODE_93`: Code 93 type. - `CODABAR`:
   * Codabar type. - `DATA_MATRIX`: 2D Data Matrix type. - `ITF`: ITF type. -
   * `EAN_13`: EAN-13 type. - `EAN_8`: EAN-8 type. - `QR_CODE`: 2D QR code type.
   * - `UPC_A`: UPC-A type. - `UPC_E`: UPC-E type. - `PDF417`: PDF417 type. -
   * `AZTEC`: 2D Aztec code type. - `DATABAR`: GS1 DataBar code type.
   */
  format?: string;
  /**
   * Raw value encoded in the barcode. For example:
   * `'MEBKM:TITLE:Google;URL:https://www.google.com;;'`.
   */
  rawValue?: string;
  /**
   * Value format describes the format of the value that a barcode encodes. The
   * supported formats are: - `CONTACT_INFO`: Contact information. - `EMAIL`:
   * Email address. - `ISBN`: ISBN identifier. - `PHONE`: Phone number. -
   * `PRODUCT`: Product. - `SMS`: SMS message. - `TEXT`: Text string. - `URL`:
   * URL address. - `WIFI`: Wifi information. - `GEO`: Geo-localization. -
   * `CALENDAR_EVENT`: Calendar event. - `DRIVER_LICENSE`: Driver's license.
   */
  valueFormat?: string;
}

/**
 * A bounding polygon for the detected image annotation.
 */
export interface GoogleCloudDocumentaiV1BoundingPoly {
  /**
   * The bounding polygon normalized vertices.
   */
  normalizedVertices?: GoogleCloudDocumentaiV1NormalizedVertex[];
  /**
   * The bounding polygon vertices.
   */
  vertices?: GoogleCloudDocumentaiV1Vertex[];
}

/**
 * Document represents the canonical document resource in Document AI. It is an
 * interchange format that provides insights into documents and allows for
 * collaboration between users and Document AI to iterate and optimize for
 * quality.
 */
export interface GoogleCloudDocumentaiV1Document {
  /**
   * Optional. Inline document content, represented as a stream of bytes. Note:
   * As with all `bytes` fields, protobuffers use a pure binary representation,
   * whereas JSON representations use base64.
   */
  content?: Uint8Array;
  /**
   * A list of entities detected on Document.text. For document shards,
   * entities in this list may cross shard boundaries.
   */
  entities?: GoogleCloudDocumentaiV1DocumentEntity[];
  /**
   * Placeholder. Relationship among Document.entities.
   */
  entityRelations?: GoogleCloudDocumentaiV1DocumentEntityRelation[];
  /**
   * Any error that occurred while processing this document.
   */
  error?: GoogleRpcStatus;
  /**
   * An IANA published MIME type (also referred to as media type). For more
   * information, see
   * https://www.iana.org/assignments/media-types/media-types.xhtml.
   */
  mimeType?: string;
  /**
   * Visual page layout for the Document.
   */
  pages?: GoogleCloudDocumentaiV1DocumentPage[];
  /**
   * Placeholder. Revision history of this document.
   */
  revisions?: GoogleCloudDocumentaiV1DocumentRevision[];
  /**
   * Information about the sharding if this document is sharded part of a
   * larger document. If the document is not sharded, this message is not
   * specified.
   */
  shardInfo?: GoogleCloudDocumentaiV1DocumentShardInfo;
  /**
   * Optional. UTF-8 encoded text in reading order from the document.
   */
  text?: string;
  /**
   * Placeholder. A list of text corrections made to Document.text. This is
   * usually used for annotating corrections to OCR mistakes. Text changes for a
   * given revision may not overlap with each other.
   */
  textChanges?: GoogleCloudDocumentaiV1DocumentTextChange[];
  /**
   * Styles for the Document.text.
   */
  textStyles?: GoogleCloudDocumentaiV1DocumentStyle[];
  /**
   * Optional. Currently supports Google Cloud Storage URI of the form
   * `gs://bucket_name/object_name`. Object versioning is not supported. See
   * [Google Cloud Storage Request
   * URIs](https://cloud.google.com/storage/docs/reference-uris) for more info.
   */
  uri?: string;
}

function serializeGoogleCloudDocumentaiV1Document(data: any): GoogleCloudDocumentaiV1Document {
  return {
    ...data,
    content: data["content"] !== undefined ? encodeBase64(data["content"]) : undefined,
    entities: data["entities"] !== undefined ? data["entities"].map((item: any) => (serializeGoogleCloudDocumentaiV1DocumentEntity(item))) : undefined,
    pages: data["pages"] !== undefined ? data["pages"].map((item: any) => (serializeGoogleCloudDocumentaiV1DocumentPage(item))) : undefined,
    revisions: data["revisions"] !== undefined ? data["revisions"].map((item: any) => (serializeGoogleCloudDocumentaiV1DocumentRevision(item))) : undefined,
    shardInfo: data["shardInfo"] !== undefined ? serializeGoogleCloudDocumentaiV1DocumentShardInfo(data["shardInfo"]) : undefined,
    textChanges: data["textChanges"] !== undefined ? data["textChanges"].map((item: any) => (serializeGoogleCloudDocumentaiV1DocumentTextChange(item))) : undefined,
    textStyles: data["textStyles"] !== undefined ? data["textStyles"].map((item: any) => (serializeGoogleCloudDocumentaiV1DocumentStyle(item))) : undefined,
  };
}

function deserializeGoogleCloudDocumentaiV1Document(data: any): GoogleCloudDocumentaiV1Document {
  return {
    ...data,
    content: data["content"] !== undefined ? decodeBase64(data["content"] as string) : undefined,
    entities: data["entities"] !== undefined ? data["entities"].map((item: any) => (deserializeGoogleCloudDocumentaiV1DocumentEntity(item))) : undefined,
    pages: data["pages"] !== undefined ? data["pages"].map((item: any) => (deserializeGoogleCloudDocumentaiV1DocumentPage(item))) : undefined,
    revisions: data["revisions"] !== undefined ? data["revisions"].map((item: any) => (deserializeGoogleCloudDocumentaiV1DocumentRevision(item))) : undefined,
    shardInfo: data["shardInfo"] !== undefined ? deserializeGoogleCloudDocumentaiV1DocumentShardInfo(data["shardInfo"]) : undefined,
    textChanges: data["textChanges"] !== undefined ? data["textChanges"].map((item: any) => (deserializeGoogleCloudDocumentaiV1DocumentTextChange(item))) : undefined,
    textStyles: data["textStyles"] !== undefined ? data["textStyles"].map((item: any) => (deserializeGoogleCloudDocumentaiV1DocumentStyle(item))) : undefined,
  };
}

/**
 * An entity that could be a phrase in the text or a property that belongs to
 * the document. It is a known entity type, such as a person, an organization,
 * or location.
 */
export interface GoogleCloudDocumentaiV1DocumentEntity {
  /**
   * Optional. Confidence of detected Schema entity. Range `[0, 1]`.
   */
  confidence?: number;
  /**
   * Optional. Canonical id. This will be a unique value in the entity list for
   * this document.
   */
  id?: string;
  /**
   * Optional. Deprecated. Use `id` field instead.
   */
  mentionId?: string;
  /**
   * Optional. Text value of the entity e.g. `1600 Amphitheatre Pkwy`.
   */
  mentionText?: string;
  /**
   * Optional. Normalized entity value. Absent if the extracted value could not
   * be converted or the type (e.g. address) is not supported for certain
   * parsers. This field is also only populated for certain supported document
   * types.
   */
  normalizedValue?: GoogleCloudDocumentaiV1DocumentEntityNormalizedValue;
  /**
   * Optional. Represents the provenance of this entity wrt. the location on
   * the page where it was found.
   */
  pageAnchor?: GoogleCloudDocumentaiV1DocumentPageAnchor;
  /**
   * Optional. Entities can be nested to form a hierarchical data structure
   * representing the content in the document.
   */
  properties?: GoogleCloudDocumentaiV1DocumentEntity[];
  /**
   * Optional. The history of this annotation.
   */
  provenance?: GoogleCloudDocumentaiV1DocumentProvenance;
  /**
   * Optional. Whether the entity will be redacted for de-identification
   * purposes.
   */
  redacted?: boolean;
  /**
   * Optional. Provenance of the entity. Text anchor indexing into the
   * Document.text.
   */
  textAnchor?: GoogleCloudDocumentaiV1DocumentTextAnchor;
  /**
   * Required. Entity type from a schema e.g. `Address`.
   */
  type?: string;
}

function serializeGoogleCloudDocumentaiV1DocumentEntity(data: any): GoogleCloudDocumentaiV1DocumentEntity {
  return {
    ...data,
    normalizedValue: data["normalizedValue"] !== undefined ? serializeGoogleCloudDocumentaiV1DocumentEntityNormalizedValue(data["normalizedValue"]) : undefined,
    pageAnchor: data["pageAnchor"] !== undefined ? serializeGoogleCloudDocumentaiV1DocumentPageAnchor(data["pageAnchor"]) : undefined,
    properties: data["properties"] !== undefined ? data["properties"].map((item: any) => (serializeGoogleCloudDocumentaiV1DocumentEntity(item))) : undefined,
    textAnchor: data["textAnchor"] !== undefined ? serializeGoogleCloudDocumentaiV1DocumentTextAnchor(data["textAnchor"]) : undefined,
  };
}

function deserializeGoogleCloudDocumentaiV1DocumentEntity(data: any): GoogleCloudDocumentaiV1DocumentEntity {
  return {
    ...data,
    normalizedValue: data["normalizedValue"] !== undefined ? deserializeGoogleCloudDocumentaiV1DocumentEntityNormalizedValue(data["normalizedValue"]) : undefined,
    pageAnchor: data["pageAnchor"] !== undefined ? deserializeGoogleCloudDocumentaiV1DocumentPageAnchor(data["pageAnchor"]) : undefined,
    properties: data["properties"] !== undefined ? data["properties"].map((item: any) => (deserializeGoogleCloudDocumentaiV1DocumentEntity(item))) : undefined,
    textAnchor: data["textAnchor"] !== undefined ? deserializeGoogleCloudDocumentaiV1DocumentTextAnchor(data["textAnchor"]) : undefined,
  };
}

/**
 * Parsed and normalized entity value.
 */
export interface GoogleCloudDocumentaiV1DocumentEntityNormalizedValue {
  /**
   * Postal address. See also:
   * https://github.com/googleapis/googleapis/blob/master/google/type/postal_
   * address.proto
   */
  addressValue?: GoogleTypePostalAddress;
  /**
   * Boolean value. Can be used for entities with binary values, or for
   * checkboxes.
   */
  booleanValue?: boolean;
  /**
   * DateTime value. Includes date, time, and timezone. See also:
   * https://github.com/googleapis/googleapis/blob/master/google/type/datetime.proto
   */
  datetimeValue?: GoogleTypeDateTime;
  /**
   * Date value. Includes year, month, day. See also:
   * https://github.com/googleapis/googleapis/blob/master/google/type/date.proto
   */
  dateValue?: GoogleTypeDate;
  /**
   * Float value.
   */
  floatValue?: number;
  /**
   * Integer value.
   */
  integerValue?: number;
  /**
   * Money value. See also:
   * https://github.com/googleapis/googleapis/blob/master/google/type/money.proto
   */
  moneyValue?: GoogleTypeMoney;
  /**
   * Optional. An optional field to store a normalized string. For some entity
   * types, one of respective `structured_value` fields may also be populated.
   * Also not all the types of `structured_value` will be normalized. For
   * example, some processors may not generate `float` or `integer` normalized
   * text by default. Below are sample formats mapped to structured values. -
   * Money/Currency type (`money_value`) is in the ISO 4217 text format. - Date
   * type (`date_value`) is in the ISO 8601 text format. - Datetime type
   * (`datetime_value`) is in the ISO 8601 text format.
   */
  text?: string;
}

function serializeGoogleCloudDocumentaiV1DocumentEntityNormalizedValue(data: any): GoogleCloudDocumentaiV1DocumentEntityNormalizedValue {
  return {
    ...data,
    datetimeValue: data["datetimeValue"] !== undefined ? serializeGoogleTypeDateTime(data["datetimeValue"]) : undefined,
    moneyValue: data["moneyValue"] !== undefined ? serializeGoogleTypeMoney(data["moneyValue"]) : undefined,
  };
}

function deserializeGoogleCloudDocumentaiV1DocumentEntityNormalizedValue(data: any): GoogleCloudDocumentaiV1DocumentEntityNormalizedValue {
  return {
    ...data,
    datetimeValue: data["datetimeValue"] !== undefined ? deserializeGoogleTypeDateTime(data["datetimeValue"]) : undefined,
    moneyValue: data["moneyValue"] !== undefined ? deserializeGoogleTypeMoney(data["moneyValue"]) : undefined,
  };
}

/**
 * Relationship between Entities.
 */
export interface GoogleCloudDocumentaiV1DocumentEntityRelation {
  /**
   * Object entity id.
   */
  objectId?: string;
  /**
   * Relationship description.
   */
  relation?: string;
  /**
   * Subject entity id.
   */
  subjectId?: string;
}

/**
 * A page in a Document.
 */
export interface GoogleCloudDocumentaiV1DocumentPage {
  /**
   * A list of visually detected text blocks on the page. A block has a set of
   * lines (collected into paragraphs) that have a common line-spacing and
   * orientation.
   */
  blocks?: GoogleCloudDocumentaiV1DocumentPageBlock[];
  /**
   * A list of detected barcodes.
   */
  detectedBarcodes?: GoogleCloudDocumentaiV1DocumentPageDetectedBarcode[];
  /**
   * A list of detected languages together with confidence.
   */
  detectedLanguages?: GoogleCloudDocumentaiV1DocumentPageDetectedLanguage[];
  /**
   * Physical dimension of the page.
   */
  dimension?: GoogleCloudDocumentaiV1DocumentPageDimension;
  /**
   * A list of visually detected form fields on the page.
   */
  formFields?: GoogleCloudDocumentaiV1DocumentPageFormField[];
  /**
   * Rendered image for this page. This image is preprocessed to remove any
   * skew, rotation, and distortions such that the annotation bounding boxes can
   * be upright and axis-aligned.
   */
  image?: GoogleCloudDocumentaiV1DocumentPageImage;
  /**
   * Image Quality Scores.
   */
  imageQualityScores?: GoogleCloudDocumentaiV1DocumentPageImageQualityScores;
  /**
   * Layout for the page.
   */
  layout?: GoogleCloudDocumentaiV1DocumentPageLayout;
  /**
   * A list of visually detected text lines on the page. A collection of tokens
   * that a human would perceive as a line.
   */
  lines?: GoogleCloudDocumentaiV1DocumentPageLine[];
  /**
   * 1-based index for current Page in a parent Document. Useful when a page is
   * taken out of a Document for individual processing.
   */
  pageNumber?: number;
  /**
   * A list of visually detected text paragraphs on the page. A collection of
   * lines that a human would perceive as a paragraph.
   */
  paragraphs?: GoogleCloudDocumentaiV1DocumentPageParagraph[];
  /**
   * The history of this page.
   */
  provenance?: GoogleCloudDocumentaiV1DocumentProvenance;
  /**
   * A list of visually detected symbols on the page.
   */
  symbols?: GoogleCloudDocumentaiV1DocumentPageSymbol[];
  /**
   * A list of visually detected tables on the page.
   */
  tables?: GoogleCloudDocumentaiV1DocumentPageTable[];
  /**
   * A list of visually detected tokens on the page.
   */
  tokens?: GoogleCloudDocumentaiV1DocumentPageToken[];
  /**
   * Transformation matrices that were applied to the original document image
   * to produce Page.image.
   */
  transforms?: GoogleCloudDocumentaiV1DocumentPageMatrix[];
  /**
   * A list of detected non-text visual elements e.g. checkbox, signature etc.
   * on the page.
   */
  visualElements?: GoogleCloudDocumentaiV1DocumentPageVisualElement[];
}

function serializeGoogleCloudDocumentaiV1DocumentPage(data: any): GoogleCloudDocumentaiV1DocumentPage {
  return {
    ...data,
    blocks: data["blocks"] !== undefined ? data["blocks"].map((item: any) => (serializeGoogleCloudDocumentaiV1DocumentPageBlock(item))) : undefined,
    detectedBarcodes: data["detectedBarcodes"] !== undefined ? data["detectedBarcodes"].map((item: any) => (serializeGoogleCloudDocumentaiV1DocumentPageDetectedBarcode(item))) : undefined,
    formFields: data["formFields"] !== undefined ? data["formFields"].map((item: any) => (serializeGoogleCloudDocumentaiV1DocumentPageFormField(item))) : undefined,
    image: data["image"] !== undefined ? serializeGoogleCloudDocumentaiV1DocumentPageImage(data["image"]) : undefined,
    layout: data["layout"] !== undefined ? serializeGoogleCloudDocumentaiV1DocumentPageLayout(data["layout"]) : undefined,
    lines: data["lines"] !== undefined ? data["lines"].map((item: any) => (serializeGoogleCloudDocumentaiV1DocumentPageLine(item))) : undefined,
    paragraphs: data["paragraphs"] !== undefined ? data["paragraphs"].map((item: any) => (serializeGoogleCloudDocumentaiV1DocumentPageParagraph(item))) : undefined,
    symbols: data["symbols"] !== undefined ? data["symbols"].map((item: any) => (serializeGoogleCloudDocumentaiV1DocumentPageSymbol(item))) : undefined,
    tables: data["tables"] !== undefined ? data["tables"].map((item: any) => (serializeGoogleCloudDocumentaiV1DocumentPageTable(item))) : undefined,
    tokens: data["tokens"] !== undefined ? data["tokens"].map((item: any) => (serializeGoogleCloudDocumentaiV1DocumentPageToken(item))) : undefined,
    transforms: data["transforms"] !== undefined ? data["transforms"].map((item: any) => (serializeGoogleCloudDocumentaiV1DocumentPageMatrix(item))) : undefined,
    visualElements: data["visualElements"] !== undefined ? data["visualElements"].map((item: any) => (serializeGoogleCloudDocumentaiV1DocumentPageVisualElement(item))) : undefined,
  };
}

function deserializeGoogleCloudDocumentaiV1DocumentPage(data: any): GoogleCloudDocumentaiV1DocumentPage {
  return {
    ...data,
    blocks: data["blocks"] !== undefined ? data["blocks"].map((item: any) => (deserializeGoogleCloudDocumentaiV1DocumentPageBlock(item))) : undefined,
    detectedBarcodes: data["detectedBarcodes"] !== undefined ? data["detectedBarcodes"].map((item: any) => (deserializeGoogleCloudDocumentaiV1DocumentPageDetectedBarcode(item))) : undefined,
    formFields: data["formFields"] !== undefined ? data["formFields"].map((item: any) => (deserializeGoogleCloudDocumentaiV1DocumentPageFormField(item))) : undefined,
    image: data["image"] !== undefined ? deserializeGoogleCloudDocumentaiV1DocumentPageImage(data["image"]) : undefined,
    layout: data["layout"] !== undefined ? deserializeGoogleCloudDocumentaiV1DocumentPageLayout(data["layout"]) : undefined,
    lines: data["lines"] !== undefined ? data["lines"].map((item: any) => (deserializeGoogleCloudDocumentaiV1DocumentPageLine(item))) : undefined,
    paragraphs: data["paragraphs"] !== undefined ? data["paragraphs"].map((item: any) => (deserializeGoogleCloudDocumentaiV1DocumentPageParagraph(item))) : undefined,
    symbols: data["symbols"] !== undefined ? data["symbols"].map((item: any) => (deserializeGoogleCloudDocumentaiV1DocumentPageSymbol(item))) : undefined,
    tables: data["tables"] !== undefined ? data["tables"].map((item: any) => (deserializeGoogleCloudDocumentaiV1DocumentPageTable(item))) : undefined,
    tokens: data["tokens"] !== undefined ? data["tokens"].map((item: any) => (deserializeGoogleCloudDocumentaiV1DocumentPageToken(item))) : undefined,
    transforms: data["transforms"] !== undefined ? data["transforms"].map((item: any) => (deserializeGoogleCloudDocumentaiV1DocumentPageMatrix(item))) : undefined,
    visualElements: data["visualElements"] !== undefined ? data["visualElements"].map((item: any) => (deserializeGoogleCloudDocumentaiV1DocumentPageVisualElement(item))) : undefined,
  };
}

/**
 * Referencing the visual context of the entity in the Document.pages. Page
 * anchors can be cross-page, consist of multiple bounding polygons and
 * optionally reference specific layout element types.
 */
export interface GoogleCloudDocumentaiV1DocumentPageAnchor {
  /**
   * One or more references to visual page elements
   */
  pageRefs?: GoogleCloudDocumentaiV1DocumentPageAnchorPageRef[];
}

function serializeGoogleCloudDocumentaiV1DocumentPageAnchor(data: any): GoogleCloudDocumentaiV1DocumentPageAnchor {
  return {
    ...data,
    pageRefs: data["pageRefs"] !== undefined ? data["pageRefs"].map((item: any) => (serializeGoogleCloudDocumentaiV1DocumentPageAnchorPageRef(item))) : undefined,
  };
}

function deserializeGoogleCloudDocumentaiV1DocumentPageAnchor(data: any): GoogleCloudDocumentaiV1DocumentPageAnchor {
  return {
    ...data,
    pageRefs: data["pageRefs"] !== undefined ? data["pageRefs"].map((item: any) => (deserializeGoogleCloudDocumentaiV1DocumentPageAnchorPageRef(item))) : undefined,
  };
}

/**
 * Represents a weak reference to a page element within a document.
 */
export interface GoogleCloudDocumentaiV1DocumentPageAnchorPageRef {
  /**
   * Optional. Identifies the bounding polygon of a layout element on the page.
   */
  boundingPoly?: GoogleCloudDocumentaiV1BoundingPoly;
  /**
   * Optional. Confidence of detected page element, if applicable. Range `[0,
   * 1]`.
   */
  confidence?: number;
  /**
   * Optional. Deprecated. Use PageRef.bounding_poly instead.
   */
  layoutId?: string;
  /**
   * Optional. The type of the layout element that is being referenced if any.
   */
  layoutType?:  | "LAYOUT_TYPE_UNSPECIFIED" | "BLOCK" | "PARAGRAPH" | "LINE" | "TOKEN" | "VISUAL_ELEMENT" | "TABLE" | "FORM_FIELD";
  /**
   * Required. Index into the Document.pages element, for example using
   * `Document.pages` to locate the related page element. This field is skipped
   * when its value is the default `0`. See
   * https://developers.google.com/protocol-buffers/docs/proto3#json.
   */
  page?: bigint;
}

function serializeGoogleCloudDocumentaiV1DocumentPageAnchorPageRef(data: any): GoogleCloudDocumentaiV1DocumentPageAnchorPageRef {
  return {
    ...data,
    page: data["page"] !== undefined ? String(data["page"]) : undefined,
  };
}

function deserializeGoogleCloudDocumentaiV1DocumentPageAnchorPageRef(data: any): GoogleCloudDocumentaiV1DocumentPageAnchorPageRef {
  return {
    ...data,
    page: data["page"] !== undefined ? BigInt(data["page"]) : undefined,
  };
}

/**
 * A block has a set of lines (collected into paragraphs) that have a common
 * line-spacing and orientation.
 */
export interface GoogleCloudDocumentaiV1DocumentPageBlock {
  /**
   * A list of detected languages together with confidence.
   */
  detectedLanguages?: GoogleCloudDocumentaiV1DocumentPageDetectedLanguage[];
  /**
   * Layout for Block.
   */
  layout?: GoogleCloudDocumentaiV1DocumentPageLayout;
  /**
   * The history of this annotation.
   */
  provenance?: GoogleCloudDocumentaiV1DocumentProvenance;
}

function serializeGoogleCloudDocumentaiV1DocumentPageBlock(data: any): GoogleCloudDocumentaiV1DocumentPageBlock {
  return {
    ...data,
    layout: data["layout"] !== undefined ? serializeGoogleCloudDocumentaiV1DocumentPageLayout(data["layout"]) : undefined,
  };
}

function deserializeGoogleCloudDocumentaiV1DocumentPageBlock(data: any): GoogleCloudDocumentaiV1DocumentPageBlock {
  return {
    ...data,
    layout: data["layout"] !== undefined ? deserializeGoogleCloudDocumentaiV1DocumentPageLayout(data["layout"]) : undefined,
  };
}

/**
 * A detected barcode.
 */
export interface GoogleCloudDocumentaiV1DocumentPageDetectedBarcode {
  /**
   * Detailed barcode information of the DetectedBarcode.
   */
  barcode?: GoogleCloudDocumentaiV1Barcode;
  /**
   * Layout for DetectedBarcode.
   */
  layout?: GoogleCloudDocumentaiV1DocumentPageLayout;
}

function serializeGoogleCloudDocumentaiV1DocumentPageDetectedBarcode(data: any): GoogleCloudDocumentaiV1DocumentPageDetectedBarcode {
  return {
    ...data,
    layout: data["layout"] !== undefined ? serializeGoogleCloudDocumentaiV1DocumentPageLayout(data["layout"]) : undefined,
  };
}

function deserializeGoogleCloudDocumentaiV1DocumentPageDetectedBarcode(data: any): GoogleCloudDocumentaiV1DocumentPageDetectedBarcode {
  return {
    ...data,
    layout: data["layout"] !== undefined ? deserializeGoogleCloudDocumentaiV1DocumentPageLayout(data["layout"]) : undefined,
  };
}

/**
 * Detected language for a structural component.
 */
export interface GoogleCloudDocumentaiV1DocumentPageDetectedLanguage {
  /**
   * Confidence of detected language. Range `[0, 1]`.
   */
  confidence?: number;
  /**
   * The BCP-47 language code, such as `en-US` or `sr-Latn`. For more
   * information, see
   * https://www.unicode.org/reports/tr35/#Unicode_locale_identifier.
   */
  languageCode?: string;
}

/**
 * Dimension for the page.
 */
export interface GoogleCloudDocumentaiV1DocumentPageDimension {
  /**
   * Page height.
   */
  height?: number;
  /**
   * Dimension unit.
   */
  unit?: string;
  /**
   * Page width.
   */
  width?: number;
}

/**
 * A form field detected on the page.
 */
export interface GoogleCloudDocumentaiV1DocumentPageFormField {
  /**
   * Created for Labeling UI to export key text. If corrections were made to
   * the text identified by the `field_name.text_anchor`, this field will
   * contain the correction.
   */
  correctedKeyText?: string;
  /**
   * Created for Labeling UI to export value text. If corrections were made to
   * the text identified by the `field_value.text_anchor`, this field will
   * contain the correction.
   */
  correctedValueText?: string;
  /**
   * Layout for the FormField name. e.g. `Address`, `Email`, `Grand total`,
   * `Phone number`, etc.
   */
  fieldName?: GoogleCloudDocumentaiV1DocumentPageLayout;
  /**
   * Layout for the FormField value.
   */
  fieldValue?: GoogleCloudDocumentaiV1DocumentPageLayout;
  /**
   * A list of detected languages for name together with confidence.
   */
  nameDetectedLanguages?: GoogleCloudDocumentaiV1DocumentPageDetectedLanguage[];
  /**
   * The history of this annotation.
   */
  provenance?: GoogleCloudDocumentaiV1DocumentProvenance;
  /**
   * A list of detected languages for value together with confidence.
   */
  valueDetectedLanguages?: GoogleCloudDocumentaiV1DocumentPageDetectedLanguage[];
  /**
   * If the value is non-textual, this field represents the type. Current valid
   * values are: - blank (this indicates the `field_value` is normal text) -
   * `unfilled_checkbox` - `filled_checkbox`
   */
  valueType?: string;
}

function serializeGoogleCloudDocumentaiV1DocumentPageFormField(data: any): GoogleCloudDocumentaiV1DocumentPageFormField {
  return {
    ...data,
    fieldName: data["fieldName"] !== undefined ? serializeGoogleCloudDocumentaiV1DocumentPageLayout(data["fieldName"]) : undefined,
    fieldValue: data["fieldValue"] !== undefined ? serializeGoogleCloudDocumentaiV1DocumentPageLayout(data["fieldValue"]) : undefined,
  };
}

function deserializeGoogleCloudDocumentaiV1DocumentPageFormField(data: any): GoogleCloudDocumentaiV1DocumentPageFormField {
  return {
    ...data,
    fieldName: data["fieldName"] !== undefined ? deserializeGoogleCloudDocumentaiV1DocumentPageLayout(data["fieldName"]) : undefined,
    fieldValue: data["fieldValue"] !== undefined ? deserializeGoogleCloudDocumentaiV1DocumentPageLayout(data["fieldValue"]) : undefined,
  };
}

/**
 * Rendered image contents for this page.
 */
export interface GoogleCloudDocumentaiV1DocumentPageImage {
  /**
   * Raw byte content of the image.
   */
  content?: Uint8Array;
  /**
   * Height of the image in pixels.
   */
  height?: number;
  /**
   * Encoding mime type for the image.
   */
  mimeType?: string;
  /**
   * Width of the image in pixels.
   */
  width?: number;
}

function serializeGoogleCloudDocumentaiV1DocumentPageImage(data: any): GoogleCloudDocumentaiV1DocumentPageImage {
  return {
    ...data,
    content: data["content"] !== undefined ? encodeBase64(data["content"]) : undefined,
  };
}

function deserializeGoogleCloudDocumentaiV1DocumentPageImage(data: any): GoogleCloudDocumentaiV1DocumentPageImage {
  return {
    ...data,
    content: data["content"] !== undefined ? decodeBase64(data["content"] as string) : undefined,
  };
}

/**
 * Image Quality Scores for the page image
 */
export interface GoogleCloudDocumentaiV1DocumentPageImageQualityScores {
  /**
   * A list of detected defects.
   */
  detectedDefects?: GoogleCloudDocumentaiV1DocumentPageImageQualityScoresDetectedDefect[];
  /**
   * The overall quality score. Range `[0, 1]` where 1 is perfect quality.
   */
  qualityScore?: number;
}

/**
 * Image Quality Defects
 */
export interface GoogleCloudDocumentaiV1DocumentPageImageQualityScoresDetectedDefect {
  /**
   * Confidence of detected defect. Range `[0, 1]` where 1 indicates strong
   * confidence of that the defect exists.
   */
  confidence?: number;
  /**
   * Name of the defect type. Supported values are: - `quality/defect_blurry` -
   * `quality/defect_noisy` - `quality/defect_dark` - `quality/defect_faint` -
   * `quality/defect_text_too_small` - `quality/defect_document_cutoff` -
   * `quality/defect_text_cutoff` - `quality/defect_glare`
   */
  type?: string;
}

/**
 * Visual element describing a layout unit on a page.
 */
export interface GoogleCloudDocumentaiV1DocumentPageLayout {
  /**
   * The bounding polygon for the Layout.
   */
  boundingPoly?: GoogleCloudDocumentaiV1BoundingPoly;
  /**
   * Confidence of the current Layout within context of the object this layout
   * is for. e.g. confidence can be for a single token, a table, a visual
   * element, etc. depending on context. Range `[0, 1]`.
   */
  confidence?: number;
  /**
   * Detected orientation for the Layout.
   */
  orientation?:  | "ORIENTATION_UNSPECIFIED" | "PAGE_UP" | "PAGE_RIGHT" | "PAGE_DOWN" | "PAGE_LEFT";
  /**
   * Text anchor indexing into the Document.text.
   */
  textAnchor?: GoogleCloudDocumentaiV1DocumentTextAnchor;
}

function serializeGoogleCloudDocumentaiV1DocumentPageLayout(data: any): GoogleCloudDocumentaiV1DocumentPageLayout {
  return {
    ...data,
    textAnchor: data["textAnchor"] !== undefined ? serializeGoogleCloudDocumentaiV1DocumentTextAnchor(data["textAnchor"]) : undefined,
  };
}

function deserializeGoogleCloudDocumentaiV1DocumentPageLayout(data: any): GoogleCloudDocumentaiV1DocumentPageLayout {
  return {
    ...data,
    textAnchor: data["textAnchor"] !== undefined ? deserializeGoogleCloudDocumentaiV1DocumentTextAnchor(data["textAnchor"]) : undefined,
  };
}

/**
 * A collection of tokens that a human would perceive as a line. Does not cross
 * column boundaries, can be horizontal, vertical, etc.
 */
export interface GoogleCloudDocumentaiV1DocumentPageLine {
  /**
   * A list of detected languages together with confidence.
   */
  detectedLanguages?: GoogleCloudDocumentaiV1DocumentPageDetectedLanguage[];
  /**
   * Layout for Line.
   */
  layout?: GoogleCloudDocumentaiV1DocumentPageLayout;
  /**
   * The history of this annotation.
   */
  provenance?: GoogleCloudDocumentaiV1DocumentProvenance;
}

function serializeGoogleCloudDocumentaiV1DocumentPageLine(data: any): GoogleCloudDocumentaiV1DocumentPageLine {
  return {
    ...data,
    layout: data["layout"] !== undefined ? serializeGoogleCloudDocumentaiV1DocumentPageLayout(data["layout"]) : undefined,
  };
}

function deserializeGoogleCloudDocumentaiV1DocumentPageLine(data: any): GoogleCloudDocumentaiV1DocumentPageLine {
  return {
    ...data,
    layout: data["layout"] !== undefined ? deserializeGoogleCloudDocumentaiV1DocumentPageLayout(data["layout"]) : undefined,
  };
}

/**
 * Representation for transformation matrix, intended to be compatible and used
 * with OpenCV format for image manipulation.
 */
export interface GoogleCloudDocumentaiV1DocumentPageMatrix {
  /**
   * Number of columns in the matrix.
   */
  cols?: number;
  /**
   * The matrix data.
   */
  data?: Uint8Array;
  /**
   * Number of rows in the matrix.
   */
  rows?: number;
  /**
   * This encodes information about what data type the matrix uses. For
   * example, 0 (CV_8U) is an unsigned 8-bit image. For the full list of OpenCV
   * primitive data types, please refer to
   * https://docs.opencv.org/4.3.0/d1/d1b/group__core__hal__interface.html
   */
  type?: number;
}

function serializeGoogleCloudDocumentaiV1DocumentPageMatrix(data: any): GoogleCloudDocumentaiV1DocumentPageMatrix {
  return {
    ...data,
    data: data["data"] !== undefined ? encodeBase64(data["data"]) : undefined,
  };
}

function deserializeGoogleCloudDocumentaiV1DocumentPageMatrix(data: any): GoogleCloudDocumentaiV1DocumentPageMatrix {
  return {
    ...data,
    data: data["data"] !== undefined ? decodeBase64(data["data"] as string) : undefined,
  };
}

/**
 * A collection of lines that a human would perceive as a paragraph.
 */
export interface GoogleCloudDocumentaiV1DocumentPageParagraph {
  /**
   * A list of detected languages together with confidence.
   */
  detectedLanguages?: GoogleCloudDocumentaiV1DocumentPageDetectedLanguage[];
  /**
   * Layout for Paragraph.
   */
  layout?: GoogleCloudDocumentaiV1DocumentPageLayout;
  /**
   * The history of this annotation.
   */
  provenance?: GoogleCloudDocumentaiV1DocumentProvenance;
}

function serializeGoogleCloudDocumentaiV1DocumentPageParagraph(data: any): GoogleCloudDocumentaiV1DocumentPageParagraph {
  return {
    ...data,
    layout: data["layout"] !== undefined ? serializeGoogleCloudDocumentaiV1DocumentPageLayout(data["layout"]) : undefined,
  };
}

function deserializeGoogleCloudDocumentaiV1DocumentPageParagraph(data: any): GoogleCloudDocumentaiV1DocumentPageParagraph {
  return {
    ...data,
    layout: data["layout"] !== undefined ? deserializeGoogleCloudDocumentaiV1DocumentPageLayout(data["layout"]) : undefined,
  };
}

/**
 * A detected symbol.
 */
export interface GoogleCloudDocumentaiV1DocumentPageSymbol {
  /**
   * A list of detected languages together with confidence.
   */
  detectedLanguages?: GoogleCloudDocumentaiV1DocumentPageDetectedLanguage[];
  /**
   * Layout for Symbol.
   */
  layout?: GoogleCloudDocumentaiV1DocumentPageLayout;
}

function serializeGoogleCloudDocumentaiV1DocumentPageSymbol(data: any): GoogleCloudDocumentaiV1DocumentPageSymbol {
  return {
    ...data,
    layout: data["layout"] !== undefined ? serializeGoogleCloudDocumentaiV1DocumentPageLayout(data["layout"]) : undefined,
  };
}

function deserializeGoogleCloudDocumentaiV1DocumentPageSymbol(data: any): GoogleCloudDocumentaiV1DocumentPageSymbol {
  return {
    ...data,
    layout: data["layout"] !== undefined ? deserializeGoogleCloudDocumentaiV1DocumentPageLayout(data["layout"]) : undefined,
  };
}

/**
 * A table representation similar to HTML table structure.
 */
export interface GoogleCloudDocumentaiV1DocumentPageTable {
  /**
   * Body rows of the table.
   */
  bodyRows?: GoogleCloudDocumentaiV1DocumentPageTableTableRow[];
  /**
   * A list of detected languages together with confidence.
   */
  detectedLanguages?: GoogleCloudDocumentaiV1DocumentPageDetectedLanguage[];
  /**
   * Header rows of the table.
   */
  headerRows?: GoogleCloudDocumentaiV1DocumentPageTableTableRow[];
  /**
   * Layout for Table.
   */
  layout?: GoogleCloudDocumentaiV1DocumentPageLayout;
  /**
   * The history of this table.
   */
  provenance?: GoogleCloudDocumentaiV1DocumentProvenance;
}

function serializeGoogleCloudDocumentaiV1DocumentPageTable(data: any): GoogleCloudDocumentaiV1DocumentPageTable {
  return {
    ...data,
    bodyRows: data["bodyRows"] !== undefined ? data["bodyRows"].map((item: any) => (serializeGoogleCloudDocumentaiV1DocumentPageTableTableRow(item))) : undefined,
    headerRows: data["headerRows"] !== undefined ? data["headerRows"].map((item: any) => (serializeGoogleCloudDocumentaiV1DocumentPageTableTableRow(item))) : undefined,
    layout: data["layout"] !== undefined ? serializeGoogleCloudDocumentaiV1DocumentPageLayout(data["layout"]) : undefined,
  };
}

function deserializeGoogleCloudDocumentaiV1DocumentPageTable(data: any): GoogleCloudDocumentaiV1DocumentPageTable {
  return {
    ...data,
    bodyRows: data["bodyRows"] !== undefined ? data["bodyRows"].map((item: any) => (deserializeGoogleCloudDocumentaiV1DocumentPageTableTableRow(item))) : undefined,
    headerRows: data["headerRows"] !== undefined ? data["headerRows"].map((item: any) => (deserializeGoogleCloudDocumentaiV1DocumentPageTableTableRow(item))) : undefined,
    layout: data["layout"] !== undefined ? deserializeGoogleCloudDocumentaiV1DocumentPageLayout(data["layout"]) : undefined,
  };
}

/**
 * A cell representation inside the table.
 */
export interface GoogleCloudDocumentaiV1DocumentPageTableTableCell {
  /**
   * How many columns this cell spans.
   */
  colSpan?: number;
  /**
   * A list of detected languages together with confidence.
   */
  detectedLanguages?: GoogleCloudDocumentaiV1DocumentPageDetectedLanguage[];
  /**
   * Layout for TableCell.
   */
  layout?: GoogleCloudDocumentaiV1DocumentPageLayout;
  /**
   * How many rows this cell spans.
   */
  rowSpan?: number;
}

function serializeGoogleCloudDocumentaiV1DocumentPageTableTableCell(data: any): GoogleCloudDocumentaiV1DocumentPageTableTableCell {
  return {
    ...data,
    layout: data["layout"] !== undefined ? serializeGoogleCloudDocumentaiV1DocumentPageLayout(data["layout"]) : undefined,
  };
}

function deserializeGoogleCloudDocumentaiV1DocumentPageTableTableCell(data: any): GoogleCloudDocumentaiV1DocumentPageTableTableCell {
  return {
    ...data,
    layout: data["layout"] !== undefined ? deserializeGoogleCloudDocumentaiV1DocumentPageLayout(data["layout"]) : undefined,
  };
}

/**
 * A row of table cells.
 */
export interface GoogleCloudDocumentaiV1DocumentPageTableTableRow {
  /**
   * Cells that make up this row.
   */
  cells?: GoogleCloudDocumentaiV1DocumentPageTableTableCell[];
}

function serializeGoogleCloudDocumentaiV1DocumentPageTableTableRow(data: any): GoogleCloudDocumentaiV1DocumentPageTableTableRow {
  return {
    ...data,
    cells: data["cells"] !== undefined ? data["cells"].map((item: any) => (serializeGoogleCloudDocumentaiV1DocumentPageTableTableCell(item))) : undefined,
  };
}

function deserializeGoogleCloudDocumentaiV1DocumentPageTableTableRow(data: any): GoogleCloudDocumentaiV1DocumentPageTableTableRow {
  return {
    ...data,
    cells: data["cells"] !== undefined ? data["cells"].map((item: any) => (deserializeGoogleCloudDocumentaiV1DocumentPageTableTableCell(item))) : undefined,
  };
}

/**
 * A detected token.
 */
export interface GoogleCloudDocumentaiV1DocumentPageToken {
  /**
   * Detected break at the end of a Token.
   */
  detectedBreak?: GoogleCloudDocumentaiV1DocumentPageTokenDetectedBreak;
  /**
   * A list of detected languages together with confidence.
   */
  detectedLanguages?: GoogleCloudDocumentaiV1DocumentPageDetectedLanguage[];
  /**
   * Layout for Token.
   */
  layout?: GoogleCloudDocumentaiV1DocumentPageLayout;
  /**
   * The history of this annotation.
   */
  provenance?: GoogleCloudDocumentaiV1DocumentProvenance;
}

function serializeGoogleCloudDocumentaiV1DocumentPageToken(data: any): GoogleCloudDocumentaiV1DocumentPageToken {
  return {
    ...data,
    layout: data["layout"] !== undefined ? serializeGoogleCloudDocumentaiV1DocumentPageLayout(data["layout"]) : undefined,
  };
}

function deserializeGoogleCloudDocumentaiV1DocumentPageToken(data: any): GoogleCloudDocumentaiV1DocumentPageToken {
  return {
    ...data,
    layout: data["layout"] !== undefined ? deserializeGoogleCloudDocumentaiV1DocumentPageLayout(data["layout"]) : undefined,
  };
}

/**
 * Detected break at the end of a Token.
 */
export interface GoogleCloudDocumentaiV1DocumentPageTokenDetectedBreak {
  /**
   * Detected break type.
   */
  type?:  | "TYPE_UNSPECIFIED" | "SPACE" | "WIDE_SPACE" | "HYPHEN";
}

/**
 * Detected non-text visual elements e.g. checkbox, signature etc. on the page.
 */
export interface GoogleCloudDocumentaiV1DocumentPageVisualElement {
  /**
   * A list of detected languages together with confidence.
   */
  detectedLanguages?: GoogleCloudDocumentaiV1DocumentPageDetectedLanguage[];
  /**
   * Layout for VisualElement.
   */
  layout?: GoogleCloudDocumentaiV1DocumentPageLayout;
  /**
   * Type of the VisualElement.
   */
  type?: string;
}

function serializeGoogleCloudDocumentaiV1DocumentPageVisualElement(data: any): GoogleCloudDocumentaiV1DocumentPageVisualElement {
  return {
    ...data,
    layout: data["layout"] !== undefined ? serializeGoogleCloudDocumentaiV1DocumentPageLayout(data["layout"]) : undefined,
  };
}

function deserializeGoogleCloudDocumentaiV1DocumentPageVisualElement(data: any): GoogleCloudDocumentaiV1DocumentPageVisualElement {
  return {
    ...data,
    layout: data["layout"] !== undefined ? deserializeGoogleCloudDocumentaiV1DocumentPageLayout(data["layout"]) : undefined,
  };
}

/**
 * Structure to identify provenance relationships between annotations in
 * different revisions.
 */
export interface GoogleCloudDocumentaiV1DocumentProvenance {
  /**
   * The Id of this operation. Needs to be unique within the scope of the
   * revision.
   */
  id?: number;
  /**
   * References to the original elements that are replaced.
   */
  parents?: GoogleCloudDocumentaiV1DocumentProvenanceParent[];
  /**
   * The index of the revision that produced this element.
   */
  revision?: number;
  /**
   * The type of provenance operation.
   */
  type?:  | "OPERATION_TYPE_UNSPECIFIED" | "ADD" | "REMOVE" | "UPDATE" | "REPLACE" | "EVAL_REQUESTED" | "EVAL_APPROVED" | "EVAL_SKIPPED";
}

/**
 * The parent element the current element is based on. Used for
 * referencing/aligning, removal and replacement operations.
 */
export interface GoogleCloudDocumentaiV1DocumentProvenanceParent {
  /**
   * The id of the parent provenance.
   */
  id?: number;
  /**
   * The index of the parent item in the corresponding item list (eg. list of
   * entities, properties within entities, etc.) in the parent revision.
   */
  index?: number;
  /**
   * The index of the index into current revision's parent_ids list.
   */
  revision?: number;
}

/**
 * Contains past or forward revisions of this document.
 */
export interface GoogleCloudDocumentaiV1DocumentRevision {
  /**
   * If the change was made by a person specify the name or id of that person.
   */
  agent?: string;
  /**
   * The time that the revision was created, internally generated by doc proto
   * storage at the time of create.
   */
  createTime?: Date;
  /**
   * Human Review information of this revision.
   */
  humanReview?: GoogleCloudDocumentaiV1DocumentRevisionHumanReview;
  /**
   * Id of the revision, internally generated by doc proto storage. Unique
   * within the context of the document.
   */
  id?: string;
  /**
   * The revisions that this revision is based on. This can include one or more
   * parent (when documents are merged.) This field represents the index into
   * the `revisions` field.
   */
  parent?: number[];
  /**
   * The revisions that this revision is based on. Must include all the ids
   * that have anything to do with this revision - eg. there are
   * `provenance.parent.revision` fields that index into this field.
   */
  parentIds?: string[];
  /**
   * If the annotation was made by processor identify the processor by its
   * resource name.
   */
  processor?: string;
}

function serializeGoogleCloudDocumentaiV1DocumentRevision(data: any): GoogleCloudDocumentaiV1DocumentRevision {
  return {
    ...data,
    createTime: data["createTime"] !== undefined ? data["createTime"].toISOString() : undefined,
  };
}

function deserializeGoogleCloudDocumentaiV1DocumentRevision(data: any): GoogleCloudDocumentaiV1DocumentRevision {
  return {
    ...data,
    createTime: data["createTime"] !== undefined ? new Date(data["createTime"]) : undefined,
  };
}

/**
 * Human Review information of the document.
 */
export interface GoogleCloudDocumentaiV1DocumentRevisionHumanReview {
  /**
   * Human review state. e.g. `requested`, `succeeded`, `rejected`.
   */
  state?: string;
  /**
   * A message providing more details about the current state of processing.
   * For example, the rejection reason when the state is `rejected`.
   */
  stateMessage?: string;
}

/**
 * For a large document, sharding may be performed to produce several document
 * shards. Each document shard contains this field to detail which shard it is.
 */
export interface GoogleCloudDocumentaiV1DocumentShardInfo {
  /**
   * Total number of shards.
   */
  shardCount?: bigint;
  /**
   * The 0-based index of this shard.
   */
  shardIndex?: bigint;
  /**
   * The index of the first character in Document.text in the overall document
   * global text.
   */
  textOffset?: bigint;
}

function serializeGoogleCloudDocumentaiV1DocumentShardInfo(data: any): GoogleCloudDocumentaiV1DocumentShardInfo {
  return {
    ...data,
    shardCount: data["shardCount"] !== undefined ? String(data["shardCount"]) : undefined,
    shardIndex: data["shardIndex"] !== undefined ? String(data["shardIndex"]) : undefined,
    textOffset: data["textOffset"] !== undefined ? String(data["textOffset"]) : undefined,
  };
}

function deserializeGoogleCloudDocumentaiV1DocumentShardInfo(data: any): GoogleCloudDocumentaiV1DocumentShardInfo {
  return {
    ...data,
    shardCount: data["shardCount"] !== undefined ? BigInt(data["shardCount"]) : undefined,
    shardIndex: data["shardIndex"] !== undefined ? BigInt(data["shardIndex"]) : undefined,
    textOffset: data["textOffset"] !== undefined ? BigInt(data["textOffset"]) : undefined,
  };
}

/**
 * Annotation for common text style attributes. This adheres to CSS conventions
 * as much as possible.
 */
export interface GoogleCloudDocumentaiV1DocumentStyle {
  /**
   * Text background color.
   */
  backgroundColor?: GoogleTypeColor;
  /**
   * Text color.
   */
  color?: GoogleTypeColor;
  /**
   * Font family such as `Arial`, `Times New Roman`.
   * https://www.w3schools.com/cssref/pr_font_font-family.asp
   */
  fontFamily?: string;
  /**
   * Font size.
   */
  fontSize?: GoogleCloudDocumentaiV1DocumentStyleFontSize;
  /**
   * Font weight. Possible values are normal, bold, bolder, and lighter.
   * https://www.w3schools.com/cssref/pr_font_weight.asp
   */
  fontWeight?: string;
  /**
   * Text anchor indexing into the Document.text.
   */
  textAnchor?: GoogleCloudDocumentaiV1DocumentTextAnchor;
  /**
   * Text decoration. Follows CSS standard.
   * https://www.w3schools.com/cssref/pr_text_text-decoration.asp
   */
  textDecoration?: string;
  /**
   * Text style. Possible values are normal, italic, and oblique.
   * https://www.w3schools.com/cssref/pr_font_font-style.asp
   */
  textStyle?: string;
}

function serializeGoogleCloudDocumentaiV1DocumentStyle(data: any): GoogleCloudDocumentaiV1DocumentStyle {
  return {
    ...data,
    textAnchor: data["textAnchor"] !== undefined ? serializeGoogleCloudDocumentaiV1DocumentTextAnchor(data["textAnchor"]) : undefined,
  };
}

function deserializeGoogleCloudDocumentaiV1DocumentStyle(data: any): GoogleCloudDocumentaiV1DocumentStyle {
  return {
    ...data,
    textAnchor: data["textAnchor"] !== undefined ? deserializeGoogleCloudDocumentaiV1DocumentTextAnchor(data["textAnchor"]) : undefined,
  };
}

/**
 * Font size with unit.
 */
export interface GoogleCloudDocumentaiV1DocumentStyleFontSize {
  /**
   * Font size for the text.
   */
  size?: number;
  /**
   * Unit for the font size. Follows CSS naming (in, px, pt, etc.).
   */
  unit?: string;
}

/**
 * Text reference indexing into the Document.text.
 */
export interface GoogleCloudDocumentaiV1DocumentTextAnchor {
  /**
   * Contains the content of the text span so that users do not have to look it
   * up in the text_segments. It is always populated for formFields.
   */
  content?: string;
  /**
   * The text segments from the Document.text.
   */
  textSegments?: GoogleCloudDocumentaiV1DocumentTextAnchorTextSegment[];
}

function serializeGoogleCloudDocumentaiV1DocumentTextAnchor(data: any): GoogleCloudDocumentaiV1DocumentTextAnchor {
  return {
    ...data,
    textSegments: data["textSegments"] !== undefined ? data["textSegments"].map((item: any) => (serializeGoogleCloudDocumentaiV1DocumentTextAnchorTextSegment(item))) : undefined,
  };
}

function deserializeGoogleCloudDocumentaiV1DocumentTextAnchor(data: any): GoogleCloudDocumentaiV1DocumentTextAnchor {
  return {
    ...data,
    textSegments: data["textSegments"] !== undefined ? data["textSegments"].map((item: any) => (deserializeGoogleCloudDocumentaiV1DocumentTextAnchorTextSegment(item))) : undefined,
  };
}

/**
 * A text segment in the Document.text. The indices may be out of bounds which
 * indicate that the text extends into another document shard for large sharded
 * documents. See ShardInfo.text_offset
 */
export interface GoogleCloudDocumentaiV1DocumentTextAnchorTextSegment {
  /**
   * TextSegment half open end UTF-8 char index in the Document.text.
   */
  endIndex?: bigint;
  /**
   * TextSegment start UTF-8 char index in the Document.text.
   */
  startIndex?: bigint;
}

function serializeGoogleCloudDocumentaiV1DocumentTextAnchorTextSegment(data: any): GoogleCloudDocumentaiV1DocumentTextAnchorTextSegment {
  return {
    ...data,
    endIndex: data["endIndex"] !== undefined ? String(data["endIndex"]) : undefined,
    startIndex: data["startIndex"] !== undefined ? String(data["startIndex"]) : undefined,
  };
}

function deserializeGoogleCloudDocumentaiV1DocumentTextAnchorTextSegment(data: any): GoogleCloudDocumentaiV1DocumentTextAnchorTextSegment {
  return {
    ...data,
    endIndex: data["endIndex"] !== undefined ? BigInt(data["endIndex"]) : undefined,
    startIndex: data["startIndex"] !== undefined ? BigInt(data["startIndex"]) : undefined,
  };
}

/**
 * This message is used for text changes aka. OCR corrections.
 */
export interface GoogleCloudDocumentaiV1DocumentTextChange {
  /**
   * The text that replaces the text identified in the `text_anchor`.
   */
  changedText?: string;
  /**
   * The history of this annotation.
   */
  provenance?: GoogleCloudDocumentaiV1DocumentProvenance[];
  /**
   * Provenance of the correction. Text anchor indexing into the Document.text.
   * There can only be a single `TextAnchor.text_segments` element. If the start
   * and end index of the text segment are the same, the text change is inserted
   * before that index.
   */
  textAnchor?: GoogleCloudDocumentaiV1DocumentTextAnchor;
}

function serializeGoogleCloudDocumentaiV1DocumentTextChange(data: any): GoogleCloudDocumentaiV1DocumentTextChange {
  return {
    ...data,
    textAnchor: data["textAnchor"] !== undefined ? serializeGoogleCloudDocumentaiV1DocumentTextAnchor(data["textAnchor"]) : undefined,
  };
}

function deserializeGoogleCloudDocumentaiV1DocumentTextChange(data: any): GoogleCloudDocumentaiV1DocumentTextChange {
  return {
    ...data,
    textAnchor: data["textAnchor"] !== undefined ? deserializeGoogleCloudDocumentaiV1DocumentTextAnchor(data["textAnchor"]) : undefined,
  };
}

/**
 * A vertex represents a 2D point in the image. NOTE: the normalized vertex
 * coordinates are relative to the original image and range from 0 to 1.
 */
export interface GoogleCloudDocumentaiV1NormalizedVertex {
  /**
   * X coordinate.
   */
  x?: number;
  /**
   * Y coordinate (starts from the top of the image).
   */
  y?: number;
}

/**
 * A vertex represents a 2D point in the image. NOTE: the vertex coordinates
 * are in the same scale as the original image.
 */
export interface GoogleCloudDocumentaiV1Vertex {
  /**
   * X coordinate.
   */
  x?: number;
  /**
   * Y coordinate (starts from the top of the image).
   */
  y?: number;
}

/**
 * Specifies the audit configuration for a service. The configuration
 * determines which permission types are logged, and what identities, if any,
 * are exempted from logging. An AuditConfig must have one or more
 * AuditLogConfigs. If there are AuditConfigs for both `allServices` and a
 * specific service, the union of the two AuditConfigs is used for that service:
 * the log_types specified in each AuditConfig are enabled, and the
 * exempted_members in each AuditLogConfig are exempted. Example Policy with
 * multiple AuditConfigs: { "audit_configs": [ { "service": "allServices",
 * "audit_log_configs": [ { "log_type": "DATA_READ", "exempted_members": [
 * "user:jose@example.com" ] }, { "log_type": "DATA_WRITE" }, { "log_type":
 * "ADMIN_READ" } ] }, { "service": "sampleservice.googleapis.com",
 * "audit_log_configs": [ { "log_type": "DATA_READ" }, { "log_type":
 * "DATA_WRITE", "exempted_members": [ "user:aliya@example.com" ] } ] } ] } For
 * sampleservice, this policy enables DATA_READ, DATA_WRITE and ADMIN_READ
 * logging. It also exempts `jose@example.com` from DATA_READ logging, and
 * `aliya@example.com` from DATA_WRITE logging.
 */
export interface GoogleIamV1AuditConfig {
  /**
   * The configuration for logging of each type of permission.
   */
  auditLogConfigs?: GoogleIamV1AuditLogConfig[];
  /**
   * Specifies a service that will be enabled for audit logging. For example,
   * `storage.googleapis.com`, `cloudsql.googleapis.com`. `allServices` is a
   * special value that covers all services.
   */
  service?: string;
}

/**
 * Provides the configuration for logging a type of permissions. Example: {
 * "audit_log_configs": [ { "log_type": "DATA_READ", "exempted_members": [
 * "user:jose@example.com" ] }, { "log_type": "DATA_WRITE" } ] } This enables
 * 'DATA_READ' and 'DATA_WRITE' logging, while exempting jose@example.com from
 * DATA_READ logging.
 */
export interface GoogleIamV1AuditLogConfig {
  /**
   * Specifies the identities that do not cause logging for this type of
   * permission. Follows the same format of Binding.members.
   */
  exemptedMembers?: string[];
  /**
   * The log type that this config enables.
   */
  logType?:  | "LOG_TYPE_UNSPECIFIED" | "ADMIN_READ" | "DATA_WRITE" | "DATA_READ";
}

/**
 * Associates `members`, or principals, with a `role`.
 */
export interface GoogleIamV1Binding {
  /**
   * The condition that is associated with this binding. If the condition
   * evaluates to `true`, then this binding applies to the current request. If
   * the condition evaluates to `false`, then this binding does not apply to the
   * current request. However, a different role binding might grant the same
   * role to one or more of the principals in this binding. To learn which
   * resources support conditions in their IAM policies, see the [IAM
   * documentation](https://cloud.google.com/iam/help/conditions/resource-policies).
   */
  condition?: GoogleTypeExpr;
  /**
   * Specifies the principals requesting access for a Google Cloud resource.
   * `members` can have the following values: * `allUsers`: A special identifier
   * that represents anyone who is on the internet; with or without a Google
   * account. * `allAuthenticatedUsers`: A special identifier that represents
   * anyone who is authenticated with a Google account or a service account.
   * Does not include identities that come from external identity providers
   * (IdPs) through identity federation. * `user:{emailid}`: An email address
   * that represents a specific Google account. For example, `alice@example.com`
   * . * `serviceAccount:{emailid}`: An email address that represents a Google
   * service account. For example, `my-other-app@appspot.gserviceaccount.com`. *
   * `serviceAccount:{projectid}.svc.id.goog[{namespace}/{kubernetes-sa}]`: An
   * identifier for a [Kubernetes service
   * account](https://cloud.google.com/kubernetes-engine/docs/how-to/kubernetes-service-accounts).
   * For example, `my-project.svc.id.goog[my-namespace/my-kubernetes-sa]`. *
   * `group:{emailid}`: An email address that represents a Google group. For
   * example, `admins@example.com`. * `domain:{domain}`: The G Suite domain
   * (primary) that represents all the users of that domain. For example,
   * `google.com` or `example.com`. * `deleted:user:{emailid}?uid={uniqueid}`:
   * An email address (plus unique identifier) representing a user that has been
   * recently deleted. For example,
   * `alice@example.com?uid=123456789012345678901`. If the user is recovered,
   * this value reverts to `user:{emailid}` and the recovered user retains the
   * role in the binding. * `deleted:serviceAccount:{emailid}?uid={uniqueid}`:
   * An email address (plus unique identifier) representing a service account
   * that has been recently deleted. For example,
   * `my-other-app@appspot.gserviceaccount.com?uid=123456789012345678901`. If
   * the service account is undeleted, this value reverts to
   * `serviceAccount:{emailid}` and the undeleted service account retains the
   * role in the binding. * `deleted:group:{emailid}?uid={uniqueid}`: An email
   * address (plus unique identifier) representing a Google group that has been
   * recently deleted. For example,
   * `admins@example.com?uid=123456789012345678901`. If the group is recovered,
   * this value reverts to `group:{emailid}` and the recovered group retains the
   * role in the binding.
   */
  members?: string[];
  /**
   * Role that is assigned to the list of `members`, or principals. For
   * example, `roles/viewer`, `roles/editor`, or `roles/owner`.
   */
  role?: string;
}

/**
 * An Identity and Access Management (IAM) policy, which specifies access
 * controls for Google Cloud resources. A `Policy` is a collection of
 * `bindings`. A `binding` binds one or more `members`, or principals, to a
 * single `role`. Principals can be user accounts, service accounts, Google
 * groups, and domains (such as G Suite). A `role` is a named list of
 * permissions; each `role` can be an IAM predefined role or a user-created
 * custom role. For some types of Google Cloud resources, a `binding` can also
 * specify a `condition`, which is a logical expression that allows access to a
 * resource only if the expression evaluates to `true`. A condition can add
 * constraints based on attributes of the request, the resource, or both. To
 * learn which resources support conditions in their IAM policies, see the [IAM
 * documentation](https://cloud.google.com/iam/help/conditions/resource-policies).
 * **JSON example:** { "bindings": [ { "role":
 * "roles/resourcemanager.organizationAdmin", "members": [
 * "user:mike@example.com", "group:admins@example.com", "domain:google.com",
 * "serviceAccount:my-project-id@appspot.gserviceaccount.com" ] }, { "role":
 * "roles/resourcemanager.organizationViewer", "members": [
 * "user:eve@example.com" ], "condition": { "title": "expirable access",
 * "description": "Does not grant access after Sep 2020", "expression":
 * "request.time < timestamp('2020-10-01T00:00:00.000Z')", } } ], "etag":
 * "BwWWja0YfJA=", "version": 3 } **YAML example:** bindings: - members: -
 * user:mike@example.com - group:admins@example.com - domain:google.com -
 * serviceAccount:my-project-id@appspot.gserviceaccount.com role:
 * roles/resourcemanager.organizationAdmin - members: - user:eve@example.com
 * role: roles/resourcemanager.organizationViewer condition: title: expirable
 * access description: Does not grant access after Sep 2020 expression:
 * request.time < timestamp('2020-10-01T00:00:00.000Z') etag: BwWWja0YfJA=
 * version: 3 For a description of IAM and its features, see the [IAM
 * documentation](https://cloud.google.com/iam/docs/).
 */
export interface GoogleIamV1Policy {
  /**
   * Specifies cloud audit logging configuration for this policy.
   */
  auditConfigs?: GoogleIamV1AuditConfig[];
  /**
   * Associates a list of `members`, or principals, with a `role`. Optionally,
   * may specify a `condition` that determines how and when the `bindings` are
   * applied. Each of the `bindings` must contain at least one principal. The
   * `bindings` in a `Policy` can refer to up to 1,500 principals; up to 250 of
   * these principals can be Google groups. Each occurrence of a principal
   * counts towards these limits. For example, if the `bindings` grant 50
   * different roles to `user:alice@example.com`, and not to any other
   * principal, then you can add another 1,450 principals to the `bindings` in
   * the `Policy`.
   */
  bindings?: GoogleIamV1Binding[];
  /**
   * `etag` is used for optimistic concurrency control as a way to help prevent
   * simultaneous updates of a policy from overwriting each other. It is
   * strongly suggested that systems make use of the `etag` in the
   * read-modify-write cycle to perform policy updates in order to avoid race
   * conditions: An `etag` is returned in the response to `getIamPolicy`, and
   * systems are expected to put that etag in the request to `setIamPolicy` to
   * ensure that their change will be applied to the same version of the policy.
   * **Important:** If you use IAM Conditions, you must include the `etag` field
   * whenever you call `setIamPolicy`. If you omit this field, then IAM allows
   * you to overwrite a version `3` policy with a version `1` policy, and all of
   * the conditions in the version `3` policy are lost.
   */
  etag?: Uint8Array;
  /**
   * Specifies the format of the policy. Valid values are `0`, `1`, and `3`.
   * Requests that specify an invalid value are rejected. Any operation that
   * affects conditional role bindings must specify version `3`. This
   * requirement applies to the following operations: * Getting a policy that
   * includes a conditional role binding * Adding a conditional role binding to
   * a policy * Changing a conditional role binding in a policy * Removing any
   * role binding, with or without a condition, from a policy that includes
   * conditions **Important:** If you use IAM Conditions, you must include the
   * `etag` field whenever you call `setIamPolicy`. If you omit this field, then
   * IAM allows you to overwrite a version `3` policy with a version `1` policy,
   * and all of the conditions in the version `3` policy are lost. If a policy
   * does not include any conditions, operations on that policy may specify any
   * valid version or leave the field unset. To learn which resources support
   * conditions in their IAM policies, see the [IAM
   * documentation](https://cloud.google.com/iam/help/conditions/resource-policies).
   */
  version?: number;
}

function serializeGoogleIamV1Policy(data: any): GoogleIamV1Policy {
  return {
    ...data,
    etag: data["etag"] !== undefined ? encodeBase64(data["etag"]) : undefined,
  };
}

function deserializeGoogleIamV1Policy(data: any): GoogleIamV1Policy {
  return {
    ...data,
    etag: data["etag"] !== undefined ? decodeBase64(data["etag"] as string) : undefined,
  };
}

/**
 * Represents the information about user's working hours during one day. Note
 * that a period on Monday from 18:00 - 00:00 is represented as a triplet (1,
 * 1080, 1440).
 */
export interface GoogleInternalAppsWaldoV1alphaAvailabilityPeriod {
  /**
   * Day of week, 0 for Sunday, 1 for Monday, ...
   */
  dayOfWeek?: number;
  /**
   * Period end, in minutes from the start of the day, exclusive.
   */
  periodEndMinutes?: number;
  /**
   * Period start, in minutes from the start of the day, inclusive.
   */
  periodStartMinutes?: number;
}

/**
 * The status indicating the user is temporarily busy and there is not a more
 * specific status derived from calendar that applies (e.g., InMeeting or
 * DoNotDisturb).
 */
export interface GoogleInternalAppsWaldoV1alphaCalendarBusy {
  /**
   * The time when the user will either stop being committed or change
   * commitment type (i.e. InMeeting, DoNotDisturb, Busy or OutOfOffice < Xh).
   * Note that the goal of this field is to provide information to help users
   * decide how to communicate with a user (see also http://shortn/_wXYXtZScgh).
   */
  committedUntil?: Date;
  /**
   * TODO(b/265939748) To be removed, always false.
   */
  committedUntilIsMixed?: boolean;
  /**
   * The summary of the corresponding event in Calendar.
   */
  eventSummary?: string;
  /**
   * The next time when the user will be available, i.e., when their status
   * will be neither InMeeting, CalendarBusy, DoNotDisturb, OutsideWorkingHours,
   * nor OutOfOffice.
   */
  nextAvailable?: Date;
  /**
   * The time when the user will stop being occupied, i.e., when their status
   * will be neither inMeeting, Busy nor DoNotDisturb.
   */
  occupiedUntil?: Date;
}

function serializeGoogleInternalAppsWaldoV1alphaCalendarBusy(data: any): GoogleInternalAppsWaldoV1alphaCalendarBusy {
  return {
    ...data,
    committedUntil: data["committedUntil"] !== undefined ? data["committedUntil"].toISOString() : undefined,
    nextAvailable: data["nextAvailable"] !== undefined ? data["nextAvailable"].toISOString() : undefined,
    occupiedUntil: data["occupiedUntil"] !== undefined ? data["occupiedUntil"].toISOString() : undefined,
  };
}

function deserializeGoogleInternalAppsWaldoV1alphaCalendarBusy(data: any): GoogleInternalAppsWaldoV1alphaCalendarBusy {
  return {
    ...data,
    committedUntil: data["committedUntil"] !== undefined ? new Date(data["committedUntil"]) : undefined,
    nextAvailable: data["nextAvailable"] !== undefined ? new Date(data["nextAvailable"]) : undefined,
    occupiedUntil: data["occupiedUntil"] !== undefined ? new Date(data["occupiedUntil"]) : undefined,
  };
}

/**
 * Custom location specified by the user.
 */
export interface GoogleInternalAppsWaldoV1alphaCustomLocation {
  /**
   * Geographic location as geo coordinates.
   */
  geoCoordinates?: GoogleTypeLatLng;
  /**
   * The custom location label as a string entered manually by the user.
   */
  label?: string;
  /**
   * Geographic location as free-form text.
   */
  location?: string;
}

/**
 * The status indicating the user should not be disturbed.
 */
export interface GoogleInternalAppsWaldoV1alphaDoNotDisturb {
  /**
   * The time when the user will either stop being committed or change
   * commitment type (i.e. InMeeting, DoNotDisturb, Busy or OutOfOffice < Xh).
   * Note that the goal of this field is to provide information to help users
   * decide how to communicate with a user (see also http://shortn/_wXYXtZScgh).
   */
  committedUntil?: Date;
  /**
   * TODO(b/265939748) To be removed, always false.
   */
  committedUntilIsMixed?: boolean;
  /**
   * The next time when the user will be available, i.e., when their status
   * will be neither InMeeting, CalendarBusy, DoNotDisturb, OutsideWorkingHours,
   * nor OutOfOffice.
   */
  nextAvailable?: Date;
  /**
   * The time when the user will stop being occupied, i.e., when their status
   * will be neither inMeeting, Busy nor DoNotDisturb.
   */
  occupiedUntil?: Date;
}

function serializeGoogleInternalAppsWaldoV1alphaDoNotDisturb(data: any): GoogleInternalAppsWaldoV1alphaDoNotDisturb {
  return {
    ...data,
    committedUntil: data["committedUntil"] !== undefined ? data["committedUntil"].toISOString() : undefined,
    nextAvailable: data["nextAvailable"] !== undefined ? data["nextAvailable"].toISOString() : undefined,
    occupiedUntil: data["occupiedUntil"] !== undefined ? data["occupiedUntil"].toISOString() : undefined,
  };
}

function deserializeGoogleInternalAppsWaldoV1alphaDoNotDisturb(data: any): GoogleInternalAppsWaldoV1alphaDoNotDisturb {
  return {
    ...data,
    committedUntil: data["committedUntil"] !== undefined ? new Date(data["committedUntil"]) : undefined,
    nextAvailable: data["nextAvailable"] !== undefined ? new Date(data["nextAvailable"]) : undefined,
    occupiedUntil: data["occupiedUntil"] !== undefined ? new Date(data["occupiedUntil"]) : undefined,
  };
}

/**
 * Home location.
 */
export interface GoogleInternalAppsWaldoV1alphaHomeLocation {
}

/**
 * The status indicating that no other status applies.
 */
export interface GoogleInternalAppsWaldoV1alphaInactive {
}

/**
 * The status indicating the user is in a meeting.
 */
export interface GoogleInternalAppsWaldoV1alphaInMeeting {
  /**
   * The time when the user will either stop being committed or change
   * commitment type (i.e. InMeeting, DoNotDisturb, Busy or OutOfOffice < Xh).
   * Note that the goal of this field is to provide information to help users
   * decide how to communicate with a user (see also http://shortn/_wXYXtZScgh).
   */
  committedUntil?: Date;
  /**
   * TODO(b/265939748) To be removed, always false.
   */
  committedUntilIsMixed?: boolean;
  /**
   * The summary of the corresponding event in Calendar.
   */
  eventSummary?: string;
  /**
   * The time when the user will stop being in a meeting.
   */
  inMeetingsUntil?: Date;
  /**
   * The next time when the user will be available, i.e., when their status
   * will be neither InMeeting, CalendarBusy, DoNotDisturb, OutsideWorkingHours,
   * nor OutOfOffice.
   */
  nextAvailable?: Date;
  /**
   * The time when the user will stop being occupied, i.e., when their status
   * will be neither InMeeting, Busy nor DoNotDisturb.
   */
  occupiedUntil?: Date;
}

function serializeGoogleInternalAppsWaldoV1alphaInMeeting(data: any): GoogleInternalAppsWaldoV1alphaInMeeting {
  return {
    ...data,
    committedUntil: data["committedUntil"] !== undefined ? data["committedUntil"].toISOString() : undefined,
    inMeetingsUntil: data["inMeetingsUntil"] !== undefined ? data["inMeetingsUntil"].toISOString() : undefined,
    nextAvailable: data["nextAvailable"] !== undefined ? data["nextAvailable"].toISOString() : undefined,
    occupiedUntil: data["occupiedUntil"] !== undefined ? data["occupiedUntil"].toISOString() : undefined,
  };
}

function deserializeGoogleInternalAppsWaldoV1alphaInMeeting(data: any): GoogleInternalAppsWaldoV1alphaInMeeting {
  return {
    ...data,
    committedUntil: data["committedUntil"] !== undefined ? new Date(data["committedUntil"]) : undefined,
    inMeetingsUntil: data["inMeetingsUntil"] !== undefined ? new Date(data["inMeetingsUntil"]) : undefined,
    nextAvailable: data["nextAvailable"] !== undefined ? new Date(data["nextAvailable"]) : undefined,
    occupiedUntil: data["occupiedUntil"] !== undefined ? new Date(data["occupiedUntil"]) : undefined,
  };
}

/**
 * Context which helps to determine the user's local time.
 */
export interface GoogleInternalAppsWaldoV1alphaLocalTimeContext {
  /**
   * The current time zone of the user. Represented as a valid time zone ID
   * from Olson database, like "Europe/Zurich" (see
   * http://google3/i18n/identifiers/data/timezones.txt).
   */
  timeZone?: string;
}

/**
 * Office location.
 */
export interface GoogleInternalAppsWaldoV1alphaOfficeLocation {
  /**
   * Experimental. Can change or disappear without warning or notice.
   * References a building from
   * http://google3/ccc/hosted/api/rosy/resources/calendar/building.proto For
   * example "US-NYC-9TH".
   */
  experimentalBuildingId?: string;
  /**
   * Experimental. Can change or disappear without warning or notice. The desk
   * id. For example "11E358K".
   */
  experimentalDeskId?: string;
  /**
   * Experimental. Can change or disappear without warning or notice. The floor
   * id. For example "11".
   */
  experimentalFloorId?: string;
}

/**
 * The status indicating the user is out of office.
 */
export interface GoogleInternalAppsWaldoV1alphaOutOfOffice {
  /**
   * The closest time when the user will be available after this OOO block.
   * This might be different from the end of the OOO block in Calendar, since
   * the OOO block might end on Friday evening, and then the user is outside
   * working hours.
   */
  comeBackTime?: Date;
  /**
   * The time when the user will either stop being committed or change
   * commitment type (i.e. InMeeting, DoNotDisturb, Busy or OutOfOffice < Xh).
   * Note that the goal of this field is to provide information to help users
   * decide how to communicate with a user (see also http://shortn/_wXYXtZScgh).
   * Note that if this OOO block is large (>=Xh), committed_until is not set.
   */
  committedUntil?: Date;
  /**
   * TODO(b/265939748) To be removed, always false.
   */
  committedUntilIsMixed?: boolean;
  /**
   * The summary of the corresponding OOO block in Calendar. This is entered by
   * the user, so we return it "as is" - no i18n.
   */
  eventSummary?: string;
}

function serializeGoogleInternalAppsWaldoV1alphaOutOfOffice(data: any): GoogleInternalAppsWaldoV1alphaOutOfOffice {
  return {
    ...data,
    comeBackTime: data["comeBackTime"] !== undefined ? data["comeBackTime"].toISOString() : undefined,
    committedUntil: data["committedUntil"] !== undefined ? data["committedUntil"].toISOString() : undefined,
  };
}

function deserializeGoogleInternalAppsWaldoV1alphaOutOfOffice(data: any): GoogleInternalAppsWaldoV1alphaOutOfOffice {
  return {
    ...data,
    comeBackTime: data["comeBackTime"] !== undefined ? new Date(data["comeBackTime"]) : undefined,
    committedUntil: data["committedUntil"] !== undefined ? new Date(data["committedUntil"]) : undefined,
  };
}

/**
 * The status indicating the user doesn't work at this time.
 */
export interface GoogleInternalAppsWaldoV1alphaOutsideWorkingHours {
  /**
   * The closest time when the user will be available after this block. This
   * might be different from the start of the working hours in Calendar, because
   * the given OutsideWorkingHours interval might be followed by OOO.
   */
  comeBackTime?: Date;
}

function serializeGoogleInternalAppsWaldoV1alphaOutsideWorkingHours(data: any): GoogleInternalAppsWaldoV1alphaOutsideWorkingHours {
  return {
    ...data,
    comeBackTime: data["comeBackTime"] !== undefined ? data["comeBackTime"].toISOString() : undefined,
  };
}

function deserializeGoogleInternalAppsWaldoV1alphaOutsideWorkingHours(data: any): GoogleInternalAppsWaldoV1alphaOutsideWorkingHours {
  return {
    ...data,
    comeBackTime: data["comeBackTime"] !== undefined ? new Date(data["comeBackTime"]) : undefined,
  };
}

/**
 * A time range, which includes the start and excludes the end.
 */
export interface GoogleInternalAppsWaldoV1alphaTimeRange {
  /**
   * End point of the range, exclusive.
   */
  endTime?: Date;
  /**
   * Starting point of the range, inclusive.
   */
  startTime?: Date;
}

function serializeGoogleInternalAppsWaldoV1alphaTimeRange(data: any): GoogleInternalAppsWaldoV1alphaTimeRange {
  return {
    ...data,
    endTime: data["endTime"] !== undefined ? data["endTime"].toISOString() : undefined,
    startTime: data["startTime"] !== undefined ? data["startTime"].toISOString() : undefined,
  };
}

function deserializeGoogleInternalAppsWaldoV1alphaTimeRange(data: any): GoogleInternalAppsWaldoV1alphaTimeRange {
  return {
    ...data,
    endTime: data["endTime"] !== undefined ? new Date(data["endTime"]) : undefined,
    startTime: data["startTime"] !== undefined ? new Date(data["startTime"]) : undefined,
  };
}

export interface GoogleInternalAppsWaldoV1alphaUpcomingCommitmentContext {
  /**
   * The status of the commitment above.
   */
  nextCommitmentStatus?: GoogleInternalAppsWaldoV1alphaUserStatus;
  /**
   * The most relevant upcoming commitment (InMeeting, DoNotDisturb,
   * CalendarBusy or OutOfOffice). This context is set only if there is an
   * upcoming commitment to show, and only on non commitments. Priority is given
   * to the next closest commitment if its start is close enough to this event,
   * otherwise the next large OOO if there is one.
   */
  nextCommitmentTime?: Date;
}

function serializeGoogleInternalAppsWaldoV1alphaUpcomingCommitmentContext(data: any): GoogleInternalAppsWaldoV1alphaUpcomingCommitmentContext {
  return {
    ...data,
    nextCommitmentStatus: data["nextCommitmentStatus"] !== undefined ? serializeGoogleInternalAppsWaldoV1alphaUserStatus(data["nextCommitmentStatus"]) : undefined,
    nextCommitmentTime: data["nextCommitmentTime"] !== undefined ? data["nextCommitmentTime"].toISOString() : undefined,
  };
}

function deserializeGoogleInternalAppsWaldoV1alphaUpcomingCommitmentContext(data: any): GoogleInternalAppsWaldoV1alphaUpcomingCommitmentContext {
  return {
    ...data,
    nextCommitmentStatus: data["nextCommitmentStatus"] !== undefined ? deserializeGoogleInternalAppsWaldoV1alphaUserStatus(data["nextCommitmentStatus"]) : undefined,
    nextCommitmentTime: data["nextCommitmentTime"] !== undefined ? new Date(data["nextCommitmentTime"]) : undefined,
  };
}

/**
 * The context indicating the user's upcoming Out of Office event.
 */
export interface GoogleInternalAppsWaldoV1alphaUpcomingOooContext {
  /**
   * The future period of absence. The start of this timerange is the start of
   * the future Out of Office event. The end of this timerange represents the
   * come back time of the user from that future OOO event. Note that the come
   * back time might be different (greater) than the end of the corresponding
   * future OOO event due to other non-working user status intervals that it may
   * be followed by.
   */
  timeRange?: GoogleInternalAppsWaldoV1alphaTimeRange;
}

function serializeGoogleInternalAppsWaldoV1alphaUpcomingOooContext(data: any): GoogleInternalAppsWaldoV1alphaUpcomingOooContext {
  return {
    ...data,
    timeRange: data["timeRange"] !== undefined ? serializeGoogleInternalAppsWaldoV1alphaTimeRange(data["timeRange"]) : undefined,
  };
}

function deserializeGoogleInternalAppsWaldoV1alphaUpcomingOooContext(data: any): GoogleInternalAppsWaldoV1alphaUpcomingOooContext {
  return {
    ...data,
    timeRange: data["timeRange"] !== undefined ? deserializeGoogleInternalAppsWaldoV1alphaTimeRange(data["timeRange"]) : undefined,
  };
}

/**
 * The current and future availabilities of a user. The response contains a
 * timeline, which starts before or at the request time, and the timeline is
 * split into a set of disjoint intervals (without gaps), where the first range
 * always contains the request time. Each range represents what should be
 * displayed in the UI during this time range. The time range might be different
 * from the actual time range of the underlying status. For example, if the user
 * is OOO from 09:00 to 10:00, and a request is made at 8:00, the response might
 * contain two intervals: [08:00, 09:00) - "User is INACTIVE, but leaving the
 * office soon" [09:00, 10:00) - "User is OOO till 10:00" For intervals that
 * don't have a clear availability signal coming from Calendar (e.g. OOO), we
 * return INACTIVE. For more details, please see
 * https://docs.google.com/presentation/d/1ADCTxGawjF9UqMnfuVrVNxGvdyjeiV8h4D7p0a9zYgw/edit#slide=id.g3e2824ac6c_12_94
 * The service returns availabilities for some short period of time - likely one
 * day, but the client should stick to the "next_poll_time" to decide when to
 * query the server again at the latest. Below there is an example response from
 * the server. Let's assume the client calls the service at 17:59:45. The client
 * receives the message and, assuming its current time is between [17:59:45,
 * 18:00:00), it displays "inactive". When the current time becomes 18:00:00 it
 * displays "outside working hours". At 18:00:40 the client issues another rpc
 * which will return the availabilities for the next minute. The original
 * response looks like availabilities { time_range { start_time: 17:59:45
 * end_time: 18:00:00 } status { inactive {} } } availabilities { time_range {
 * start_time: 18:00:00 end_time: 18:00:45 } status { outside_working_hours { }
 * } } next_poll_time: 18:00:40
 */
export interface GoogleInternalAppsWaldoV1alphaUserAvailabilities {
  /**
   * A list of user availabilities having contiguous time ranges which are
   * ordered chronologically. The first one starts at the time of the request or
   * before, and is guaranteed to contain the request time. That means the first
   * element always indicates the current status of a user. A client that wants
   * to display a user's availability in real time should display the
   * availability whose time range contains the current time.
   */
  availabilities?: GoogleInternalAppsWaldoV1alphaUserAvailability[];
  /**
   * The time at which the client should issue the next availability query for
   * this user. This field should only be used to control the polling frequency.
   * This time is always before the end of the time range of the last
   * availability so that the client always knows the current availability.
   */
  nextPollTime?: Date;
  /**
   * Information about the user's working hours. This will only be set in case
   * working hours are enabled in their calendar settings.
   */
  workingHours?: GoogleInternalAppsWaldoV1alphaWorkingHours;
}

function serializeGoogleInternalAppsWaldoV1alphaUserAvailabilities(data: any): GoogleInternalAppsWaldoV1alphaUserAvailabilities {
  return {
    ...data,
    availabilities: data["availabilities"] !== undefined ? data["availabilities"].map((item: any) => (serializeGoogleInternalAppsWaldoV1alphaUserAvailability(item))) : undefined,
    nextPollTime: data["nextPollTime"] !== undefined ? data["nextPollTime"].toISOString() : undefined,
  };
}

function deserializeGoogleInternalAppsWaldoV1alphaUserAvailabilities(data: any): GoogleInternalAppsWaldoV1alphaUserAvailabilities {
  return {
    ...data,
    availabilities: data["availabilities"] !== undefined ? data["availabilities"].map((item: any) => (deserializeGoogleInternalAppsWaldoV1alphaUserAvailability(item))) : undefined,
    nextPollTime: data["nextPollTime"] !== undefined ? new Date(data["nextPollTime"]) : undefined,
  };
}

/**
 * A single availability range. The displayed status should be the same during
 * the entire time range.
 */
export interface GoogleInternalAppsWaldoV1alphaUserAvailability {
  /**
   * The contexts contain additional information about the current user's
   * availability or its upcoming changes. The client doesn't need to extract
   * certain bits to visualize the status or apply custom logic based on the
   * content of this field: the status field should contain everything needed
   * for the correct visualization.
   */
  contexts?: GoogleInternalAppsWaldoV1alphaUserContext;
  /**
   * The user status during the time range.
   */
  status?: GoogleInternalAppsWaldoV1alphaUserStatus;
  /**
   * The time range when this availability should be displayed.
   */
  timeRange?: GoogleInternalAppsWaldoV1alphaTimeRange;
}

function serializeGoogleInternalAppsWaldoV1alphaUserAvailability(data: any): GoogleInternalAppsWaldoV1alphaUserAvailability {
  return {
    ...data,
    contexts: data["contexts"] !== undefined ? serializeGoogleInternalAppsWaldoV1alphaUserContext(data["contexts"]) : undefined,
    status: data["status"] !== undefined ? serializeGoogleInternalAppsWaldoV1alphaUserStatus(data["status"]) : undefined,
    timeRange: data["timeRange"] !== undefined ? serializeGoogleInternalAppsWaldoV1alphaTimeRange(data["timeRange"]) : undefined,
  };
}

function deserializeGoogleInternalAppsWaldoV1alphaUserAvailability(data: any): GoogleInternalAppsWaldoV1alphaUserAvailability {
  return {
    ...data,
    contexts: data["contexts"] !== undefined ? deserializeGoogleInternalAppsWaldoV1alphaUserContext(data["contexts"]) : undefined,
    status: data["status"] !== undefined ? deserializeGoogleInternalAppsWaldoV1alphaUserStatus(data["status"]) : undefined,
    timeRange: data["timeRange"] !== undefined ? deserializeGoogleInternalAppsWaldoV1alphaTimeRange(data["timeRange"]) : undefined,
  };
}

/**
 * Additional context about the user's current and/or future availability to
 * give a better understanding of the status ("Working from Zurich").
 */
export interface GoogleInternalAppsWaldoV1alphaUserContext {
  /**
   * Helps to determine the user's local time by providing their current time
   * zone.
   */
  localTime?: GoogleInternalAppsWaldoV1alphaLocalTimeContext;
  /**
   * Information about upcoming events.
   */
  upcomingCommitmentContext?: GoogleInternalAppsWaldoV1alphaUpcomingCommitmentContext;
  /**
   * Set if user has upcoming OOO.
   */
  upcomingOoo?: GoogleInternalAppsWaldoV1alphaUpcomingOooContext;
  /**
   * Set if the user has a working location. Not just elsewhere (legacy name).
   */
  workingElsewhere?: GoogleInternalAppsWaldoV1alphaWorkingElsewhereContext;
}

function serializeGoogleInternalAppsWaldoV1alphaUserContext(data: any): GoogleInternalAppsWaldoV1alphaUserContext {
  return {
    ...data,
    upcomingCommitmentContext: data["upcomingCommitmentContext"] !== undefined ? serializeGoogleInternalAppsWaldoV1alphaUpcomingCommitmentContext(data["upcomingCommitmentContext"]) : undefined,
    upcomingOoo: data["upcomingOoo"] !== undefined ? serializeGoogleInternalAppsWaldoV1alphaUpcomingOooContext(data["upcomingOoo"]) : undefined,
  };
}

function deserializeGoogleInternalAppsWaldoV1alphaUserContext(data: any): GoogleInternalAppsWaldoV1alphaUserContext {
  return {
    ...data,
    upcomingCommitmentContext: data["upcomingCommitmentContext"] !== undefined ? deserializeGoogleInternalAppsWaldoV1alphaUpcomingCommitmentContext(data["upcomingCommitmentContext"]) : undefined,
    upcomingOoo: data["upcomingOoo"] !== undefined ? deserializeGoogleInternalAppsWaldoV1alphaUpcomingOooContext(data["upcomingOoo"]) : undefined,
  };
}

/**
 * Location of the user, which might be "home", for example, or an office
 * building, as well as a custom location specified by the user.
 */
export interface GoogleInternalAppsWaldoV1alphaUserLocation {
  /**
   * Indicates the user is working from some other location.
   */
  customLocation?: GoogleInternalAppsWaldoV1alphaCustomLocation;
  /**
   * Indicates the user is working from home.
   */
  homeLocation?: GoogleInternalAppsWaldoV1alphaHomeLocation;
  /**
   * Indicates the user is working from the office.
   */
  officeLocation?: GoogleInternalAppsWaldoV1alphaOfficeLocation;
}

/**
 * The actual status of the user. The message contains everything needed for
 * visualisation of this status.
 */
export interface GoogleInternalAppsWaldoV1alphaUserStatus {
  /**
   * Set if the user is temporarily busy and there is not a more specific
   * status derived from calendar that applies (e.g., InMeeting or
   * DoNotDisturb).
   */
  calendarBusy?: GoogleInternalAppsWaldoV1alphaCalendarBusy;
  /**
   * Set if the user is in a Focus Time block. Note that this is different than
   * Chat's Do not disturb status, but they may coincide, see:
   * go/focus-time-dnd.
   */
  doNotDisturb?: GoogleInternalAppsWaldoV1alphaDoNotDisturb;
  /**
   * Set if no other statuses apply.
   */
  inactive?: GoogleInternalAppsWaldoV1alphaInactive;
  /**
   * Set if the user is in a meeting.
   */
  inMeeting?: GoogleInternalAppsWaldoV1alphaInMeeting;
  /**
   * Set if the user is out of office.
   */
  outOfOffice?: GoogleInternalAppsWaldoV1alphaOutOfOffice;
  /**
   * Set if the user doesn't work at this time.
   */
  outsideWorkingHours?: GoogleInternalAppsWaldoV1alphaOutsideWorkingHours;
}

function serializeGoogleInternalAppsWaldoV1alphaUserStatus(data: any): GoogleInternalAppsWaldoV1alphaUserStatus {
  return {
    ...data,
    calendarBusy: data["calendarBusy"] !== undefined ? serializeGoogleInternalAppsWaldoV1alphaCalendarBusy(data["calendarBusy"]) : undefined,
    doNotDisturb: data["doNotDisturb"] !== undefined ? serializeGoogleInternalAppsWaldoV1alphaDoNotDisturb(data["doNotDisturb"]) : undefined,
    inMeeting: data["inMeeting"] !== undefined ? serializeGoogleInternalAppsWaldoV1alphaInMeeting(data["inMeeting"]) : undefined,
    outOfOffice: data["outOfOffice"] !== undefined ? serializeGoogleInternalAppsWaldoV1alphaOutOfOffice(data["outOfOffice"]) : undefined,
    outsideWorkingHours: data["outsideWorkingHours"] !== undefined ? serializeGoogleInternalAppsWaldoV1alphaOutsideWorkingHours(data["outsideWorkingHours"]) : undefined,
  };
}

function deserializeGoogleInternalAppsWaldoV1alphaUserStatus(data: any): GoogleInternalAppsWaldoV1alphaUserStatus {
  return {
    ...data,
    calendarBusy: data["calendarBusy"] !== undefined ? deserializeGoogleInternalAppsWaldoV1alphaCalendarBusy(data["calendarBusy"]) : undefined,
    doNotDisturb: data["doNotDisturb"] !== undefined ? deserializeGoogleInternalAppsWaldoV1alphaDoNotDisturb(data["doNotDisturb"]) : undefined,
    inMeeting: data["inMeeting"] !== undefined ? deserializeGoogleInternalAppsWaldoV1alphaInMeeting(data["inMeeting"]) : undefined,
    outOfOffice: data["outOfOffice"] !== undefined ? deserializeGoogleInternalAppsWaldoV1alphaOutOfOffice(data["outOfOffice"]) : undefined,
    outsideWorkingHours: data["outsideWorkingHours"] !== undefined ? deserializeGoogleInternalAppsWaldoV1alphaOutsideWorkingHours(data["outsideWorkingHours"]) : undefined,
  };
}

/**
 * The context providing the User Location (not just Elsewhere). This is a
 * legacy name from when it was only set for users working remotely, now it is
 * also set when the user is working from the office.
 */
export interface GoogleInternalAppsWaldoV1alphaWorkingElsewhereContext {
  /**
   * The new location of the user. Might represent home, office, or a custom
   * address on the map.
   */
  location?: GoogleInternalAppsWaldoV1alphaUserLocation;
}

/**
 * Information about the user's working hours.
 */
export interface GoogleInternalAppsWaldoV1alphaWorkingHours {
  /**
   * A list of availability periods representing the user's working hours as
   * configured in calendar.
   */
  availableTime?: GoogleInternalAppsWaldoV1alphaAvailabilityPeriod[];
}

/**
 * Id for message recipients, e.g. users, groups etc.
 */
export interface GoogleInternalCommunicationsInstantmessagingV1Id {
  /**
   * app is the tachyon client application that generated or is to receive a
   * message.
   */
  app?: string;
  /**
   * country_code is the E164_COUNTRY_CODE format country code for this id,
   * used as a hint for its region. E.g, "+1" will be used for North America,
   * "+86" will be used for China, etc. Should be filled only for RCS group id.
   */
  countryCode?: string;
  /**
   * id is a unique (for this type and app) identifier of a message source or
   * recipient.
   */
  id?: string;
  /**
   * location_hint is used as a hint for the user's region.
   */
  locationHint?: GoogleInternalCommunicationsInstantmessagingV1LocationHint;
  /**
   * Raw byte array containing encoded routing information. Clients of Tachyon
   * are expected to include the most recent routing_info_cookie that they have
   * received from the server in the requests that they make. Its format is
   * purposely opaque so that clients do not need to concern themselves with the
   * content of this field. This field is expected to be used primarily by
   * Tachygram clients for go/tachygram-groups to simplify the API contract for
   * group operations while reducing the need for unnecessary lookups.
   */
  routingInfoToken?: Uint8Array;
  /**
   * type defines what the id field contains, e.g. phone number, Fi-number,
   * Gaia ID etc.
   */
  type?:  | "UNSET" | "PHONE_NUMBER" | "GROUP_ID" | "FIREBALL_BOT" | "CALL_CONTROLLER" | "SUGGESTER" | "FI_ID" | "SYSTEM" | "DUO_BOT" | "MATCHBOX_ID" | "RCS_BOT" | "WIREBALL" | "SERVICE_ACCOUNT" | "DEVICE_ID" | "FOREIGN_RCS_GROUP" | "DITTO" | "EMAIL" | "GAIA_ID" | "LIGHTER_ID" | "OPAQUE_ID" | "SERVER" | "SHORT_CODE" | "CLOUDCAST_PLAYER_ID" | "CHROMOTING_ID" | "UNNORMALIZABLE_PHONE_NUMBER" | "NOT_KNOWN" | "ANDROID_ID" | "NEARBY_ID" | "WAZE_ID" | "GUEST" | "MESSAGES_DATA_DONATION" | "DUO_CLIP_ID" | "ACCOUNT_ID" | "CARRIER_ID" | "EXTERNAL_PARTNER_ID" | "UNAUTHENTICATED_USER_ID" | "SUPPORT_CASES_ID" | "FITBIT_P11_ID" | "SHORT_PHONE_NUMBER";
}

function serializeGoogleInternalCommunicationsInstantmessagingV1Id(data: any): GoogleInternalCommunicationsInstantmessagingV1Id {
  return {
    ...data,
    routingInfoToken: data["routingInfoToken"] !== undefined ? encodeBase64(data["routingInfoToken"]) : undefined,
  };
}

function deserializeGoogleInternalCommunicationsInstantmessagingV1Id(data: any): GoogleInternalCommunicationsInstantmessagingV1Id {
  return {
    ...data,
    routingInfoToken: data["routingInfoToken"] !== undefined ? decodeBase64(data["routingInfoToken"] as string) : undefined,
  };
}

/**
 * LocationHint is used to specify a location as well as format.
 */
export interface GoogleInternalCommunicationsInstantmessagingV1LocationHint {
  /**
   * the format of location.
   */
  format?:  | "UNKNOWN" | "E164_CALLING" | "ISO_3166_1_ALPHA_2";
  /**
   * Location is the location, provided in the format specified by format.
   */
  location?: string;
}

/**
 * This resource represents a long-running operation that is the result of a
 * network API call.
 */
export interface GoogleLongrunningOperation {
  /**
   * If the value is `false`, it means the operation is still in progress. If
   * `true`, the operation is completed, and either `error` or `response` is
   * available.
   */
  done?: boolean;
  /**
   * The error result of the operation in case of failure or cancellation.
   */
  error?: GoogleRpcStatus;
  /**
   * Service-specific metadata associated with the operation. It typically
   * contains progress information and common metadata such as create time. Some
   * services might not provide such metadata. Any method that returns a
   * long-running operation should document the metadata type, if any.
   */
  metadata?: {
    [key: string]: any
  };
  /**
   * The server-assigned name, which is only unique within the same service
   * that originally returns it. If you use the default HTTP mapping, the `name`
   * should be a resource name ending with `operations/{unique_id}`.
   */
  name?: string;
  /**
   * The normal response of the operation in case of success. If the original
   * method returns no data on success, such as `Delete`, the response is
   * `google.protobuf.Empty`. If the original method is standard
   * `Get`/`Create`/`Update`, the response should be the resource. For other
   * methods, the response should have the type `XxxResponse`, where `Xxx` is
   * the original method name. For example, if the original method name is
   * `TakeSnapshot()`, the inferred response type is `TakeSnapshotResponse`.
   */
  response?: {
    [key: string]: any
  };
}

/**
 * A generic empty message that you can re-use to avoid defining duplicated
 * empty messages in your APIs. A typical example is to use it as the request or
 * the response type of an API method. For instance: service Foo { rpc
 * Bar(google.protobuf.Empty) returns (google.protobuf.Empty); }
 */
export interface GoogleProtobufEmpty {
}

/**
 * The `Status` type defines a logical error model that is suitable for
 * different programming environments, including REST APIs and RPC APIs. It is
 * used by [gRPC](https://github.com/grpc). Each `Status` message contains three
 * pieces of data: error code, error message, and error details. You can find
 * out more about this error model and how to work with it in the [API Design
 * Guide](https://cloud.google.com/apis/design/errors).
 */
export interface GoogleRpcStatus {
  /**
   * The status code, which should be an enum value of google.rpc.Code.
   */
  code?: number;
  /**
   * A list of messages that carry the error details. There is a common set of
   * message types for APIs to use.
   */
  details?: {
    [key: string]: any
  }[];
  /**
   * A developer-facing error message, which should be in English. Any
   * user-facing error message should be localized and sent in the
   * google.rpc.Status.details field, or localized by the client.
   */
  message?: string;
}

/**
 * Represents a color in the RGBA color space. This representation is designed
 * for simplicity of conversion to/from color representations in various
 * languages over compactness. For example, the fields of this representation
 * can be trivially provided to the constructor of `java.awt.Color` in Java; it
 * can also be trivially provided to UIColor's `+colorWithRed:green:blue:alpha`
 * method in iOS; and, with just a little work, it can be easily formatted into
 * a CSS `rgba()` string in JavaScript. This reference page doesn't carry
 * information about the absolute color space that should be used to interpret
 * the RGB value (e.g. sRGB, Adobe RGB, DCI-P3, BT.2020, etc.). By default,
 * applications should assume the sRGB color space. When color equality needs to
 * be decided, implementations, unless documented otherwise, treat two colors as
 * equal if all their red, green, blue, and alpha values each differ by at most
 * 1e-5. Example (Java): import com.google.type.Color; // ... public static
 * java.awt.Color fromProto(Color protocolor) { float alpha =
 * protocolor.hasAlpha() ? protocolor.getAlpha().getValue() : 1.0; return new
 * java.awt.Color( protocolor.getRed(), protocolor.getGreen(),
 * protocolor.getBlue(), alpha); } public static Color toProto(java.awt.Color
 * color) { float red = (float) color.getRed(); float green = (float)
 * color.getGreen(); float blue = (float) color.getBlue(); float denominator =
 * 255.0; Color.Builder resultBuilder = Color .newBuilder() .setRed(red /
 * denominator) .setGreen(green / denominator) .setBlue(blue / denominator); int
 * alpha = color.getAlpha(); if (alpha != 255) { result.setAlpha( FloatValue
 * .newBuilder() .setValue(((float) alpha) / denominator) .build()); } return
 * resultBuilder.build(); } // ... Example (iOS / Obj-C): // ... static UIColor*
 * fromProto(Color* protocolor) { float red = [protocolor red]; float green =
 * [protocolor green]; float blue = [protocolor blue]; FloatValue* alpha_wrapper
 * = [protocolor alpha]; float alpha = 1.0; if (alpha_wrapper != nil) { alpha =
 * [alpha_wrapper value]; } return [UIColor colorWithRed:red green:green
 * blue:blue alpha:alpha]; } static Color* toProto(UIColor* color) { CGFloat
 * red, green, blue, alpha; if (![color getRed:&red green:&green blue:&blue
 * alpha:&alpha]) { return nil; } Color* result = [[Color alloc] init]; [result
 * setRed:red]; [result setGreen:green]; [result setBlue:blue]; if (alpha <=
 * 0.9999) { [result setAlpha:floatWrapperWithValue(alpha)]; } [result
 * autorelease]; return result; } // ... Example (JavaScript): // ... var
 * protoToCssColor = function(rgb_color) { var redFrac = rgb_color.red || 0.0;
 * var greenFrac = rgb_color.green || 0.0; var blueFrac = rgb_color.blue || 0.0;
 * var red = Math.floor(redFrac * 255); var green = Math.floor(greenFrac * 255);
 * var blue = Math.floor(blueFrac * 255); if (!('alpha' in rgb_color)) { return
 * rgbToCssColor(red, green, blue); } var alphaFrac = rgb_color.alpha.value ||
 * 0.0; var rgbParams = [red, green, blue].join(','); return ['rgba(',
 * rgbParams, ',', alphaFrac, ')'].join(''); }; var rgbToCssColor =
 * function(red, green, blue) { var rgbNumber = new Number((red << 16) | (green
 * << 8) | blue); var hexString = rgbNumber.toString(16); var missingZeros = 6 -
 * hexString.length; var resultBuilder = ['#']; for (var i = 0; i <
 * missingZeros; i++) { resultBuilder.push('0'); }
 * resultBuilder.push(hexString); return resultBuilder.join(''); }; // ...
 */
export interface GoogleTypeColor {
  /**
   * The fraction of this color that should be applied to the pixel. That is,
   * the final pixel color is defined by the equation: `pixel color = alpha *
   * (this color) + (1.0 - alpha) * (background color)` This means that a value
   * of 1.0 corresponds to a solid color, whereas a value of 0.0 corresponds to
   * a completely transparent color. This uses a wrapper message rather than a
   * simple float scalar so that it is possible to distinguish between a default
   * value and the value being unset. If omitted, this color object is rendered
   * as a solid color (as if the alpha value had been explicitly given a value
   * of 1.0).
   */
  alpha?: number;
  /**
   * The amount of blue in the color as a value in the interval [0, 1].
   */
  blue?: number;
  /**
   * The amount of green in the color as a value in the interval [0, 1].
   */
  green?: number;
  /**
   * The amount of red in the color as a value in the interval [0, 1].
   */
  red?: number;
}

/**
 * Represents a whole or partial calendar date, such as a birthday. The time of
 * day and time zone are either specified elsewhere or are insignificant. The
 * date is relative to the Gregorian Calendar. This can represent one of the
 * following: * A full date, with non-zero year, month, and day values. * A
 * month and day, with a zero year (for example, an anniversary). * A year on
 * its own, with a zero month and a zero day. * A year and month, with a zero
 * day (for example, a credit card expiration date). Related types: *
 * google.type.TimeOfDay * google.type.DateTime * google.protobuf.Timestamp
 */
export interface GoogleTypeDate {
  /**
   * Day of a month. Must be from 1 to 31 and valid for the year and month, or
   * 0 to specify a year by itself or a year and month where the day isn't
   * significant.
   */
  day?: number;
  /**
   * Month of a year. Must be from 1 to 12, or 0 to specify a year without a
   * month and day.
   */
  month?: number;
  /**
   * Year of the date. Must be from 1 to 9999, or 0 to specify a date without a
   * year.
   */
  year?: number;
}

/**
 * Represents civil time (or occasionally physical time). This type can
 * represent a civil time in one of a few possible ways: * When utc_offset is
 * set and time_zone is unset: a civil time on a calendar day with a particular
 * offset from UTC. * When time_zone is set and utc_offset is unset: a civil
 * time on a calendar day in a particular time zone. * When neither time_zone
 * nor utc_offset is set: a civil time on a calendar day in local time. The date
 * is relative to the Proleptic Gregorian Calendar. If year, month, or day are
 * 0, the DateTime is considered not to have a specific year, month, or day
 * respectively. This type may also be used to represent a physical time if all
 * the date and time fields are set and either case of the `time_offset` oneof
 * is set. Consider using `Timestamp` message for physical time instead. If your
 * use case also would like to store the user's timezone, that can be done in
 * another field. This type is more flexible than some applications may want.
 * Make sure to document and validate your application's limitations.
 */
export interface GoogleTypeDateTime {
  /**
   * Optional. Day of month. Must be from 1 to 31 and valid for the year and
   * month, or 0 if specifying a datetime without a day.
   */
  day?: number;
  /**
   * Optional. Hours of day in 24 hour format. Should be from 0 to 23, defaults
   * to 0 (midnight). An API may choose to allow the value "24:00:00" for
   * scenarios like business closing time.
   */
  hours?: number;
  /**
   * Optional. Minutes of hour of day. Must be from 0 to 59, defaults to 0.
   */
  minutes?: number;
  /**
   * Optional. Month of year. Must be from 1 to 12, or 0 if specifying a
   * datetime without a month.
   */
  month?: number;
  /**
   * Optional. Fractions of seconds in nanoseconds. Must be from 0 to
   * 999,999,999, defaults to 0.
   */
  nanos?: number;
  /**
   * Optional. Seconds of minutes of the time. Must normally be from 0 to 59,
   * defaults to 0. An API may allow the value 60 if it allows leap-seconds.
   */
  seconds?: number;
  /**
   * Time zone.
   */
  timeZone?: GoogleTypeTimeZone;
  /**
   * UTC offset. Must be whole seconds, between -18 hours and +18 hours. For
   * example, a UTC offset of -4:00 would be represented as { seconds: -14400 }.
   */
  utcOffset?: number /* Duration */;
  /**
   * Optional. Year of date. Must be from 1 to 9999, or 0 if specifying a
   * datetime without a year.
   */
  year?: number;
}

function serializeGoogleTypeDateTime(data: any): GoogleTypeDateTime {
  return {
    ...data,
    utcOffset: data["utcOffset"] !== undefined ? data["utcOffset"] : undefined,
  };
}

function deserializeGoogleTypeDateTime(data: any): GoogleTypeDateTime {
  return {
    ...data,
    utcOffset: data["utcOffset"] !== undefined ? data["utcOffset"] : undefined,
  };
}

/**
 * Represents a textual expression in the Common Expression Language (CEL)
 * syntax. CEL is a C-like expression language. The syntax and semantics of CEL
 * are documented at https://github.com/google/cel-spec. Example (Comparison):
 * title: "Summary size limit" description: "Determines if a summary is less
 * than 100 chars" expression: "document.summary.size() < 100" Example
 * (Equality): title: "Requestor is owner" description: "Determines if requestor
 * is the document owner" expression: "document.owner ==
 * request.auth.claims.email" Example (Logic): title: "Public documents"
 * description: "Determine whether the document should be publicly visible"
 * expression: "document.type != 'private' && document.type != 'internal'"
 * Example (Data Manipulation): title: "Notification string" description:
 * "Create a notification string with a timestamp." expression: "'New message
 * received at ' + string(document.create_time)" The exact variables and
 * functions that may be referenced within an expression are determined by the
 * service that evaluates it. See the service documentation for additional
 * information.
 */
export interface GoogleTypeExpr {
  /**
   * Optional. Description of the expression. This is a longer text which
   * describes the expression, e.g. when hovered over it in a UI.
   */
  description?: string;
  /**
   * Textual representation of an expression in Common Expression Language
   * syntax.
   */
  expression?: string;
  /**
   * Optional. String indicating the location of the expression for error
   * reporting, e.g. a file name and a position in the file.
   */
  location?: string;
  /**
   * Optional. Title for the expression, i.e. a short string describing its
   * purpose. This can be used e.g. in UIs which allow to enter the expression.
   */
  title?: string;
}

/**
 * Represents a time interval, encoded as a Timestamp start (inclusive) and a
 * Timestamp end (exclusive). The start must be less than or equal to the end.
 * When the start equals the end, the interval is empty (matches no time). When
 * both start and end are unspecified, the interval matches any time.
 */
export interface GoogleTypeInterval {
  /**
   * Optional. Exclusive end of the interval. If specified, a Timestamp
   * matching this interval will have to be before the end.
   */
  endTime?: Date;
  /**
   * Optional. Inclusive start of the interval. If specified, a Timestamp
   * matching this interval will have to be the same or after the start.
   */
  startTime?: Date;
}

function serializeGoogleTypeInterval(data: any): GoogleTypeInterval {
  return {
    ...data,
    endTime: data["endTime"] !== undefined ? data["endTime"].toISOString() : undefined,
    startTime: data["startTime"] !== undefined ? data["startTime"].toISOString() : undefined,
  };
}

function deserializeGoogleTypeInterval(data: any): GoogleTypeInterval {
  return {
    ...data,
    endTime: data["endTime"] !== undefined ? new Date(data["endTime"]) : undefined,
    startTime: data["startTime"] !== undefined ? new Date(data["startTime"]) : undefined,
  };
}

/**
 * An object that represents a latitude/longitude pair. This is expressed as a
 * pair of doubles to represent degrees latitude and degrees longitude. Unless
 * specified otherwise, this object must conform to the WGS84 standard. Values
 * must be within normalized ranges.
 */
export interface GoogleTypeLatLng {
  /**
   * The latitude in degrees. It must be in the range [-90.0, +90.0].
   */
  latitude?: number;
  /**
   * The longitude in degrees. It must be in the range [-180.0, +180.0].
   */
  longitude?: number;
}

/**
 * Represents an amount of money with its currency type.
 */
export interface GoogleTypeMoney {
  /**
   * The three-letter currency code defined in ISO 4217.
   */
  currencyCode?: string;
  /**
   * Number of nano (10^-9) units of the amount. The value must be between
   * -999,999,999 and +999,999,999 inclusive. If `units` is positive, `nanos`
   * must be positive or zero. If `units` is zero, `nanos` can be positive,
   * zero, or negative. If `units` is negative, `nanos` must be negative or
   * zero. For example $-1.75 is represented as `units`=-1 and
   * `nanos`=-750,000,000.
   */
  nanos?: number;
  /**
   * The whole units of the amount. For example if `currencyCode` is `"USD"`,
   * then 1 unit is one US dollar.
   */
  units?: bigint;
}

function serializeGoogleTypeMoney(data: any): GoogleTypeMoney {
  return {
    ...data,
    units: data["units"] !== undefined ? String(data["units"]) : undefined,
  };
}

function deserializeGoogleTypeMoney(data: any): GoogleTypeMoney {
  return {
    ...data,
    units: data["units"] !== undefined ? BigInt(data["units"]) : undefined,
  };
}

/**
 * Represents a postal address, e.g. for postal delivery or payments addresses.
 * Given a postal address, a postal service can deliver items to a premise, P.O.
 * Box or similar. It is not intended to model geographical locations (roads,
 * towns, mountains). In typical usage an address would be created via user
 * input or from importing existing data, depending on the type of process.
 * Advice on address input / editing: - Use an internationalization-ready
 * address widget such as https://github.com/google/libaddressinput) - Users
 * should not be presented with UI elements for input or editing of fields
 * outside countries where that field is used. For more guidance on how to use
 * this schema, please see: https://support.google.com/business/answer/6397478
 */
export interface GoogleTypePostalAddress {
  /**
   * Unstructured address lines describing the lower levels of an address.
   * Because values in address_lines do not have type information and may
   * sometimes contain multiple values in a single field (e.g. "Austin, TX"), it
   * is important that the line order is clear. The order of address lines
   * should be "envelope order" for the country/region of the address. In places
   * where this can vary (e.g. Japan), address_language is used to make it
   * explicit (e.g. "ja" for large-to-small ordering and "ja-Latn" or "en" for
   * small-to-large). This way, the most specific line of an address can be
   * selected based on the language. The minimum permitted structural
   * representation of an address consists of a region_code with all remaining
   * information placed in the address_lines. It would be possible to format
   * such an address very approximately without geocoding, but no semantic
   * reasoning could be made about any of the address components until it was at
   * least partially resolved. Creating an address only containing a region_code
   * and address_lines, and then geocoding is the recommended way to handle
   * completely unstructured addresses (as opposed to guessing which parts of
   * the address should be localities or administrative areas).
   */
  addressLines?: string[];
  /**
   * Optional. Highest administrative subdivision which is used for postal
   * addresses of a country or region. For example, this can be a state, a
   * province, an oblast, or a prefecture. Specifically, for Spain this is the
   * province and not the autonomous community (e.g. "Barcelona" and not
   * "Catalonia"). Many countries don't use an administrative area in postal
   * addresses. E.g. in Switzerland this should be left unpopulated.
   */
  administrativeArea?: string;
  /**
   * Optional. BCP-47 language code of the contents of this address (if known).
   * This is often the UI language of the input form or is expected to match one
   * of the languages used in the address' country/region, or their
   * transliterated equivalents. This can affect formatting in certain
   * countries, but is not critical to the correctness of the data and will
   * never affect any validation or other non-formatting related operations. If
   * this value is not known, it should be omitted (rather than specifying a
   * possibly incorrect default). Examples: "zh-Hant", "ja", "ja-Latn", "en".
   */
  languageCode?: string;
  /**
   * Optional. Generally refers to the city/town portion of the address.
   * Examples: US city, IT comune, UK post town. In regions of the world where
   * localities are not well defined or do not fit into this structure well,
   * leave locality empty and use address_lines.
   */
  locality?: string;
  /**
   * Optional. The name of the organization at the address.
   */
  organization?: string;
  /**
   * Optional. Postal code of the address. Not all countries use or require
   * postal codes to be present, but where they are used, they may trigger
   * additional validation with other parts of the address (e.g. state/zip
   * validation in the U.S.A.).
   */
  postalCode?: string;
  /**
   * Optional. The recipient at the address. This field may, under certain
   * circumstances, contain multiline information. For example, it might contain
   * "care of" information.
   */
  recipients?: string[];
  /**
   * Required. CLDR region code of the country/region of the address. This is
   * never inferred and it is up to the user to ensure the value is correct. See
   * https://cldr.unicode.org/ and
   * https://www.unicode.org/cldr/charts/30/supplemental/territory_information.html
   * for details. Example: "CH" for Switzerland.
   */
  regionCode?: string;
  /**
   * The schema revision of the `PostalAddress`. This must be set to 0, which
   * is the latest revision. All new revisions **must** be backward compatible
   * with old revisions.
   */
  revision?: number;
  /**
   * Optional. Additional, country-specific, sorting code. This is not used in
   * most regions. Where it is used, the value is either a string like "CEDEX",
   * optionally followed by a number (e.g. "CEDEX 7"), or just a number alone,
   * representing the "sector code" (Jamaica), "delivery area indicator"
   * (Malawi) or "post office indicator" (e.g. Cte d'Ivoire).
   */
  sortingCode?: string;
  /**
   * Optional. Sublocality of the address. For example, this can be
   * neighborhoods, boroughs, districts.
   */
  sublocality?: string;
}

/**
 * Represents a time of day. The date and time zone are either not significant
 * or are specified elsewhere. An API may choose to allow leap seconds. Related
 * types are google.type.Date and `google.protobuf.Timestamp`.
 */
export interface GoogleTypeTimeOfDay {
  /**
   * Hours of day in 24 hour format. Should be from 0 to 23. An API may choose
   * to allow the value "24:00:00" for scenarios like business closing time.
   */
  hours?: number;
  /**
   * Minutes of hour of day. Must be from 0 to 59.
   */
  minutes?: number;
  /**
   * Fractions of seconds in nanoseconds. Must be from 0 to 999,999,999.
   */
  nanos?: number;
  /**
   * Seconds of minutes of the time. Must normally be from 0 to 59. An API may
   * allow the value 60 if it allows leap-seconds.
   */
  seconds?: number;
}

/**
 * Represents a time zone from the [IANA Time Zone
 * Database](https://www.iana.org/time-zones).
 */
export interface GoogleTypeTimeZone {
  /**
   * IANA Time Zone Database time zone, e.g. "America/New_York".
   */
  id?: string;
  /**
   * Optional. IANA Time Zone Database version number, e.g. "2019a".
   */
  version?: string;
}

export interface GroupsPerDocData {
  AuthorId?: bigint;
  GroupGaiaId?: bigint;
  /**
   * Legacy group mysql id.
   */
  GroupId?: bigint;
  ThreadId?: bigint;
}

function serializeGroupsPerDocData(data: any): GroupsPerDocData {
  return {
    ...data,
    AuthorId: data["AuthorId"] !== undefined ? String(data["AuthorId"]) : undefined,
    GroupGaiaId: data["GroupGaiaId"] !== undefined ? String(data["GroupGaiaId"]) : undefined,
    GroupId: data["GroupId"] !== undefined ? String(data["GroupId"]) : undefined,
    ThreadId: data["ThreadId"] !== undefined ? String(data["ThreadId"]) : undefined,
  };
}

function deserializeGroupsPerDocData(data: any): GroupsPerDocData {
  return {
    ...data,
    AuthorId: data["AuthorId"] !== undefined ? BigInt(data["AuthorId"]) : undefined,
    GroupGaiaId: data["GroupGaiaId"] !== undefined ? BigInt(data["GroupGaiaId"]) : undefined,
    GroupId: data["GroupId"] !== undefined ? BigInt(data["GroupId"]) : undefined,
    ThreadId: data["ThreadId"] !== undefined ? BigInt(data["ThreadId"]) : undefined,
  };
}

export interface HomeGraphCommonRoute {
  /**
   * The device ID defined by the agent.
   */
  agentDeviceId?: string;
  /**
   * The agent's ID. Generally it is the agent's Google cloud project id.
   */
  agentId?: string;
  /**
   * chip endpoint index (if the target is CHIP). Set packed = true to handle
   * error caused by b/32953375 when exporting this data. Note that we should
   * never change this to non-repeated: a packed field will not work properly if
   * you change the field to non-repeated later.
   */
  chipEndpoint?: number[];
  /**
   * Execution routing target.
   */
  targetType?:  | "UNSPECIFIED" | "PARTNER_CLOUD" | "LOCAL" | "CHIP";
}

/**
 * Defines execution routing information for Traits, which will be used to be
 * mapped for each Trait as following: map traits_to_routing_table_map = X;
 * We'll use this for CHIP first. And expect to migrate the existing routing
 * logic to this gradually.
 */
export interface HomeGraphCommonRoutingTable {
  /**
   * List of supported execution route.
   */
  supportedRoutes?: HomeGraphCommonRoute[];
}

/**
 * LINT.IfChange go/shed-per-trait-routing. Making it object to allow for
 * extendible design, where we can add attributes in future.
 */
export interface HomeGraphCommonTraitRoutingHints {
  /**
   * Set to true for a non-local trait.
   */
  cloudFulfillmentOnly?: boolean;
  /**
   * Trait name, e.g., "action.devices.traits.MediaInitiation". See [device
   * traits](https://developers.home.google.com/cloud-to-cloud/traits). See
   * java/com/google/home/graph/common/devices/config/protoconf.pi for the
   * exhaustive list of trait-strings.
   */
  trait?: string;
}

/**
 * TimingStatPair message stores a timing period name and a time value. This is
 * intentionally vague for doing fine level timing of rendering as what we
 * measure is likely to change as we iterate. The intention is also that these
 * values will just be dumped to varzs for evaluation purposed and not used
 * programmatically.
 */
export interface HtmlrenderWebkitHeadlessProtoAnonTimingStatPair {
  name?: string;
  timeS?: number;
}

/**
 * A simple 2D box represented by an (x, y) coordinate, a width, and a height.
 * Coordinates are in pixels.
 */
export interface HtmlrenderWebkitHeadlessProtoBox {
  height?: number;
  width?: number;
  /**
   * on horizontal axis
   */
  x?: number;
  /**
   * on vertical axis
   */
  y?: number;
}

/**
 * A message to describe the trace events returned by Chromium.
 */
export interface HtmlrenderWebkitHeadlessProtoChromiumTrace {
  chromiumTrace?: string;
}

/**
 * ConsoleLogEntry message stores messages logged by the renderer to the
 * console. Typically error messages related to JS execution, parsing, any CSS
 * errors, etc are logged by the renderer to the console. Next id: 7.
 */
export interface HtmlrenderWebkitHeadlessProtoConsoleLogEntry {
  /**
   * Line number of the document which caused an error.
   */
  lineNumber?: number;
  /**
   * Message which indicates the nature of the error. e.g. parse error,
   * reference error (happens when javascript functions or variables are not
   * resolvable) etc.
   */
  message?: string;
  /**
   * message level
   */
  messageLevel?:  | "TIP_MESSAGE_LEVEL" | "DEBUG_MESSAGE_LEVEL" | "LOG_MESSAGE_LEVEL" | "INFO_MESSAGE_LEVEL" | "WARNING_MESSAGE_LEVEL" | "ERROR_MESSAGE_LEVEL";
  /**
   * The url of the document which has the error.
   */
  sourceUrl?: string;
  /**
   * Stack trace which functions were called when generating the console log.
   * The first frame is the innermost one.
   */
  stackTrace?: HtmlrenderWebkitHeadlessProtoScriptStackFrame[];
  /**
   * Wall time (s) when the log entry was recorded
   */
  timestamp?: number;
}

export interface HtmlrenderWebkitHeadlessProtoCookie {
  domain?: string;
  expiration?: number;
  httpOnly?: boolean;
  name?: Uint8Array;
  path?: string;
  sameSite?:  | "SAME_SITE_UNSPECIFIED" | "SAME_SITE_LAX" | "SAME_SITE_STRICT" | "SAME_SITE_NONE";
  secure?: boolean;
  value?: Uint8Array;
}

function serializeHtmlrenderWebkitHeadlessProtoCookie(data: any): HtmlrenderWebkitHeadlessProtoCookie {
  return {
    ...data,
    name: data["name"] !== undefined ? encodeBase64(data["name"]) : undefined,
    value: data["value"] !== undefined ? encodeBase64(data["value"]) : undefined,
  };
}

function deserializeHtmlrenderWebkitHeadlessProtoCookie(data: any): HtmlrenderWebkitHeadlessProtoCookie {
  return {
    ...data,
    name: data["name"] !== undefined ? decodeBase64(data["name"] as string) : undefined,
    value: data["value"] !== undefined ? decodeBase64(data["value"] as string) : undefined,
  };
}

/**
 * Next available tag: 24
 */
export interface HtmlrenderWebkitHeadlessProtoDocument {
  /**
   * Document's base uri.
   */
  baseUri?: string;
  /**
   * Document's charset.
   */
  charset?: string;
  contentHeight?: number;
  /**
   * Document's language.
   */
  contentLanguage?: string;
  /**
   * These fields contain the actual width and height of the document content,
   * which may exceed the size of the rendering viewport. *DEPRECATED* Use
   * rendered_content_area instead. These two fields always assume the content
   * area begins at viewport coordinates (0,0).
   */
  contentWidth?: number;
  /**
   * A flat list of all the DOMTreeNodes in the DOM. A flat list is preferred
   * to a tree to avoid recursion and potential stack overflows. Note that the
   * first node in this list will always be the root node.
   */
  domTreeNode?: HtmlrenderWebkitHeadlessProtoDOMTreeNode[];
  /**
   * A unique identifier for the frame (browser window of iframe) this document
   * is loaded in. This identifier matches the identifiers used in the timeline
   * data to identify frames and therefore only set if the record_timeline field
   * of the RenderRequest message was set to true. frame_id is not supported on
   * Chromium.
   */
  frameId?: string;
  /**
   * The name of the frame (browser window of iframe) this document is loaded
   * in. May not be set if the frame name was empty.
   */
  frameName?: string;
  /**
   * --------------------------------------------------------------------------
   * Input context. These fields are copied from RenderRequest so that Document
   * can be a self contained protobuf. We would've liked to place them in a ##
   * nested InputContext message but it's too late now. ## Time specified to
   * RenderRequest.JavaScriptOptions.time_of_day, if any. ## End of input
   * context. Output-only fields below.
   */
  javascriptTimeOfDay?: number;
  /**
   * The chain of redirects (and redirect methods) used to get to the final
   * resource for this Document. Deprecated: Use the redirect events in the
   * render_event field instead.
   */
  redirectHop?: HtmlrenderWebkitHeadlessProtoRedirectHop[];
  /**
   * Contains a list of Resources which the renderer requested -- both those
   * that were found and those that were not. Resources are returned in the
   * order that they were requested.
   */
  referencedResource?: HtmlrenderWebkitHeadlessProtoReferencedResource[];
  /**
   * The bounding box which represents the whole area of rendered content,
   * which may exceed the size of the rendering viewport. It doesn't include the
   * body's margin.
   */
  renderedContentArea?: HtmlrenderWebkitHeadlessProtoBox;
  /**
   * Different types of events which happened during rendering. All events for
   * this document's frame are included, so for example if a confirmation dialog
   * is created before a client redirect to this document the
   * ConfirmationDialogEvent will still be included even though the dialog was
   * created by a different document. See render_event.proto for the types of
   * events which are recorded. Note that this is present regardless of whether
   * record_timeline was set in the RenderRequest.
   */
  renderEvent?: HtmlrenderWebkitHeadlessProtoRenderEvent[];
  /**
   * See htmlrender_webkit_headless_utils::SerializeRenderStyle() if a
   * serialized css string is wanted.
   */
  renderStyle?: HtmlrenderWebkitHeadlessProtoStyle[];
  /**
   * A flat list of all the RenderTreeNodes from the render tree. A flat list
   * is preferred to a tree to avoid recursion and potential stack overflows.
   * Note that the first node in this list will always be the RenderTreeNode for
   * the #document node (aka root).
   */
  renderTreeNode?: HtmlrenderWebkitHeadlessProtoRenderTreeNode[];
  /**
   * DEPRECATED - This field to be removed mid-2011. If you need this, use the
   * library directly: //google3/htmlrender/webkit_headless/snapshot_quality
   * Indicates how good or bad the rendering is from the perspective of the
   * render tree. This is different from snapshot_quality_score in that the
   * quality analysis examines everything that can be rendered, not just the
   * portion within the document's viewport. It also ignores missing resouces
   * with fixed width/height specified in the tag. A score of 1 (100%) implies
   * the entire document can be rendered at the best quality and a score of 0
   * implies the entire document is unusable.
   */
  renderTreeQualityScore?: number;
  /**
   * Scroll offset of this document within the frame. Note that if
   * expand_frame_to_content_height or expand_frame_to_content_width is true,
   * this field reflects the final scroll offset after frame expansion.
   */
  scrollX?: number;
  scrollY?: number;
  /**
   * DEPRECATED - This field to be removed mid-2011. If you need this, use the
   * library directly: //google3/htmlrender/webkit_headless/snapshot_quality
   * Indicates how good or bad the rendered snapshot is within the rendered
   * content area within the document's viewport. A score of 1 (100%) implies
   * the snapshot is of best quality and a score of 0 implies the snapshot is
   * unusable.
   */
  snapshotQualityScore?: number;
  /**
   * Document's title.
   */
  title?: string;
  /**
   * Document uri is the URL that this document was fetched from. The displayed
   * URL and base URL may be different. If this document was not fetched from
   * any URL (e.g. iframe with no src, populated by script) uri will be
   * "about:blank".
   */
  uri?: string;
  /**
   * The page's layout size.
   */
  viewport?: HtmlrenderWebkitHeadlessProtoBox;
}

function serializeHtmlrenderWebkitHeadlessProtoDocument(data: any): HtmlrenderWebkitHeadlessProtoDocument {
  return {
    ...data,
    domTreeNode: data["domTreeNode"] !== undefined ? data["domTreeNode"].map((item: any) => (serializeHtmlrenderWebkitHeadlessProtoDOMTreeNode(item))) : undefined,
    referencedResource: data["referencedResource"] !== undefined ? data["referencedResource"].map((item: any) => (serializeHtmlrenderWebkitHeadlessProtoReferencedResource(item))) : undefined,
  };
}

function deserializeHtmlrenderWebkitHeadlessProtoDocument(data: any): HtmlrenderWebkitHeadlessProtoDocument {
  return {
    ...data,
    domTreeNode: data["domTreeNode"] !== undefined ? data["domTreeNode"].map((item: any) => (deserializeHtmlrenderWebkitHeadlessProtoDOMTreeNode(item))) : undefined,
    referencedResource: data["referencedResource"] !== undefined ? data["referencedResource"].map((item: any) => (deserializeHtmlrenderWebkitHeadlessProtoReferencedResource(item))) : undefined,
  };
}

export interface HtmlrenderWebkitHeadlessProtoDOMStorageItem {
  key?: string;
  securityOrigin?: string;
  value?: string;
}

/**
 * DOMTreeNode Defines a DOM Node. An instance can contain references to one or
 * more children (of type DOMTreeNode) and one or more attributes. The
 * DOMTreeNode also encapsulates rendering information (if applicable) in the
 * form of references to one or more RenderTreeNodes. Next tag available: 16
 */
export interface HtmlrenderWebkitHeadlessProtoDOMTreeNode {
  attribute?: HtmlrenderWebkitHeadlessProtoDOMTreeNodeAttribute[];
  /**
   * An index per child. Indexes can be used to fetch the DOMTreeNodes from the
   * list maintained by the Document.
   */
  childDomTreeNodeIndex?: number[];
  /**
   * For elements, the actual url that was used to fetch the image. Note that
   * this field is set only if it is different from the 'src' attribute value.
   */
  currentSourceUrl?: string;
  /**
   * If the node represents an iframe or a frame then document will be set.
   */
  document?: HtmlrenderWebkitHeadlessProtoDocument;
  /**
   * Identifies the HTML tag type (IMG, P, DIV, etc). Applicable only for DOM
   * nodes that are representative of html elements. For a list of possible
   * types refer HtmlTagEnum defined in webutil/html/htmltagenum.h.
   */
  htmlTagType?: number;
  /**
   * Whether this DOM node responds to mouse clicks. This includes e.g. nodes
   * that have had click event listeners attached via JavaScript as well as e.g.
   * anchor tags that naturally navigate when clicked.
   */
  isClickable?: boolean;
  /**
   * Name of the node (document, text, comment, div, etc).
   */
  name?: string;
  /**
   * URL of the script, if any, which created or populated this node.
   */
  originUrl?: string;
  /**
   * List of referenced resource indexes for any resources that this DOM tree
   * node references.
   */
  referencedResourceIndex?: number[];
  /**
   * RenderTreeNode can be looked up from the list of RenderTreeNodes stored in
   * the Document using render_tree_node_index. RenderTreeNode gives rendering
   * information (bounding box, style that was applied, etc). Note: 1. If a
   * DOMTreeNode does not have a RenderTreeNode then it is safe to assume that
   * the DOMTreeNode has no effect on the rendering. DOMTreeNodes for a ,
   */
  renderTreeNodeIndex?: number[];
  type?:  | "ELEMENT_NODE" | "ATTRIBUTE_NODE" | "TEXT_NODE" | "CDATA_SECTION_NODE" | "ENTITY_REFERENCE_NODE" | "ENTITY_NODE" | "PROCESSING_INSTRUCTION_NODE" | "COMMENT_NODE" | "DOCUMENT_NODE" | "DOCUMENT_TYPE_NODE" | "DOCUMENT_FRAGMENT_NODE" | "NOTATION_NODE" | "XPATH_NAMESPACE_NODE" | "SHADOW_ROOT_NODE";
  /**
   * The node value is applicable for TEXT_NODEs, DOCUMENT_TYPE_NODEs, and user
   * input elements such as , and <option>. For DOCUMENT_TYPE_NODEs, the value
   * contains the publicId and SystemId. For input elements, the value reflects
   * the current value in the element at the time the snapshot was taken.
   */
  value?: string;
}

function serializeHtmlrenderWebkitHeadlessProtoDOMTreeNode(data: any): HtmlrenderWebkitHeadlessProtoDOMTreeNode {
  return {
    ...data,
    document: data["document"] !== undefined ? serializeHtmlrenderWebkitHeadlessProtoDocument(data["document"]) : undefined,
  };
}

function deserializeHtmlrenderWebkitHeadlessProtoDOMTreeNode(data: any): HtmlrenderWebkitHeadlessProtoDOMTreeNode {
  return {
    ...data,
    document: data["document"] !== undefined ? deserializeHtmlrenderWebkitHeadlessProtoDocument(data["document"]) : undefined,
  };
}

/**
 * Zero or more attributes for the node.
 */
export interface HtmlrenderWebkitHeadlessProtoDOMTreeNodeAttribute {
  /**
   * Identifies the HTML attribute type (src, width, height, etc). For a list
   * of possible types refer HtmlAttributeEnum defined in
   * webutil/html/htmlattrenum.h.
   */
  htmlAttributeType?: number;
  name?: string;
  value?: string;
}

/**
 * Event for frame resize. Currently we only record resize events caused by
 * automatic frame expansion.
 */
export interface HtmlrenderWebkitHeadlessProtoFrameResizeEvent {
  resizeType?:  | "UNKNOWN" | "AUTOMATIC_FRAME_EXPANSION_TO_CONTENT_WIDTH" | "AUTOMATIC_FRAME_EXPANSION_TO_CONTENT_HEIGHT";
  visibleRectAfterResize?: HtmlrenderWebkitHeadlessProtoBox;
  visibleRectBeforeResize?: HtmlrenderWebkitHeadlessProtoBox;
}

export interface HtmlrenderWebkitHeadlessProtoImage {
  /**
   * The binary image data, stored in a format decided by the application and a
   * particular RenderService implementation.
   */
  data?: Uint8Array;
  height?: number;
  /**
   * The page number if this is an image of a page from a print-mode rendering.
   */
  pageNumber?: number;
  /**
   * The viewport from which this image was generated. This is relative to the
   * upper left of the page's document.
   */
  viewport?: HtmlrenderWebkitHeadlessProtoBox;
  /**
   * The width and height of the image stored in the data field.
   */
  width?: number;
}

function serializeHtmlrenderWebkitHeadlessProtoImage(data: any): HtmlrenderWebkitHeadlessProtoImage {
  return {
    ...data,
    data: data["data"] !== undefined ? encodeBase64(data["data"]) : undefined,
  };
}

function deserializeHtmlrenderWebkitHeadlessProtoImage(data: any): HtmlrenderWebkitHeadlessProtoImage {
  return {
    ...data,
    data: data["data"] !== undefined ? decodeBase64(data["data"] as string) : undefined,
  };
}

/**
 * Event for the initial load of a frame, including main frame and subframes.
 */
export interface HtmlrenderWebkitHeadlessProtoInitialLoadEvent {
  url?: string;
}

/**
 * Event for a modal dialog created by one of window.confirm(),
 * window.prompt(), or window.alert().
 */
export interface HtmlrenderWebkitHeadlessProtoModalDialogEvent {
  /**
   * Whether a confirm() or prompt() dialog was confirmed. Will not be present
   * for an alert() dialog.
   */
  confirmed?: boolean;
  message?: string;
  /**
   * For a prompt() dialog, the result of the prompt. Will not be present for
   * other types of dialogs. If confirmed == false and the prompt had a default
   * value, result will contain the default value.
   */
  result?: string;
  type?:  | "CONFIRM" | "PROMPT" | "ALERT";
}

export interface HtmlrenderWebkitHeadlessProtoOffset {
  unit?:  | "PIXELS" | "PERCENT";
  value?: number;
}

/**
 * PartialRenders can be created using the extension API to store the document
 * state and/or create an image at points before the final render.
 */
export interface HtmlrenderWebkitHeadlessProtoPartialRender {
  /**
   * Cookies at the time of snapshot creation.
   */
  cookie?: HtmlrenderWebkitHeadlessProtoCookie[];
  /**
   * Current url as would appear in the web browser's address bar at the time
   * of snapshot creation.
   */
  currentClientUrl?: string;
  /**
   * Snapshot of the document DOM + Render trees, if requested
   */
  document?: HtmlrenderWebkitHeadlessProtoDocument;
  /**
   * ID set by the render extension
   */
  id?: string;
  /**
   * Image of the render, if requested
   */
  image?: HtmlrenderWebkitHeadlessProtoImage;
}

function serializeHtmlrenderWebkitHeadlessProtoPartialRender(data: any): HtmlrenderWebkitHeadlessProtoPartialRender {
  return {
    ...data,
    cookie: data["cookie"] !== undefined ? data["cookie"].map((item: any) => (serializeHtmlrenderWebkitHeadlessProtoCookie(item))) : undefined,
    document: data["document"] !== undefined ? serializeHtmlrenderWebkitHeadlessProtoDocument(data["document"]) : undefined,
    image: data["image"] !== undefined ? serializeHtmlrenderWebkitHeadlessProtoImage(data["image"]) : undefined,
  };
}

function deserializeHtmlrenderWebkitHeadlessProtoPartialRender(data: any): HtmlrenderWebkitHeadlessProtoPartialRender {
  return {
    ...data,
    cookie: data["cookie"] !== undefined ? data["cookie"].map((item: any) => (deserializeHtmlrenderWebkitHeadlessProtoCookie(item))) : undefined,
    document: data["document"] !== undefined ? deserializeHtmlrenderWebkitHeadlessProtoDocument(data["document"]) : undefined,
    image: data["image"] !== undefined ? deserializeHtmlrenderWebkitHeadlessProtoImage(data["image"]) : undefined,
  };
}

export interface HtmlrenderWebkitHeadlessProtoPdf {
  /**
   * The binary PDF data.
   */
  data?: Uint8Array;
}

function serializeHtmlrenderWebkitHeadlessProtoPdf(data: any): HtmlrenderWebkitHeadlessProtoPdf {
  return {
    ...data,
    data: data["data"] !== undefined ? encodeBase64(data["data"]) : undefined,
  };
}

function deserializeHtmlrenderWebkitHeadlessProtoPdf(data: any): HtmlrenderWebkitHeadlessProtoPdf {
  return {
    ...data,
    data: data["data"] !== undefined ? decodeBase64(data["data"] as string) : undefined,
  };
}

export interface HtmlrenderWebkitHeadlessProtoRectangle {
  bottom?: HtmlrenderWebkitHeadlessProtoOffset;
  left?: HtmlrenderWebkitHeadlessProtoOffset;
  right?: HtmlrenderWebkitHeadlessProtoOffset;
  /**
   * A missing value for any field in this message means 'auto'.
   */
  top?: HtmlrenderWebkitHeadlessProtoOffset;
}

/**
 * A redirect event represents a change in the resource URL for a document.
 * This includes HTTP redirects, as well things which trigger client navigations
 * such as script changing window.location, tags, HTTP Refresh headers, etc.
 */
export interface HtmlrenderWebkitHeadlessProtoRedirectEvent {
  /**
   * The HTTP method of the request for the redirect target.
   */
  httpMethod?:  | "OTHER_HTTP_METHOD" | "GET" | "POST";
  /**
   * For HTTP redirects, the HTTP status code returned in the initial HTTP
   * response.
   */
  httpStatusCode?: number;
  refreshType?:  | "HTTP_REFRESH" | "META_HTTP_EQUIV_REFRESH";
  /**
   * True if the redirect led to a download instead of loading a new page. Note
   * that such redirects can appear anywhere in the list of redirect events.
   */
  targetContentDownloaded?: boolean;
  targetUrl?: string;
  type?:  | "UNKNOWN_REDIRECT_TYPE" | "HTTP" | "SCRIPT" | "REFRESH";
}

export interface HtmlrenderWebkitHeadlessProtoRedirectHop {
  type?:  | "SERVER" | "CLIENT";
  /**
   * The redirect target url.
   */
  url?: string;
}

/**
 * ReferencedResource contains an entry per url referenced by the browser while
 * rendering a document. Next tag available: 20
 */
export interface HtmlrenderWebkitHeadlessProtoReferencedResource {
  /**
   * True if this fetch was canceled due to render server policy. e.g. the page
   * exceeded the fetch budget or an extension canceled the fetch.
   */
  canceled?: boolean;
  /**
   * Content type of this resource (webutil/http/content-type.h). The content
   * type is from guess based on the file extension, any mime type in http
   * headers at the beginning of the content, any content-disposition http
   * header, and the content body itself. Note: the content type defined in
   * webutil/http/content-type.proto is incomplete. If you are interested in
   * missing types, please update the enum and the logic of content type
   * detection.
   */
  contentType?: number;
  /**
   * DOMTreeNode index which has the url as one of its attributes specified
   * using either src, href or background attributes. src attribute applies to
   * img, script, frame and iframe nodes, href applies to link nodes and
   * background applies to body node. It is possible for a url to be referenced
   * by multiple DOM nodes. For e.g. an tag with the same src attribute can
   * occur in multiple places within a document. It is possible for a url to not
   * have any DOM node reference. For example, redirects don't have DOM tree
   * nodes.
   */
  domTreeNodeIndex?: number[];
  /**
   * True when a HTTP request succeeded but the resource was not made
   * accessible to script due to a HTTP Access Control (CORS) failure. This
   * field is not implemented on Chromium.
   */
  failedHttpAccessControlCheck?: boolean;
  /**
   * Where this resource comes from.
   */
  fetchSourceInfo?: WirelessTranscoderFetchFetchSourceInfo[];
  /**
   * The FetchStatus returned by the fetcher. Values are taken from
   * wireless_transcoder_fetch.FetchConstants.FetchStatus in
   * fetch_service.proto. The default value is SUCCESS(0).
   */
  fetchStatus?:  | "SUCCESS" | "TIMEOUT" | "CONNECTION_ERROR" | "IO_ERROR" | "RPC_ERROR" | "INTERRUPTED" | "UNSUPPORTED_PROTOCOL" | "MALFORMED_URL" | "TOO_MANY_REDIRECTS" | "MALFORMED_RESPONSE" | "NOT_PERMITTED" | "CERTIFICATE_ERROR" | "INVALID_REQUEST" | "BUSY" | "INVALID_CUSTOM_PARAMS" | "NOT_HANDLED";
  /**
   * HTTP headers from the fetcher.
   */
  httpHeader?: HtmlrenderWebkitHeadlessProtoReferencedResourceHttpHeader[];
  /**
   * HTTP response code if we had tried to fetch the url. Absence of this field
   * indicates either we have not tried to fetch the url or the fetcher never
   * got back to us with any response.
   */
  httpResponseCode?: number;
  metadata?: WirelessTranscoderFetchFetchMetadata[];
  /**
   * The post_data field is only valid when the HTTP request method is POST.
   */
  postData?: Uint8Array;
  /**
   * If the http_response_code is a HTTP redirect, the redirect target will be
   * stored here.
   */
  redirectTarget?: string;
  /**
   * Indicates which referenced_resource_content (in RenderResponse) this
   * RefencedResource points to. This field will be set only when there is
   * referenced_resource_content for this RefencedResource in RenderResponse.
   */
  referencedResourceContentIndex?: number;
  /**
   * Only necessary headers are recorded. See
   * google3/htmlrender/webkit_headless/resource_key.cc
   */
  requestHeader?: HtmlrenderWebkitHeadlessProtoReferencedResourceHttpHeader[];
  /**
   * The HTTP request method (GET, HEAD, POST, etc) used for this request.
   * Values are taken from the HTTPHeaders::Protocol enum in
   * webutil/http/httputils.h. HTTPHeaders::PROTO_GET
   */
  requestMethod?: number;
  /**
   * style index which has the url specified using either the background-image
   * property or the list-style-image property.
   */
  styleIndex?: number[];
  /**
   * Whether it is synchronously fetched.
   */
  synchronouslyFetched?: boolean;
  timing?: HtmlrenderWebkitHeadlessProtoReferencedResourceFetchTiming[];
  /**
   * Does not have a #fragment.
   */
  url?: string;
  /**
   * Additional information webkit about this resource. e.g. intended usage
   */
  webkitMetadata?: HtmlrenderWebkitHeadlessProtoWebKitFetchMetadata;
}

function serializeHtmlrenderWebkitHeadlessProtoReferencedResource(data: any): HtmlrenderWebkitHeadlessProtoReferencedResource {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? data["metadata"].map((item: any) => (serializeWirelessTranscoderFetchFetchMetadata(item))) : undefined,
    postData: data["postData"] !== undefined ? encodeBase64(data["postData"]) : undefined,
    timing: data["timing"] !== undefined ? data["timing"].map((item: any) => (serializeHtmlrenderWebkitHeadlessProtoReferencedResourceFetchTiming(item))) : undefined,
  };
}

function deserializeHtmlrenderWebkitHeadlessProtoReferencedResource(data: any): HtmlrenderWebkitHeadlessProtoReferencedResource {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? data["metadata"].map((item: any) => (deserializeWirelessTranscoderFetchFetchMetadata(item))) : undefined,
    postData: data["postData"] !== undefined ? decodeBase64(data["postData"] as string) : undefined,
    timing: data["timing"] !== undefined ? data["timing"].map((item: any) => (deserializeHtmlrenderWebkitHeadlessProtoReferencedResourceFetchTiming(item))) : undefined,
  };
}

/**
 * Timing data produced by the fetcher.
 */
export interface HtmlrenderWebkitHeadlessProtoReferencedResourceFetchTiming {
  finishMsec?: bigint;
  /**
   * A string identifying the fetcher that added this timing information.
   */
  name?: string;
  /**
   * UNIX epoch timestamps in milliseconds.
   */
  startMsec?: bigint;
}

function serializeHtmlrenderWebkitHeadlessProtoReferencedResourceFetchTiming(data: any): HtmlrenderWebkitHeadlessProtoReferencedResourceFetchTiming {
  return {
    ...data,
    finishMsec: data["finishMsec"] !== undefined ? String(data["finishMsec"]) : undefined,
    startMsec: data["startMsec"] !== undefined ? String(data["startMsec"]) : undefined,
  };
}

function deserializeHtmlrenderWebkitHeadlessProtoReferencedResourceFetchTiming(data: any): HtmlrenderWebkitHeadlessProtoReferencedResourceFetchTiming {
  return {
    ...data,
    finishMsec: data["finishMsec"] !== undefined ? BigInt(data["finishMsec"]) : undefined,
    startMsec: data["startMsec"] !== undefined ? BigInt(data["startMsec"]) : undefined,
  };
}

/**
 * HTTP Headers included with the resource request.
 */
export interface HtmlrenderWebkitHeadlessProtoReferencedResourceHttpHeader {
  name?: string;
  value?: string;
}

export interface HtmlrenderWebkitHeadlessProtoRenderEvent {
  frameResize?: HtmlrenderWebkitHeadlessProtoFrameResizeEvent;
  initialLoad?: HtmlrenderWebkitHeadlessProtoInitialLoadEvent;
  modalDialog?: HtmlrenderWebkitHeadlessProtoModalDialogEvent;
  redirect?: HtmlrenderWebkitHeadlessProtoRedirectEvent;
  /**
   * The URL of the script which caused this event, if any. Analogous to
   * origin_url in DOMTreeNode.
   */
  scriptOriginUrl?: string;
  /**
   * Virtual time of the event, as an offset from the beginning of the render
   * in seconds.
   */
  virtualTimeOffset?: number;
  windowOpen?: HtmlrenderWebkitHeadlessProtoWindowOpenEvent;
}

/**
 * Results returned by a render server extension. Next id: 3
 */
export interface HtmlrenderWebkitHeadlessProtoRenderExtensionResult {
  /**
   * Log messages and errors generated by extension script.
   */
  consoleLogEntry?: HtmlrenderWebkitHeadlessProtoConsoleLogEntry[];
  result?: string;
}

/**
 * See go/wrs-render-quality for how to evaluate the results. Next id: 24
 */
export interface HtmlrenderWebkitHeadlessProtoRenderResponse {
  /**
   * Contains chromium trace generated during page rendering. This is present
   * if a chromium_trace_config was provided in the request.
   */
  chromiumTrace?: HtmlrenderWebkitHeadlessProtoChromiumTrace;
  /**
   * Contents of the browser's cookie jar. (if cookies_enabled was set to true
   * in the RenderRequest).
   */
  cookie?: HtmlrenderWebkitHeadlessProtoCookie[];
  /**
   * Contains the DOM tree, render tree and more. For details consult
   * document.proto.
   */
  document?: HtmlrenderWebkitHeadlessProtoDocument;
  /**
   * Provides extra debugging details when certain exception bits are set.
   */
  exceptionDetail?: string;
  /**
   * Exceptions (possibly serious conditions) that occurred during this
   * rendering. 0 means none. Bitfield encoding. See the RenderingException enum
   * above for an explanation.
   */
  exceptions?: bigint;
  /**
   * Render extension results (if `devtools_script` was provided with the
   * request.)
   */
  extensionResult?: HtmlrenderWebkitHeadlessProtoRenderExtensionResult;
  /**
   * This field contains the final url as would appear in the web browser's
   * address bar. Note that JavaScript can modify the contents of the location
   * bar so this URL may not appear on the list of referenced resources. If we
   * fail to follow a redirect this field will contain the URL that we failed to
   * redirect to, not the last one we successfully loaded.
   */
  finalClientUrl?: string;
  /**
   * Contains the viewport images rendered by webkit (if generate_image was set
   * to true in the RenderRequest). Will also contain the print-mode images (if
   * generate_print_mode_images was set to true).
   */
  image?: HtmlrenderWebkitHeadlessProtoImage[];
  /**
   * Contents of the browser's local storage.
   */
  localStorage?: HtmlrenderWebkitHeadlessProtoDOMStorageItem[];
  /**
   * Partial render snapshots (if requested by a render extension)
   */
  partialRender?: HtmlrenderWebkitHeadlessProtoPartialRender[];
  /**
   * Contains the PDF document (if generate_pdf was set to true in the
   * RenderRequest)
   */
  pdf?: HtmlrenderWebkitHeadlessProtoPdf;
  /**
   * Contents for all the urls fetched by the render server. This field is
   * present only if generate_referenced_resource_content was set to true in the
   * RenderRequest.
   */
  referencedResourceContent?: HtmlrenderWebkitHeadlessProtoResource[];
  /**
   * Time to render the url, total size of a document, number of referenced
   * images, etc will be part of RenderStats.
   */
  renderStats?: HtmlrenderWebkitHeadlessProtoRenderStats;
  /**
   * Contents of the browser's session storage.
   */
  sessionStorage?: HtmlrenderWebkitHeadlessProtoDOMStorageItem[];
  /**
   * Contains the page title produced by webkit, in the UTF-8 encoding.
   */
  title?: string;
}

function serializeHtmlrenderWebkitHeadlessProtoRenderResponse(data: any): HtmlrenderWebkitHeadlessProtoRenderResponse {
  return {
    ...data,
    cookie: data["cookie"] !== undefined ? data["cookie"].map((item: any) => (serializeHtmlrenderWebkitHeadlessProtoCookie(item))) : undefined,
    document: data["document"] !== undefined ? serializeHtmlrenderWebkitHeadlessProtoDocument(data["document"]) : undefined,
    exceptions: data["exceptions"] !== undefined ? String(data["exceptions"]) : undefined,
    image: data["image"] !== undefined ? data["image"].map((item: any) => (serializeHtmlrenderWebkitHeadlessProtoImage(item))) : undefined,
    partialRender: data["partialRender"] !== undefined ? data["partialRender"].map((item: any) => (serializeHtmlrenderWebkitHeadlessProtoPartialRender(item))) : undefined,
    pdf: data["pdf"] !== undefined ? serializeHtmlrenderWebkitHeadlessProtoPdf(data["pdf"]) : undefined,
    referencedResourceContent: data["referencedResourceContent"] !== undefined ? data["referencedResourceContent"].map((item: any) => (serializeHtmlrenderWebkitHeadlessProtoResource(item))) : undefined,
    renderStats: data["renderStats"] !== undefined ? serializeHtmlrenderWebkitHeadlessProtoRenderStats(data["renderStats"]) : undefined,
  };
}

function deserializeHtmlrenderWebkitHeadlessProtoRenderResponse(data: any): HtmlrenderWebkitHeadlessProtoRenderResponse {
  return {
    ...data,
    cookie: data["cookie"] !== undefined ? data["cookie"].map((item: any) => (deserializeHtmlrenderWebkitHeadlessProtoCookie(item))) : undefined,
    document: data["document"] !== undefined ? deserializeHtmlrenderWebkitHeadlessProtoDocument(data["document"]) : undefined,
    exceptions: data["exceptions"] !== undefined ? BigInt(data["exceptions"]) : undefined,
    image: data["image"] !== undefined ? data["image"].map((item: any) => (deserializeHtmlrenderWebkitHeadlessProtoImage(item))) : undefined,
    partialRender: data["partialRender"] !== undefined ? data["partialRender"].map((item: any) => (deserializeHtmlrenderWebkitHeadlessProtoPartialRender(item))) : undefined,
    pdf: data["pdf"] !== undefined ? deserializeHtmlrenderWebkitHeadlessProtoPdf(data["pdf"]) : undefined,
    referencedResourceContent: data["referencedResourceContent"] !== undefined ? data["referencedResourceContent"].map((item: any) => (deserializeHtmlrenderWebkitHeadlessProtoResource(item))) : undefined,
    renderStats: data["renderStats"] !== undefined ? deserializeHtmlrenderWebkitHeadlessProtoRenderStats(data["renderStats"]) : undefined,
  };
}

/**
 * Next id: 17.
 */
export interface HtmlrenderWebkitHeadlessProtoRenderStats {
  /**
   * Deliberately non-named fine timing stats. These are all related to each
   * other and unrelated to other timing stats in this message.
   */
  anonRenderFineTimingStats?: HtmlrenderWebkitHeadlessProtoAnonTimingStatPair[];
  /**
   * Any messages logged by the renderer to the console. Note that we capture a
   * subset of the messages logged by the renderer here to avoid explosion.
   */
  consoleLogEntry?: HtmlrenderWebkitHeadlessProtoConsoleLogEntry[];
  counter?: HtmlrenderWebkitHeadlessProtoRenderStatsCounter[];
  /**
   * Time to build document and render tree response data.
   */
  documentBuildTimeMsec?: number;
  /**
   * Number of dropped log messages. Since we capture only a subset of the
   * messages in console_log_entry this field is included just so that the
   * consumers can get an idea of how many actual attempts were made by the
   * renderer.
   */
  droppedLogEntryCount?: number;
  /**
   * Image encoding (e.g. raw -> PNG) time.
   */
  imageEncodingTimeMsec?: number;
  /**
   * Image scaling time.
   */
  imageScalingTimeMsec?: number;
  /**
   * Time from starting render to document finished loading. This includes all
   * fetches, parsing, decoding, running JavaScript, etc.
   */
  layoutTimeMsec?: number;
  /**
   * Time required to paint a document into our buffer.
   */
  paintTimeMsec?: number;
  /**
   * Total cost this render spent running and RPC cost in milliGCUs.
   */
  renderCostMgcu?: number;
  /**
   * Render engine used to render this document.
   */
  renderEngine?:  | "UNKNOWN" | "BLINK_HEADLESS" | "CHROME_HEADLESS" | "UNKNOWN_DUE_TO_RPC_FAILURE";
  /**
   * Total CPU time this render spent running in milliseconds.
   */
  renderRunningTimeMsec?: number;
  /**
   * The CL from which the render engine was built.
   */
  renderServerBaselineCl?: bigint;
  /**
   * Total wall time taken to render a document in milliseconds.
   */
  renderTimeMsec?: number;
  /**
   * Total time spent in the sandbox in milliseconds. This time includes all
   * phases measured individually below.
   */
  sandboxRenderTimeMsec?: number;
}

function serializeHtmlrenderWebkitHeadlessProtoRenderStats(data: any): HtmlrenderWebkitHeadlessProtoRenderStats {
  return {
    ...data,
    counter: data["counter"] !== undefined ? data["counter"].map((item: any) => (serializeHtmlrenderWebkitHeadlessProtoRenderStatsCounter(item))) : undefined,
    renderServerBaselineCl: data["renderServerBaselineCl"] !== undefined ? String(data["renderServerBaselineCl"]) : undefined,
  };
}

function deserializeHtmlrenderWebkitHeadlessProtoRenderStats(data: any): HtmlrenderWebkitHeadlessProtoRenderStats {
  return {
    ...data,
    counter: data["counter"] !== undefined ? data["counter"].map((item: any) => (deserializeHtmlrenderWebkitHeadlessProtoRenderStatsCounter(item))) : undefined,
    renderServerBaselineCl: data["renderServerBaselineCl"] !== undefined ? BigInt(data["renderServerBaselineCl"]) : undefined,
  };
}

/**
 * Render event counters.
 */
export interface HtmlrenderWebkitHeadlessProtoRenderStatsCounter {
  count?: bigint;
  /**
   * By convention, counters may contain a "." which we use to separate a
   * metric name from a counter name in streamz.
   */
  name?: string;
}

function serializeHtmlrenderWebkitHeadlessProtoRenderStatsCounter(data: any): HtmlrenderWebkitHeadlessProtoRenderStatsCounter {
  return {
    ...data,
    count: data["count"] !== undefined ? String(data["count"]) : undefined,
  };
}

function deserializeHtmlrenderWebkitHeadlessProtoRenderStatsCounter(data: any): HtmlrenderWebkitHeadlessProtoRenderStatsCounter {
  return {
    ...data,
    count: data["count"] !== undefined ? BigInt(data["count"]) : undefined,
  };
}

export interface HtmlrenderWebkitHeadlessProtoRenderTreeNode {
  /**
   * Box is set for render blocks ( , , etc). Box for any RenderTreeNode can be
   * found either in the RenderTreeNode itself or by traversing up the ancestors
   * until a RenderTreeNode with a Box is found.
   */
  box?: HtmlrenderWebkitHeadlessProtoBox;
  /**
   * child_render_tree_node_index is an index into the list of RenderTreeNodes
   * stored in the Document. *** WARNING ***: Don't use this field. Applications
   * should not rely on the structure of the render tree. This is an internal
   * browser implementation detail and it changes from time to time. Generally,
   * applications should obtain rendering information by starting with the
   * relevant DOMTreeNode and following pointers from there to the relevant
   * RenderTreeNodes.
   */
  childRenderTreeNodeIndex?: number[];
  /**
   * Index of the DOMTreeNode for which this RenderTreeNode is applicable. This
   * index can be used to lookup a DOMTreeNode from list of DOMTreeNodes stored
   * in the Document.
   */
  domTreeNodeIndex?: number;
  inlineTextBox?: HtmlrenderWebkitHeadlessProtoRenderTreeNodeInlineTextBox[];
  /**
   * The actual text that was rendered. This is applicable only for text nodes.
   */
  renderedText?: string;
  /**
   * Style index is set for rendered nodes (text nodes, image nodes, widgets,
   * etc). The style_index can be used to lookup the style from the list of
   * styles stored in the Document.
   */
  styleIndex?: number;
}

/**
 * For text nodes, individual lines of text. This repeats rendered_text with
 * more specific bounding boxes.
 */
export interface HtmlrenderWebkitHeadlessProtoRenderTreeNodeInlineTextBox {
  box?: HtmlrenderWebkitHeadlessProtoBox;
  renderedText?: string;
}

/**
 * Next id: 9.
 */
export interface HtmlrenderWebkitHeadlessProtoResource {
  /**
   * content contains a complete HTTP response message including the HTTP
   * status line, headers and body. For example: HTTP/1.1 200 OK\r\n
   * Content-Type: text/html\r\n \r\n ... content ... For inputs
   * (RenderRequest.resource): Any HTTP content encoding (e.g. gzip) and
   * transfer encoding (e.g. chunked) MUST be decoded. HTTP content and transfer
   * encoding headers will be ignored if present. For outputs
   * (RenderResponse.referenced_resource_content): The body will be decoded (no
   * content or transfer encoding) however any content or transfer encoding
   * headers present in the original fetch response will be passed through.
   * Decoding this field requires a correct text encoding. The charset field of
   * Document proto can be a good guess but is not guaranteed to be correct.
   */
  content?: Uint8Array;
  /**
   * Where this resource comes from.
   */
  fetchSourceInfo?: WirelessTranscoderFetchFetchSourceInfo[];
  /**
   * The url that contributes the final content. Only existed when metadata
   * contains FetchReplyData.
   */
  finalContentUrl?: string;
  metadata?: WirelessTranscoderFetchFetchMetadata[];
  /**
   * The HTTP request method (GET, HEAD, POST, etc) used for this request.
   * Values are taken from the HTTPHeaders::Protocol enum in
   * webutil/http/httputils.h. If it's not set, we will infer GET or POST based
   * on the presence of post_data.
   */
  method?: number;
  postData?: Uint8Array;
  /**
   * Only necessary headers are included in the resource key by default. See
   * google3/htmlrender/webkit_headless/resource_key.cc
   */
  requestHeader?: HtmlrenderWebkitHeadlessProtoResourceHttpHeader[];
  url?: string;
}

function serializeHtmlrenderWebkitHeadlessProtoResource(data: any): HtmlrenderWebkitHeadlessProtoResource {
  return {
    ...data,
    content: data["content"] !== undefined ? encodeBase64(data["content"]) : undefined,
    metadata: data["metadata"] !== undefined ? data["metadata"].map((item: any) => (serializeWirelessTranscoderFetchFetchMetadata(item))) : undefined,
    postData: data["postData"] !== undefined ? encodeBase64(data["postData"]) : undefined,
  };
}

function deserializeHtmlrenderWebkitHeadlessProtoResource(data: any): HtmlrenderWebkitHeadlessProtoResource {
  return {
    ...data,
    content: data["content"] !== undefined ? decodeBase64(data["content"] as string) : undefined,
    metadata: data["metadata"] !== undefined ? data["metadata"].map((item: any) => (deserializeWirelessTranscoderFetchFetchMetadata(item))) : undefined,
    postData: data["postData"] !== undefined ? decodeBase64(data["postData"] as string) : undefined,
  };
}

export interface HtmlrenderWebkitHeadlessProtoResourceHttpHeader {
  name?: string;
  value?: string;
}

/**
 * Describes a script stack frame.
 */
export interface HtmlrenderWebkitHeadlessProtoScriptStackFrame {
  /**
   * The current column number for the stack frame.
   */
  columnNumber?: number;
  /**
   * The function name of the stack frame.
   */
  functionName?: string;
  /**
   * The current line number for the stack frame.
   */
  lineNumber?: number;
  /**
   * The URL of the script being executed.
   */
  url?: string;
}

/**
 * Next id: 54
 */
export interface HtmlrenderWebkitHeadlessProtoStyle {
  backgroundAttachment?:  | "SCROLL" | "FIXED";
  /**
   * Background color encoded as ARGB
   */
  backgroundColorArgb?: number;
  backgroundGradientColorStopArgb?: number[];
  backgroundGradientRepeat?: boolean;
  backgroundGradientType?:  | "LINEAR" | "RADIAL";
  backgroundImageRepeat?:  | "NO_REPEAT" | "REPEAT" | "REPEAT_X" | "REPEAT_Y";
  /**
   * The url of the background image in the first layer.
   */
  backgroundImageUrl?: string;
  /**
   * Background image position (x, y).
   */
  backgroundImageXPos?: HtmlrenderWebkitHeadlessProtoOffset;
  backgroundImageYPos?: HtmlrenderWebkitHeadlessProtoOffset;
  backgroundSize?:  | "CONTAIN" | "COVER" | "SIZE_LENGTH" | "SIZE_NONE";
  backgroundSizeHeight?: HtmlrenderWebkitHeadlessProtoOffset;
  /**
   * Only present (but may be missing) if background_size == SIZE_LENGTH.
   */
  backgroundSizeWidth?: HtmlrenderWebkitHeadlessProtoOffset;
  borderColorArgbBottom?: number;
  borderColorArgbLeft?: number;
  borderColorArgbRight?: number;
  borderColorArgbTop?: number;
  borderPixelWidthBottom?: number;
  borderPixelWidthLeft?: number;
  borderPixelWidthRight?: number;
  borderPixelWidthTop?: number;
  borderStyleBottom?:  | "BNONE" | "BHIDDEN" | "INSET" | "GROOVE" | "RIDGE" | "OUTSET" | "DOTTED" | "DASHED" | "SOLID" | "DOUBLE";
  borderStyleLeft?:  | "BNONE" | "BHIDDEN" | "INSET" | "GROOVE" | "RIDGE" | "OUTSET" | "DOTTED" | "DASHED" | "SOLID" | "DOUBLE";
  borderStyleRight?:  | "BNONE" | "BHIDDEN" | "INSET" | "GROOVE" | "RIDGE" | "OUTSET" | "DOTTED" | "DASHED" | "SOLID" | "DOUBLE";
  borderStyleTop?:  | "BNONE" | "BHIDDEN" | "INSET" | "GROOVE" | "RIDGE" | "OUTSET" | "DOTTED" | "DASHED" | "SOLID" | "DOUBLE";
  /**
   * Default value for clip is "auto", which is represented here as
   * !has_clip().
   */
  clip?: HtmlrenderWebkitHeadlessProtoRectangle;
  direction?:  | "LTR" | "RTL";
  display?:  | "BLOCK" | "INLINE" | "INLINE_BLOCK";
  /**
   * Font and text decorations:
   */
  fontFamily?: string;
  fontSize?: number;
  fontStyle?:  | "FONT_NORMAL" | "FONT_ITALIC";
  fontWeight?: number;
  /**
   * Foreground color encoded as ARGB
   */
  foregroundColorArgb?: number;
  /**
   * Starting from Chromium, has_background is set when there is a non-empty
   * specification for background_image, whether it be a url, gradient or other
   * cases, such as cross-fade. Besides setting this field, We additionally
   * parse url and gradient cases and populate some of the following background
   * fields.
   */
  hasBackground?: boolean;
  listStyleImageUrl?: string;
  listStyleType?:  | "DEFAULT_DISC" | "CIRCLE" | "SQUARE" | "DECIMAL_LIST_STYLE" | "DECIMAL_LEADING_ZERO" | "ARABIC_INDIC" | "BINARY_LIST_STYLE" | "BENGALI" | "CAMBODIAN" | "KHMER" | "DEVANAGARI" | "GUJARATI" | "GURMUKHI" | "KANNADA" | "LOWER_HEXADECIMAL" | "LAO" | "MALAYALAM" | "MONGOLIAN" | "MYANMAR" | "OCTAL" | "ORIYA" | "PERSIAN" | "URDU" | "TELUGU" | "TIBETAN" | "THAI" | "UPPER_HEXADECIMAL" | "LOWER_ROMAN" | "UPPER_ROMAN" | "LOWER_GREEK" | "LOWER_ALPHA" | "LOWER_LATIN" | "UPPER_ALPHA" | "UPPER_LATIN" | "AFAR" | "ETHIOPIC_HALEHAME_AA_ET" | "ETHIOPIC_HALEHAME_AA_ER" | "AMHARIC" | "ETHIOPIC_HALEHAME_AM_ET" | "AMHARIC_ABEGEDE" | "ETHIOPIC_ABEGEDE_AM_ET" | "CJK_EARTHLY_BRANCH" | "CJK_HEAVENLY_STEM" | "ETHIOPIC" | "ETHIOPIC_HALEHAME_GEZ" | "ETHIOPIC_ABEGEDE" | "ETHIOPIC_ABEGEDE_GEZ" | "HANGUL_CONSONANT" | "HANGUL" | "LOWER_NORWEGIAN" | "OROMO" | "ETHIOPIC_HALEHAME_OM_ET" | "SIDAMA" | "ETHIOPIC_HALEHAME_SID_ET" | "SOMALI" | "ETHIOPIC_HALEHAME_SO_ET" | "TIGRE" | "ETHIOPIC_HALEHAME_TIG" | "TIGRINYA_ER" | "ETHIOPIC_HALEHAME_TI_ER" | "TIGRINYA_ER_ABEGEDE" | "ETHIOPIC_ABEGEDE_TI_ER" | "TIGRINYA_ET" | "ETHIOPIC_HALEHAME_TI_ET" | "TIGRINYA_ET_ABEGEDE" | "ETHIOPIC_ABEGEDE_TI_ET" | "UPPER_GREEK" | "UPPER_NORWEGIAN" | "ASTERISKS" | "FOOTNOTES" | "HEBREW" | "ARMENIAN" | "LOWER_ARMENIAN" | "UPPER_ARMENIAN" | "GEORGIAN" | "CJK_IDEOGRAPHIC" | "HIRAGANA" | "KATAKANA" | "HIRAGANA_IROHA" | "KATAKANA_IROHA" | "NONE_LIST_STYLE";
  marginBottom?: HtmlrenderWebkitHeadlessProtoOffset;
  marginLeft?: HtmlrenderWebkitHeadlessProtoOffset;
  marginRight?: HtmlrenderWebkitHeadlessProtoOffset;
  /**
   * Margin
   */
  marginTop?: HtmlrenderWebkitHeadlessProtoOffset;
  opacity?: number;
  overflowX?:  | "OVISIBLE" | "OHIDDEN" | "OSCROLL" | "OAUTO" | "OOVERLAY" | "OMARQUEE";
  overflowY?:  | "OVISIBLE" | "OHIDDEN" | "OSCROLL" | "OAUTO" | "OOVERLAY" | "OMARQUEE";
  paddingBottom?: HtmlrenderWebkitHeadlessProtoOffset;
  paddingLeft?: HtmlrenderWebkitHeadlessProtoOffset;
  paddingRight?: HtmlrenderWebkitHeadlessProtoOffset;
  /**
   * Padding
   */
  paddingTop?: HtmlrenderWebkitHeadlessProtoOffset;
  position?:  | "POSITION_STATIC" | "POSITION_RELATIVE" | "POSITION_ABSOLUTE" | "POSITION_FIXED";
  /**
   * List of referenced resource indexes for any resources that this style
   * references. (e.g. background images.) (see document.proto)
   */
  referencedResourceIndex?: number[];
  textAlign?:  | "DEFAULT_TASTART" | "LEFT" | "RIGHT" | "CENTER" | "JUSTIFY" | "WEBKIT_LEFT" | "WEBKIT_RIGHT" | "WEBKIT_CENTER" | "TAEND";
  textDecoration?:  | "NONE" | "UNDERLINED" | "LINE_THROUGH";
  textShadowColorArgb?: number;
  visibility?:  | "VISIBLE" | "HIDDEN" | "COLLAPSE";
  /**
   * Default value for z-index is "auto" which means "inherit from parent".
   */
  zIndex?: number;
}

/**
 * WebkKitFetchMetadata holds additional webkit-specific information for a
 * single resource fetch.
 */
export interface HtmlrenderWebkitHeadlessProtoWebKitFetchMetadata {
  /**
   * Chromium DevTools frame ID of the frame that initiated this fetch. Only
   * populated in the streaming render service with FETCH_MODE_CLIENT.
   */
  devtoolsFrameId?: string;
  targetType?:  | "TARGET_UNSPECIFIED" | "TARGET_MAIN_FRAME" | "TARGET_SUBFRAME" | "TARGET_SUBRESOURCE" | "TARGET_STYLE_SHEET" | "TARGET_SCRIPT" | "TARGET_FONT" | "TARGET_IMAGE" | "TARGET_OBJECT" | "TARGET_MEDIA" | "TARGET_WORKER" | "TARGET_SHARED_WORKER" | "TARGET_PREFETCH" | "TARGET_FAVICON" | "TARGET_XHR" | "TARGET_TEXT_TRACK" | "TARGET_BEACON" | "TARGET_FILE" | "TARGET_MANIFEST" | "TARGET_PING" | "TARGET_RAW" | "TARGET_EVENT_SOURCE";
}

/**
 * Corresponds to a call to window.open(). Note that a WindowOpenEvent will be
 * present whether or not the call was successful.
 */
export interface HtmlrenderWebkitHeadlessProtoWindowOpenEvent {
  /**
   * Whether or not the window was allowed to be opened by the popup blocker.
   * Unless user events are created with a render extension this should be
   * false.
   */
  allowed?: boolean;
  /**
   * The URL for the new window. Note that this is the URL after it has been
   * processed by WebKit, so, for example, relative links passed to
   * window.create() will have been made absolute.
   */
  url?: string;
  /**
   * Window features passed to window.open().
   */
  windowFeatures?: string;
  /**
   * Window name passed to window.open(). If no name is provided this defaults
   * to "_blank".
   */
  windowName?: string;
}

/**
 * The PhoneNumber object that is used by all LibPhoneNumber API's to fully
 * represent a phone number.
 */
export interface I18nPhonenumbersPhoneNumber {
  /**
   * The country calling code for this number, as defined by the International
   * Telecommunication Union (ITU). For example, this would be 1 for NANPA
   * countries, and 33 for France.
   */
  countryCode?: number;
  /**
   * The source from which the country_code is derived.
   */
  countryCodeSource?:  | "UNSPECIFIED" | "FROM_NUMBER_WITH_PLUS_SIGN" | "FROM_NUMBER_WITH_IDD" | "FROM_NUMBER_WITHOUT_PLUS_SIGN" | "FROM_DEFAULT_COUNTRY";
  /**
   * Extension is not standardized in ITU recommendations, except for being
   * defined as a series of numbers with a maximum length of 40 digits. It is
   * defined as a string here to accommodate for the possible use of a leading
   * zero in the extension (organizations have complete freedom to do so, as
   * there is no standard defined). Other than digits, some other dialling
   * characters such as "," (indicating a wait) may be stored here.
   */
  extension?: string;
  /**
   * In some countries, the national (significant) number starts with one or
   * more "0"s without this being a national prefix or trunk code of some kind.
   * For example, the leading zero in the national (significant) number of an
   * Italian phone number indicates the number is a fixed-line number. There
   * have been plans to migrate fixed-line numbers to start with the digit two
   * since December 2000, but it has not happened yet. See
   * http://en.wikipedia.org/wiki/%2B39 for more details. These fields can be
   * safely ignored (there is no need to set them) for most countries. Some
   * limited number of countries behave like Italy - for these cases, if the
   * leading zero(s) of a number would be retained even when dialling
   * internationally, set this flag to true, and also set the number of leading
   * zeros. Clients who use the parsing or conversion functionality of the i18n
   * phone number libraries (go/phonenumbers) will have these fields set if
   * necessary automatically.
   */
  italianLeadingZero?: boolean;
  /**
   * The National (significant) Number, as defined in International
   * Telecommunication Union (ITU) Recommendation E.164, without any leading
   * zero. The leading-zero is stored separately if required, since this is an
   * uint64 and hence cannot store such information. Do not use this field
   * directly: if you want the national significant number, call the
   * getNationalSignificantNumber method of PhoneNumberUtil. For countries which
   * have the concept of an "area code" or "national destination code", this is
   * included in the National (significant) Number. Although the ITU says the
   * maximum length should be 15, we have found longer numbers in some countries
   * e.g. Germany. Note that the National (significant) Number does not contain
   * the National (trunk) prefix. Obviously, as a uint64, it will never contain
   * any formatting (hyphens, spaces, parentheses), nor any alphanumeric
   * spellings.
   */
  nationalNumber?: bigint;
  /**
   * Full description of this field in the comment for italian_leading_zero
   * since this field will only be set when italian_leading_zero is true.
   */
  numberOfLeadingZeros?: number;
  /**
   * The carrier selection code that is preferred when calling this phone
   * number domestically. This also includes codes that need to be dialed in
   * some countries when calling from landlines to mobiles or vice versa. For
   * example, in Columbia, a "3" needs to be dialed before the phone number
   * itself when calling from a mobile phone to a domestic landline phone and
   * vice versa. Note this is the "preferred" code, which means other codes may
   * work as well.
   */
  preferredDomesticCarrierCode?: string;
  /**
   * This field is used to store the raw input string containing phone numbers
   * before it was canonicalized by the library. For example, it could be used
   * to store alphanumerical numbers such as "1-800-GOOG-411".
   */
  rawInput?: string;
}

function serializeI18nPhonenumbersPhoneNumber(data: any): I18nPhonenumbersPhoneNumber {
  return {
    ...data,
    nationalNumber: data["nationalNumber"] !== undefined ? String(data["nationalNumber"]) : undefined,
  };
}

function deserializeI18nPhonenumbersPhoneNumber(data: any): I18nPhonenumbersPhoneNumber {
  return {
    ...data,
    nationalNumber: data["nationalNumber"] !== undefined ? BigInt(data["nationalNumber"]) : undefined,
  };
}

/**
 * Next ID: 15
 */
export interface ImageBaseThumbnailMetadata {
  /**
   * the size of the stored thumbnail
   */
  byteSize?: number;
  /**
   * SmartCrop crop-hints By default, this field is not populated.
   */
  crops?: ContentAwareCropsIndexing;
  /**
   * DeepCrop crop-hints. Usage in thumbnails could be deprecated in favor or
   * deep_crop_pixels (below). By default, this field is not populated.
   */
  deepCrop?: DeepCropIndexing;
  /**
   * DeepCrop signal in pixels, equivalent to deep_crop (above) but with pixels
   * instead of percentages. By default, this field is not populated.
   */
  deepCropPixels?: DeepCropPixels;
  /**
   * the Amarna docid of the thumbnail
   */
  docid?: bigint;
  /**
   * encrypted version of docid
   */
  encryptedDocid?: string;
  /**
   * the fprint of the thumbnail
   */
  fprint?: bigint;
  /**
   * the height of the stored thumbnail
   */
  height?: number;
  /**
   * The mime_type of the thumbnail ("image/jpeg", "image/png", etc.).
   */
  mimeType?: string;
  originalHeight?: number;
  /**
   * Not populated by Amarna/image pipelines, ever. This was apparently
   * introduced by a customer that wished to extend ThumbnailMetadata with this
   * custom data.
   */
  originalWidth?: number;
  type?:  | "THUMBNAIL_TYPE_DEFAULT" | "THUMBNAIL_TYPE_AREA_50K" | "THUMBNAIL_TYPE_400" | "THUMBNAIL_TYPE_800" | "THUMBNAIL_TYPE_ORIGINAL" | "THUMBNAIL_TYPE_ORIGINAL_HQ" | "THUMBNAIL_TYPE_FAVICON_16" | "THUMBNAIL_TYPE_FAVICON_28" | "THUMBNAIL_TYPE_FAVICON_32" | "THUMBNAIL_TYPE_FAVICON_64" | "THUMBNAIL_TYPE_FAVICON_ORIGINAL" | "THUMBNAIL_TYPE_FAVICON_16_DARK" | "THUMBNAIL_TYPE_FAVICON_28_DARK" | "THUMBNAIL_TYPE_FAVICON_32_DARK" | "THUMBNAIL_TYPE_FAVICON_64_DARK" | "THUMBNAIL_TYPE_FAVICON_ORIGINAL_DARK" | "THUMBNAIL_TYPE_1080" | "THUMBNAIL_TYPE_1600_HQ" | "THUMBNAIL_TYPE_AREA_300K" | "THUMBNAIL_TYPE_AREA_50K_ALPHA" | "THUMBNAIL_TYPE_AREA_50K_SYNTHETIC_ALPHA" | "THUMBNAIL_TYPE_AREA_2M" | "THUMBNAIL_TYPE_AREA_2M_METADATA" | "THUMBNAIL_TYPE_800_ALPHA_WHITE" | "THUMBNAIL_TYPE_ORIGINAL_ALPHA_WHITE" | "THUMBNAIL_TYPE_ANIMATED_H144" | "THUMBNAIL_TYPE_ORIGINAL_HQ_LICENSED" | "THUMBNAIL_TYPE_TENOR_250K_GIF" | "THUMBNAIL_TYPE_TENOR_100K_OPTIMIZED_GIF" | "THUMBNAIL_TYPE_TENOR_30K_OPTIMIZED_THUMBNAIL_GIF" | "THUMBNAIL_TYPE_TENOR_45K_OPTIMIZED_90P_GIF" | "THUMBNAIL_TYPE_TENOR_50K_OPTIMIZED_100P_GIF" | "THUMBNAIL_TYPE_TENOR_100K_OPTIMIZED_200P_GIF" | "THUMBNAIL_TYPE_TENOR_50K_OPTIMIZED_100W_GIF" | "THUMBNAIL_TYPE_TENOR_100K_OPTIMIZED_200W_GIF" | "THUMBNAIL_TYPE_TENOR_45K_PREVIEW_GIF" | "THUMBNAIL_TYPE_TENOR_250K_MEDIUM_GIF" | "THUMBNAIL_TYPE_AREA_2M_WEBP" | "THUMBNAIL_TYPE_AREA_2M_WEBP_METADATA" | "THUMBNAIL_TYPE_AREA_2M_AVIF" | "THUMBNAIL_TYPE_AREA_2M_AVIF_METADATA" | "THUMBNAIL_TYPE_AREA_50K_WEBP" | "THUMBNAIL_TYPE_AREA_50K_AVIF" | "THUMBNAIL_TYPE_ORIGINAL_HQ_KG";
  /**
   * the width of the stored thumbnail
   */
  width?: number;
}

function serializeImageBaseThumbnailMetadata(data: any): ImageBaseThumbnailMetadata {
  return {
    ...data,
    crops: data["crops"] !== undefined ? serializeContentAwareCropsIndexing(data["crops"]) : undefined,
    deepCrop: data["deepCrop"] !== undefined ? serializeDeepCropIndexing(data["deepCrop"]) : undefined,
    docid: data["docid"] !== undefined ? String(data["docid"]) : undefined,
    fprint: data["fprint"] !== undefined ? String(data["fprint"]) : undefined,
  };
}

function deserializeImageBaseThumbnailMetadata(data: any): ImageBaseThumbnailMetadata {
  return {
    ...data,
    crops: data["crops"] !== undefined ? deserializeContentAwareCropsIndexing(data["crops"]) : undefined,
    deepCrop: data["deepCrop"] !== undefined ? deserializeDeepCropIndexing(data["deepCrop"]) : undefined,
    docid: data["docid"] !== undefined ? BigInt(data["docid"]) : undefined,
    fprint: data["fprint"] !== undefined ? BigInt(data["fprint"]) : undefined,
  };
}

/**
 * This message is used internally in Amarna and is also used to store
 * information in the VideoWebAttachment portion of the websearch index. Only
 * the following fields will be used in the index: VideoPreviewType type int32
 * width int32 height byte byte_size If more fields are added, please update
 * this list.
 */
export interface ImageBaseVideoPreviewMetadata {
  /**
   * Size of the stored preview.
   */
  byteSize?: number;
  /**
   * 64 bit docid of the original video.
   */
  docid?: bigint;
  /**
   * TODO (yzliu): consider using duration_ms as field name since it is number
   * of milliseconds. Duration of the preview in ms.
   */
  duration?: number;
  /**
   * Expiration timestamp of preview in microseconds since epoch.
   */
  expirationTimestampMicros?: bigint;
  /**
   * 
   * LINT.ThenChange(//depot/google3/video/crawl/indexing/signal_combiner.cc:video_preview)
   * Fingerprint of the preview.
   */
  fprint?: bigint;
  /**
   * Height of the stored preview.
   */
  height?: number;
  /**
   * Mime type of the preview ("video/mp4").
   */
  mimeType?: string;
  /**
   * Indicates the state in Venom for this preview type.
   */
  state?:  | "STATE_UNKNOWN" | "STATE_DONE" | "STATE_NOT_APPLICABLE" | "STATE_MISSING" | "STATE_DELETED" | "STATE_DIRTY" | "STATE_OBSOLETE" | "STATE_PENDING_PUBLICATION" | "STATE_FAILED";
  /**
   * Timestamp of start of preview in ms.
   */
  timestamp?: number;
  /**
   * LINT.IfChange
   */
  type?:  | "VPREVIEW_TYPE_8K" | "VPREVIEW_TYPE_30K" | "VPREVIEW_TYPE_90K" | "VPREVIEW_TYPE_300K_24FPS" | "VPREVIEW_TYPE_VERTICAL_30K" | "VPREVIEW_TYPE_VERTICAL_90K" | "VPREVIEW_TYPE_540K_ORIGINAL_HQ_LICENSED" | "VPREVIEW_TYPE_90K_SPORT_HIGHLIGHT" | "VPREVIEW_TYPE_VIDEO_ANSWER_300K_15SEC" | "VPREVIEW_TYPE_VIDEO_ANSWER_300K_6SEC" | "VPREVIEW_TENOR_250K_PREVIEW" | "VPREVIEW_TENOR_100K_OPTIMIZED_PREVIEW" | "VPREVIEW_TENOR_30K_OPTIMIZED_THUMBNAIL_PREVIEW" | "VPREVIEW_TENOR_45K_OPTIMIZED_90P_PREVIEW" | "VPREVIEW_TENOR_50K_OPTIMIZED_100P_PREVIEW" | "VPREVIEW_TENOR_100K_OPTIMIZED_200P_PREVIEW" | "VPREVIEW_TENOR_50K_OPTIMIZED_100W_PREVIEW" | "VPREVIEW_TENOR_100K_OPTIMIZED_200W_PREVIEW" | "VPREVIEW_TENOR_250K_MEDIUM_PREVIEW" | "VPREVIEW_TENOR_250K_TINY_VIDEO_PREVIEW" | "VPREVIEW_TENOR_250K_NANO_VIDEO_PREVIEW" | "VPREVIEW_TENOR_100K_PREVIEW_MP4" | "VPREVIEW_TENOR_250K_MP4" | "VPREVIEW_TENOR_250K_MP4_AV" | "VPREVIEW_TENOR_160K_TINY_MP4" | "VPREVIEW_TENOR_75K_NANO_MP4" | "VPREVIEW_TENOR_50K_FIXED_100P_MP4" | "VPREVIEW_TENOR_100K_FIXED_200P_MP4" | "VPREVIEW_TENOR_50K_FIXED_100W_MP4" | "VPREVIEW_TENOR_100K_FIXED_200W_MP4";
  /**
   * The end timestamp of the video segment in microseconds that this preview
   * is generated from. Used for segmented video previews.
   */
  videoSegmentEndUs?: bigint;
  /**
   * The start timestamp of the video segment in microseconds that this preview
   * is generated from. Used for segmented video previews.
   */
  videoSegmentStartUs?: bigint;
  /**
   * Width of the stored preview.
   */
  width?: number;
}

function serializeImageBaseVideoPreviewMetadata(data: any): ImageBaseVideoPreviewMetadata {
  return {
    ...data,
    docid: data["docid"] !== undefined ? String(data["docid"]) : undefined,
    expirationTimestampMicros: data["expirationTimestampMicros"] !== undefined ? String(data["expirationTimestampMicros"]) : undefined,
    fprint: data["fprint"] !== undefined ? String(data["fprint"]) : undefined,
    videoSegmentEndUs: data["videoSegmentEndUs"] !== undefined ? String(data["videoSegmentEndUs"]) : undefined,
    videoSegmentStartUs: data["videoSegmentStartUs"] !== undefined ? String(data["videoSegmentStartUs"]) : undefined,
  };
}

function deserializeImageBaseVideoPreviewMetadata(data: any): ImageBaseVideoPreviewMetadata {
  return {
    ...data,
    docid: data["docid"] !== undefined ? BigInt(data["docid"]) : undefined,
    expirationTimestampMicros: data["expirationTimestampMicros"] !== undefined ? BigInt(data["expirationTimestampMicros"]) : undefined,
    fprint: data["fprint"] !== undefined ? BigInt(data["fprint"]) : undefined,
    videoSegmentEndUs: data["videoSegmentEndUs"] !== undefined ? BigInt(data["videoSegmentEndUs"]) : undefined,
    videoSegmentStartUs: data["videoSegmentStartUs"] !== undefined ? BigInt(data["videoSegmentStartUs"]) : undefined,
  };
}

/**
 * The subset of FlowProto that we want to go into production AND be stored in
 * ContentSignals.
 */
export interface ImageContentFlowProtoProd {
  /**
   * Repeated so that multiple versions can exist in prod simultaneously.
   */
  starburst?: ImageContentStarburstVersionGroup[];
}

function serializeImageContentFlowProtoProd(data: any): ImageContentFlowProtoProd {
  return {
    ...data,
    starburst: data["starburst"] !== undefined ? data["starburst"].map((item: any) => (serializeImageContentStarburstVersionGroup(item))) : undefined,
  };
}

function deserializeImageContentFlowProtoProd(data: any): ImageContentFlowProtoProd {
  return {
    ...data,
    starburst: data["starburst"] !== undefined ? data["starburst"].map((item: any) => (deserializeImageContentStarburstVersionGroup(item))) : undefined,
  };
}

/**
 * Image content based multipliers. Current usage is in the pamir_section.
 */
export interface ImageContentQueryBoost {
  queryboost?: ImageContentQueryBoostQueryBoost[];
}

export interface ImageContentQueryBoostQueryBoost {
  /**
   * Score multiplier (fully normalized 1 is nop).
   */
  boost?: number;
  /**
   * Canonicalized query string.
   */
  query?: string;
}

export interface ImageContentStarburstVersionGroup {
  /**
   * Raw dense float feature vector.
   */
  descriptorFloat?: number[];
  /**
   * Short descriptor for image content features, e.g. compressed bytes. This
   * is the compressed version of descriptor_float below. It can be can be
   * decompressed to descriptor_float with a tiny bit of compression error (in
   * most cases it should be totally fine).
   */
  descriptorShort?: Uint8Array;
  enumVersion?:  | "UNKNOWN_VERSION" | "STARBURST_V1" | "STARBURST_V2" | "STARBURST_V3" | "STARBURST_V4" | "STARBURST_VISUAL_V4" | "STARBURST_V5" | "STARBURST_V5_5";
  minorVersion?:  | "UNKNOWN_MINOR_VERSION" | "V3_ORIGINAL" | "V3_ENET_EMULATED" | "V3_FNET_EMULATED" | "V3_STARBURST_LITE" | "V4_ORIGINAL" | "V4_STRETCH_RESIZE" | "VISUAL_V4_ORIGINAL" | "V5_ORIGINAL" | "V5_5_ORIGINAL";
  /**
   * Starburst tokens.
   */
  starburstTokens?: number[];
  /**
   * The following integers are currently used: Starburst V1: 1 Starburst V2: 2
   * Starburst V3: 3 Starburst V4: 4 Starburst Visual V4: 1004 This field is
   * deprecated. Please try to use the 'enum_version' in future.
   */
  version?: number;
}

function serializeImageContentStarburstVersionGroup(data: any): ImageContentStarburstVersionGroup {
  return {
    ...data,
    descriptorShort: data["descriptorShort"] !== undefined ? encodeBase64(data["descriptorShort"]) : undefined,
  };
}

function deserializeImageContentStarburstVersionGroup(data: any): ImageContentStarburstVersionGroup {
  return {
    ...data,
    descriptorShort: data["descriptorShort"] !== undefined ? decodeBase64(data["descriptorShort"] as string) : undefined,
  };
}

/**
 * This defines the per-doc data which is extracted from thumbnails and
 * propagated over to indexing. It contains all information that can be used for
 * restricts. Next tag id: 129
 */
export interface ImageData {
  /**
   * Warning: adaboost_image_feature_porn* and imageFeaturePorn fields are
   * DEPRECATED in favor of brain_porn_scores. Please do not use them. Contact
   * safesearch@ for transition advice.
   */
  adaboostImageFeaturePorn?: number;
  adaboostImageFeaturePornMinorVersion?: number;
  adaboostImageFeaturePornVersion?: number;
  /**
   * Present for animated images only: additional animatated image perdoc data.
   */
  animatedImageData?: ImageRepositoryAnimatedImagePerdocData;
  /**
   * A [0..1] SafeSearch scores based on image pixels, using Google Brain:
   * porn, csai, violence, medical, and spoof. For porn only, if available
   * prefer final_porn_score as it should be more precise than
   * brain_porn_scores.porn_score.
   */
  brainPornScores?: ImageSafesearchContentBrainPornAnnotation;
  /**
   * A string that indicates the version of SafeSearch classifier used to
   * compute brain_porn_scores.
   */
  brainPornScoresVersion?: string;
  /**
   * This is the image docid used in image search. For ImageData protos coming
   * from Alexandria/Freshdocs, this is a 'required' field that MUST be
   * populated.
   */
  canonicalDocid?: bigint;
  /**
   * A score in (0, 1] to indicate how likely this image is considered as a
   * click magnet based on clicks received from bad queries.
   */
  clickMagnetScore?: number;
  /**
   * Image content based classifier scores.
   */
  clipartDetectorScore?: number;
  clipartDetectorVersion?: number;
  /**
   * Superlabels generated cluster id.
   */
  clusterId?: Uint8Array;
  /**
   * Like is_visible, this is a property of the (web-doc, img_url) pair not
   * just the image. A high codomain_strength indicates high confidence based on
   * collected stats that the image is hosted on a companion domain. If not
   * enough stats are available for codomain strength, this field may be absent
   * in ImageData, and hence the CompositeDoc. Do not place negative values
   * here. Permitted values range between 0 and
   * image_quality_codomain::kMaxCodomainStrength defined in
   * //image/quality/codomain/codomain-stats-utils.h.
   */
  codomainStrength?: number;
  /**
   * Fraction of the image that contains pixels over a certain saturation
   * threshold: can be used to determine if the image is grayscale or not.
   */
  coloredPixelsFrac?: number;
  /**
   * Colorness scores for the image. Each score represents the amount of a
   * particular color in the image. At the current time, there are 12 colors, so
   * there should always be 0 or 12 values in this array. The 12 colors are
   * black, blue, brown, gray, green, orange, pink, purple, red, teal, white,
   * yellow. The convention is that the scores are stored in alphabetical order,
   * so the first score is black, and the last score is yellow.
   */
  colorScore?: number[];
  colorScoreVersion?: number;
  /**
   * Earliest known crawl time among all neardups of this image
   * (go/imagecontentage).
   */
  contentFirstCrawlTime?: number;
  /**
   * Corpus scoring info for images indexed through Amarna.
   */
  corpusSelectionInfo?: CorpusSelectionInfo[];
  /**
   * The content-aware cropping information.
   */
  crops?: ContentAwareCropsIndexing;
  /**
   * DeepCrop based cropping information. See go/creatism/deepcrop for details.
   */
  deepCrop?: DeepCropIndexing;
  /**
   * Productionized Deep Image Engagingness score.
   */
  deepImageEngagingness?: ImageRepositoryDeepImageEngagingnessOutput;
  /**
   * VSS generated deep tags for shopping images.
   */
  deepTags?: CommerceDatastoreImageDeepTags;
  /**
   * fingerprint(non-canonicalized absolute image url) This is *not* the image
   * docid. Use canonical_docid instead. For ImageData protos coming from
   * Alexandria/Freshdocs, this is a 'required' field that MUST be populated.
   * But once again, this is very likely NOT something you need. Use
   * canonical_docid instead.
   */
  docid?: bigint;
  /**
   * the EXIF/IPTC metadata
   */
  embeddedMetadata?: ImageExifImageEmbeddedMetadata;
  /**
   * The thumbnail is guaranteed to be kept in the serving system until the
   * expiration timestamp has passed, in microseconds.
   */
  expirationTimestamp?: bigint;
  /**
   * The EXIF generated by photos backend team's (more specifically FIFE's)
   * thumbnailer library. This exif model is more comprehensive since a
   * dedicated team is constantly improving it and adding new fields over time.
   * This is currently populated by moonshine for selected corpora.
   */
  extendedExif?: PhotosImageMetadata;
  /**
   * Properties used in featured imagesearch project. inspiration_score
   * indicates how well an image is related to products, or how inspirational it
   * is.
   */
  featuredImageProp?: ImageMonetizationFeaturedImageProperties;
  /**
   * True file format (not extension).
   */
  fileFormat?:  | "FF_INVALID" | "FF_JPG" | "FF_GIF" | "FF_PNG" | "FF_BMP" | "FF_SVG" | "FF_WEBP" | "FF_ICO" | "FF_CRAW" | "FF_HEIF";
  /**
   * A [0..1] porn score based on some image-level features (like content
   * score, referrer statistics, navboost queries, etc.). See class
   * RiflePornScorer for more details.
   */
  finalPornScore?: number;
  /**
   * A string that indicates the version of SafeSearch classifier used to
   * compute final_porn_score.
   */
  finalPornScoreVersion?: string;
  /**
   * Earliest known timestamp about this image. Today, this is the timestamp
   * when the content key was generated for this image. The time is in seconds.
   */
  firstCrawlTime?: number;
  /**
   * The first time this image URL was seen on the containing web page. Only
   * set during web indexing.
   */
  firstTimeSeenOnDocSec?: number;
  /**
   * Use image_perdoc.h to read/write 'flags'.
   */
  flags?: number;
  /**
   * The output of various features generated by the Flow framework, most
   * importantly data from Starburst (go/starburst). Do NOT interact with the
   * internals of this proto since they may change over time. Instead, use the
   * existing interfaces that consume FlowProtoProd's directly, e.g.,
   * image/mustang/content/image_content_distance.h For more info, please
   * contact image-content-core@.
   */
  flowOutput?: ImageContentFlowProtoProd;
  h2c?: number;
  /**
   * 'Hovers to Impressions' and 'Hovers to Clicks' ratios for an image.
   */
  h2i?: number;
  /**
   * Hate logo detections from the VSS logo_recognition module.
   */
  hateLogoDetection?: ImageUnderstandingIndexingAnnotationGroup;
  /**
   * Height
   */
  height?: number;
  /**
   * Image Content Scored per query boosts. Currently this is filled by the
   * pamir algorithm and populates the pamir_section.
   */
  imageContentQueryBoost?: ImageContentQueryBoost;
  /**
   * A set of query fingerprints and confidence scores. There queries are
   * supposed to be relevant to the image with high confidence.
   */
  imageExactBoost?: ImageExactBoost;
  /**
   * Indicates license info of this image, which will tell image search users
   * how to use this image legally.
   */
  imageLicenseInfo?: ImageSearchImageLicenseInfo;
  imagerank?: number;
  /**
   * Regions detected within the image (go/images-region-search-edd). Regions
   * contain bounding boxes circumscribing objects of interest in the image,
   * along with object labels. Regions may overlap.
   */
  imageRegions?: ImageRegionsImageRegions;
  /**
   * IIP in scope signal (go/iip). Set to true if the image is annotated with
   * any iip_in_scope entities (go/iukp-trust-v2).
   */
  isIipInScope?: boolean;
  /**
   * If this image was not selected for indexing by imagesearch, these fields
   * say so and explain why.
   */
  isIndexedByImagesearch?: boolean;
  /**
   * True if the original image contains multiple frames (e.g., for animated or
   * stereoscopic images).
   */
  isMultiframe?: boolean;
  /**
   * Field to indicate the image is unwanted for search index. The data is
   * propagated from amarna to alexandria to be annotated in the cdoc. Refer to
   * image/repository/proto/unwanted_content.proto for more info.
   */
  isUnwantedContent?: boolean;
  /**
   * True if the image is inlined on the page (typicially via ) or false if the
   * image is linked to (via an href).
   */
  isVisible?: boolean;
  /**
   * Fraction of image covered by the largest face (should match
   * largestFaceFraction, but without scaling). In perdocs, is set only if
   * numberFaces > 0.
   */
  largestFaceFrac?: number;
  /**
   * Fraction of image covered by the largest face, scaled by 1000. Warning: Is
   * DEPRECATED in favor of largest_face_frac. Do not use.
   */
  largestFaceFraction?: number;
  /**
   * Most recent timestamp in seconds when this URL was crawled.
   */
  lastCrawlTime?: number;
  /**
   * Indicates the web-master opt-in state of this image, and will be used for
   * Google products to decide usage rights like showing large previews.
   */
  licensedWebImagesOptInState?:  | "IMAGES_OPTIN_NONE" | "IMAGES_OPTIN_FULL" | "PAGE_SNIPPET_CONTROL_SIZE_NONE" | "PAGE_SNIPPET_CONTROL_SIZE_STANDARD" | "PAGE_SNIPPET_CONTROL_SIZE_LARGE" | "IMAGE_TAG_SNIPPET_CONTROL_SIZE_NONE" | "IMAGE_TAG_SNIPPET_CONTROL_SIZE_STANDARD" | "IMAGE_TAG_SNIPPET_CONTROL_SIZE_LARGE";
  lineartDetectorScore?: number;
  lineartDetectorVersion?: number;
  multibangKgEntities?: ImageDataMultibangEntities;
  nearDupFeatures?: Uint8Array;
  nearDupFeaturesSmall?: Uint8Array[];
  /**
   * The following fields contain information about a smaller and less powerful
   * version of the hash, needed for neardup retrieval. A compressed and an
   * encoded version of the small hash are stored below. The smaller hash may
   * have a few variants to increase recall. NOTE: This hash is generated by V2
   * hash computation. A compressed version of the small hash. Currently, a
   * 4-byte fingerprint.
   */
  nearDupFeaturesSmallVersion?: number;
  /**
   * Image content derived data used for finding image near dups. NOTE: This
   * hash is generated by V1 hash computation.
   */
  nearDupFeaturesVersion?: number;
  /**
   * Productionized Nima AVA score. Both this field and nima_vq were added on
   * the top of nima_ava_score and nima_vq_score because the signals are already
   * integrated with Batch Amarna in
   * image/repository/schema/global_output_tags.h using NimaOutput.
   */
  nimaAva?: ImageRepositoryNimaOutput;
  /**
   * Productionized Nima VQ score.
   */
  nimaVq?: ImageRepositoryNimaOutput;
  noIndexReason?:  | "NO_INDEX_IMAGE_URL_NOT_SELECTED" | "NO_INDEX_REFERRER_URL_NOT_SELECTED" | "NO_INDEX_X_RAW_IMAGE" | "NO_INDEX_FAVICON" | "NO_INDEX_DETECTED_VIA_CONTENT" | "NO_INDEX_EXTERNAL_VIDEO_THUMBNAIL" | "NO_INDEX_ONSITE_ANCHOR" | "NO_INDEX_RSS_FEED" | "NO_INDEX_REJECTED_BY_IMAGE_SELECTION" | "NO_INDEX_EXPIRED_THUMBNAIL" | "NO_INDEX_REJECTED_BY_IMAGE_SELECTION_V1" | "NO_INDEX_REJECTED_BY_PYTHIA" | "NO_INDEX_EMPTY_THUMBNAIL"[];
  /**
   * Number of faces detected in the image
   */
  numberFaces?: number;
  /**
   * Pruned OCR Goodoc see vss_aksara_ocr_util.h for the fields copied.
   */
  ocrGoodoc?: GoodocDocument;
  /**
   * Ocr detected by ocr_taser module.
   */
  ocrTaser?: GoodocDocument;
  /**
   * Text lines detected by OCR engine.
   */
  ocrTextboxes?: OcrPhotoTextBox[];
  /**
   * For an image not explicitly visible on this page, the following url is the
   * one which most closely matches it.
   */
  onPageAlternateUrl?: string;
  /**
   * Encodes face number and largest face frac into a small package for storage
   * in mustang. This is calculated directly from FaceDetectionResult.
   */
  packedFullFaceInfo?: FaceIndexing;
  /**
   * Contains person attributes from the LookNet-Person model and the Style AI
   * Iconic Person Scorer for the most iconic person in a style image.
   */
  personAttributes?: LensDiscoveryStylePersonAttributes;
  /**
   * Contains person detection result.
   */
  personDetectionSignals?: LensDiscoveryStylePersonDetectionSignals;
  photoDetectorScore?: number;
  photoDetectorVersion?: number;
  /**
   * Used by the segindexer for combined www+image indices.
   */
  pornFlagData?: PornFlagData;
  /**
   * Restricts computed before building a Mustang index.
   */
  precomputedRestricts?: PrecomputedRestricts;
  /**
   * Rank in near-dup cluster (go/image-rank-in-neardup-cluster). The rank is
   * 1-indexed: rank 1 is the best.
   */
  rankInNeardupCluster?: number;
  /**
   * A string representation of all the restricts associated with this image.
   */
  restrictStrings?: string[];
  /**
   * CSV list of user agents for which this image should be considered roboted.
   * Note: All images are crawled using googlebot-images, this exists for
   * clients that require additional restrictions beyond googlebot-images such
   * as news.
   */
  robotedAgents?: string;
  /**
   * The Shoppable Images product information to be annotated in the Cdoc. All
   * fields will be populated except the product location bounding box.
   */
  shoppingProductInformation?: ImageRepositoryShoppingProductInformation;
  /**
   * Size in bytes of original (non-thumbnail)
   */
  size?: number;
  /**
   * Web docids that correspond to high ranked smeared landing pages for this
   * image. Used for conditional retrieval of actionable landing pages for image
   * search.
   */
  smearedTopWebLandingPageDocids?: bigint[];
  smearedTopWebLandingPages?: SmearedWebLandingPageEntry[];
  /**
   * Aesthetics score of a style image.
   */
  styleAestheticsScore?: LensDiscoveryStyleAestheticsScoreSignals;
  /**
   * Prediction of a style image type: Stage, Stock, Street or Outfits.
   */
  styleImageType?: LensDiscoveryStyleStyleImageTypeSignals;
  /**
   * This field is for testing purposes, more information in
   * go/media-dirt-2022.
   */
  testingScore?: number;
  thumbHeight?: number;
  thumbnail?: ImageDataThumbnail[];
  thumbSize?: number;
  /**
   * Thumbnail width.
   */
  thumbWidth?: number;
  /**
   * Time in seconds since epoch after which this image should be considered
   * unavailable.
   */
  unavailableAfterSecs?: bigint;
  /**
   * Canonicalized absolute image url.
   */
  url?: string;
  whiteBackgroundScore?: number;
  /**
   * Image is likely an object on a white background (value on [0,1]).
   */
  whiteBackgroundScoreVersion?: number;
  width?: number;
}

function serializeImageData(data: any): ImageData {
  return {
    ...data,
    canonicalDocid: data["canonicalDocid"] !== undefined ? String(data["canonicalDocid"]) : undefined,
    clusterId: data["clusterId"] !== undefined ? encodeBase64(data["clusterId"]) : undefined,
    corpusSelectionInfo: data["corpusSelectionInfo"] !== undefined ? data["corpusSelectionInfo"].map((item: any) => (serializeCorpusSelectionInfo(item))) : undefined,
    crops: data["crops"] !== undefined ? serializeContentAwareCropsIndexing(data["crops"]) : undefined,
    deepCrop: data["deepCrop"] !== undefined ? serializeDeepCropIndexing(data["deepCrop"]) : undefined,
    docid: data["docid"] !== undefined ? String(data["docid"]) : undefined,
    embeddedMetadata: data["embeddedMetadata"] !== undefined ? serializeImageExifImageEmbeddedMetadata(data["embeddedMetadata"]) : undefined,
    expirationTimestamp: data["expirationTimestamp"] !== undefined ? String(data["expirationTimestamp"]) : undefined,
    extendedExif: data["extendedExif"] !== undefined ? serializePhotosImageMetadata(data["extendedExif"]) : undefined,
    flowOutput: data["flowOutput"] !== undefined ? serializeImageContentFlowProtoProd(data["flowOutput"]) : undefined,
    hateLogoDetection: data["hateLogoDetection"] !== undefined ? serializeImageUnderstandingIndexingAnnotationGroup(data["hateLogoDetection"]) : undefined,
    imageExactBoost: data["imageExactBoost"] !== undefined ? serializeImageExactBoost(data["imageExactBoost"]) : undefined,
    imageRegions: data["imageRegions"] !== undefined ? serializeImageRegionsImageRegions(data["imageRegions"]) : undefined,
    nearDupFeatures: data["nearDupFeatures"] !== undefined ? encodeBase64(data["nearDupFeatures"]) : undefined,
    nearDupFeaturesSmall: data["nearDupFeaturesSmall"] !== undefined ? data["nearDupFeaturesSmall"].map((item: any) => (encodeBase64(item))) : undefined,
    ocrGoodoc: data["ocrGoodoc"] !== undefined ? serializeGoodocDocument(data["ocrGoodoc"]) : undefined,
    ocrTaser: data["ocrTaser"] !== undefined ? serializeGoodocDocument(data["ocrTaser"]) : undefined,
    packedFullFaceInfo: data["packedFullFaceInfo"] !== undefined ? serializeFaceIndexing(data["packedFullFaceInfo"]) : undefined,
    pornFlagData: data["pornFlagData"] !== undefined ? serializePornFlagData(data["pornFlagData"]) : undefined,
    shoppingProductInformation: data["shoppingProductInformation"] !== undefined ? serializeImageRepositoryShoppingProductInformation(data["shoppingProductInformation"]) : undefined,
    smearedTopWebLandingPageDocids: data["smearedTopWebLandingPageDocids"] !== undefined ? data["smearedTopWebLandingPageDocids"].map((item: any) => (String(item))) : undefined,
    smearedTopWebLandingPages: data["smearedTopWebLandingPages"] !== undefined ? data["smearedTopWebLandingPages"].map((item: any) => (serializeSmearedWebLandingPageEntry(item))) : undefined,
    thumbnail: data["thumbnail"] !== undefined ? data["thumbnail"].map((item: any) => (serializeImageDataThumbnail(item))) : undefined,
    unavailableAfterSecs: data["unavailableAfterSecs"] !== undefined ? String(data["unavailableAfterSecs"]) : undefined,
  };
}

function deserializeImageData(data: any): ImageData {
  return {
    ...data,
    canonicalDocid: data["canonicalDocid"] !== undefined ? BigInt(data["canonicalDocid"]) : undefined,
    clusterId: data["clusterId"] !== undefined ? decodeBase64(data["clusterId"] as string) : undefined,
    corpusSelectionInfo: data["corpusSelectionInfo"] !== undefined ? data["corpusSelectionInfo"].map((item: any) => (deserializeCorpusSelectionInfo(item))) : undefined,
    crops: data["crops"] !== undefined ? deserializeContentAwareCropsIndexing(data["crops"]) : undefined,
    deepCrop: data["deepCrop"] !== undefined ? deserializeDeepCropIndexing(data["deepCrop"]) : undefined,
    docid: data["docid"] !== undefined ? BigInt(data["docid"]) : undefined,
    embeddedMetadata: data["embeddedMetadata"] !== undefined ? deserializeImageExifImageEmbeddedMetadata(data["embeddedMetadata"]) : undefined,
    expirationTimestamp: data["expirationTimestamp"] !== undefined ? BigInt(data["expirationTimestamp"]) : undefined,
    extendedExif: data["extendedExif"] !== undefined ? deserializePhotosImageMetadata(data["extendedExif"]) : undefined,
    flowOutput: data["flowOutput"] !== undefined ? deserializeImageContentFlowProtoProd(data["flowOutput"]) : undefined,
    hateLogoDetection: data["hateLogoDetection"] !== undefined ? deserializeImageUnderstandingIndexingAnnotationGroup(data["hateLogoDetection"]) : undefined,
    imageExactBoost: data["imageExactBoost"] !== undefined ? deserializeImageExactBoost(data["imageExactBoost"]) : undefined,
    imageRegions: data["imageRegions"] !== undefined ? deserializeImageRegionsImageRegions(data["imageRegions"]) : undefined,
    nearDupFeatures: data["nearDupFeatures"] !== undefined ? decodeBase64(data["nearDupFeatures"] as string) : undefined,
    nearDupFeaturesSmall: data["nearDupFeaturesSmall"] !== undefined ? data["nearDupFeaturesSmall"].map((item: any) => (decodeBase64(item as string))) : undefined,
    ocrGoodoc: data["ocrGoodoc"] !== undefined ? deserializeGoodocDocument(data["ocrGoodoc"]) : undefined,
    ocrTaser: data["ocrTaser"] !== undefined ? deserializeGoodocDocument(data["ocrTaser"]) : undefined,
    packedFullFaceInfo: data["packedFullFaceInfo"] !== undefined ? deserializeFaceIndexing(data["packedFullFaceInfo"]) : undefined,
    pornFlagData: data["pornFlagData"] !== undefined ? deserializePornFlagData(data["pornFlagData"]) : undefined,
    shoppingProductInformation: data["shoppingProductInformation"] !== undefined ? deserializeImageRepositoryShoppingProductInformation(data["shoppingProductInformation"]) : undefined,
    smearedTopWebLandingPageDocids: data["smearedTopWebLandingPageDocids"] !== undefined ? data["smearedTopWebLandingPageDocids"].map((item: any) => (BigInt(item))) : undefined,
    smearedTopWebLandingPages: data["smearedTopWebLandingPages"] !== undefined ? data["smearedTopWebLandingPages"].map((item: any) => (deserializeSmearedWebLandingPageEntry(item))) : undefined,
    thumbnail: data["thumbnail"] !== undefined ? data["thumbnail"].map((item: any) => (deserializeImageDataThumbnail(item))) : undefined,
    unavailableAfterSecs: data["unavailableAfterSecs"] !== undefined ? BigInt(data["unavailableAfterSecs"]) : undefined,
  };
}

/**
 * Multibang kg entities.
 */
export interface ImageDataMultibangEntities {
  entity?: ImageDataMultibangEntitiesMultibangEntity[];
}

export interface ImageDataMultibangEntitiesMultibangEntity {
  /**
   * Entity ID.
   */
  entityId?: string;
  /**
   * Multibang score.
   */
  score?: number;
}

export interface ImageDataThumbnail {
  /**
   * The thumbnail is guaranteed to be kept in the serving system until the
   * expiration timestamp has passed, in microseconds.
   */
  expirationTimestampMicros?: bigint;
  height?: number;
  mimeType?: string;
  size?: number;
  type?:  | "THUMBNAIL_TYPE_DEFAULT" | "THUMBNAIL_TYPE_AREA_50K" | "THUMBNAIL_TYPE_400" | "THUMBNAIL_TYPE_800" | "THUMBNAIL_TYPE_ORIGINAL" | "THUMBNAIL_TYPE_ORIGINAL_HQ" | "THUMBNAIL_TYPE_FAVICON_16" | "THUMBNAIL_TYPE_FAVICON_28" | "THUMBNAIL_TYPE_FAVICON_32" | "THUMBNAIL_TYPE_FAVICON_64" | "THUMBNAIL_TYPE_FAVICON_ORIGINAL" | "THUMBNAIL_TYPE_FAVICON_16_DARK" | "THUMBNAIL_TYPE_FAVICON_28_DARK" | "THUMBNAIL_TYPE_FAVICON_32_DARK" | "THUMBNAIL_TYPE_FAVICON_64_DARK" | "THUMBNAIL_TYPE_FAVICON_ORIGINAL_DARK" | "THUMBNAIL_TYPE_1080" | "THUMBNAIL_TYPE_1600_HQ" | "THUMBNAIL_TYPE_AREA_300K" | "THUMBNAIL_TYPE_AREA_50K_ALPHA" | "THUMBNAIL_TYPE_AREA_50K_SYNTHETIC_ALPHA" | "THUMBNAIL_TYPE_AREA_2M" | "THUMBNAIL_TYPE_AREA_2M_METADATA" | "THUMBNAIL_TYPE_800_ALPHA_WHITE" | "THUMBNAIL_TYPE_ORIGINAL_ALPHA_WHITE" | "THUMBNAIL_TYPE_ANIMATED_H144" | "THUMBNAIL_TYPE_ORIGINAL_HQ_LICENSED" | "THUMBNAIL_TYPE_TENOR_250K_GIF" | "THUMBNAIL_TYPE_TENOR_100K_OPTIMIZED_GIF" | "THUMBNAIL_TYPE_TENOR_30K_OPTIMIZED_THUMBNAIL_GIF" | "THUMBNAIL_TYPE_TENOR_45K_OPTIMIZED_90P_GIF" | "THUMBNAIL_TYPE_TENOR_50K_OPTIMIZED_100P_GIF" | "THUMBNAIL_TYPE_TENOR_100K_OPTIMIZED_200P_GIF" | "THUMBNAIL_TYPE_TENOR_50K_OPTIMIZED_100W_GIF" | "THUMBNAIL_TYPE_TENOR_100K_OPTIMIZED_200W_GIF" | "THUMBNAIL_TYPE_TENOR_45K_PREVIEW_GIF" | "THUMBNAIL_TYPE_TENOR_250K_MEDIUM_GIF" | "THUMBNAIL_TYPE_AREA_2M_WEBP" | "THUMBNAIL_TYPE_AREA_2M_WEBP_METADATA" | "THUMBNAIL_TYPE_AREA_2M_AVIF" | "THUMBNAIL_TYPE_AREA_2M_AVIF_METADATA" | "THUMBNAIL_TYPE_AREA_50K_WEBP" | "THUMBNAIL_TYPE_AREA_50K_AVIF" | "THUMBNAIL_TYPE_ORIGINAL_HQ_KG";
  width?: number;
}

function serializeImageDataThumbnail(data: any): ImageDataThumbnail {
  return {
    ...data,
    expirationTimestampMicros: data["expirationTimestampMicros"] !== undefined ? String(data["expirationTimestampMicros"]) : undefined,
  };
}

function deserializeImageDataThumbnail(data: any): ImageDataThumbnail {
  return {
    ...data,
    expirationTimestampMicros: data["expirationTimestampMicros"] !== undefined ? BigInt(data["expirationTimestampMicros"]) : undefined,
  };
}

export interface ImageExactBoost {
  navquery?: ImageExactBoostNavQuery[];
}

function serializeImageExactBoost(data: any): ImageExactBoost {
  return {
    ...data,
    navquery: data["navquery"] !== undefined ? data["navquery"].map((item: any) => (serializeImageExactBoostNavQuery(item))) : undefined,
  };
}

function deserializeImageExactBoost(data: any): ImageExactBoost {
  return {
    ...data,
    navquery: data["navquery"] !== undefined ? data["navquery"].map((item: any) => (deserializeImageExactBoostNavQuery(item))) : undefined,
  };
}

/**
 * Navboost query data.
 */
export interface ImageExactBoostNavQuery {
  /**
   * Associated confidence scores for the image for the query.
   */
  confidence?: number;
  /**
   * Click-based rank of the image for this query.
   */
  imageClickRank?: number;
  /**
   * Query fingerprint.
   */
  navFp?: bigint;
  /**
   * The normalized raw query text.
   */
  navQuery?: string;
  /**
   * List of all referrers, sorted by their rank (stored in Moosedog).
   */
  referrerDocid?: bigint[];
  /**
   * Rank of the current web doc referrer (stored in docjoins).
   */
  referrerRank?: number;
}

function serializeImageExactBoostNavQuery(data: any): ImageExactBoostNavQuery {
  return {
    ...data,
    navFp: data["navFp"] !== undefined ? String(data["navFp"]) : undefined,
    referrerDocid: data["referrerDocid"] !== undefined ? data["referrerDocid"].map((item: any) => (String(item))) : undefined,
  };
}

function deserializeImageExactBoostNavQuery(data: any): ImageExactBoostNavQuery {
  return {
    ...data,
    navFp: data["navFp"] !== undefined ? BigInt(data["navFp"]) : undefined,
    referrerDocid: data["referrerDocid"] !== undefined ? data["referrerDocid"].map((item: any) => (BigInt(item))) : undefined,
  };
}

/**
 * This class holds the EXIf/IPTC meta data Next Id: 104
 */
export interface ImageExifImageEmbeddedMetadata {
  altitude?: number;
  aperture?: number;
  /**
   * Text fields EXIF_TAG_ARTIST
   */
  author?: string;
  /**
   * EXIF_TAG_XP_AUTHOR
   */
  author2?: string;
  brightness?: number;
  /**
   * Device - Camera raw text without normalization
   */
  cameraMaker?: string;
  /**
   * raw text without normalization
   */
  cameraModel?: string;
  /**
   * This is the extracted serial number from EXIF (the source depends on
   * camera, most of the cameras store it in makers note tag).
   */
  cameraSerialNumber?: string;
  /**
   * Capturing settings in time_t
   */
  captureTime?: bigint;
  colorSpace?: number;
  /**
   * EXIF_TAG_USER_COMMENT
   */
  comments?: string;
  /**
   * EXIF_TAG_XP_COMMENT
   */
  comments2?: string;
  continousDriveMode?: boolean;
  /**
   * EXIF_TAG_COPYRIGHT
   */
  copyright?: string;
  /**
   * Location from IPTC @deprecated: Use iptc.location instead.
   */
  deprecatedCity?: string;
  deprecatedCountry?: string;
  deprecatedState?: string;
  /**
   * EXIF_TAG_IMAGE_DESCRIPTION
   */
  description?: string;
  destBearing?: number;
  /**
   * Bearing and distance to destination point.
   */
  destBearingRef?: number;
  destDistance?: number;
  /**
   * GPS location of destination point.
   */
  destLatitude?: number;
  destLongitude?: number;
  digitalZoomRatio?: number;
  exposureBias?: number;
  /**
   * 1-8, see EXIF definition
   */
  exposureProgram?: number;
  exposureTime?: number;
  flashUsed?: boolean;
  focalLength?: number;
  /**
   * convert to match 35mm film camera
   */
  focalLength35mm?: number;
  focalPlaneResUnit?: number;
  focalPlaneXres?: number;
  focusMode?:  | "MANUAL_FOCUS" | "AF_ONE_SHOT" | "AF_CONTINUOUS" | "AF_AUTO" | "OTHER_FOCUS";
  /**
   * Dilution of precision. HDOP/PDOP depends on measure mode. Find out more at
   * http://en.wikipedia.org/wiki/Dilution_of_precision_(GPS)
   */
  gpsDop?: number;
  gpsMeasureMode?:  | "MEASURE_MODE_2D" | "MEASURE_MODE_3D";
  gpsStatus?:  | "GPS_STATUS_ACTIVE" | "GPS_STATUS_VOID";
  /**
   * in meters
   */
  hPositioningError?: number;
  imageHeight?: number;
  imageWidth?: number;
  /**
   * GPS Heading 0.00 to 359.99 degrees
   */
  imgDirection?: number;
  imgDirectionRef?:  | "DirectionRef_True" | "DirectionRef_Magnetic";
  iptc?: ImageExifIPTCMetadata;
  iso?: number;
  /**
   * EXIF_TAG_XP_KEYWORDS
   */
  keywords?: string;
  /**
   * GPS location +/- 90 inclusive
   */
  latitude?: number;
  /**
   * Device - Lens We use this extended id to identify a lens uniquely. Canon:
   * "%d %d %d"=.. Nikon: "%.2X %.2X %.2X %.2X %.2X %.2X %.2X %.2X" Don't change
   * the format of the internal lens id because we use them to look up the lens
   * names.
   */
  lensId?: string;
  lensMaker?: string;
  lightSource?: number;
  longFocal?: number;
  /**
   * +/- 180 inclusive
   */
  longitude?: number;
  maxApertureAtLongFocal?: number;
  maxApertureAtShortFocal?: number;
  /**
   * 1-6, see EXIF definition
   */
  meteringMode?: number;
  /**
   * in time_t
   */
  modificationTime?: bigint;
  orientation?:  | "ORIENTATION_0_DEG" | "ORIENTATION_MIRROR_0_DEG" | "ORIENTATION_180_DEG" | "ORIENTATION_MIRROR_180_DEG" | "ORIENTATION_MIRROR_270_DEG" | "ORIENTATION_90_DEG" | "ORIENTATION_MIRROR_90_DEG" | "ORIENTATION_270_DEG";
  shortFocal?: number;
  /**
   * EXIF_TAG_SOFTWARE
   */
  software?: string;
  /**
   * EXIF_TAG_XP_SUBJECT
   */
  subject?: string;
  subjectDistance?: number;
  subjectLocationX?: number;
  subjectLocationY?: number;
  /**
   * EXIF_TAG_XP_TITLE
   */
  title?: string;
  /**
   * pixels per inch
   */
  xResolution?: number;
  /**
   * pixels per inch
   */
  yResolution?: number;
}

function serializeImageExifImageEmbeddedMetadata(data: any): ImageExifImageEmbeddedMetadata {
  return {
    ...data,
    captureTime: data["captureTime"] !== undefined ? String(data["captureTime"]) : undefined,
    iptc: data["iptc"] !== undefined ? serializeImageExifIPTCMetadata(data["iptc"]) : undefined,
    modificationTime: data["modificationTime"] !== undefined ? String(data["modificationTime"]) : undefined,
  };
}

function deserializeImageExifImageEmbeddedMetadata(data: any): ImageExifImageEmbeddedMetadata {
  return {
    ...data,
    captureTime: data["captureTime"] !== undefined ? BigInt(data["captureTime"]) : undefined,
    iptc: data["iptc"] !== undefined ? deserializeImageExifIPTCMetadata(data["iptc"]) : undefined,
    modificationTime: data["modificationTime"] !== undefined ? BigInt(data["modificationTime"]) : undefined,
  };
}

/**
 * This proto holds IPTC metadata.
 * http://www.iptc.org/cms/site/index.html?channel=CH0099 Proto field name is
 * same with IPTC property name except which is clearly stated. Next Id: 63
 */
export interface ImageExifIPTCMetadata {
  /**
   * Page URL about how to acquire this licensable image.
   */
  acquireLicensePage?: string;
  artwork?: ImageExifIPTCMetadataArtwork[];
  contactinfo?: ImageExifIPTCMetadataContactInfo;
  copyrightNotice?: string;
  /**
   * IPTC authorship & copyright related fields.
   */
  creator?: string[];
  creditLine?: string;
  /**
   * Time (in seconds)
   */
  dateCreated?: bigint;
  dateExpired?: bigint;
  dateReleased?: bigint;
  description?: string;
  event?: string;
  headline?: string;
  /**
   * PLUS field, not used.
   */
  imageSupplier?: string;
  instructions?: string;
  keywords?: string[];
  /**
   * License URL about how to distribute the image.
   */
  licenseUrl?: string;
  location?: ImageExifIPTCMetadataLocation;
  /**
   * Location of the camera
   */
  locationCreated?: ImageExifIPTCMetadataLocationInfo;
  /**
   * Location shown on the image
   */
  locationShown?: ImageExifIPTCMetadataLocationInfo[];
  modelReleaseStatus?:  | "MR_UNKNOWN" | "MR_NONE" | "MR_NOT_APPLICABLE" | "MR_UNLIMITED" | "MR_LIMITED_OR_INCOMPLETE";
  propertyReleaseStatus?:  | "PR_UNKNOWN" | "PR_NONE" | "PR_NOT_APPLICABLE" | "PR_UNLIMITED" | "PR_LIMITED_OR_INCOMPLETE";
  rightsUsageTerms?: string;
  source?: string;
  supplementalCategories?: string[];
  /**
   * IPTC description related fields.
   */
  title?: string;
}

function serializeImageExifIPTCMetadata(data: any): ImageExifIPTCMetadata {
  return {
    ...data,
    dateCreated: data["dateCreated"] !== undefined ? String(data["dateCreated"]) : undefined,
    dateExpired: data["dateExpired"] !== undefined ? String(data["dateExpired"]) : undefined,
    dateReleased: data["dateReleased"] !== undefined ? String(data["dateReleased"]) : undefined,
  };
}

function deserializeImageExifIPTCMetadata(data: any): ImageExifIPTCMetadata {
  return {
    ...data,
    dateCreated: data["dateCreated"] !== undefined ? BigInt(data["dateCreated"]) : undefined,
    dateExpired: data["dateExpired"] !== undefined ? BigInt(data["dateExpired"]) : undefined,
    dateReleased: data["dateReleased"] !== undefined ? BigInt(data["dateReleased"]) : undefined,
  };
}

/**
 * Artwork or Object in the Image Details
 */
export interface ImageExifIPTCMetadataArtwork {
  /**
   * Other fields omitted.
   */
  title?: string;
}

export interface ImageExifIPTCMetadataContactInfo {
  address?: string;
  city?: string;
  country?: string;
  email?: string;
  phone?: string;
  postalCode?: string;
  state?: string;
  webUrl?: string;
}

/**
 * Location of the camera @deprecated: Use location_created instead.
 */
export interface ImageExifIPTCMetadataLocation {
  city?: string;
  country?: string;
  countryCode?: string;
  state?: string;
  subLocation?: string;
  worldRegion?: string;
}

export interface ImageExifIPTCMetadataLocationInfo {
  city?: string;
  country?: string;
  countryCode?: string;
  state?: string;
  subLocation?: string;
  worldRegion?: string;
}

export interface ImageMonetizationFeaturedImageProperties {
  /**
   * How an image is inspirational, [0, 1].
   */
  inspirationScore?: number;
}

export interface ImageMoosedogCrawlState {
  code?:  | "VALID_IMAGE" | "INVALID_FETCH_REPLY" | "XROBOTED" | "URL_NOT_CRAWLED" | "PARSE_ERROR" | "INVALID_IMAGE" | "IMS_CRAWL_NOT_MODIFIED" | "EXPIRED_DISCOVERY_CRAWL" | "EXPIRED_FEED_CRAWL" | "EXPIRED_PRIORITY_FEED_CRAWL" | "INVALID_URL" | "VALID_VIDEO" | "VALID_SWF" | "VALID_SILVERLIGHT" | "INVALID_VIDEO" | "TRUNCATED_CONTENTS" | "FAST_CRAWL_LOCK_ACQUIRE_FAILED" | "FAST_CRAWL_TTL_EXPIRED";
  /**
   * Each of the above not_crawled_reason will have a set of detailed reason
   * defined in crawler/trawler/trawler_enums.proto.
   */
  detailedReason?: number;
  /**
   * The status returned when RPCs are used to internally fetch the image (eg.
   * from FIFE).
   */
  internalStatus?: UtilStatusProto;
  /**
   * Specifies if the current crawl state is terminal.
   */
  isTerminal?: boolean;
  /**
   * Time in seconds since epoch after which this image should be considered
   * unavailable.
   */
  noIndexAfterTimestamp?: bigint;
  notCrawledReason?:  | "URL_CRAWLED" | "URL_ERROR" | "URL_ROBOTED" | "URL_UNREACHABLE" | "URL_TIMEOUT" | "URL_REJECTED" | "URL_NOT_FOLLOWED" | "NUM_STATE_TYPES";
  /**
   * When true, it means that a non-terminal state has overwrote a terminal
   * one.
   */
  overrodeTerminalState?: boolean;
  /**
   * The repid for the urls. This repid is the id given to the dupe cluster
   * this url belongs to.
   */
  repid?: Uint8Array;
  /**
   * A comma separated list of user agents for which this image should be
   * considered roboted. All images are crawled using googlebot-images and this
   * exists here purely for informative reasons.
   */
  robotedAgents?: string;
  /**
   * The url at which we crawled this content. With us starting to use repids
   * the crawl table key no longer is suggestive of the url. In addition this is
   * used in Amarna to detect race conditions between a reference changing its
   * crawl directive and the original crawl job finishing.
   */
  url?: string;
  /**
   * Set to true if the url is taken down by clients. This indicates that this
   * crawl state is used to fast remove the crawl result of the url instead of
   * waiting for Multiverse crawl results. For more information, please refer to
   * go/amarna-url-deletion.
   */
  urlDeleted?: boolean;
}

function serializeImageMoosedogCrawlState(data: any): ImageMoosedogCrawlState {
  return {
    ...data,
    noIndexAfterTimestamp: data["noIndexAfterTimestamp"] !== undefined ? String(data["noIndexAfterTimestamp"]) : undefined,
    repid: data["repid"] !== undefined ? encodeBase64(data["repid"]) : undefined,
  };
}

function deserializeImageMoosedogCrawlState(data: any): ImageMoosedogCrawlState {
  return {
    ...data,
    noIndexAfterTimestamp: data["noIndexAfterTimestamp"] !== undefined ? BigInt(data["noIndexAfterTimestamp"]) : undefined,
    repid: data["repid"] !== undefined ? decodeBase64(data["repid"] as string) : undefined,
  };
}

/**
 * For detailed info, please see go/naive-image-selection
 */
export interface ImageMustangImageLinkSelectionInfo {
  /**
   * score calculated in image selection phase, higher
   * imagelink_selection_score more relevant the link is related to the web page
   */
  webRelevanceScore?: number;
}

/**
 * A proto buffer to organize shopping offer info from Inventory & Policy
 * Service.
 */
export interface ImageMustangShoppingOffer {
  inferredImageTypes?:  | "UNKNOWN" | "MERCHANT_IMAGE" | "ML_INFERRED_IMAGE" | "NEARDUP_INFERRED_IMAGE"[];
  ipsOfferId?: bigint;
}

function serializeImageMustangShoppingOffer(data: any): ImageMustangShoppingOffer {
  return {
    ...data,
    ipsOfferId: data["ipsOfferId"] !== undefined ? String(data["ipsOfferId"]) : undefined,
  };
}

function deserializeImageMustangShoppingOffer(data: any): ImageMustangShoppingOffer {
  return {
    ...data,
    ipsOfferId: data["ipsOfferId"] !== undefined ? BigInt(data["ipsOfferId"]) : undefined,
  };
}

export interface ImagePerDocData {
  /**
   * entropy and color values for thumbnail (4 bytes consisting of R, G, B and
   * entropy values)
   */
  DEPRECATEDEntropyColor?: number;
  /**
   * about 10 bytes
   */
  filename?: string;
  /**
   * image_perdoc.h
   */
  flags?: number;
  height?: number;
  width?: number;
}

/**
 * Used to store debug information of the overall classifier.
 */
export interface ImagePornDebugInfo {
  info?: string;
}

/**
 * A single region within an image. NEXT_ID: 11
 */
export interface ImageRegionsImageRegion {
  /**
   * The bounding box of the region.
   */
  boundingBox?: PhotosVisionGroundtruthdbNormalizedBoundingBox;
  /**
   * The confidence score associated with the bounding box.
   */
  boundingBoxScore?: number;
  /**
   * A unique identifier for the region within the image. The id is unique only
   * among other regions in the image.
   */
  id?: string;
  /**
   * Set true if the region represents a product, i.e., if any of its labels
   * are on a product labels whitelist. See ImageRegionsConfig for details on
   * the product whitelist.
   */
  isProduct?: boolean;
  /**
   * The score for this region based on how visually similar its neighbors are.
   */
  knnScore?: number;
  /**
   * The label group corresponding to the first LabelParams listed in
   * ImageRegionsConfig.
   */
  labelGroup?: ImageUnderstandingIndexingLabelGroup;
  /**
   * The version string of the labels with which the region was processed.
   */
  labelVersion?: string;
  /**
   * The primary label associated with the region. Specifically, the
   * highest-scored whitelisted label associated with the region. See
   * ImageRegionsConfig for details on the whitelist.
   */
  primaryLabel?: ImageUnderstandingIndexingLabel;
  renderType?:  | "UNSET" | "DONT_RENDER" | "RENDER_ONLY_BOUNDING_BOX" | "RENDER_BOUNDING_BOX_AND_PRIMARY_LABEL";
  /**
   * The starburst v4 features and tokens for the region.
   */
  starburstV4?: ImageUnderstandingIndexingFeature;
}

function serializeImageRegionsImageRegion(data: any): ImageRegionsImageRegion {
  return {
    ...data,
    starburstV4: data["starburstV4"] !== undefined ? serializeImageUnderstandingIndexingFeature(data["starburstV4"]) : undefined,
  };
}

function deserializeImageRegionsImageRegion(data: any): ImageRegionsImageRegion {
  return {
    ...data,
    starburstV4: data["starburstV4"] !== undefined ? deserializeImageUnderstandingIndexingFeature(data["starburstV4"]) : undefined,
  };
}

/**
 * An image with regions within it. NEXT_ID: 11
 */
export interface ImageRegionsImageRegions {
  /**
   * The final_porn_score for the image.
   */
  finalPornScore?: number;
  /**
   * The final_violence_score for the image.
   */
  finalViolenceScore?: number;
  /**
   * The output of various features generated by the Flow framework, most
   * importantly data from Starburst (go/starburst).
   */
  flowOutput?: ImageContentFlowProtoProd;
  /**
   * True if the image has a 300k thumb.
   */
  has300kThumb?: boolean;
  /**
   * True if the image has navboost.
   */
  hasNavboost?: boolean;
  /**
   * True if the image is iu-inappropriate.
   */
  isIuInappropriate?: boolean;
  /**
   * The pedo_score of the image.
   */
  pedoScore?: number;
  /**
   * The precomputed restricts for the image.
   */
  precomputedRestricts?: PrecomputedRestricts;
  /**
   * The racy_score of the image.
   */
  racyScore?: number;
  /**
   * The list of regions.
   */
  region?: ImageRegionsImageRegion[];
}

function serializeImageRegionsImageRegions(data: any): ImageRegionsImageRegions {
  return {
    ...data,
    flowOutput: data["flowOutput"] !== undefined ? serializeImageContentFlowProtoProd(data["flowOutput"]) : undefined,
    region: data["region"] !== undefined ? data["region"].map((item: any) => (serializeImageRegionsImageRegion(item))) : undefined,
  };
}

function deserializeImageRegionsImageRegions(data: any): ImageRegionsImageRegions {
  return {
    ...data,
    flowOutput: data["flowOutput"] !== undefined ? deserializeImageContentFlowProtoProd(data["flowOutput"]) : undefined,
    region: data["region"] !== undefined ? data["region"].map((item: any) => (deserializeImageRegionsImageRegion(item))) : undefined,
  };
}

/**
 * Next Tag: 8
 */
export interface ImageRepositoryAmarnaCloudSpeechSignals {
  /**
   * If this field is set to true, it means that Youtube already processed the
   * ASR from S3 for the langID. Please find the ASR result from transcript_asr
   * in google3/image/repository/proto/video_search.proto instead.
   */
  duplicateOfYtS3Asr?: boolean;
  /**
   * The language id input for creating this ASR without regional info. Same
   * format as in go/ytlangid. This field is populated in Kronos Amarna Cloud
   * Speech operator and passed to Amarna, but it is cleared before stored in
   * Amarna's metadata table.
   */
  langWithoutLocale?: string;
  /**
   * Identifying which ASR models are used for the result
   */
  modelIdentifier?: string;
  /**
   * Raw results from Cloud Speech API
   */
  results?: ImageRepositorySpeechRecognitionResult[];
  /**
   * This field contains full (stitched) transcription, word-level time offset
   * , and word-level byte offset. The value of this field is derived from the
   * SpeechRecognitionResult field above.
   */
  transcriptAsr?: PseudoVideoData;
}

function serializeImageRepositoryAmarnaCloudSpeechSignals(data: any): ImageRepositoryAmarnaCloudSpeechSignals {
  return {
    ...data,
    results: data["results"] !== undefined ? data["results"].map((item: any) => (serializeImageRepositorySpeechRecognitionResult(item))) : undefined,
    transcriptAsr: data["transcriptAsr"] !== undefined ? serializePseudoVideoData(data["transcriptAsr"]) : undefined,
  };
}

function deserializeImageRepositoryAmarnaCloudSpeechSignals(data: any): ImageRepositoryAmarnaCloudSpeechSignals {
  return {
    ...data,
    results: data["results"] !== undefined ? data["results"].map((item: any) => (deserializeImageRepositorySpeechRecognitionResult(item))) : undefined,
    transcriptAsr: data["transcriptAsr"] !== undefined ? deserializePseudoVideoData(data["transcriptAsr"]) : undefined,
  };
}

export interface ImageRepositoryAmarnaSignalsBlob {
  frameFeatures?: DrishtiFeatureSetDataSequence;
}

function serializeImageRepositoryAmarnaSignalsBlob(data: any): ImageRepositoryAmarnaSignalsBlob {
  return {
    ...data,
    frameFeatures: data["frameFeatures"] !== undefined ? serializeDrishtiFeatureSetDataSequence(data["frameFeatures"]) : undefined,
  };
}

function deserializeImageRepositoryAmarnaSignalsBlob(data: any): ImageRepositoryAmarnaSignalsBlob {
  return {
    ...data,
    frameFeatures: data["frameFeatures"] !== undefined ? deserializeDrishtiFeatureSetDataSequence(data["frameFeatures"]) : undefined,
  };
}

export interface ImageRepositoryAmarnaSignalsBlobInfo {
  /**
   * Blob id for AmarnaSignalsBlob (see `Blob proto` section of
   * go/revisit-frame-level-signals-amarna).
   */
  signalsBlobId?: string;
  /**
   * Additional timestamp field for when the blob is written/updated, serving
   * as the dirty field to help checksum-based update push (see `Dirty field`
   * section in go/revisit-frame-level-signals-amarna).
   */
  signalsBlobUpdateTimestamp?: Date;
}

function serializeImageRepositoryAmarnaSignalsBlobInfo(data: any): ImageRepositoryAmarnaSignalsBlobInfo {
  return {
    ...data,
    signalsBlobUpdateTimestamp: data["signalsBlobUpdateTimestamp"] !== undefined ? data["signalsBlobUpdateTimestamp"].toISOString() : undefined,
  };
}

function deserializeImageRepositoryAmarnaSignalsBlobInfo(data: any): ImageRepositoryAmarnaSignalsBlobInfo {
  return {
    ...data,
    signalsBlobUpdateTimestamp: data["signalsBlobUpdateTimestamp"] !== undefined ? new Date(data["signalsBlobUpdateTimestamp"]) : undefined,
  };
}

/**
 * This message stores the status and reason why Amarna was unable to provide
 * perdoc information for an image.
 */
export interface ImageRepositoryAmarnaStatus {
  reason?:  | "NOT_REJECTED" | "INVALID_MEDIA" | "TERMINAL_CRAWL_ERROR" | "LOW_PRIORITY_REFERRER" | "REMOVED_BY_CLIENT_REQUEST" | "XROBOTED" | "CONTENT_PROCESSING_ERROR" | "MISSING_DOCID" | "ROBOTED" | "UNWANTED_CONTENT" | "NOT_A_VIDEO" | "INDEXING_DELAY";
  status?:  | "READY" | "REJECTED" | "NOT_READY" | "DEPRECATED_3";
}

/**
 * Additional animated image data stored in perdoc (ImageData); will only be
 * stored for animated images.
 */
export interface ImageRepositoryAnimatedImagePerdocData {
  /**
   * Aggregated porn scores for animated images. Aggregated using max sampling
   * rate / max duration. Note the plan is to fold these scores into existing
   * summarized scores, for cases where these scores are available. See tracking
   * bug b/63580795.
   */
  aggregatedPornScores?: ImageSafesearchContentBrainPornAnnotation;
  /**
   * Total duration of animation, in ms.
   */
  durationMs?: number;
}

/**
 * The metadata returned with each transcode. Next available field: 9
 */
export interface ImageRepositoryApiItagSpecificMetadata {
  /**
   * Timestamp (measured in seconds since epoch) after which Amarna will delete
   * the serving transcode.
   */
  expirationTimestampSec?: bigint;
  /**
   * The Venom Genus that this transcode was produced for.
   */
  genus?:  | "GENUS_UNKNOWN" | "GENUS_YT_HIGH_VALUE_CONTENT" | "GENUS_YT_USER_GENERATED_CONTENT" | "GENUS_GMAIL" | "GENUS_KIDS_HUB" | "GENUS_YOUTUBE_DIRECTOR" | "GENUS_DCLK_VIDEO_ADS" | "GENUS_DAI_PODCAST" | "GENUS_TESTING" | "GENUS_YT_UNPLUGGED_SVOD" | "GENUS_YT_UNPLUGGED_DVR" | "GENUS_HVC_INGESTION" | "GENUS_DRIVE" | "GENUS_YT_LIGHTWEIGHT_VIDEO" | "GENUS_ASK_QNA" | "GENUS_LOCAL_VIDEO" | "GENUS_PLAY_AUDIOBOOKS" | "GENUS_HANGOUTS_CHAT" | "GENUS_VIDEO_INTEREST_FEED" | "GENUS_YT_MUSIC" | "GENUS_RECORDER" | "GENUS_YT_ORIGINAL_CONTENT" | "GENUS_STAMP" | "GENUS_BULLETIN_AUDIO" | "GENUS_CRAWL" | "GENUS_PHOTOS" | "GENUS_MATERIAL_GALLERY" | "GENUS_YT_REFERENCE" | "GENUS_LENSLETS_VIDEOS" | "GENUS_BLOGGER" | "GENUS_PODCASTS" | "GENUS_OCEAN" | "GENUS_LMS" | "GENUS_WEB_VIDEO_ADS" | "GENUS_STUDIO" | "GENUS_YT_TDSD_REFERENCE" | "GENUS_WEB_STORY" | "GENUS_NEST_CAMERA_CLOUD" | "GENUS_AREA120_BLUEBIRD" | "GENUS_ARTS_AND_CULTURE" | "GENUS_DEMO" | "GENUS_KARTO" | "GENUS_CONTRIB_SERVICE_SHARED" | "GENUS_CONTRIB_SERVICE_GEO_UGC" | "GENUS_SEARCH_SPORTS" | "GENUS_BUSINESSMESSAGING";
  /**
   * Indicates the state in Venom for this transcode type.
   */
  state?:  | "STATE_UNKNOWN" | "STATE_DONE" | "STATE_NOT_APPLICABLE" | "STATE_MISSING" | "STATE_DELETED" | "STATE_DIRTY" | "STATE_OBSOLETE" | "STATE_PENDING_PUBLICATION" | "STATE_FAILED";
  /**
   * transcode type which are available for the video.
   */
  transcodeItag?: number;
  /**
   * The Venom ID that this transcode was produced for.
   */
  videoId?: VideoAssetsVenomVideoId;
  /**
   * Indicates xtags if present. Xtag makes the different transcode. For
   * transcode "MP4_AVCBASE640_AAC/af=sq" (itag 18 with xtag), "af=sq" is the
   * xtag part. This is a different transcode than "MP4_AVCBASE640_AAC" (itag
   * 18).
   */
  xtagsList?: ImageRepositoryApiXtagList;
}

function serializeImageRepositoryApiItagSpecificMetadata(data: any): ImageRepositoryApiItagSpecificMetadata {
  return {
    ...data,
    expirationTimestampSec: data["expirationTimestampSec"] !== undefined ? String(data["expirationTimestampSec"]) : undefined,
    videoId: data["videoId"] !== undefined ? serializeVideoAssetsVenomVideoId(data["videoId"]) : undefined,
  };
}

function deserializeImageRepositoryApiItagSpecificMetadata(data: any): ImageRepositoryApiItagSpecificMetadata {
  return {
    ...data,
    expirationTimestampSec: data["expirationTimestampSec"] !== undefined ? BigInt(data["expirationTimestampSec"]) : undefined,
    videoId: data["videoId"] !== undefined ? deserializeVideoAssetsVenomVideoId(data["videoId"]) : undefined,
  };
}

export interface ImageRepositoryApiXtag {
  /**
   * Names are all stored case-sensitive, and no case-folding is done for
   * comparisons.
   */
  name?: string;
  /**
   * The value associated with this Xtag. Values are all stored case-sensitive,
   * and no case-folding is done for comparisons.
   */
  value?: string;
}

/**
 * XtagList -- a collection of Xtag instances with unique names. This would be
 * associated with one specific piece of content.
 */
export interface ImageRepositoryApiXtagList {
  xtags?: ImageRepositoryApiXtag[];
}

/**
 * Next Tag: 49
 */
export interface ImageRepositoryContentBasedVideoMetadata {
  /**
   * A hash of the video bytes used as a key to Amarna's video_metadata table.
   */
  amarnaDocid?: string;
  /**
   * Timestamp of the last successful Ares classification request.
   */
  aresClassificationRequestTimestamp?: Date;
  /**
   * Both audio- and audio-video-files are treated as videos during indexing
   * (whether they share a container format, like .mp4, or not, like .mp3). This
   * bool indicates that there's no video track, just an audio track.
   */
  audioOnly?: boolean;
  /**
   * Transcript generated from Cloud Speech API
   */
  cloudSpeechSignals?: ImageRepositoryAmarnaCloudSpeechSignals;
  /**
   * Video Understanding Golden features.
   * (go/amarna-video-signals#golden-signals) Note: Golden6 features (names
   * matching "video_*") are DEPRECATED. Please migrate to Golden7
   * ("VideoFeatures.*"). For more context, see
   * go/golden7/migrating-from-golden6 and go/amarna-golden-feature-tracker.
   * Signals popluated in Raffia cdoc.doc_videos are configured in
   * cs/symbol:AMARNA_EXPORTED_GOLDEN7_FEATURES.
   */
  featureSetData?: DrishtiFeatureSetData;
  /**
   * Golden7 video-level people features. (go/ypf-video-features)
   */
  golden7SoapboxSummary?: DrishtiFeatureSetData;
  /**
   * Metadata related to Inline playback on the Interest Feed. This field is
   * filled by Hamilton.
   */
  inlinePlayback?: VideoCrawlVideoInlinePlaybackMetadata;
  languageIdentification?: VideoTimedtextS4ALIResults;
  /**
   * Legos results
   */
  legosAnnotationData?: VideoLegosLegosAnnotationsSets;
  /**
   * LMS preview frame perdocs. Timestamps of the frame perdocs are from the
   * original video, not from the preview.
   */
  lmsPreviewFramePerdocs?: ImageRepositoryFramePerdocs;
  /**
   * When Transcode itag 140 is requested, MediaAnalyzer (as the part of Viper
   * graph) generates audio info including loudness_data, which is then
   * published to Streamer. For Audio news client, we extract this loudness data
   * from Streamer to this field.
   */
  loudnessData?: VideoStorageLoudnessData;
  /**
   * Information about the media file, such as duration, resolution, and detail
   * about each audio/video stream. Note that it contains no PII.
   */
  mediaInfo?: VideoMediaInfo;
  representativeFrameData?: ImageData;
  /**
   * Trnascript generated through AMARNA_CLOUD_SPEECH asset in Venom. Note that
   * AMARNA_CLOUD_SPEECH uses S3 as the speech engine backend, similar to YT
   * caption's SPEECH_RECOGNIZER asset. However, they may use different S3
   * models.
   */
  s3Asr?: ImageRepositoryAmarnaCloudSpeechSignals;
  s3LanguageIdentification?: ImageRepositoryS3LangIdSignals;
  /**
   * Contains SafeSearch video classification outputs which are
   * vertical_name/float pairs.
   */
  safesearchVideoContentSignals?: SafesearchVideoContentSignals;
  /**
   * 64 bit docid used for retrieving video previews.
   */
  searchDocid?: bigint;
  /**
   * Amarna signals blob that contains large-size signals like VCA frame-level
   * signals.
   */
  signalsBlob?: ImageRepositoryAmarnaSignalsBlob;
  /**
   * Information for the amarna signals blob.
   */
  signalsBlobInfo?: ImageRepositoryAmarnaSignalsBlobInfo;
  speechProperties?: IndexingSpeechSpeechPropertiesProto;
  thumbnailerData?: VideoPipelineViperThumbnailerColumnData;
  /**
   * Thumbnail quality score predict how visual pleasing a thumbnail is, based
   * on the model trained with deep neural networks.(go/thumb_features_dd) Note
   * the signal currently only available for Youtube videos.
   */
  thumbnailQualityScore?: VideoThumbnailsThumbnailScore;
  /**
   * Metadata about each transcode requested.
   */
  transcodeMetadata?: ImageRepositoryApiItagSpecificMetadata[];
  /**
   * Speech related metadata The transcript_asr field is generated from the YT
   * caption's SPEECH_RECOGNIZER asset.
   */
  transcriptAsr?: PseudoVideoData;
  /**
   * Data about whether or not the video was truncated.
   */
  truncationInfo?: ImageRepositoryFileTruncationInfo;
  /**
   * If set, video has been deleted using the deletion service
   * (MediaDeletionService).
   */
  unwantedContent?: ImageRepositoryUnwantedContent;
  /**
   * The video id in the venom pipeline for STAMP purposes. DEPRECATED: Use
   * transcode_metadata or venom_processing_info instead, which includes the ID
   * and contains information for all clients.
   */
  venomId?: string;
  /**
   * Information about the video's status in Venom, including IDs and
   * processing times.
   */
  venomProcessingInfo?: ImageRepositoryVenomProcessingInfo;
  /**
   * Video anchor sets hold set of anchors with multiple anchor types and
   * sequence of VideoAnchor which contains metadata about the anchor, such as
   * thumbnail, perdoc data.
   */
  videoAnchorSet?: VideoContentSearchVideoAnchorSets;
  /**
   * Set from the video header if truncated, or is the verified length if
   * completely crawled.
   */
  videoDurationSec?: number;
  /**
   * The video porn confidence score extracted from Whisper featureSet:
   * "video_labels:whisper_v3", with CR2 label: "/cr2/1".
   */
  videoPornScore?: number;
  /**
   * The video porn confidence score extracted from WhisperV4 featureSet:
   * "VideoFeatures.whisper_v4_labels", with CR2 label: "/tns/porn".
   */
  videoPornScoreV4?: number;
  /**
   * video_preview_bytes is only exported as virtual dataset by IE
   * VideoUnderstanding and should not be persisted. It will be used by
   * downstream IE functions to push for serving.
   */
  videoPreviewBytes?: ImageRepositoryVideoPreviewsVideoPreview[];
  /**
   * video_previews contain the preview metadata but no bytes. It exits for IE
   * and non-IE cases.
   */
  videoPreviews?: ImageBaseVideoPreviewMetadata[];
  /**
   * Deprecated, please use media_info.
   */
  videoStreamInfo?: VideoPipelineViperVSIColumnData;
  /**
   * VideoTranscriptAnnotations holds sentence segmented text and timing
   * information to be used for VideoAnswers (go/video-answers). Note that only
   * punctuated_transcript, timing_info, and lang field are filled, and other
   * fields will be filled in the later stage.
   */
  videoTranscriptAnnotations?: QualityWebanswersVideoTranscriptAnnotations;
  /**
   * Contains lists of reasons why YT videos were filtered from specific
   * processing.
   */
  youtubeProcessingFilter?: ImageRepositoryYoutubeProcessingFilter;
}

function serializeImageRepositoryContentBasedVideoMetadata(data: any): ImageRepositoryContentBasedVideoMetadata {
  return {
    ...data,
    aresClassificationRequestTimestamp: data["aresClassificationRequestTimestamp"] !== undefined ? data["aresClassificationRequestTimestamp"].toISOString() : undefined,
    cloudSpeechSignals: data["cloudSpeechSignals"] !== undefined ? serializeImageRepositoryAmarnaCloudSpeechSignals(data["cloudSpeechSignals"]) : undefined,
    featureSetData: data["featureSetData"] !== undefined ? serializeDrishtiFeatureSetData(data["featureSetData"]) : undefined,
    golden7SoapboxSummary: data["golden7SoapboxSummary"] !== undefined ? serializeDrishtiFeatureSetData(data["golden7SoapboxSummary"]) : undefined,
    inlinePlayback: data["inlinePlayback"] !== undefined ? serializeVideoCrawlVideoInlinePlaybackMetadata(data["inlinePlayback"]) : undefined,
    lmsPreviewFramePerdocs: data["lmsPreviewFramePerdocs"] !== undefined ? serializeImageRepositoryFramePerdocs(data["lmsPreviewFramePerdocs"]) : undefined,
    mediaInfo: data["mediaInfo"] !== undefined ? serializeVideoMediaInfo(data["mediaInfo"]) : undefined,
    representativeFrameData: data["representativeFrameData"] !== undefined ? serializeImageData(data["representativeFrameData"]) : undefined,
    s3Asr: data["s3Asr"] !== undefined ? serializeImageRepositoryAmarnaCloudSpeechSignals(data["s3Asr"]) : undefined,
    s3LanguageIdentification: data["s3LanguageIdentification"] !== undefined ? serializeImageRepositoryS3LangIdSignals(data["s3LanguageIdentification"]) : undefined,
    searchDocid: data["searchDocid"] !== undefined ? String(data["searchDocid"]) : undefined,
    signalsBlob: data["signalsBlob"] !== undefined ? serializeImageRepositoryAmarnaSignalsBlob(data["signalsBlob"]) : undefined,
    signalsBlobInfo: data["signalsBlobInfo"] !== undefined ? serializeImageRepositoryAmarnaSignalsBlobInfo(data["signalsBlobInfo"]) : undefined,
    thumbnailerData: data["thumbnailerData"] !== undefined ? serializeVideoPipelineViperThumbnailerColumnData(data["thumbnailerData"]) : undefined,
    thumbnailQualityScore: data["thumbnailQualityScore"] !== undefined ? serializeVideoThumbnailsThumbnailScore(data["thumbnailQualityScore"]) : undefined,
    transcodeMetadata: data["transcodeMetadata"] !== undefined ? data["transcodeMetadata"].map((item: any) => (serializeImageRepositoryApiItagSpecificMetadata(item))) : undefined,
    transcriptAsr: data["transcriptAsr"] !== undefined ? serializePseudoVideoData(data["transcriptAsr"]) : undefined,
    truncationInfo: data["truncationInfo"] !== undefined ? serializeImageRepositoryFileTruncationInfo(data["truncationInfo"]) : undefined,
    venomProcessingInfo: data["venomProcessingInfo"] !== undefined ? serializeImageRepositoryVenomProcessingInfo(data["venomProcessingInfo"]) : undefined,
    videoAnchorSet: data["videoAnchorSet"] !== undefined ? serializeVideoContentSearchVideoAnchorSets(data["videoAnchorSet"]) : undefined,
    videoPreviewBytes: data["videoPreviewBytes"] !== undefined ? data["videoPreviewBytes"].map((item: any) => (serializeImageRepositoryVideoPreviewsVideoPreview(item))) : undefined,
    videoPreviews: data["videoPreviews"] !== undefined ? data["videoPreviews"].map((item: any) => (serializeImageBaseVideoPreviewMetadata(item))) : undefined,
    videoStreamInfo: data["videoStreamInfo"] !== undefined ? serializeVideoPipelineViperVSIColumnData(data["videoStreamInfo"]) : undefined,
    videoTranscriptAnnotations: data["videoTranscriptAnnotations"] !== undefined ? serializeQualityWebanswersVideoTranscriptAnnotations(data["videoTranscriptAnnotations"]) : undefined,
  };
}

function deserializeImageRepositoryContentBasedVideoMetadata(data: any): ImageRepositoryContentBasedVideoMetadata {
  return {
    ...data,
    aresClassificationRequestTimestamp: data["aresClassificationRequestTimestamp"] !== undefined ? new Date(data["aresClassificationRequestTimestamp"]) : undefined,
    cloudSpeechSignals: data["cloudSpeechSignals"] !== undefined ? deserializeImageRepositoryAmarnaCloudSpeechSignals(data["cloudSpeechSignals"]) : undefined,
    featureSetData: data["featureSetData"] !== undefined ? deserializeDrishtiFeatureSetData(data["featureSetData"]) : undefined,
    golden7SoapboxSummary: data["golden7SoapboxSummary"] !== undefined ? deserializeDrishtiFeatureSetData(data["golden7SoapboxSummary"]) : undefined,
    inlinePlayback: data["inlinePlayback"] !== undefined ? deserializeVideoCrawlVideoInlinePlaybackMetadata(data["inlinePlayback"]) : undefined,
    lmsPreviewFramePerdocs: data["lmsPreviewFramePerdocs"] !== undefined ? deserializeImageRepositoryFramePerdocs(data["lmsPreviewFramePerdocs"]) : undefined,
    mediaInfo: data["mediaInfo"] !== undefined ? deserializeVideoMediaInfo(data["mediaInfo"]) : undefined,
    representativeFrameData: data["representativeFrameData"] !== undefined ? deserializeImageData(data["representativeFrameData"]) : undefined,
    s3Asr: data["s3Asr"] !== undefined ? deserializeImageRepositoryAmarnaCloudSpeechSignals(data["s3Asr"]) : undefined,
    s3LanguageIdentification: data["s3LanguageIdentification"] !== undefined ? deserializeImageRepositoryS3LangIdSignals(data["s3LanguageIdentification"]) : undefined,
    searchDocid: data["searchDocid"] !== undefined ? BigInt(data["searchDocid"]) : undefined,
    signalsBlob: data["signalsBlob"] !== undefined ? deserializeImageRepositoryAmarnaSignalsBlob(data["signalsBlob"]) : undefined,
    signalsBlobInfo: data["signalsBlobInfo"] !== undefined ? deserializeImageRepositoryAmarnaSignalsBlobInfo(data["signalsBlobInfo"]) : undefined,
    thumbnailerData: data["thumbnailerData"] !== undefined ? deserializeVideoPipelineViperThumbnailerColumnData(data["thumbnailerData"]) : undefined,
    thumbnailQualityScore: data["thumbnailQualityScore"] !== undefined ? deserializeVideoThumbnailsThumbnailScore(data["thumbnailQualityScore"]) : undefined,
    transcodeMetadata: data["transcodeMetadata"] !== undefined ? data["transcodeMetadata"].map((item: any) => (deserializeImageRepositoryApiItagSpecificMetadata(item))) : undefined,
    transcriptAsr: data["transcriptAsr"] !== undefined ? deserializePseudoVideoData(data["transcriptAsr"]) : undefined,
    truncationInfo: data["truncationInfo"] !== undefined ? deserializeImageRepositoryFileTruncationInfo(data["truncationInfo"]) : undefined,
    venomProcessingInfo: data["venomProcessingInfo"] !== undefined ? deserializeImageRepositoryVenomProcessingInfo(data["venomProcessingInfo"]) : undefined,
    videoAnchorSet: data["videoAnchorSet"] !== undefined ? deserializeVideoContentSearchVideoAnchorSets(data["videoAnchorSet"]) : undefined,
    videoPreviewBytes: data["videoPreviewBytes"] !== undefined ? data["videoPreviewBytes"].map((item: any) => (deserializeImageRepositoryVideoPreviewsVideoPreview(item))) : undefined,
    videoPreviews: data["videoPreviews"] !== undefined ? data["videoPreviews"].map((item: any) => (deserializeImageBaseVideoPreviewMetadata(item))) : undefined,
    videoStreamInfo: data["videoStreamInfo"] !== undefined ? deserializeVideoPipelineViperVSIColumnData(data["videoStreamInfo"]) : undefined,
    videoTranscriptAnnotations: data["videoTranscriptAnnotations"] !== undefined ? deserializeQualityWebanswersVideoTranscriptAnnotations(data["videoTranscriptAnnotations"]) : undefined,
  };
}

/**
 * Fields for crawl-status-related debugging information.
 */
export interface ImageRepositoryCrawlStatusInfo {
  code?:  | "VALID_IMAGE" | "INVALID_FETCH_REPLY" | "XROBOTED" | "URL_NOT_CRAWLED" | "PARSE_ERROR" | "INVALID_IMAGE" | "IMS_CRAWL_NOT_MODIFIED" | "EXPIRED_DISCOVERY_CRAWL" | "EXPIRED_FEED_CRAWL" | "EXPIRED_PRIORITY_FEED_CRAWL" | "INVALID_URL" | "VALID_VIDEO" | "VALID_SWF" | "VALID_SILVERLIGHT" | "INVALID_VIDEO" | "TRUNCATED_CONTENTS" | "FAST_CRAWL_LOCK_ACQUIRE_FAILED" | "FAST_CRAWL_TTL_EXPIRED";
  notCrawledReason?:  | "URL_CRAWLED" | "URL_ERROR" | "URL_ROBOTED" | "URL_UNREACHABLE" | "URL_TIMEOUT" | "URL_REJECTED" | "URL_NOT_FOLLOWED" | "NUM_STATE_TYPES";
}

export interface ImageRepositoryDeepImageEngagingnessOutput {
  /**
   * DeepImageEngagingness score.
   */
  score?: number;
}

/**
 * Describes our knowledge about whether a stored file is truncated with
 * respect to its original file online.
 */
export interface ImageRepositoryFileTruncationInfo {
  /**
   * A lower bound on the original file's size.
   */
  originalFileSizeLowerBoundBytes?: bigint;
  /**
   * Indicates whether the stored file is equal to the original file
   * (COMPLETE), is only a prefix (TRUNCATED), or that we don't know (UNKNOWN,
   * the default).
   */
  truncationState?:  | "UNKNOWN" | "COMPLETE" | "TRUNCATED";
}

function serializeImageRepositoryFileTruncationInfo(data: any): ImageRepositoryFileTruncationInfo {
  return {
    ...data,
    originalFileSizeLowerBoundBytes: data["originalFileSizeLowerBoundBytes"] !== undefined ? String(data["originalFileSizeLowerBoundBytes"]) : undefined,
  };
}

function deserializeImageRepositoryFileTruncationInfo(data: any): ImageRepositoryFileTruncationInfo {
  return {
    ...data,
    originalFileSizeLowerBoundBytes: data["originalFileSizeLowerBoundBytes"] !== undefined ? BigInt(data["originalFileSizeLowerBoundBytes"]) : undefined,
  };
}

/**
 * Identifier for frames associated with a video.
 */
export interface ImageRepositoryFrameIdentifier {
  previewFrameZeroVariant?: ImageRepositoryFrameIdentifierPreviewFrameZeroVariant;
  thumbnailVariant?: ImageRepositoryFrameIdentifierThumbnailVariant;
  /**
   * Offset of the frame from the beginning of the video (in milliseconds).
   */
  timestampMs?: number;
}

/**
 * This variant defines the frame to be the first frame of the video's
 * generated preview.
 */
export interface ImageRepositoryFrameIdentifierPreviewFrameZeroVariant {
  previewLength?:  | "UNSPECIFIED" | "THREE_SECONDS" | "SIX_SECONDS";
  /**
   * All xtags used in the generation of the preview. The same frame generated
   * from the same preview with different xtags will likely have different bytes
   * (such as, for example, resulting from a different aspect ratio).
   */
  xtagList?: ImageRepositoryApiXtagList;
}

/**
 * This variant defines the frame to be a thumbnail of the video.
 */
export interface ImageRepositoryFrameIdentifierThumbnailVariant {
}

/**
 * Only one of timestamp_msec or frame_identifier should be set. timestamp_msec
 * is the old identifier for frames, and is still used on thumbnail frames.
 * frame_identifier should be used on other kinds of frames (e.g. preview frame
 * zero).
 */
export interface ImageRepositoryFramePerdoc {
  frameIdentifier?: ImageRepositoryFrameIdentifier;
  perdoc?: ImageData;
  /**
   * Timestamp (in msec) of the frame from the original video DEPRECATED: Use
   * the timestamp_ms field in frame_identifier instead.
   */
  timestampMsec?: number;
}

function serializeImageRepositoryFramePerdoc(data: any): ImageRepositoryFramePerdoc {
  return {
    ...data,
    perdoc: data["perdoc"] !== undefined ? serializeImageData(data["perdoc"]) : undefined,
  };
}

function deserializeImageRepositoryFramePerdoc(data: any): ImageRepositoryFramePerdoc {
  return {
    ...data,
    perdoc: data["perdoc"] !== undefined ? deserializeImageData(data["perdoc"]) : undefined,
  };
}

/**
 * This proto stores perdocs extracted from video frames.
 */
export interface ImageRepositoryFramePerdocs {
  framePerdoc?: ImageRepositoryFramePerdoc[];
}

function serializeImageRepositoryFramePerdocs(data: any): ImageRepositoryFramePerdocs {
  return {
    ...data,
    framePerdoc: data["framePerdoc"] !== undefined ? data["framePerdoc"].map((item: any) => (serializeImageRepositoryFramePerdoc(item))) : undefined,
  };
}

function deserializeImageRepositoryFramePerdocs(data: any): ImageRepositoryFramePerdocs {
  return {
    ...data,
    framePerdoc: data["framePerdoc"] !== undefined ? data["framePerdoc"].map((item: any) => (deserializeImageRepositoryFramePerdoc(item))) : undefined,
  };
}

export interface ImageRepositoryNimaOutput {
  /**
   * NIMA score.
   */
  score?: number;
}

/**
 * Next Tag: 9
 */
export interface ImageRepositoryS3LangIdSignals {
  /**
   * Whether this audio chunk has speech or not.
   */
  containsSpeech?: boolean;
  endSec?: bigint;
  /**
   * S3 langID result. We keep langid_result even if contains_speech = false.
   */
  langidResult?: SpeechS3LanguageIdentificationResult;
  /**
   * Converted version of the langid_result field, so that we have the YT
   * compatible version of the langID result.
   */
  languageIdentification?: VideoTimedtextS4ALIResults;
  /**
   * The version of the model used for S3 LangID service.
   */
  modelVersion?: string;
  speechFrameCount?: number;
  /**
   * The audio chunk which corresponds to this langID result expressed as a
   * start_sec and end_sec.
   */
  startSec?: bigint;
  /**
   * Count the number of total frames in the audio chunk as well as the number
   * of speech frames.
   */
  totalFrameCount?: number;
}

function serializeImageRepositoryS3LangIdSignals(data: any): ImageRepositoryS3LangIdSignals {
  return {
    ...data,
    endSec: data["endSec"] !== undefined ? String(data["endSec"]) : undefined,
    langidResult: data["langidResult"] !== undefined ? serializeSpeechS3LanguageIdentificationResult(data["langidResult"]) : undefined,
    startSec: data["startSec"] !== undefined ? String(data["startSec"]) : undefined,
  };
}

function deserializeImageRepositoryS3LangIdSignals(data: any): ImageRepositoryS3LangIdSignals {
  return {
    ...data,
    endSec: data["endSec"] !== undefined ? BigInt(data["endSec"]) : undefined,
    langidResult: data["langidResult"] !== undefined ? deserializeSpeechS3LanguageIdentificationResult(data["langidResult"]) : undefined,
    startSec: data["startSec"] !== undefined ? BigInt(data["startSec"]) : undefined,
  };
}

/**
 * A message containing embedding information and localization scores using the
 * VSS product recognition module.
 */
export interface ImageRepositoryShoppingProductInformation {
  /**
   * Information about versioned product sets found. There will be at most two
   * versions present. The results from the current version of the models used
   * in VSS and the results from the previous version of the models used. Note
   * that not all products may have two version since the model might detect the
   * product in one version and not the other.
   */
  productSets?: ImageRepositoryShoppingProductInformationVersionedProductInformationSet[];
}

function serializeImageRepositoryShoppingProductInformation(data: any): ImageRepositoryShoppingProductInformation {
  return {
    ...data,
    productSets: data["productSets"] !== undefined ? data["productSets"].map((item: any) => (serializeImageRepositoryShoppingProductInformationVersionedProductInformationSet(item))) : undefined,
  };
}

function deserializeImageRepositoryShoppingProductInformation(data: any): ImageRepositoryShoppingProductInformation {
  return {
    ...data,
    productSets: data["productSets"] !== undefined ? data["productSets"].map((item: any) => (deserializeImageRepositoryShoppingProductInformationVersionedProductInformationSet(item))) : undefined,
  };
}

/**
 * Contains the coordinates of the normalized bounding box.
 */
export interface ImageRepositoryShoppingProductInformationBoundingBox {
  /**
   * The vertical height of the bounding box (ymax - ymin + 1), normalized by
   * image height with range [0,1].
   */
  h?: number;
  /**
   * The horizontal width of the bound box (xmax - xmin + 1), normalized by
   * image width with range [0,1].
   */
  w?: number;
  /**
   * The x coordinate (xmin), normalized by image width with range [0,1).
   */
  x?: number;
  /**
   * The y coordinate (ymin), normalized by image height with range [0,1).
   */
  y?: number;
}

/**
 * The recognized entity.
 */
export interface ImageRepositoryShoppingProductInformationEntity {
  id?: string;
  /**
   * The normalized recognition score between 0 and 1.
   */
  score?: number;
}

/**
 * Information about a single product. For ProductNet models, each product has
 * one label with a detection score. The label is mapped to one or multiple
 * category ids. For PRIMI generic feature models, each product can have
 * multiple entities, and each entity has a score. The category_id and
 * detection_score fields are not populated for PRIMI generic feature models.
 */
export interface ImageRepositoryShoppingProductInformationProductInformation {
  /**
   * The possible Merlot ids for the item. There may be more than one if the
   * product detector result corresponds to a collection of merlot ids, which
   * can't be easily grouped up to a common ancestor, for which the detector
   * would still make sense for all the children. E.g. a detected "chair" can be
   * either an indoor chair or an outdoor one, however in Merlot the common
   * ancestor of the two is furniture.
   */
  categoryId?: number[];
  /**
   * The k-d tree clusters for retrieval. Will be deprecated, use the
   * token_groups instead. To add tokens/cluster_ids from new tokenization model
   * in the future, add it to the token_groups.
   */
  clusterIds?: number[];
  /**
   * The localization detection score.
   */
  detectionScore?: number;
  /**
   * The serialized embedding values.
   */
  embedding?: Uint8Array;
  /**
   * The recognized entities and scores.
   */
  entities?: ImageRepositoryShoppingProductInformationEntity[];
  /**
   * Feature type (different detectors and embedders) requested.
   */
  featureType?: string;
  /**
   * The bounding box.
   */
  productLocation?: ImageRepositoryShoppingProductInformationBoundingBox;
  tokenGroups?: ImageRepositoryShoppingProductInformationProductInformationTokenGroup[];
}

function serializeImageRepositoryShoppingProductInformationProductInformation(data: any): ImageRepositoryShoppingProductInformationProductInformation {
  return {
    ...data,
    embedding: data["embedding"] !== undefined ? encodeBase64(data["embedding"]) : undefined,
  };
}

function deserializeImageRepositoryShoppingProductInformationProductInformation(data: any): ImageRepositoryShoppingProductInformationProductInformation {
  return {
    ...data,
    embedding: data["embedding"] !== undefined ? decodeBase64(data["embedding"] as string) : undefined,
  };
}

/**
 * The tokens for retrieval.
 */
export interface ImageRepositoryShoppingProductInformationProductInformationTokenGroup {
  model?:  | "UNKNOWN" | "KMEANS" | "KMEANSV2" | "KMEANSV3";
  tokens?: number[];
}

/**
 * Store ProductInformation for a given version of the models used in VSS.
 */
export interface ImageRepositoryShoppingProductInformationVersionedProductInformationSet {
  /**
   * The type of the model.
   */
  modelType?:  | "MODEL_TYPE_UNKNOWN" | "MODEL_TYPE_PRODUCTNET" | "MODEL_TYPE_PRIMI_GENERIC";
  /**
   * List of ProductInformation for this version.
   */
  products?: ImageRepositoryShoppingProductInformationProductInformation[];
  /**
   * The version of the models used in VSS. Newer version will have a higher
   * version number.
   */
  version?: number;
}

function serializeImageRepositoryShoppingProductInformationVersionedProductInformationSet(data: any): ImageRepositoryShoppingProductInformationVersionedProductInformationSet {
  return {
    ...data,
    products: data["products"] !== undefined ? data["products"].map((item: any) => (serializeImageRepositoryShoppingProductInformationProductInformation(item))) : undefined,
  };
}

function deserializeImageRepositoryShoppingProductInformationVersionedProductInformationSet(data: any): ImageRepositoryShoppingProductInformationVersionedProductInformationSet {
  return {
    ...data,
    products: data["products"] !== undefined ? data["products"].map((item: any) => (deserializeImageRepositoryShoppingProductInformationProductInformation(item))) : undefined,
  };
}

/**
 * Alternative hypotheses (a.k.a. n-best list).
 */
export interface ImageRepositorySpeechRecognitionAlternative {
  /**
   * The confidence estimate between 0.0 and 1.0. A higher number indicates an
   * estimated greater likelihood that the recognized words are correct. This
   * field is set only for the top alternative of a non-streaming result or, of
   * a streaming result where `is_final=true`. This field is not guaranteed to
   * be accurate and users should not rely on it to be always provided. The
   * default of 0.0 is a sentinel value indicating `confidence` was not set.
   */
  confidence?: number;
  /**
   * Transcript text representing the words that the user spoke.
   */
  transcript?: string;
  /**
   * A list of word-specific information for each recognized word. Note: When
   * `enable_speaker_diarization` is true, you will see all the words from the
   * beginning of the audio.
   */
  words?: ImageRepositoryWordInfo[];
}

function serializeImageRepositorySpeechRecognitionAlternative(data: any): ImageRepositorySpeechRecognitionAlternative {
  return {
    ...data,
    words: data["words"] !== undefined ? data["words"].map((item: any) => (serializeImageRepositoryWordInfo(item))) : undefined,
  };
}

function deserializeImageRepositorySpeechRecognitionAlternative(data: any): ImageRepositorySpeechRecognitionAlternative {
  return {
    ...data,
    words: data["words"] !== undefined ? data["words"].map((item: any) => (deserializeImageRepositoryWordInfo(item))) : undefined,
  };
}

/**
 * A speech recognition result corresponding to a portion of the audio. This
 * field is copied from cloud/speech/v1p1beta1/cloud_speech.proto. Amarna needs
 * to have a standalone version as v1p1beta1/cloud_speech.proto is in the for of
 * versioned proto and it breaks other prod code depending on Amarna's video
 * schema.
 */
export interface ImageRepositorySpeechRecognitionResult {
  /**
   * May contain one or more recognition hypotheses (up to the maximum
   * specified in `max_alternatives`). These alternatives are ordered in terms
   * of accuracy, with the top (first) alternative being the most probable, as
   * ranked by the recognizer.
   */
  alternatives?: ImageRepositorySpeechRecognitionAlternative[];
  /**
   * For multi-channel audio, this is the channel number corresponding to the
   * recognized result for the audio from that channel. For audio_channel_count
   * = N, its output values can range from '1' to 'N'.
   */
  channelTag?: number;
  /**
   * The [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag of
   * the language in this result. This language code was detected to have the
   * most likelihood of being spoken in the audio.
   */
  languageCode?: string;
  /**
   * Time offset of the end of this result relative to the beginning of the
   * audio. This field is internal-only and is used to order results based on
   * their timestamps.
   */
  resultEndTime?: number /* Duration */;
}

function serializeImageRepositorySpeechRecognitionResult(data: any): ImageRepositorySpeechRecognitionResult {
  return {
    ...data,
    alternatives: data["alternatives"] !== undefined ? data["alternatives"].map((item: any) => (serializeImageRepositorySpeechRecognitionAlternative(item))) : undefined,
    resultEndTime: data["resultEndTime"] !== undefined ? data["resultEndTime"] : undefined,
  };
}

function deserializeImageRepositorySpeechRecognitionResult(data: any): ImageRepositorySpeechRecognitionResult {
  return {
    ...data,
    alternatives: data["alternatives"] !== undefined ? data["alternatives"].map((item: any) => (deserializeImageRepositorySpeechRecognitionAlternative(item))) : undefined,
    resultEndTime: data["resultEndTime"] !== undefined ? data["resultEndTime"] : undefined,
  };
}

/**
 * To indicate whether the image or video is to be deleted from the repository
 * due to legal reasons or hidden from search results.
 */
export interface ImageRepositoryUnwantedContent {
  deletionReason?:  | "OTHER" | "CP";
  hideReason?:  | "UNKNOWN" | "NCEI";
}

export interface ImageRepositoryVenomProcessingInfo {
  /**
   * Contains one status for each Genus that this video belongs to in Venom.
   * For example, a video that is both 1) Found on the web, and 2) Opted-in by
   * an Interest Feed partner would have two entries, one for GENUS_CRAWL and
   * one for GENUS_VIDEO_INTEREST_FEED
   */
  venomStatus?: ImageRepositoryVenomStatus[];
}

function serializeImageRepositoryVenomProcessingInfo(data: any): ImageRepositoryVenomProcessingInfo {
  return {
    ...data,
    venomStatus: data["venomStatus"] !== undefined ? data["venomStatus"].map((item: any) => (serializeImageRepositoryVenomStatus(item))) : undefined,
  };
}

function deserializeImageRepositoryVenomProcessingInfo(data: any): ImageRepositoryVenomProcessingInfo {
  return {
    ...data,
    venomStatus: data["venomStatus"] !== undefined ? data["venomStatus"].map((item: any) => (deserializeImageRepositoryVenomStatus(item))) : undefined,
  };
}

export interface ImageRepositoryVenomStatus {
  /**
   * Venom ACL of the video. Used to check if other systems, such as Ares, are
   * able to process the video.
   */
  acl?: VideoAssetsVenomACL;
  deletionTimestampUsec?: bigint;
  /**
   * The Genus (Venom's client ID) that this media belongs to.
   */
  genus?:  | "GENUS_UNKNOWN" | "GENUS_YT_HIGH_VALUE_CONTENT" | "GENUS_YT_USER_GENERATED_CONTENT" | "GENUS_GMAIL" | "GENUS_KIDS_HUB" | "GENUS_YOUTUBE_DIRECTOR" | "GENUS_DCLK_VIDEO_ADS" | "GENUS_DAI_PODCAST" | "GENUS_TESTING" | "GENUS_YT_UNPLUGGED_SVOD" | "GENUS_YT_UNPLUGGED_DVR" | "GENUS_HVC_INGESTION" | "GENUS_DRIVE" | "GENUS_YT_LIGHTWEIGHT_VIDEO" | "GENUS_ASK_QNA" | "GENUS_LOCAL_VIDEO" | "GENUS_PLAY_AUDIOBOOKS" | "GENUS_HANGOUTS_CHAT" | "GENUS_VIDEO_INTEREST_FEED" | "GENUS_YT_MUSIC" | "GENUS_RECORDER" | "GENUS_YT_ORIGINAL_CONTENT" | "GENUS_STAMP" | "GENUS_BULLETIN_AUDIO" | "GENUS_CRAWL" | "GENUS_PHOTOS" | "GENUS_MATERIAL_GALLERY" | "GENUS_YT_REFERENCE" | "GENUS_LENSLETS_VIDEOS" | "GENUS_BLOGGER" | "GENUS_PODCASTS" | "GENUS_OCEAN" | "GENUS_LMS" | "GENUS_WEB_VIDEO_ADS" | "GENUS_STUDIO" | "GENUS_YT_TDSD_REFERENCE" | "GENUS_WEB_STORY" | "GENUS_NEST_CAMERA_CLOUD" | "GENUS_AREA120_BLUEBIRD" | "GENUS_ARTS_AND_CULTURE" | "GENUS_DEMO" | "GENUS_KARTO" | "GENUS_CONTRIB_SERVICE_SHARED" | "GENUS_CONTRIB_SERVICE_GEO_UGC" | "GENUS_SEARCH_SPORTS" | "GENUS_BUSINESSMESSAGING";
  /**
   * Time that VideoNotification result was received from Venom.
   */
  insertionResponseTimestampUsec?: bigint;
  insertionTimestampUsec?: bigint;
  /**
   * Record the attempts num of previous insertion. It's only updated when
   * either the insertion succeeds or fails with reason
   * INSERTION_ATTEMPTS_EXCEEDED, but it's always set so that we can easily
   * construct venom_id with this attempts num for future insertions.
   */
  lastInsertionAttemptsNum?: number;
  reason?:  | "NONE" | "INVALID" | "WRONG_CRITERIA" | "DISABLED" | "FAILED_INSERTION" | "INSERTION_SKIPPED" | "FAILED_DELETION" | "INCOMPLETE_DOWNLOAD" | "FILTERED" | "NOT_FOUND" | "INSERTION_ATTEMPTS_EXCEEDED" | "ASSET_ALREADY_EXISTS";
  /**
   * The Settings that were used to customize the Venom request for this media.
   */
  settings?: VideoAssetsVenomSettings[];
  state?:  | "UNKNOWN_STATE" | "INSERTED" | "RESPONDED" | "NOT_INSERTED" | "DELETED" | "NOT_DELETED";
  /**
   * Transition contains the Objective and Outcome of the latest Venom run.
   */
  transition?: VideoAssetsVenomTransition;
  /**
   * The media's unique identifier within Venom.
   */
  venomId?: VideoAssetsVenomVideoId;
  /**
   * The generation number returned by Venom.
   */
  venomMutationGeneration?: bigint;
  /**
   * This field is not persisted anywhere. It is only used in deletion service
   * for converying the VideoVenomSetting when deleting Venom data.
   */
  videoVenomSetting?:  | "VIDEO_VENOM_SETTING_COMMON" | "VIDEO_VENOM_SETTING_VINEYARD";
}

function serializeImageRepositoryVenomStatus(data: any): ImageRepositoryVenomStatus {
  return {
    ...data,
    deletionTimestampUsec: data["deletionTimestampUsec"] !== undefined ? String(data["deletionTimestampUsec"]) : undefined,
    insertionResponseTimestampUsec: data["insertionResponseTimestampUsec"] !== undefined ? String(data["insertionResponseTimestampUsec"]) : undefined,
    insertionTimestampUsec: data["insertionTimestampUsec"] !== undefined ? String(data["insertionTimestampUsec"]) : undefined,
    venomId: data["venomId"] !== undefined ? serializeVideoAssetsVenomVideoId(data["venomId"]) : undefined,
    venomMutationGeneration: data["venomMutationGeneration"] !== undefined ? String(data["venomMutationGeneration"]) : undefined,
  };
}

function deserializeImageRepositoryVenomStatus(data: any): ImageRepositoryVenomStatus {
  return {
    ...data,
    deletionTimestampUsec: data["deletionTimestampUsec"] !== undefined ? BigInt(data["deletionTimestampUsec"]) : undefined,
    insertionResponseTimestampUsec: data["insertionResponseTimestampUsec"] !== undefined ? BigInt(data["insertionResponseTimestampUsec"]) : undefined,
    insertionTimestampUsec: data["insertionTimestampUsec"] !== undefined ? BigInt(data["insertionTimestampUsec"]) : undefined,
    venomId: data["venomId"] !== undefined ? deserializeVideoAssetsVenomVideoId(data["venomId"]) : undefined,
    venomMutationGeneration: data["venomMutationGeneration"] !== undefined ? BigInt(data["venomMutationGeneration"]) : undefined,
  };
}

export interface ImageRepositoryVideoIndexingInfo {
  notIndexedVideoLink?: ImageRepositoryVideoLinkIndexingInfo[];
}

export interface ImageRepositoryVideoLinkIndexingInfo {
  /**
   * Fields for crawl-status-related debugging information.
   */
  crawlStatusInfo?: ImageRepositoryCrawlStatusInfo;
  /**
   * The video URL.
   */
  url?: string;
}

export interface ImageRepositoryVideoPreviewsDebuggingInfo {
  /**
   * Last Amarna processing timestamp.
   */
  lastAmarnaProcessingTime?: Date;
  /**
   * The underlying processing engine, like 'viper' or 'kronos'.
   */
  processingEngine?: string;
}

function serializeImageRepositoryVideoPreviewsDebuggingInfo(data: any): ImageRepositoryVideoPreviewsDebuggingInfo {
  return {
    ...data,
    lastAmarnaProcessingTime: data["lastAmarnaProcessingTime"] !== undefined ? data["lastAmarnaProcessingTime"].toISOString() : undefined,
  };
}

function deserializeImageRepositoryVideoPreviewsDebuggingInfo(data: any): ImageRepositoryVideoPreviewsDebuggingInfo {
  return {
    ...data,
    lastAmarnaProcessingTime: data["lastAmarnaProcessingTime"] !== undefined ? new Date(data["lastAmarnaProcessingTime"]) : undefined,
  };
}

export interface ImageRepositoryVideoPreviewsVideoPreview {
  /**
   * The actual video preview bytes generated for the video.
   */
  content?: Uint8Array;
  /**
   * Used for debugging only.
   */
  debuggingInfo?: ImageRepositoryVideoPreviewsDebuggingInfo;
  /**
   * The metadata associated with the preview (i.e. the type: 8k, 90k, etc.)
   */
  metadata?: ImageBaseVideoPreviewMetadata;
  /**
   * 0th frame image of the preview. This frame has the same resolution as the
   * associated preview video bytes, as it is taken directly from the preview
   * bytes in Venom/Viper processing. Right now, we only populate
   * preview_frame_zero only for the VPREVIEW_TYPE_540K_ORIGINAL_HQ_LICENSED
   * preview type. Note that preview_frame_zero.thumbnails(0).timestamp_ms() is
   * the timestamp from the full video, not from the preview.
   */
  previewFrameZero?: DrishtiVesperVideoThumbnail;
}

function serializeImageRepositoryVideoPreviewsVideoPreview(data: any): ImageRepositoryVideoPreviewsVideoPreview {
  return {
    ...data,
    content: data["content"] !== undefined ? encodeBase64(data["content"]) : undefined,
    debuggingInfo: data["debuggingInfo"] !== undefined ? serializeImageRepositoryVideoPreviewsDebuggingInfo(data["debuggingInfo"]) : undefined,
    metadata: data["metadata"] !== undefined ? serializeImageBaseVideoPreviewMetadata(data["metadata"]) : undefined,
    previewFrameZero: data["previewFrameZero"] !== undefined ? serializeDrishtiVesperVideoThumbnail(data["previewFrameZero"]) : undefined,
  };
}

function deserializeImageRepositoryVideoPreviewsVideoPreview(data: any): ImageRepositoryVideoPreviewsVideoPreview {
  return {
    ...data,
    content: data["content"] !== undefined ? decodeBase64(data["content"] as string) : undefined,
    debuggingInfo: data["debuggingInfo"] !== undefined ? deserializeImageRepositoryVideoPreviewsDebuggingInfo(data["debuggingInfo"]) : undefined,
    metadata: data["metadata"] !== undefined ? deserializeImageBaseVideoPreviewMetadata(data["metadata"]) : undefined,
    previewFrameZero: data["previewFrameZero"] !== undefined ? deserializeDrishtiVesperVideoThumbnail(data["previewFrameZero"]) : undefined,
  };
}

export interface ImageRepositoryVideoProperties {
  /**
   * Both audio- and audio-video-files are treated as videos during indexing
   * (whether they share a container format, like .mp4, or not, like .mp3). This
   * bool indicates that there's no video track, just an audio track.
   */
  audioOnly?: boolean;
  /**
   * Information derived from fetched video bytes.
   */
  contentBasedMetadata?: ImageRepositoryContentBasedVideoMetadata;
  /**
   * The raw crawl state.
   */
  crawlState?: ImageMoosedogCrawlState;
  /**
   * Timestamp of the first time that the video was successfully crawled.
   */
  firstCrawlTimestampSec?: bigint;
  /**
   * Timestamp when this video's videoProperties is populated for the first
   * time, measured in seconds since epoch.
   */
  firstProcessingTimestampSec?: bigint;
  /**
   * DEPRECATED: please use content_based_metadata.inline_playback. Metadata
   * related to Inline playback on the Interest Feed
   */
  inlinePlayback?: VideoCrawlVideoInlinePlaybackMetadata;
  /**
   * Timestamp when this video's last crawling is requested, measured in
   * seconds since epoch.
   */
  lastCrawlRequestTimestampSec?: bigint;
  /**
   * Last timestamp when this video's videoProperties is populated, measured in
   * seconds since epoch.
   */
  lastProcessingTimestampSec?: bigint;
  /**
   * This is the video url taken from the key of the Amarna references table
   * row corresponding to this message.
   */
  url?: string;
}

function serializeImageRepositoryVideoProperties(data: any): ImageRepositoryVideoProperties {
  return {
    ...data,
    contentBasedMetadata: data["contentBasedMetadata"] !== undefined ? serializeImageRepositoryContentBasedVideoMetadata(data["contentBasedMetadata"]) : undefined,
    crawlState: data["crawlState"] !== undefined ? serializeImageMoosedogCrawlState(data["crawlState"]) : undefined,
    firstCrawlTimestampSec: data["firstCrawlTimestampSec"] !== undefined ? String(data["firstCrawlTimestampSec"]) : undefined,
    firstProcessingTimestampSec: data["firstProcessingTimestampSec"] !== undefined ? String(data["firstProcessingTimestampSec"]) : undefined,
    inlinePlayback: data["inlinePlayback"] !== undefined ? serializeVideoCrawlVideoInlinePlaybackMetadata(data["inlinePlayback"]) : undefined,
    lastCrawlRequestTimestampSec: data["lastCrawlRequestTimestampSec"] !== undefined ? String(data["lastCrawlRequestTimestampSec"]) : undefined,
    lastProcessingTimestampSec: data["lastProcessingTimestampSec"] !== undefined ? String(data["lastProcessingTimestampSec"]) : undefined,
  };
}

function deserializeImageRepositoryVideoProperties(data: any): ImageRepositoryVideoProperties {
  return {
    ...data,
    contentBasedMetadata: data["contentBasedMetadata"] !== undefined ? deserializeImageRepositoryContentBasedVideoMetadata(data["contentBasedMetadata"]) : undefined,
    crawlState: data["crawlState"] !== undefined ? deserializeImageMoosedogCrawlState(data["crawlState"]) : undefined,
    firstCrawlTimestampSec: data["firstCrawlTimestampSec"] !== undefined ? BigInt(data["firstCrawlTimestampSec"]) : undefined,
    firstProcessingTimestampSec: data["firstProcessingTimestampSec"] !== undefined ? BigInt(data["firstProcessingTimestampSec"]) : undefined,
    inlinePlayback: data["inlinePlayback"] !== undefined ? deserializeVideoCrawlVideoInlinePlaybackMetadata(data["inlinePlayback"]) : undefined,
    lastCrawlRequestTimestampSec: data["lastCrawlRequestTimestampSec"] !== undefined ? BigInt(data["lastCrawlRequestTimestampSec"]) : undefined,
    lastProcessingTimestampSec: data["lastProcessingTimestampSec"] !== undefined ? BigInt(data["lastProcessingTimestampSec"]) : undefined,
  };
}

/**
 * Word-specific information for recognized words.
 */
export interface ImageRepositoryWordInfo {
  /**
   * The confidence estimate between 0.0 and 1.0. A higher number indicates an
   * estimated greater likelihood that the recognized words are correct. This
   * field is set only for the top alternative of a non-streaming result or, of
   * a streaming result where `is_final=true`. This field is not guaranteed to
   * be accurate and users should not rely on it to be always provided. The
   * default of 0.0 is a sentinel value indicating `confidence` was not set.
   */
  confidence?: number;
  /**
   * Time offset relative to the beginning of the audio, and corresponding to
   * the end of the spoken word. This field is only set if
   * `enable_word_time_offsets=true` and only in the top hypothesis. This is an
   * experimental feature and the accuracy of the time offset can vary.
   */
  endTime?: number /* Duration */;
  /**
   * A distinct integer value is assigned for every speaker within the audio.
   * This field specifies which one of those speakers was detected to have
   * spoken this word. Value ranges from '1' to diarization_speaker_count.
   * speaker_tag is set if enable_speaker_diarization = 'true' and only in the
   * top alternative.
   */
  speakerTag?: number;
  /**
   * Time offset relative to the beginning of the audio, and corresponding to
   * the start of the spoken word. This field is only set if
   * `enable_word_time_offsets=true` and only in the top hypothesis. This is an
   * experimental feature and the accuracy of the time offset can vary.
   */
  startTime?: number /* Duration */;
  /**
   * The word corresponding to this set of information.
   */
  word?: string;
}

function serializeImageRepositoryWordInfo(data: any): ImageRepositoryWordInfo {
  return {
    ...data,
    endTime: data["endTime"] !== undefined ? data["endTime"] : undefined,
    startTime: data["startTime"] !== undefined ? data["startTime"] : undefined,
  };
}

function deserializeImageRepositoryWordInfo(data: any): ImageRepositoryWordInfo {
  return {
    ...data,
    endTime: data["endTime"] !== undefined ? data["endTime"] : undefined,
    startTime: data["startTime"] !== undefined ? data["startTime"] : undefined,
  };
}

/**
 * Next available tag: 13
 */
export interface ImageRepositoryYoutubeProcessingFilter {
  previewsFilteredReason?:  | "UNKNOWN" | "CONTENT_CLAIMS" | "MATURE_CONTENT" | "INVALID_VIDEO_DATA" | "NO_VSI" | "SHORT_DURATION" | "NO_DURATION" | "EMPTY_DATA" | "DELETED" | "OFFICIAL_MUSIC_VIDEO" | "PREMIUM_CONTENT" | "ART_TRACK" | "PHARMA_CHANNEL"[];
}

/**
 * Don't change the field names. The names are used as sparse feature labels in
 * client projects.
 */
export interface ImageSafesearchContentBrainPornAnnotation {
  /**
   * The probability that the youngest person in the image is a child.
   */
  childScore?: number;
  /**
   * This score correlates with potential child abuse. Google confidential!
   */
  csaiScore?: number;
  /**
   * This field contains the probability that an image is inappropriate for
   * Images Universal, according to this policy: go/iupolicy.
   */
  iuInappropriateScore?: number;
  medicalScore?: number;
  pedoScore?: number;
  pornScore?: number;
  /**
   * This score is related to an image being sexually suggestive.
   */
  racyScore?: number;
  spoofScore?: number;
  /**
   * This field is an experimental one with a quite vague meaning. Please
   * contact safesearch@ before any meaningful use of it. There is no guarantee
   * it will preserve its behavior in the future.
   */
  version?: string;
  violenceScore?: number;
  /**
   * Deprecated, use porn_score instead. The most recent model version does not
   * produce this anymore.
   */
  ytPornScore?: number;
}

/**
 * A protocol buffer to store the OCR annotation. Next available tag id: 10.
 */
export interface ImageSafesearchContentOCRAnnotation {
  /**
   * A string that indicates the version of SafeSearch OCR annotation.
   */
  ocrAnnotationVersion?: string;
  /**
   * The score produced by Aksara geometry and spoof score. Describes the
   * 'visibility' or 'importance' of the text on the image [0, 1]
   */
  ocrProminenceScore?: number;
  /**
   * Image OCR racyness/pornyness, computed by porn query classifier.
   */
  pornScore?: number;
  /**
   * Same as offensive_score, but weighted by prominence.
   */
  prominentOffensiveScore?: number;
  /**
   * Same as vulgar_score, but weighted by prominence.
   */
  prominentVulgarScore?: number;
  /**
   * The score produced by offensive salient terms model.
   */
  qbstOffensiveScore?: number;
  /**
   * Presence of i18n-recognized vulgar term in the OCR.
   */
  vulgarI18nBit?: boolean;
  /**
   * Image OCR vulgarity, computed by vulgar query classifier.
   */
  vulgarScore?: number;
}

export interface ImageSafesearchContentOffensiveSymbolDetection {
  matches?: ImageSafesearchContentOffensiveSymbolMatch[];
}

/**
 * Each entry corresponds to an image containing an offensive symbol.
 */
export interface ImageSafesearchContentOffensiveSymbolMatch {
  /**
   * Confidence score of the match. The higher, the more likely to match the
   * symbol.
   */
  score?: number;
  type?:  | "INVALID" | "SWASTIKA_WHITE_ON_BLACK" | "SWASTIKA_BLACK_ON_WHITE" | "SWASTIKA_BLACK_ON_WHITE_ROTATED" | "NAZI_YELLOW_BADGE";
}

export interface ImageSearchImageIndexingInfo {
  /**
   * Image Selection Info
   */
  imageLinkSelectionInfo?: ImageSearchImageSelectionInfo[];
  /**
   * URLs and Amarna status of images on the page for which image data is not
   * yet available and weren't selected for indexing in image search. Used by
   * consumers of docjoins that need a complete view of image urls on the page
   * (i.e. Digdug).
   */
  rejectedNotIndexedImageLink?: ImageSearchUnindexedImageLink[];
  /**
   * URLs and Amarna status of images on the page for which image data is not
   * yet available and were otherwise selected for indexing in image search.
   * Used by consumers of docjoins that need a complete view of selected image
   * urls on the page (i.e. Hearse, the index selection testbed).
   */
  selectedNotIndexedImageLink?: ImageSearchUnindexedImageLink[];
}

/**
 * The image license info for licensable images(go/Licensable-Images-PRD) This
 * proto in design doc: go/licensable-images-edd
 */
export interface ImageSearchImageLicenseInfo {
  /**
   * Records web page url about how to use the licensed image.
   */
  acquireLicensePage?: string;
  /**
   * Provides copyright info.
   */
  copyrightNotice?: string;
  /**
   * Source type for copyright_notice field.
   */
  copyrightNoticeSourceType?:  | "UNKNOWN_SOURCE" | "SCHEMA_ORG_MARKUP" | "IPTC_METADATA";
  /**
   * creator, authors.
   */
  creator?: string[];
  /**
   * Source type for creator field.
   */
  creatorSourceType?:  | "UNKNOWN_SOURCE" | "SCHEMA_ORG_MARKUP" | "IPTC_METADATA";
  /**
   * Text for crediting persons or organizations.
   */
  creditText?: string;
  /**
   * Source type for credit_text field.
   */
  creditTextSourceType?:  | "UNKNOWN_SOURCE" | "SCHEMA_ORG_MARKUP" | "IPTC_METADATA";
  /**
   * Whether this license url is in retired license list, which is from:
   * https://creativecommons.org/retiredlicenses/
   */
  isRetiredCcUrl?: boolean;
  licenseType?:  | "NO_LICENSE" | "CREATIVE_COMMONS_LICENSE" | "NON_CREATIVE_COMMONS_LICENSE";
  /**
   * Records license URL.
   */
  licenseUrl?: string;
  /**
   * A bitwise-OR of SafeSearch filtering flags. If present, the flags will be
   * a bitwise-AND between this value and all the
   * classifier_porn::query::Vertical enums. If the value is -1, it indicates
   * there is some error with SafeSearch classifier. The default value 0 means
   * no filtering flags are set.
   */
  safesearchFlags?: number;
  sourceType?:  | "UNKNOWN_SOURCE" | "SCHEMA_ORG_MARKUP" | "IPTC_METADATA";
}

export interface ImageSearchImageSelectionInfo {
  /**
   * Image Selection Info.
   */
  imageLinkSelectionInfo?: ImageMustangImageLinkSelectionInfo;
  /**
   * The image URL.
   */
  url?: string;
}

export interface ImageSearchUnindexedImageLink {
  /**
   * Insight on why we do not have data for this imagelink.
   */
  amarnaStatus?: ImageRepositoryAmarnaStatus;
  /**
   * Fields for crawl-status-related debugging information.
   */
  crawlStatusInfo?: ImageRepositoryCrawlStatusInfo;
  /**
   * The image URL.
   */
  url?: string;
}

/**
 * Annotation packs various recognition, detection, embedding, and parsing
 * results. One Annotation per bounding box detection.
 */
export interface ImageUnderstandingIndexingAnnotation {
  /**
   * Multiple feature embeddings for this bounding box.
   */
  feature?: ImageUnderstandingIndexingFeature[];
  /**
   * Multiple label annotations for this bounding box.
   */
  labelGroup?: ImageUnderstandingIndexingLabelGroup[];
  /**
   * Detected bounding box. Leave it not set for whole image annotation.
   */
  roi?: ImageUnderstandingIndexingImageRegion;
}

function serializeImageUnderstandingIndexingAnnotation(data: any): ImageUnderstandingIndexingAnnotation {
  return {
    ...data,
    feature: data["feature"] !== undefined ? data["feature"].map((item: any) => (serializeImageUnderstandingIndexingFeature(item))) : undefined,
  };
}

function deserializeImageUnderstandingIndexingAnnotation(data: any): ImageUnderstandingIndexingAnnotation {
  return {
    ...data,
    feature: data["feature"] !== undefined ? data["feature"].map((item: any) => (deserializeImageUnderstandingIndexingFeature(item))) : undefined,
  };
}

export interface ImageUnderstandingIndexingAnnotationGroup {
  annotation?: ImageUnderstandingIndexingAnnotation[];
}

function serializeImageUnderstandingIndexingAnnotationGroup(data: any): ImageUnderstandingIndexingAnnotationGroup {
  return {
    ...data,
    annotation: data["annotation"] !== undefined ? data["annotation"].map((item: any) => (serializeImageUnderstandingIndexingAnnotation(item))) : undefined,
  };
}

function deserializeImageUnderstandingIndexingAnnotationGroup(data: any): ImageUnderstandingIndexingAnnotationGroup {
  return {
    ...data,
    annotation: data["annotation"] !== undefined ? data["annotation"].map((item: any) => (deserializeImageUnderstandingIndexingAnnotation(item))) : undefined,
  };
}

/**
 * Image feature embedding proto. It supports various embedding formats: raw
 * bytes, floating point values, and tokens.
 */
export interface ImageUnderstandingIndexingFeature {
  /**
   * Multiple fields can be set. For example for Starburst V3, they can be used
   * to store compressed byte, raw float feature, and tokens, respectively.
   */
  bytesValue?: Uint8Array;
  floatValue?: number[];
  /**
   * Local features.
   */
  imageTemplate?: PhotosVisionObjectrecImageTemplate;
  int32Value?: number[];
  version?: string;
}

function serializeImageUnderstandingIndexingFeature(data: any): ImageUnderstandingIndexingFeature {
  return {
    ...data,
    bytesValue: data["bytesValue"] !== undefined ? encodeBase64(data["bytesValue"]) : undefined,
    imageTemplate: data["imageTemplate"] !== undefined ? serializePhotosVisionObjectrecImageTemplate(data["imageTemplate"]) : undefined,
  };
}

function deserializeImageUnderstandingIndexingFeature(data: any): ImageUnderstandingIndexingFeature {
  return {
    ...data,
    bytesValue: data["bytesValue"] !== undefined ? decodeBase64(data["bytesValue"] as string) : undefined,
    imageTemplate: data["imageTemplate"] !== undefined ? deserializePhotosVisionObjectrecImageTemplate(data["imageTemplate"]) : undefined,
  };
}

/**
 * Image region produced by a detector.
 */
export interface ImageUnderstandingIndexingImageRegion {
  /**
   * Bounding box normalized to [0,1] scale independent on the image size. For
   * example if the original image has the size 1600x1200, the rectangle [200,
   * 200, 800, 600] from the image would have a normalized bounding box [1/8,
   * 1/6, 1/2, 1/2].
   */
  box?: PhotosVisionGroundtruthdbNormalizedBoundingBox;
  /**
   * Box confidence score. This is used to store the confidence of the box
   * proposal, not the score associated with any specific labels. The box
   * proposal confidence score is a float number per region between [0, 1]
   * indicating how likely a box contains an "object".
   */
  score?: number;
  version?: string;
}

/**
 * A single label with score and meta data.
 */
export interface ImageUnderstandingIndexingLabel {
  /**
   * Human readable text.
   */
  canonicalText?: string;
  /**
   * KG entity id.
   */
  entityId?: string;
  /**
   * Meta data for topicality, visible labels, attribute, etc.
   */
  metaData?: ImageUnderstandingIndexingMetaData[];
  /**
   * Confidence score.
   */
  score?: number;
}

/**
 * LabelGroup is a set of labels produced by a single model, or by multiple
 * models that share the same versioning. It can be used to store results from
 * ICA, box classifier, visible labels, noun+attribute, and so on.
 */
export interface ImageUnderstandingIndexingLabelGroup {
  label?: ImageUnderstandingIndexingLabel[];
  version?: string;
}

/**
 * Meta data useful to annotation Label and Feature with extra information.
 */
export interface ImageUnderstandingIndexingMetaData {
  floatValue?: number;
  name?: string;
  stringValue?: string;
}

/**
 * This protobuffer stores bad SSL certificate information for a canonical URL,
 * and meant to be included in DocJoins and push to serving time.
 */
export interface IndexingBadSSLCertificate {
  badSslCertificate?: TrawlerSSLCertificateInfo;
  /**
   * The URL where the bad SSL certificate really comes from. Present iff it is
   * different from the source URL, i.e. a redirect target of the source URL).
   */
  urlWithBadSslCertificate?: Uint8Array;
}

function serializeIndexingBadSSLCertificate(data: any): IndexingBadSSLCertificate {
  return {
    ...data,
    badSslCertificate: data["badSslCertificate"] !== undefined ? serializeTrawlerSSLCertificateInfo(data["badSslCertificate"]) : undefined,
    urlWithBadSslCertificate: data["urlWithBadSslCertificate"] !== undefined ? encodeBase64(data["urlWithBadSslCertificate"]) : undefined,
  };
}

function deserializeIndexingBadSSLCertificate(data: any): IndexingBadSSLCertificate {
  return {
    ...data,
    badSslCertificate: data["badSslCertificate"] !== undefined ? deserializeTrawlerSSLCertificateInfo(data["badSslCertificate"]) : undefined,
    urlWithBadSslCertificate: data["urlWithBadSslCertificate"] !== undefined ? decodeBase64(data["urlWithBadSslCertificate"] as string) : undefined,
  };
}

export interface IndexingConverterLocalizedAlternateName {
  annotationSource?:  | "HTTP" | "HTML" | "SITEMAP";
  /**
   * Device match info calculated only by URL pattern.
   */
  deviceMatchInfo?:  | "UNKNOWN" | "WWW_TO_WWW" | "WWW_TO_M" | "M_TO_M" | "M_TO_WWW";
  /**
   * Fp96 of webmirror ECN as of the last time the canonical was processed.
   */
  ecnFp?: Uint8Array;
  /**
   * Populated if annotation_source is SITEMAP.
   */
  feedUrl?: string;
  language?: string;
  /**
   * Parsed language and region code from language field.
   */
  parsedLanguage?:  | "ENGLISH" | "DANISH" | "DUTCH" | "FINNISH" | "FRENCH" | "GERMAN" | "HEBREW" | "ITALIAN" | "JAPANESE" | "KOREAN" | "NORWEGIAN" | "POLISH" | "PORTUGUESE" | "RUSSIAN" | "SPANISH" | "SWEDISH" | "CHINESE" | "CZECH" | "GREEK" | "ICELANDIC" | "LATVIAN" | "LITHUANIAN" | "ROMANIAN" | "HUNGARIAN" | "ESTONIAN" | "TG_UNKNOWN_LANGUAGE" | "UNKNOWN_LANGUAGE" | "BULGARIAN" | "CROATIAN" | "SERBIAN" | "IRISH" | "GALICIAN" | "TAGALOG" | "TURKISH" | "UKRAINIAN" | "HINDI" | "MACEDONIAN" | "BENGALI" | "INDONESIAN" | "LATIN" | "MALAY" | "MALAYALAM" | "WELSH" | "NEPALI" | "TELUGU" | "ALBANIAN" | "TAMIL" | "BELARUSIAN" | "JAVANESE" | "OCCITAN" | "URDU" | "BIHARI" | "GUJARATI" | "THAI" | "ARABIC" | "CATALAN" | "ESPERANTO" | "BASQUE" | "INTERLINGUA" | "KANNADA" | "PUNJABI" | "SCOTS_GAELIC" | "SWAHILI" | "SLOVENIAN" | "MARATHI" | "MALTESE" | "VIETNAMESE" | "FRISIAN" | "SLOVAK" | "CHINESE_T" | "FAROESE" | "SUNDANESE" | "UZBEK" | "AMHARIC" | "AZERBAIJANI" | "GEORGIAN" | "TIGRINYA" | "PERSIAN" | "BOSNIAN" | "SINHALESE" | "NORWEGIAN_N" | "PORTUGUESE_P" | "PORTUGUESE_B" | "XHOSA" | "ZULU" | "GUARANI" | "SESOTHO" | "TURKMEN" | "KYRGYZ" | "BRETON" | "TWI" | "YIDDISH" | "SERBO_CROATIAN" | "SOMALI" | "UIGHUR" | "KURDISH" | "MONGOLIAN" | "ARMENIAN" | "LAOTHIAN" | "SINDHI" | "RHAETO_ROMANCE" | "AFRIKAANS" | "LUXEMBOURGISH" | "BURMESE" | "KHMER" | "TIBETAN" | "DHIVEHI" | "CHEROKEE" | "SYRIAC" | "LIMBU" | "ORIYA" | "ASSAMESE" | "CORSICAN" | "INTERLINGUE" | "KAZAKH" | "LINGALA" | "MOLDAVIAN" | "PASHTO" | "QUECHUA" | "SHONA" | "TAJIK" | "TATAR" | "TONGA" | "YORUBA" | "CREOLES_AND_PIDGINS_ENGLISH_BASED" | "CREOLES_AND_PIDGINS_FRENCH_BASED" | "CREOLES_AND_PIDGINS_PORTUGUESE_BASED" | "CREOLES_AND_PIDGINS_OTHER" | "MAORI" | "WOLOF" | "ABKHAZIAN" | "AFAR" | "AYMARA" | "BASHKIR" | "BISLAMA" | "DZONGKHA" | "FIJIAN" | "GREENLANDIC" | "HAUSA" | "HAITIAN_CREOLE" | "INUPIAK" | "INUKTITUT" | "KASHMIRI" | "KINYARWANDA" | "MALAGASY" | "NAURU" | "OROMO" | "RUNDI" | "SAMOAN" | "SANGO" | "SANSKRIT" | "SISWANT" | "TSONGA" | "TSWANA" | "VOLAPUK" | "ZHUANG" | "KHASI" | "SCOTS" | "GANDA" | "MANX" | "MONTENEGRIN" | "AKAN" | "IGBO" | "MAURITIAN_CREOLE" | "HAWAIIAN" | "CEBUANO" | "EWE" | "GA" | "HMONG" | "KRIO" | "LOZI" | "LUBA_LULUA" | "LUO_KENYA_AND_TANZANIA" | "NEWARI" | "NYANJA" | "OSSETIAN" | "PAMPANGA" | "PEDI" | "RAJASTHANI" | "SESELWA_CREOLE_FRENCH" | "TUMBUKA" | "VENDA" | "WARAY_PHILIPPINES" | "NUM_LANGUAGES";
  parsedRegion?: number;
  url?: Uint8Array;
  /**
   * see webutil/urlencoding
   */
  urlEncoding?: number;
}

function serializeIndexingConverterLocalizedAlternateName(data: any): IndexingConverterLocalizedAlternateName {
  return {
    ...data,
    ecnFp: data["ecnFp"] !== undefined ? encodeBase64(data["ecnFp"]) : undefined,
    url: data["url"] !== undefined ? encodeBase64(data["url"]) : undefined,
  };
}

function deserializeIndexingConverterLocalizedAlternateName(data: any): IndexingConverterLocalizedAlternateName {
  return {
    ...data,
    ecnFp: data["ecnFp"] !== undefined ? decodeBase64(data["ecnFp"] as string) : undefined,
    url: data["url"] !== undefined ? decodeBase64(data["url"] as string) : undefined,
  };
}

/**
 * The proto to be stored in raw_redirect_info column of document table.
 */
export interface IndexingConverterRawRedirectInfo {
  /**
   * Final redirect target found from rendering. It is the same as the last
   * element of raw_redirect_chain_from_rendering. It is used as an input source
   * for the indexable fragment detection pipeline and also downstream phases.
   */
  rawFinalTargetFromRendering?: string;
  /**
   * This is with-fragment version of redirect_with_contents. This field is
   * populated only if there was a fragment. This field is used by
   * indexing::mobile::GetRedirectTarget() defined in
   * indexing/mobile/internal/smartphone-util.cc, which extracts the redirect
   * target for smartphone optimized pages. The extracted target in turn is
   * served in search results for smartphone users. We need with-fragment
   * version because with-fragment url can return different content than
   * fragment-stripped url. For example, http://www.example.com/m#article=11 and
   * http://www.example.com/m can return different content. These cases are most
   * typical for Ajaxy sites. This fragment does not have to be indexable.
   */
  rawFinalTargetFromTrawler?: string;
  /**
   * Redirect chain generated from redirect events in rendering. At the
   * beginning of it, there could be some redirects from trawler (i.e. could be
   * partial or entire trawler redirect chain), other redirects have their
   * RedirectParams::is_redirect_from_rendering fields set to true. Redirects
   * here have no RedirectChain::Hop::raw_target fields populated, and targets
   * stored in RedirectChain::Hop::target fields are likely cleaned while
   * keeping fragments (also sometimes they could be uncleaned ones because of
   * cleaning failures), fragments could be indexable or non-indexable.
   */
  rawRedirectChainFromRendering?: IndexingConverterRedirectChain;
  /**
   * This is used to describe how many redirect hops from Webkit were kept in
   * the raw_redirect_chain_from_rendering. If it is -1, it means it kept all
   * the hops from Webkit in redirect chain.
   */
  renderingRedirectLimit?: number;
}

/**
 * Redirect_chain is present for redirects, and absent for the final target. It
 * contains the chain from the current hop's target to the final target.
 */
export interface IndexingConverterRedirectChain {
  hop?: IndexingConverterRedirectChainHop[];
}

/**
 * NOLINT
 */
export interface IndexingConverterRedirectChainHop {
  params?: IndexingConverterRedirectParams;
  /**
   * Redirect target with fragment. This field is populated only if there was a
   * fragment.
   */
  rawTarget?: string;
  /**
   * Redirect target URL and params of the current hop in the redirect chain.
   */
  target?: string;
}

/**
 * If we detect any server or content based redirect, we will store the
 * characteristics in this message.
 */
export interface IndexingConverterRedirectParams {
  /**
   * The time difference between page loading and redirect occurrence. When
   * missing, it means the redirect happens immediately (i.e. delay = 0). In
   * seconds.
   */
  delay?: number;
  /**
   * Populated for SINGLE_FRAME and SINGLE_IFRAME redirects only and indicates
   * that the target url requested not to be framed, by virtue of using the
   * "X-Frame-Options" HTTP header.
   */
  frameTargetDeniesFraming?: boolean;
  /**
   * Indicates corresponding redirect is a download. This field is only set
   * when rendering redirect chain is used. This field represents the value of
   * corresponding "RedirectEvent.target_content_downloaded" field.
   */
  isDownload?: boolean;
  /**
   * Indicates corresponding redirect is from rendering if set to true.
   */
  isRenderingRedirect?: boolean;
  /**
   * If set, it means that the redirect of type META was detected by Trawler
   * (as opposed to the content processor.) Only makes sense when type is META.
   */
  metaRedirectFromTrawler?: boolean;
  type?:  | "PERMANENT" | "TEMPORARY" | "WIKIPEDIA_DEPRECATED" | "JAVASCRIPT" | "META" | "SINGLE_FRAME" | "CRYPTO301" | "LINK_REL_CANONICAL" | "SINGLE_IFRAME" | "WEBKIT" | "META_FRAGMENT" | "SINGLE_CHOICE_300" | "SINGLE_PAGE" | "DATAFILE" | "HTTP_REFRESH" | "HTTP_POST" | "HTML5_HISTORY_API" | "AJAX_CRAWLING";
}

/**
 * Contains information about 3 versions of the content of a document: 1.
 * Original: the crawled content (possibly patched in ConversionFilters). 2.
 * Processed: the final version of the content indexed in Web search. 3.
 * Intermediate (no longer generated): intermediate version between the original
 * and the processed content. All 3 versions of the content consist of HTTP
 * headers (in unknown encoding) concatenated with the document body (in
 * interchange valid UTF-8 encoding).
 */
export interface IndexingConverterRichContentData {
  range?: IndexingConverterRichContentDataRange[];
}

function serializeIndexingConverterRichContentData(data: any): IndexingConverterRichContentData {
  return {
    ...data,
    range: data["range"] !== undefined ? data["range"].map((item: any) => (serializeIndexingConverterRichContentDataRange(item))) : undefined,
  };
}

function deserializeIndexingConverterRichContentData(data: any): IndexingConverterRichContentData {
  return {
    ...data,
    range: data["range"] !== undefined ? data["range"].map((item: any) => (deserializeIndexingConverterRichContentDataRange(item))) : undefined,
  };
}

/**
 * Stores an ordered list of ranges of content from the original, processed,
 * and intermediate content, such that: 1. The original content can be
 * reconstructed from the ranges of type ORIGINAL_AND_PROCESSED, ORIGINAL_ONLY,
 * and ORIGINAL_AND_INTERMEDIATE. 2. The processed content can be reconstructed
 * from the ranges of type ORIGINAL_AND_PROCESSED and PROCESSED_ONLY. 3. The
 * intermediate content (if present) can be reconstructed from the ranges of
 * type ORIGINAL_AND_INTERMEDIATE and INTERMEDIATE_ONLY.
 */
export interface IndexingConverterRichContentDataRange {
  rangeType?:  | "ORIGINAL_AND_PROCESSED" | "ORIGINAL_ONLY" | "PROCESSED_ONLY" | "ORIGINAL_AND_INTERMEDIATE" | "INTERMEDIATE_ONLY";
  /**
   * Range size when uncompressed, in bytes.
   */
  size?: number;
  /**
   * The source of this range of content. Present iff 'type' is PROCESSED_ONLY
   * or INTERMEDIATE_ONLY. Note: 'source_type' is not present for
   * ORIGINAL_AND_PROCESSED, ORIGINAL_ONLY, and ORIGINAL_AND_INTERMEDIATE
   * because for those range types the source of their content is the original
   * crawled content.
   */
  sourceType?:  | "SEPARATOR" | "FRAME" | "DOMTRACKER_JAVASCRIPT" | "FLASH" | "IFRAME" | "WEBKIT_PHRASES_DEPRECATED" | "WEBKIT_CONTENT_REPLACEMENT";
  /**
   * The source URL of this range of content. Present iff 'source_type' is
   * present and 'source_type' is FRAME or FLASH or IFRAME.
   */
  sourceUrl?: string;
  /**
   * The content of the range, compressed with 'text_compression_method'.
   * Present iff 'type' is ORIGINAL_ONLY or ORIGINAL_AND_INTERMEDIATE or
   * INTERMEDIATE_ONLY. Useful to reconstruct the original content or the
   * intermediate content. Note: 'text' is not present for
   * ORIGINAL_AND_PROCESSED and PROCESSED_ONLY because the processed content is
   * already stored separately (in the contents column, and in
   * CompositeDoc.doc.Content.Representation).
   */
  text?: Uint8Array;
  /**
   * Method used to compress the 'text' field. May be present only when the
   * 'text' is present.
   */
  textCompressionMethod?:  | "TEXT_COMPRESSION_NONE" | "TEXT_COMPRESSION_BMDIFF";
}

function serializeIndexingConverterRichContentDataRange(data: any): IndexingConverterRichContentDataRange {
  return {
    ...data,
    text: data["text"] !== undefined ? encodeBase64(data["text"]) : undefined,
  };
}

function deserializeIndexingConverterRichContentDataRange(data: any): IndexingConverterRichContentDataRange {
  return {
    ...data,
    text: data["text"] !== undefined ? decodeBase64(data["text"] as string) : undefined,
  };
}

/**
 * Robots Info encapsulates all robots.txt or related information that we know
 * about the Document collected from multiple sources such as HTTP headers, meta
 * robots tags etc.
 */
export interface IndexingConverterRobotsInfo {
  /**
   * time in unix time format after which this content should not be shown in
   * the results. This in inferred from the X-Robots-Tag HTTP header with
   * unavailable_after: Do not use this field directly. There is a column called
   * content_expiration in Alexandria that includes this and other signals.
   */
  contentExpiry?: number;
  convertToRobotedReason?:  | "BLOCKING_HOST" | "EMPTY_PAGE" | "MOBILE_IP_RESTRICTED" | "CLOAKING_4XX" | "UNSUPPORTED_PROTOCOL";
  disallowedReason?: number;
  /**
   * IMPORTANT: if you add a new field here, update the MergeRobotsInfo()
   * function to merge the new field.
   */
  indexifembeddedReason?: number;
  /**
   * Max image preview restriction applied to this data. A value of
   * THUMBNAIL_UNSPECIFIED can be treated as though there is no restriction.
   */
  maxImagePreview?:  | "THUMBNAIL_UNSPECIFIED" | "NONE" | "STANDARD" | "LARGE";
  /**
   * Max snippet preview restriction applied to this data. If this field is
   * zero, it indicates that no snippet data can be displayed, therefore this
   * field should be checked using has_max_snippet_length to determine if it was
   * set.
   */
  maxSnippetLength?: bigint;
  noarchiveReason?: number;
  nofollowReason?: number;
  noimageframeoverlayReason?: number;
  noimageindexReason?: number;
  /**
   * Bit map of RobotedReasons values. When set to a non-zero value, the
   * document should not be indexed or archived etc. based on the name of the
   * tag.
   */
  noindexReason?: number;
  nopreviewReason?: number;
  nosnippetReason?: number;
  notranslateReason?: number;
}

function serializeIndexingConverterRobotsInfo(data: any): IndexingConverterRobotsInfo {
  return {
    ...data,
    maxSnippetLength: data["maxSnippetLength"] !== undefined ? String(data["maxSnippetLength"]) : undefined,
  };
}

function deserializeIndexingConverterRobotsInfo(data: any): IndexingConverterRobotsInfo {
  return {
    ...data,
    maxSnippetLength: data["maxSnippetLength"] !== undefined ? BigInt(data["maxSnippetLength"]) : undefined,
  };
}

/**
 * Used for storing fingerprints, along with meta-data that expresses how the
 * fingerprint was computed. The metadata can be anything that fits in an
 * uint64.
 */
export interface IndexingConverterShingleFingerprint {
  metadata?: bigint;
  /**
   * Repeated to allow for fingerprints larger than 64-bits.
   */
  value?: bigint[];
}

function serializeIndexingConverterShingleFingerprint(data: any): IndexingConverterShingleFingerprint {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? String(data["metadata"]) : undefined,
    value: data["value"] !== undefined ? data["value"].map((item: any) => (String(item))) : undefined,
  };
}

function deserializeIndexingConverterShingleFingerprint(data: any): IndexingConverterShingleFingerprint {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? BigInt(data["metadata"]) : undefined,
    value: data["value"] !== undefined ? data["value"].map((item: any) => (BigInt(item))) : undefined,
  };
}

export interface IndexingCrawlerIdServingDocumentIdentifier {
  /**
   * Only for double indexing experiments. This field is set for duplicated
   * documents so that docjoin users will not see duplicated docs.
   */
  doubleIndexingExperimentId?: string;
  /**
   * Only for Experimental clusters, not relevant for production serving data:
   * Index-Dups can run experiments in Quality Clusters where different versions
   * of the same document (e.g. with different signals) are serving in parallel.
   * They are uniquely identified by the dup-experiment-IDs. This is for
   * experimental clusters only. In prod-versions the member will not be set.
   */
  dupExperimentId?: string;
  /**
   * The primary identifier of a production document is the document key, which
   * is the same as the row-key in Alexandria, and represents a URL and its
   * crawling context. The document key is the unique identifier for each
   * document, but multiple document keys can cover the same URL (e.g. crawled
   * with different device types). In your production code, please always assume
   * that the document key is the only way to uniquely identify a document. Link
   * for more background information: http://go/url The document key is
   * populated for all docs in indexing since 2014-03. ## Recommended way of
   * reading: const string& doc_key = cdoc.doc().id().key(); ##
   * CHECK(!doc_key.empty()); Note: For older DocJoins (e.g. historical
   * DocJoins), the field is not populated. In those scenarios it is recommended
   * to use the function 'GetDocumentKeyFromCompositeDoc' in
   * '//indexing/crawler_id/utils/compositedoc/compositedoc_util.h' instead.
   */
  key?: string;
}

/**
 * Following signals identify spike of spammy anchor phrases. Anchors created
 * during the spike are tagged with LINK_SPAM_PHRASE_SPIKE.
 */
export interface IndexingDocjoinerAnchorPhraseSpamInfo {
  /**
   * How many spam phrases found in the anchors among unique domains.
   */
  phraseAnchorSpamCount?: number;
  /**
   * Over how many days 80% of these phrases were discovered.
   */
  phraseAnchorSpamDays?: number;
  /**
   * Total number of demoted anchors.
   */
  phraseAnchorSpamDemoted?: number;
  /**
   * Time when anchor spam spike ended with padding.
   */
  phraseAnchorSpamEnd?: number;
  /**
   * Spam phrases fraction of all anchors of the document.
   */
  phraseAnchorSpamFraq?: number;
  /**
   * Combined penalty for anchor demotion.
   */
  phraseAnchorSpamPenalty?: number;
  /**
   * Total number of observed anchors.
   */
  phraseAnchorSpamProcessed?: number;
  /**
   * Average daily rate of spam anchor discovery.
   */
  phraseAnchorSpamRate?: number;
  /**
   * Time when anchor spam spike started with padding.
   */
  phraseAnchorSpamStart?: number;
}

/**
 * Following structure summarizes output of AnchorSpamPenalizer. Spammy anchors
 * are tagged with LINK_SPAM_PHRASE_PENALIZER and demoted to SPAM locality in
 * anchor-localizer.cc
 */
export interface IndexingDocjoinerAnchorSpamInfo {
  /**
   * End date of the last anchor of the document.
   */
  anchorEnd?: number;
  /**
   * Ratio of spam demoted period to all anchor period.
   */
  anchorFraq?: number;
  /**
   * Start date of the first anchor of the document.
   */
  anchorStart?: number;
  /**
   * Following field record details of anchor demotion in action. How many
   * anchors were demoted.
   */
  demoted?: number;
  /**
   * Demoted all anchors in the period or only anchors classified as spam.
   */
  demotedAll?: boolean;
  /**
   * End date of the demotion period.
   */
  demotedEnd?: number;
  /**
   * Start date of the demotion period.
   */
  demotedStart?: number;
  /**
   * Following fields record signals used in anchor spam classification. How
   * many spam phrases found in the anchors among unique domains.
   */
  phraseCount?: number;
  /**
   * Over how many days 80% of these phrases were discovered.
   */
  phraseDays?: number;
  /**
   * Spam phrases fraction of all anchors of the document.
   */
  phraseFraq?: number;
  /**
   * Average daily rate of spam anchor discovery.
   */
  phraseRate?: number;
  /**
   * Total number of processed anchors.
   */
  processed?: number;
  /**
   * True if anchors were sampled during observation phrase.
   */
  sampled?: boolean;
  /**
   * Detailed information about trusted sources and match computation.
   * Populated only when --anchorspam_penalizer_debug=true.
   */
  sources?: IndexingDocjoinerAnchorTrustedInfo[];
  /**
   * Additional debug information about computation of spam probability.
   */
  spamDebugInfo?: string;
  /**
   * Combined penalty for anchor demotion.
   */
  spamPenalty?: number;
  /**
   * Predicted probability of spam.
   */
  spamProbability?: number;
  /**
   * Number of trusted anchors used in computation of spam probability.
   */
  trustedDemoted?: number;
  /**
   * Examples of trusted sources.
   */
  trustedExamples?: string;
  /**
   * Number of trusted anchors with anchor text matching spam terms.
   */
  trustedMatching?: number;
  /**
   * Following fields record details about trusted anchors True if is this URL
   * is on trusted source.
   */
  trustedTarget?: boolean;
  /**
   * Total number of trusted sources for this URL.
   */
  trustedTotal?: number;
}

/**
 * Statistics of the anchors in a docjoin. Next available tag ID: 63.
 */
export interface IndexingDocjoinerAnchorStatistics {
  anchorCount?: number;
  /**
   * The number of unique anchor phrases. Capped by the constant
   * kMaxAnchorPhraseCountInStats (=5000) defined in
   * indexing/docjoiner/anchors/anchor-manager.cc.
   */
  anchorPhraseCount?: number;
  /**
   * This structure contains signals and penalties of AnchorSpamPenalizer. It
   * replaces phrase_anchor_spam_info above, that is deprecated.
   */
  anchorSpamInfo?: IndexingDocjoinerAnchorSpamInfo;
  /**
   * The number of anchors for which some ImprovAnchors phrases have been
   * removed due to duplication within source org.
   */
  anchorsWithDedupedImprovanchors?: number;
  /**
   * Whether this doc is penalized by BadBackLinks, in which case we should not
   * use improvanchor score in mustang ascorer.
   */
  badbacklinksPenalized?: boolean;
  baseAnchorCount?: number;
  baseOffdomainAnchorCount?: number;
  droppedHomepageAnchorCount?: number;
  droppedLocalAnchorCount?: number;
  droppedNonLocalAnchorCount?: number;
  /**
   * Sum of anchors_dropped in the repeated group RedundantAnchorInfo, but can
   * go higher if the latter reaches the cap of kMaxRecordsToKeep.
   * (indexing/docjoiner/anchors/anchor-loader.cc), currently 10,000
   */
  droppedRedundantAnchorCount?: number;
  fakeAnchorCount?: number;
  forwardedAnchorCount?: number;
  forwardedOffdomainAnchorCount?: number;
  /**
   * Metric of number of changed global anchors computed as,
   * size(union(previous, new) - intersection(previous, new)).
   */
  globalAnchorDelta?: number;
  linkBeforeSitechangeTaggedAnchors?: number;
  localAnchorCount?: number;
  lowCorpusAnchorCount?: number;
  lowCorpusOffdomainAnchorCount?: number;
  mediumCorpusAnchorCount?: number;
  mediumCorpusOffdomainAnchorCount?: number;
  /**
   * Minimum local outdegree of all anchor sources that are domain home pages
   * as well as on the same domain as the current target URL.
   */
  minDomainHomePageLocalOutdegree?: number;
  /**
   * Minimum local outdegree of all anchor sources that are host home pages as
   * well as on the same host as the current target URL.
   */
  minHostHomePageLocalOutdegree?: number;
  nonLocalAnchorCount?: number;
  offdomainAnchorCount?: number;
  ondomainAnchorCount?: number;
  onsiteAnchorCount?: number;
  /**
   * Set in SignalPenalizer::FillInAnchorStatistics.
   */
  pageFromExpiredTaggedAnchors?: number;
  pageMismatchTaggedAnchors?: number;
  /**
   * Doc is protected by goodness of early anchors.
   */
  penguinEarlyAnchorProtected?: boolean;
  /**
   * BEGIN: Penguin related fields. Timestamp when penguin scores were last
   * updated. Measured in days since Jan. 1st 1995.
   */
  penguinLastUpdate?: number;
  /**
   * Page-level penguin penalty (0 = good, 1 = bad).
   */
  penguinPenalty?: number;
  /**
   * Doc not scored because it has too many anchor sources. END: Penguin
   * related fields.
   */
  penguinTooManySources?: boolean;
  perdupstats?: IndexingDocjoinerAnchorStatisticsPerDupStats[];
  /**
   * Following signals identify spike of spammy anchor phrases. Anchors created
   * during the spike are tagged with LINK_SPAM_PHRASE_SPIKE.
   */
  phraseAnchorSpamInfo?: IndexingDocjoinerAnchorPhraseSpamInfo;
  /**
   * Total anchor dropped due to exceed per domain phrase cap. Equals to sum of
   * anchors_dropped in the repeated group RedundantAnchorInfoForPhraseCap, but
   * can go higher if the latter reaches the cap of
   * kMaxDomainsToKeepForPhraseCap (indexing/docjoiner/anchors/anchor-loader.h),
   * currently 1000.
   */
  redundantAnchorForPhraseCapCount?: number;
  redundantanchorinfo?: IndexingDocjoinerAnchorStatisticsRedundantAnchorInfo[];
  redundantanchorinfoforphrasecap?: IndexingDocjoinerAnchorStatisticsRedundantAnchorInfoForPhraseCap[];
  /**
   * The total number of anchors being scanned from storage.
   */
  scannedAnchorCount?: number;
  /**
   * A count of the number of times anchor accumulation has been skipped for
   * this document. Note: Only used when canonical.
   */
  skippedAccumulate?: number;
  /**
   * Reason to skip accumulate, when skipped, or Reason for reprocessing when
   * not skipped.
   */
  skippedOrReusedReason?: string;
  /**
   * The log base 10 odds that this set of anchors exhibits spammy behavior.
   * Computed in the AnchorLocalizer.
   */
  spamLog10Odds?: number;
  /**
   * Walltime of when anchors were accumulated last.
   */
  timestamp?: number;
  topPrOffdomainAnchorCount?: number;
  topPrOndomainAnchorCount?: number;
  /**
   * According to anchor quality bucket, anchor with pagrank > 51000 is the
   * best anchor. anchors with pagerank < 47000 are all same.
   */
  topPrOnsiteAnchorCount?: number;
  /**
   * The following should be equal to the size of the following repeated group,
   * except that it can go higher than 10,000.
   */
  totalDomainPhrasePairsAboveLimit?: number;
  /**
   * Number of domain/phrase pairs in total -- i.e. how many anchors we would
   * have if the domain/phrase cutoff was set to 1 instead of 200. This is
   * "approx" for large anchor clusters because there can be double counting
   * when the LRU cache forgets about rare domain/phrase pairs.
   */
  totalDomainPhrasePairsSeenApprox?: number;
  /**
   * Number of domains above per domain phrase cap. We see too many phrases in
   * the domains.
   */
  totalDomainsAbovePhraseCap?: number;
  /**
   * Number of domains seen in total.
   */
  totalDomainsSeen?: number;
}

function serializeIndexingDocjoinerAnchorStatistics(data: any): IndexingDocjoinerAnchorStatistics {
  return {
    ...data,
    redundantanchorinfo: data["redundantanchorinfo"] !== undefined ? data["redundantanchorinfo"].map((item: any) => (serializeIndexingDocjoinerAnchorStatisticsRedundantAnchorInfo(item))) : undefined,
  };
}

function deserializeIndexingDocjoinerAnchorStatistics(data: any): IndexingDocjoinerAnchorStatistics {
  return {
    ...data,
    redundantanchorinfo: data["redundantanchorinfo"] !== undefined ? data["redundantanchorinfo"].map((item: any) => (deserializeIndexingDocjoinerAnchorStatisticsRedundantAnchorInfo(item))) : undefined,
  };
}

/**
 * -------------------------------------------------------------------------
 * The total number of anchors collected per dupforwarding (including the
 * canonical itself). Includes additional data about redundant and offdomain
 * counts and the last timestamp it was collected from.
 */
export interface IndexingDocjoinerAnchorStatisticsPerDupStats {
  /**
   * Count of anchors kept from forwarding.
   */
  anchorCount?: number;
  /**
   * This is EcnCollectType in anchor-ecn-matcher.h for the latest ECN of this
   * dup: - kCollectNormal = 0, // Normal collection. - kCollectUnforwarded = 1,
   * // Forwarding leader docid match only. - kCollectWhitelisted = 2, //
   * Collected anchors matching whitelist. - kCollectNone = 4 // Skipped ECN
   * anchor cluster.
   */
  collectType?: number;
  /**
   * If missing, the same as the canonical.
   */
  dupUrl?: string;
  /**
   * Count of offdomain anchors.
   */
  offdomainAnchorCount?: number;
  /**
   * Count of redundant anchors.
   */
  redundantAnchorCount?: number;
  /**
   * The number of anchors being scanned from storage per dupforwarding.
   */
  scannedAnchorCount?: number;
  /**
   * Walltime when this was scanned last.
   */
  timestamp?: number;
}

/**
 * -------------------------------------------------------------------------
 * The total number of redundant anchors dropped per (domain, text). If we
 * receive a large number of anchors from a particular domain, then we'll throw
 * out all but 200 of them from that domain. The data is sorted by the (domain,
 * text) pairs. This is capped at 10,000 entries (if less, it will have the same
 * number of elements as the above_limit count).
 */
export interface IndexingDocjoinerAnchorStatisticsRedundantAnchorInfo {
  anchorsDropped?: bigint;
  domain?: string;
  text?: string;
}

function serializeIndexingDocjoinerAnchorStatisticsRedundantAnchorInfo(data: any): IndexingDocjoinerAnchorStatisticsRedundantAnchorInfo {
  return {
    ...data,
    anchorsDropped: data["anchorsDropped"] !== undefined ? String(data["anchorsDropped"]) : undefined,
  };
}

function deserializeIndexingDocjoinerAnchorStatisticsRedundantAnchorInfo(data: any): IndexingDocjoinerAnchorStatisticsRedundantAnchorInfo {
  return {
    ...data,
    anchorsDropped: data["anchorsDropped"] !== undefined ? BigInt(data["anchorsDropped"]) : undefined,
  };
}

export interface IndexingDocjoinerAnchorStatisticsRedundantAnchorInfoForPhraseCap {
  anchorsDropped?: number;
  domain?: string;
}

/**
 * This message summarized anchors of one trusted site.
 */
export interface IndexingDocjoinerAnchorTrustedInfo {
  /**
   * Difference in KL-divergence from spam and non-spam anchors. Value >0
   * indicate that anchor text from this trusted source is similar to anchors
   * classified as spam which means that spammy anchors are legitimate.
   */
  matchedScore?: number;
  /**
   * Detailed debug information about computation of trusted anchors match.
   * Populated only when --anchorspam_penalizer_debug=true
   */
  matchedScoreInfo?: string[];
  /**
   * Count of anchors classified as spam using anchor text.
   */
  phrasesScore?: number;
  /**
   * Site name from anchor.source().site().
   */
  site?: string;
  /**
   * Tokenized text of all anchors from the site.
   */
  text?: string[];
  /**
   * Fraction of pages with newsy anchors on the site, >0 for trusted sites.
   */
  trustedScore?: number;
}

/**
 * Holds extra info except annotations and raw cdoc for buildint the final
 * cdoc.
 */
export interface IndexingDocjoinerCDocBuildInfo {
  extraMessage?: Proto2BridgeMessageSet;
}

/**
 * DataVersion tracks the version of data in CompositeDoc. The notion of "data"
 * here is loose and people can define the name of their own. For example, a
 * signal generated by Index Signals or an annotation generated by Goldmine (and
 * other components) can all be considered as data here. Each field in this
 * proto represents the human readable version string and the timestamp of one
 * particular data. We choose to explicitly list out all of the data here for
 * better understanding about which data are tracked. NOTE that
 * human_readable_version is not intended for comparison, use timestamp_micros.
 * In addition, we have an annotation about the field paths of each data. With
 * proto reflection (using google3/net/proto2/util/public/field_path.h),
 * downstream systems can take advantage of this annotation to automatically
 * handle newly introduced data without modifying their code. Please also see
 * the comment of FieldProjector above. There are also some fields in DataInfo
 * that annotate who generates the data, the Index Signals or Goldmine annotator
 * name.
 */
export interface IndexingDocjoinerDataVersion {
  acceleratedShoppingSignal?: IndexingDocjoinerDataVersionVersionInfo;
  chromeCounts?: IndexingDocjoinerDataVersionVersionInfo;
  /**
   * 
   * LINT.ThenChange(//depot/google3/indexing/ames/spanner/schema/web-version.proto)
   */
  creator?: IndexingDocjoinerDataVersionVersionInfo;
  instantNavboost?: IndexingDocjoinerDataVersionVersionInfo;
  localyp?: IndexingDocjoinerDataVersionVersionInfo;
  localypVersion?: string;
  modernFormatContent?: IndexingDocjoinerDataVersionVersionInfo;
  modernFormatContentVersion?: string;
  /**
   * LINT.IfChange
   */
  navboost?: IndexingDocjoinerDataVersionVersionInfo;
  /**
   * DEPRECATED
   */
  navboostVersion?: string;
  rankembed?: IndexingDocjoinerDataVersionVersionInfo;
  universalFacts?: IndexingDocjoinerDataVersionVersionInfo;
  videoScoringSignal?: IndexingDocjoinerDataVersionVersionInfo;
  videoScoringSignalVersion?: string;
  volt?: IndexingDocjoinerDataVersionVersionInfo;
  voltVersion?: string;
}

function serializeIndexingDocjoinerDataVersion(data: any): IndexingDocjoinerDataVersion {
  return {
    ...data,
    acceleratedShoppingSignal: data["acceleratedShoppingSignal"] !== undefined ? serializeIndexingDocjoinerDataVersionVersionInfo(data["acceleratedShoppingSignal"]) : undefined,
    chromeCounts: data["chromeCounts"] !== undefined ? serializeIndexingDocjoinerDataVersionVersionInfo(data["chromeCounts"]) : undefined,
    creator: data["creator"] !== undefined ? serializeIndexingDocjoinerDataVersionVersionInfo(data["creator"]) : undefined,
    instantNavboost: data["instantNavboost"] !== undefined ? serializeIndexingDocjoinerDataVersionVersionInfo(data["instantNavboost"]) : undefined,
    localyp: data["localyp"] !== undefined ? serializeIndexingDocjoinerDataVersionVersionInfo(data["localyp"]) : undefined,
    modernFormatContent: data["modernFormatContent"] !== undefined ? serializeIndexingDocjoinerDataVersionVersionInfo(data["modernFormatContent"]) : undefined,
    navboost: data["navboost"] !== undefined ? serializeIndexingDocjoinerDataVersionVersionInfo(data["navboost"]) : undefined,
    rankembed: data["rankembed"] !== undefined ? serializeIndexingDocjoinerDataVersionVersionInfo(data["rankembed"]) : undefined,
    universalFacts: data["universalFacts"] !== undefined ? serializeIndexingDocjoinerDataVersionVersionInfo(data["universalFacts"]) : undefined,
    videoScoringSignal: data["videoScoringSignal"] !== undefined ? serializeIndexingDocjoinerDataVersionVersionInfo(data["videoScoringSignal"]) : undefined,
    volt: data["volt"] !== undefined ? serializeIndexingDocjoinerDataVersionVersionInfo(data["volt"]) : undefined,
  };
}

function deserializeIndexingDocjoinerDataVersion(data: any): IndexingDocjoinerDataVersion {
  return {
    ...data,
    acceleratedShoppingSignal: data["acceleratedShoppingSignal"] !== undefined ? deserializeIndexingDocjoinerDataVersionVersionInfo(data["acceleratedShoppingSignal"]) : undefined,
    chromeCounts: data["chromeCounts"] !== undefined ? deserializeIndexingDocjoinerDataVersionVersionInfo(data["chromeCounts"]) : undefined,
    creator: data["creator"] !== undefined ? deserializeIndexingDocjoinerDataVersionVersionInfo(data["creator"]) : undefined,
    instantNavboost: data["instantNavboost"] !== undefined ? deserializeIndexingDocjoinerDataVersionVersionInfo(data["instantNavboost"]) : undefined,
    localyp: data["localyp"] !== undefined ? deserializeIndexingDocjoinerDataVersionVersionInfo(data["localyp"]) : undefined,
    modernFormatContent: data["modernFormatContent"] !== undefined ? deserializeIndexingDocjoinerDataVersionVersionInfo(data["modernFormatContent"]) : undefined,
    navboost: data["navboost"] !== undefined ? deserializeIndexingDocjoinerDataVersionVersionInfo(data["navboost"]) : undefined,
    rankembed: data["rankembed"] !== undefined ? deserializeIndexingDocjoinerDataVersionVersionInfo(data["rankembed"]) : undefined,
    universalFacts: data["universalFacts"] !== undefined ? deserializeIndexingDocjoinerDataVersionVersionInfo(data["universalFacts"]) : undefined,
    videoScoringSignal: data["videoScoringSignal"] !== undefined ? deserializeIndexingDocjoinerDataVersionVersionInfo(data["videoScoringSignal"]) : undefined,
    volt: data["volt"] !== undefined ? deserializeIndexingDocjoinerDataVersionVersionInfo(data["volt"]) : undefined,
  };
}

export interface IndexingDocjoinerDataVersionVersionInfo {
  humanReadableVersion?: string;
  timestampMicros?: bigint;
}

function serializeIndexingDocjoinerDataVersionVersionInfo(data: any): IndexingDocjoinerDataVersionVersionInfo {
  return {
    ...data,
    timestampMicros: data["timestampMicros"] !== undefined ? String(data["timestampMicros"]) : undefined,
  };
}

function deserializeIndexingDocjoinerDataVersionVersionInfo(data: any): IndexingDocjoinerDataVersionVersionInfo {
  return {
    ...data,
    timestampMicros: data["timestampMicros"] !== undefined ? BigInt(data["timestampMicros"]) : undefined,
  };
}

/**
 * The serving cluster id metadata. Why we cluster the documents. The default
 * value is UNKNOWN. Serving-Side Clustering is used for pages which represent
 * the same content but are not identical (e.g. translated pages, or paginated
 * content). Those documents are not dup-clustered in Alexandria so that all
 * documents (and their tokens) are available to search queries. However, those
 * documents are assigned the same Serving-Time-Cluster-ID (on the same
 * reasontype), which during serving guarantees that only one of them is shown
 * to the user.
 */
export interface IndexingDocjoinerServingTimeClusterId {
  /**
   * The unique id to distinguish members in cluster. It could be generated in
   * different ways according to reason, e.g. LINK_REL_NEXT_PREVIOUS: it is the
   * fingerprint of the URL of index 0; PAGE_PARAMETER_INFO: it is the
   * fingerprint of pagination pattern (pagination_pattern_fp field in
   * PageParamInfo message).
   */
  clusterId?: bigint;
  /**
   * The member index of this document in cluster. Starts from "0". Note that
   * indices of pages in a cluster may not be consistent with each other,
   * because we may update them at different points in time. Currently only used
   * for debugging.
   */
  indexForDebugging?: number;
  /**
   * The reason why this document is clustered into this cluster.
   */
  reason?:  | "UNKNOWN" | "LINK_REL_NEXT_PREVIOUS" | "PAGE_PARAMETER_INFO" | "DEPRECATED_DO_NOT_USE_LANGUAGE_REGION_VARIATION" | "SITE_DUP" | "FLIPPED_CANONICAL" | "MOBILE_REDIRECTION_DUP" | "BROKEN_REL_CANONICAL" | "ROBOTED_SAME_HOST" | "DEPRECATED_DO_NOT_USE_SAME_PRE_RENDER_CHECKSUM";
}

function serializeIndexingDocjoinerServingTimeClusterId(data: any): IndexingDocjoinerServingTimeClusterId {
  return {
    ...data,
    clusterId: data["clusterId"] !== undefined ? String(data["clusterId"]) : undefined,
  };
}

function deserializeIndexingDocjoinerServingTimeClusterId(data: any): IndexingDocjoinerServingTimeClusterId {
  return {
    ...data,
    clusterId: data["clusterId"] !== undefined ? BigInt(data["clusterId"]) : undefined,
  };
}

/**
 * This message contains a set of cluster ids used to de-dup at serving time. A
 * document could be clustered into different clusters according to different
 * properties.
 */
export interface IndexingDocjoinerServingTimeClusterIds {
  /**
   * The exact cluster metadata for each individual cluster if any.
   */
  clusterId?: IndexingDocjoinerServingTimeClusterId[];
}

function serializeIndexingDocjoinerServingTimeClusterIds(data: any): IndexingDocjoinerServingTimeClusterIds {
  return {
    ...data,
    clusterId: data["clusterId"] !== undefined ? data["clusterId"].map((item: any) => (serializeIndexingDocjoinerServingTimeClusterId(item))) : undefined,
  };
}

function deserializeIndexingDocjoinerServingTimeClusterIds(data: any): IndexingDocjoinerServingTimeClusterIds {
  return {
    ...data,
    clusterId: data["clusterId"] !== undefined ? data["clusterId"].map((item: any) => (deserializeIndexingDocjoinerServingTimeClusterId(item))) : undefined,
  };
}

export interface IndexingDupsComputedLocalizedAlternateNamesLocaleEntry {
  /**
   * Cluster-ID of that locale entry. Not Populated if the message is part of a
   * Cluster-Proto (e.g. when loaded as a signal). The data is being populated
   * when the proto is used outside of the cluster context. For instance, when
   * being used as a dups-computed-localized-alternate-name.
   */
  clusterId?: bigint;
  /**
   * Device match info calculated only by URL pattern.
   */
  deviceMatchInfo?:  | "UNKNOWN" | "WWW_TO_WWW" | "WWW_TO_M" | "M_TO_M" | "M_TO_WWW";
  /**
   * Language/Region code. E.g. "en-US" or "de". Allowed values are
   * language-region codes based on the W3C recommendation
   * http://www.w3.org/TR/html401/struct/dirlang.html#langcodes
   */
  language?: string;
  /**
   * The alternate url representing the content for a specific language and
   * region (or language only).
   */
  url?: string;
  /**
   * see webutil/urlencoding
   */
  urlEncoding?: number;
  /**
   * The region code that was extracted from the URL, either by the TLD or via
   * a pattern (like 'en-ca' as a path element).. Always filled in if known,
   * unlike the sometimes left out region part of the language field. Unknown
   * Region Code
   */
  urlRegionCode?: number;
}

function serializeIndexingDupsComputedLocalizedAlternateNamesLocaleEntry(data: any): IndexingDupsComputedLocalizedAlternateNamesLocaleEntry {
  return {
    ...data,
    clusterId: data["clusterId"] !== undefined ? String(data["clusterId"]) : undefined,
  };
}

function deserializeIndexingDupsComputedLocalizedAlternateNamesLocaleEntry(data: any): IndexingDupsComputedLocalizedAlternateNamesLocaleEntry {
  return {
    ...data,
    clusterId: data["clusterId"] !== undefined ? BigInt(data["clusterId"]) : undefined,
  };
}

export interface IndexingDupsLocalizedLocalizedCluster {
  /**
   * Defined as a source-blocker, a result which can be a boost target but
   * should itself not be boosted (e.g. roboted documents). For more details on
   * source and target blocking, please read through the code for
   * quality/twiddler/impls/PROTECTED/local_result_twiddler_v2.cc
   */
  boostSourceBlocker?: boolean;
  cluster?: IndexingDupsLocalizedLocalizedClusterCluster[];
  /**
   * Since July 2014 those two fiels are no longer populated, the data is
   * stored in the TargetLinkSets instead. The deprecated fields contain values
   * only for docs which have not been processed since July 2014.
   */
  deprecatedHreflangInfo?: IndexingDupsLocalizedLocalizedClusterLinkBasedClusterInfo;
  deprecatedOutlinksInfo?: IndexingDupsLocalizedLocalizedClusterLinkBasedClusterInfo;
  /**
   * The language of this document (as detected by on-page language detection,
   * not influenced by external anchor signals or other indirect conclusions).
   */
  documentLanguage?:  | "ENGLISH" | "DANISH" | "DUTCH" | "FINNISH" | "FRENCH" | "GERMAN" | "HEBREW" | "ITALIAN" | "JAPANESE" | "KOREAN" | "NORWEGIAN" | "POLISH" | "PORTUGUESE" | "RUSSIAN" | "SPANISH" | "SWEDISH" | "CHINESE" | "CZECH" | "GREEK" | "ICELANDIC" | "LATVIAN" | "LITHUANIAN" | "ROMANIAN" | "HUNGARIAN" | "ESTONIAN" | "TG_UNKNOWN_LANGUAGE" | "UNKNOWN_LANGUAGE" | "BULGARIAN" | "CROATIAN" | "SERBIAN" | "IRISH" | "GALICIAN" | "TAGALOG" | "TURKISH" | "UKRAINIAN" | "HINDI" | "MACEDONIAN" | "BENGALI" | "INDONESIAN" | "LATIN" | "MALAY" | "MALAYALAM" | "WELSH" | "NEPALI" | "TELUGU" | "ALBANIAN" | "TAMIL" | "BELARUSIAN" | "JAVANESE" | "OCCITAN" | "URDU" | "BIHARI" | "GUJARATI" | "THAI" | "ARABIC" | "CATALAN" | "ESPERANTO" | "BASQUE" | "INTERLINGUA" | "KANNADA" | "PUNJABI" | "SCOTS_GAELIC" | "SWAHILI" | "SLOVENIAN" | "MARATHI" | "MALTESE" | "VIETNAMESE" | "FRISIAN" | "SLOVAK" | "CHINESE_T" | "FAROESE" | "SUNDANESE" | "UZBEK" | "AMHARIC" | "AZERBAIJANI" | "GEORGIAN" | "TIGRINYA" | "PERSIAN" | "BOSNIAN" | "SINHALESE" | "NORWEGIAN_N" | "PORTUGUESE_P" | "PORTUGUESE_B" | "XHOSA" | "ZULU" | "GUARANI" | "SESOTHO" | "TURKMEN" | "KYRGYZ" | "BRETON" | "TWI" | "YIDDISH" | "SERBO_CROATIAN" | "SOMALI" | "UIGHUR" | "KURDISH" | "MONGOLIAN" | "ARMENIAN" | "LAOTHIAN" | "SINDHI" | "RHAETO_ROMANCE" | "AFRIKAANS" | "LUXEMBOURGISH" | "BURMESE" | "KHMER" | "TIBETAN" | "DHIVEHI" | "CHEROKEE" | "SYRIAC" | "LIMBU" | "ORIYA" | "ASSAMESE" | "CORSICAN" | "INTERLINGUE" | "KAZAKH" | "LINGALA" | "MOLDAVIAN" | "PASHTO" | "QUECHUA" | "SHONA" | "TAJIK" | "TATAR" | "TONGA" | "YORUBA" | "CREOLES_AND_PIDGINS_ENGLISH_BASED" | "CREOLES_AND_PIDGINS_FRENCH_BASED" | "CREOLES_AND_PIDGINS_PORTUGUESE_BASED" | "CREOLES_AND_PIDGINS_OTHER" | "MAORI" | "WOLOF" | "ABKHAZIAN" | "AFAR" | "AYMARA" | "BASHKIR" | "BISLAMA" | "DZONGKHA" | "FIJIAN" | "GREENLANDIC" | "HAUSA" | "HAITIAN_CREOLE" | "INUPIAK" | "INUKTITUT" | "KASHMIRI" | "KINYARWANDA" | "MALAGASY" | "NAURU" | "OROMO" | "RUNDI" | "SAMOAN" | "SANGO" | "SANSKRIT" | "SISWANT" | "TSONGA" | "TSWANA" | "VOLAPUK" | "ZHUANG" | "KHASI" | "SCOTS" | "GANDA" | "MANX" | "MONTENEGRIN" | "AKAN" | "IGBO" | "MAURITIAN_CREOLE" | "HAWAIIAN" | "CEBUANO" | "EWE" | "GA" | "HMONG" | "KRIO" | "LOZI" | "LUBA_LULUA" | "LUO_KENYA_AND_TANZANIA" | "NEWARI" | "NYANJA" | "OSSETIAN" | "PAMPANGA" | "PEDI" | "RAJASTHANI" | "SESELWA_CREOLE_FRENCH" | "TUMBUKA" | "VENDA" | "WARAY_PHILIPPINES" | "NUM_LANGUAGES";
  hreflangTargetLink?: IndexingDupsLocalizedLocalizedClusterTargetLinkSets;
  inbodyTargetLink?: IndexingDupsLocalizedLocalizedClusterTargetLinkSets;
  outlinksTargetLink?: IndexingDupsLocalizedLocalizedClusterTargetLinkSets;
  /**
   * The list of Sitedup rule IDs for this specific URL. The value is only
   * populated if the URL has at least one localized cluster fulfilling the
   * following conditions: - spans more than one host - does not have filtering
   * enabled due to other input (e.g. due to being a hreflang cluster).
   */
  sitedupRuleId?: bigint[];
  /**
   * A warning indicator that a problem has occurred, e.g. cross-domain links
   * being filtered early. The warning is just presented for debugging purposes.
   */
  warningMessage?: string[];
}

function serializeIndexingDupsLocalizedLocalizedCluster(data: any): IndexingDupsLocalizedLocalizedCluster {
  return {
    ...data,
    cluster: data["cluster"] !== undefined ? data["cluster"].map((item: any) => (serializeIndexingDupsLocalizedLocalizedClusterCluster(item))) : undefined,
    deprecatedHreflangInfo: data["deprecatedHreflangInfo"] !== undefined ? serializeIndexingDupsLocalizedLocalizedClusterLinkBasedClusterInfo(data["deprecatedHreflangInfo"]) : undefined,
    deprecatedOutlinksInfo: data["deprecatedOutlinksInfo"] !== undefined ? serializeIndexingDupsLocalizedLocalizedClusterLinkBasedClusterInfo(data["deprecatedOutlinksInfo"]) : undefined,
    hreflangTargetLink: data["hreflangTargetLink"] !== undefined ? serializeIndexingDupsLocalizedLocalizedClusterTargetLinkSets(data["hreflangTargetLink"]) : undefined,
    inbodyTargetLink: data["inbodyTargetLink"] !== undefined ? serializeIndexingDupsLocalizedLocalizedClusterTargetLinkSets(data["inbodyTargetLink"]) : undefined,
    outlinksTargetLink: data["outlinksTargetLink"] !== undefined ? serializeIndexingDupsLocalizedLocalizedClusterTargetLinkSets(data["outlinksTargetLink"]) : undefined,
    sitedupRuleId: data["sitedupRuleId"] !== undefined ? data["sitedupRuleId"].map((item: any) => (String(item))) : undefined,
  };
}

function deserializeIndexingDupsLocalizedLocalizedCluster(data: any): IndexingDupsLocalizedLocalizedCluster {
  return {
    ...data,
    cluster: data["cluster"] !== undefined ? data["cluster"].map((item: any) => (deserializeIndexingDupsLocalizedLocalizedClusterCluster(item))) : undefined,
    deprecatedHreflangInfo: data["deprecatedHreflangInfo"] !== undefined ? deserializeIndexingDupsLocalizedLocalizedClusterLinkBasedClusterInfo(data["deprecatedHreflangInfo"]) : undefined,
    deprecatedOutlinksInfo: data["deprecatedOutlinksInfo"] !== undefined ? deserializeIndexingDupsLocalizedLocalizedClusterLinkBasedClusterInfo(data["deprecatedOutlinksInfo"]) : undefined,
    hreflangTargetLink: data["hreflangTargetLink"] !== undefined ? deserializeIndexingDupsLocalizedLocalizedClusterTargetLinkSets(data["hreflangTargetLink"]) : undefined,
    inbodyTargetLink: data["inbodyTargetLink"] !== undefined ? deserializeIndexingDupsLocalizedLocalizedClusterTargetLinkSets(data["inbodyTargetLink"]) : undefined,
    outlinksTargetLink: data["outlinksTargetLink"] !== undefined ? deserializeIndexingDupsLocalizedLocalizedClusterTargetLinkSets(data["outlinksTargetLink"]) : undefined,
    sitedupRuleId: data["sitedupRuleId"] !== undefined ? data["sitedupRuleId"].map((item: any) => (BigInt(item))) : undefined,
  };
}

export interface IndexingDupsLocalizedLocalizedClusterCluster {
  /**
   * The cluster id, a unique int64 id for the cluster.
   */
  clusterId?: bigint;
  clusterType?:  | "UNDEFINED_CLUSTER_TYPE" | "COMPUTED_ORGMAP" | "COMPUTED_URL_PATTERN" | "HREFLANG_ANNOTATION" | "HREFLANG_ANNOTATION_OPTIMISTIC_GUESS" | "HREFLANG_ANNOTATION_FROM_BODY" | "PAGE_OUTLINKS" | "NOT_USED_4" | "NOT_USED_6" | "NOT_USED_8" | "NOT_USED_9";
  /**
   * Debug Info being attached to each cluster, to understand how it was
   * created. That info is stored in Alexandria, but not available during
   * serving.
   */
  deprecatedDebugInfo?: string[];
  /**
   * Indicates that filtering can be applied on the category (if many results
   * of one cluster show up on the SERP, only one should be kept).
   */
  filteringEnabled?: boolean;
  /**
   * The language as represented by the URL, e.g. 'use this document on the
   * cluster for German queries'.
   */
  language?:  | "ENGLISH" | "DANISH" | "DUTCH" | "FINNISH" | "FRENCH" | "GERMAN" | "HEBREW" | "ITALIAN" | "JAPANESE" | "KOREAN" | "NORWEGIAN" | "POLISH" | "PORTUGUESE" | "RUSSIAN" | "SPANISH" | "SWEDISH" | "CHINESE" | "CZECH" | "GREEK" | "ICELANDIC" | "LATVIAN" | "LITHUANIAN" | "ROMANIAN" | "HUNGARIAN" | "ESTONIAN" | "TG_UNKNOWN_LANGUAGE" | "UNKNOWN_LANGUAGE" | "BULGARIAN" | "CROATIAN" | "SERBIAN" | "IRISH" | "GALICIAN" | "TAGALOG" | "TURKISH" | "UKRAINIAN" | "HINDI" | "MACEDONIAN" | "BENGALI" | "INDONESIAN" | "LATIN" | "MALAY" | "MALAYALAM" | "WELSH" | "NEPALI" | "TELUGU" | "ALBANIAN" | "TAMIL" | "BELARUSIAN" | "JAVANESE" | "OCCITAN" | "URDU" | "BIHARI" | "GUJARATI" | "THAI" | "ARABIC" | "CATALAN" | "ESPERANTO" | "BASQUE" | "INTERLINGUA" | "KANNADA" | "PUNJABI" | "SCOTS_GAELIC" | "SWAHILI" | "SLOVENIAN" | "MARATHI" | "MALTESE" | "VIETNAMESE" | "FRISIAN" | "SLOVAK" | "CHINESE_T" | "FAROESE" | "SUNDANESE" | "UZBEK" | "AMHARIC" | "AZERBAIJANI" | "GEORGIAN" | "TIGRINYA" | "PERSIAN" | "BOSNIAN" | "SINHALESE" | "NORWEGIAN_N" | "PORTUGUESE_P" | "PORTUGUESE_B" | "XHOSA" | "ZULU" | "GUARANI" | "SESOTHO" | "TURKMEN" | "KYRGYZ" | "BRETON" | "TWI" | "YIDDISH" | "SERBO_CROATIAN" | "SOMALI" | "UIGHUR" | "KURDISH" | "MONGOLIAN" | "ARMENIAN" | "LAOTHIAN" | "SINDHI" | "RHAETO_ROMANCE" | "AFRIKAANS" | "LUXEMBOURGISH" | "BURMESE" | "KHMER" | "TIBETAN" | "DHIVEHI" | "CHEROKEE" | "SYRIAC" | "LIMBU" | "ORIYA" | "ASSAMESE" | "CORSICAN" | "INTERLINGUE" | "KAZAKH" | "LINGALA" | "MOLDAVIAN" | "PASHTO" | "QUECHUA" | "SHONA" | "TAJIK" | "TATAR" | "TONGA" | "YORUBA" | "CREOLES_AND_PIDGINS_ENGLISH_BASED" | "CREOLES_AND_PIDGINS_FRENCH_BASED" | "CREOLES_AND_PIDGINS_PORTUGUESE_BASED" | "CREOLES_AND_PIDGINS_OTHER" | "MAORI" | "WOLOF" | "ABKHAZIAN" | "AFAR" | "AYMARA" | "BASHKIR" | "BISLAMA" | "DZONGKHA" | "FIJIAN" | "GREENLANDIC" | "HAUSA" | "HAITIAN_CREOLE" | "INUPIAK" | "INUKTITUT" | "KASHMIRI" | "KINYARWANDA" | "MALAGASY" | "NAURU" | "OROMO" | "RUNDI" | "SAMOAN" | "SANGO" | "SANSKRIT" | "SISWANT" | "TSONGA" | "TSWANA" | "VOLAPUK" | "ZHUANG" | "KHASI" | "SCOTS" | "GANDA" | "MANX" | "MONTENEGRIN" | "AKAN" | "IGBO" | "MAURITIAN_CREOLE" | "HAWAIIAN" | "CEBUANO" | "EWE" | "GA" | "HMONG" | "KRIO" | "LOZI" | "LUBA_LULUA" | "LUO_KENYA_AND_TANZANIA" | "NEWARI" | "NYANJA" | "OSSETIAN" | "PAMPANGA" | "PEDI" | "RAJASTHANI" | "SESELWA_CREOLE_FRENCH" | "TUMBUKA" | "VENDA" | "WARAY_PHILIPPINES" | "NUM_LANGUAGES";
  /**
   * Same as language, except for the country. This is the Stable Region Code.
   * This value may be UNKNOWN even though the URL region code is known, namely
   * when the known region code was the main region for the language and for
   * that language no other region is specified (e.g. de-DE being the only
   * german variation). Unknown Region Code
   */
  regionCode?: number;
  /**
   * Similar to region_code, but always has the value filled in if known.
   * Unknown Region Code
   */
  urlRegionCode?: number;
}

function serializeIndexingDupsLocalizedLocalizedClusterCluster(data: any): IndexingDupsLocalizedLocalizedClusterCluster {
  return {
    ...data,
    clusterId: data["clusterId"] !== undefined ? String(data["clusterId"]) : undefined,
  };
}

function deserializeIndexingDupsLocalizedLocalizedClusterCluster(data: any): IndexingDupsLocalizedLocalizedClusterCluster {
  return {
    ...data,
    clusterId: data["clusterId"] !== undefined ? BigInt(data["clusterId"]) : undefined,
  };
}

/**
 * ClusterInfo no longer being populated (they are the 'old' version of storing
 * meta-information only available in old not-reprocessed documents, all
 * documents processed since July 2014 use the 'TargetLinkSet' instead.
 */
export interface IndexingDupsLocalizedLocalizedClusterLinkBasedClusterInfo {
  /**
   * A fingerprint of all outlink-URLs of this document that have been used as
   * algorithmic input.
   */
  fpOutlinks?: bigint;
  /**
   * The last time the set of outgoing links of this document was modified.
   * This is the input for our calculation.
   */
  lastModifiedInputTimestampMs?: bigint;
  /**
   * The last time the cross-validation of the links was done. Between that
   * last timestamp and now, only cached results have been used.
   */
  lastProcessedOutputTimestampMs?: bigint;
  /**
   * All verified members of the cluster (including recursive inclusions).
   */
  linkMember?: IndexingDupsLocalizedLocalizedClusterLinkBasedClusterInfoLinkMember[];
  unvalidatedOutlink?: IndexingDupsLocalizedLocalizedClusterLinkBasedClusterInfoLinkData[];
}

function serializeIndexingDupsLocalizedLocalizedClusterLinkBasedClusterInfo(data: any): IndexingDupsLocalizedLocalizedClusterLinkBasedClusterInfo {
  return {
    ...data,
    fpOutlinks: data["fpOutlinks"] !== undefined ? String(data["fpOutlinks"]) : undefined,
    lastModifiedInputTimestampMs: data["lastModifiedInputTimestampMs"] !== undefined ? String(data["lastModifiedInputTimestampMs"]) : undefined,
    lastProcessedOutputTimestampMs: data["lastProcessedOutputTimestampMs"] !== undefined ? String(data["lastProcessedOutputTimestampMs"]) : undefined,
  };
}

function deserializeIndexingDupsLocalizedLocalizedClusterLinkBasedClusterInfo(data: any): IndexingDupsLocalizedLocalizedClusterLinkBasedClusterInfo {
  return {
    ...data,
    fpOutlinks: data["fpOutlinks"] !== undefined ? BigInt(data["fpOutlinks"]) : undefined,
    lastModifiedInputTimestampMs: data["lastModifiedInputTimestampMs"] !== undefined ? BigInt(data["lastModifiedInputTimestampMs"]) : undefined,
    lastProcessedOutputTimestampMs: data["lastProcessedOutputTimestampMs"] !== undefined ? BigInt(data["lastProcessedOutputTimestampMs"]) : undefined,
  };
}

export interface IndexingDupsLocalizedLocalizedClusterLinkBasedClusterInfoLinkData {
  annotationSource?:  | "HTTP" | "HTML" | "SITEMAP";
  /**
   * If set, represents the crawl timestamp. If not set, there is no known
   * crawl timestamp for that url.
   */
  crawlTimestamp?: number;
  url?: string;
}

export interface IndexingDupsLocalizedLocalizedClusterLinkBasedClusterInfoLinkMember {
  annotationSource?:  | "HTTP" | "HTML" | "SITEMAP";
  languageCode?: string[];
  url?: string;
}

/**
 * Message containing information about the localized URL linked to from this
 * document in a localized-variation-context.
 */
export interface IndexingDupsLocalizedLocalizedClusterTargetLink {
  linkData?: IndexingDupsLocalizedLocalizedClusterTargetLinkLink;
  metaData?: IndexingDupsLocalizedLocalizedClusterTargetLinkMetadata;
  targetDocData?: IndexingDupsLocalizedLocalizedClusterTargetLinkTargetDocData;
  validationStatus?:  | "VALIDATION_UNKNOWN" | "SELFLINK" | "NO_BACKLINK" | "HAS_BACKLINK" | "BLINDLY_TRUSTED" | "BLINDLY_TRUSTED_WITH_BACKLINK";
}

function serializeIndexingDupsLocalizedLocalizedClusterTargetLink(data: any): IndexingDupsLocalizedLocalizedClusterTargetLink {
  return {
    ...data,
    metaData: data["metaData"] !== undefined ? serializeIndexingDupsLocalizedLocalizedClusterTargetLinkMetadata(data["metaData"]) : undefined,
  };
}

function deserializeIndexingDupsLocalizedLocalizedClusterTargetLink(data: any): IndexingDupsLocalizedLocalizedClusterTargetLink {
  return {
    ...data,
    metaData: data["metaData"] !== undefined ? deserializeIndexingDupsLocalizedLocalizedClusterTargetLinkMetadata(data["metaData"]) : undefined,
  };
}

/**
 * Basic information about the link target, i.e. the URL or the language code
 * it's believed to represent.
 */
export interface IndexingDupsLocalizedLocalizedClusterTargetLinkLink {
  annotationSourceInfo?: IndexingDupsLocalizedLocalizedClusterTargetLinkLinkAnnotationSourceInfo[];
  /**
   * For a link A->B where B is represented by this proto, cross_domain :=
   * Host(A) != Host(B).
   */
  crossDomain?: boolean;
  /**
   * The URL the information in TargetLink refers to.
   */
  url?: string;
}

/**
 * Message describing where was the link discovered and with what language
 * annotation.
 */
export interface IndexingDupsLocalizedLocalizedClusterTargetLinkLinkAnnotationSourceInfo {
  /**
   * Optional field for storing the anchor text the language code was extracted
   * from. Applies to outlinks only.
   */
  anchorText?: string;
  /**
   * Information about where the language code was extracted from.
   */
  annotationSource?:  | "HTTP" | "HTML" | "SITEMAP";
  /**
   * Language code extracted from the URL (hreflang or outlink). One URL can
   * represent multiple language codes, like e.g. de-at and de-ch
   */
  languageCode?: string;
  /**
   * Optional field that stores the feed URL where a Sitemap annotation was
   * discovered. Only populated if annotation_source is SITEMAP.
   */
  sourceFeedUrl?: string;
}

/**
 * Information derived from alexandria when processing the cross-link
 * validation (e.g. when this was done the last time, or when we started to see
 * the outlink for the first time).
 */
export interface IndexingDupsLocalizedLocalizedClusterTargetLinkMetadata {
  /**
   * When was the first time a link seen. Defaults to last crawled timestamp.
   */
  firstSeenMs?: bigint;
  /**
   * When was the last time a link validated. Validation is the process of
   * (re)reading the relevant information for a linked document from its
   * respective row in the document table. Data needed for understanding the
   * correctness of the cluster is copied over to have it available locally.
   */
  lastVerifiedMs?: bigint;
}

function serializeIndexingDupsLocalizedLocalizedClusterTargetLinkMetadata(data: any): IndexingDupsLocalizedLocalizedClusterTargetLinkMetadata {
  return {
    ...data,
    firstSeenMs: data["firstSeenMs"] !== undefined ? String(data["firstSeenMs"]) : undefined,
    lastVerifiedMs: data["lastVerifiedMs"] !== undefined ? String(data["lastVerifiedMs"]) : undefined,
  };
}

function deserializeIndexingDupsLocalizedLocalizedClusterTargetLinkMetadata(data: any): IndexingDupsLocalizedLocalizedClusterTargetLinkMetadata {
  return {
    ...data,
    firstSeenMs: data["firstSeenMs"] !== undefined ? BigInt(data["firstSeenMs"]) : undefined,
    lastVerifiedMs: data["lastVerifiedMs"] !== undefined ? BigInt(data["lastVerifiedMs"]) : undefined,
  };
}

export interface IndexingDupsLocalizedLocalizedClusterTargetLinkSets {
  /**
   * Direct links are the simplest scenarios where A simply links to B.
   */
  directTargetLink?: IndexingDupsLocalizedLocalizedClusterTargetLink[];
  /**
   * Repeated field for URLs that are not directly linking to the document
   * TargetLink refers to. We can encounter the following scenario: A -> Links
   * to B -> links to C (i.e. without (A) linking to (C)). In the context of B,
   * indirect_inclusion would include the link to 'C' but not the link back to
   * 'A'.
   */
  indirectTargetLink?: IndexingDupsLocalizedLocalizedClusterTargetLink[];
}

function serializeIndexingDupsLocalizedLocalizedClusterTargetLinkSets(data: any): IndexingDupsLocalizedLocalizedClusterTargetLinkSets {
  return {
    ...data,
    directTargetLink: data["directTargetLink"] !== undefined ? data["directTargetLink"].map((item: any) => (serializeIndexingDupsLocalizedLocalizedClusterTargetLink(item))) : undefined,
    indirectTargetLink: data["indirectTargetLink"] !== undefined ? data["indirectTargetLink"].map((item: any) => (serializeIndexingDupsLocalizedLocalizedClusterTargetLink(item))) : undefined,
  };
}

function deserializeIndexingDupsLocalizedLocalizedClusterTargetLinkSets(data: any): IndexingDupsLocalizedLocalizedClusterTargetLinkSets {
  return {
    ...data,
    directTargetLink: data["directTargetLink"] !== undefined ? data["directTargetLink"].map((item: any) => (deserializeIndexingDupsLocalizedLocalizedClusterTargetLink(item))) : undefined,
    indirectTargetLink: data["indirectTargetLink"] !== undefined ? data["indirectTargetLink"].map((item: any) => (deserializeIndexingDupsLocalizedLocalizedClusterTargetLink(item))) : undefined,
  };
}

/**
 * Information about the URLs being validated.
 */
export interface IndexingDupsLocalizedLocalizedClusterTargetLinkTargetDocData {
  /**
   * The detected on-page content language of the document.
   */
  contentLanguage?:  | "ENGLISH" | "DANISH" | "DUTCH" | "FINNISH" | "FRENCH" | "GERMAN" | "HEBREW" | "ITALIAN" | "JAPANESE" | "KOREAN" | "NORWEGIAN" | "POLISH" | "PORTUGUESE" | "RUSSIAN" | "SPANISH" | "SWEDISH" | "CHINESE" | "CZECH" | "GREEK" | "ICELANDIC" | "LATVIAN" | "LITHUANIAN" | "ROMANIAN" | "HUNGARIAN" | "ESTONIAN" | "TG_UNKNOWN_LANGUAGE" | "UNKNOWN_LANGUAGE" | "BULGARIAN" | "CROATIAN" | "SERBIAN" | "IRISH" | "GALICIAN" | "TAGALOG" | "TURKISH" | "UKRAINIAN" | "HINDI" | "MACEDONIAN" | "BENGALI" | "INDONESIAN" | "LATIN" | "MALAY" | "MALAYALAM" | "WELSH" | "NEPALI" | "TELUGU" | "ALBANIAN" | "TAMIL" | "BELARUSIAN" | "JAVANESE" | "OCCITAN" | "URDU" | "BIHARI" | "GUJARATI" | "THAI" | "ARABIC" | "CATALAN" | "ESPERANTO" | "BASQUE" | "INTERLINGUA" | "KANNADA" | "PUNJABI" | "SCOTS_GAELIC" | "SWAHILI" | "SLOVENIAN" | "MARATHI" | "MALTESE" | "VIETNAMESE" | "FRISIAN" | "SLOVAK" | "CHINESE_T" | "FAROESE" | "SUNDANESE" | "UZBEK" | "AMHARIC" | "AZERBAIJANI" | "GEORGIAN" | "TIGRINYA" | "PERSIAN" | "BOSNIAN" | "SINHALESE" | "NORWEGIAN_N" | "PORTUGUESE_P" | "PORTUGUESE_B" | "XHOSA" | "ZULU" | "GUARANI" | "SESOTHO" | "TURKMEN" | "KYRGYZ" | "BRETON" | "TWI" | "YIDDISH" | "SERBO_CROATIAN" | "SOMALI" | "UIGHUR" | "KURDISH" | "MONGOLIAN" | "ARMENIAN" | "LAOTHIAN" | "SINDHI" | "RHAETO_ROMANCE" | "AFRIKAANS" | "LUXEMBOURGISH" | "BURMESE" | "KHMER" | "TIBETAN" | "DHIVEHI" | "CHEROKEE" | "SYRIAC" | "LIMBU" | "ORIYA" | "ASSAMESE" | "CORSICAN" | "INTERLINGUE" | "KAZAKH" | "LINGALA" | "MOLDAVIAN" | "PASHTO" | "QUECHUA" | "SHONA" | "TAJIK" | "TATAR" | "TONGA" | "YORUBA" | "CREOLES_AND_PIDGINS_ENGLISH_BASED" | "CREOLES_AND_PIDGINS_FRENCH_BASED" | "CREOLES_AND_PIDGINS_PORTUGUESE_BASED" | "CREOLES_AND_PIDGINS_OTHER" | "MAORI" | "WOLOF" | "ABKHAZIAN" | "AFAR" | "AYMARA" | "BASHKIR" | "BISLAMA" | "DZONGKHA" | "FIJIAN" | "GREENLANDIC" | "HAUSA" | "HAITIAN_CREOLE" | "INUPIAK" | "INUKTITUT" | "KASHMIRI" | "KINYARWANDA" | "MALAGASY" | "NAURU" | "OROMO" | "RUNDI" | "SAMOAN" | "SANGO" | "SANSKRIT" | "SISWANT" | "TSONGA" | "TSWANA" | "VOLAPUK" | "ZHUANG" | "KHASI" | "SCOTS" | "GANDA" | "MANX" | "MONTENEGRIN" | "AKAN" | "IGBO" | "MAURITIAN_CREOLE" | "HAWAIIAN" | "CEBUANO" | "EWE" | "GA" | "HMONG" | "KRIO" | "LOZI" | "LUBA_LULUA" | "LUO_KENYA_AND_TANZANIA" | "NEWARI" | "NYANJA" | "OSSETIAN" | "PAMPANGA" | "PEDI" | "RAJASTHANI" | "SESELWA_CREOLE_FRENCH" | "TUMBUKA" | "VENDA" | "WARAY_PHILIPPINES" | "NUM_LANGUAGES";
  crawlStatus?:  | "UNKNOWN" | "CONTENT" | "ROBOTED" | "ERROR";
  /**
   * The timestamp of the last crawl attempt from crawl_timestamp column.
   */
  crawlTimestampSeconds?: number;
  /**
   * Whether the URL being validated is canonical at the time of processing.
   */
  isCanonical?: boolean;
  /**
   * Repeated field for data about the outgoing hreflang links that appear in
   * the document that the currently processed URL refers to.
   */
  outgoingLinkData?: IndexingDupsLocalizedLocalizedClusterTargetLinkLink[];
}

/**
 * This protobuf is used (1) To pass data between EmbeddedExporter and the
 * publisher, and (2) As a member of CompositeDoc, to stick embedded content
 * output into the docjoins. Next tag available: 21
 */
export interface IndexingEmbeddedContentEmbeddedContentInfo {
  /**
   * The document's DOM and render tree produced by WebKit as a side effect of
   * rendering the page. It might be compressed or not. Thus, use
   * indexing::embedded_content::UncompressWebkitDocument to decode it.
   */
  compressedDocumentTrees?: Uint8Array;
  /**
   * The converted contents, as produced by the same DocumentUpdater
   * transaction that generated the render tree. Useful whenever one of our
   * users wants to experiment with deriving an annotation from the render tree.
   */
  convertedContents?: string;
  /**
   * Information about all external resources needed to render this page,
   * a.k.a. embedded links. This includes .css files, images embedded in a page,
   * external javascripts, iframes etc.
   */
  embeddedLinksInfo?: IndexingEmbeddedContentEmbeddedLinksInfo;
  /**
   * The headless response for rendering the document.
   */
  headlessResponse?: HtmlrenderWebkitHeadlessProtoRenderResponse;
  /**
   * Indicate if the snapshot is generated from alternate snapshot. If true,
   * the snapshot will be exported even if the snapshot quality score is low.
   */
  isAlternateSnapshot?: boolean;
  /**
   * The original encoding of the content crawled from trawler. It's the value
   * of enum i18n::encodings::encoding. We put a int32 here instead of encoding
   * proto to maintain the compatibility of "py_api_version = 1"
   */
  originalEncoding?: number;
  /**
   * *** DEPRECATED *** This field is only populated in fresh_doc which is
   * shutting down.
   */
  rawRedirectInfo?: IndexingConverterRawRedirectInfo;
  /**
   * Information about all external resources used to render this page, a.k.a.
   * embedded links. This includes .css files, images embedded in a page,
   * external javascripts, iframes etc.
   */
  referencedResource?: HtmlrenderWebkitHeadlessProtoReferencedResource[];
  /**
   * Only exist in dry run mode.
   */
  renderedSnapshot?: HtmlrenderWebkitHeadlessProtoImage;
  /**
   * Snapshot image of a rendered html document (possibly encoded as png, jpeg,
   * or webp).
   */
  renderedSnapshotImage?: string;
  /**
   * A collection of values which are needed by the users of the Kodachrome
   * bigtable.
   */
  renderedSnapshotMetadata?: SnapshotSnapshotMetadata;
  /**
   * The quality of the image, 0.0 is the worst, 1.0 is the best. If all
   * dependencies are successfully crawled, the quality should be 1.0. If one or
   * more of the dependencies are unknown, the quality will be lower.
   */
  renderedSnapshotQualityScore?: number;
  renderingOutputMetadata?: IndexingEmbeddedContentRenderingOutputMetadata;
  /**
   * The rich content data to recover the original contents from the
   * converted_contents. Useful for offline content analysis.
   */
  richcontentData?: IndexingConverterRichContentData;
}

function serializeIndexingEmbeddedContentEmbeddedContentInfo(data: any): IndexingEmbeddedContentEmbeddedContentInfo {
  return {
    ...data,
    compressedDocumentTrees: data["compressedDocumentTrees"] !== undefined ? encodeBase64(data["compressedDocumentTrees"]) : undefined,
    embeddedLinksInfo: data["embeddedLinksInfo"] !== undefined ? serializeIndexingEmbeddedContentEmbeddedLinksInfo(data["embeddedLinksInfo"]) : undefined,
    headlessResponse: data["headlessResponse"] !== undefined ? serializeHtmlrenderWebkitHeadlessProtoRenderResponse(data["headlessResponse"]) : undefined,
    referencedResource: data["referencedResource"] !== undefined ? data["referencedResource"].map((item: any) => (serializeHtmlrenderWebkitHeadlessProtoReferencedResource(item))) : undefined,
    renderedSnapshot: data["renderedSnapshot"] !== undefined ? serializeHtmlrenderWebkitHeadlessProtoImage(data["renderedSnapshot"]) : undefined,
    renderedSnapshotMetadata: data["renderedSnapshotMetadata"] !== undefined ? serializeSnapshotSnapshotMetadata(data["renderedSnapshotMetadata"]) : undefined,
    renderingOutputMetadata: data["renderingOutputMetadata"] !== undefined ? serializeIndexingEmbeddedContentRenderingOutputMetadata(data["renderingOutputMetadata"]) : undefined,
    richcontentData: data["richcontentData"] !== undefined ? serializeIndexingConverterRichContentData(data["richcontentData"]) : undefined,
  };
}

function deserializeIndexingEmbeddedContentEmbeddedContentInfo(data: any): IndexingEmbeddedContentEmbeddedContentInfo {
  return {
    ...data,
    compressedDocumentTrees: data["compressedDocumentTrees"] !== undefined ? decodeBase64(data["compressedDocumentTrees"] as string) : undefined,
    embeddedLinksInfo: data["embeddedLinksInfo"] !== undefined ? deserializeIndexingEmbeddedContentEmbeddedLinksInfo(data["embeddedLinksInfo"]) : undefined,
    headlessResponse: data["headlessResponse"] !== undefined ? deserializeHtmlrenderWebkitHeadlessProtoRenderResponse(data["headlessResponse"]) : undefined,
    referencedResource: data["referencedResource"] !== undefined ? data["referencedResource"].map((item: any) => (deserializeHtmlrenderWebkitHeadlessProtoReferencedResource(item))) : undefined,
    renderedSnapshot: data["renderedSnapshot"] !== undefined ? deserializeHtmlrenderWebkitHeadlessProtoImage(data["renderedSnapshot"]) : undefined,
    renderedSnapshotMetadata: data["renderedSnapshotMetadata"] !== undefined ? deserializeSnapshotSnapshotMetadata(data["renderedSnapshotMetadata"]) : undefined,
    renderingOutputMetadata: data["renderingOutputMetadata"] !== undefined ? deserializeIndexingEmbeddedContentRenderingOutputMetadata(data["renderingOutputMetadata"]) : undefined,
    richcontentData: data["richcontentData"] !== undefined ? deserializeIndexingConverterRichContentData(data["richcontentData"]) : undefined,
  };
}

export interface IndexingEmbeddedContentEmbeddedLinksInfo {
  /**
   * This field is optional only because we're adding it late and want to
   * support records written before that. For newly produced records, this field
   * should always be set.
   */
  embedderInfo?: IndexingEmbeddedContentEmbedderInfo;
  link?: IndexingEmbeddedContentLinkInfo[];
  /**
   * Page download size.
   */
  pageSizeInfo?: IndexingEmbeddedContentPageSizeInfo;
  /**
   * This field is the sum of http_response_length for the embedder and all
   * embedded resources. This is expected to be set only in the docjoins, not in
   * the pinax tables or the exported bigtable.
   */
  sumHttpResponseLength?: number;
  uncrawledLinkUrl?: string[];
}

function serializeIndexingEmbeddedContentEmbeddedLinksInfo(data: any): IndexingEmbeddedContentEmbeddedLinksInfo {
  return {
    ...data,
    embedderInfo: data["embedderInfo"] !== undefined ? serializeIndexingEmbeddedContentEmbedderInfo(data["embedderInfo"]) : undefined,
    link: data["link"] !== undefined ? data["link"].map((item: any) => (serializeIndexingEmbeddedContentLinkInfo(item))) : undefined,
  };
}

function deserializeIndexingEmbeddedContentEmbeddedLinksInfo(data: any): IndexingEmbeddedContentEmbeddedLinksInfo {
  return {
    ...data,
    embedderInfo: data["embedderInfo"] !== undefined ? deserializeIndexingEmbeddedContentEmbedderInfo(data["embedderInfo"]) : undefined,
    link: data["link"] !== undefined ? data["link"].map((item: any) => (deserializeIndexingEmbeddedContentLinkInfo(item))) : undefined,
  };
}

export interface IndexingEmbeddedContentEmbedderInfo {
  importanceAsEmbedder?: number;
  linkInfo?: IndexingEmbeddedContentLinkInfo;
}

function serializeIndexingEmbeddedContentEmbedderInfo(data: any): IndexingEmbeddedContentEmbedderInfo {
  return {
    ...data,
    linkInfo: data["linkInfo"] !== undefined ? serializeIndexingEmbeddedContentLinkInfo(data["linkInfo"]) : undefined,
  };
}

function deserializeIndexingEmbeddedContentEmbedderInfo(data: any): IndexingEmbeddedContentEmbedderInfo {
  return {
    ...data,
    linkInfo: data["linkInfo"] !== undefined ? deserializeIndexingEmbeddedContentLinkInfo(data["linkInfo"]) : undefined,
  };
}

/**
 * Log how many urls finally goes to trawler on a host in rendering.
 */
export interface IndexingEmbeddedContentFetchHostCount {
  counter?: IndexingEmbeddedContentFetchHostCountCounter[];
  host?: string;
  num?: number;
}

export interface IndexingEmbeddedContentFetchHostCountCounter {
  name?: string;
  num?: number;
}

/**
 * Capsulate all metadata annotated from fetch server. This message will
 * typically go through: - EmbeddedContentFetcher, or - EmbeddedLinkGetter->
 * DenormalizedContent -> ContentStore. And finally deposit in
 * referenced_resources and link_info.
 */
export interface IndexingEmbeddedContentFetchUrlResponseMetadata {
  adsResourceType?:  | "ADS_TYPE_UNKNOWN" | "ADS_TYPE_NON_ADS" | "ADS_TYPE_PATTERN" | "ADS_TYPE_CENTERPIECE_ADS_MATCHER";
  /**
   * The field always exists, and has four options: UNKNOWN, CONTENT, ROBOTED
   * and ERROR, which are defined in indexing.converter.CrawlStatus.
   */
  crawlStatus?: number;
  criticalResourceType?:  | "UNKNOWN" | "NON_CRITICAL" | "CONTENT_BASED" | "GEOMETRY_LAYOUT_BASED" | "THREE_WAY" | "MANUAL" | "TARGET_MAIN_FRAME" | "ROBOTED";
  /**
   * True if the response is fetched with SMARTPHONE user agent.
   */
  fetchWithSmartphoneUa?: boolean;
  isAdsResource?: boolean;
  isCriticalResource?: boolean;
  isTrivialResource?: boolean;
  /**
   * Number of trawler fetches while fetching this URL. In most cases, this
   * number will be 0 or 1.
   */
  numTrawlerFetches?: number;
  /**
   * Used for logging purposes only here.
   */
  rewriteMethod?: string;
  /**
   * Note that this robots_info should only be used for noindex_reason and will
   * only be present for TARGET_MAIN_FRAME / TARGET_SUBFRAME fetches.
   */
  robotsInfo?: IndexingConverterRobotsInfo;
}

function serializeIndexingEmbeddedContentFetchUrlResponseMetadata(data: any): IndexingEmbeddedContentFetchUrlResponseMetadata {
  return {
    ...data,
    robotsInfo: data["robotsInfo"] !== undefined ? serializeIndexingConverterRobotsInfo(data["robotsInfo"]) : undefined,
  };
}

function deserializeIndexingEmbeddedContentFetchUrlResponseMetadata(data: any): IndexingEmbeddedContentFetchUrlResponseMetadata {
  return {
    ...data,
    robotsInfo: data["robotsInfo"] !== undefined ? deserializeIndexingConverterRobotsInfo(data["robotsInfo"]) : undefined,
  };
}

/**
 * Information about one embedded link. Next tag: 18
 */
export interface IndexingEmbeddedContentLinkInfo {
  /**
   * Size of the HTTP body (payload of the HTTP response, excluding headers),
   * pre-decompression. Equal to the value of the Content-Length header if any.
   * NOTE: if this proto is converted to from ReferencedResource, we have to use
   * the size of the full HTTP response (i.e. http_response_length) as an
   * approximation, as we could not get the size of HTTP headers.
   */
  contentLength?: number;
  contentType?: number;
  /**
   * Time spent downloading this resource, in milliseconds. Not a timestamp!
   */
  crawlDuration?: number;
  /**
   * Enum values for crawl_status are defined in
   * indexing/converter/proto/converter.proto
   */
  crawlStatus?: number;
  crawlTimestamp?: number;
  deprecatedRedirect?: string[];
  /**
   * Where this resource comes from.
   */
  fetchSourceInfo?: WirelessTranscoderFetchFetchSourceInfo[];
  /**
   * Fetch status from trawler.
   */
  fetchStatus?: TrawlerFetchStatus;
  /**
   * Populated from embedded-content fetch server.
   */
  fetchUrlResponseMetadata?: IndexingEmbeddedContentFetchUrlResponseMetadata;
  /**
   * FetchReplyData from trawler.
   */
  frd?: TrawlerFetchReplyData;
  /**
   * Size of the full HTTP response (headers and body pre-decompression).
   * Semantically equal to content_length plus size of the HTTP headers.
   */
  httpResponseLength?: number;
  isCacheable?: boolean;
  isRobotedContentFromFastnet?: boolean;
  /**
   * Size of the HTTP body (payload of the HTTP response, excluding headers),
   * post-decompression. Equal to content_length if the body was not compressed
   * to begin with. NOTE: if this proto is converted to from ReferencedResource,
   * we have to use the size of the full HTTP response as an approximation, as
   * we could not get the size of HTTP headers.
   */
  uncompressedContentLength?: number;
  url?: Uint8Array;
  webkitFetchMetadata?: HtmlrenderWebkitHeadlessProtoWebKitFetchMetadata;
}

function serializeIndexingEmbeddedContentLinkInfo(data: any): IndexingEmbeddedContentLinkInfo {
  return {
    ...data,
    fetchUrlResponseMetadata: data["fetchUrlResponseMetadata"] !== undefined ? serializeIndexingEmbeddedContentFetchUrlResponseMetadata(data["fetchUrlResponseMetadata"]) : undefined,
    frd: data["frd"] !== undefined ? serializeTrawlerFetchReplyData(data["frd"]) : undefined,
    url: data["url"] !== undefined ? encodeBase64(data["url"]) : undefined,
  };
}

function deserializeIndexingEmbeddedContentLinkInfo(data: any): IndexingEmbeddedContentLinkInfo {
  return {
    ...data,
    fetchUrlResponseMetadata: data["fetchUrlResponseMetadata"] !== undefined ? deserializeIndexingEmbeddedContentFetchUrlResponseMetadata(data["fetchUrlResponseMetadata"]) : undefined,
    frd: data["frd"] !== undefined ? deserializeTrawlerFetchReplyData(data["frd"]) : undefined,
    url: data["url"] !== undefined ? decodeBase64(data["url"] as string) : undefined,
  };
}

/**
 * For each of the output fields generated by the embedded content system, the
 * Unix timestamp of when it was most recently generated. Used for controlling
 * the frequency of generation (and thus exporting) of the fields which are
 * expensive to generate and/or the consumers of which are not able to handle
 * the high load of daily/hourly updates. If a timestamp corresponding to an
 * output field is missing, it means the last attempt to generate this field
 * failed (which could be mean that the document was not important enough for
 * this field to be generated, or that we hit a bug in WebKit). In case we
 * choose not to regenerate the field (because the latest generation timestamp
 * is too fresh) the corresponding timestamp doesn't change. Next tag available:
 * 8
 */
export interface IndexingEmbeddedContentOutputGenerationTimestamps {
  documentData?: number;
  renderedSnapshot?: number;
}

/**
 * Page download size information.
 */
export interface IndexingEmbeddedContentPageSizeInfo {
  /**
   * Images are also resources. num_images <= num_resources.
   */
  numImages?: number;
  /**
   * Number of images whose crawl status is CONTENT.
   */
  numImagesWithContent?: number;
  /**
   * Numbers below don't include embedder.
   */
  numResources?: number;
  /**
   * Number of resources whose crawl status is CONTENT.
   */
  numResourcesWithContent?: number;
  /**
   * Sum of embedder and all referenced resources.
   */
  sumHttpResponseLength?: number;
}

/**
 * Fields used to track cache use in the rendering microservice. Next tag
 * available: 6
 */
export interface IndexingEmbeddedContentRenderCacheStats {
  /**
   * When the rendered content would expire from the cache in microseconds.
   */
  cacheExpireTimestampUsec?: bigint;
  crawledSimhashDistance?: number;
  /**
   * The last time the document was rendered, in microseconds. Does not update
   * in case of cache use.
   */
  lastRenderedTimestampUsec?: bigint;
  renderCache?:  | "UNKNOWN_CACHE" | "CACHE_MISS" | "CACHE_SKIPPED" | "ARECA_CACHE" | "CRAWLED_SIMHASH_CACHE";
  renderedSimhashDistance?: number;
}

function serializeIndexingEmbeddedContentRenderCacheStats(data: any): IndexingEmbeddedContentRenderCacheStats {
  return {
    ...data,
    cacheExpireTimestampUsec: data["cacheExpireTimestampUsec"] !== undefined ? String(data["cacheExpireTimestampUsec"]) : undefined,
    lastRenderedTimestampUsec: data["lastRenderedTimestampUsec"] !== undefined ? String(data["lastRenderedTimestampUsec"]) : undefined,
  };
}

function deserializeIndexingEmbeddedContentRenderCacheStats(data: any): IndexingEmbeddedContentRenderCacheStats {
  return {
    ...data,
    cacheExpireTimestampUsec: data["cacheExpireTimestampUsec"] !== undefined ? BigInt(data["cacheExpireTimestampUsec"]) : undefined,
    lastRenderedTimestampUsec: data["lastRenderedTimestampUsec"] !== undefined ? BigInt(data["lastRenderedTimestampUsec"]) : undefined,
  };
}

/**
 * Fetch stats during rendering.
 */
export interface IndexingEmbeddedContentRenderingFetchStats {
  /**
   * A host->count mapping to log how many embedded_links in each host finally
   * goes to trawler during rendering.
   */
  fetchHostCount?: IndexingEmbeddedContentFetchHostCount[];
}

/**
 * Small values from rendering output. It's stored as a column in alexandria
 * document table. Next tag available: 30
 */
export interface IndexingEmbeddedContentRenderingOutputMetadata {
  configParams?: IndexingEmbeddedContentRenderRequestConfigConfigParams;
  /**
   * The exceptions observed during the rendering. In bit-field encoding of
   * enum values of RenderResponse.RenderingException.
   */
  exceptions?: bigint;
  /**
   * Total GCU time for rendering the document in millisecond. This data is
   * from render_stats.render_cost_mgcu in RenderResponse proto. Note that this
   * is *experimental* field. Please check with rendering-infra@ if you want to
   * use.
   */
  experimentalRenderTimeMsec?: number;
  generationTimestamps?: IndexingEmbeddedContentOutputGenerationTimestamps;
  /**
   * The importance value of the rendered document.
   */
  importance?: number;
  /**
   * The timestamp of last new content probing.
   */
  lastNewContentProbingTimestamp?: number;
  /**
   * Percentage of new tokens in the rendered the document content.
   */
  newTokensPercentageAfterRendering?: number;
  numNewTokensFoundInRendering?: number;
  refresh?: boolean;
  /**
   * A collection of fields to track stats on cache use in the Rendering
   * microservice.
   */
  renderCacheStats?: IndexingEmbeddedContentRenderCacheStats;
  /**
   * Short signature (usually less than 1 KB) which captures a perceptual hash
   * on the rendered image. This is used to determine whether successive
   * renderings should be output. See the library in
   * googlen/snapshot/shared/similarity.* for more info about how this value is
   * interpreted and used.
   */
  renderedSnapshotSignature?: Uint8Array;
  /**
   * Current time in microseconds the document is going through rendering
   * system. This field is set regardless of whether the document is being
   * rendered or if we are skipping rendering by using a cache.
   */
  renderedTimeUsec?: bigint;
  renderEngine?:  | "UNKNOWN" | "BLINK_HEADLESS" | "CHROME_HEADLESS";
  /**
   * Different types of events which happened during rendering.
   */
  renderEvent?: HtmlrenderWebkitHeadlessProtoRenderEvent[];
  renderingFetchStats?: IndexingEmbeddedContentRenderingFetchStats;
  /**
   * The CL from which the render engine was built.
   */
  renderServerCl?: bigint;
  renderTreeQualityScore?: number;
  /**
   * The corpus selection result. Can be used for offline analysis.
   */
  selectionResult?: IndexingEmbeddedContentSelectionResult;
  /**
   * These scores are copied from htmlrender_webkit_headless_proto.Document.
   */
  snapshotQualityScore?: number;
  /**
   * True if there were any missing resources during the rendering.
   */
  withMissingResources?: boolean;
}

function serializeIndexingEmbeddedContentRenderingOutputMetadata(data: any): IndexingEmbeddedContentRenderingOutputMetadata {
  return {
    ...data,
    exceptions: data["exceptions"] !== undefined ? String(data["exceptions"]) : undefined,
    renderCacheStats: data["renderCacheStats"] !== undefined ? serializeIndexingEmbeddedContentRenderCacheStats(data["renderCacheStats"]) : undefined,
    renderedSnapshotSignature: data["renderedSnapshotSignature"] !== undefined ? encodeBase64(data["renderedSnapshotSignature"]) : undefined,
    renderedTimeUsec: data["renderedTimeUsec"] !== undefined ? String(data["renderedTimeUsec"]) : undefined,
    renderServerCl: data["renderServerCl"] !== undefined ? String(data["renderServerCl"]) : undefined,
  };
}

function deserializeIndexingEmbeddedContentRenderingOutputMetadata(data: any): IndexingEmbeddedContentRenderingOutputMetadata {
  return {
    ...data,
    exceptions: data["exceptions"] !== undefined ? BigInt(data["exceptions"]) : undefined,
    renderCacheStats: data["renderCacheStats"] !== undefined ? deserializeIndexingEmbeddedContentRenderCacheStats(data["renderCacheStats"]) : undefined,
    renderedSnapshotSignature: data["renderedSnapshotSignature"] !== undefined ? decodeBase64(data["renderedSnapshotSignature"] as string) : undefined,
    renderedTimeUsec: data["renderedTimeUsec"] !== undefined ? BigInt(data["renderedTimeUsec"]) : undefined,
    renderServerCl: data["renderServerCl"] !== undefined ? BigInt(data["renderServerCl"]) : undefined,
  };
}

export interface IndexingEmbeddedContentRenderRequestConfigConfigParams {
  virtualTime?: number;
}

/**
 * Output that indicates a url should be in our corpus.
 */
export interface IndexingEmbeddedContentSelectionResult {
  renderEffort?:  | "RENDER_NONE" | "RENDER_SKIP" | "RENDER_TRIVIAL" | "RENDER_LIGHT" | "RENDER_CONTROL" | "RENDER_FULL" | "RENDER_FORCE" | "RENDER_REJECT";
  /**
   * Indicate which selector has made the decision.
   */
  selectorId?:  | "NO_SELECTOR" | "INELIGIBLE" | "NO_INDEX" | "IMPORTANCE" | "HOME_PAGE" | "LIGHT_WEIGHT" | "SMARTPHONE" | "VIDEO_SIGNAL" | "VIDEO_CLASSIFER" | "PINPOINT_SIGNAL" | "CENTER_PIECE_SIGNAL" | "INDEXABLE_FRAGMENT" | "ESCAPED_FRAGMENT" | "FRAGMENT_REDIRECT" | "META_REFRESH_REDIRECT" | "FORCE" | "FORCE_BY_TIMESTAMP" | "INTEREST" | "IMPORTANCE_PROTECTED" | "NOT_SUPPORTED_CRAWLER_ID" | "BLACK_LIST" | "NEWS_ONLY" | "SAMPLER" | "CONTENT_REPLACEMENT_WHITELIST" | "SMART" | "SMART_RANDOM" | "SMARTPHONE_SMART" | "SMARTPHONE_REJECT" | "SMART_GROUND_TRUTH" | "APP" | "CONTROL_GROUP" | "NAVBOOST_COUNT" | "DEFAULT_LIGHT" | "NEWS";
}

export interface IndexingMlVerticalVerticalItem {
  /**
   * Unique ID.
   */
  id?: number;
  /**
   * The description name.
   */
  name?: string;
  /**
   * The corresponding Petacat ID.
   */
  petacatId?: number;
  /**
   * The probability of the vertical, whose value is in [0.0, 1.0].
   */
  probability?: number;
}

/**
 * Desktop interstitials signal. The message contains both fields for
 * site-level signal lookup in Index Signals (go/index-signals) and fields for
 * final attachment in DocJoin.
 */
export interface IndexingMobileInterstitialsProtoDesktopInterstitials {
  details?: IndexingMobileInterstitialsProtoDesktopInterstitialsDetails[];
  /**
   * Epoch of the interstitial offline pipeline generating this signal.
   */
  pipelineEpoch?: string;
  /**
   * If present, pipeline_pattern identifies the cluster of URLs for which the
   * signal value was smeared.
   */
  pipelinePattern?: string;
  /**
   * URL tree of interstitial patterns belong to the host, to be used as
   * site-level signal in Index Signals. A pattern may contain a payload
   * InterstitialPatternPayload, which will indicate the violated interstitial
   * types of this pattern.
   */
  urlTree?: IndexingUrlPatternUrlTreeUrlTree;
  /**
   * Overall policy violation status. If this is true, at least one of the
   * InterstitialSignal below indicates a violation.
   */
  violatesDesktopInterstitialPolicy?: boolean;
}

function serializeIndexingMobileInterstitialsProtoDesktopInterstitials(data: any): IndexingMobileInterstitialsProtoDesktopInterstitials {
  return {
    ...data,
    urlTree: data["urlTree"] !== undefined ? serializeIndexingUrlPatternUrlTreeUrlTree(data["urlTree"]) : undefined,
  };
}

function deserializeIndexingMobileInterstitialsProtoDesktopInterstitials(data: any): IndexingMobileInterstitialsProtoDesktopInterstitials {
  return {
    ...data,
    urlTree: data["urlTree"] !== undefined ? deserializeIndexingUrlPatternUrlTreeUrlTree(data["urlTree"]) : undefined,
  };
}

/**
 * An optional message that may contain details of the signals computation.
 */
export interface IndexingMobileInterstitialsProtoDesktopInterstitialsDetails {
  basicInfo?: IndexingMobileInterstitialsProtoInterstitialBasicInfo;
  /**
   * Indicates whether the signal value is "smeared", e.g. extrapolated from
   * other URLs.
   */
  isSmearedSignal?: boolean;
}

/**
 * Basic interstitial info, shared by all layout types. This message can be
 * used to quickly iterate through detected interstitials, if layout type
 * specific details are not required. Note: this message stores info for one
 * primary interstitial as detected by a particular layout codepath. Some
 * codepaths, e.g. overlay interstitial detection, may find multiple
 * interstitial candidates; such details can be found in codepath-specific
 * messages below.
 */
export interface IndexingMobileInterstitialsProtoInterstitialBasicInfo {
  /**
   * Stores the geometry of detected interstitial in absolute page pixels.
   */
  absoluteBox?: HtmlrenderWebkitHeadlessProtoBox;
  contentType?:  | "UNSPECIFIED" | "GENERIC" | "APP_INSTALL_PROMO" | "COOKIE" | "ADULT_CONTENT" | "LOGIN" | "HEALTH_CARE_PROFESSIONAL" | "WHITELISTED" | "ADS" | "SUBSCRIPTION";
  detectionMode?:  | "NORMAL" | "DELAYED" | "AFTER_SCROLL";
  layoutType?:  | "INTERSTITIAL_LAYOUT_TYPE_UNSPECIFIED" | "OVERLAY" | "SCROLLABLE" | "STANDALONE" | "DENSITY";
}

/**
 * Core Web Vitals (https://web.dev/vitals/) carried in VoltSignal: the field
 * data metrics extracted from UKM aggregated 75-percentile data.
 */
export interface IndexingMobileVoltCoreWebVitals {
  /**
   * Cumulative Layout Shift.
   */
  cls?: bigint;
  /**
   * First Input Delay.
   */
  fid?: bigint;
  inp?: bigint;
  /**
   * Largest Contentful Paint.
   */
  lcp?: bigint;
}

function serializeIndexingMobileVoltCoreWebVitals(data: any): IndexingMobileVoltCoreWebVitals {
  return {
    ...data,
    cls: data["cls"] !== undefined ? String(data["cls"]) : undefined,
    fid: data["fid"] !== undefined ? String(data["fid"]) : undefined,
    inp: data["inp"] !== undefined ? String(data["inp"]) : undefined,
    lcp: data["lcp"] !== undefined ? String(data["lcp"]) : undefined,
  };
}

function deserializeIndexingMobileVoltCoreWebVitals(data: any): IndexingMobileVoltCoreWebVitals {
  return {
    ...data,
    cls: data["cls"] !== undefined ? BigInt(data["cls"]) : undefined,
    fid: data["fid"] !== undefined ? BigInt(data["fid"]) : undefined,
    inp: data["inp"] !== undefined ? BigInt(data["inp"]) : undefined,
    lcp: data["lcp"] !== undefined ? BigInt(data["lcp"]) : undefined,
  };
}

/**
 * The protocol buffer stored in the legacyperdocdata muppet attachment for
 * VOLT (go/volt). The data is used for ranking changes. Only CWV signals and
 * secure signal are stored. MobileFriendliness is stored separately in the
 * legacyperdocdata. Safe browsing and BAS/AER conditions are not used for
 * ranking.
 */
export interface IndexingMobileVoltVoltPerDocData {
  /**
   * Desktop Core Wev Vital metrics. NOTE(yunchengz): This field will not be
   * populated in Muppet.
   */
  desktopCwv?: IndexingMobileVoltCoreWebVitals;
  desktopDisplayUrlIsHttps?: boolean;
  displayUrlIsHttps?: boolean;
  /**
   * Mobile Core Web Vital metrics. NOTE(yunchengz): This field will not be
   * populated in Muppet.
   */
  mobileCwv?: IndexingMobileVoltCoreWebVitals;
}

function serializeIndexingMobileVoltVoltPerDocData(data: any): IndexingMobileVoltVoltPerDocData {
  return {
    ...data,
    desktopCwv: data["desktopCwv"] !== undefined ? serializeIndexingMobileVoltCoreWebVitals(data["desktopCwv"]) : undefined,
    mobileCwv: data["mobileCwv"] !== undefined ? serializeIndexingMobileVoltCoreWebVitals(data["mobileCwv"]) : undefined,
  };
}

function deserializeIndexingMobileVoltVoltPerDocData(data: any): IndexingMobileVoltVoltPerDocData {
  return {
    ...data,
    desktopCwv: data["desktopCwv"] !== undefined ? deserializeIndexingMobileVoltCoreWebVitals(data["desktopCwv"]) : undefined,
    mobileCwv: data["mobileCwv"] !== undefined ? deserializeIndexingMobileVoltCoreWebVitals(data["mobileCwv"]) : undefined,
  };
}

export interface IndexingPrivacyAccessAccessRequirements {
  restrictionCategories?:  | "UNSPECIFIED" | "CHILD_SAFETY_CONTENT"[];
}

/**
 * State data for AdaptiveFrequencyEstimator
 */
export interface IndexingSignalAggregatorAdaptiveIntervalData {
  clicksGoodInterval?: number;
  clicksGoodPriorWeight?: number;
  clicksTotalInterval?: number;
  clicksTotalPriorWeight?: number;
  ctrwiInterval?: number;
  ctrwiPriorWeight?: number;
  dwellsInterval?: number;
  dwellsPriorWeight?: number;
  luDwellsInterval?: number;
  luDwellsPriorWeight?: number;
}

/**
 * Accumulated coverage data for an url using a constant half-life time. Next
 * tag: 28
 */
export interface IndexingSignalAggregatorAgeWeightedCoverageData {
  /**
   * Weighted averged timestamps of the decayed chances.
   */
  averageChanceTime?: number;
  /**
   * Numbers below are all total in the decayed manner. To get rate of
   * impression/clicks, divide by chances.
   */
  chances?: number;
  clicksBad?: number;
  clicksGood?: number;
  clicksImage?: number;
  clicksTotal?: number;
  clicksUnclassified?: number;
  /**
   * Epoch seconds at which this weighted coverage data was calculated.
   */
  coverageTimestamp?: bigint;
  ctrWeightedImpressions?: number;
  /**
   * Dwells from KnowledgePanel and WebAnswers.
   */
  dwells?: number;
  /**
   * Epoch seconds at which this url first gets coverage in BASE.
   */
  firstBaseCoverageTimestamp?: bigint;
  /**
   * The pagerank when the url was serving for the first time.
   */
  firstCoveragePagerankNs?: number;
  /**
   * Epoch seconds at which this url first gets coverage data.
   */
  firstCoverageTimestamp?: bigint;
  firstseen?: bigint;
  impressions?: number;
  /**
   * Interval Data to track the average time between clicks_total, clicks_good,
   * and ctr_weighted_impression.
   */
  intervalData?: IndexingSignalAggregatorAdaptiveIntervalData;
  language?: number;
  /**
   * Indicates the date when this document received the last KnowledgePanel or
   * WebAnswer dwell. Note: The date is identified in terms of number of days
   * since Epoch.
   */
  lastDwellDateInDays?: number;
  /**
   * Indicates the date when this document received the last good click. Note:
   * The date is identified in terms of number of days since Epoch.
   */
  lastGoodClickDateInDays?: number;
  /**
   * Indicates the date when this document received the last impression. Note:
   * The date is identified in terms of number of days since Epoch.
   */
  lastImpressionDateInDays?: number;
  /**
   * Indicates the date when this document received the last LocalUniversal
   * dwell. Note: The date is identified in terms of number of days since Epoch.
   */
  lastLuDwellDateInDays?: number;
  /**
   * Indicates the date when this document received the last pseudo-impression.
   * I.e., when it was retrieved as a result but GWS would not show it because
   * of the document's age in the index. Note: The date is identified in terms
   * of number of days since Epoch.
   */
  lastPseudoImpressionsDateInDays?: number;
  /**
   * Dwells from LocalUniversal.
   */
  luDwells?: number;
  /**
   * Repid in Alexandria pipeline.
   */
  repid?: Uint8Array;
  /**
   * Total number of chances on this urls (not decayed).
   */
  totalChances?: bigint;
  url?: string;
  /**
   * Temporary variable, only used during mapreduce.
   */
  urlfp?: bigint;
}

function serializeIndexingSignalAggregatorAgeWeightedCoverageData(data: any): IndexingSignalAggregatorAgeWeightedCoverageData {
  return {
    ...data,
    coverageTimestamp: data["coverageTimestamp"] !== undefined ? String(data["coverageTimestamp"]) : undefined,
    firstBaseCoverageTimestamp: data["firstBaseCoverageTimestamp"] !== undefined ? String(data["firstBaseCoverageTimestamp"]) : undefined,
    firstCoverageTimestamp: data["firstCoverageTimestamp"] !== undefined ? String(data["firstCoverageTimestamp"]) : undefined,
    firstseen: data["firstseen"] !== undefined ? String(data["firstseen"]) : undefined,
    repid: data["repid"] !== undefined ? encodeBase64(data["repid"]) : undefined,
    totalChances: data["totalChances"] !== undefined ? String(data["totalChances"]) : undefined,
    urlfp: data["urlfp"] !== undefined ? String(data["urlfp"]) : undefined,
  };
}

function deserializeIndexingSignalAggregatorAgeWeightedCoverageData(data: any): IndexingSignalAggregatorAgeWeightedCoverageData {
  return {
    ...data,
    coverageTimestamp: data["coverageTimestamp"] !== undefined ? BigInt(data["coverageTimestamp"]) : undefined,
    firstBaseCoverageTimestamp: data["firstBaseCoverageTimestamp"] !== undefined ? BigInt(data["firstBaseCoverageTimestamp"]) : undefined,
    firstCoverageTimestamp: data["firstCoverageTimestamp"] !== undefined ? BigInt(data["firstCoverageTimestamp"]) : undefined,
    firstseen: data["firstseen"] !== undefined ? BigInt(data["firstseen"]) : undefined,
    repid: data["repid"] !== undefined ? decodeBase64(data["repid"] as string) : undefined,
    totalChances: data["totalChances"] !== undefined ? BigInt(data["totalChances"]) : undefined,
    urlfp: data["urlfp"] !== undefined ? BigInt(data["urlfp"]) : undefined,
  };
}

/**
 * Aggregated signal used by NumericSignalAggregator. Next field id: 25
 */
export interface IndexingSignalAggregatorAggregatedScore {
  /**
   * A number reflecting the deviation of Url scores.
   */
  deviation?: number;
  /**
   * State variables for West & Chan variance algorithm used to be stored here
   * directly. Now they are stored inside RunningMeanAndVarianceInternalState.
   */
  m2?: number;
  /**
   * Input UrlScore with max score.
   */
  maxScoreUrl?: IndexingSignalAggregatorUrlScore;
  mean?: number;
  /**
   * Overall stats that are only available in final aggregation results. The
   * aggregated score.
   */
  meanScore?: number;
  /**
   * Input UrlScore with min score.
   */
  minScoreUrl?: IndexingSignalAggregatorUrlScore;
  numImportantUrls?: bigint;
  /**
   * Final Stats that are also available in intermediate output. Number of Urls
   * matching the class.
   */
  numUrlsMatched?: bigint;
  /**
   * Not every matching url has a signal.
   */
  numUrlsWithSignal?: bigint;
  /**
   * Experimental layer of the corresponding pattern.
   */
  patternLayer?:  | "PRODUCTION" | "EXPERIMENTAL_LAYER_A" | "EXPERIMENTAL_LAYER_B" | "NEXT_LAYER";
  /**
   * Optionally populated in mediators. A list of patterns that actually
   * contributed to the final mediated signal.
   */
  patternsUsedInMediation?: string[];
  /**
   * Score percentile of matching urls. If present, it has N entries for
   * buckets of roughly equal number of urls. N is specified the aggregation.
   * The value is the min score in that bucket.
   */
  percentile?: number[];
  runningMeanAndVarianceInternalState?: IndexingSignalAggregatorRunningMeanAndVarianceInternalState;
  /**
   * Random samples.
   */
  samples?: IndexingSignalAggregatorUrlScore[];
  /**
   * for calculating percentile
   */
  scores?: number[];
  /**
   * For debugging purposes, this is an id of the signal associated with this
   * AggregatedScore. For pattern score, this may be the length of the pattern.
   */
  signalId?: number;
  /**
   * If this field presents, it is for a single url. No other field should
   * appear.
   */
  singleUrlScore?: IndexingSignalAggregatorUrlScore;
  /**
   * summation varaible used to get mean
   */
  totalScore?: number;
  /**
   * low-order part of total_score
   */
  totalScoreLow?: number;
  /**
   * summation variable for calculating deviation note, these are now only used
   * for legacy and debugging purposes
   */
  totalScoreSqr?: number;
  /**
   * low order part of total_score_sq
   */
  totalScoreSqrLow?: number;
  /**
   * for calculating weighted mean/dev
   */
  totalWeight?: number;
  /**
   * low order part of total_weight
   */
  totalWeightLow?: number;
}

function serializeIndexingSignalAggregatorAggregatedScore(data: any): IndexingSignalAggregatorAggregatedScore {
  return {
    ...data,
    maxScoreUrl: data["maxScoreUrl"] !== undefined ? serializeIndexingSignalAggregatorUrlScore(data["maxScoreUrl"]) : undefined,
    minScoreUrl: data["minScoreUrl"] !== undefined ? serializeIndexingSignalAggregatorUrlScore(data["minScoreUrl"]) : undefined,
    numImportantUrls: data["numImportantUrls"] !== undefined ? String(data["numImportantUrls"]) : undefined,
    numUrlsMatched: data["numUrlsMatched"] !== undefined ? String(data["numUrlsMatched"]) : undefined,
    numUrlsWithSignal: data["numUrlsWithSignal"] !== undefined ? String(data["numUrlsWithSignal"]) : undefined,
    samples: data["samples"] !== undefined ? data["samples"].map((item: any) => (serializeIndexingSignalAggregatorUrlScore(item))) : undefined,
    singleUrlScore: data["singleUrlScore"] !== undefined ? serializeIndexingSignalAggregatorUrlScore(data["singleUrlScore"]) : undefined,
  };
}

function deserializeIndexingSignalAggregatorAggregatedScore(data: any): IndexingSignalAggregatorAggregatedScore {
  return {
    ...data,
    maxScoreUrl: data["maxScoreUrl"] !== undefined ? deserializeIndexingSignalAggregatorUrlScore(data["maxScoreUrl"]) : undefined,
    minScoreUrl: data["minScoreUrl"] !== undefined ? deserializeIndexingSignalAggregatorUrlScore(data["minScoreUrl"]) : undefined,
    numImportantUrls: data["numImportantUrls"] !== undefined ? BigInt(data["numImportantUrls"]) : undefined,
    numUrlsMatched: data["numUrlsMatched"] !== undefined ? BigInt(data["numUrlsMatched"]) : undefined,
    numUrlsWithSignal: data["numUrlsWithSignal"] !== undefined ? BigInt(data["numUrlsWithSignal"]) : undefined,
    samples: data["samples"] !== undefined ? data["samples"].map((item: any) => (deserializeIndexingSignalAggregatorUrlScore(item))) : undefined,
    singleUrlScore: data["singleUrlScore"] !== undefined ? deserializeIndexingSignalAggregatorUrlScore(data["singleUrlScore"]) : undefined,
  };
}

/**
 * Internal state of the West & Chan running variance algorithm. Fields of this
 * proto should not be accessed directly; instead, please use
 * RunningMeanAndVarianceUtil. The fields of this message only have meaning in
 * the context of the West & Chan algorithm, which is documented (or
 * Wikipedia-linked) in the doc comments of RunningMeanAndVarianceUtil. We do
 * however give some explanation of the meanings of these fields in the context
 * of the algorithm (i.e. if you have the Wikipedia page open and are ready to
 * do some math). Also see the file doc of RunningMeanAndVarianceUtil for a
 * specification and more info about the algorithm. Notation: The data set is X
 * = {(x_1, w_1), ..., (x_n, w_n)}. It consists of n weighted data points. The
 * ith data point has value x_i and weight w_i. REQUIRES: x_i is finite for each
 * i. w_i is finite for each i. w_i >= 0 for each i.
 */
export interface IndexingSignalAggregatorRunningMeanAndVarianceInternalState {
  /**
   * The variable which in the Wikipedia page is referred to as M_2: m2 = w_1 *
   * (x_1 - mean)^2 + ... + w_n * (x_n - mean)^2. The algorithm implemented in
   * RunningMeanAndVarianceUtil provides a way to update m2 in a numerically
   * stable way when the data set grows. If total_weight = 0, then m2 is
   * meaningless, and its value is unspecified, except that it must be finite
   * and >= 0.
   */
  m2?: number;
  /**
   * Mean of the data set, mean = (w_1 * x_1 + ... + w_n * x_n) / total_weight.
   * The algorithm implemented in RunningMeanAndVarianceUtil provides a way to
   * update this mean in a numerically stable way when the data set grows. If
   * total_weight = 0, then mean is meaningless, and its value is unspecified,
   * except that it must be finite.
   */
  mean?: number;
  /**
   * Total weight of the data set, total_weight = w_1 + ... + w_n.
   */
  totalWeight?: number;
}

export interface IndexingSignalAggregatorSccData {
  parentPattern?: IndexingSignalAggregatorSccSignal;
  /**
   * The most immediate pattern data.
   */
  pattern?: IndexingSignalAggregatorSccSignal;
}

function serializeIndexingSignalAggregatorSccData(data: any): IndexingSignalAggregatorSccData {
  return {
    ...data,
    parentPattern: data["parentPattern"] !== undefined ? serializeIndexingSignalAggregatorSccSignal(data["parentPattern"]) : undefined,
    pattern: data["pattern"] !== undefined ? serializeIndexingSignalAggregatorSccSignal(data["pattern"]) : undefined,
  };
}

function deserializeIndexingSignalAggregatorSccData(data: any): IndexingSignalAggregatorSccData {
  return {
    ...data,
    parentPattern: data["parentPattern"] !== undefined ? deserializeIndexingSignalAggregatorSccSignal(data["parentPattern"]) : undefined,
    pattern: data["pattern"] !== undefined ? deserializeIndexingSignalAggregatorSccSignal(data["pattern"]) : undefined,
  };
}

export interface IndexingSignalAggregatorSccSignal {
  clicksBad?: number;
  clicksImage?: number;
  clicksTotal?: number;
  /**
   * For debugging purpose only.
   */
  debugInfo?: string[];
  /**
   * This represents the number of urls with image clicks. A url can have both
   * image and non-image clicks, in which case we set num_image_urls to be the
   * ratio of image_clicks vs total clicks. For example, if a url has 10 total
   * clicks and 7 image clicks, num_image_urls will be set to 0.7.
   */
  numImageUrls?: number;
  numUrls?: bigint;
  /**
   * For debugging purpose only.
   */
  pattern?: string;
}

function serializeIndexingSignalAggregatorSccSignal(data: any): IndexingSignalAggregatorSccSignal {
  return {
    ...data,
    numUrls: data["numUrls"] !== undefined ? String(data["numUrls"]) : undefined,
  };
}

function deserializeIndexingSignalAggregatorSccSignal(data: any): IndexingSignalAggregatorSccSignal {
  return {
    ...data,
    numUrls: data["numUrls"] !== undefined ? BigInt(data["numUrls"]) : undefined,
  };
}

/**
 * Contains only the signals necessary to perform per-URL click prediction.
 * Used by Index Selection for scoring. NEXT ID TO USE: 7
 */
export interface IndexingSignalAggregatorUrlPatternSignals {
  coverage?: IndexingSignalAggregatorAgeWeightedCoverageData;
  pagerankScore?: IndexingSignalAggregatorAggregatedScore;
  patternScore?: IndexingSignalAggregatorAggregatedScore;
  priorSignal?: IndexingSignalAggregatorUrlPatternSignalsPriorSignal[];
  regexpPatternScore?: IndexingSignalAggregatorAggregatedScore;
  sccData?: IndexingSignalAggregatorSccData;
}

function serializeIndexingSignalAggregatorUrlPatternSignals(data: any): IndexingSignalAggregatorUrlPatternSignals {
  return {
    ...data,
    coverage: data["coverage"] !== undefined ? serializeIndexingSignalAggregatorAgeWeightedCoverageData(data["coverage"]) : undefined,
    pagerankScore: data["pagerankScore"] !== undefined ? serializeIndexingSignalAggregatorAggregatedScore(data["pagerankScore"]) : undefined,
    patternScore: data["patternScore"] !== undefined ? serializeIndexingSignalAggregatorAggregatedScore(data["patternScore"]) : undefined,
    priorSignal: data["priorSignal"] !== undefined ? data["priorSignal"].map((item: any) => (serializeIndexingSignalAggregatorUrlPatternSignalsPriorSignal(item))) : undefined,
    regexpPatternScore: data["regexpPatternScore"] !== undefined ? serializeIndexingSignalAggregatorAggregatedScore(data["regexpPatternScore"]) : undefined,
    sccData: data["sccData"] !== undefined ? serializeIndexingSignalAggregatorSccData(data["sccData"]) : undefined,
  };
}

function deserializeIndexingSignalAggregatorUrlPatternSignals(data: any): IndexingSignalAggregatorUrlPatternSignals {
  return {
    ...data,
    coverage: data["coverage"] !== undefined ? deserializeIndexingSignalAggregatorAgeWeightedCoverageData(data["coverage"]) : undefined,
    pagerankScore: data["pagerankScore"] !== undefined ? deserializeIndexingSignalAggregatorAggregatedScore(data["pagerankScore"]) : undefined,
    patternScore: data["patternScore"] !== undefined ? deserializeIndexingSignalAggregatorAggregatedScore(data["patternScore"]) : undefined,
    priorSignal: data["priorSignal"] !== undefined ? data["priorSignal"].map((item: any) => (deserializeIndexingSignalAggregatorUrlPatternSignalsPriorSignal(item))) : undefined,
    regexpPatternScore: data["regexpPatternScore"] !== undefined ? deserializeIndexingSignalAggregatorAggregatedScore(data["regexpPatternScore"]) : undefined,
    sccData: data["sccData"] !== undefined ? deserializeIndexingSignalAggregatorSccData(data["sccData"]) : undefined,
  };
}

/**
 * This message provides a container for any signal used in scoring, and allows
 * UrlPatternSignals to extend beyond (regexp_)pattern_score and pagerank_score.
 */
export interface IndexingSignalAggregatorUrlPatternSignalsPriorSignal {
  aggregatedScore?: IndexingSignalAggregatorAggregatedScore;
  priorSignalId?:  | "PRIOR_SIGNAL_PAGERANK" | "PRIOR_SIGNAL_PATTERN" | "PRIOR_SIGNAL_REGEXP_PATTERN" | "PRIOR_SIGNAL_CLICKRANK" | "PRIOR_SIGNAL_LENGTH" | "PRIOR_SIGNAL_SIBYL" | "PRIOR_SIGNAL_TENSORFLOW";
}

function serializeIndexingSignalAggregatorUrlPatternSignalsPriorSignal(data: any): IndexingSignalAggregatorUrlPatternSignalsPriorSignal {
  return {
    ...data,
    aggregatedScore: data["aggregatedScore"] !== undefined ? serializeIndexingSignalAggregatorAggregatedScore(data["aggregatedScore"]) : undefined,
  };
}

function deserializeIndexingSignalAggregatorUrlPatternSignalsPriorSignal(data: any): IndexingSignalAggregatorUrlPatternSignalsPriorSignal {
  return {
    ...data,
    aggregatedScore: data["aggregatedScore"] !== undefined ? deserializeIndexingSignalAggregatorAggregatedScore(data["aggregatedScore"]) : undefined,
  };
}

/**
 * Representation of numeric signal of a url.
 */
export interface IndexingSignalAggregatorUrlScore {
  /**
   * The number of weekly performance records if the UrlScore is extracted from
   * the DSAC data. It should be used in case a URL is no longer served. As of
   * 2014-10-14, this field is for the evaluation purpose only.
   */
  dsacNumWeeklyPerfRecords?: number;
  /**
   * If this field is set, it indicates the url is eligible to be aggregated to
   * one of the experimental layers.
   */
  eligibleExperimentalLayer?:  | "PRODUCTION" | "EXPERIMENTAL_LAYER_A" | "EXPERIMENTAL_LAYER_B" | "NEXT_LAYER";
  /**
   * The timestamp of the first time this document is served anywhere.
   */
  firstServedTimestamp?: bigint;
  /**
   * Whether this url has important signal. Used for keeping patterns that
   * match too few URLs but some of them have good clicks.
   */
  isImportant?: boolean;
  /**
   * score might be missing if the url does not have signal.
   */
  score?: number;
  /**
   * url might be missing if we can get it from sstable key.
   */
  url?: string;
  /**
   * weight for this url.
   */
  weight?: number;
}

function serializeIndexingSignalAggregatorUrlScore(data: any): IndexingSignalAggregatorUrlScore {
  return {
    ...data,
    firstServedTimestamp: data["firstServedTimestamp"] !== undefined ? String(data["firstServedTimestamp"]) : undefined,
  };
}

function deserializeIndexingSignalAggregatorUrlScore(data: any): IndexingSignalAggregatorUrlScore {
  return {
    ...data,
    firstServedTimestamp: data["firstServedTimestamp"] !== undefined ? BigInt(data["firstServedTimestamp"]) : undefined,
  };
}

/**
 * The information about spoken content that's based on purely the media
 * resource contents (and not the embedding page or context, etc).
 */
export interface IndexingSpeechSpeechPropertiesProto {
  /**
   * Duration of audio in processed fragment (including non-speech), in
   * seconds.
   */
  audioDuration?: number;
  /**
   * If true, the media file is audio-only. If false, also has video track(s).
   */
  audioOnly?: boolean;
  /**
   * Estimated duration of audio in the whole file (including non-speech), in
   * seconds. If this is greater than 0, then it will either be equal to
   * audio_duration (when truncated_file is false), or to the length of the
   * content (audio or video) according to the file header (when truncated_file
   * is true).
   */
  estimatedAudioDuration?: number;
  /**
   * Our confidence in the duration estimate, on a scale from 0 (not confident)
   * to 1 (very confident). An estimate should have a confidence of at least 0.5
   * if it is to be shown to users.
   */
  estimatedAudioDurationConfidence?: number;
  /**
   * The spoken language, see i18n/identifiers/languagecode.h and go/gl2014.
   * This may or may not match the language of the written page. (Examples:
   * "en", "sv", "zh-CN").
   */
  languageCode?: string;
  /**
   * Total number of recognized words in processed fragment.
   */
  numWords?: number;
  /**
   * Measure of the estimated output accuracy from the speech recognition code,
   * from 0 to 1. Based on word-level confidence and possibly other factors.
   */
  recognizerAccuracy?: number;
  /**
   * Duration of speech in processed fragment, in seconds.
   */
  speechDuration?: number;
  /**
   * If true, we may have processed a truncated file (most likely due to a
   * size-cutoff when crawling). As a result, the audio duration is a lower
   * bound and the other fields reflect only the processed prefix of the file.
   */
  truncatedFile?: boolean;
}

/**
 * Representing a dominating branch of the URL tree.
 */
export interface IndexingUrlPatternUrlTreeBigTreeBranch {
  features?: IndexingUrlPatternUrlTreeUrlFeatures;
  /**
   * The fingerprint of the features string.
   */
  patternId?: bigint;
  payload?: Proto2BridgeMessageSet;
}

function serializeIndexingUrlPatternUrlTreeBigTreeBranch(data: any): IndexingUrlPatternUrlTreeBigTreeBranch {
  return {
    ...data,
    features: data["features"] !== undefined ? serializeIndexingUrlPatternUrlTreeUrlFeatures(data["features"]) : undefined,
    patternId: data["patternId"] !== undefined ? String(data["patternId"]) : undefined,
  };
}

function deserializeIndexingUrlPatternUrlTreeBigTreeBranch(data: any): IndexingUrlPatternUrlTreeBigTreeBranch {
  return {
    ...data,
    features: data["features"] !== undefined ? deserializeIndexingUrlPatternUrlTreeUrlFeatures(data["features"]) : undefined,
    patternId: data["patternId"] !== undefined ? BigInt(data["patternId"]) : undefined,
  };
}

export interface IndexingUrlPatternUrlTreeUrlFeature {
  fingerprint?: bigint;
  /**
   * If consider position when calculating fingerprint of url feature.
   */
  fingerprintWithGroupInType?: boolean;
  /**
   * Used together w/ type field to group features, for finding features with
   * too many possible values.
   */
  groupInType?: string;
  type?:  | "HOST_SEGMENT" | "PATH_SEGMENT" | "DOCUMENT_NAME_SEGMENT" | "QUERY_NAME" | "QUERY_VALUE" | "HOST_SEGMENT_COUNT" | "PATH_SEGMENT_COUNT" | "QUERY_COUNT" | "GMAIL_SUBJECT" | "GMAIL_BODY_TEXT" | "GMAIL_BODY_TREE" | "PROTOCOL" | "PACKAGE_ID" | "SCHEME" | "AUTHORITY" | "APP_URI_PATH_SEGMENT" | "APP_URI_PATH_SEGMENT_COUNT" | "APP_URI_DOCUMENT_NAME_SEGMENT" | "APP_URI_QUERY_NAME" | "APP_URI_QUERY_VALUE";
  value?: string;
}

function serializeIndexingUrlPatternUrlTreeUrlFeature(data: any): IndexingUrlPatternUrlTreeUrlFeature {
  return {
    ...data,
    fingerprint: data["fingerprint"] !== undefined ? String(data["fingerprint"]) : undefined,
  };
}

function deserializeIndexingUrlPatternUrlTreeUrlFeature(data: any): IndexingUrlPatternUrlTreeUrlFeature {
  return {
    ...data,
    fingerprint: data["fingerprint"] !== undefined ? BigInt(data["fingerprint"]) : undefined,
  };
}

export interface IndexingUrlPatternUrlTreeUrlFeatures {
  feature?: IndexingUrlPatternUrlTreeUrlFeature[];
}

function serializeIndexingUrlPatternUrlTreeUrlFeatures(data: any): IndexingUrlPatternUrlTreeUrlFeatures {
  return {
    ...data,
    feature: data["feature"] !== undefined ? data["feature"].map((item: any) => (serializeIndexingUrlPatternUrlTreeUrlFeature(item))) : undefined,
  };
}

function deserializeIndexingUrlPatternUrlTreeUrlFeatures(data: any): IndexingUrlPatternUrlTreeUrlFeatures {
  return {
    ...data,
    feature: data["feature"] !== undefined ? data["feature"].map((item: any) => (deserializeIndexingUrlPatternUrlTreeUrlFeature(item))) : undefined,
  };
}

export interface IndexingUrlPatternUrlTreeUrlTree {
  /**
   * Keeping information for dominating branches separately, to prevent docs on
   * smaller branches from being dropping during sampling.
   */
  bigBranch?: IndexingUrlPatternUrlTreeBigTreeBranch[];
  debugInfo?: IndexingUrlPatternUrlTreeUrlTreeDebugInfo;
  key?: IndexingUrlPatternUrlTreeUrlTreeKey;
  /**
   * node(0) is root.
   */
  node?: IndexingUrlPatternUrlTreeUrlTreeNode[];
  /**
   * Used in url pattern matcher for cache invalidation.
   */
  retrievalTimestamp?: number;
  /**
   * The key for this UrlTree, also will be the key in sstable. The old format
   * is site, while the new format will be UrlTreeKey. Only one field can be set
   * in the same time for site and key.
   */
  site?: string;
  /**
   * The time when this UrlTree is built, encoded as seconds past the epoch
   * (Jan 1, 1970).
   */
  timestamp?: number;
  /**
   * Any additional information.
   */
  treeInfo?: Proto2BridgeMessageSet;
}

function serializeIndexingUrlPatternUrlTreeUrlTree(data: any): IndexingUrlPatternUrlTreeUrlTree {
  return {
    ...data,
    bigBranch: data["bigBranch"] !== undefined ? data["bigBranch"].map((item: any) => (serializeIndexingUrlPatternUrlTreeBigTreeBranch(item))) : undefined,
    node: data["node"] !== undefined ? data["node"].map((item: any) => (serializeIndexingUrlPatternUrlTreeUrlTreeNode(item))) : undefined,
  };
}

function deserializeIndexingUrlPatternUrlTreeUrlTree(data: any): IndexingUrlPatternUrlTreeUrlTree {
  return {
    ...data,
    bigBranch: data["bigBranch"] !== undefined ? data["bigBranch"].map((item: any) => (deserializeIndexingUrlPatternUrlTreeBigTreeBranch(item))) : undefined,
    node: data["node"] !== undefined ? data["node"].map((item: any) => (deserializeIndexingUrlPatternUrlTreeUrlTreeNode(item))) : undefined,
  };
}

export interface IndexingUrlPatternUrlTreeUrlTreeDebugInfo {
  innerSimilarity?: number;
}

/**
 * A UID of URL Tree. There is a hash function and a equality function for
 * UrlTreeKey in //indexing/url_pattern/url_tree/util/url-tree-key-util.h. When
 * adding or deprecating a field in this proto, please also update the hash
 * function and the equality function. LINT.IfChange
 */
export interface IndexingUrlPatternUrlTreeUrlTreeKey {
  crawlerId?:  | "UNKNOWN" | "DESKTOP" | "SMARTPHONE";
  domain?: string;
  hostname?: string;
}

export interface IndexingUrlPatternUrlTreeUrlTreeNode {
  indexOfSubTreeWithoutSplittingFeature?: number;
  indexOfSubTreeWithSplittingFeature?: number;
  parent?: number;
  /**
   * The path from root to current node. This is only used for debugging.
   */
  pathFromRoot?: string;
  /**
   * This is only used in leaf nodes which represents a url pattern. It is the
   * fingerprint of the splitting url features from root to the leaf.
   */
  patternId?: bigint;
  payload?: Proto2BridgeMessageSet;
  splittingFeature?: IndexingUrlPatternUrlTreeUrlFeature;
  /**
   * The information gain of content features when selecting this splitting
   * feature to split the node.
   */
  splittingFeatureScore?: number;
}

function serializeIndexingUrlPatternUrlTreeUrlTreeNode(data: any): IndexingUrlPatternUrlTreeUrlTreeNode {
  return {
    ...data,
    patternId: data["patternId"] !== undefined ? String(data["patternId"]) : undefined,
    splittingFeature: data["splittingFeature"] !== undefined ? serializeIndexingUrlPatternUrlTreeUrlFeature(data["splittingFeature"]) : undefined,
  };
}

function deserializeIndexingUrlPatternUrlTreeUrlTreeNode(data: any): IndexingUrlPatternUrlTreeUrlTreeNode {
  return {
    ...data,
    patternId: data["patternId"] !== undefined ? BigInt(data["patternId"]) : undefined,
    splittingFeature: data["splittingFeature"] !== undefined ? deserializeIndexingUrlPatternUrlTreeUrlFeature(data["splittingFeature"]) : undefined,
  };
}

/**
 * This proto captures the output of analyses that ran on Automatic Speech
 * Recogntion produced by the recognizer.
 */
export interface IndexingVideosAsrTranscriptRepairAnnotation {
  gibberishResult?:  | "UNDEFINED_GIBBERISH_RESULT" | "NOT_GIBBERISH" | "IS_GIBBERISH" | "GIBBERISH_UNSUPPORTED_LANGUAGE" | "GIBBERISH_DECLINED" | "GIBBERISH_DETECTION_FAILED";
}

export interface KaltixPerDocData {
  /**
   * approx. 2 bytes for top 1B
   */
  KaltixRank?: number;
  /**
   * empty for now
   */
  LocalKaltixRank?: number;
  /**
   * empty for now
   */
  SiteKaltixRank?: number;
}

/**
 * Wrapper message containing list of regions and their corresponding type of
 * region signal to use in data governance.
 */
export interface KeGovernanceTypedRegions {
  /**
   * Values are go/iii RegionCode in capital case. It is a good practice to
   * keep elements in this list unique, although not enforced. In case of
   * duplicated entries, they'll be treated as if there were only one entry of
   * the same value.
   */
  regions?: string[];
  /**
   * The particular type of region should be explicitly set to disambiguate.
   */
  regionType?:  | "UNKNOWN" | "FRONTEND_REGION_CODE" | "TRUSTED_LOCATION_VIEW_REGION_CODE";
}

/**
 * Accepts any non-empty value. This is meant for special cases allowing any
 * value or any composition to be valid in a slot. If you are thinking of using
 * this, please contact mrf-team@.
 */
export interface KnowledgeAnswersAnyType {
  /**
   * Contains data about current schema remodelings at this ValueType level.
   * For more information see go/meaning-remodeling-framework.
   */
  remodelings?: NlpMeaningMeaningRemodelings;
}

function serializeKnowledgeAnswersAnyType(data: any): KnowledgeAnswersAnyType {
  return {
    ...data,
    remodelings: data["remodelings"] !== undefined ? serializeNlpMeaningMeaningRemodelings(data["remodelings"]) : undefined,
  };
}

function deserializeKnowledgeAnswersAnyType(data: any): KnowledgeAnswersAnyType {
  return {
    ...data,
    remodelings: data["remodelings"] !== undefined ? deserializeNlpMeaningMeaningRemodelings(data["remodelings"]) : undefined,
  };
}

/**
 * An attribute type configures a value whose type is intended to be a
 * attribute defined in the schema.
 */
export interface KnowledgeAnswersAttributeType {
  /**
   * Use in parsing: the value filled with must be in the list of this. If no
   * attribute ids are specified, this value can be filled with any attribute.
   */
  attribute?: string[];
  /**
   * If exist, the attribute will be applied on the given pivot slot. This
   * helps type checking when qrewrite constructs function calls with an
   * attribute-typed slot.
   */
  pivotEntitySlot?: string;
  /**
   * Contains data about current schema remodelings at this ValueType level.
   * For more information see go/meaning-remodeling-framework.
   */
  remodelings?: NlpMeaningMeaningRemodelings;
}

function serializeKnowledgeAnswersAttributeType(data: any): KnowledgeAnswersAttributeType {
  return {
    ...data,
    remodelings: data["remodelings"] !== undefined ? serializeNlpMeaningMeaningRemodelings(data["remodelings"]) : undefined,
  };
}

function deserializeKnowledgeAnswersAttributeType(data: any): KnowledgeAnswersAttributeType {
  return {
    ...data,
    remodelings: data["remodelings"] !== undefined ? deserializeNlpMeaningMeaningRemodelings(data["remodelings"]) : undefined,
  };
}

/**
 * A BooleanType configures a yes/no value.
 */
export interface KnowledgeAnswersBooleanType {
  /**
   * Contains data about current schema remodelings at this ValueType level.
   * For more information see go/meaning-remodeling-framework.
   */
  remodelings?: NlpMeaningMeaningRemodelings;
}

function serializeKnowledgeAnswersBooleanType(data: any): KnowledgeAnswersBooleanType {
  return {
    ...data,
    remodelings: data["remodelings"] !== undefined ? serializeNlpMeaningMeaningRemodelings(data["remodelings"]) : undefined,
  };
}

function deserializeKnowledgeAnswersBooleanType(data: any): KnowledgeAnswersBooleanType {
  return {
    ...data,
    remodelings: data["remodelings"] !== undefined ? deserializeNlpMeaningMeaningRemodelings(data["remodelings"]) : undefined,
  };
}

/**
 * A CollectionType configures a value whose type is intended to be a
 * collection.
 */
export interface KnowledgeAnswersCollectionType {
  /**
   * The collection this value is filled with must be one of these collections
   * (denoted by a /collection/* id). If no collections are specified, this
   * value can be filled with any collection.
   */
  collection?: string[];
  /**
   * Contains data about current schema remodelings at this ValueType level.
   * For more information see go/meaning-remodeling-framework.
   */
  remodelings?: NlpMeaningMeaningRemodelings;
}

function serializeKnowledgeAnswersCollectionType(data: any): KnowledgeAnswersCollectionType {
  return {
    ...data,
    remodelings: data["remodelings"] !== undefined ? serializeNlpMeaningMeaningRemodelings(data["remodelings"]) : undefined,
  };
}

function deserializeKnowledgeAnswersCollectionType(data: any): KnowledgeAnswersCollectionType {
  return {
    ...data,
    remodelings: data["remodelings"] !== undefined ? deserializeNlpMeaningMeaningRemodelings(data["remodelings"]) : undefined,
  };
}

/**
 * A CompoundType configures a value composed of multiple answer values.
 */
export interface KnowledgeAnswersCompoundType {
  /**
   * Contains data about current schema remodelings at this ValueType level.
   * For more information see go/meaning-remodeling-framework.
   */
  remodelings?: NlpMeaningMeaningRemodelings;
}

function serializeKnowledgeAnswersCompoundType(data: any): KnowledgeAnswersCompoundType {
  return {
    ...data,
    remodelings: data["remodelings"] !== undefined ? serializeNlpMeaningMeaningRemodelings(data["remodelings"]) : undefined,
  };
}

function deserializeKnowledgeAnswersCompoundType(data: any): KnowledgeAnswersCompoundType {
  return {
    ...data,
    remodelings: data["remodelings"] !== undefined ? deserializeNlpMeaningMeaningRemodelings(data["remodelings"]) : undefined,
  };
}

export interface KnowledgeAnswersContainerType {
  slotNames?: string[];
}

/**
 * A DateType configures a value whose type is intended to be a date.
 * LINT.IfChange Next id: 16
 */
export interface KnowledgeAnswersDateType {
  /**
   * If true, will allow all resolutions that are ranges.
   */
  allowAllRangeResolutions?: boolean;
  /**
   * If true, overrides all other options in this message and allows any kind
   * of DateTime annotation.
   */
  allowAllResolutions?: boolean;
  /**
   * If true, will allow all resolutions except holidays.
   */
  allowAllResolutionsExceptHolidays?: boolean;
  /**
   * If true, will allow resolutions that aren't contiguous sequences of 4
   * digits annotated as 24-hr times. These are often mis-interpreted years or
   * postcodes.
   */
  allowAllResolutionsWithout4digit24hrTime?: boolean;
  /**
   * If true, will allow resolutions without an explicit hour. Symbolic ranges
   * such as [this evening] are not considered as explicit hour, but the range
   * [1-3pm] is considered as explicit.
   */
  allowAllResolutionsWithoutTime?: boolean;
  /**
   * If true, will parse a mention to DateTime of resolution day. This allows
   * parsing strings like "August 30th", "2012-12-25";
   */
  allowDayResolution?: boolean;
  /**
   * If true, will allow day resolutions except holidays or ordinal numbers,
   * such as "today", "December 13", but "Christmas", "first" are not allowed.
   */
  allowDayResolutionExceptHolidaysOrOrdinal?: boolean;
  /**
   * If true, will allow resolutions with an explicit hour such as "8am",
   * "5pm".
   */
  allowHourResolution?: boolean;
  /**
   * If true, will parse a mention to DateTime of resolution month. This allows
   * parsing strings like "this August", "2012-12";
   */
  allowMonthResolution?: boolean;
  /**
   * If true, will allow "now" resolutions, but not any other time
   */
  allowNowResolution?: boolean;
  /**
   * If true, will allow symbolic time resolutions such as "tonight".
   */
  allowSymbolicTime?: boolean;
  /**
   * If true, will allow time resolutions without an explicit timezone.
   */
  allowTimeResolutionsWithoutExplicitTimezone?: boolean;
  /**
   * If true, will parse a mention to DateTime of resolution year. This allows
   * parsing strings like "Next year ", "2010";
   */
  allowYearResolution?: boolean;
  /**
   * Contains data about current schema remodelings at this ValueType level.
   * For more information see go/meaning-remodeling-framework.
   */
  remodelings?: NlpMeaningMeaningRemodelings;
  subType?:  | "DATE_TIME_DEFAULT" | "DATE_ONLY" | "DATE_WITH_DAY_OF_WEEK" | "DATE_YEAR_ONLY" | "DATE_MONTH_ONLY";
}

function serializeKnowledgeAnswersDateType(data: any): KnowledgeAnswersDateType {
  return {
    ...data,
    remodelings: data["remodelings"] !== undefined ? serializeNlpMeaningMeaningRemodelings(data["remodelings"]) : undefined,
  };
}

function deserializeKnowledgeAnswersDateType(data: any): KnowledgeAnswersDateType {
  return {
    ...data,
    remodelings: data["remodelings"] !== undefined ? deserializeNlpMeaningMeaningRemodelings(data["remodelings"]) : undefined,
  };
}

export interface KnowledgeAnswersDependencyType {
  containerType?: KnowledgeAnswersContainerType;
  intersectType?: KnowledgeAnswersIntersectType;
  /**
   * Contains data about current schema remodelings at this ValueType level.
   * For more information see go/meaning-remodeling-framework.
   */
  remodelings?: NlpMeaningMeaningRemodelings;
  sameType?: KnowledgeAnswersSameType;
  unionType?: KnowledgeAnswersUnionType;
}

function serializeKnowledgeAnswersDependencyType(data: any): KnowledgeAnswersDependencyType {
  return {
    ...data,
    remodelings: data["remodelings"] !== undefined ? serializeNlpMeaningMeaningRemodelings(data["remodelings"]) : undefined,
  };
}

function deserializeKnowledgeAnswersDependencyType(data: any): KnowledgeAnswersDependencyType {
  return {
    ...data,
    remodelings: data["remodelings"] !== undefined ? deserializeNlpMeaningMeaningRemodelings(data["remodelings"]) : undefined,
  };
}

/**
 * How a piece of data was resolved through external data (either elsewhere in
 * the query, or from a previous query). Examples: [obama and his age] -> "his"
 * is resolved from the Obama entity obama -> "he" is resolved from the Obama
 * entity starbucks -> Q2 is resolved from the list of shops
 */
export interface KnowledgeAnswersDialogReferentialResolution {
  /**
   * True iff this ReferentialResolution is part of an intent and refers to the
   * full MRF subtree (rather than just the intent).
   */
  refersToFullMrf?: boolean;
  resolutionType?:  | "NONE" | "SAFT_PRONOUN" | "NOUN_PHRASE" | "LOCAL_SEMANTIC_FUNCTION_MERGE" | "CONTEXTUAL_SUBGRAMMAR_ANNOTATION" | "RIPPLES_LIST_SELECTION";
}

/**
 * A DurationType configures a value whose type is a duration.
 */
export interface KnowledgeAnswersDurationType {
  /**
   * Range constraint limits the set of durations accepted. The values of the
   * range are in milliseconds. Currently, this constraint is only enforced in
   * Loose Parser.
   */
  rangeConstraint?: KnowledgeAnswersRangeConstraint;
  /**
   * Contains data about current schema remodelings at this ValueType level.
   * For more information see go/meaning-remodeling-framework.
   */
  remodelings?: NlpMeaningMeaningRemodelings;
}

function serializeKnowledgeAnswersDurationType(data: any): KnowledgeAnswersDurationType {
  return {
    ...data,
    remodelings: data["remodelings"] !== undefined ? serializeNlpMeaningMeaningRemodelings(data["remodelings"]) : undefined,
  };
}

function deserializeKnowledgeAnswersDurationType(data: any): KnowledgeAnswersDurationType {
  return {
    ...data,
    remodelings: data["remodelings"] !== undefined ? deserializeNlpMeaningMeaningRemodelings(data["remodelings"]) : undefined,
  };
}

/**
 * An EntityType configures a value whose type is intended to be an entity.
 * Entities may be specified using either the collection(s) to which they
 * belong, or explicitly via a list of KG-ids. Both collections and ids can be
 * specified, in which case the type will be the union of the id(s) and all mids
 * within the collection(s). Next available tag: 9
 */
export interface KnowledgeAnswersEntityType {
  /**
   * This field specifies that containing entity must be: - in *any*
   * 'collection' if 'in_all_collections' is false (default) - in *every*
   * 'collection' if 'in_all_collections' is true. The collection field contains
   * strings of the form '/collection/'. If no collections are specified, this
   * value can be filled with any entity. A collection specified as an empty
   * string has a special meaning for Aqua induction, which is that the type
   * includes all entities.
   */
  collection?: string[];
  /**
   * The entity that this value is filled with must not be any of these
   * collections (denoted by a /collection/* id). This restriction does not
   * affect parsing; it is used only to filter attributes in the extraction
   * flow.
   */
  excludedCollection?: string[];
  /**
   * The entity that this value is filled with must be one of the following
   * explicitly specified KG-ids.
   */
  id?: string[];
  /**
   * The entity that this value is filled with must be of the explicit type
   * and/or contain the explicitly specified id. This field can not be used for
   * kg mids, which should directly use the id field above.
   */
  identifier?: KnowledgeAnswersIntentQueryIdentifier[];
  inAllCollections?: boolean;
  /**
   * If this is set to true for a slot and the entity is a location, the
   * latitude and longitude will be available in variables $SlotName_Latitude
   * and $SlotName_Longitude, respectively. The latitude and longitude data
   * comes from KG.
   */
  includeGeolocationData?: boolean;
  /**
   * Contains data about current schema remodelings at this ValueType level.
   * For more information see go/meaning-remodeling-framework.
   */
  remodelings?: NlpMeaningMeaningRemodelings;
  /**
   * This field is deprecated. It is not removed completely since this proto
   * was saved with this field in proto text files used by the Grammy tool.
   */
  stbrDomain?:  | "UNKNOWN" | "DEFAULT" | "SPORTS" | "FINANCE"[];
}

function serializeKnowledgeAnswersEntityType(data: any): KnowledgeAnswersEntityType {
  return {
    ...data,
    remodelings: data["remodelings"] !== undefined ? serializeNlpMeaningMeaningRemodelings(data["remodelings"]) : undefined,
  };
}

function deserializeKnowledgeAnswersEntityType(data: any): KnowledgeAnswersEntityType {
  return {
    ...data,
    remodelings: data["remodelings"] !== undefined ? deserializeNlpMeaningMeaningRemodelings(data["remodelings"]) : undefined,
  };
}

/**
 * Modifiers decorate a Meaning Expression (i.e. intent FunctionCall) with
 * signals that depend on the source language's grammar and syntax. See
 * go/intent-modifiers for details. NOTE: Modifiers don't necessarily impact
 * go/intent-resolution semantics. LINT.IfChange
 */
export interface KnowledgeAnswersIntentModifiers {
  /**
   * Language of all of the non-annotation tokens of the query interpretation,
   * if it is different than |language|. This can happen with English smearing,
   * e.g. [height rousseau] will trigger as "fr" when issued in fr/FR, but
   * really the language is "en". This can also happen when we have extra
   * information about the language model, e.g. language="zh",
   * alternate_language="zh-Hant".
   */
  alternateLanguage?: string;
  definiteness?:  | "UNKNOWN_DEFINITENESS" | "DEFINITE" | "INDEFINITE";
  /**
   * Language of parsed query.
   */
  language?: string;
  /**
   * Since there's only IMPERATIVE, consider using Marker.command instead.
   */
  mood?:  | "UNKNOWN_MOOD" | "IMPERATIVE";
  plurality?:  | "UNKNOWN_PLURALITY" | "SINGULAR" | "PLURAL";
  /**
   * Whether or not the question is a polar (yes/no) question.
   */
  polarQuestion?: boolean;
  /**
   * Sentiment analysis attached to an intent implies the sentiment user
   * expressed behind that query. This is generated by the Empathetic Servlet in
   * the QRewrite.
   */
  sentiment?: SentimentSentiment;
  tense?:  | "UNKNOWN_TENSE" | "PRESENT" | "FUTURE" | "PAST";
}

/**
 * Signals coming from the Annotation Layer of TUIG. See more details at
 * http://go/unified-intent-generation-apis.
 */
export interface KnowledgeAnswersIntentQueryAnnotationLayerSignals {
  customVehicleActionArgumentAnnotatorSignals?: KnowledgeAnswersIntentQueryCustomVehicleActionArgumentAnnotatorSignals;
  freetextAnnotationSignals?: KnowledgeAnswersIntentQueryFreetextAnnotationSignals;
  nimbleAnnotationSignals?: KnowledgeAnswersIntentQueryNimbleAnnotationSignals;
  ntprAnnotationSignals?: KnowledgeAnswersIntentQueryNTPRAnnotationSignals;
  qrefAnnotationSignals?: KnowledgeAnswersIntentQueryQrefAnnotationSignals;
  semanticAnnotationSignals?: KnowledgeAnswersIntentQuerySemanticAnnotationSignals;
  teleportArgumentAnnotatorSignals?: KnowledgeAnswersIntentQueryTeleportArgumentAnnotatorSignals;
}

export interface KnowledgeAnswersIntentQueryArgPath {
  components?: KnowledgeAnswersIntentQueryArgPathComponent[];
}

/**
 * LINT.IfChange(ArgPath) Given a FunctionCall and an Argument somewhere in it,
 * an ArgPath is a list of name-index pairs that uniquely determines the path
 * down to that Argument. For each pair, the |index|, starting from zero,
 * distinguishes between "sibling" (i.e. belonging to the same sub-FunctionCall)
 * Arguments with the same name. For example, given the following FunctionCall:
 * A(X=D(W=5), Z=B(Z=6), Z=C(Y=7)) The path to the Z=6 argument is {{"Z", 0},
 * {"Z", 0}} It's the first of two Z "siblings" under A, then the only Z under
 * B. The path to the Y=7 argument is {{"Z", 1}, {"Y", 0}} It's the second of
 * two Z "siblings" under A, then the only Y under C. The path to the Z=B(...)
 * argument is {{"Z", 0}} It's the first of two Z "siblings" under A.
 */
export interface KnowledgeAnswersIntentQueryArgPathComponent {
  argName?: string;
  index?: number;
}

/**
 * A message representing the function argument. Next ID: 9 Important: If you
 * add new fields that do not reflect signals data, but actual semantics of the
 * FunctionCall, please also update CreateFuncallCopyWithoutSignals and
 * CreateFuncallCopyWithArgumentSignals in function_call_utils. LINT.IfChange
 */
export interface KnowledgeAnswersIntentQueryArgument {
  /**
   * This field is used inside Aqua and outside Aqua for identifying the token
   * indices and/or byte offsets of this argument
   */
  evalData?: NlpSemanticParsingAnnotationEvalData;
  /**
   * Eval_data was not derived at parsing time (i.e. is not expected to be
   * produced by the IG), but heuristically determined by matching the
   * ArgumentValue to an annotation/query fragment.
   */
  heuristicEvalData?: NlpSemanticParsingAnnotationEvalData;
  /**
   * Slot schema key for this Argument. Note: This is still under development
   * and not available for general use. Contact meaning-platform-eng@ for
   * questions. Note: Currently MeaningSchemaSlotKey proto has both mid and
   * unique_id. In future, only mid will be present in it. We are in the process
   * of moving "unique_id" out of it. See (b/168907943). Note: The logged
   * version of intent_query will only have "mid" populated in it to save space
   * and avoid data duplication.
   */
  key?: KnowledgeAnswersMeaningSchemaSlotKey;
  /**
   * A flattened representation of all intent modifiers that apply to this
   * argument.
   */
  modifiers?: KnowledgeAnswersIntentModifiers;
  /**
   * Name of this argument. If this Argument is part of a FunctionCall, it must
   * have a name or it is not well-formed. If this Argument is from an
   * Annotator, the name field should be empty.
   */
  name?: string;
  /**
   * Signals associated with this argument.
   */
  signals?: KnowledgeAnswersIntentQueryArgumentSignals;
  /**
   * The value of this argument.
   */
  value?: KnowledgeAnswersIntentQueryArgumentValue;
}

function serializeKnowledgeAnswersIntentQueryArgument(data: any): KnowledgeAnswersIntentQueryArgument {
  return {
    ...data,
    key: data["key"] !== undefined ? serializeKnowledgeAnswersMeaningSchemaSlotKey(data["key"]) : undefined,
    signals: data["signals"] !== undefined ? serializeKnowledgeAnswersIntentQueryArgumentSignals(data["signals"]) : undefined,
    value: data["value"] !== undefined ? serializeKnowledgeAnswersIntentQueryArgumentValue(data["value"]) : undefined,
  };
}

function deserializeKnowledgeAnswersIntentQueryArgument(data: any): KnowledgeAnswersIntentQueryArgument {
  return {
    ...data,
    key: data["key"] !== undefined ? deserializeKnowledgeAnswersMeaningSchemaSlotKey(data["key"]) : undefined,
    signals: data["signals"] !== undefined ? deserializeKnowledgeAnswersIntentQueryArgumentSignals(data["signals"]) : undefined,
    value: data["value"] !== undefined ? deserializeKnowledgeAnswersIntentQueryArgumentValue(data["value"]) : undefined,
  };
}

/**
 * NextId: 11
 */
export interface KnowledgeAnswersIntentQueryArgumentProvenance {
  /**
   * If populated, the current query contains an anaphor that refers to the
   * value. For example: U: Weather in Paris. [Weather(location=paris)] G: 65
   * degrees and sunny. U: How many people live there? [Population(city=paris)]
   * The "there" in the current query would have the "anaphor" field set. NOTE:
   * after a string rewrite this field will not be populated anymore if the
   * rewrite replaced the anaphor with the corresponding value. For example, if
   * we rewrite [How many people there] to [How many people in Paris], the
   * CurrentQuerySignals for "paris" will not contain an "anaphor" message
   * anymore in the following turns. It will only contain an eval_data for the
   * span that corresponds to "paris" in the query.
   */
  anaphor?: KnowledgeAnswersIntentQueryArgumentProvenanceQueryAnaphor;
  attentionalEntity?: KnowledgeAnswersIntentQueryArgumentProvenanceAttentionalEntity;
  /**
   * NOTE: PreviousQuery is used for values that originate directly from QRef
   * entities annotated in the user query. AttentionalEntity is used for values
   * that come from the system (entities published by a dialog). These values
   * could also originate from an entity annotated by QRef in the query, but
   * this is not necessarily the case. SearchAnswerValue is used for values that
   * come from the system as part of the answer of the user query. For example:
   * U: Wife of Barack Obama G: Barack Obama's wife is Michelle Obama Here
   * "Barack Obama" can have an ArgumentProvenance of PreviousQuery, or
   * AttentionalEntity if a dialog publishes that entity and the interpretation
   * pulls the value from it. "Michelle Obama" can have an ArgumentProvenance of
   * SearchAnswerValue, or AttentionalEntity if the dialog publishes that entity
   * and the interpretation pulls the value it.
   */
  currentQuery?: KnowledgeAnswersIntentQueryArgumentProvenanceCurrentQuery;
  injectedContextualSchema?: KnowledgeAnswersIntentQueryArgumentProvenanceInjectedContextualSchema;
  previousQuery?: KnowledgeAnswersIntentQueryArgumentProvenancePreviousQuery;
  previousResponseMeaning?: KnowledgeAnswersIntentQueryArgumentProvenancePreviousResponseMeaning;
  previousTaskState?: KnowledgeAnswersIntentQueryArgumentProvenancePreviousTaskState;
  searchAnswerValue?: KnowledgeAnswersIntentQueryArgumentProvenanceSearchAnswerValue;
}

function serializeKnowledgeAnswersIntentQueryArgumentProvenance(data: any): KnowledgeAnswersIntentQueryArgumentProvenance {
  return {
    ...data,
    attentionalEntity: data["attentionalEntity"] !== undefined ? serializeKnowledgeAnswersIntentQueryArgumentProvenanceAttentionalEntity(data["attentionalEntity"]) : undefined,
    previousQuery: data["previousQuery"] !== undefined ? serializeKnowledgeAnswersIntentQueryArgumentProvenancePreviousQuery(data["previousQuery"]) : undefined,
    searchAnswerValue: data["searchAnswerValue"] !== undefined ? serializeKnowledgeAnswersIntentQueryArgumentProvenanceSearchAnswerValue(data["searchAnswerValue"]) : undefined,
  };
}

function deserializeKnowledgeAnswersIntentQueryArgumentProvenance(data: any): KnowledgeAnswersIntentQueryArgumentProvenance {
  return {
    ...data,
    attentionalEntity: data["attentionalEntity"] !== undefined ? deserializeKnowledgeAnswersIntentQueryArgumentProvenanceAttentionalEntity(data["attentionalEntity"]) : undefined,
    previousQuery: data["previousQuery"] !== undefined ? deserializeKnowledgeAnswersIntentQueryArgumentProvenancePreviousQuery(data["previousQuery"]) : undefined,
    searchAnswerValue: data["searchAnswerValue"] !== undefined ? deserializeKnowledgeAnswersIntentQueryArgumentProvenanceSearchAnswerValue(data["searchAnswerValue"]) : undefined,
  };
}

/**
 * The value is carried over from an attentional entity. For example, in a
 * dialog about a movie that publishes an attentional entity for /m/matrix: U:
 * What is the cast. [Cast(location=/m/matrix)] G: The cast includes Keanu
 * Reeves and others. U: Great, buy some tickets. [BuyTickets(movie=/m/matrix)]
 * On the second user query, the "movie" argument would have a provenance of
 * ATTENTIONAL_ENTITY.
 */
export interface KnowledgeAnswersIntentQueryArgumentProvenanceAttentionalEntity {
  /**
   * This key can be used to recover the attentional entity from the
   * corresponding attentional_entities::EntityCache.
   */
  attentionalEntityKey?: bigint;
  /**
   * Source information from the AttentionalEntityReader.
   */
  mentionProperties?: AttentionalEntitiesMentionProperties;
}

function serializeKnowledgeAnswersIntentQueryArgumentProvenanceAttentionalEntity(data: any): KnowledgeAnswersIntentQueryArgumentProvenanceAttentionalEntity {
  return {
    ...data,
    attentionalEntityKey: data["attentionalEntityKey"] !== undefined ? String(data["attentionalEntityKey"]) : undefined,
    mentionProperties: data["mentionProperties"] !== undefined ? serializeAttentionalEntitiesMentionProperties(data["mentionProperties"]) : undefined,
  };
}

function deserializeKnowledgeAnswersIntentQueryArgumentProvenanceAttentionalEntity(data: any): KnowledgeAnswersIntentQueryArgumentProvenanceAttentionalEntity {
  return {
    ...data,
    attentionalEntityKey: data["attentionalEntityKey"] !== undefined ? BigInt(data["attentionalEntityKey"]) : undefined,
    mentionProperties: data["mentionProperties"] !== undefined ? deserializeAttentionalEntitiesMentionProperties(data["mentionProperties"]) : undefined,
  };
}

/**
 * NOTE: These comments should stay in sync with the comments in
 * logs/proto/knowledge/interpretation/intent_query.proto LINT.IfChange The
 * argument comes from the current query. For example: U: Book a hotel in Paris.
 * [BookHotel(location=/m/paris)] The "location" argument would have a
 * provenance of CURRENT_QUERY.
 */
export interface KnowledgeAnswersIntentQueryArgumentProvenanceCurrentQuery {
  /**
   * The span(s) in the query where the value comes from. Note that if the
   * argument is split across the current and previous query, this message
   * should *NOT* be populated. Please use PreviousQuery below, populating it's
   * eval-data fields accordingly.
   */
  evalData?: NlpSemanticParsingAnnotationEvalData[];
  neuralLocationAnnotator?: KnowledgeAnswersIntentQueryArgumentProvenanceNeuralLocationAnnotator;
}

/**
 * The value is carried from injected contextual schema. Such schemas can be
 * injected by go/qu-biasing-config for particular clients when their biasing
 * configs are triggered for their traffic Config: (if QRewrite source ==
 * CARS_IMMERSIVE then inject LocalCarListings and Cars) Context: (QRewrite
 * source == CARS_IMMERSIVE) U: Red [LocalCarListings(Cars() &
 * RelatedTo(/m/red))] In this case, both LocalCarListings and Cars are spanless
 * injected contextual schemas.
 */
export interface KnowledgeAnswersIntentQueryArgumentProvenanceInjectedContextualSchema {
}

/**
 * The value is used for CurrentQuery.annotator and PreviousQuery.annotator to
 * indicate what annotator annotated the argument
 */
export interface KnowledgeAnswersIntentQueryArgumentProvenanceNeuralLocationAnnotator {
}

/**
 * The value is carried over from either the previous winning IntentQuery or an
 * entity annotated by QRef in a previous query. For example: U: How old is
 * Obama. [Age(person=/m/obama)] G: Barack Obama is 56 years old. U: Who is his
 * wife. [Spouse(person=/m/obama)] The "person" argument would have a provenance
 * of PREVIOUS_QUERY. However, if a dialog publishes an attentional entity for
 * "Obama", the "person" argument can have a provenance of ATTENTIONAL_ENTITY
 * instead. This includes arguments with provenance that spans both the current
 * and previous query.
 */
export interface KnowledgeAnswersIntentQueryArgumentProvenancePreviousQuery {
  /**
   * The span(s) in the current query where the value comes from. This is used
   * when the argument spans both the current and previous query. Eg jfk death
   * -> [death, when] spans both queries.
   */
  currentQueryEvalData?: NlpSemanticParsingAnnotationEvalData[];
  /**
   * The span(s) in the query where the value comes from.
   */
  evalData?: NlpSemanticParsingAnnotationEvalData[];
  /**
   * The event ID of the query where this value was pulled from.
   */
  eventId?: EventIdMessage;
  neuralLocationAnnotator?: KnowledgeAnswersIntentQueryArgumentProvenanceNeuralLocationAnnotator;
  role?: KnowledgeAnswersIntentQueryArgumentProvenancePreviousQueryRole;
  source?:  | "UNKNOWN" | "QUERY_STRING" | "INTERPRETATION" | "QUERY_JOIN" | "PROMPT";
}

function serializeKnowledgeAnswersIntentQueryArgumentProvenancePreviousQuery(data: any): KnowledgeAnswersIntentQueryArgumentProvenancePreviousQuery {
  return {
    ...data,
    eventId: data["eventId"] !== undefined ? serializeEventIdMessage(data["eventId"]) : undefined,
  };
}

function deserializeKnowledgeAnswersIntentQueryArgumentProvenancePreviousQuery(data: any): KnowledgeAnswersIntentQueryArgumentProvenancePreviousQuery {
  return {
    ...data,
    eventId: data["eventId"] !== undefined ? deserializeEventIdMessage(data["eventId"]) : undefined,
  };
}

/**
 * The role that this data played in the previous query.
 */
export interface KnowledgeAnswersIntentQueryArgumentProvenancePreviousQueryRole {
  intentId?: string;
  slotName?: string;
}

export interface KnowledgeAnswersIntentQueryArgumentProvenancePreviousResponseMeaning {
}

/**
 * Value is derived from previous task state (go/taskstates).
 */
export interface KnowledgeAnswersIntentQueryArgumentProvenancePreviousTaskState {
  /**
   * Argument names in the DialogIntentState that the argument corresponds to.
   * This is repeated so it can handle complex argument update paths. (ordered
   * from outermost argument to innermost argument)
   */
  argumentName?: string[];
  /**
   * The span(s) in the current query (if any) used to resolve the previous
   * query's DIS. Example: U: Barack Obama G: Do you want his age or his height?
   * U: The first one. G: Age(/m/obama) In this example, the intent is derived
   * from the previous query's DIS, but also needs to be resolved in the current
   * query since the user was presented with multiple options.
   */
  currentQueryEvalData?: NlpSemanticParsingAnnotationEvalData[];
  /**
   * The id of the specific DialogIntentState instance that the argument
   * corresponds to.
   */
  dialogIntentStateId?: string;
  /**
   * Intent name of the DialogIntentState that the argument corresponds to.
   */
  intentName?: string;
  listCandidate?: KnowledgeAnswersIntentQueryArgumentProvenancePreviousTaskStateListCandidate;
  previousFunctionCall?: KnowledgeAnswersIntentQueryArgumentProvenancePreviousTaskStatePreviousFunctionCall;
}

/**
 * The value is carried over from a field_candidate in a DialogIntentState. For
 * example: U: Send a message to John. G: Which John do you want to message? U:
 * John A. [ListPresentationIntent(contact_disambiguation.person=0)] On the
 * second user query, the "contact_disambiguation.person" argument would have a
 * provenance of PREVIOUS_TASK_STATE_LIST_CANDIDATE.
 */
export interface KnowledgeAnswersIntentQueryArgumentProvenancePreviousTaskStateListCandidate {
  /**
   * The presented_index of the field_candidate in the DialogIntentState
   * field_signals that the argument corresponds to.
   */
  candidateIndex?: number;
}

/**
 * The value was carried over from the previous function call. For example: U:
 * Create an alarm titled "Wake". [CreateAlarm(title=Wake)] G: Sure, at what
 * time? U: 5 am. [CreateAlarm(title=Wake,time=5am)] On the second user query,
 * the "title" argument would have a provenance of PREVIOUS_TASK_STATE.
 */
export interface KnowledgeAnswersIntentQueryArgumentProvenancePreviousTaskStatePreviousFunctionCall {
}

/**
 * Signals about an anaphor in the query: for example an occurrence of the
 * pronoun "it".
 */
export interface KnowledgeAnswersIntentQueryArgumentProvenanceQueryAnaphor {
  /**
   * If populated, the spans in the current query where this value was
   * annotated. This is a repeated field because some values can be annotated
   * from a set of discontiguous spans (e.g. some intent phrases), but in most
   * cases this field will contain only one item or it will be empty (for values
   * inferred from context without the use of anaphora).
   */
  evalData?: NlpSemanticParsingAnnotationEvalData[];
}

/**
 * The value was carried over from a SearchAnswerValue triggered by a previous
 * query (go/search-answer-values). For example: U: Movies with Tom Cruise.
 * [Movies(actor=/m/tom_cruise)] G: Tom Cruise's movies include Top Gun, The
 * Mummy, and 52 others. U: Reviews for the second one.
 * [Reviews(movie=/m/the_mummy)] The "movie" argument in the last query would
 * have a provenance of SEARCH_ANSWER_VALUE.
 */
export interface KnowledgeAnswersIntentQueryArgumentProvenanceSearchAnswerValue {
  /**
   * This identifies the SearchAnswerValues where this value was pulled from.
   */
  eventId?: EventIdMessage;
  /**
   * Each SearchAnswerValue can have a primary value and a list of metadata
   * values. If this index is set, this value was pulled from the metadata value
   * at this index, otherwise it was pulled from the primary value.
   */
  metadataValueIndex?: number;
  /**
   * The display text of this answer value. It's taken from the search answer
   * value display text if present, or the canonical name if it's an entity.
   */
  text?: string;
  /**
   * The index of the SearchAnswerValue where this value was pulled from.
   */
  valueIndex?: number;
}

function serializeKnowledgeAnswersIntentQueryArgumentProvenanceSearchAnswerValue(data: any): KnowledgeAnswersIntentQueryArgumentProvenanceSearchAnswerValue {
  return {
    ...data,
    eventId: data["eventId"] !== undefined ? serializeEventIdMessage(data["eventId"]) : undefined,
  };
}

function deserializeKnowledgeAnswersIntentQueryArgumentProvenanceSearchAnswerValue(data: any): KnowledgeAnswersIntentQueryArgumentProvenanceSearchAnswerValue {
  return {
    ...data,
    eventId: data["eventId"] !== undefined ? deserializeEventIdMessage(data["eventId"]) : undefined,
  };
}

/**
 * A message representing the signals associated with an argument. NEXT ID TO
 * USE: 57 For
 * //depot/google3/logs/proto/knowledge/interpretation/intent_query.proto in the
 * "ThenChange", fields under Argument.signals in the serving proto are stored
 * directly under Argument on the logging side. For example, see
 * http://google3/nlp/semantic_parsing/data_management/logs/web_logs/semantic_logging_converters/semantic_logging_request_argument_converter.cc?l=58&rcl=322925428.
 * LINT.IfChange
 */
export interface KnowledgeAnswersIntentQueryArgumentSignals {
  /**
   * Whether this argument was added by CloseAnswers in Postref. This bit is
   * used to mark the corresponding interpretation/intent query as such by
   * setting is_close_interpretation bit.
   */
  addedByCloseAnswers?: boolean;
  /**
   * For this argument, backend performed fuzzy match.
   */
  allowedFuzzyMatch?: boolean;
  /**
   * Relationships between entities
   */
  annotatedRelationship?: LogsSemanticInterpretationIntentQueryWebrefEntityRelationship[];
  /**
   * Signals to facilitate orchestration of TUIG annotations.
   */
  annotationLayerSignals?: KnowledgeAnswersIntentQueryAnnotationLayerSignals;
  /**
   * One or more ChainIds from a ChainAnnotation whose "organization_mid"
   * matches the MID. As of 2021-01 multiple chain_ids may be specified if the
   * organization for MID controls multiple chains. See
   * go/chains-lckp-robust-triggering for motivation.
   */
  chainId?: LocalsearchChainId[];
  /**
   * If the literal.obj_type of the argument value is ID (Entity), this stores
   * cluster scoring information for that entity, if the entity belongs to a
   * cluster.
   */
  clusterInfo?: QualityViewsExtractionClusterInfo;
  /**
   * If the literal.obj_type of the argument value is ID (Entity), this
   * represents the collection that the entity in this argument is a member of.
   */
  collectionMembership?: KnowledgeAnswersIntentQueryCollectionMembership[];
  /**
   * How this argument was resolved through context from a previous query.
   * Examples: obama -> "he" is resolved from the Obama entity starbucks -> Q2
   * is resolved from the list of shops (Attentional Entities)
   */
  contextResolution?:  | "NONE" | "SAFT_PRONOUN" | "NOUN_PHRASE" | "LOCAL_SEMANTIC_FUNCTION_MERGE" | "CONTEXTUAL_SUBGRAMMAR_ANNOTATION";
  /**
   * If the literal.obj_type of the argument value is ID (Entity), this
   * represents freebase types of the entity in this argument.
   */
  deprecatedFreebaseType?: string[];
  /**
   * A list of mids that "support" this argument in voting, i.e, results that
   * support these mids will be treated as if they support the argument. This
   * field has been deprecated in favor of related_entity. b/27363861
   */
  deprecatedSupportingMid?: string[];
  /**
   * Signals about what other entities this entity implies / is implied by.
   * This is useful for grounding. Example: b/138388207: suppressing song
   * intents if the artist entity doesn't link to the song title. This value
   * specifies the order of annotations in a QRef annotation chain so they can
   * refer to each other.
   */
  entityNumber?: number;
  /**
   * Signals about what other entities this entity implies / is implied by.
   * This is useful for grounding. Example: b/138388207: suppressing song
   * intents if the artist entity doesn't link to the song title.
   */
  entityRelationship?: NlpSemanticParsingQRefAnnotationEntityRelationship[];
  /**
   * Status indicating whether the user has completely expressed the semantics
   * of the argument.
   */
  expressionStatus?: NlpSemanticParsingExpressionStatus;
  /**
   * Whether the argument entity comes from a manual graphic symbol annotation.
   * This is later used as a heuristic for poor web result quality.
   */
  fromManualSymbolAnnotation?: boolean;
  /**
   * Whether the argument entity comes from a graphic symbol annotation. This
   * is later used as a heuristic for poor web result quality.
   */
  fromSymbolAnnotation?: boolean;
  /**
   * The gaia id for the entity (person or plus page).
   */
  gaiaId?: bigint;
  groundingSignals?: KnowledgeAnswersIntentQueryGroundingSignals;
  /**
   * If the argument is entity, the ungrounded type the entity is. For example,
   * the entity argument is /m/0p83l (Jasmine), the value of this field should
   * be "Plant" if it is present.
   */
  isAUngroundedTypeOf?: string;
  /**
   * If true, the value of the argument is populated with the default value
   * specified by the system if the value can't be inferred from the input
   * query. In IntentConfig case, the default value is specified by using
   * IntentConfig.slot.default_value.
   */
  isDefaultValue?: boolean;
  /**
   * Set when the argument has an enum value - a normalized_string_type from
   * the intent catalog.
   */
  isEnum?: boolean;
  /**
   * Set when the eval_data was not derived at parsing time, but heuristically
   * determined by matching the ArgumentValue to an annotation/query fragment.
   */
  isEvalDataHeuristic?: boolean;
  /**
   * Whether this annotation was propagated as part of a Genie rewrite
   * (go/genie-aqua).
   */
  isGenieAnnotation?: boolean;
  /**
   * Whether this argument was annotated by Intentgen QUIK model
   * (go/intentgen-quik)
   */
  isIntentgenAnnotation?: boolean;
  /**
   * Whether this argument was annotated by nimble (go/nimble-annotator)
   */
  isNimbleAnnotation?: boolean;
  /**
   * Entity location information (latitude/longitude) from freebase.
   */
  location?: GeostorePointProto;
  /**
   * The usual semantic role associated with the signal from lightweight tokens
   * attached to this argument span.
   */
  locationMarkersSignals?: KnowledgeAnswersIntentQueryLocationMarkersSignals;
  /**
   * Signals about the media entity for this argument.
   */
  mediaEntitySignals?: KnowledgeAnswersIntentQueryMediaEntitySignals;
  /**
   * List of QRef implied entities merged into this entity during parsing.
   * Clients should not rely on the order, as it is derivation-dependent.
   */
  mergedImpliedEntity?: KnowledgeAnswersIntentQueryImpliedEntity[];
  /**
   * For collection arguments, it is useful to save what was the original mid
   * that qref annotated. For example, if the collection is /collection/films,
   * we'll have the mid for /en/film here (/m/02vxn).
   */
  midEquivalentToCollection?: string;
  /**
   * Whether there were multiple equally good matches from
   * horizontal_list_selection.
   */
  multipleHorizontalListSelectionMatches?: boolean;
  /**
   * Signals derived from Munin Function call annotations.
   */
  muninSignals?: KnowledgeAnswersIntentQueryMuninSignals;
  /**
   * Additional signals for on-device annotations.
   */
  onDeviceAnnotationSignals?: KnowledgeAnswersIntentQueryOnDeviceAnnotationSignals;
  /**
   * The oyster feature id. NOTE: As of Mar 2017, the cell ID field of the
   * feature ID might not be set. See http://b/35447230#comment10
   */
  oysterId?: GeostoreFeatureIdProto;
  /**
   * Experiment ID for experiments that were used to parse this FunctionCall.
   * Empty indicates no experiments used.
   */
  parsedDueToExperiment?: string[];
  /**
   * Personal entities are compound entities made up of entities and their
   * attributes, where the entities can be compound too. E.g., "my father's
   * mother" can have a summary node annotation of "Mother(Father(Myself))"
   */
  personalEntity?: KnowledgeAnswersIntentQueryPersonalEntity[];
  /**
   * Information about where the value of this argument came from. For example,
   * it could have been explicitly provided in the query, pulled in from the
   * previous state, or pulled from attentional entities.
   */
  provenance?: KnowledgeAnswersIntentQueryArgumentProvenance[];
  /**
   * The QRef confidence score for an entity argument.
   */
  qrefConfidenceScore?: number;
  /**
   * The index of the QueryJoin interpretation from which this annotation is
   * taken. We copy over the value given by
   * nlp.semantic_parsing.annotators.QrefAnnotator. The value will be "-1" if
   * the annotation is coming from low confidence Qref annotations. NOTE - this
   * is generated from as QRef's interetation_number.
   */
  qrefInterpretationIndex?: number;
  /**
   * A copy of the span of canonical (raw) parser input text corresponding to
   * this annotation.
   */
  rawQueryText?: string;
  /**
   * List of entities that are semantically related to the argument as well as
   * details of the relationship.
   */
  relatedEntity?: NlpSemanticParsingRelatedEntity[];
  /**
   * Relatedness Matrix signals about this argument, e.g., query_popularity.
   */
  relatednessSignals?: KnowledgeAnswersIntentQueryRelatednessSignals;
  /**
   * Whether this argument was resolved through context from a previous query.
   * Examples: obama -> "he" is resolved from the Obama entity starbucks -> Q2
   * is resolved from the list of shops
   */
  resolvedFromContext?: boolean;
  /**
   * Whether this argument was resolved from a pronoun mention in the query.
   * Eg: [how old was obama when *he* became president]
   */
  resolvedFromPronoun?: boolean;
  /**
   * The list of result supports for this Argument.
   */
  resultSupport?: UniversalsearchNewPackerKnowledgeResultSupport[];
  /**
   * Signals derived from SAFT.
   */
  saftSignals?: KnowledgeAnswersIntentQuerySaftSignals;
  /**
   * Equivalent shopping ids for the argument.
   */
  shoppingIds?: KnowledgeAnswersIntentQueryShoppingIds;
  /**
   * go/stbr supportthis is an
   */
  supportTransferRules?: LogsSemanticInterpretationIntentQuerySupportTransferRule[];
  /**
   * Support Transfer signals for this entity.
   */
  supportTransferSignals?: KnowledgeAnswersIntentQuerySupportTransferSignals;
  /**
   * Type of ungrounded argument. It is exclusively used when
   * simple_value.ungrounded_value is populated.
   */
  ungroundedValueType?: KnowledgeAnswersValueType;
  /**
   * Webref entity index for this argument, necessary for interpreting the
   * relationship structure, and the list to index into. Specifically we need
   * this to understand qref implications since they edges are represented with
   * entity indexes.
   */
  webrefEntitiesIndex?: number;
  /**
   * This represents which list entities index refers to.
   */
  webrefListSource?:  | "UNSET" | "INTERPRETATION_LIST" | "ANNOTATION_LIST" | "CANDIDATE_LIST";
}

function serializeKnowledgeAnswersIntentQueryArgumentSignals(data: any): KnowledgeAnswersIntentQueryArgumentSignals {
  return {
    ...data,
    gaiaId: data["gaiaId"] !== undefined ? String(data["gaiaId"]) : undefined,
    mergedImpliedEntity: data["mergedImpliedEntity"] !== undefined ? data["mergedImpliedEntity"].map((item: any) => (serializeKnowledgeAnswersIntentQueryImpliedEntity(item))) : undefined,
    oysterId: data["oysterId"] !== undefined ? serializeGeostoreFeatureIdProto(data["oysterId"]) : undefined,
    provenance: data["provenance"] !== undefined ? data["provenance"].map((item: any) => (serializeKnowledgeAnswersIntentQueryArgumentProvenance(item))) : undefined,
    relatednessSignals: data["relatednessSignals"] !== undefined ? serializeKnowledgeAnswersIntentQueryRelatednessSignals(data["relatednessSignals"]) : undefined,
    resultSupport: data["resultSupport"] !== undefined ? data["resultSupport"].map((item: any) => (serializeUniversalsearchNewPackerKnowledgeResultSupport(item))) : undefined,
    shoppingIds: data["shoppingIds"] !== undefined ? serializeKnowledgeAnswersIntentQueryShoppingIds(data["shoppingIds"]) : undefined,
    ungroundedValueType: data["ungroundedValueType"] !== undefined ? serializeKnowledgeAnswersValueType(data["ungroundedValueType"]) : undefined,
  };
}

function deserializeKnowledgeAnswersIntentQueryArgumentSignals(data: any): KnowledgeAnswersIntentQueryArgumentSignals {
  return {
    ...data,
    gaiaId: data["gaiaId"] !== undefined ? BigInt(data["gaiaId"]) : undefined,
    mergedImpliedEntity: data["mergedImpliedEntity"] !== undefined ? data["mergedImpliedEntity"].map((item: any) => (deserializeKnowledgeAnswersIntentQueryImpliedEntity(item))) : undefined,
    oysterId: data["oysterId"] !== undefined ? deserializeGeostoreFeatureIdProto(data["oysterId"]) : undefined,
    provenance: data["provenance"] !== undefined ? data["provenance"].map((item: any) => (deserializeKnowledgeAnswersIntentQueryArgumentProvenance(item))) : undefined,
    relatednessSignals: data["relatednessSignals"] !== undefined ? deserializeKnowledgeAnswersIntentQueryRelatednessSignals(data["relatednessSignals"]) : undefined,
    resultSupport: data["resultSupport"] !== undefined ? data["resultSupport"].map((item: any) => (deserializeUniversalsearchNewPackerKnowledgeResultSupport(item))) : undefined,
    shoppingIds: data["shoppingIds"] !== undefined ? deserializeKnowledgeAnswersIntentQueryShoppingIds(data["shoppingIds"]) : undefined,
    ungroundedValueType: data["ungroundedValueType"] !== undefined ? deserializeKnowledgeAnswersValueType(data["ungroundedValueType"]) : undefined,
  };
}

/**
 * A message representing the value of an argument. All types in the "value"
 * oneof should have a corresponding field in the ValueType or OpaqueType protos
 * defined in knowledge/answers/config/value.proto. This is specified by
 * annotating each ArgumentValue type with options of the form (value_type_name)
 * = A unit test ensure that this field is set and is valid for all types in
 * ArgumentValue. A small number of special cases (such as funcall and
 * simple_value) are allowed to omit the annotation. See
 * intent_query_proto_test.cc for details. Note: If you are trying to add a new
 * OpaqueType, stop; OpaqueType is deprecated, refer to go/opaque_type for
 * details. If you think this is the only way to implement your feature, attend
 * an office hours (go/meaning-help) and discuss with the MRF team. Next Id: 41
 */
export interface KnowledgeAnswersIntentQueryArgumentValue {
  /**
   * Custom type used by actions-on-google in-dialog queries. See
   * go/3p-custom-intents-wrt-meaning-catalog
   */
  aogSlot?: NlpSemanticParsingProtoActionsOnGoogleAogSlot;
  /**
   * Device actions custom types.
   */
  appAnnotation?: NlpSemanticParsingAppAnnotation;
  audio?: NlpSemanticParsingModelsMediaAudio;
  /**
   * Calendar custom types. Details in go/cal-ref.
   */
  calendarEvent?: AssistantApiCoreTypesCalendarEvent;
  /**
   * Details in go/multi-account-event-representation.
   */
  calendarEventWrapper?: AssistantApiCoreTypesCalendarEventWrapper;
  calendarReference?: QualityQrewriteCalendarReference;
  /**
   * Custom type used by Complex Queries. This is populated based on the output
   * of the RPC to the Complex Queries Boq node.
   */
  complexQueriesRewrite?: QualityGenieComplexQueriesComplexQueriesOutputRewrite;
  /**
   * Component reference between WebrefEntity and Mention. This should only
   * ever be set in argument values in WebrefEntities (e.g. in a QueryJoin). The
   * processing expectation is that the value including the component reference
   * is discarded altogether and replaced by reference target. Use
   * QueryJoinToMeaningStructConverter to perform the replacement. An example
   * value parallel to this reference may exist, but it's meant purely for human
   * consumption and should not be used.
   */
  componentReference?: RepositoryWebrefComponentReference;
  /**
   * A value that is a coreference or variable binding to some other part of
   * the tree. See go/mrf-variables.
   */
  coreference?: KnowledgeAnswersIntentQueryCoreference;
  /**
   * *** Opaque types that are likely to become fully supported: ***
   * Represents: date and time expressions. Annotated by: datetime subgrammar.
   */
  dateTime?: NlpSemanticParsingDatetimeDateTime;
  /**
   * Media custom types. For example use, see go/valyrian-media-dd.
   */
  device?: NlpSemanticParsingModelsMediaCastDeviceAnnotation;
  /**
   * DeviceId custom types. Details in go/reply-broadcast
   */
  deviceId?: AssistantApiCoreTypesDeviceId;
  /**
   * DeviceUserIdentity custom types. Details in go/reply-broadcast
   */
  deviceUserIdentity?: AssistantApiCoreTypesDeviceUserIdentity;
  /**
   * Represents: duration expressions (e.g. 5 minutes). Annotated by: datetime
   * subgrammar.
   */
  duration?: NlpSemanticParsingDatetimeDuration;
  /**
   * *** Fully supported types *** An argument can also be a function call.
   */
  funcall?: KnowledgeAnswersIntentQueryFunctionCall;
  /**
   * HomeAutomation custom types. Details in go/smarthome_with_monastery.
   */
  homeAutomationDevice?: AssistantVerticalsHomeautomationProtoHomeAutomationDevice;
  /**
   * Represents: location expressions. Annotated by: location subgrammar.
   */
  location?: NlpSemanticParsingLocalLocation;
  media?: NlpSemanticParsingModelsMediaMediaAnnotation;
  /**
   * Custom type used by tap-to-read for embedding a MessageNotification
   * message in a GetMessageContent intent.
   */
  messageNotification?: AssistantApiCoreTypesMessageNotification;
  /**
   * Represents: money expressions (e.g. 25$). Annotated by: number subgrammar.
   */
  money?: NlpSemanticParsingModelsMoneyMoney;
  /**
   * Custom type used by NarrativeNews. This is populated by the narrative news
   * provider annotator, and it differs semantically from a mid for a news brand
   * in that it doesn't refer to the field of widely known news brands but
   * rather but to the specific audio news RSS feeds that the narrative news
   * feature serves. (There is of course substantial overlap between those two
   * concepts)
   */
  narrativeNewsProvider?: NlpSemanticParsingModelsNarrativeNewsNewsProvider;
  /**
   * Represents: number expressions. Annotated by: number subgrammar.
   */
  number?: NlpSemanticParsingNumberNumber;
  /**
   * OnDevice custom types. Device on which an intent should be fulfilled.
   * Differs semantically from device fields used by Media and HomeAutomation:
   * this is annotated by the on_device subgrammar, and will not output any
   * metadata beyond what the subgrammar outputs. See
   * go/on_device_induction_quality.
   */
  onDevice?: NlpSemanticParsingModelsOnDevice;
  /**
   * Represents: structured person names, including common names and personal
   * contacts. Annotated by: go/person-subgrammar.
   */
  person?: NlpSemanticParsingModelsPersonPerson;
  /**
   * Entity parsed from manual grammar interpretation in the Personal
   * Intelligence domain.
   */
  personalIntelligenceEntity?: NlpSemanticParsingPersonalIntelligenceEntity;
  productivityListItem?: AssistantProductivityListItem;
  /**
   * Represents: intervals of recurrence for repeated tasks. See
   * go/recurrence-subgrammar Annotated by: recurrence subgrammar.
   */
  recurrence?: NlpSemanticParsingModelsRecurrence;
  reminder?: QualityActionsReminder;
  /**
   * Sensitive value, see go/sensitive-intents and go/a4w-multi-turn-dialog
   */
  sensitiveValue?: KnowledgeAnswersIntentQuerySensitiveArgumentValueGuard;
  /**
   * Argument level query sensitivities. 1) Statically defined Sensitivity is
   * copied from IntentSlot at serving time so it can be propagated along with
   * FunctionCall to places where the Intent Catalog is not available. See
   * go/sensitive-intents for details. 2) For the same reason, contextual
   * sensitivites (eg., from AttentionalEntity mentions) are populated here too.
   * See go/tagging-sensitive-ae for details.
   */
  sensitivity?: KnowledgeAnswersSensitivitySensitivity[];
  shoppingMerchant?: NlpSemanticParsingModelsShoppingAssistantMerchant;
  /**
   * Shopping custom types. See go/sopa-attentional.
   */
  shoppingOffer?: NlpSemanticParsingModelsShoppingAssistantOffer;
  shoppingProduct?: NlpSemanticParsingModelsShoppingAssistantProduct;
  shoppingProductExpression?: NlpSemanticParsingModelsShoppingAssistantProductExpression;
  shoppingStore?: NlpSemanticParsingModelsShoppingAssistantStore;
  /**
   * When literal is a datetime, it's really just an ISO 8601 datetime string.
   * This case will eventually be replaced with the date_time field, which is
   * more expressive and can also represent recurrences, ranges, etc. Likewise,
   * simple_value will replace the other types of simple values that literal is
   * currently being used to represent.
   */
  simpleValue?: KnowledgeAnswersIntentQuerySimpleValue;
  /**
   * Productivity custom types. Team: go/productivity-assistance.
   */
  timer?: QualityActionsTimer;
  /**
   * Represents: timezone expressions (e.g. Eastern Daylight Time). Annotated
   * by: datetime subgrammar.
   */
  timezone?: NlpSemanticParsingDatetimeTimeZone;
}

function serializeKnowledgeAnswersIntentQueryArgumentValue(data: any): KnowledgeAnswersIntentQueryArgumentValue {
  return {
    ...data,
    appAnnotation: data["appAnnotation"] !== undefined ? serializeNlpSemanticParsingAppAnnotation(data["appAnnotation"]) : undefined,
    audio: data["audio"] !== undefined ? serializeNlpSemanticParsingModelsMediaAudio(data["audio"]) : undefined,
    calendarEvent: data["calendarEvent"] !== undefined ? serializeAssistantApiCoreTypesCalendarEvent(data["calendarEvent"]) : undefined,
    calendarReference: data["calendarReference"] !== undefined ? serializeQualityQrewriteCalendarReference(data["calendarReference"]) : undefined,
    dateTime: data["dateTime"] !== undefined ? serializeNlpSemanticParsingDatetimeDateTime(data["dateTime"]) : undefined,
    device: data["device"] !== undefined ? serializeNlpSemanticParsingModelsMediaCastDeviceAnnotation(data["device"]) : undefined,
    deviceUserIdentity: data["deviceUserIdentity"] !== undefined ? serializeAssistantApiCoreTypesDeviceUserIdentity(data["deviceUserIdentity"]) : undefined,
    funcall: data["funcall"] !== undefined ? serializeKnowledgeAnswersIntentQueryFunctionCall(data["funcall"]) : undefined,
    homeAutomationDevice: data["homeAutomationDevice"] !== undefined ? serializeAssistantVerticalsHomeautomationProtoHomeAutomationDevice(data["homeAutomationDevice"]) : undefined,
    location: data["location"] !== undefined ? serializeNlpSemanticParsingLocalLocation(data["location"]) : undefined,
    media: data["media"] !== undefined ? serializeNlpSemanticParsingModelsMediaMediaAnnotation(data["media"]) : undefined,
    messageNotification: data["messageNotification"] !== undefined ? serializeAssistantApiCoreTypesMessageNotification(data["messageNotification"]) : undefined,
    person: data["person"] !== undefined ? serializeNlpSemanticParsingModelsPersonPerson(data["person"]) : undefined,
    personalIntelligenceEntity: data["personalIntelligenceEntity"] !== undefined ? serializeNlpSemanticParsingPersonalIntelligenceEntity(data["personalIntelligenceEntity"]) : undefined,
    recurrence: data["recurrence"] !== undefined ? serializeNlpSemanticParsingModelsRecurrence(data["recurrence"]) : undefined,
    reminder: data["reminder"] !== undefined ? serializeQualityActionsReminder(data["reminder"]) : undefined,
    sensitiveValue: data["sensitiveValue"] !== undefined ? serializeKnowledgeAnswersIntentQuerySensitiveArgumentValueGuard(data["sensitiveValue"]) : undefined,
    sensitivity: data["sensitivity"] !== undefined ? data["sensitivity"].map((item: any) => (serializeKnowledgeAnswersSensitivitySensitivity(item))) : undefined,
    shoppingMerchant: data["shoppingMerchant"] !== undefined ? serializeNlpSemanticParsingModelsShoppingAssistantMerchant(data["shoppingMerchant"]) : undefined,
    shoppingOffer: data["shoppingOffer"] !== undefined ? serializeNlpSemanticParsingModelsShoppingAssistantOffer(data["shoppingOffer"]) : undefined,
    shoppingProduct: data["shoppingProduct"] !== undefined ? serializeNlpSemanticParsingModelsShoppingAssistantProduct(data["shoppingProduct"]) : undefined,
    shoppingProductExpression: data["shoppingProductExpression"] !== undefined ? serializeNlpSemanticParsingModelsShoppingAssistantProductExpression(data["shoppingProductExpression"]) : undefined,
    shoppingStore: data["shoppingStore"] !== undefined ? serializeNlpSemanticParsingModelsShoppingAssistantStore(data["shoppingStore"]) : undefined,
    simpleValue: data["simpleValue"] !== undefined ? serializeKnowledgeAnswersIntentQuerySimpleValue(data["simpleValue"]) : undefined,
    timer: data["timer"] !== undefined ? serializeQualityActionsTimer(data["timer"]) : undefined,
  };
}

function deserializeKnowledgeAnswersIntentQueryArgumentValue(data: any): KnowledgeAnswersIntentQueryArgumentValue {
  return {
    ...data,
    appAnnotation: data["appAnnotation"] !== undefined ? deserializeNlpSemanticParsingAppAnnotation(data["appAnnotation"]) : undefined,
    audio: data["audio"] !== undefined ? deserializeNlpSemanticParsingModelsMediaAudio(data["audio"]) : undefined,
    calendarEvent: data["calendarEvent"] !== undefined ? deserializeAssistantApiCoreTypesCalendarEvent(data["calendarEvent"]) : undefined,
    calendarReference: data["calendarReference"] !== undefined ? deserializeQualityQrewriteCalendarReference(data["calendarReference"]) : undefined,
    dateTime: data["dateTime"] !== undefined ? deserializeNlpSemanticParsingDatetimeDateTime(data["dateTime"]) : undefined,
    device: data["device"] !== undefined ? deserializeNlpSemanticParsingModelsMediaCastDeviceAnnotation(data["device"]) : undefined,
    deviceUserIdentity: data["deviceUserIdentity"] !== undefined ? deserializeAssistantApiCoreTypesDeviceUserIdentity(data["deviceUserIdentity"]) : undefined,
    funcall: data["funcall"] !== undefined ? deserializeKnowledgeAnswersIntentQueryFunctionCall(data["funcall"]) : undefined,
    homeAutomationDevice: data["homeAutomationDevice"] !== undefined ? deserializeAssistantVerticalsHomeautomationProtoHomeAutomationDevice(data["homeAutomationDevice"]) : undefined,
    location: data["location"] !== undefined ? deserializeNlpSemanticParsingLocalLocation(data["location"]) : undefined,
    media: data["media"] !== undefined ? deserializeNlpSemanticParsingModelsMediaMediaAnnotation(data["media"]) : undefined,
    messageNotification: data["messageNotification"] !== undefined ? deserializeAssistantApiCoreTypesMessageNotification(data["messageNotification"]) : undefined,
    person: data["person"] !== undefined ? deserializeNlpSemanticParsingModelsPersonPerson(data["person"]) : undefined,
    personalIntelligenceEntity: data["personalIntelligenceEntity"] !== undefined ? deserializeNlpSemanticParsingPersonalIntelligenceEntity(data["personalIntelligenceEntity"]) : undefined,
    recurrence: data["recurrence"] !== undefined ? deserializeNlpSemanticParsingModelsRecurrence(data["recurrence"]) : undefined,
    reminder: data["reminder"] !== undefined ? deserializeQualityActionsReminder(data["reminder"]) : undefined,
    sensitiveValue: data["sensitiveValue"] !== undefined ? deserializeKnowledgeAnswersIntentQuerySensitiveArgumentValueGuard(data["sensitiveValue"]) : undefined,
    sensitivity: data["sensitivity"] !== undefined ? data["sensitivity"].map((item: any) => (deserializeKnowledgeAnswersSensitivitySensitivity(item))) : undefined,
    shoppingMerchant: data["shoppingMerchant"] !== undefined ? deserializeNlpSemanticParsingModelsShoppingAssistantMerchant(data["shoppingMerchant"]) : undefined,
    shoppingOffer: data["shoppingOffer"] !== undefined ? deserializeNlpSemanticParsingModelsShoppingAssistantOffer(data["shoppingOffer"]) : undefined,
    shoppingProduct: data["shoppingProduct"] !== undefined ? deserializeNlpSemanticParsingModelsShoppingAssistantProduct(data["shoppingProduct"]) : undefined,
    shoppingProductExpression: data["shoppingProductExpression"] !== undefined ? deserializeNlpSemanticParsingModelsShoppingAssistantProductExpression(data["shoppingProductExpression"]) : undefined,
    shoppingStore: data["shoppingStore"] !== undefined ? deserializeNlpSemanticParsingModelsShoppingAssistantStore(data["shoppingStore"]) : undefined,
    simpleValue: data["simpleValue"] !== undefined ? deserializeKnowledgeAnswersIntentQuerySimpleValue(data["simpleValue"]) : undefined,
    timer: data["timer"] !== undefined ? deserializeQualityActionsTimer(data["timer"]) : undefined,
  };
}

/**
 * Contains an attribute id and it's completion score.
 */
export interface KnowledgeAnswersIntentQueryAttributeSignal {
  attributeId?: string;
  score?: number;
}

/**
 * A message representing the collection membership of an entity.
 */
export interface KnowledgeAnswersIntentQueryCollectionMembership {
  /**
   * Human readable id of the collection.
   */
  collectionId?: string;
  /**
   * Identifier of the collection, usually a MID (/m/xyz or /g/zyw).
   */
  collectionMid?: string;
  /**
   * The collection score for a entity.
   */
  collectionScore?: number;
  /**
   * Different types of scores for the collection. Each score type has at most
   * one score.
   */
  score?: KnowledgeAnswersIntentQueryCollectionScore[];
}

export interface KnowledgeAnswersIntentQueryCollectionScore {
  scoreType?:  | "UNKNOWN" | "GENERAL";
  scoreValue?: number;
}

/**
 * A message representing a coreferenced value defined elsewhere in the meaning
 * struct.
 */
export interface KnowledgeAnswersIntentQueryCoreference {
  /**
   * A coreference is represented by an argument path starting from the root of
   * the whole tree to the referenced value.
   */
  argPath?: KnowledgeAnswersIntentQueryArgPath;
}

/**
 * Signals associated with CustomVehicleActionArgumentAnnotator annotations.
 */
export interface KnowledgeAnswersIntentQueryCustomVehicleActionArgumentAnnotatorSignals {
  /**
   * Stores any additional data which is required only at the intent fulfilment
   * phase.
   */
  additionalAnnotationData?: {
    [key: string]: string
  };
}

/**
 * Signals associated with FreetextAnnotator annotations. Empty. The signal
 * being present is enough for the conformance checking library to be able to
 * check.
 */
export interface KnowledgeAnswersIntentQueryFreetextAnnotationSignals {
}

/**
 * A message representing the function call of an answers intent query. Next
 * ID: 19 Important: If you add new fields that do not reflect signals data, but
 * actual semantics of the FunctionCall, please also update
 * CreateFuncallCopyWithoutSignals and CreateFuncallCopyWithArgumentSignals in
 * function_call_utils. LINT.IfChange
 */
export interface KnowledgeAnswersIntentQueryFunctionCall {
  /**
   * A list of arguments of this function call.
   */
  argument?: KnowledgeAnswersIntentQueryArgument[];
  /**
   * The corresponding meaning catalog version that was used to generate this
   * FunctionCall.
   */
  catalogVersion?: bigint;
  /**
   * Contextual Sensitivity (go/contextual-sensitivity) metadata indicating
   * that a policy- or privacy- sensitive conversation context (previous
   * queries, rewritten user queries, and previous system responses, like
   * attentional entities) is used to generate this FunctionCall. This needs
   * propagation (1) from Interp to DialogIntentState (DIS) (see b/148479837)
   * and (2) from QRewrite/QUS down to Assistant Server's memory finalizer. One
   * can use knowledge/answers/sensitivity/sensitivity_reader.h to parse this
   * proto. NOTE(b/149091449): This is part of the migration of contextual
   * sensitivity protos from Interp sensitivity extension.
   * (nlp::semantic_parsing::sensitivity) to this proto field. See the bug to
   * track the migration progress and for more details.
   */
  contextualSensitivity?: KnowledgeAnswersSensitivitySensitivity[];
  /**
   * Contains data about which remodelings are being used for this funcall. For
   * more information see go/meaning-remodeling-framework.
   */
  enabledRemodelings?: NlpMeaningMeaningRemodelingControl;
  /**
   * A list of token lists that were ignored during parsing because they are
   * known context phrases for this interpretation. For example, for query [tell
   * me how tall height of Obama really], assuming "tell me", "tall", "of",
   * "really" are explained and thus ignored, with corresponding prior 0.9, 0.8,
   * 0.7, 0.6, following ignored tokens will be populated: { ignored_tokens {
   * token { ngram: "tell me", prior: 0.9} score: 0.9 } ignored_tokens { token {
   * ngram: "tall", prior: 0.8} token { ngram: "of", prior: 0.7} score: 0.56 //
   * currently score = prior1 * prior2 * ... * prior N } ignored_tokens { token
   * { ngram: "really", prior: 0.6} score: 0.6 } } These tokens can serve two
   * purpose: 1) debug info to show why an interpretation is generated; 2) carry
   * the signals for downstream usage. Note: This field is under active
   * development, and significant changes could happen. Please contact
   * porky-pig@ if you want to use it.
   */
  ignoredTokens?: KnowledgeAnswersIntentQueryTokens[];
  /**
   * The primary key for this FunctionCall. Note: This is still under
   * development and not available for general use. Contact
   * meaning-platform-eng@ for questions.
   */
  key?: KnowledgeAnswersMeaningSchemaKey;
  /**
   * The marker specifies the purpose of this meaning struct / function call:
   * Is it asking a question, and if yes, for which slot(s)? Is it a command,
   * statement, etc? This corresponds to a (very coarse) notion of dialog acts.
   * In the absence of this field, it will be inferred using the following
   * algorithm (subject to marker applicability rules specified in marker.proto,
   * see also go/requested-slots): 1) Use the underlying Meaning Schema's
   * default marker, if applicable. 2) Assume that the Meaning Struct is polar
   * or a statement. The presence of a marker will affect the value type of this
   * function call.
   */
  marker?: KnowledgeAnswersMarker;
  /**
   * A flattened representation of all intent modifiers that apply to this
   * function call.
   */
  modifiers?: KnowledgeAnswersIntentModifiers;
  /**
   * Name of this function call. The name must be present. If it is omitted,
   * the FunctionCall is not well-formed.
   */
  name?: string;
  /**
   * Intent level query sensitivity (go/sensitive-intents). This metadata comes
   * directly from Intent Catalog, indicating a single-shot query sensitivity
   * without putting context into considerations. Therefore, this requires a
   * one-to-one match with each intent registered in Intent Catalog.
   */
  sensitivity?: KnowledgeAnswersSensitivitySensitivity;
  /**
   * Signals at the function call level
   */
  signals?: KnowledgeAnswersIntentQueryFunctionCallSignals;
  /**
   * A list of tokens that were ignored during parsing that cannot be explained
   * by context phrases.
   */
  unexplainedTokens?: KnowledgeAnswersIntentQueryTokens[];
}

function serializeKnowledgeAnswersIntentQueryFunctionCall(data: any): KnowledgeAnswersIntentQueryFunctionCall {
  return {
    ...data,
    argument: data["argument"] !== undefined ? data["argument"].map((item: any) => (serializeKnowledgeAnswersIntentQueryArgument(item))) : undefined,
    catalogVersion: data["catalogVersion"] !== undefined ? String(data["catalogVersion"]) : undefined,
    contextualSensitivity: data["contextualSensitivity"] !== undefined ? data["contextualSensitivity"].map((item: any) => (serializeKnowledgeAnswersSensitivitySensitivity(item))) : undefined,
    enabledRemodelings: data["enabledRemodelings"] !== undefined ? serializeNlpMeaningMeaningRemodelingControl(data["enabledRemodelings"]) : undefined,
    key: data["key"] !== undefined ? serializeKnowledgeAnswersMeaningSchemaKey(data["key"]) : undefined,
    marker: data["marker"] !== undefined ? serializeKnowledgeAnswersMarker(data["marker"]) : undefined,
    sensitivity: data["sensitivity"] !== undefined ? serializeKnowledgeAnswersSensitivitySensitivity(data["sensitivity"]) : undefined,
    signals: data["signals"] !== undefined ? serializeKnowledgeAnswersIntentQueryFunctionCallSignals(data["signals"]) : undefined,
  };
}

function deserializeKnowledgeAnswersIntentQueryFunctionCall(data: any): KnowledgeAnswersIntentQueryFunctionCall {
  return {
    ...data,
    argument: data["argument"] !== undefined ? data["argument"].map((item: any) => (deserializeKnowledgeAnswersIntentQueryArgument(item))) : undefined,
    catalogVersion: data["catalogVersion"] !== undefined ? BigInt(data["catalogVersion"]) : undefined,
    contextualSensitivity: data["contextualSensitivity"] !== undefined ? data["contextualSensitivity"].map((item: any) => (deserializeKnowledgeAnswersSensitivitySensitivity(item))) : undefined,
    enabledRemodelings: data["enabledRemodelings"] !== undefined ? deserializeNlpMeaningMeaningRemodelingControl(data["enabledRemodelings"]) : undefined,
    key: data["key"] !== undefined ? deserializeKnowledgeAnswersMeaningSchemaKey(data["key"]) : undefined,
    marker: data["marker"] !== undefined ? deserializeKnowledgeAnswersMarker(data["marker"]) : undefined,
    sensitivity: data["sensitivity"] !== undefined ? deserializeKnowledgeAnswersSensitivitySensitivity(data["sensitivity"]) : undefined,
    signals: data["signals"] !== undefined ? deserializeKnowledgeAnswersIntentQueryFunctionCallSignals(data["signals"]) : undefined,
  };
}

/**
 * Next ID: 36
 */
export interface KnowledgeAnswersIntentQueryFunctionCallSignals {
  /**
   * The argument mid that was used to compose the entity for a concept
   * interpretation, along with the intent_composing_mid (one of the intent's
   * equivalent MIDs).
   */
  argumentComposingMid?: string;
  /**
   * The attributes from which this intent was generated during execution of
   * AttributeSignalsProvider. |attribute_signals| is only populated for single
   * entity funcalls.
   */
  attributeSignals?: KnowledgeAnswersIntentQueryAttributeSignal[];
  /**
   * An entity that represents the concept of an entity-attribute intent by
   * being composed of an intent equivalent MID and the argument MID.
   */
  conceptEntityMid?: string;
  confidenceLevel?:  | "UNKNOWN" | "LOW" | "MEDIUM" | "HIGH" | "ALWAYS_TRIGGER";
  /**
   * FunctionCall-s that this funcall was deduped against.
   */
  dedupedFuncalls?: KnowledgeAnswersIntentQueryFunctionCall[];
  /**
   * Status indicating whether the user has completely expressed their intended
   * semantics. (See go/streaming-nlu-fulfilment-protocol-v1 for more info. )
   */
  expressionStatus?: NlpSemanticParsingExpressionStatus;
  freefolksTrigger?:  | "NONE_FREEFOLKS_TRIGGER" | "LOW_CONF_FREEFOLKS_TRIGGER" | "HIGH_CONF_FREEFOLKS_TRIGGER";
  /**
   * Grounding signals for ranking/filtering, as well as whether to use
   * Grounding Box and PGRP in AnswersRewriter. See comment on GroundingSignals
   * for details.
   */
  groundingSignals?: KnowledgeAnswersIntentQueryGroundingSignals;
  /**
   * Used to indicate that an interpretation is high confidence and triggers
   * different voting behavior. This bit should only be set for verticals.
   * DEPRECATED. Use confidence_level instead.
   */
  highConfidence?: boolean;
  intentAnnotationSources?:  | "UNKNOWN_SOURCE" | "ORBIT" | "LEXICON"[];
  /**
   * An intent_relevant_mid that was used to compose the entity for a concept
   * interpretation, along with argument_composing_mid (the question's argument
   * MID).
   */
  intentComposingMid?: string;
  /**
   * Information about where the value of this intent came from. For example,
   * it could have been explicitly provided in the query, pulled in from the
   * previous dialog state, or pulled from previous queries.
   */
  intentProvenance?: KnowledgeAnswersIntentQueryArgumentProvenance[];
  /**
   * KG mids of entities that represent this intent. These entities are seen as
   * equivalent to the Intent definition, and are specified in the Intent
   * Catalog as relevant_mid.
   */
  intentRelevantMid?: string[];
  /**
   * Whether the interpretation was generated using similar queries in POSTREF.
   * In case POSTREF_AQUA generated the same entity-attribute interpretation,
   * this is still set to true.
   */
  isCloseInterpretation?: boolean;
  /**
   * Denotes whether this is an intent being fulfilled from user tapping a
   * disambiguation card. More info in go/cardea-deck.
   */
  isDisambiguationCardIntent?: boolean;
  /**
   * Denotes whether this is a sub-intent of an ambiguous SystemUncertain
   * intent go/intent-disambiguation.
   */
  isDisambiguationIntent?: boolean;
  /**
   * Whether the interpretation was generated from the neural categorical
   * parser.
   */
  isNeuralCategoricalInterpretation?: boolean;
  /**
   * Denotes this is a sub-intent used for composing an Assistant UI response.
   * The assistant dialog should output ui_composition_shelf in the
   * SystemResponse if it can fulfill the intent. More info in go/davinci-design
   * and go/davinci-di-fulfillment
   */
  isUiCompositionIntent?: boolean;
  /**
   * Information about Local results to be used in the Packer for Local
   * Categorical derived intent deduplication and conformance.
   */
  localSignals?: KnowledgeAnswersIntentQueryLocalSignals;
  /**
   * A tag to annotate user's journey (e.g., JourneyFollowCampusUpdates). This
   * will be used for Journey OSRP demo (go/josrp-sprint). !!NOTE!! This field
   * is reserved for Journey OSRP demo, and will be deprecated shortly after its
   * completion. DO NOT USE.
   */
  osrpJourneyTag?: string;
  /**
   * Experiments that caused this FunctionCall to parse, without which this
   * would not have parsed.
   */
  parsedDueToExperiment?: string[];
  /**
   * Parsing signals for ranking/filtering.
   */
  parsingSignals?: KnowledgeAnswersIntentQueryParsingSignals;
  /**
   * Identifies a score, determined before fulfillment but after grounding.
   * Written by the Prefulfillment Ranker, and used as a signal for ACE Ranking.
   */
  prefulfillmentRankingScore?: number;
  /**
   * All the input signals to the Prefulfillment Ranker.
   */
  prefulfillmentSignals?: AssistantPrefulfillmentRankerPrefulfillmentSignals;
  /**
   * Describes how this intent was resolved via external data (either elsewhere
   * in the query, or in a previous query).
   */
  referentialResolution?: KnowledgeAnswersDialogReferentialResolution;
  /**
   * The id of the summary node if this funcall represents an mdvc
   * interpretation
   */
  refxSummaryNodeId?: string;
  /**
   * Signal data from SRM generation. Solely used internally. See:
   * go/srm-design.
   */
  responseMeaningSignals?: KnowledgeAnswersIntentQueryResponseMeaningSignalsResponseMeaningSignals;
  /**
   * The list of result supports for this FunctionCall.
   */
  resultSupport?: UniversalsearchNewPackerKnowledgeResultSupport[];
  role?:  | "UNKNOWN_ROLE" | "QUERY_INTERPRETATION" | "DERIVED_INTENT";
  /**
   * Identifies whether the Prefulfillment Ranker selected this intent for
   * emission. This is needed temporarily while migrating intent emitters from
   * ACE to QUS/PFR. See go/pfr-intent-emitter for more info
   */
  selectedByPrefulfillmentRanking?: boolean;
  /**
   * Equivalent shopping ids for the function call.
   */
  shoppingIds?: KnowledgeAnswersIntentQueryShoppingIds;
  /**
   * Additional intents to be used for intent scoring. This field must only be
   * populated when we cannot find a single unified intent. For example, when we
   * compute signals for a LocalEntities function call, this means we could not
   * find a unified intent to capture all the local results. In this case, we
   * add a fallback intent for each local result (e.g. GeoSchool, GeoRestaurant,
   * and GeoBank if those are the results we show).
   */
  signalsFallbackIntents?: KnowledgeAnswersIntentQuerySignalComputationFallbackIntent[];
}

function serializeKnowledgeAnswersIntentQueryFunctionCallSignals(data: any): KnowledgeAnswersIntentQueryFunctionCallSignals {
  return {
    ...data,
    dedupedFuncalls: data["dedupedFuncalls"] !== undefined ? data["dedupedFuncalls"].map((item: any) => (serializeKnowledgeAnswersIntentQueryFunctionCall(item))) : undefined,
    intentProvenance: data["intentProvenance"] !== undefined ? data["intentProvenance"].map((item: any) => (serializeKnowledgeAnswersIntentQueryArgumentProvenance(item))) : undefined,
    parsingSignals: data["parsingSignals"] !== undefined ? serializeKnowledgeAnswersIntentQueryParsingSignals(data["parsingSignals"]) : undefined,
    responseMeaningSignals: data["responseMeaningSignals"] !== undefined ? serializeKnowledgeAnswersIntentQueryResponseMeaningSignalsResponseMeaningSignals(data["responseMeaningSignals"]) : undefined,
    resultSupport: data["resultSupport"] !== undefined ? data["resultSupport"].map((item: any) => (serializeUniversalsearchNewPackerKnowledgeResultSupport(item))) : undefined,
    shoppingIds: data["shoppingIds"] !== undefined ? serializeKnowledgeAnswersIntentQueryShoppingIds(data["shoppingIds"]) : undefined,
  };
}

function deserializeKnowledgeAnswersIntentQueryFunctionCallSignals(data: any): KnowledgeAnswersIntentQueryFunctionCallSignals {
  return {
    ...data,
    dedupedFuncalls: data["dedupedFuncalls"] !== undefined ? data["dedupedFuncalls"].map((item: any) => (deserializeKnowledgeAnswersIntentQueryFunctionCall(item))) : undefined,
    intentProvenance: data["intentProvenance"] !== undefined ? data["intentProvenance"].map((item: any) => (deserializeKnowledgeAnswersIntentQueryArgumentProvenance(item))) : undefined,
    parsingSignals: data["parsingSignals"] !== undefined ? deserializeKnowledgeAnswersIntentQueryParsingSignals(data["parsingSignals"]) : undefined,
    responseMeaningSignals: data["responseMeaningSignals"] !== undefined ? deserializeKnowledgeAnswersIntentQueryResponseMeaningSignalsResponseMeaningSignals(data["responseMeaningSignals"]) : undefined,
    resultSupport: data["resultSupport"] !== undefined ? data["resultSupport"].map((item: any) => (deserializeUniversalsearchNewPackerKnowledgeResultSupport(item))) : undefined,
    shoppingIds: data["shoppingIds"] !== undefined ? deserializeKnowledgeAnswersIntentQueryShoppingIds(data["shoppingIds"]) : undefined,
  };
}

/**
 * Grounding-related signals to be propagated down stream. Next ID: 12
 */
export interface KnowledgeAnswersIntentQueryGroundingSignals {
  /**
   * True if the argument was added during grounding. This signal is intended
   * to be used with ArgumentSignals. Note that the added argument's value must
   * be a FunctionCall that only contains resolutions, i.e. grounding cannot
   * add/modify/delete any ungrounded values.
   */
  addedByGrounding?: boolean;
  /**
   * Score indicating how grounded the intent is, populated by the Grounding
   * Box, used by the pre-fulfillment ranker, see
   * http://go/prefulfillment-ranker.
   */
  groundabilityScore?: number;
  /**
   * Sum of the number of constraints used by the Grounding Box to ground each
   * variable.
   */
  numConstraints?: number;
  /**
   * Sum of the number of constraints satisfied for each variable. Depending on
   * the match score for a constraint, this number can be fractional and is in
   * the range [0, num_constraints].
   */
  numConstraintsSatisfied?: number;
  /**
   * Number of groundable arguments in the parsed intent.
   */
  numGroundableArgs?: number;
  /**
   * Number of arguments that got actually grounded.
   */
  numGroundedArgs?: number;
  /**
   * Number of arguments, possibly nested, that the Grounding Box tried to
   * ground.
   */
  numVariables?: number;
  /**
   * Number of arguments, possibly nested, that the Grounding Box was able to
   * ground. This includes ambiguously grounded arguments.
   */
  numVariablesGrounded?: number;
  /**
   * PGRP outputs PROD_INTENT_FACTORY intent format by default. See
   * go/intent-conversion-locations-in-sage. Experimental flags can change or
   * make PGRP output additional intents formatted for PORTMON_FULFILLMENT (e.g.
   * with RDs). This is used by the PortMon/ARM dark launch
   * (go/arm-dark-launch-infra). Longer term, this will be replaced by DGS
   * system-internal transformations (go/if-dgs).
   */
  pgrpOutputFormat?:  | "INTENT_FORMAT_UNSPECIFIED" | "PROD_INTENT_FACTORY" | "PORTMON_FULFILLMENT";
  /**
   * If true, then GroundingBox and PGRP are used in AnswersRewriter to process
   * the intent. Other post-processing steps, including IGDP, are adjusted
   * accordingly. Note this will be removed once GroundingBox is fully launched
   * and all prod traffic goes through it. Before that happens, each IG that
   * needs to go through GB and PGRP (post GB ranking pruning) will need to
   * explicitly set this field to true. See http://go/gb-impl and
   * http://go/gb-post-ranker-pruner for details.
   */
  usesGroundingBox?: boolean;
}

/**
 * Identifiers are references to a specific entity of a specified type, such as
 * a TIMER_ID XXX. For more backround and uses see go/grounding-common-ids.
 */
export interface KnowledgeAnswersIntentQueryIdentifier {
  id?: string;
  idType?:  | "UNKNOWN_ID_TYPE" | "ALARM" | "CALENDAR" | "CALENDAR_EVENT" | "KG" | "LIST" | "LIST_ITEM" | "NOTE" | "PROVIDER" | "STOPWATCH" | "TIMER" | "DEVICE" | "DEVICE_SETTING" | "ROOM" | "STRUCTURE" | "ZONE" | "REMINDER" | "RECIPE" | "PERSON" | "COMM_ENDPOINT" | "CALL_LOG" | "NEWS" | "MEDIA" | "CONCEPT" | "RELATION" | "ATTENTIONAL_ENTITY" | "AUDIO_MESSAGE_METADATA_ID" | "BROADCAST" | "MESSAGE_CONTENT";
}

/**
 * Signals for $QRefImpliedEntities that are merged into entity arguments
 * during parsing.
 */
export interface KnowledgeAnswersIntentQueryImpliedEntity {
  /**
   * A copy of the span of canonical (raw) parser input text corresponding to
   * this annotation. Copied from QRefAnnotation.annotated_span.
   */
  annotatedSpan?: string;
  /**
   * This field is used inside Aqua for evaluation purposes.
   */
  evalData?: NlpSemanticParsingAnnotationEvalData;
  /**
   * TODO (b/143536264): Create a new ImpliedTokens message and remove this.
   * Whether the implied entity is ungrounded value, set to true when the entity
   * doesn't have a KG mid.
   */
  isUngroundedValue?: boolean;
  /**
   * The KG mid of the implied entity.
   */
  mid?: string;
  /**
   * The QRef confidence (in [0, 1]) of the entity being correctly annotated.
   */
  qrefConfidenceScore?: number;
  /**
   * All ShoppingIds for this implied entity that need to be copied to
   * IntentQuery (FunctionCall) if this implied entity is used in intent
   * generation. See go/iql-shopping-ids for details.
   */
  shoppingIds?: KnowledgeAnswersIntentQueryShoppingIds;
}

function serializeKnowledgeAnswersIntentQueryImpliedEntity(data: any): KnowledgeAnswersIntentQueryImpliedEntity {
  return {
    ...data,
    shoppingIds: data["shoppingIds"] !== undefined ? serializeKnowledgeAnswersIntentQueryShoppingIds(data["shoppingIds"]) : undefined,
  };
}

function deserializeKnowledgeAnswersIntentQueryImpliedEntity(data: any): KnowledgeAnswersIntentQueryImpliedEntity {
  return {
    ...data,
    shoppingIds: data["shoppingIds"] !== undefined ? deserializeKnowledgeAnswersIntentQueryShoppingIds(data["shoppingIds"]) : undefined,
  };
}

/**
 * Mustang/Kgraph attachment to encode IQL expressions annotated by Webref,
 * Pianno, and other applications. This is currently a prototype implementation.
 * The attachment is not yet output in production. Please contact simonz@ for
 * more info. The planned use-cases include: - Pianno page-level intents
 * (go/pianno-design). - Compound entity representations (go/compounds-in-refx).
 * See go/iql-in-wma for more details about IQL attachment and its encoding
 * design. Next available tag: 5
 */
export interface KnowledgeAnswersIntentQueryIndexingIQLAttachment {
  /**
   * The version of encoder for the IQL FunctionCalls. We bump up the version
   * when, but not limited to, we change how an IQL is converted to a byte
   * array, or the change of byte compression algorithm.
   */
  iqlEncodingVersion?: number;
  /**
   * A compressed byte array that represents IQL FunctionCalls. A list of IQL
   * FunctionCalls are first encoded as a byte array. The byte array is then
   * compressed. For more details on the encoding, see go/iql-in-wma.
   */
  iqlFuncalls?: Uint8Array;
  /**
   * The Pianno confidence scores of all intents of the IQL FunctionCalls. For
   * space reasons this is stored as a [0, 100] integer that represents the
   * confidence up to two decimal points (fixed point). Convert it to
   * confidence_score using the following formula: float pianno_confidence_score
   * = pianno_confidence_score_e2 / 100.0f It should have the same number of
   * elements as the IQL expressions after decoding. For non-Pianno top level
   * intents, this score is 0.
   */
  piannoConfidenceScoreE2?: number[];
  /**
   * A bit map indicating if the intents in the IQL FunctionCalls are top level
   * intents for Pianno (go/pianno). This is a repeated field. In the event of
   * more than 32 intents, the first uint32/ represents the 1st to the 32nd
   * intents, and the second uint32 represents/ the 33rd to the 64th intents,
   * and so on. Within each uint32, the bits are in reversed order, i.e. the
   * right-most bit of the first uint32 indicating if the first intent in IQL
   * expressions is a top level intent for Pianno. The prevailing (unused) bits
   * of the last uint32 are filled with 0s.
   */
  piannoIqlBitmap?: number[];
}

function serializeKnowledgeAnswersIntentQueryIndexingIQLAttachment(data: any): KnowledgeAnswersIntentQueryIndexingIQLAttachment {
  return {
    ...data,
    iqlFuncalls: data["iqlFuncalls"] !== undefined ? encodeBase64(data["iqlFuncalls"]) : undefined,
  };
}

function deserializeKnowledgeAnswersIntentQueryIndexingIQLAttachment(data: any): KnowledgeAnswersIntentQueryIndexingIQLAttachment {
  return {
    ...data,
    iqlFuncalls: data["iqlFuncalls"] !== undefined ? decodeBase64(data["iqlFuncalls"] as string) : undefined,
  };
}

/**
 * A message that stores signals relating to a Local result.
 */
export interface KnowledgeAnswersIntentQueryLocalResultSignals {
  /**
   * Geo intents corresponding to the gcids obtained from the Local result.
   */
  gcidIntent?: string[];
  /**
   * Salient terms associated with this Local result based on the result gcids.
   */
  salientTermSet?: QualitySalientTermsSalientTermSet;
}

/**
 * A message that stores information about Local results to be used in the
 * Packer for Local Categorical derived intent deduplication and conformance.
 */
export interface KnowledgeAnswersIntentQueryLocalSignals {
  /**
   * Signals relating to each Local result.
   */
  localResultSignals?: KnowledgeAnswersIntentQueryLocalResultSignals[];
  /**
   * Minimum salient term similarity between Local results.
   */
  minSalientTermSimilarity?: number;
}

/**
 * Signals from LightweightToken. The span for an argument may have been
 * extended to include lightweight token markers such as FROM or TO. This signal
 * provides the semantics for the range extension.
 */
export interface KnowledgeAnswersIntentQueryLocationMarkersSignals {
  /**
   * The type of the lightweight token match.
   */
  type?:  | "UNKNOWN" | "SOURCE" | "GOAL";
}

/**
 * Signals about the media entity.
 */
export interface KnowledgeAnswersIntentQueryMediaEntitySignals {
  /**
   * For songs, this is the name of the primary artist, i.e. "Shallow" would
   * "Lady Gaga" set.
   */
  artistTitle?: string;
  /**
   * Name of the media entity, i.e. "Lady Gaga".
   */
  name?: string;
}

/**
 * Signals derived from Munin Function call annotations.
 */
export interface KnowledgeAnswersIntentQueryMuninSignals {
  /**
   * If the modifier is only a good soft modifier by itself, then we would
   * trigger only if it's the only modifier
   */
  isIsolated?: boolean;
  /**
   * Signals for $ListQueryRuleWithSoftModifier. Collections allowed by the
   * soft modifier.
   */
  softModifierCollection?: string[];
  /**
   * If true, the text for this argument did not come from the query, but was
   * generated somehow else.
   */
  textIsGenerated?: boolean;
}

/**
 * Signals associated with NimbleAnnotator annotations.
 */
export interface KnowledgeAnswersIntentQueryNimbleAnnotationSignals {
  /**
   * Where the annotation has been read from.
   */
  annotationSource?:  | "SSTABLE" | "LG" | "TS" | "PRIVATE_SSTABLE";
  /**
   * A client-controlled identifier that the client can use to distinguish
   * between different sets of annotations.
   */
  type?: string;
  /**
   * Version identifier used to isolate different clients from each other. A
   * client should intersect this list of versions with the ones the client is
   * interested in, and use the annotation if the intersection is non-empty.
   */
  version?: string[];
}

/**
 * Signals associated with NTPRAnnotator annotations. Empty. The signal being
 * present is enough for the conformance checking library to be able to check.
 */
export interface KnowledgeAnswersIntentQueryNTPRAnnotationSignals {
}

/**
 * Signals coming from on-device annotators.
 */
export interface KnowledgeAnswersIntentQueryOnDeviceAnnotationSignals {
  /**
   * Provenance of the annotator. Equivalent to the `provenance` field in
   * OnDeviceParserInput::AnnotationInfo. This is used to map from
   * AnnotationInfo to nlp_sage.ScoredAnnotation, since
   * nlp_sage.ScoredAnnotation doesn't have a native `provenance` field. Note in
   * the (very) long term, we'd like to replace ScoredAnnotation with Argument
   * altogether.
   */
  provenance?: string;
}

/**
 * Parsing-related signals. Only horizontal signals should appear directly as
 * fields on this message. Each domain should create their own extension for
 * anything that they need to propagate down stream from AQUA. Note that this
 * proto is not the same as the Superroot proto ParsingSignals
 * (http://google3/knowledge/proto/scoring-signals.proto), which is a
 * Superroot-specific signal used in Scoring. Next ID: 7
 */
export interface KnowledgeAnswersIntentQueryParsingSignals {
  /**
   * A parsing score that is independently calibrated by each parser/IG, used
   * by pre-fulfillment ranker, see http://go/prefulfillment-ranker.
   */
  calibratedParsingScore?: number;
  /**
   * The total effective length of the spans for the arguments used to
   * construct the parse. May include vertical specific adjustments. Eg: For the
   * query [delete my 7 p.m. alarm called chicken] and intent
   * Delete_alarm(alarm_object=RD(category=AlarmObject( label="chicken",
   * trigger_time_datetime=<< 7 PM >>))), the effective argument span is "7
   * p.m." + "chicken" (total length of 13).
   */
  effectiveArgSpanLength?: number;
  /**
   * This is a cross-intent feature which is calculated by iterating all intent
   * candidates. This feature should be populated in post-IG stage (before GB).
   */
  inQueryMaxEffectiveArgSpanLength?: number;
  /**
   * This proto holds the complete call path info of the QRewrite client (e.g.
   * the QUS's phase like "RBT","QBT"; the QUS's candidate type like "Identity";
   * and the ACE's candidate type like "FuzzyMatcher").
   */
  qrewriteCallPathInfo?: NlpLoggingQRewriteClientCallPathInfo;
  /**
   * This proto holds the fingerprint of the call path info of QRewrite client
   * (e.g. the QUS's phase like "RBT","QBT"; the QUS's candidate type like
   * "Identity"; and the ACE's candidate type like "FuzzyMatcher").
   */
  qrewriteCallPathInfoFingerprint?: bigint;
  /**
   * The parser that calibrated the parsing score below.
   */
  source?:  | "UNKNOWN_PARSING_SOURCE" | "SAGE" | "UNSTRUCTURED_INTENTS" | "NSP" | "AQUA" | "PHONE_GENIE";
}

function serializeKnowledgeAnswersIntentQueryParsingSignals(data: any): KnowledgeAnswersIntentQueryParsingSignals {
  return {
    ...data,
    qrewriteCallPathInfo: data["qrewriteCallPathInfo"] !== undefined ? serializeNlpLoggingQRewriteClientCallPathInfo(data["qrewriteCallPathInfo"]) : undefined,
    qrewriteCallPathInfoFingerprint: data["qrewriteCallPathInfoFingerprint"] !== undefined ? String(data["qrewriteCallPathInfoFingerprint"]) : undefined,
  };
}

function deserializeKnowledgeAnswersIntentQueryParsingSignals(data: any): KnowledgeAnswersIntentQueryParsingSignals {
  return {
    ...data,
    qrewriteCallPathInfo: data["qrewriteCallPathInfo"] !== undefined ? deserializeNlpLoggingQRewriteClientCallPathInfo(data["qrewriteCallPathInfo"]) : undefined,
    qrewriteCallPathInfoFingerprint: data["qrewriteCallPathInfoFingerprint"] !== undefined ? BigInt(data["qrewriteCallPathInfoFingerprint"]) : undefined,
  };
}

/**
 * A message encapsulating all "/collection/personal_memory" annotations from
 * QRef annotator. These annotations are present in personal_summary_node_child
 * proto field of input QRefAnnotation proto. NEXT ID TO USE: 5
 */
export interface KnowledgeAnswersIntentQueryPersonalEntity {
  /**
   * Attribute ID of a personal_summary_node_child.
   */
  attributeId?: string;
  entityRelationship?: KnowledgeAnswersIntentQueryPersonalEntityEntityRelationship[];
  /**
   * The mid of the entity in freebase associated with this span.
   */
  freebaseMid?: string;
  /**
   * Every PersonalEntity might itself rescursively contain related Personal
   * Entities, e.g. for, "my father's mother" a parent Personal Entity for
   * 'Mother()' contains a child Personal Entity of the form 'Mother(Myself)'.
   */
  personalEntityChild?: KnowledgeAnswersIntentQueryPersonalEntity[];
}

/**
 * The relationship information from QRef. Only included if the QRefAnnotator
 * is initialised with include_annotated_relationships.
 */
export interface KnowledgeAnswersIntentQueryPersonalEntityEntityRelationship {
  /**
   * The index of the other entity in the relationship.
   */
  entityIndex?: number;
  /**
   * Names of the relationship links.
   */
  linkPropertyName?: string[];
}

/**
 * Signals associated with Qref annotations.
 */
export interface KnowledgeAnswersIntentQueryQrefAnnotationSignals {
  /**
   * Numeric value associated with each annotation within the Qref servlet
   * output.
   */
  score?: number;
  /**
   * Trusted name confidence signal
   * https://g3doc.corp.google.com/repository/webref/preprocessing/names/tnc_classifier/README.md
   */
  trustedNameConfidence?: number;
}

/**
 * Relatedness Matrix signals for FunctionCall Arguments.
 */
export interface KnowledgeAnswersIntentQueryRelatednessSignals {
  queryPopularity?: number;
  youtubeViews?: bigint;
}

function serializeKnowledgeAnswersIntentQueryRelatednessSignals(data: any): KnowledgeAnswersIntentQueryRelatednessSignals {
  return {
    ...data,
    youtubeViews: data["youtubeViews"] !== undefined ? String(data["youtubeViews"]) : undefined,
  };
}

function deserializeKnowledgeAnswersIntentQueryRelatednessSignals(data: any): KnowledgeAnswersIntentQueryRelatednessSignals {
  return {
    ...data,
    youtubeViews: data["youtubeViews"] !== undefined ? BigInt(data["youtubeViews"]) : undefined,
  };
}

/**
 * SRM signal data. Properties here should be nonsemantic. Semantic properties
 * should be modeled directly in the SRM.
 */
export interface KnowledgeAnswersIntentQueryResponseMeaningSignalsResponseMeaningSignals {
  propertyValue?: FreebasePropertyValue[];
}

function serializeKnowledgeAnswersIntentQueryResponseMeaningSignalsResponseMeaningSignals(data: any): KnowledgeAnswersIntentQueryResponseMeaningSignalsResponseMeaningSignals {
  return {
    ...data,
    propertyValue: data["propertyValue"] !== undefined ? data["propertyValue"].map((item: any) => (serializeFreebasePropertyValue(item))) : undefined,
  };
}

function deserializeKnowledgeAnswersIntentQueryResponseMeaningSignalsResponseMeaningSignals(data: any): KnowledgeAnswersIntentQueryResponseMeaningSignalsResponseMeaningSignals {
  return {
    ...data,
    propertyValue: data["propertyValue"] !== undefined ? data["propertyValue"].map((item: any) => (deserializeFreebasePropertyValue(item))) : undefined,
  };
}

/**
 * Signals derived from overlapping saft annotations.
 */
export interface KnowledgeAnswersIntentQuerySaftSignals {
  entityType?:  | "UNMARKED" | "PERSON" | "NOMINAL_PERSON" | "ORGANIZATION" | "LOCATION" | "OTHER";
  isHeadOfIntent?: boolean;
  /**
   * Saft often marks verbs as head of intent and we may want to ignore those.
   */
  isVerb?: boolean;
  number?:  | "UNKNOWN" | "SINGULAR" | "PLURAL";
}

/**
 * Signals associated with nlp_ig::v1::SemanticAnnotator.
 */
export interface KnowledgeAnswersIntentQuerySemanticAnnotationSignals {
  /**
   * Name of the subgrammar category this annotation is associated with.
   */
  category?: string;
  /**
   * Name of the subgrammar domain.
   */
  domain?: string;
  features?: KnowledgeAnswersIntentQuerySemanticAnnotationSignalsFeature[];
  /**
   * Numeric value associated with each subgrammar annotation. Used for
   * in-domain ranking inside the Aqua Analyzer. This field is not guaranteed to
   * be in any range. Furthermore, this field should never be compared for
   * annotations with differing 'domain' value. The field is included here for
   * making the Aqua Analyzer work with subgrammar annotations that have been
   * generated in a different Aqua Analyzer (typically by TUIG
   * SemanticAnnotationServlet). TL;DR: Consumers of this message are STRONGLY
   * DISCOURAGED from using this field.
   */
  score?: number;
}

/**
 * Aqua features exported from a subgrammar. Primarily added here for External
 * Subgrammar Annotations to work. See go/esa-exported-features for details.
 * NOTE: Feature names can change and the existence of any feature is not
 * guaranteed. Get in touch with ig-eng@ before using these features.
 */
export interface KnowledgeAnswersIntentQuerySemanticAnnotationSignalsFeature {
  name?: string;
  value?: number;
}

export interface KnowledgeAnswersIntentQuerySensitiveArgumentValueGuard {
  /**
   * Decrypted and deserialized contents of |encrypted_value|. This field
   * should never be populated in prod. This is only provided for easier human
   * inspection when using dev builds (dev keys are public).
   */
  doNotUseDebugOnlyDecryptedValue?: KnowledgeAnswersIntentQueryArgumentValue;
  /**
   * Encrypted protobuffer of type ArgumentValue.
   */
  encryptedValue?: Uint8Array;
}

function serializeKnowledgeAnswersIntentQuerySensitiveArgumentValueGuard(data: any): KnowledgeAnswersIntentQuerySensitiveArgumentValueGuard {
  return {
    ...data,
    doNotUseDebugOnlyDecryptedValue: data["doNotUseDebugOnlyDecryptedValue"] !== undefined ? serializeKnowledgeAnswersIntentQueryArgumentValue(data["doNotUseDebugOnlyDecryptedValue"]) : undefined,
    encryptedValue: data["encryptedValue"] !== undefined ? encodeBase64(data["encryptedValue"]) : undefined,
  };
}

function deserializeKnowledgeAnswersIntentQuerySensitiveArgumentValueGuard(data: any): KnowledgeAnswersIntentQuerySensitiveArgumentValueGuard {
  return {
    ...data,
    doNotUseDebugOnlyDecryptedValue: data["doNotUseDebugOnlyDecryptedValue"] !== undefined ? deserializeKnowledgeAnswersIntentQueryArgumentValue(data["doNotUseDebugOnlyDecryptedValue"]) : undefined,
    encryptedValue: data["encryptedValue"] !== undefined ? decodeBase64(data["encryptedValue"] as string) : undefined,
  };
}

/**
 * Additional shopping identifiers related to an entity or IQL function call.
 * This must be passed along to the shopping backend (go/o4) to aid in
 * fulfillment. Because the shopping data models do not always line up 1-1 with
 * KG entities and are not always reconciled with each other, the message may
 * contain multiple ids. Next id: 8 LINT.IfChange
 */
export interface KnowledgeAnswersIntentQueryShoppingIds {
  /**
   * A shopping aspect cluster id. These are attributes mined from mentions in
   * web articles.
   */
  aspectClusterIds?: bigint[];
  /**
   * Brand entity id. Brands are fully reconciled with KG entities so there
   * should never be ambiguity as to which brand applies (those would be
   * separate MIDs).
   */
  brandEntityId?: bigint;
  /**
   * A category in the shopping browseonomy, a taxonomy of product types that
   * can be found at go/bx. This field is expected to contain the deepest node
   * in the browseonomy that the intent or argument pertains to, which may be an
   * internal node. It does not contain the entire path of categories.
   */
  bxCategoryIds?: number[];
  measures?: KnowledgeAnswersIntentQueryShoppingIdsMeasureValue[];
  /**
   * List of merchant customer account IDs associated with a merchant entity in
   * KG. NOTE: Soon to be deprecated, see go/merchant_mids_in_indexer design
   */
  merchantIds?: bigint[];
  /**
   * A shopping merchant source id, i.e. the key used to identify Shopping
   * Merchants as they are imported into KG. For reference, these IDs are
   * populated in: * CommerceDB under
   * BusinessIdentification.knowledge_graph.source_id * KG using the
   * /shopping/merchant/id predicate
   */
  merchantSourceIds?: bigint[];
  /**
   * Moka attributes of a product. This includes color tags but currently not
   * brand. We allow the possibility for multiple tag ids, as multiple Moka tag
   * ids may map to the same mid, and we may not be able to find a single
   * matching Moka tag. Also, cross-category Moka colors intentionally map a
   * single color mentioned in the query to an expansion of many tags
   * representing points in LAB color space (although this representation is
   * expected to change).
   */
  tagIds?: bigint[];
}

function serializeKnowledgeAnswersIntentQueryShoppingIds(data: any): KnowledgeAnswersIntentQueryShoppingIds {
  return {
    ...data,
    aspectClusterIds: data["aspectClusterIds"] !== undefined ? data["aspectClusterIds"].map((item: any) => (String(item))) : undefined,
    brandEntityId: data["brandEntityId"] !== undefined ? String(data["brandEntityId"]) : undefined,
    measures: data["measures"] !== undefined ? data["measures"].map((item: any) => (serializeKnowledgeAnswersIntentQueryShoppingIdsMeasureValue(item))) : undefined,
    merchantIds: data["merchantIds"] !== undefined ? data["merchantIds"].map((item: any) => (String(item))) : undefined,
    merchantSourceIds: data["merchantSourceIds"] !== undefined ? data["merchantSourceIds"].map((item: any) => (String(item))) : undefined,
    tagIds: data["tagIds"] !== undefined ? data["tagIds"].map((item: any) => (String(item))) : undefined,
  };
}

function deserializeKnowledgeAnswersIntentQueryShoppingIds(data: any): KnowledgeAnswersIntentQueryShoppingIds {
  return {
    ...data,
    aspectClusterIds: data["aspectClusterIds"] !== undefined ? data["aspectClusterIds"].map((item: any) => (BigInt(item))) : undefined,
    brandEntityId: data["brandEntityId"] !== undefined ? BigInt(data["brandEntityId"]) : undefined,
    measures: data["measures"] !== undefined ? data["measures"].map((item: any) => (deserializeKnowledgeAnswersIntentQueryShoppingIdsMeasureValue(item))) : undefined,
    merchantIds: data["merchantIds"] !== undefined ? data["merchantIds"].map((item: any) => (BigInt(item))) : undefined,
    merchantSourceIds: data["merchantSourceIds"] !== undefined ? data["merchantSourceIds"].map((item: any) => (BigInt(item))) : undefined,
    tagIds: data["tagIds"] !== undefined ? data["tagIds"].map((item: any) => (BigInt(item))) : undefined,
  };
}

/**
 * A measured value of a product (e.g. Hard drive size = 1 TB). The value is
 * measured in the facet's base unit. This does not necessarily match the unit
 * expressed by the user in the query. The exact unit is known to the O4 server
 * and is used in fulfillment.
 */
export interface KnowledgeAnswersIntentQueryShoppingIdsMeasureValue {
  facetId?: bigint;
  value?: number;
}

function serializeKnowledgeAnswersIntentQueryShoppingIdsMeasureValue(data: any): KnowledgeAnswersIntentQueryShoppingIdsMeasureValue {
  return {
    ...data,
    facetId: data["facetId"] !== undefined ? String(data["facetId"]) : undefined,
  };
}

function deserializeKnowledgeAnswersIntentQueryShoppingIdsMeasureValue(data: any): KnowledgeAnswersIntentQueryShoppingIdsMeasureValue {
  return {
    ...data,
    facetId: data["facetId"] !== undefined ? BigInt(data["facetId"]) : undefined,
  };
}

/**
 * A message representing an intent to use for intent scoring if the root
 * intent is invalid.
 */
export interface KnowledgeAnswersIntentQuerySignalComputationFallbackIntent {
  /**
   * The intent name of the fallback intent.
   */
  intent?: string;
}

/**
 * A message representing a simple literal value.
 */
export interface KnowledgeAnswersIntentQuerySimpleValue {
  boolValue?: boolean;
  doubleValue?: number;
  identifier?: KnowledgeAnswersIntentQueryIdentifier;
  intValue?: bigint;
  stringValue?: string;
  /**
   * Ungrounded value contains the part of the query (or web snippet, etc.)
   * that was not understood. For more information on this field, see the
   * "Ungrounded value" item in the table of contents of go/iql-v1
   */
  ungroundedValue?: string;
}

function serializeKnowledgeAnswersIntentQuerySimpleValue(data: any): KnowledgeAnswersIntentQuerySimpleValue {
  return {
    ...data,
    intValue: data["intValue"] !== undefined ? String(data["intValue"]) : undefined,
  };
}

function deserializeKnowledgeAnswersIntentQuerySimpleValue(data: any): KnowledgeAnswersIntentQuerySimpleValue {
  return {
    ...data,
    intValue: data["intValue"] !== undefined ? BigInt(data["intValue"]) : undefined,
  };
}

/**
 * Signals indicating whether this entity received or transferred support (and
 * from which entities).
 */
export interface KnowledgeAnswersIntentQuerySupportTransferSignals {
  /**
   * Entities that transferred support to this entity (mids).
   */
  supportTransferSource?: string[];
  /**
   * Entities that received support from this entity (mids).
   */
  supportTransferTarget?: string[];
}

/**
 * Signals associated with TeleportArgumentAnnotator annotations. Empty. The
 * signal being present is enough for the conformance checking library to be
 * able to check.
 */
export interface KnowledgeAnswersIntentQueryTeleportArgumentAnnotatorSignals {
}

/**
 * A token represents an ngram with relevant information about it. If the token
 * is a context phrase, it will have a prior score associated with it. The prior
 * is computed via knowledge/answers/query_generalization/
 * word_prior/word_prior_from_examples_lib.cc, and ranges between 0 and 1.
 * Stopwords and intent tokens (primary and component) have a score of 1.0.
 */
export interface KnowledgeAnswersIntentQueryToken {
  /**
   * This field is used inside Aqua and outside Aqua for identifying the token
   * indices and/or byte offsets of this Token.
   */
  evalData?: NlpSemanticParsingAnnotationEvalData;
  /**
   * |ngram| should be populated with a string from the raw query, not the
   * normalized tokens. E.g. The ngram in the ignored token for the Height
   * intent on the query [Height of barack obama], will be "Height". The ngram
   * in the ignored token for the Videos intent on the query [vidos] will be
   * "vidos".
   */
  ngram?: string;
  /**
   * Experiments that caused this Token to parse, without which this would not
   * have parsed.
   */
  parsedDueToExperiment?: string[];
  prior?: number;
  provenance?:  | "UNKNOWN" | "INTENT_PRIMARY" | "INTENT_COMPONENT" | "STOPWORD" | "CONTEXT_INTENT" | "CONTEXT_ANSWER_TYPE" | "CONTEXT_ENTITY_TYPE" | "PUNCTUATION" | "LOCATION_ALIAS_ANNOTATION" | "OPTIONALIZED";
  /**
   * Unique identifiers for the provenance of this token, for example, NLP
   * Repository Example IDs.
   */
  provenanceId?: string[];
  provenanceLanguage?: string;
  synonyms?: KnowledgeAnswersIntentQueryTokenSynonym[];
}

/**
 * Tokens includes a list of tokens, with an aggregated score of the priors of
 * the tokens, if any.
 */
export interface KnowledgeAnswersIntentQueryTokens {
  /**
   * Score for this group of tokens is currently product of priors.
   */
  score?: number;
  token?: KnowledgeAnswersIntentQueryToken[];
}

/**
 * A TokenSynonym contains information about synonyms of a Token's ngram. The
 * synonyms were the ones used during parsing for token explanation in place of
 * the original ngrams. Example 1: [present population of nyc] We can generate
 * interpretation kc:/location/statistical_region:population by converting
 * "present" to its synonym "current", which is a context phrase for the intent.
 * The ngram for this token would be "present" and the string "current" would be
 * stored in synonym_ngram. Example 2: [nys important cities] We can generate
 * interpretation kc:/location/us_state:cities by converting "important" to its
 * synonym "major" or its synonym "biggest", because both "major cities" and
 * "biggest cities" are attribute phrases for the intent. In this case, the
 * ngram in this Token is "important cities", and the token_synonyms
 * (specifically, the synonym_ngram field) would store "major cities" and
 * "biggest cities", since those are the actual synonym ngrams that match the
 * attribute phrases. For context phrases, we generally should have only one
 * matched_squery_synonyms, since we try to find the best synonyms to use using
 * the context phrase score. However, for attribute phrase we don't really have
 * enough info to determine which synonym is better if they both trigger the
 * same intent, and hence we will propagate both synonyms.
 */
export interface KnowledgeAnswersIntentQueryTokenSynonym {
  source?:  | "UNKNOWN" | "SQUERY";
  synonymNgram?: string;
}

export interface KnowledgeAnswersIntersectType {
  slotNames?: string[];
}

/**
 * A Marker specifies a Meaning Expression's (i.e. intent FunctionCall)
 * purpose. NOTE: Markers always impact go/intent-resolution semantics.
 */
export interface KnowledgeAnswersMarker {
  command?: KnowledgeAnswersMarkerCommand;
  openQuestion?: KnowledgeAnswersMarkerOpenQuestion;
  polarQuestion?: KnowledgeAnswersMarkerPolarQuestion;
  stateOfAffairs?: KnowledgeAnswersMarkerStateOfAffairs;
}

function serializeKnowledgeAnswersMarker(data: any): KnowledgeAnswersMarker {
  return {
    ...data,
    openQuestion: data["openQuestion"] !== undefined ? serializeKnowledgeAnswersMarkerOpenQuestion(data["openQuestion"]) : undefined,
  };
}

function deserializeKnowledgeAnswersMarker(data: any): KnowledgeAnswersMarker {
  return {
    ...data,
    openQuestion: data["openQuestion"] !== undefined ? deserializeKnowledgeAnswersMarkerOpenQuestion(data["openQuestion"]) : undefined,
  };
}

/**
 * Indicates a command, instructing someone to do something which might be
 * explicit (e.g. [call me]) or implicit (e.g. [can you call me]).
 */
export interface KnowledgeAnswersMarkerCommand {
}

/**
 * Indicates a question, requesting the value of a specified slot. Not
 * applicable if the requested slot simultaneously appears as an argument. See
 * go/requested-slots for details. Next ID: 3
 */
export interface KnowledgeAnswersMarkerOpenQuestion {
  /**
   * Note: This is still under development and not available for general use.
   * Contact meaning-platform-eng@ for questions.
   */
  slotKey?: KnowledgeAnswersMeaningSchemaSlotKey;
  /**
   * One or multiple slots may be requested by the marker. See
   * go/mrf-multiple-output-slots for details on requesting multiple output
   * slots.
   */
  slotName?: string[];
}

function serializeKnowledgeAnswersMarkerOpenQuestion(data: any): KnowledgeAnswersMarkerOpenQuestion {
  return {
    ...data,
    slotKey: data["slotKey"] !== undefined ? serializeKnowledgeAnswersMeaningSchemaSlotKey(data["slotKey"]) : undefined,
  };
}

function deserializeKnowledgeAnswersMarkerOpenQuestion(data: any): KnowledgeAnswersMarkerOpenQuestion {
  return {
    ...data,
    slotKey: data["slotKey"] !== undefined ? deserializeKnowledgeAnswersMeaningSchemaSlotKey(data["slotKey"]) : undefined,
  };
}

/**
 * Indicates a question, requesting the truth-value/actualness of a state of
 * affairs denoted by the expression encompassed by the FunctionCall this
 * appears on. Often this is a yes/no question, e.g. [was tom cruise in top gun]
 * : ActedIn.polar(Movie=/m/top_gun, Actor=/m/tom_cruise) Not all polar
 * questions will necessarily have a yes/no answer; the expected resolution of a
 * polar question is a StateOfAffairs. e.g. [is chocolate good for you] :
 * FoodItemAttribute.polar(/m/chocolate, /m/healthy) which may not have a simple
 * yes/no answer. See go/mrf-polar-questions for details.
 */
export interface KnowledgeAnswersMarkerPolarQuestion {
}

/**
 * Indicates a reference to a particular state of affairs denoted by the
 * expression encompassed by the FunctionCall this appears on. The state may be
 * actual e.g. [new york is a city] : IsA.state(/m/new_york, /m/city) or not
 * e.g. [1+1=3] : Addition.state(Sum=3, Addend=1, Addend=1) The state can also
 * represent an proposition of an action, e.g. [cinar gave jason a cookie] :
 * Give.state(Giver=cinar, Receiver=jason, Object=cookie) See
 * go/mrf-polar-questions for details.
 */
export interface KnowledgeAnswersMarkerStateOfAffairs {
}

/**
 * The primary key for an intent. Next ID: 3
 */
export interface KnowledgeAnswersMeaningSchemaKey {
  /**
   * The version has been changed to be defined as a horizontal version on the
   * entire meaning catalog instead of per-schema.
   */
  deprecatedVersion?: bigint;
  /**
   * The minted MID for an intent.
   */
  mid?: string;
}

function serializeKnowledgeAnswersMeaningSchemaKey(data: any): KnowledgeAnswersMeaningSchemaKey {
  return {
    ...data,
    deprecatedVersion: data["deprecatedVersion"] !== undefined ? String(data["deprecatedVersion"]) : undefined,
  };
}

function deserializeKnowledgeAnswersMeaningSchemaKey(data: any): KnowledgeAnswersMeaningSchemaKey {
  return {
    ...data,
    deprecatedVersion: data["deprecatedVersion"] !== undefined ? BigInt(data["deprecatedVersion"]) : undefined,
  };
}

/**
 * The primary key for a MeaningSchema slot. Next ID: 3 For
 * //depot/google3/logs/proto/knowledge/interpretation/intent_query.proto in the
 * "ThenChange", please update Argument.SlotKey. LINT.IfChange
 */
export interface KnowledgeAnswersMeaningSchemaSlotKey {
  /**
   * The minted MID for the slot. This ID uniquely identifies the slot
   * globally.
   */
  mid?: string;
  /**
   * A stable unique ID for this intent minted from go/uniqueid. NOTE: This is
   * considered a private field used only for internal Intent Catalog purposes
   * (i.e. as a source ID for generating this intent's associated MID).
   * Additionally, this field is only populated on the schema. TODO
   * (b/168907943): Move "unique_id" out of MeaningSchemaSlotKey proto message.
   * Note: Please do not use this field. It is going to be moved out of this
   * proto message.
   */
  uniqueId?: bigint;
}

function serializeKnowledgeAnswersMeaningSchemaSlotKey(data: any): KnowledgeAnswersMeaningSchemaSlotKey {
  return {
    ...data,
    uniqueId: data["uniqueId"] !== undefined ? String(data["uniqueId"]) : undefined,
  };
}

function deserializeKnowledgeAnswersMeaningSchemaSlotKey(data: any): KnowledgeAnswersMeaningSchemaSlotKey {
  return {
    ...data,
    uniqueId: data["uniqueId"] !== undefined ? BigInt(data["uniqueId"]) : undefined,
  };
}

/**
 * A MeasurementType configures a value that consists of a measurement. The
 * expected value should have a number and a mid representing the unit. Note:
 * this is currently only used for attribute answer value types. Configuration
 * intent slot as measurement is yet to be supported (or instead we should
 * universally use SemanticType).
 */
export interface KnowledgeAnswersMeasurementType {
  /**
   * Contains data about current schema remodelings at this ValueType level.
   * For more information see go/meaning-remodeling-framework.
   */
  remodelings?: NlpMeaningMeaningRemodelings;
}

function serializeKnowledgeAnswersMeasurementType(data: any): KnowledgeAnswersMeasurementType {
  return {
    ...data,
    remodelings: data["remodelings"] !== undefined ? serializeNlpMeaningMeaningRemodelings(data["remodelings"]) : undefined,
  };
}

function deserializeKnowledgeAnswersMeasurementType(data: any): KnowledgeAnswersMeasurementType {
  return {
    ...data,
    remodelings: data["remodelings"] !== undefined ? deserializeNlpMeaningMeaningRemodelings(data["remodelings"]) : undefined,
  };
}

/**
 * A NormalizedStringType configures a value that is one of the listed
 * normalized_values. An arbitrary mapping from input strings to
 * normalized_values can be specified in the local intent config. Only
 * alphabetical strings can be used as normalized_values. This type should NOT
 * be used for: - Mids, ids, dates, or other structured data. Use an annotator
 * instead, and address any quality issues at the annotator level. - Simplifying
 * grammar rules. If you are not using the normalized_values in your question
 * semantics, you should remove the slot. Use additional query_examples instead.
 */
export interface KnowledgeAnswersNormalizedStringType {
  normalizedValue?: string[];
  /**
   * Contains data about current schema remodelings at this ValueType level.
   * For more information see go/meaning-remodeling-framework.
   */
  remodelings?: NlpMeaningMeaningRemodelings;
}

function serializeKnowledgeAnswersNormalizedStringType(data: any): KnowledgeAnswersNormalizedStringType {
  return {
    ...data,
    remodelings: data["remodelings"] !== undefined ? serializeNlpMeaningMeaningRemodelings(data["remodelings"]) : undefined,
  };
}

function deserializeKnowledgeAnswersNormalizedStringType(data: any): KnowledgeAnswersNormalizedStringType {
  return {
    ...data,
    remodelings: data["remodelings"] !== undefined ? deserializeNlpMeaningMeaningRemodelings(data["remodelings"]) : undefined,
  };
}

/**
 * A NumberType configures a value whose type is intended to be numeric.
 */
export interface KnowledgeAnswersNumberType {
  /**
   * If true, the semantics of the NumberType argument are retained as a
   * string, rather than being converted to a float-type object. This option is
   * particularly useful in cases where leading 0s in the user input are
   * meaningful, e.g. for zip codes or sports jersey numbers. For the user-
   * specified value "01", for instance, the PathQuery semantics will be: def
   * $Slot "01"
   */
  keepAsString?: boolean;
  /**
   * Range constraint limits the set of numbers accepted by this type. The
   * constraint applies to all subtypes. Currently, this constraint is only
   * enforced in Loose Parser.
   */
  rangeConstraint?: KnowledgeAnswersRangeConstraint;
  /**
   * Contains data about current schema remodelings at this ValueType level.
   * For more information see go/meaning-remodeling-framework.
   */
  remodelings?: NlpMeaningMeaningRemodelings;
  /**
   * sub_type is a list of the NumberSubTypes which are accepted. If the list
   * is empty, that means all numeric or ordinal values are accepted. If
   * multiple values are specified, then this value accepts any of the sub_types
   * in the list.
   */
  subType?:  | "NONE" | "ORDINAL" | "NUMERIC" | "INTEGER" | "FLOAT"[];
}

function serializeKnowledgeAnswersNumberType(data: any): KnowledgeAnswersNumberType {
  return {
    ...data,
    remodelings: data["remodelings"] !== undefined ? serializeNlpMeaningMeaningRemodelings(data["remodelings"]) : undefined,
  };
}

function deserializeKnowledgeAnswersNumberType(data: any): KnowledgeAnswersNumberType {
  return {
    ...data,
    remodelings: data["remodelings"] !== undefined ? deserializeNlpMeaningMeaningRemodelings(data["remodelings"]) : undefined,
  };
}

/**
 * Custom opaque type used by actions-on-google in-dialog queries. See
 * go/3p-custom-intents-wrt-meaning-catalog
 */
export interface KnowledgeAnswersOpaqueAogType {
}

export interface KnowledgeAnswersOpaqueAppAnnotationType {
}

export interface KnowledgeAnswersOpaqueAudioType {
}

export interface KnowledgeAnswersOpaqueCalendarEventType {
}

/**
 * Used for sensitive calendar events that require additional BUILD visibility
 * protection. See go/multi-account-event-representation.
 */
export interface KnowledgeAnswersOpaqueCalendarEventWrapperType {
}

export interface KnowledgeAnswersOpaqueCalendarReferenceType {
}

export interface KnowledgeAnswersOpaqueComplexQueriesRewriteType {
}

export interface KnowledgeAnswersOpaqueComponentReferenceIndexType {
}

export interface KnowledgeAnswersOpaqueDeviceIdType {
}

export interface KnowledgeAnswersOpaqueDeviceType {
}

export interface KnowledgeAnswersOpaqueDeviceUserIdentityType {
}

export interface KnowledgeAnswersOpaqueHomeAutomationDeviceType {
}

export interface KnowledgeAnswersOpaqueLocationType {
}

export interface KnowledgeAnswersOpaqueMediaType {
}

export interface KnowledgeAnswersOpaqueMessageNotificationType {
}

export interface KnowledgeAnswersOpaqueMoneyType {
}

export interface KnowledgeAnswersOpaqueNewsProviderType {
}

export interface KnowledgeAnswersOpaqueOnDeviceType {
}

/**
 * Entity parsed from manual grammar interpretation in the Personal
 * Intelligence domain.
 */
export interface KnowledgeAnswersOpaquePersonalIntelligenceEntityType {
}

export interface KnowledgeAnswersOpaquePersonType {
}

export interface KnowledgeAnswersOpaqueProductivityListItemType {
}

export interface KnowledgeAnswersOpaqueRecurrenceType {
}

export interface KnowledgeAnswersOpaqueReminderType {
}

export interface KnowledgeAnswersOpaqueShoppingMerchantType {
}

export interface KnowledgeAnswersOpaqueShoppingOfferType {
}

export interface KnowledgeAnswersOpaqueShoppingProductExpressionType {
}

export interface KnowledgeAnswersOpaqueShoppingProductType {
}

export interface KnowledgeAnswersOpaqueShoppingStoreType {
}

export interface KnowledgeAnswersOpaqueTimerType {
}

/**
 * Note: OpaqueType is deprecated and addition of new fields is not allowed.
 * Refer to go/opaque_type for details. If you think this is the only way to
 * implement your feature, attend an office hours (go/meaning-help) and discuss
 * with the MRF team. An OpaqueType configures a value whose type is only
 * interpretable by _specific_ clients of the intent catalog. This means
 * horizontal 'features' like pretty printing, correct logging, intent
 * blacklisting and signal aggregation will not work for opaque value types. It
 * has a field for each type in IntentQuery that is not covered by a non-opaque
 * type (specifically: protocol messages). The fields are themselves messages
 * declared in this file. The specific opaque value types must be empty
 * messages. If you find a need to add any fields to these messages, make them
 * non-opaque and implement all of the code to treat them as first class types.
 * It is allowable for a value to have more than one of the opaque types. See
 * http://go/opaque-type-for-value-type. LINT.IfChange Next Id: 31
 */
export interface KnowledgeAnswersOpaqueType {
  aogType?: KnowledgeAnswersOpaqueAogType;
  appAnnotationType?: KnowledgeAnswersOpaqueAppAnnotationType;
  audioType?: KnowledgeAnswersOpaqueAudioType;
  calendarEventType?: KnowledgeAnswersOpaqueCalendarEventType;
  calendarEventWrapperType?: KnowledgeAnswersOpaqueCalendarEventWrapperType;
  calendarReferenceType?: KnowledgeAnswersOpaqueCalendarReferenceType;
  complexQueriesRewriteType?: KnowledgeAnswersOpaqueComplexQueriesRewriteType;
  componentReferenceType?: KnowledgeAnswersOpaqueComponentReferenceIndexType;
  deviceIdType?: KnowledgeAnswersOpaqueDeviceIdType;
  deviceType?: KnowledgeAnswersOpaqueDeviceType;
  deviceUserIdentityType?: KnowledgeAnswersOpaqueDeviceUserIdentityType;
  homeAutomationDeviceType?: KnowledgeAnswersOpaqueHomeAutomationDeviceType;
  locationType?: KnowledgeAnswersOpaqueLocationType;
  mediaType?: KnowledgeAnswersOpaqueMediaType;
  messageNotificationType?: KnowledgeAnswersOpaqueMessageNotificationType;
  moneyType?: KnowledgeAnswersOpaqueMoneyType;
  narrativeNewsProviderType?: KnowledgeAnswersOpaqueNewsProviderType;
  onDeviceType?: KnowledgeAnswersOpaqueOnDeviceType;
  personalIntelligenceEntityType?: KnowledgeAnswersOpaquePersonalIntelligenceEntityType;
  personType?: KnowledgeAnswersOpaquePersonType;
  productivityListItemType?: KnowledgeAnswersOpaqueProductivityListItemType;
  recurrenceType?: KnowledgeAnswersOpaqueRecurrenceType;
  reminderType?: KnowledgeAnswersOpaqueReminderType;
  /**
   * Contains data about current schema remodelings at this ValueType level.
   * For more information see go/meaning-remodeling-framework.
   */
  remodelings?: NlpMeaningMeaningRemodelings;
  shoppingMerchantType?: KnowledgeAnswersOpaqueShoppingMerchantType;
  shoppingOfferType?: KnowledgeAnswersOpaqueShoppingOfferType;
  shoppingProductExpressionType?: KnowledgeAnswersOpaqueShoppingProductExpressionType;
  shoppingProductType?: KnowledgeAnswersOpaqueShoppingProductType;
  shoppingStoreType?: KnowledgeAnswersOpaqueShoppingStoreType;
  timerType?: KnowledgeAnswersOpaqueTimerType;
}

function serializeKnowledgeAnswersOpaqueType(data: any): KnowledgeAnswersOpaqueType {
  return {
    ...data,
    remodelings: data["remodelings"] !== undefined ? serializeNlpMeaningMeaningRemodelings(data["remodelings"]) : undefined,
  };
}

function deserializeKnowledgeAnswersOpaqueType(data: any): KnowledgeAnswersOpaqueType {
  return {
    ...data,
    remodelings: data["remodelings"] !== undefined ? deserializeNlpMeaningMeaningRemodelings(data["remodelings"]) : undefined,
  };
}

/**
 * Plexity is a conceptual distinction between viewing something (a slot
 * filler, for example) as a single individual, or as a complex concept
 * consisting of multiple individuals or subparts. Note that plexity is not the
 * same as (or correlated with) either grammatical number or with distributive
 * and collective interpretations of the slot. The PlexityRequirement proto and
 * Plexity enum are defined outside ValueType as we may move the plexity
 * specification to a different place in the intent protos in future.
 */
export interface KnowledgeAnswersPlexityRequirement {
  /**
   * Contains data about current schema remodelings at this ValueType level.
   * For more information see go/meaning-remodeling-framework.
   */
  remodelings?: NlpMeaningMeaningRemodelings;
  /**
   * Simple plexity: the slot's filler must allow the specified plexity value,
   * for example it must contain multiple individuals if the plexity is
   * MULTIPLEX.
   */
  simplePlexity?:  | "UNSPECIFIED_PLEXITY" | "UNIPLEX" | "MULTIPLEX" | "ANY_PLEXITY";
}

function serializeKnowledgeAnswersPlexityRequirement(data: any): KnowledgeAnswersPlexityRequirement {
  return {
    ...data,
    remodelings: data["remodelings"] !== undefined ? serializeNlpMeaningMeaningRemodelings(data["remodelings"]) : undefined,
  };
}

function deserializeKnowledgeAnswersPlexityRequirement(data: any): KnowledgeAnswersPlexityRequirement {
  return {
    ...data,
    remodelings: data["remodelings"] !== undefined ? deserializeNlpMeaningMeaningRemodelings(data["remodelings"]) : undefined,
  };
}

/**
 * A special type representing a polar question.
 */
export interface KnowledgeAnswersPolarQuestionType {
  /**
   * Contains data about current schema remodelings at this ValueType level.
   * For more information see go/meaning-remodeling-framework.
   */
  remodelings?: NlpMeaningMeaningRemodelings;
}

function serializeKnowledgeAnswersPolarQuestionType(data: any): KnowledgeAnswersPolarQuestionType {
  return {
    ...data,
    remodelings: data["remodelings"] !== undefined ? serializeNlpMeaningMeaningRemodelings(data["remodelings"]) : undefined,
  };
}

function deserializeKnowledgeAnswersPolarQuestionType(data: any): KnowledgeAnswersPolarQuestionType {
  return {
    ...data,
    remodelings: data["remodelings"] !== undefined ? deserializeNlpMeaningMeaningRemodelings(data["remodelings"]) : undefined,
  };
}

export interface KnowledgeAnswersRangeConstraint {
  max?: KnowledgeAnswersRangeConstraintRangeEndpoint;
  min?: KnowledgeAnswersRangeConstraintRangeEndpoint;
}

export interface KnowledgeAnswersRangeConstraintRangeEndpoint {
  /**
   * If true, then this endpoint's value is not included in the range.
   */
  isExclusive?: boolean;
  /**
   * The value of this endpoint
   */
  value?: number;
}

export interface KnowledgeAnswersSameType {
  slotName?: string;
}

/**
 * A SemanticType configures a value determined by another source, in
 * particular another intent or a semantic frame. See go/unifying-intents and
 * go/framery.
 */
export interface KnowledgeAnswersSemanticType {
  /**
   * If true, is compatible with a schema whose answer_type is any
   * semantic_type including empty (since by default schemas return themselves
   * as semantic_types (b/211438997). This is used primarily for slot
   * composition. Example: for the slot name: Operand type { semantic_type {
   * allow_all: true } entity_type {} } * An entity_type or a schema with
   * answer_type 'entity_type' can fill Operand. * A schema with either (a) no
   * answer_type or (b) answer_type with !semantic_type.names().empty() can fill
   * Operand * A schema with answer_type 'date' CAN NOT fill Operand. Note that
   * when there is an explicit answer_type, the 'self' semantic_type is not
   * considered.
   */
  allowAll?: boolean;
  /**
   * Determines whether or not the meaning schema that contains this
   * semantic_type conforms to a function call with the name and arguments taken
   * from the meaning schema. As it refers to the "containing_intent", this
   * field should only be set in a semantic_type declared in an intent's
   * type_members field. The behavior of this field is undefined in other cases,
   * for example, declaring the type of an intent slot. On Assistant, we use
   * meaning schemas for argument types to represent both function call values
   * as well as a reusable tool to host other argument values (opaque types,
   * normalized strings, subsets of entities) across intents. Teams need this
   * information to run conformance checks and annotate new data. Example: If
   * the intents below are in the intent catalog, then: - Intent(slot="some
   * string") is conformant, because Type has string_type{} in its type_members.
   * - Intent(slot=Type()) is not conformant, because Type has set
   * semantic_type.includes_containing_intent to false. - Intent(slot=SubType())
   * is conformant, because type_members is not inherited. { id: "Intent" slot:
   * { name: "slot" type: { semantic_type { name: "Type" }} } } { id: "Type"
   * type_members { string_type{} semantic_type { includes_containing_intent:
   * false } } } { id: "SubType" parent { id: "Type" relationship_type: SUBTYPE
   * } }
   */
  includesContainingIntent?: boolean;
  /**
   * Names of valid sources of the semantics (for example: a frame or an
   * intent).
   */
  name?: string[];
  /**
   * Contains data about current schema remodelings at the SemanticType name
   * level. The "name" field contains all possible semantic type names and
   * "semantic_type_name_remodelings" acts as an overlay to determine which ones
   * to surface based on which schema remodeling IDs are requested. For more
   * information see go/meaning-remodeling-framework.
   */
  nameRemodelings?: NlpMeaningSemanticTypeNameMeaningRemodelings[];
  /**
   * Contains data about current schema remodelings at this ValueType level.
   * For more information see go/meaning-remodeling-framework.
   */
  remodelings?: NlpMeaningMeaningRemodelings;
}

function serializeKnowledgeAnswersSemanticType(data: any): KnowledgeAnswersSemanticType {
  return {
    ...data,
    nameRemodelings: data["nameRemodelings"] !== undefined ? data["nameRemodelings"].map((item: any) => (serializeNlpMeaningSemanticTypeNameMeaningRemodelings(item))) : undefined,
    remodelings: data["remodelings"] !== undefined ? serializeNlpMeaningMeaningRemodelings(data["remodelings"]) : undefined,
  };
}

function deserializeKnowledgeAnswersSemanticType(data: any): KnowledgeAnswersSemanticType {
  return {
    ...data,
    nameRemodelings: data["nameRemodelings"] !== undefined ? data["nameRemodelings"].map((item: any) => (deserializeNlpMeaningSemanticTypeNameMeaningRemodelings(item))) : undefined,
    remodelings: data["remodelings"] !== undefined ? deserializeNlpMeaningMeaningRemodelings(data["remodelings"]) : undefined,
  };
}

/**
 * Policy controlling argument level eval.
 */
export interface KnowledgeAnswersSensitivityArgumentEvalPolicy {
  /**
   * Optional cannery policy name. If it presents then Intent Scrubber will use
   * the corresponding Cannery rule for argument scrubbing and redaction
   * instead. It should only be used for existing complex argment value types
   * such as HomeAutomationDevice.
   */
  policyName?: string;
  /**
   * Redact corresponding span of the string query.
   */
  redactQuerySpan?: boolean;
  /**
   * Customized replacement phrase, if missing ${ArgumentName}_REDACTED is used
   * as default.
   */
  replacement?: string;
  /**
   * Scrub argument value and signals before saving to eval storage. If not
   * set, 1) inherit the policy from the outer argument if there is one (for
   * nested intents); 2) finally default to type based scrubbing: see
   * go/argument-type-scrubbing.
   */
  scrubArgumentValue?: boolean;
}

/**
 * Instructions (eg., logging, disambiguation, ads serving) of handling a
 * sensitive intent and its data. LINT.IfChange NextId: 8
 */
export interface KnowledgeAnswersSensitivityInstruction {
  argument?: KnowledgeAnswersSensitivityInstructionArgument;
  intent?: KnowledgeAnswersSensitivityInstructionIntent;
  /**
   * This field is for backward compatibility.
   */
  legacyAssistantSensitivity?: SearchPolicyRankableSensitivity;
  /**
   * Controls whether a top-level intent is multi-account approved. NLU will do
   * go/cross-account-understanding only for intents with this bit on. Also,
   * this bit should be propagated to user turn Attentionl Entities to extend
   * protection of cross-account data to next turns. In principle fulfillment
   * services (e.g., Monastery) should only dispatch such intents to
   * multi-account approved fulfillers (schemas), at least when the user has a
   * linked dasher account. The Assistant runtime policy engine should treat a
   * query as dasher data if 1) this bit is true in the string redaction, and 2)
   * the user has a linked dasher account, and apply a more restrictive rule for
   * whitelisting, regardless of the actual account provenance in Sensitivity.
   * Example: [User logged in to their personal gmail account.] Q1: "Schedule a
   * meeting tiltled okr review at 3pm". Assistant: "Should I scheduled it on
   * your xyz@gmail.com account?" Q2: "No, add it to my xyz@bigcorp.com
   * account." We don't know Q1 is dasher data until Q2. To prevent leaking of
   * Q1 to non-dasher approved binaries, this bit should be used as a proactive
   * measure. It might introduce some over-triggering (e.g., user says "Yes" in
   * Q2), but is much better than blindly treating every query as dasher, not
   * considering whether it actually triggers any multi-account capable intents
   * or not (see b/164420114 for example).
   */
  multiAccountAllowed?: boolean;
  previousQuery?: KnowledgeAnswersSensitivityInstructionPreviousQuery;
}

function serializeKnowledgeAnswersSensitivityInstruction(data: any): KnowledgeAnswersSensitivityInstruction {
  return {
    ...data,
    legacyAssistantSensitivity: data["legacyAssistantSensitivity"] !== undefined ? serializeSearchPolicyRankableSensitivity(data["legacyAssistantSensitivity"]) : undefined,
  };
}

function deserializeKnowledgeAnswersSensitivityInstruction(data: any): KnowledgeAnswersSensitivityInstruction {
  return {
    ...data,
    legacyAssistantSensitivity: data["legacyAssistantSensitivity"] !== undefined ? deserializeSearchPolicyRankableSensitivity(data["legacyAssistantSensitivity"]) : undefined,
  };
}

/**
 * Slot/Argument level instructions.
 */
export interface KnowledgeAnswersSensitivityInstructionArgument {
  eval?: KnowledgeAnswersSensitivityArgumentEvalPolicy;
  logging?: KnowledgeAnswersSensitivityLoggingPolicy;
  serving?: KnowledgeAnswersSensitivityServingPolicy;
  storage?: KnowledgeAnswersSensitivityStoragePolicy;
}

/**
 * Intent level instructions apply to the entire intent and all its argument
 * values.
 */
export interface KnowledgeAnswersSensitivityInstructionIntent {
  eval?: KnowledgeAnswersSensitivityIntentEvalPolicy;
  footprints?: KnowledgeAnswersSensitivityMyActivityPolicy;
  logging?: KnowledgeAnswersSensitivityLoggingPolicy;
  serving?: KnowledgeAnswersSensitivityServingPolicy;
  storage?: KnowledgeAnswersSensitivityStoragePolicy;
}

/**
 * Instructions for knowledge_context.PreviousQuery. See
 * go/apps-userdata-guidelines.
 */
export interface KnowledgeAnswersSensitivityInstructionPreviousQuery {
  logging?: KnowledgeAnswersSensitivityLoggingPolicy;
  serving?: KnowledgeAnswersSensitivityServingPolicy;
  storage?: KnowledgeAnswersSensitivityStoragePolicy;
}

/**
 * Policy controlling intent level eval.
 */
export interface KnowledgeAnswersSensitivityIntentEvalPolicy {
  /**
   * Policy for all arguments, so no need to repeat on every argument.
   */
  allArguments?: KnowledgeAnswersSensitivityArgumentEvalPolicy;
  /**
   * Controls whether to enabled limited logging (rpc whitelisting + GWS log
   * query redaction) if the intent wins post-fulfillment ranking.
   */
  enabled?: boolean;
  /**
   * The eval policy won't apply if the annotated intent is a root. This check
   * is majorly to prevent calling IntentScrubber halfway from
   * InterpretationScrubber via nested intents.
   */
  nestedIntentOnly?: boolean;
  /**
   * Scrub entire intent before saving to eval storage, leaving only intent
   * name and sensitivity info.
   */
  scrubEntireIntent?: boolean;
}

/**
 * Policies controlling the logging.
 */
export interface KnowledgeAnswersSensitivityLoggingPolicy {
  /**
   * The contents of the argument value should be scrubbed before being written
   * to logs.
   */
  scrubArgumentValue?: boolean;
  /**
   * If this is set to true, this Sensitivity's presence will result in
   * QRewrite to enable AS logging to scrub any discourse context.
   */
  scrubContext?: boolean;
}

/**
 * Policy controlling MyActivity.
 */
export interface KnowledgeAnswersSensitivityMyActivityPolicy {
  myActivityRedactedAction?:  | "UNKNOWN_ACTION" | "REPLY_TO_BROADCAST" | "INITIATE_CALL" | "SEARCH_EMAIL" | "SEND_SMS" | "SEND_MESSAGE" | "SEND_EMAIL" | "SEND_CHAT_MESSAGE" | "VIEW_AGENDA" | "SHOW_CALENDAR_EVENT" | "ADD_CALENDAR_EVENT" | "DELETE_CALENDAR_EVENT" | "MODIFY_CALENDAR_EVENT" | "SEARCH_CALENDAR" | "SEARCH_TEXT_MESSAGE" | "REPLY_TO_MESSAGE" | "REPLY_TO_NOTIFICATION" | "READ_MESSAGE_NOTIFICATION" | "REPLY_TO_READ_MESSAGE_NOTIFICATION" | "SEARCH_GMAIL" | "YOUTUBE_KIDS" | "SEND_DIGITAL_OBJECT" | "SEND_FEEDBACK" | "SHARE_PHOTO" | "SHARE_VIDEO" | "SHARE_MUSIC" | "SHARE_SCREENSHOT" | "SHARE_WEBPAGE" | "REDIAL_CALL" | "RETURN_CALL" | "RETURN_MISSED_CALL" | "ROUTINE" | "DIAL_INTO_MEETING" | "SHARE_DIGITAL_OBJECT" | "COMPOSE_EMAIL" | "FIND_ON_APP_OR_BROWSER" | "KEYBOARD_DICTATION" | "SEARCH_GSUITE" | "JOIN_MEETING" | "CREATE_MEETING" | "CREATE_MEMORY" | "IN_CALL_PUNT" | "TELL_MY_FAMILY" | "ADD_REMINDER" | "SHOW_REMINDER" | "UPDATE_REMINDER" | "DELETE_REMINDER" | "SHOW_LIST" | "MODIFY_LIST" | "SHOW_NOTE" | "MODIFY_NOTE" | "READ_SLEEP" | "WRITE_SLEEP" | "READ_ACTIVITY" | "WRITE_ACTIVITY" | "READ_NUTRITION" | "WRITE_NUTRITION" | "READ_WELLNESS" | "WRITE_WELLNESS" | "MAKE_BROADCAST";
  /**
   * This field will be translated by footprints and is used to describe the
   * content that was redacted that will be displayed to the user in MyActivity.
   */
  myActivityRedactionKey?: string;
}

/**
 * Canonical representation of query sensitivites. See go/sensitive-intents for
 * more details.
 */
export interface KnowledgeAnswersSensitivitySensitivity {
  /**
   * Used to annotate the provenace of cross-account personal data. See
   * go/cross-account-understanding. Sensitivity could be annotated at query,
   * intent, and argument levels. Query and intent could have data from multiple
   * accounts, so this field is repeated. A sensitive
   * knowledge_context.PreviousQuery might be dropped to prevent leaking
   * cross-account data via Genie rewrite. For arguments, the best practice is
   * to not blend multi-account data, and this field should be treated as
   * singular to make ownership clear. When publishing attentional entities,
   * contextual NLU might drop an argument that contains data from a different
   * account for data protection. Mixing multi-account data in one argument will
   * cause data from the primary account to be dropped altogether, which is an
   * unnecessary quality loss.
   */
  accountProvenance?: QualityQrewriteAccountProvenance[];
  /**
   * Instruction of handling sensitive intent/argument data. Can be specified
   * in Intent Catalog.
   */
  instruction?: KnowledgeAnswersSensitivityInstruction;
  /**
   * This should be systematically added without requiring the feature
   * developers to add a source. This is for debug purpose as to whether the
   * Sensitivity's trace/path included any of landmark code path helpful for
   * tracing back the sensitivity sources. One should add a new source when one
   * sees fits. It's chronological order as to which source is added first. One
   * should not manually add a source. The same source can be repeated if the
   * Sensitivity object went through the same code path twice.
   */
  source?:  | "UNKNOWN_SOURCE" | "INTENT_CATALOG" | "GENIE_REWRITER" | "FUNCTION_CALL_ARGUMENT_VALUE" | "ATTENTIONAL_ENTITY" | "PII_DETECTOR" | "DIALOG_STATE" | "ON_DEVICE" | "FUNCTION_CALL" | "END_OF_QREWRITE" | "SYSTEM_RESPONSE" | "DIALOG_INTENT_STATE" | "ANALYZER_POST_PROCESSOR" | "SAGE" | "ANNOTATION_ARGUMENT_VALUE" | "DIALOG_INTENT_STATE_INTENT" | "DIALOG_INTENT_STATE_INTENT_CONTEXTUAL" | "IGDP"[];
  /**
   * Sensitivity type. See the enum definition below.
   */
  type?:  | "UNKNOWN_TYPE" | "INTENT" | "CONTEXTUAL";
}

function serializeKnowledgeAnswersSensitivitySensitivity(data: any): KnowledgeAnswersSensitivitySensitivity {
  return {
    ...data,
    accountProvenance: data["accountProvenance"] !== undefined ? data["accountProvenance"].map((item: any) => (serializeQualityQrewriteAccountProvenance(item))) : undefined,
    instruction: data["instruction"] !== undefined ? serializeKnowledgeAnswersSensitivityInstruction(data["instruction"]) : undefined,
  };
}

function deserializeKnowledgeAnswersSensitivitySensitivity(data: any): KnowledgeAnswersSensitivitySensitivity {
  return {
    ...data,
    accountProvenance: data["accountProvenance"] !== undefined ? data["accountProvenance"].map((item: any) => (deserializeQualityQrewriteAccountProvenance(item))) : undefined,
    instruction: data["instruction"] !== undefined ? deserializeKnowledgeAnswersSensitivityInstruction(data["instruction"]) : undefined,
  };
}

/**
 * Policies controlling RPC Whitelist at serving time.
 */
export interface KnowledgeAnswersSensitivityServingPolicy {
  /**
   * If this is set to true, QRewrite will enable RPC Whitelist to be applied
   * in Assistant Server and Genie Rewriter.
   */
  enableRpcWhitelist?: boolean;
}

/**
 * Policies controlling the storage.
 */
export interface KnowledgeAnswersSensitivityStoragePolicy {
  /**
   * The contents of the argument value should be encrypted before being
   * written to a persistent storage (even if the storage has short
   * time-to-live). No-op when specified at intent level.
   */
  encryptArgumentValue?: boolean;
  /**
   * If this is set true, we encrypt QueryAnnotationDataProto prior to writing
   * it to Footprint ASSISTANT_EPHEMERAL corpus. This enables restricting ACL to
   * the data.
   */
  encryptQueryAnnotationData?: boolean;
  /**
   * If this is set to true, the following fields in ConversationSnapshot are
   * scrubbed: * circulated_state.squery * spoken_query * All client_op
   * arguments |from_assistant| interactions
   */
  scrubAuxiliaryFieldsInConversationSnapshot?: boolean;
}

/**
 * A special type representing a StateOfAffairs. Currently (as of 2021Q2) this
 * is duplicative with semantic_type { name: "StateOfAffairs" } but we
 * (mrf-team) will encourage clients to migrate to this new type.
 */
export interface KnowledgeAnswersStateOfAffairsType {
  /**
   * Contains data about current schema remodelings at this ValueType level.
   * For more information see go/meaning-remodeling-framework.
   */
  remodelings?: NlpMeaningMeaningRemodelings;
}

function serializeKnowledgeAnswersStateOfAffairsType(data: any): KnowledgeAnswersStateOfAffairsType {
  return {
    ...data,
    remodelings: data["remodelings"] !== undefined ? serializeNlpMeaningMeaningRemodelings(data["remodelings"]) : undefined,
  };
}

function deserializeKnowledgeAnswersStateOfAffairsType(data: any): KnowledgeAnswersStateOfAffairsType {
  return {
    ...data,
    remodelings: data["remodelings"] !== undefined ? deserializeNlpMeaningMeaningRemodelings(data["remodelings"]) : undefined,
  };
}

/**
 * A StringType configures a value whose type is intended to be arbitrary text.
 */
export interface KnowledgeAnswersStringType {
  /**
   * Contains data about current schema remodelings at this ValueType level.
   * For more information see go/meaning-remodeling-framework.
   */
  remodelings?: NlpMeaningMeaningRemodelings;
  /**
   * If true, this value will match a single token. If false, this value will
   * match any nonzero number of tokens.
   */
  singleToken?: boolean;
}

function serializeKnowledgeAnswersStringType(data: any): KnowledgeAnswersStringType {
  return {
    ...data,
    remodelings: data["remodelings"] !== undefined ? serializeNlpMeaningMeaningRemodelings(data["remodelings"]) : undefined,
  };
}

function deserializeKnowledgeAnswersStringType(data: any): KnowledgeAnswersStringType {
  return {
    ...data,
    remodelings: data["remodelings"] !== undefined ? deserializeNlpMeaningMeaningRemodelings(data["remodelings"]) : undefined,
  };
}

/**
 * A TimeZoneType configures a value whose type is a timezone.
 */
export interface KnowledgeAnswersTimeZoneType {
  /**
   * Contains data about current schema remodelings at this ValueType level.
   * For more information see go/meaning-remodeling-framework.
   */
  remodelings?: NlpMeaningMeaningRemodelings;
}

function serializeKnowledgeAnswersTimeZoneType(data: any): KnowledgeAnswersTimeZoneType {
  return {
    ...data,
    remodelings: data["remodelings"] !== undefined ? serializeNlpMeaningMeaningRemodelings(data["remodelings"]) : undefined,
  };
}

function deserializeKnowledgeAnswersTimeZoneType(data: any): KnowledgeAnswersTimeZoneType {
  return {
    ...data,
    remodelings: data["remodelings"] !== undefined ? deserializeNlpMeaningMeaningRemodelings(data["remodelings"]) : undefined,
  };
}

/**
 * A TrackingNumberType configures a value whose type is a TrackingNumber.
 */
export interface KnowledgeAnswersTrackingNumberType {
  /**
   * Contains data about current schema remodelings at this ValueType level.
   * For more information see go/meaning-remodeling-framework.
   */
  remodelings?: NlpMeaningMeaningRemodelings;
}

function serializeKnowledgeAnswersTrackingNumberType(data: any): KnowledgeAnswersTrackingNumberType {
  return {
    ...data,
    remodelings: data["remodelings"] !== undefined ? serializeNlpMeaningMeaningRemodelings(data["remodelings"]) : undefined,
  };
}

function deserializeKnowledgeAnswersTrackingNumberType(data: any): KnowledgeAnswersTrackingNumberType {
  return {
    ...data,
    remodelings: data["remodelings"] !== undefined ? deserializeNlpMeaningMeaningRemodelings(data["remodelings"]) : undefined,
  };
}

/**
 * A TypeTrait configures a value that has a property with any of the given
 * trait_id. In practice this means: - any entity that has a metadata ID defined
 * in the KP type_schema, - any intent that has a slot with the given ID. When
 * comparing trait_id to metadata IDs or slot IDs, we lowercase and normalize
 * for comparison.
 */
export interface KnowledgeAnswersTypeTrait {
  /**
   * Contains data about current schema remodelings at this ValueType level.
   * For more information see go/meaning-remodeling-framework.
   */
  remodelings?: NlpMeaningMeaningRemodelings;
  traitId?: string[];
}

function serializeKnowledgeAnswersTypeTrait(data: any): KnowledgeAnswersTypeTrait {
  return {
    ...data,
    remodelings: data["remodelings"] !== undefined ? serializeNlpMeaningMeaningRemodelings(data["remodelings"]) : undefined,
  };
}

function deserializeKnowledgeAnswersTypeTrait(data: any): KnowledgeAnswersTypeTrait {
  return {
    ...data,
    remodelings: data["remodelings"] !== undefined ? deserializeNlpMeaningMeaningRemodelings(data["remodelings"]) : undefined,
  };
}

export interface KnowledgeAnswersUnionType {
  slotNames?: string[];
}

/**
 * Specifies the allowed type(s) that a value can have, e.g. for a Slot. For
 * example, having both entity_type and string_type present in a ValueType field
 * of a Slot means that the Slot can take _either_ an an EntityType _or_
 * StringType as a value, and nothing else. It may be helpful to think of this
 * proto as being called something like AllAllowedValueTypes. Next tag id: 25
 * LINT.IfChange
 */
export interface KnowledgeAnswersValueType {
  /**
   * This type is meant to accept "any" type and allow any and all composition.
   * As such, it should not be used for any composition algorithms, e.g. in
   * Loose Parser. See more detailed discussion at go/any-type-in-mrf. This type
   * may appear on an answer_type, implying that the output of that Meaning
   * Schema is allowed to nest in any other slot. However, support for this is
   * NOT implemented in Loose Parser due to risk of overcomposition, but the MRF
   * Conformance checker allows for this. If you are thinking of using this,
   * please contact mrf-team@.
   */
  anyType?: KnowledgeAnswersAnyType;
  attributeType?: KnowledgeAnswersAttributeType;
  booleanType?: KnowledgeAnswersBooleanType;
  collectionType?: KnowledgeAnswersCollectionType;
  compoundType?: KnowledgeAnswersCompoundType;
  dateType?: KnowledgeAnswersDateType;
  /**
   * Used for configuring dynamic types to allow for type transparency. See:
   * go/type-dependencies
   */
  dependencyType?: KnowledgeAnswersDependencyType;
  durationType?: KnowledgeAnswersDurationType;
  entityType?: KnowledgeAnswersEntityType;
  /**
   * When specified on a slot's type, restricts composition based on the enum
   * value. This does not mean anything when the value type is to be interpreted
   * as an output_type.
   */
  inputCompositionConfig?:  | "UNSPECIFIED_COMPOSITION" | "ALL_COMPOSITION" | "PRIMITIVES_ONLY_COMPOSITION" | "PRIMITIVES_AND_OPERATORS_OF_PRIMITIVES_COMPOSITION" | "PRIMITIVES_AND_SEMANTIC_TYPES_COMPOSITION";
  measurementType?: KnowledgeAnswersMeasurementType;
  /**
   * Note that normalized_string_type is NOT supported in the loose parser. A
   * slot with this type will cause the intent to not be parsed.
   */
  normalizedStringType?: KnowledgeAnswersNormalizedStringType;
  numberType?: KnowledgeAnswersNumberType;
  opaqueType?: KnowledgeAnswersOpaqueType;
  plexityRequirement?: KnowledgeAnswersPlexityRequirement;
  pluralityType?:  | "ALL" | "PLURAL_ONLY" | "SINGULAR_ONLY";
  polarQuestionType?: KnowledgeAnswersPolarQuestionType;
  semanticType?: KnowledgeAnswersSemanticType;
  stateOfAffairsType?: KnowledgeAnswersStateOfAffairsType;
  stringType?: KnowledgeAnswersStringType;
  timezoneType?: KnowledgeAnswersTimeZoneType;
  trackingNumberType?: KnowledgeAnswersTrackingNumberType;
  /**
   * Extra trait information for compound value types. Note: currently the
   * semantics of having both the data type (e.g. "entity_type") and
   * "with_trait" is an OR operation. Eg. HorizontalDateRestrict has a
   * SetToModify slot that accepts some collections like /collection/films. And
   * also intent queries with_trait date, start_date, etc.
   */
  withTrait?: KnowledgeAnswersTypeTrait;
}

function serializeKnowledgeAnswersValueType(data: any): KnowledgeAnswersValueType {
  return {
    ...data,
    anyType: data["anyType"] !== undefined ? serializeKnowledgeAnswersAnyType(data["anyType"]) : undefined,
    attributeType: data["attributeType"] !== undefined ? serializeKnowledgeAnswersAttributeType(data["attributeType"]) : undefined,
    booleanType: data["booleanType"] !== undefined ? serializeKnowledgeAnswersBooleanType(data["booleanType"]) : undefined,
    collectionType: data["collectionType"] !== undefined ? serializeKnowledgeAnswersCollectionType(data["collectionType"]) : undefined,
    compoundType: data["compoundType"] !== undefined ? serializeKnowledgeAnswersCompoundType(data["compoundType"]) : undefined,
    dateType: data["dateType"] !== undefined ? serializeKnowledgeAnswersDateType(data["dateType"]) : undefined,
    dependencyType: data["dependencyType"] !== undefined ? serializeKnowledgeAnswersDependencyType(data["dependencyType"]) : undefined,
    durationType: data["durationType"] !== undefined ? serializeKnowledgeAnswersDurationType(data["durationType"]) : undefined,
    entityType: data["entityType"] !== undefined ? serializeKnowledgeAnswersEntityType(data["entityType"]) : undefined,
    measurementType: data["measurementType"] !== undefined ? serializeKnowledgeAnswersMeasurementType(data["measurementType"]) : undefined,
    normalizedStringType: data["normalizedStringType"] !== undefined ? serializeKnowledgeAnswersNormalizedStringType(data["normalizedStringType"]) : undefined,
    numberType: data["numberType"] !== undefined ? serializeKnowledgeAnswersNumberType(data["numberType"]) : undefined,
    opaqueType: data["opaqueType"] !== undefined ? serializeKnowledgeAnswersOpaqueType(data["opaqueType"]) : undefined,
    plexityRequirement: data["plexityRequirement"] !== undefined ? serializeKnowledgeAnswersPlexityRequirement(data["plexityRequirement"]) : undefined,
    polarQuestionType: data["polarQuestionType"] !== undefined ? serializeKnowledgeAnswersPolarQuestionType(data["polarQuestionType"]) : undefined,
    semanticType: data["semanticType"] !== undefined ? serializeKnowledgeAnswersSemanticType(data["semanticType"]) : undefined,
    stateOfAffairsType: data["stateOfAffairsType"] !== undefined ? serializeKnowledgeAnswersStateOfAffairsType(data["stateOfAffairsType"]) : undefined,
    stringType: data["stringType"] !== undefined ? serializeKnowledgeAnswersStringType(data["stringType"]) : undefined,
    timezoneType: data["timezoneType"] !== undefined ? serializeKnowledgeAnswersTimeZoneType(data["timezoneType"]) : undefined,
    trackingNumberType: data["trackingNumberType"] !== undefined ? serializeKnowledgeAnswersTrackingNumberType(data["trackingNumberType"]) : undefined,
    withTrait: data["withTrait"] !== undefined ? serializeKnowledgeAnswersTypeTrait(data["withTrait"]) : undefined,
  };
}

function deserializeKnowledgeAnswersValueType(data: any): KnowledgeAnswersValueType {
  return {
    ...data,
    anyType: data["anyType"] !== undefined ? deserializeKnowledgeAnswersAnyType(data["anyType"]) : undefined,
    attributeType: data["attributeType"] !== undefined ? deserializeKnowledgeAnswersAttributeType(data["attributeType"]) : undefined,
    booleanType: data["booleanType"] !== undefined ? deserializeKnowledgeAnswersBooleanType(data["booleanType"]) : undefined,
    collectionType: data["collectionType"] !== undefined ? deserializeKnowledgeAnswersCollectionType(data["collectionType"]) : undefined,
    compoundType: data["compoundType"] !== undefined ? deserializeKnowledgeAnswersCompoundType(data["compoundType"]) : undefined,
    dateType: data["dateType"] !== undefined ? deserializeKnowledgeAnswersDateType(data["dateType"]) : undefined,
    dependencyType: data["dependencyType"] !== undefined ? deserializeKnowledgeAnswersDependencyType(data["dependencyType"]) : undefined,
    durationType: data["durationType"] !== undefined ? deserializeKnowledgeAnswersDurationType(data["durationType"]) : undefined,
    entityType: data["entityType"] !== undefined ? deserializeKnowledgeAnswersEntityType(data["entityType"]) : undefined,
    measurementType: data["measurementType"] !== undefined ? deserializeKnowledgeAnswersMeasurementType(data["measurementType"]) : undefined,
    normalizedStringType: data["normalizedStringType"] !== undefined ? deserializeKnowledgeAnswersNormalizedStringType(data["normalizedStringType"]) : undefined,
    numberType: data["numberType"] !== undefined ? deserializeKnowledgeAnswersNumberType(data["numberType"]) : undefined,
    opaqueType: data["opaqueType"] !== undefined ? deserializeKnowledgeAnswersOpaqueType(data["opaqueType"]) : undefined,
    plexityRequirement: data["plexityRequirement"] !== undefined ? deserializeKnowledgeAnswersPlexityRequirement(data["plexityRequirement"]) : undefined,
    polarQuestionType: data["polarQuestionType"] !== undefined ? deserializeKnowledgeAnswersPolarQuestionType(data["polarQuestionType"]) : undefined,
    semanticType: data["semanticType"] !== undefined ? deserializeKnowledgeAnswersSemanticType(data["semanticType"]) : undefined,
    stateOfAffairsType: data["stateOfAffairsType"] !== undefined ? deserializeKnowledgeAnswersStateOfAffairsType(data["stateOfAffairsType"]) : undefined,
    stringType: data["stringType"] !== undefined ? deserializeKnowledgeAnswersStringType(data["stringType"]) : undefined,
    timezoneType: data["timezoneType"] !== undefined ? deserializeKnowledgeAnswersTimeZoneType(data["timezoneType"]) : undefined,
    trackingNumberType: data["trackingNumberType"] !== undefined ? deserializeKnowledgeAnswersTrackingNumberType(data["trackingNumberType"]) : undefined,
    withTrait: data["withTrait"] !== undefined ? deserializeKnowledgeAnswersTypeTrait(data["withTrait"]) : undefined,
  };
}

/**
 * /////////// DATE //////////
 */
export interface KnowledgeGraphDateTimeProto {
  /**
   * A day of month, 1-31. If present, year and month must be present as well,
   * and must form a valid date.
   */
  days?: number;
  /**
   * Hour of the day, 0-23
   */
  hours?: number;
  /**
   * Microsecond, in the interval [0, 999999]. If present, seconds have to be
   * present as well.
   */
  microseconds?: number;
  /**
   * Minute, 0-59. If present, hours have to be present as well.
   */
  minutes?: number;
  /**
   * A month, 1-12. If present, year must be present as well.
   */
  months?: number;
  /**
   * Second, in the interval [0, 60], where 60 is an exceptional value reserved
   * for leap seconds. If present, minutes have to be present as well.
   */
  seconds?: number;
  /**
   * Timezone offset in seconds (can be positive/negative). If present, hours
   * have to be present as well If absent, we expect the time above to be in
   * local time (a.k.a. civil time, go/httat#civil_time).
   */
  tzOffset?: bigint;
  /**
   * A year.
   */
  years?: number;
}

function serializeKnowledgeGraphDateTimeProto(data: any): KnowledgeGraphDateTimeProto {
  return {
    ...data,
    tzOffset: data["tzOffset"] !== undefined ? String(data["tzOffset"]) : undefined,
  };
}

function deserializeKnowledgeGraphDateTimeProto(data: any): KnowledgeGraphDateTimeProto {
  return {
    ...data,
    tzOffset: data["tzOffset"] !== undefined ? BigInt(data["tzOffset"]) : undefined,
  };
}

/**
 * A nested struct is a recursive tree structure for storing a set of triples.
 * more info can be found at go/nested-struct-primer
 */
export interface KnowledgeGraphNestedStruct {
  /**
   * predicate_objs.pred should be unique within the list.
   */
  predicateObjs?: KnowledgeGraphNestedStructPredicateObjs[];
}

function serializeKnowledgeGraphNestedStruct(data: any): KnowledgeGraphNestedStruct {
  return {
    ...data,
    predicateObjs: data["predicateObjs"] !== undefined ? data["predicateObjs"].map((item: any) => (serializeKnowledgeGraphNestedStructPredicateObjs(item))) : undefined,
  };
}

function deserializeKnowledgeGraphNestedStruct(data: any): KnowledgeGraphNestedStruct {
  return {
    ...data,
    predicateObjs: data["predicateObjs"] !== undefined ? data["predicateObjs"].map((item: any) => (deserializeKnowledgeGraphNestedStructPredicateObjs(item))) : undefined,
  };
}

export interface KnowledgeGraphNestedStructPredicateObjs {
  objs?: KnowledgeGraphTripleObj[];
  pred?: string;
}

function serializeKnowledgeGraphNestedStructPredicateObjs(data: any): KnowledgeGraphNestedStructPredicateObjs {
  return {
    ...data,
    objs: data["objs"] !== undefined ? data["objs"].map((item: any) => (serializeKnowledgeGraphTripleObj(item))) : undefined,
  };
}

function deserializeKnowledgeGraphNestedStructPredicateObjs(data: any): KnowledgeGraphNestedStructPredicateObjs {
  return {
    ...data,
    objs: data["objs"] !== undefined ? data["objs"].map((item: any) => (deserializeKnowledgeGraphTripleObj(item))) : undefined,
  };
}

/**
 * A qualifier represents an extra piece of context about an assertion/fact.
 * See go/qualifiers-in-kg for more details.
 */
export interface KnowledgeGraphQualifier {
  /**
   * The qualifier pred must be a qualifier property defined in KG schema as
   * applying to the predicate of the triple this qualifier is attached to.
   */
  pred?: string;
  value?: KnowledgeGraphTripleObj;
}

function serializeKnowledgeGraphQualifier(data: any): KnowledgeGraphQualifier {
  return {
    ...data,
    value: data["value"] !== undefined ? serializeKnowledgeGraphTripleObj(data["value"]) : undefined,
  };
}

function deserializeKnowledgeGraphQualifier(data: any): KnowledgeGraphQualifier {
  return {
    ...data,
    value: data["value"] !== undefined ? deserializeKnowledgeGraphTripleObj(data["value"]) : undefined,
  };
}

/**
 * A QualifierSet represents a grouping of qualifiers that together with an SPO
 * make up a logical assertion or fact. One triple can contain multiple
 * qualifier sets and thus represent several different assertions about the same
 * SPO.
 */
export interface KnowledgeGraphQualifierSet {
  qualifiers?: KnowledgeGraphQualifier[];
}

function serializeKnowledgeGraphQualifierSet(data: any): KnowledgeGraphQualifierSet {
  return {
    ...data,
    qualifiers: data["qualifiers"] !== undefined ? data["qualifiers"].map((item: any) => (serializeKnowledgeGraphQualifier(item))) : undefined,
  };
}

function deserializeKnowledgeGraphQualifierSet(data: any): KnowledgeGraphQualifierSet {
  return {
    ...data,
    qualifiers: data["qualifiers"] !== undefined ? data["qualifiers"].map((item: any) => (deserializeKnowledgeGraphQualifier(item))) : undefined,
  };
}

/**
 * A Triple is a representation of data with a Subject, a Predicate, and an
 * Object, For example: (Triple, IS-A, "data representation"). Triples are a
 * very good representation of data where the relationship between data points
 * is significant, because the Object of a Triple can be the Subject of another
 * Triple: (Triple, HAS-A, Subject) (Subject, IS-A, "Term of a proposition") The
 * ease with which Triples can represent relationships makes them an excellent
 * candidate for representing graphs. Next id: 21
 */
export interface KnowledgeGraphTriple {
  /**
   * If is_negation is set to true then this triple is considered a statement
   * that the fact is false. This allows for the storage of both what we know to
   * be true and what we know to be false.
   */
  isNegation?: boolean;
  /**
   * obj is the value of a relationship.
   */
  obj?: KnowledgeGraphTripleObj;
  /**
   * pred is an arbitrary node id representing the predicate (name) of a graph
   * relationship.
   */
  pred?: string;
  provenance?: KnowledgeGraphTripleProvenance[];
  /**
   * WARNING: This is currently defined for experimentation purposes only.
   * Please do not set. Data set in this field will not be published to any
   * systems downstream of Livegraph. Together with the SPO of this triple, each
   * qualifier set here represents a different logical assertion/fact.
   */
  qualifierSets?: KnowledgeGraphQualifierSet[];
  /**
   * sub is an arbitrary node id representing the source entity of a graph
   * relationship.
   */
  sub?: string;
}

function serializeKnowledgeGraphTriple(data: any): KnowledgeGraphTriple {
  return {
    ...data,
    obj: data["obj"] !== undefined ? serializeKnowledgeGraphTripleObj(data["obj"]) : undefined,
    provenance: data["provenance"] !== undefined ? data["provenance"].map((item: any) => (serializeKnowledgeGraphTripleProvenance(item))) : undefined,
    qualifierSets: data["qualifierSets"] !== undefined ? data["qualifierSets"].map((item: any) => (serializeKnowledgeGraphQualifierSet(item))) : undefined,
  };
}

function deserializeKnowledgeGraphTriple(data: any): KnowledgeGraphTriple {
  return {
    ...data,
    obj: data["obj"] !== undefined ? deserializeKnowledgeGraphTripleObj(data["obj"]) : undefined,
    provenance: data["provenance"] !== undefined ? data["provenance"].map((item: any) => (deserializeKnowledgeGraphTripleProvenance(item))) : undefined,
    qualifierSets: data["qualifierSets"] !== undefined ? data["qualifierSets"].map((item: any) => (deserializeKnowledgeGraphQualifierSet(item))) : undefined,
  };
}

export interface KnowledgeGraphTripleObj {
  boolValue?: boolean;
  datetimeValue?: KnowledgeGraphDateTimeProto;
  doubleValue?: number;
  /**
   * seconds
   */
  durationValue?: bigint;
  /**
   * An id representing an entity (mid or hrid)
   */
  idValue?: string;
  int64Value?: bigint;
  /**
   * The language code for the object value. It must be a BCP 47-compliant
   * language tag (b/10005172). See also go/kg-data-l10n.
   */
  locale?: string;
  nestedStructValue?: KnowledgeGraphNestedStruct;
  protoValue?: KnowledgeGraphTripleObjProto;
  s2cellId?: bigint;
  /**
   * A UTF-8 string value to be used for the following expected schema types: -
   * /type/rawstring - /type/text - /type/key
   */
  stringValue?: string;
  uint64Value?: bigint;
  /**
   * A UTF-8 string value to be used for expected type /type/uri - b/68760994.
   */
  uriValue?: string;
}

function serializeKnowledgeGraphTripleObj(data: any): KnowledgeGraphTripleObj {
  return {
    ...data,
    datetimeValue: data["datetimeValue"] !== undefined ? serializeKnowledgeGraphDateTimeProto(data["datetimeValue"]) : undefined,
    durationValue: data["durationValue"] !== undefined ? String(data["durationValue"]) : undefined,
    int64Value: data["int64Value"] !== undefined ? String(data["int64Value"]) : undefined,
    nestedStructValue: data["nestedStructValue"] !== undefined ? serializeKnowledgeGraphNestedStruct(data["nestedStructValue"]) : undefined,
    protoValue: data["protoValue"] !== undefined ? serializeKnowledgeGraphTripleObjProto(data["protoValue"]) : undefined,
    s2cellId: data["s2cellId"] !== undefined ? String(data["s2cellId"]) : undefined,
    uint64Value: data["uint64Value"] !== undefined ? String(data["uint64Value"]) : undefined,
  };
}

function deserializeKnowledgeGraphTripleObj(data: any): KnowledgeGraphTripleObj {
  return {
    ...data,
    datetimeValue: data["datetimeValue"] !== undefined ? deserializeKnowledgeGraphDateTimeProto(data["datetimeValue"]) : undefined,
    durationValue: data["durationValue"] !== undefined ? BigInt(data["durationValue"]) : undefined,
    int64Value: data["int64Value"] !== undefined ? BigInt(data["int64Value"]) : undefined,
    nestedStructValue: data["nestedStructValue"] !== undefined ? deserializeKnowledgeGraphNestedStruct(data["nestedStructValue"]) : undefined,
    protoValue: data["protoValue"] !== undefined ? deserializeKnowledgeGraphTripleObjProto(data["protoValue"]) : undefined,
    s2cellId: data["s2cellId"] !== undefined ? BigInt(data["s2cellId"]) : undefined,
    uint64Value: data["uint64Value"] !== undefined ? BigInt(data["uint64Value"]) : undefined,
  };
}

export interface KnowledgeGraphTripleObjProto {
  /**
   * The encoded proto data.
   */
  data?: Uint8Array;
  /**
   * The full name of the proto descriptor, such as 'music.AlbumSummary'.
   */
  descriptorFullName?: string;
}

function serializeKnowledgeGraphTripleObjProto(data: any): KnowledgeGraphTripleObjProto {
  return {
    ...data,
    data: data["data"] !== undefined ? encodeBase64(data["data"]) : undefined,
  };
}

function deserializeKnowledgeGraphTripleObjProto(data: any): KnowledgeGraphTripleObjProto {
  return {
    ...data,
    data: data["data"] !== undefined ? decodeBase64(data["data"] as string) : undefined,
  };
}

/**
 * Message containing information about the source of this triple. See
 * go/kg-provenance for an explanation of the fields.
 */
export interface KnowledgeGraphTripleProvenance {
  /**
   * Specifies the contract or legal visibility required to see the Triple. See
   * go/kg-triple-level-access-controls for details and background. Note that we
   * use an int32 here so that we won't lose values when decoding on a stale
   * binary. The int32 references to the enum
   * storage_graph_bfg.Triple.Provenance.AccessRequirement.
   */
  accessRequired?: number;
  /**
   * Historically, this field was used to encode the Freebase User ID, Google
   * username, or Google MDB group that was responsible for the pipeline that is
   * producing this data. However, there is currently no horizontal validation
   * in place, and as of Q3 2018, this field is used essentially as a free-form
   * string by multiple data providers. NOTE: Do not use this field in new
   * pipelines without first consulting with the OWNERS of this proto.
   */
  creator?: string;
  /**
   * The dataset which asserted this data. Must be a valid mid. See
   * go/kg-provenance
   */
  datasetMid?: bigint;
  /**
   * Indicates that the corresponding data is supporting evidence for
   * reconciliation only, and is *not* an assertion that should be visible to
   * other systems or to external users. Note that this also means that no
   * provenances indicating supporting data will be visible in the composed
   * graph. Please see go/supporting-kg-triples-design-doc for additional
   * details and background.
   */
  isSupportingData?: boolean;
  /**
   * Internal metadata used by Livegraph and possibly other horizontal KG infra
   * systems. This is not part of the logical triple or its provenance, and
   * contents may not be visible downstream of LG.
   */
  lgMetadata?: StorageGraphBfgLivegraphProvenanceMetadata;
  /**
   * Metadata specifying data governance policies. This information will be
   * processed and enforced in KE systems. For more context, see
   * go/ke-triple-dg-policy-and-metadata. WARNING: This field is WIP and please
   * do not populate it without consulting ke-data-governance@.
   */
  policyMetadata?: StorageGraphBfgPolicyMetadata;
  /**
   * An identifier for the process that asserted this triple.
   */
  process?: string;
  restrictions?:  | "REQUIRES_CITATION" | "REQUIRES_PCOUNSEL_REVIEW" | "UNRESTRICTED_WITHIN_GOOGLE_NO_3P_USE"[];
  /**
   * Used to measure impact of 3P contributions. See go/ke-metrics.
   */
  sourceCategory?:  | "THIRD_PARTY" | "CURATION" | "PARTNER_FEED" | "EXTRACTION";
  /**
   * The websearch doc_id of the source_url. Used in conjunction with
   * source_category for measuring 3P contributions.
   */
  sourceDocId?: bigint;
  /**
   * If the triple was extracted from the web, the source URL where the
   * assertion was found. Used for citation if needed (see restrictions field
   * below).
   */
  sourceUrl?: string;
  /**
   * A fact about potentially sensitive personal info (http://what/SPII) can be
   * "certified" iff it meets specific requirements. See
   * go/kg-spii-certification for details.
   */
  spiiCertification?: StorageGraphBfgSpiiCertification;
}

function serializeKnowledgeGraphTripleProvenance(data: any): KnowledgeGraphTripleProvenance {
  return {
    ...data,
    datasetMid: data["datasetMid"] !== undefined ? String(data["datasetMid"]) : undefined,
    lgMetadata: data["lgMetadata"] !== undefined ? serializeStorageGraphBfgLivegraphProvenanceMetadata(data["lgMetadata"]) : undefined,
    policyMetadata: data["policyMetadata"] !== undefined ? serializeStorageGraphBfgPolicyMetadata(data["policyMetadata"]) : undefined,
    sourceDocId: data["sourceDocId"] !== undefined ? String(data["sourceDocId"]) : undefined,
    spiiCertification: data["spiiCertification"] !== undefined ? serializeStorageGraphBfgSpiiCertification(data["spiiCertification"]) : undefined,
  };
}

function deserializeKnowledgeGraphTripleProvenance(data: any): KnowledgeGraphTripleProvenance {
  return {
    ...data,
    datasetMid: data["datasetMid"] !== undefined ? BigInt(data["datasetMid"]) : undefined,
    lgMetadata: data["lgMetadata"] !== undefined ? deserializeStorageGraphBfgLivegraphProvenanceMetadata(data["lgMetadata"]) : undefined,
    policyMetadata: data["policyMetadata"] !== undefined ? deserializeStorageGraphBfgPolicyMetadata(data["policyMetadata"]) : undefined,
    sourceDocId: data["sourceDocId"] !== undefined ? BigInt(data["sourceDocId"]) : undefined,
    spiiCertification: data["spiiCertification"] !== undefined ? deserializeStorageGraphBfgSpiiCertification(data["spiiCertification"]) : undefined,
  };
}

/**
 * A user specified location to trigger weather for a specific location. Also
 * it can be generalized for other verticals.
 */
export interface KnowledgeVerticalsWeatherProtoUserSpecifiedLocation {
  /**
   * (Mandatory) Oyster ID.
   */
  featureId?: GeostoreFeatureIdProto;
  /**
   * (Mandatory) Coordinates of the location for which weather is requested.
   */
  latLng?: GoogleTypeLatLng;
  /**
   * The name to display. If specified it will override the formatted address
   * of "feature_id".
   */
  locationName?: string;
  /**
   * MID corresponding to the location from feature_id.
   */
  mid?: string;
  /**
   * The timezone to display the current conditions observation time. Optional
   * and will override the timezone of "feature_id".
   */
  timezone?: string;
}

function serializeKnowledgeVerticalsWeatherProtoUserSpecifiedLocation(data: any): KnowledgeVerticalsWeatherProtoUserSpecifiedLocation {
  return {
    ...data,
    featureId: data["featureId"] !== undefined ? serializeGeostoreFeatureIdProto(data["featureId"]) : undefined,
  };
}

function deserializeKnowledgeVerticalsWeatherProtoUserSpecifiedLocation(data: any): KnowledgeVerticalsWeatherProtoUserSpecifiedLocation {
  return {
    ...data,
    featureId: data["featureId"] !== undefined ? deserializeGeostoreFeatureIdProto(data["featureId"]) : undefined,
  };
}

export interface LegalCitation {
  /**
   * For Courts, the country the court is in. For Statues,? 3 leter country
   * code ISO 3166 alpha2
   */
  CountryCode?: string;
  courtdocument?: LegalCitationCourtDocument;
  law?: LegalCitationLaw;
  ParseType?: number;
  /**
   * State or province of the court or statue (if applicable) What standard?
   */
  State?: string;
  /**
   * DocType
   */
  Type?: number;
}

/**
 * Information about a published version of the document. Not all
 * references/documents will have this because some will be vendor and/or media
 * neutral.
 */
export interface LegalCitationCourtDocument {
  /**
   * One entry per judge who listened to the case in this court
   */
  ArguedBefore?: LegalPerson[];
  ArguedDate?: LegalDate;
  /**
   * For an appeal, the name of the lower court that sent this up Abbreviation
   * form? Verbose form?
   */
  CertiorariCourtName?: string;
  CertiorariRelationship?: number;
  court?: LegalCitationCourtDocumentCourt;
  /**
   * Usually the name of a month. Not sure really what it means.
   */
  CourtTerm?: string;
  /**
   * Various dates related to the generation of document most of these are
   * opinion-centric
   */
  DecidedDate?: LegalDate;
  FiledDate?: LegalDate;
  /**
   * Not sure what this is. But I've seen it.
   */
  MemoID?: string;
  ModifiedDate?: LegalDate;
  opinioninfo?: LegalCitationCourtDocumentOpinionInfo[];
  perdocketinfo?: LegalCitationCourtDocumentPerDocketInfo[];
  pub?: LegalCitationCourtDocumentPub[];
  /**
   * A summary of the document or a syllabus for this document
   */
  Syllabus?: string;
  unknowndate?: LegalCitationCourtDocumentUnknownDate[];
}

export interface LegalCitationCourtDocumentCourt {
  /**
   * The name of the court to be displayed to users.
   */
  DisplayName?: string;
  /**
   * Maybe be redundant with the Name. We can remove this later if we don't
   * find it useful. Court Level
   */
  Level?: number;
  /**
   * Court id for matching records; "name" is a historic misnomer.
   */
  Name?: string;
  namecomponent?: LegalCitationCourtDocumentCourtNameComponent[];
  /**
   * The name of the court as taken directly from the source document
   */
  OriginalName?: string;
}

/**
 * The name broken down into its various components, such as core court, state,
 * and district
 */
export interface LegalCitationCourtDocumentCourtNameComponent {
  Text?: string;
  Type?: number;
}

/**
 * A variety of opinions may be published as a single document. We have one
 * OpinionInfo for each opinion About the "CONCURRING" opinion type: It means
 * that a judge "concurs" to the conclusion (judegment) of the majority of the
 * court, however, he may not agree with the argument in the primary opinion. If
 * multiple judges "concur" or "dissent" the primary opinion, then one judge
 * delivers their opinion, and other judges are said to "join" him.
 */
export interface LegalCitationCourtDocumentOpinionInfo {
  Bench?: number;
  /**
   * if Type == PER_CURIAM, then DeliveredBy is unnecessary since it is
   * delivered by the full court. Who delivered the opinion?
   */
  DeliveredBy?: LegalPerson;
  /**
   * Who agrees with the opinion
   */
  JoinedBy?: LegalPerson;
  /**
   * OpinionType
   */
  Type?: number;
}

/**
 * Information associated with a docket. Note that multiple dockets can be
 * combined and argued as one and produce a single opinion
 */
export interface LegalCitationCourtDocumentPerDocketInfo {
  /**
   * An alpha-numeric (usually, mostly numeric) string used to identify the
   * case by the court
   */
  DocketID?: string;
  /**
   * Who is bringing the action? (X in X vs. Y)
   */
  Petitioner?: LegalPerson[];
  /**
   * Who represents the petitioner?
   */
  PetitionerCounsel?: LegalPerson[];
  /**
   * Who is responding to the action? (Y in X vs. Y)
   */
  Respondent?: LegalPerson[];
  /**
   * Who represents the respondent?
   */
  RespondentCounsel?: LegalPerson[];
  /**
   * The "in re" or "matter of" field.
   */
  Topic?: string;
}

export interface LegalCitationCourtDocumentPub {
  /**
   * Page number
   */
  Page?: string;
  /**
   * Paragraph number
   */
  Paragraph?: string;
  /**
   * The publisher of the opinion. For example, 'U.S.' - United States Reports
   * 'S. Ct.' - Supreme Court Reporter 'L. Ed. 2d' - Lawyers Edition Second
   * Series
   */
  Reporter?: string;
  /**
   * For documents published by a court reporter. Vendor/Media neutral
   * citations will probably not have this.
   */
  Volume?: number;
  /**
   * This is the publication year. In many citations, there is one year listed
   * and it is typically the year the opinion was handed down. For example: Roe
   * v. Wade, 410 U.S. 113 (1973) Occasionally, the publication year of the
   * reporter is included. This happens typically when the law reporter volume
   * numbers are numbered within a calendar year. For example, Swiss Bank Corp.
   * v. Air Canada, [1988] 1 F.C. 71. It some (most?) areas, publication date is
   * denoted by [] while opinion date is denoted by ().
   */
  Year?: number;
}

/**
 * Dates that we didn't fully parse, so we don't know exactly what they are,
 * but we are keeping in case it's all we have.
 */
export interface LegalCitationCourtDocumentUnknownDate {
  Date?: LegalDate;
  Description?: string;
}

export interface LegalCitationLaw {
  collectionname?: LegalCitationLawCollectionName;
  level?: LegalCitationLawLevel[];
  RevisionDate?: LegalDate;
  /**
   * LawStatus
   */
  Status?: number;
  /**
   * LawType
   */
  Type?: number;
}

/**
 * this is used to store information about law collections Normalized is the
 * normalized name for the law (e.g., USC for USCA and USCS) Source is the text
 * that represents the law in the citation
 */
export interface LegalCitationLawCollectionName {
  Normalized?: string;
  Source?: string;
}

/**
 * Law have tree-like sturcture (title, section, etc), but the levels and their
 * names are not fixed. e.g., we could have: US Constitution -> Article 3 ->
 * Section 4, OR, US Code -> Title 12 -> Chapter 6 -> Sub-chapter I -> Section
 * 602, OR, US Code -> Title 10 -> Sub-title A -> Part 2 -> Chapter 32 ->
 * Section 523. We use a repeated group to represent this structure. NOTE:
 * Always insert higher levels before lower levels,
 */
export interface LegalCitationLawLevel {
  /**
   * A counter that specifies the depth of the level in the parse
   */
  Depth?: number;
  /**
   * "SECTION, TITLE, PART, etc."
   */
  LevelTypeNormalized?: string;
  /**
   * "Section, Sect., , etc"
   */
  LevelTypeSourceText?: string;
  /**
   * deprecated
   */
  LevelTypeString?: string;
  /**
   * The name of the chapter/section/etc.
   */
  Name?: string;
  /**
   * deprecated
   */
  Type?: number;
  /**
   * "3", "42(a)", etc
   */
  Value?: string;
}

export interface LegalDate {
  Day?: number;
  Month?: number;
  Year?: number;
}

export interface LegalPerson {
  Description?: string;
  LastName?: string;
  OtherNames?: string;
}

/**
 * Aesthetics score of a style image. Check
 * http://go/styleai-indexing-g3doc#aesthetic-model for more details about the
 * Style AI Aesthetics Model.
 */
export interface LensDiscoveryStyleAestheticsScoreSignals {
  /**
   * Aesthetics score discretized into range [0, 100].
   */
  discretizedAestheticsScore?: number;
  version?:  | "VERSION_UNKNOWN" | "AESTHETICS_V1" | "AESTHETICS_V2";
}

/**
 * Bounding box with absolute integer coordinates.
 */
export interface LensDiscoveryStyleBoundingBox {
  x1?: number;
  x2?: number;
  y1?: number;
  y2?: number;
}

/**
 * This message holds person attributes from the Person Interpreter model
 * (go/person-interpreter) and the Style AI Iconic Person Scorer
 * (go/styleai-indexing-g3doc#iconic-person-scorer) for the most iconic person
 * in a style image. Discretization of float values is recommended by CDS for
 * cheaper and more efficient storage. Next ID: 11
 */
export interface LensDiscoveryStylePersonAttributes {
  /**
   * The visibility of the face of the most iconic person in the image
   * discretized into range [0, 100].
   */
  discretizedFaceVisibilityScore?: number;
  discretizedFemaleConfidence?: number;
  /**
   * Male and female confidence scores are discretized into the [0, 100] range.
   */
  discretizedMaleConfidence?: number;
  /**
   * Age prediction is rounded to the first decimal place and multiplied by 10
   * (e.g. 12.3 -> 123). *** Not populated in Amarna for legal reasons. ***
   */
  discretizedPredictedAge?: number;
  /**
   * The area ratio of the most iconic person to the whole image discretized
   * into range [0, 100].
   */
  discretizedVisualSaliencyScore?: number;
  /**
   * Bounding box of the most iconic person in the image.
   */
  personBoundingBox?: LensDiscoveryStyleBoundingBox;
  personVisibilityScores?: LensDiscoveryStylePersonAttributesPersonVisibilityScores;
  /**
   * Bucketed version of the predicted age.
   */
  predictedAgeBucket?:  | "PERSON_AGE_UNKNOWN" | "PERSON_AGE_YOUNG_ADULT" | "PERSON_AGE_20_29" | "PERSON_AGE_30_49" | "PERSON_AGE_50_64" | "PERSON_AGE_65_74" | "PERSON_AGE_ABOVE_75";
  version?:  | "VERSION_UNKNOWN" | "LOOKNET_PERSON_V2B" | "PERSON_INTERPRETATION_V1";
}

export interface LensDiscoveryStylePersonAttributesPersonVisibilityScores {
  /**
   * A measure of the visibility of the most iconic person between [0, 100],
   * derived by combining all label predictions by the Person Visibility model
   * according to go/person-visibility-formula. Higher values indicate greater
   * visibility while lower values indicate lesser visibility.
   */
  discretizedPersonVisibilityScore?: number;
  /**
   * Repeated for # of PersonVisibility types.
   */
  personVisibilityPredictions?: LensDiscoveryStylePersonAttributesPersonVisibilityScoresPersonVisibilityPrediction[];
}

export interface LensDiscoveryStylePersonAttributesPersonVisibilityScoresPersonVisibilityPrediction {
  /**
   * Confidence score of the visibility type prediction discretized into range
   * [0, 100].
   */
  discretizedIconicPersonVisibilityConfidence?: number;
  /**
   * Classification of how much of the body of the most iconic person in the
   * image is visible.
   */
  iconicPersonVisibilityType?:  | "PERSON_VISIBILITY_UNKNOWN" | "PERSON_VISIBILITY_HEAD_AND_SHOULDERS_ONLY" | "PERSON_VISIBILITY_HALF_LENGTH" | "PERSON_VISIBILITY_THREE_QUARTER_LENGTH" | "PERSON_VISIBILITY_FULL_LENGTH";
}

/**
 * This message holds bounding boxes of detected people in the image. Next ID:
 * 3
 */
export interface LensDiscoveryStylePersonDetectionSignals {
  /**
   * Information of all detected people in the image, sorted by decreasing size
   * of the bounding box. We store a maximum of 10 detected people.
   */
  detectedPersons?: LensDiscoveryStylePersonDetectionSignalsDetectedPerson[];
  version?:  | "VERSION_UNKNOWN" | "FASTER_RCNN" | "PERSON_INTERPRETATION_V1";
}

/**
 * Holds information about a detected person in the image.
 */
export interface LensDiscoveryStylePersonDetectionSignalsDetectedPerson {
  /**
   * Bounding box of the detected person.
   */
  boundingBox?: LensDiscoveryStyleBoundingBox;
}

/**
 * Prediction of a style image type: Stage, Stock, Street or Outfits. Check
 * http://go/styleai-indexing-g3doc#style-image-type-classifier for more details
 * about the Style AI Style Image Type Classifier.
 */
export interface LensDiscoveryStyleStyleImageTypeSignals {
  /**
   * Repeated for # of StyleImageType types.
   */
  styleImageTypePredictions?: LensDiscoveryStyleStyleImageTypeSignalsStyleImageTypePrediction[];
  version?:  | "VERSION_UNKNOWN" | "STYLE_IMAGE_TYPE_V1";
}

export interface LensDiscoveryStyleStyleImageTypeSignalsStyleImageTypePrediction {
  /**
   * Style image type confidence discretized into range [0, 100].
   */
  discretizedStyleImageTypeConfidence?: number;
  /**
   * Predicted style image type.
   */
  styleImageType?:  | "TYPE_UNKNOWN" | "TYPE_STAGE" | "TYPE_STOCK" | "TYPE_STREET" | "TYPE_OUTFITS";
}

/**
 * Data to generate the list snippets UI.
 */
export interface ListSnippetResponse {
  header?: ListSnippetResponseRow;
  /**
   * Should list be formatted as a table?
   */
  isTable?: boolean;
  row?: ListSnippetResponseRow[];
  /**
   * The number of rows annotated in the doc, of which 'row' is a subset.
   */
  totalRows?: number;
}

export interface ListSnippetResponseRow {
  column?: string[];
}

/**
 * An unique identification of a chain. The following are the possible chain id
 * forms: 1) prominent_entity_id only: The entity uniquely represents a chain,
 * which may have multiple sitechunks. 2) sitechunk only: The sitechunk uniquely
 * represents a chain while the chain currently does not have an entity in KG.
 * 3) prominent_entity_id + sitechunk: The chain could be represented by the
 * entity, but not merged at last, and the sitechunks represents the chain
 * better. 4) prominent_entity_id + category: There are multiple subchains for
 * the prominent entity, and category is used to differentiate subchains. NOTE:
 * the size and complexity of the ChainId proto has implications in the serving
 * system and should be thoughtfully kept under control.
 */
export interface LocalsearchChainId {
  /**
   * The category associated with this chain, currently only used for
   * subchains.
   */
  category?: string;
  /**
   * The Knowledge Graph (KG) entity of the chain, found and used in chain
   * mining.
   */
  prominentEntityId?: string;
  /**
   * The website sitechunk/domain that is owned by the chain.
   */
  sitechunk?: string;
}

/**
 * Next tag: 23
 */
export interface LocalsearchDocInfo {
}

/**
 * * Proto representing the metadata associated with food ordering internal
 * action. Next ID: 13
 */
export interface LocalsearchProtoInternalFoodOrderingActionMetadata {
  /**
   * The action type of this action metadata.
   */
  actionType?:  | "UNKNOWN_ACTION_TYPE" | "E2E" | "TOA" | "AUTOBOT" | "PAS";
  /**
   * If true, it indicates that the merchant has a primarily food intent. This
   * field will only be set when enable_food_gcid_strict_check in
   * FoodOrderingRestrictionProto is true, see
   * go/togo-unified:overlapping-for-le. See go/togo-unified-gcid for how this
   * is calculated.
   */
  hasPrimarilyFoodIntent?: boolean;
  /**
   * If set, indicates that the food ordering service is out of operational
   * hours. This could only be populated if the request explicitly asks for
   * ignore_operational_hours in request
   * (universalsearch/rpc/geo/food_ordering_restriction.proto). Design doc:
   * go/fo-persistent-v1.
   */
  isOutOfOperationalHours?: boolean;
  /**
   * When true, indicates that this is a whitelisted restaurant from a first
   * party (but non FO) partner, i.e. a merchant from the orderig app, who is
   * Google owned first party food ordering platform. Design doc:
   * go/onboard-mavn-to-fo. Tracking bug: b/150331855
   */
  isWhitelistedExternalRestaurant?: boolean;
  /**
   * Next opening time when the food ordering service will be available. This
   * is only present if the unavailability reason is OUT_OF_OPERATIONAL_HOURS.
   */
  nextOpeningTime?: Date;
  /**
   * Indicates whether only order ahead services are available. Order ahead
   * services allow only to place order for future and ASAP order can not be
   * placed via them.
   */
  onlyOrderAheadServicesAvailable?: boolean;
  /**
   * Aggregated service information by service type. Each service type would
   * only have one ServiceInfo. Optional.
   */
  serviceInfo?: LocalsearchProtoInternalFoodOrderingActionMetadataServiceInfo[];
  /**
   * Food ordering service type.
   */
  supportedServiceType?:  | "UNKNOWN_TYPE" | "DELIVERY" | "PICKUP" | "ANY_TYPE";
  /**
   * Reason for unavailability of internal food ordering action. This is only
   * present when FOPA is unavailable for a particular restaurant. When this is
   * set, all other fields in this proto will not be populated. Note(fo-search):
   * If there are log only partners and this particular restaurant is only
   * supported because of log only partners, this field will not be set to
   * NOT_INTEGRATED_WITH_FOPA.
   */
  unavailabilityReason?:  | "UNKNOWN_REASON" | "NOT_INTEGRATED_WITH_FOPA" | "OUT_OF_OPERATIONAL_HOURS" | "OUT_OF_SERVICE_AREA" | "PERMANENTLY_CLOSED" | "BLACKLISTED" | "TEMPORARILY_CLOSED";
}

function serializeLocalsearchProtoInternalFoodOrderingActionMetadata(data: any): LocalsearchProtoInternalFoodOrderingActionMetadata {
  return {
    ...data,
    nextOpeningTime: data["nextOpeningTime"] !== undefined ? data["nextOpeningTime"].toISOString() : undefined,
    serviceInfo: data["serviceInfo"] !== undefined ? data["serviceInfo"].map((item: any) => (serializeLocalsearchProtoInternalFoodOrderingActionMetadataServiceInfo(item))) : undefined,
  };
}

function deserializeLocalsearchProtoInternalFoodOrderingActionMetadata(data: any): LocalsearchProtoInternalFoodOrderingActionMetadata {
  return {
    ...data,
    nextOpeningTime: data["nextOpeningTime"] !== undefined ? new Date(data["nextOpeningTime"]) : undefined,
    serviceInfo: data["serviceInfo"] !== undefined ? data["serviceInfo"].map((item: any) => (deserializeLocalsearchProtoInternalFoodOrderingActionMetadataServiceInfo(item))) : undefined,
  };
}

/**
 * Includes all partners that are either open now or supporting order ahead.
 */
export interface LocalsearchProtoInternalFoodOrderingActionMetadataAvailablePartnerInfo {
  /**
   * Available partner's id.
   */
  availablePartnerId?: bigint;
  /**
   * Indicates whether the partner is log only.
   */
  logOnly?: boolean;
}

function serializeLocalsearchProtoInternalFoodOrderingActionMetadataAvailablePartnerInfo(data: any): LocalsearchProtoInternalFoodOrderingActionMetadataAvailablePartnerInfo {
  return {
    ...data,
    availablePartnerId: data["availablePartnerId"] !== undefined ? String(data["availablePartnerId"]) : undefined,
  };
}

function deserializeLocalsearchProtoInternalFoodOrderingActionMetadataAvailablePartnerInfo(data: any): LocalsearchProtoInternalFoodOrderingActionMetadataAvailablePartnerInfo {
  return {
    ...data,
    availablePartnerId: data["availablePartnerId"] !== undefined ? BigInt(data["availablePartnerId"]) : undefined,
  };
}

export interface LocalsearchProtoInternalFoodOrderingActionMetadataServiceInfo {
  /**
   * Information about Food Ordering partner, which is used for whitelisting
   * the partner in Food Ordering entry points such as Placesheet.
   */
  availablePartnerInfo?: LocalsearchProtoInternalFoodOrderingActionMetadataAvailablePartnerInfo[];
  /**
   * Maximum max_wait_time in second.
   */
  maxWaitTimeSec?: bigint;
  /**
   * Only present for delivery case, service fee is not included.
   */
  minDeliveryFee?: GoogleTypeMoney;
  /**
   * Minimum min_wait_time in second.
   */
  minWaitTimeSec?: bigint;
  /**
   * Food ordering service type. Please note that only ServiceType.PICKUP and
   * ServiceType.DELIVERY are valid values for this field.
   */
  serviceType?:  | "UNKNOWN_TYPE" | "DELIVERY" | "PICKUP" | "ANY_TYPE";
}

function serializeLocalsearchProtoInternalFoodOrderingActionMetadataServiceInfo(data: any): LocalsearchProtoInternalFoodOrderingActionMetadataServiceInfo {
  return {
    ...data,
    availablePartnerInfo: data["availablePartnerInfo"] !== undefined ? data["availablePartnerInfo"].map((item: any) => (serializeLocalsearchProtoInternalFoodOrderingActionMetadataAvailablePartnerInfo(item))) : undefined,
    maxWaitTimeSec: data["maxWaitTimeSec"] !== undefined ? String(data["maxWaitTimeSec"]) : undefined,
    minDeliveryFee: data["minDeliveryFee"] !== undefined ? serializeGoogleTypeMoney(data["minDeliveryFee"]) : undefined,
    minWaitTimeSec: data["minWaitTimeSec"] !== undefined ? String(data["minWaitTimeSec"]) : undefined,
  };
}

function deserializeLocalsearchProtoInternalFoodOrderingActionMetadataServiceInfo(data: any): LocalsearchProtoInternalFoodOrderingActionMetadataServiceInfo {
  return {
    ...data,
    availablePartnerInfo: data["availablePartnerInfo"] !== undefined ? data["availablePartnerInfo"].map((item: any) => (deserializeLocalsearchProtoInternalFoodOrderingActionMetadataAvailablePartnerInfo(item))) : undefined,
    maxWaitTimeSec: data["maxWaitTimeSec"] !== undefined ? BigInt(data["maxWaitTimeSec"]) : undefined,
    minDeliveryFee: data["minDeliveryFee"] !== undefined ? deserializeGoogleTypeMoney(data["minDeliveryFee"]) : undefined,
    minWaitTimeSec: data["minWaitTimeSec"] !== undefined ? BigInt(data["minWaitTimeSec"]) : undefined,
  };
}

/**
 * Next Id: 36
 */
export interface LocalWWWInfo {
  address?: LocalWWWInfoAddress[];
  brickAndMortarStrength?: number;
  cluster?: LocalWWWInfoCluster[];
  docid?: bigint;
  /**
   * Information about geo locations, rather than individual businesses.
   */
  geotopicality?: RepositoryAnnotationsGeoTopicality;
  hours?: LocalWWWInfoOpeningHours[];
  /**
   * Does this LocalWWWInfo represent a widely-distributed chain?
   */
  isLargeChain?: boolean;
  isLargeLocalwwwinfo?: boolean;
  phone?: LocalWWWInfoPhone[];
  /**
   * These are per-document signals independent of any particular address.
   */
  siteSiblings?: number;
  /**
   * These are for convenience during intermediate data processing, and should
   * be cleared before the data gets into doc-joins.
   */
  url?: string;
  wrapptorItem?: LocalWWWInfoWrapptorItem[];
}

function serializeLocalWWWInfo(data: any): LocalWWWInfo {
  return {
    ...data,
    address: data["address"] !== undefined ? data["address"].map((item: any) => (serializeLocalWWWInfoAddress(item))) : undefined,
    cluster: data["cluster"] !== undefined ? data["cluster"].map((item: any) => (serializeLocalWWWInfoCluster(item))) : undefined,
    docid: data["docid"] !== undefined ? String(data["docid"]) : undefined,
    geotopicality: data["geotopicality"] !== undefined ? serializeRepositoryAnnotationsGeoTopicality(data["geotopicality"]) : undefined,
    hours: data["hours"] !== undefined ? data["hours"].map((item: any) => (serializeLocalWWWInfoOpeningHours(item))) : undefined,
    phone: data["phone"] !== undefined ? data["phone"].map((item: any) => (serializeLocalWWWInfoPhone(item))) : undefined,
    wrapptorItem: data["wrapptorItem"] !== undefined ? data["wrapptorItem"].map((item: any) => (serializeLocalWWWInfoWrapptorItem(item))) : undefined,
  };
}

function deserializeLocalWWWInfo(data: any): LocalWWWInfo {
  return {
    ...data,
    address: data["address"] !== undefined ? data["address"].map((item: any) => (deserializeLocalWWWInfoAddress(item))) : undefined,
    cluster: data["cluster"] !== undefined ? data["cluster"].map((item: any) => (deserializeLocalWWWInfoCluster(item))) : undefined,
    docid: data["docid"] !== undefined ? BigInt(data["docid"]) : undefined,
    geotopicality: data["geotopicality"] !== undefined ? deserializeRepositoryAnnotationsGeoTopicality(data["geotopicality"]) : undefined,
    hours: data["hours"] !== undefined ? data["hours"].map((item: any) => (deserializeLocalWWWInfoOpeningHours(item))) : undefined,
    phone: data["phone"] !== undefined ? data["phone"].map((item: any) => (deserializeLocalWWWInfoPhone(item))) : undefined,
    wrapptorItem: data["wrapptorItem"] !== undefined ? data["wrapptorItem"].map((item: any) => (deserializeLocalWWWInfoWrapptorItem(item))) : undefined,
  };
}

/**
 * These are the addresses, phone numbers, and opening hours related to this
 * document, or the local businesses mentioned on this document. We currently
 * populate these fields from web extractions, i.e, from the data present
 * explicitly on the document, but in future, they can also be filled with data
 * coming from the local index. We populate addresses and phone numbers only if
 * there are <= 4 addresses and phone numbers on the document, respectively.
 * This is primarily for space reasons.
 */
export interface LocalWWWInfoAddress {
  address?: GeostoreAddressProto;
  addrFprint?: bigint;
  latE7?: number;
  lngE7?: number;
}

function serializeLocalWWWInfoAddress(data: any): LocalWWWInfoAddress {
  return {
    ...data,
    address: data["address"] !== undefined ? serializeGeostoreAddressProto(data["address"]) : undefined,
    addrFprint: data["addrFprint"] !== undefined ? String(data["addrFprint"]) : undefined,
  };
}

function deserializeLocalWWWInfoAddress(data: any): LocalWWWInfoAddress {
  return {
    ...data,
    address: data["address"] !== undefined ? deserializeGeostoreAddressProto(data["address"]) : undefined,
    addrFprint: data["addrFprint"] !== undefined ? BigInt(data["addrFprint"]) : undefined,
  };
}

export interface LocalWWWInfoCluster {
  addrFprint?: bigint;
  /**
   * Confidence score for business mention annotations which is copied from
   * LocalEntityAnnotations::location_confidence.
   */
  annotationConfidence?: number;
  clusterdocid?: bigint;
  clusterid?: string;
  /**
   * Probability that this is the authority page of the business. Same as
   * LocalListing.authority_page_probability, only set for pages with
   * page_type_flags & AUTHORITY.
   */
  confidence?: number;
  /**
   * Feature type for this listing, from LocalListing::info::related_feature. A
   * geostore::FeatureProto::TypeCategory. Intended primarily to indicate
   * POI-ness (i.e., TYPE_ESTABLISHMENT_POI).
   */
  featureType?: number;
  /**
   * Opening hours for the business, from Local attributes and/or extracted
   * annotations.
   */
  hours?: GeostoreTimeScheduleProto;
  hoursSource?:  | "LOCAL" | "EXTRACTED_ONPAGE";
  includeInIndex?: boolean;
  /**
   * TODO(local-universal) Consider deleting is_plusbox once the new scheme
   * that uses make_plusbox_visible rolled out.
   */
  isPlusbox?: boolean;
  latitudeE6?: number;
  /**
   * DEPRECATED / NO LONGER WRITTEN. URL path level from actual references to
   * this webpage.
   */
  level?: number;
  longitudeE6?: number;
  /**
   * A hint for frontend to decide whether this plusbox should be visible or
   * not.
   */
  makePlusboxVisible?: boolean;
  /**
   * Menu link for the business. Currently only comes from Local attributes.
   */
  menuUrl?: string[];
  /**
   * Type of the web reference.
   */
  pageTypeFlags?: number;
  phoneFprint?: bigint;
  phoneNumber?: TelephoneNumber;
  postalAddress?: PostalAddress;
  /**
   * DEPRECATED / NO LONGER WRITTEN. How relevant the webpage is to the
   * business (clustering distance). Same as LocalListing::Reference.relevance.
   * Typically only set for pages with (page_type_flags & WEB_EXTRACTION &&
   * !AUTHORITY).
   */
  relevance?: number;
  showInSnippets?: boolean;
  source?: string[];
  title?: string;
}

function serializeLocalWWWInfoCluster(data: any): LocalWWWInfoCluster {
  return {
    ...data,
    addrFprint: data["addrFprint"] !== undefined ? String(data["addrFprint"]) : undefined,
    clusterdocid: data["clusterdocid"] !== undefined ? String(data["clusterdocid"]) : undefined,
    phoneFprint: data["phoneFprint"] !== undefined ? String(data["phoneFprint"]) : undefined,
  };
}

function deserializeLocalWWWInfoCluster(data: any): LocalWWWInfoCluster {
  return {
    ...data,
    addrFprint: data["addrFprint"] !== undefined ? BigInt(data["addrFprint"]) : undefined,
    clusterdocid: data["clusterdocid"] !== undefined ? BigInt(data["clusterdocid"]) : undefined,
    phoneFprint: data["phoneFprint"] !== undefined ? BigInt(data["phoneFprint"]) : undefined,
  };
}

/**
 * Populated from StoreHoursAnnotations.
 */
export interface LocalWWWInfoOpeningHours {
  hours?: GeostoreTimeScheduleProto;
  hoursFprint?: bigint;
}

function serializeLocalWWWInfoOpeningHours(data: any): LocalWWWInfoOpeningHours {
  return {
    ...data,
    hoursFprint: data["hoursFprint"] !== undefined ? String(data["hoursFprint"]) : undefined,
  };
}

function deserializeLocalWWWInfoOpeningHours(data: any): LocalWWWInfoOpeningHours {
  return {
    ...data,
    hoursFprint: data["hoursFprint"] !== undefined ? BigInt(data["hoursFprint"]) : undefined,
  };
}

export interface LocalWWWInfoPhone {
  phoneFprint?: bigint;
  phoneNumber?: TelephoneNumber;
}

function serializeLocalWWWInfoPhone(data: any): LocalWWWInfoPhone {
  return {
    ...data,
    phoneFprint: data["phoneFprint"] !== undefined ? String(data["phoneFprint"]) : undefined,
  };
}

function deserializeLocalWWWInfoPhone(data: any): LocalWWWInfoPhone {
  return {
    ...data,
    phoneFprint: data["phoneFprint"] !== undefined ? BigInt(data["phoneFprint"]) : undefined,
  };
}

/**
 * A single WrapptorItem, with a business name, an address and a phone number.
 * We keep only the fingerprints of address and phone number. The full address
 * and phone protos will be elsewhere within LocalWWWInfo.
 */
export interface LocalWWWInfoWrapptorItem {
  addrFprint?: bigint;
  bizName?: string;
  phoneFprint?: bigint;
}

function serializeLocalWWWInfoWrapptorItem(data: any): LocalWWWInfoWrapptorItem {
  return {
    ...data,
    addrFprint: data["addrFprint"] !== undefined ? String(data["addrFprint"]) : undefined,
    phoneFprint: data["phoneFprint"] !== undefined ? String(data["phoneFprint"]) : undefined,
  };
}

function deserializeLocalWWWInfoWrapptorItem(data: any): LocalWWWInfoWrapptorItem {
  return {
    ...data,
    addrFprint: data["addrFprint"] !== undefined ? BigInt(data["addrFprint"]) : undefined,
    phoneFprint: data["phoneFprint"] !== undefined ? BigInt(data["phoneFprint"]) : undefined,
  };
}

/**
 * Proto-representation of the Crawler-ID in Web-Search (Alexandria-Scope). The
 * string-representation (covered in
 * //indexing/crawler_id/scope/alexandria/crawler_id.h) and the
 * proto-representation are identical in meaning. For more information in regard
 * to the crawler_id, please look at //depot/google3/indexing/crawler_id Used
 * within the following components: - WebMirror: To understand the parsed
 * crawler-ID and apply attributes within their own tables. - Serving : to
 * identify the crawler-ID within the GenericSearchResponse, which implies being
 * stored in the MDU and returned by ascorer to Superroot. - QSessions: To store
 * the crawler-ID in all logged events for analysis. The default values
 * represent the 'empty string' crawler-ID for the Alexandria-scope.
 */
export interface LogsProtoIndexingCrawlerIdCrawlerIdProto {
  /**
   * The country to crawl the country from, defaults to the default
   * non-specified crawling node (which is interpreted by most web-servers as
   * USA). When specified, the crawling will fetch the document from a node in
   * that country instead.
   */
  country?:  | "NO_COUNTRY" | "AUSTRALIA" | "CANADA" | "GREAT_BRITAIN" | "MEXICO" | "RUSSIA";
  /**
   * The device type, which maps into the useragent to be set when initiating
   * the fetch-request, e.g. desktop-googlebot vs. smartphone-googlebot.
   */
  deviceType?:  | "DESKTOP" | "SMARTPHONE" | "MOBILE" | "JPMOBILE" | "IMAGE" | "VIDEO" | "APP" | "ANDROID_APP" | "IOS_APP" | "PIDGIN";
  /**
   * Specifies whether the document is a duplicated document from the index
   * growth experiment, detailed at go/indexsize_exp, defaults to not in any
   * experiment.
   */
  indexGrowthExptType?:  | "INDEX_GROWTH_EXPERIMENT_TYPE_DEFAULT" | "INDEX_GROWTH_EXPERIMENT_TYPE_DUPLICATED";
  /**
   * The language being set by the crawler. Defaults to UNKNOWN_LANGUAGE which
   * indicates to not apply an accept-language header on the FetchRequest. When
   * a language is specified, on crawling this language is converted into an
   * accept-language header (e.g. GERMAN -> "Accept-language: de"). Script
   * variations, e.g. ZH-HANS vs. ZH-HANT, are handled as different enum values
   * (e.g. CHINESE vs. CHINESE_T).
   */
  language?:  | "ENGLISH" | "DANISH" | "DUTCH" | "FINNISH" | "FRENCH" | "GERMAN" | "HEBREW" | "ITALIAN" | "JAPANESE" | "KOREAN" | "NORWEGIAN" | "POLISH" | "PORTUGUESE" | "RUSSIAN" | "SPANISH" | "SWEDISH" | "CHINESE" | "CZECH" | "GREEK" | "ICELANDIC" | "LATVIAN" | "LITHUANIAN" | "ROMANIAN" | "HUNGARIAN" | "ESTONIAN" | "TG_UNKNOWN_LANGUAGE" | "UNKNOWN_LANGUAGE" | "BULGARIAN" | "CROATIAN" | "SERBIAN" | "IRISH" | "GALICIAN" | "TAGALOG" | "TURKISH" | "UKRAINIAN" | "HINDI" | "MACEDONIAN" | "BENGALI" | "INDONESIAN" | "LATIN" | "MALAY" | "MALAYALAM" | "WELSH" | "NEPALI" | "TELUGU" | "ALBANIAN" | "TAMIL" | "BELARUSIAN" | "JAVANESE" | "OCCITAN" | "URDU" | "BIHARI" | "GUJARATI" | "THAI" | "ARABIC" | "CATALAN" | "ESPERANTO" | "BASQUE" | "INTERLINGUA" | "KANNADA" | "PUNJABI" | "SCOTS_GAELIC" | "SWAHILI" | "SLOVENIAN" | "MARATHI" | "MALTESE" | "VIETNAMESE" | "FRISIAN" | "SLOVAK" | "CHINESE_T" | "FAROESE" | "SUNDANESE" | "UZBEK" | "AMHARIC" | "AZERBAIJANI" | "GEORGIAN" | "TIGRINYA" | "PERSIAN" | "BOSNIAN" | "SINHALESE" | "NORWEGIAN_N" | "PORTUGUESE_P" | "PORTUGUESE_B" | "XHOSA" | "ZULU" | "GUARANI" | "SESOTHO" | "TURKMEN" | "KYRGYZ" | "BRETON" | "TWI" | "YIDDISH" | "SERBO_CROATIAN" | "SOMALI" | "UIGHUR" | "KURDISH" | "MONGOLIAN" | "ARMENIAN" | "LAOTHIAN" | "SINDHI" | "RHAETO_ROMANCE" | "AFRIKAANS" | "LUXEMBOURGISH" | "BURMESE" | "KHMER" | "TIBETAN" | "DHIVEHI" | "CHEROKEE" | "SYRIAC" | "LIMBU" | "ORIYA" | "ASSAMESE" | "CORSICAN" | "INTERLINGUE" | "KAZAKH" | "LINGALA" | "MOLDAVIAN" | "PASHTO" | "QUECHUA" | "SHONA" | "TAJIK" | "TATAR" | "TONGA" | "YORUBA" | "CREOLES_AND_PIDGINS_ENGLISH_BASED" | "CREOLES_AND_PIDGINS_FRENCH_BASED" | "CREOLES_AND_PIDGINS_PORTUGUESE_BASED" | "CREOLES_AND_PIDGINS_OTHER" | "MAORI" | "WOLOF" | "ABKHAZIAN" | "AFAR" | "AYMARA" | "BASHKIR" | "BISLAMA" | "DZONGKHA" | "FIJIAN" | "GREENLANDIC" | "HAUSA" | "HAITIAN_CREOLE" | "INUPIAK" | "INUKTITUT" | "KASHMIRI" | "KINYARWANDA" | "MALAGASY" | "NAURU" | "OROMO" | "RUNDI" | "SAMOAN" | "SANGO" | "SANSKRIT" | "SISWANT" | "TSONGA" | "TSWANA" | "VOLAPUK" | "ZHUANG" | "KHASI" | "SCOTS" | "GANDA" | "MANX" | "MONTENEGRIN" | "AKAN" | "IGBO" | "MAURITIAN_CREOLE" | "HAWAIIAN" | "CEBUANO" | "EWE" | "GA" | "HMONG" | "KRIO" | "LOZI" | "LUBA_LULUA" | "LUO_KENYA_AND_TANZANIA" | "NEWARI" | "NYANJA" | "OSSETIAN" | "PAMPANGA" | "PEDI" | "RAJASTHANI" | "SESELWA_CREOLE_FRENCH" | "TUMBUKA" | "VENDA" | "WARAY_PHILIPPINES" | "NUM_LANGUAGES";
  /**
   * Language-code used for identifying the locale of the document. 'language'
   * and 'country' above are used for web-based documents, representing the
   * detected language of the document and the country it was crawled from. The
   * language code here, however, rather represents an artifical language_code
   * applied to manually translated webpages (e.g. feeds), for instance for the
   * pidgin-usecase. They are limited to the set of III-codes being supported by
   * the client, yet are beyond the enum in 'language', e.g. to support variants
   * of English across different countries.
   */
  languageCode?:  | "LANGCODE_UNKNOWN" | "LANGCODE_EN_US" | "LANGCODE_EN_AU" | "LANGCODE_EN_CA" | "LANGCODE_DE_DE" | "LANGCODE_FR_FR" | "LANGCODE_FR_CA";
}

/**
 * Logs version of the repository_webref.EntityLinkMetadata proto Used to
 * represent QRef implications
 */
export interface LogsSemanticInterpretationIntentQueryEntityLinkMetadata {
  aggregateFlags?: LogsSemanticInterpretationIntentQueryLinkKindFlags;
  kindInfo?: LogsSemanticInterpretationIntentQueryLinkKindInfo[];
}

/**
 * Logs version of the repository_webref.LinkKindFlags proto Used to represent
 * QRef implications Next available tag: 8
 */
export interface LogsSemanticInterpretationIntentQueryLinkKindFlags {
  cluster?:  | "NO_CLUSTER" | "CLUSTER_CHILD_OF" | "CLUSTER_PARENT_OF";
  geoContainment?:  | "NO_CONTAINMENT" | "CONTAINED_BY" | "CONTAINS" | "PARTIAL_OVERLAP" | "HAS_STREET_NUMBER" | "LOCATED_ON_STREET";
  implication?:  | "NO_IMPLICATION" | "IMPLIED_BY" | "IMPLIES" | "BIDIRECTIONAL_IMPLICATION" | "UNDERMERGED";
  latentEntity?:  | "NO_LATENT_ENTITY" | "LATENT_ENTITY" | "MANIFEST_ENTITY" | "LATENT_ENTITY_V2" | "MANIFEST_ENTITY_V2";
  mdvc?:  | "NO_MDVC" | "MDVC_SPECIALIZATION_OF" | "MDVC_GENERALIZATION_OF" | "MDVC_DIMENSION_VALUE" | "MDVC_DIMENSION_VALUE_OF" | "MDVC_RESOLUTION" | "MDVC_EXPANDED_OUTPUT";
  property?:  | "NO_PROPERTY" | "EQUIVALENT_TOPIC" | "EQUIVALENT_PROPERTY";
  resolution?:  | "NO_RESOLUTION" | "MAY_BE_RESOLVED_FROM" | "MAY_RESOLVE_TO" | "RESOLVED_FROM" | "RESOLVES_TO";
}

/**
 * Logs version of the repository_webref.LinkKindInfo proto Used to represent
 * QRef implications
 */
export interface LogsSemanticInterpretationIntentQueryLinkKindInfo {
  flags?: LogsSemanticInterpretationIntentQueryLinkKindFlags;
  kcLinkName?: string;
  topicPropertyName?: string;
}

/**
 * Logs version of the repository_webref.SupportTransferRule proto Non-logs
 * version supports go/stbr
 */
export interface LogsSemanticInterpretationIntentQuerySupportTransferRule {
  allowWildcardIntents?: boolean;
  domain?: string;
  isReverseLink?: boolean;
  mentionsOnly?: boolean;
  supportShare?: boolean;
  targetCollection?: string;
  userCountry?: string;
  userLanguage?: string;
}

/**
 * Logs version of the repository_webref.WebrefEntityRelationship proto Used to
 * represent QRef implications
 */
export interface LogsSemanticInterpretationIntentQueryWebrefEntityRelationship {
  entityIndex?: number;
  linkMetadata?: LogsSemanticInterpretationIntentQueryEntityLinkMetadata;
  linkWeight?: number;
}

/**
 * An experimental long snippet. The protocol allows any permutation of headers
 * and plain text paragraphs, but typical responses are just paragraphs or
 * alternating headers and paragraphs.
 */
export interface LongStructuredSnippet {
  entry?: LongStructuredSnippetEntry[];
}

export interface LongStructuredSnippetEntry {
  /**
   * Is this a header or normal paragraph?
   */
  header?: boolean;
  /**
   * The text of the header or paragraph.
   */
  text?: string;
}

/**
 * The information on whether the contact is related to an app shortcut. Next
 * ID: 2
 */
export interface MajelContactInformationShortcutInformation {
  shortcutContactType?:  | "UNSPECIFIED" | "NON_SHORTCUT" | "INDIVIDUAL" | "GROUP";
}

/**
 * Flags that describe the information about a special word. If you add another
 * flag please add it to the special words implemenation in
 * google3/maps/quality/internal/special_words.cc. -- Next available id: 22 --
 */
export interface MapsQualitySpecialWordsFlags {
  /**
   * An affix that indicates an alley. Alleys are unnamed, numbered routes that
   * are always linked to a "parent street". As these parent streets can be
   * named e.g. "7th street" and alleys might be referred to as "7th alley", we
   * need to be able to distinguish those affixes. For more details about alleys
   * see go/vn-alley-geocoding.
   */
  isAlleyAffix?: boolean;
  /**
   * Common words E.g.: center, park, etc.
   */
  isCommonWord?: boolean;
  /**
   * Whether this special word is part of a name without a separator (like e.g.
   * suffix "strasse" in Freigutstrasse).
   */
  isDeconstructible?: boolean;
  /**
   * Directional modifier. E.g.: north, south, etc.
   */
  isDirectionalModifier?: boolean;
  /**
   * An affix that indicates distance marker on a route, e.g., 'km'.
   */
  isDistanceMarker?: boolean;
  /**
   * Whether geo paths are forbidden to contain this word.
   */
  isForbiddenWord?: boolean;
  /**
   * A keyword for a house id.
   */
  isHouseIdIdentifier?: boolean;
  /**
   * Intersection. E.g.: and, at, corner.
   */
  isIntersectionConnector?: boolean;
  /**
   * An affix that indicates a landmark, e.g. "opposite", "near" etc.
   */
  isLandmarkIdentifier?: boolean;
  /**
   * Language indicator. E.g.: platz in German, straat in Dutch.
   */
  isLanguageIndicator?: boolean;
  /**
   * Whether this is a name synonym and should be allowed to be matched on when
   * searching (that is, added to the retrieval query with the name/ prefix).
   */
  isNameSynonym?: boolean;
  /**
   * Terms which are not allowed to be used by the legacy street number
   * detection.
   */
  isNotForLegacyStreetNumberDetection?: boolean;
  /**
   * Terms which are not allowed to be treated as optional.
   */
  isNotOptionalizable?: boolean;
  /**
   * Numbers. E.g.: 1, one, 2, two.
   */
  isNumber?: boolean;
  /**
   * E.g. suffixes in French: bis, ter.
   */
  isNumberSuffix?: boolean;
  /**
   * Is this special word optional?
   */
  isOptional?: boolean;
  /**
   * E.g.: 1st, first.
   */
  isOrdinalNumber?: boolean;
  /**
   * Optional terms that should not geocode by themselves.
   */
  isPenalizedIfMissing?: boolean;
  /**
   * Personal titles (e.g. doctor, professor, general, etc.)
   */
  isPersonalTitle?: boolean;
  /**
   * E.g.: the, in, near, where.
   */
  isStopWord?: boolean;
  /**
   * A keyword that denotes a street number, e.g. "number", "unit" etc.
   */
  isStreetNumberIdentifier?: boolean;
}

/**
 * The goal of the special words are to: - Canonicalize the user query by
 * rewriting abbreviations into the canonical version that is indexed. - Figure
 * out at index time for each element which tokens are important. We use this to
 * decide if an address component is matched or not. For instance in "1600
 * Pennsylvania Ave NW" since "NW" is recognised as a directional (and "Ave" is
 * recognised as a street visible type), "Pennsylvania" becomes the name and you
 * can't match this street by just specifying "avenue" or "NW".
 */
export interface MapsQualitySpecialWordsProto {
  /**
   * Alternate versions of this canonical form. This is mainly abbreviations of
   * the canonical form e.g. "St", "NE", etc. This should be present as it is
   * used in the specified language with the correct capitalization, accents,
   * etc. in UTF-8.
   */
  alternate?: string[];
  /**
   * Canonical versions: the version which is in oyster. This should be present
   * as it is used in the specified language with the correct capitalization,
   * accents, etc. in UTF-8. The canonical can be a single or a multi-token
   * string. There can be several canonicals, e.g. "center" and "centre" in
   * English.
   */
  canonical?: string[];
  /**
   * If empty, apply this rule to any country. Otherwise, a list of ISO 3166-1
   * alpha-2 (2-letter uppercase) country codes that this description applies
   * to.
   */
  country?: string[];
  /**
   * Boolean flags indicating what type of special word this is.
   */
  flags?: MapsQualitySpecialWordsFlags;
  /**
   * The III language code of the language that this description applies to. No
   * language means that this applies worldwide. This could be useful for codes
   * like country codes or airport codes or for displayed language neutral
   * icons. A special word with a language code here also applies to the
   * regional variants of that language (e.g. "en" applies to "en-GB" and
   * "en-US" as well).
   */
  language?: string[];
  position?:  | "AFFIX" | "PREFIX" | "SUFFIX";
  /**
   * visible_type_id from VisibleTypeProto for visible types converted to the
   * special words. For original special words this field is empty.
   */
  visibleTypeId?: string[];
}

/**
 * Stores coordinates corresponding to the dimensions of the box surrounding
 * the region of interest. Coordinates may be normalized or absolute depending
 * on the implementation and signal corresponding to this field.
 */
export interface MediaIndexBoundingbox {
  /**
   * The area of the region as a fraction of the image. The value is in the
   * range (0, 1).
   */
  areaFraction?: number;
  xmax?: number;
  xmin?: number;
  ymax?: number;
  ymin?: number;
}

/**
 * Packages entity id and score together for a given source.
 */
export interface MediaIndexEntityField {
  /**
   * The custom source should only be a-z[0-9] dashes, underscores, and colons.
   * Special characters should be avoided.
   */
  customSource?: string;
  entityId?: string;
  quantizedScore?: bigint;
  source?:  | "UNKNOWN" | "ICA_LABELS" | "VISUAL_DICTIONARY" | "VISUAL_SEARCH_LANDMARK" | "WEBREF_ANNOTATIONS" | "KG_KP" | "SMEARED_VISUAL_DICTIONARY" | "SMEARED_VISUAL_SEARCH_LANDMARK" | "CURATED_SIGNAL" | "LAVD_BONES" | "ICA_H_TOPICALITY" | "WEBREF_CONFIDENCE" | "LAVD_TRAVEL_SNAPWIRE" | "LAVD_TRAVEL_500PX" | "LAVD_TRAVEL_ALAMY" | "LAVD_TRAVEL_EYEEM" | "LAVD_TRAVEL_SHUTTERSTOCK" | "LAVD_TRAVEL_GETTY" | "PROVIDED_PEOPLE" | "KG_AUTOMOTIVE" | "SMEARED_NAVBOOST" | "KIWI_ENTITY_VISUAL_SCORE" | "KIWI_ENTITY_RANK" | "KIWI_ENTITY_VISUAL_SCORE_EXP" | "KIWI_ENTITY_RANK_EXP";
}

function serializeMediaIndexEntityField(data: any): MediaIndexEntityField {
  return {
    ...data,
    quantizedScore: data["quantizedScore"] !== undefined ? String(data["quantizedScore"]) : undefined,
  };
}

function deserializeMediaIndexEntityField(data: any): MediaIndexEntityField {
  return {
    ...data,
    quantizedScore: data["quantizedScore"] !== undefined ? BigInt(data["quantizedScore"]) : undefined,
  };
}

/**
 * Identifier for frames associated with a video.
 */
export interface MediaIndexFrameIdentifier {
  previewFrameZeroVariant?: MediaIndexFrameIdentifierPreviewFrameZeroVariant;
  /**
   * Offset of the frame from the beginning of the video (in milliseconds).
   */
  timestampMs?: number;
}

/**
 * This variant defines the frame to be the first frame of the video's
 * generated preview.
 */
export interface MediaIndexFrameIdentifierPreviewFrameZeroVariant {
  previewLength?:  | "UNSPECIFIED" | "THREE_SECONDS" | "SIX_SECONDS";
  /**
   * All xtags used in the generation of the preview. The same frame generated
   * from the same preview with different xtags will likely have different bytes
   * (such as, for example, resulting from a different aspect ratio).
   */
  xtagList?: MediaIndexXtagList;
}

/**
 * Metadata associated with a region in an image. NEXT_ID: 14
 */
export interface MediaIndexRegion {
  /**
   * The bounding box corresponding to the region.
   */
  boundingBox?: MediaIndexBoundingbox;
  /**
   * Detected Entities found within this region.
   */
  entityFields?: MediaIndexEntityField[];
  /**
   * The labels associated with the region encoded as a SparseFloatVector to
   * facilitate dot product computation during sorting. The columns are the
   * fingerprints of the labels and the values are the corresponding confidence
   * scores. The vector is L2 normalized.
   */
  labels?: MediaIndexSparseFloatVector;
  /**
   * PRIMI Apparel Features v2 embedding and tokens.
   */
  primiApparelFeaturesV2?: Uint8Array;
  primiApparelTokensV2?: Uint8Array[];
  /**
   * PRIMI Generic Features v2.5 embedding and tokens.
   */
  primiGenericFeaturesV25?: Uint8Array;
  primiGenericTokensV25?: Uint8Array[];
  /**
   * Starburst v4 embedding and tokens.
   */
  starburstFeaturesV4?: Uint8Array;
  /**
   * Starburst v5 embedding and tokens.
   */
  starburstFeaturesV5?: Uint8Array;
  starburstTokensV4?: Uint8Array[];
  starburstTokensV5?: Uint8Array[];
  starburstV4?: ImageContentStarburstVersionGroup;
  starburstV5?: ImageContentStarburstVersionGroup;
}

function serializeMediaIndexRegion(data: any): MediaIndexRegion {
  return {
    ...data,
    entityFields: data["entityFields"] !== undefined ? data["entityFields"].map((item: any) => (serializeMediaIndexEntityField(item))) : undefined,
    labels: data["labels"] !== undefined ? serializeMediaIndexSparseFloatVector(data["labels"]) : undefined,
    primiApparelFeaturesV2: data["primiApparelFeaturesV2"] !== undefined ? encodeBase64(data["primiApparelFeaturesV2"]) : undefined,
    primiApparelTokensV2: data["primiApparelTokensV2"] !== undefined ? data["primiApparelTokensV2"].map((item: any) => (encodeBase64(item))) : undefined,
    primiGenericFeaturesV25: data["primiGenericFeaturesV25"] !== undefined ? encodeBase64(data["primiGenericFeaturesV25"]) : undefined,
    primiGenericTokensV25: data["primiGenericTokensV25"] !== undefined ? data["primiGenericTokensV25"].map((item: any) => (encodeBase64(item))) : undefined,
    starburstFeaturesV4: data["starburstFeaturesV4"] !== undefined ? encodeBase64(data["starburstFeaturesV4"]) : undefined,
    starburstFeaturesV5: data["starburstFeaturesV5"] !== undefined ? encodeBase64(data["starburstFeaturesV5"]) : undefined,
    starburstTokensV4: data["starburstTokensV4"] !== undefined ? data["starburstTokensV4"].map((item: any) => (encodeBase64(item))) : undefined,
    starburstTokensV5: data["starburstTokensV5"] !== undefined ? data["starburstTokensV5"].map((item: any) => (encodeBase64(item))) : undefined,
    starburstV4: data["starburstV4"] !== undefined ? serializeImageContentStarburstVersionGroup(data["starburstV4"]) : undefined,
    starburstV5: data["starburstV5"] !== undefined ? serializeImageContentStarburstVersionGroup(data["starburstV5"]) : undefined,
  };
}

function deserializeMediaIndexRegion(data: any): MediaIndexRegion {
  return {
    ...data,
    entityFields: data["entityFields"] !== undefined ? data["entityFields"].map((item: any) => (deserializeMediaIndexEntityField(item))) : undefined,
    labels: data["labels"] !== undefined ? deserializeMediaIndexSparseFloatVector(data["labels"]) : undefined,
    primiApparelFeaturesV2: data["primiApparelFeaturesV2"] !== undefined ? decodeBase64(data["primiApparelFeaturesV2"] as string) : undefined,
    primiApparelTokensV2: data["primiApparelTokensV2"] !== undefined ? data["primiApparelTokensV2"].map((item: any) => (decodeBase64(item as string))) : undefined,
    primiGenericFeaturesV25: data["primiGenericFeaturesV25"] !== undefined ? decodeBase64(data["primiGenericFeaturesV25"] as string) : undefined,
    primiGenericTokensV25: data["primiGenericTokensV25"] !== undefined ? data["primiGenericTokensV25"].map((item: any) => (decodeBase64(item as string))) : undefined,
    starburstFeaturesV4: data["starburstFeaturesV4"] !== undefined ? decodeBase64(data["starburstFeaturesV4"] as string) : undefined,
    starburstFeaturesV5: data["starburstFeaturesV5"] !== undefined ? decodeBase64(data["starburstFeaturesV5"] as string) : undefined,
    starburstTokensV4: data["starburstTokensV4"] !== undefined ? data["starburstTokensV4"].map((item: any) => (decodeBase64(item as string))) : undefined,
    starburstTokensV5: data["starburstTokensV5"] !== undefined ? data["starburstTokensV5"].map((item: any) => (decodeBase64(item as string))) : undefined,
    starburstV4: data["starburstV4"] !== undefined ? deserializeImageContentStarburstVersionGroup(data["starburstV4"]) : undefined,
    starburstV5: data["starburstV5"] !== undefined ? deserializeImageContentStarburstVersionGroup(data["starburstV5"]) : undefined,
  };
}

export interface MediaIndexSparseFloatVector {
  /**
   * Parallel arrays of column / value. Exactly one of those columns vector
   * should be set. Columns must be in monotonically increasing order.
   */
  columns?: bigint[];
  columnsInt16?: Uint8Array;
  columnsInt32?: number[];
  /**
   * Columns are fixed integers, used for accelerated parse.
   */
  columnsInt64?: bigint[];
  columnsInt8?: Uint8Array;
  values?: number[];
}

function serializeMediaIndexSparseFloatVector(data: any): MediaIndexSparseFloatVector {
  return {
    ...data,
    columns: data["columns"] !== undefined ? data["columns"].map((item: any) => (String(item))) : undefined,
    columnsInt16: data["columnsInt16"] !== undefined ? encodeBase64(data["columnsInt16"]) : undefined,
    columnsInt64: data["columnsInt64"] !== undefined ? data["columnsInt64"].map((item: any) => (String(item))) : undefined,
    columnsInt8: data["columnsInt8"] !== undefined ? encodeBase64(data["columnsInt8"]) : undefined,
  };
}

function deserializeMediaIndexSparseFloatVector(data: any): MediaIndexSparseFloatVector {
  return {
    ...data,
    columns: data["columns"] !== undefined ? data["columns"].map((item: any) => (BigInt(item))) : undefined,
    columnsInt16: data["columnsInt16"] !== undefined ? decodeBase64(data["columnsInt16"] as string) : undefined,
    columnsInt64: data["columnsInt64"] !== undefined ? data["columnsInt64"].map((item: any) => (BigInt(item))) : undefined,
    columnsInt8: data["columnsInt8"] !== undefined ? decodeBase64(data["columnsInt8"] as string) : undefined,
  };
}

/**
 * Data about the behavior of the video across the pages it is embedded in.
 */
export interface MediaIndexVideoCentroid {
  domainScores?: MediaIndexVideoCentroidDomainScore[];
}

/**
 * See go/video-centroid-domain-score.
 */
export interface MediaIndexVideoCentroidDomainScore {
  /**
   * The domain this score was generated for.
   */
  domain?: string;
  /**
   * Number of pages from the domain used to generate this DomainScore.
   */
  numDocs?: number;
  /**
   * In general, lower scores indicate the video is appearing on more diverse
   * pages.
   */
  score?: number;
}

/**
 * Core signals for video content corpus which will be fetched for every query.
 * If a signal is required only for a subset of search queries then it should be
 * added as a separate field in the schema.
 */
export interface MediaIndexVideoCoreSignals {
  centroid?: MediaIndexVideoCentroid;
  videoFrames?: MediaIndexVideoFrame[];
}

function serializeMediaIndexVideoCoreSignals(data: any): MediaIndexVideoCoreSignals {
  return {
    ...data,
    videoFrames: data["videoFrames"] !== undefined ? data["videoFrames"].map((item: any) => (serializeMediaIndexVideoFrame(item))) : undefined,
  };
}

function deserializeMediaIndexVideoCoreSignals(data: any): MediaIndexVideoCoreSignals {
  return {
    ...data,
    videoFrames: data["videoFrames"] !== undefined ? data["videoFrames"].map((item: any) => (deserializeMediaIndexVideoFrame(item))) : undefined,
  };
}

/**
 * Data about a frame associated with the video.
 */
export interface MediaIndexVideoFrame {
  /**
   * The canonical docid of the frame.
   */
  docid?: bigint;
  frameIdentifier?: MediaIndexFrameIdentifier;
  /**
   * Metadata associated with regions within this frame.
   */
  regions?: MediaIndexRegion[];
  /**
   * Starburst v4 embedding and tokens.
   */
  starburstFeaturesV4?: string;
  /**
   * Note: due to the migration to Golden7-source Starburst v4 embedding, no
   * starburst_tokens_v4 will be provided in video content corpus
   * (go/video-content-corpus). But this field is kept in case other purposes
   * may still use it in the proto.
   */
  starburstTokensV4?: string[];
  /**
   * Set of available thumbnail types for this frame. Should be valid
   * image_base.ThumbnailType values (enumerated at
   * http://google3/image/base/thumbnail-type.proto).
   */
  thumbnailType?: bigint[];
}

function serializeMediaIndexVideoFrame(data: any): MediaIndexVideoFrame {
  return {
    ...data,
    docid: data["docid"] !== undefined ? String(data["docid"]) : undefined,
    regions: data["regions"] !== undefined ? data["regions"].map((item: any) => (serializeMediaIndexRegion(item))) : undefined,
    thumbnailType: data["thumbnailType"] !== undefined ? data["thumbnailType"].map((item: any) => (String(item))) : undefined,
  };
}

function deserializeMediaIndexVideoFrame(data: any): MediaIndexVideoFrame {
  return {
    ...data,
    docid: data["docid"] !== undefined ? BigInt(data["docid"]) : undefined,
    regions: data["regions"] !== undefined ? data["regions"].map((item: any) => (deserializeMediaIndexRegion(item))) : undefined,
    thumbnailType: data["thumbnailType"] !== undefined ? data["thumbnailType"].map((item: any) => (BigInt(item))) : undefined,
  };
}

/**
 * Data about multiple video frames associated with the video.
 */
export interface MediaIndexVideoFrames {
  videoFrames?: MediaIndexVideoFrame[];
}

function serializeMediaIndexVideoFrames(data: any): MediaIndexVideoFrames {
  return {
    ...data,
    videoFrames: data["videoFrames"] !== undefined ? data["videoFrames"].map((item: any) => (serializeMediaIndexVideoFrame(item))) : undefined,
  };
}

function deserializeMediaIndexVideoFrames(data: any): MediaIndexVideoFrames {
  return {
    ...data,
    videoFrames: data["videoFrames"] !== undefined ? data["videoFrames"].map((item: any) => (deserializeMediaIndexVideoFrame(item))) : undefined,
  };
}

export interface MediaIndexXtag {
  /**
   * Names are all stored case-sensitive, and no case-folding is done for
   * comparisons.
   */
  name?: string;
  /**
   * The value associated with this Xtag. Values are all stored case-sensitive,
   * and no case-folding is done for comparisons.
   */
  value?: string;
}

/**
 * XtagList -- a collection of Xtag instances with unique names. This would be
 * associated with one specific piece of content.
 */
export interface MediaIndexXtagList {
  xtags?: MediaIndexXtag[];
}

/**
 * Note: This message is also in the RTUpdate protocol buffer.
 */
export interface MobilePerDocData {
  flags?: number;
  /**
   * DEPRECATED: Url of the mobile version of the document. This is set during
   * canonicalization if we do not know that the Web url also serves the mobile
   * version.
   */
  mobileurl?: string;
  /**
   * DEPRECATED: The transcoded page quality repesented in 7-bits range from 0
   * to 127.
   */
  transcodedPageScore?: number;
}

/**
 * Defines the presence of a field. This can help distinguish between empty vs.
 * not-present annotations.
 */
export interface MultiscaleFieldPresence {
  /**
   * Whether the field (data field or pointer) is defined.
   */
  present?: boolean;
  wellDefined?:  | "WD_UNDEFINED" | "WD_WELL_DEFINED" | "WD_PARTIAL";
}

/**
 * Defines the presence of a layer (previously called "scale").
 */
export interface MultiscaleLayerPresence {
  /**
   * If the layer is not materialized but things point into it, this gives the
   * effective length.
   */
  implicitLength?: number;
  /**
   * Whether the layer is present.
   */
  present?: boolean;
}

/**
 * Pointer to a single node in a target scale. `pointer.Index` fields should be
 * annotated with a `(pointer.to)` annotation, indicating what scale they point
 * at.
 */
export interface MultiscalePointerIndex {
  /**
   * The index of the node that this pointer points to.
   */
  index?: number;
}

/**
 * Pointer to a contiguous range of nodes in a target scale. `pointer.Span`
 * fields should be annotated with a `(pointer.to)` annotation, indicating what
 * scale they point at.
 */
export interface MultiscalePointerSpan {
  /**
   * The exclusive end index for the span of nodes that this pointer points to
   * -- i.e., one plus the index of the last node in the span. Must be greater
   * than or equal to `start`. If equal to `start`, then the target span is
   * empty.
   */
  limit?: number;
  /**
   * The inclusive start index for the span of nodes that this pointer points
   * to -- i.e., the index of the first node in the span.
   */
  start?: number;
}

/**
 * CandidateFeature contains a pair of feature name and score for a snippet
 * candidate.
 */
export interface MustangReposWwwSnippetsCandidateFeature {
  /**
   * Name corresponds to the names in WebChooserScorer::FeatureNames.
   */
  name?: string;
  score?: number;
}

/**
 * Data to generate the list preview for organic list snippets.
 */
export interface MustangReposWwwSnippetsOrganicListSnippetResponse {
  /**
   * The texts of header and listing items.
   */
  header?: string;
  /**
   * The ratio of header tokens covered by title.
   */
  headerTitleRedundancy?: number;
  /**
   * If the header being used in organic snippet.
   */
  headerUsedInSnippet?: boolean;
  items?: string[];
  /**
   * The number of items in the original list.
   */
  originalTotalItems?: number;
  /**
   * The score of the radish signal.
   */
  radishScore?: number;
}

/**
 * This message contains features for candidates at the chooser level. For each
 * snippet candidate, we also log the final score as the last candidate feature.
 */
export interface MustangReposWwwSnippetsSnippetCandidate {
  /**
   * data_source_type corresponds to the ChosenSnippet::SnippetType enum.
   */
  dataSourceType?: number;
  features?: MustangReposWwwSnippetsCandidateFeature[];
  text?: string;
}

/**
 * This is a protocol buffer to export into flatfiles in ranklab. All fields
 * are converted into flatfiles with some specific prefix and a field name like
 * 'snippet_features_snippet_data_source_type'.
 */
export interface MustangReposWwwSnippetsSnippetsRanklabFeatures {
  /**
   * Browser width.
   */
  browserWidth?: number;
  /**
   * Features for snippets candidates, generated by both old and new scorer.
   * Currently only features for chosen candidate is generated.
   */
  candidates?: MustangReposWwwSnippetsSnippetCandidate[];
  /**
   * Snippet features for the final chosen snippet. This field is firstly
   * populated by Muppet, and then overwriten by Superroot if SnippetBrain is
   * triggered.
   */
  displaySnippet?: QualityPreviewRanklabSnippet;
  /**
   * locale of the document.
   */
  documentLanguage?: string;
  /**
   * Original query term coverage in titles and / or snippets.
   */
  originalQueryTermCoverages?: QualityPreviewSnippetQueryTermCoverageFeatures;
  /**
   * locale of the query,
   */
  queryLanguage?: string;
  /**
   * Snippet data source.
   */
  snippetDataSourceType?: number;
  /**
   * Query term coverage in snippets.
   */
  snippetQueryTermCoverage?: number;
  /**
   * Snippet features for Muppet snippet candidates. In production, only the
   * data for chosen snippet will be recorded.
   */
  snippets?: QualityPreviewRanklabSnippet[];
  /**
   * Title data source.
   */
  titleDataSourceType?: number;
  /**
   * Query term coverage in titles.
   */
  titleQueryTermCoverage?: number;
  /**
   * Per-candidate title features for ranklab models, sorted from the best
   * candidate to the worst candidate (i.e., the first element is the actually
   * selected title).
   */
  titles?: QualityPreviewRanklabTitle[];
  /**
   * Query term coverage in titles and snippets.
   */
  titleSnippetQueryTermCoverage?: number;
}

function serializeMustangReposWwwSnippetsSnippetsRanklabFeatures(data: any): MustangReposWwwSnippetsSnippetsRanklabFeatures {
  return {
    ...data,
    displaySnippet: data["displaySnippet"] !== undefined ? serializeQualityPreviewRanklabSnippet(data["displaySnippet"]) : undefined,
    snippets: data["snippets"] !== undefined ? data["snippets"].map((item: any) => (serializeQualityPreviewRanklabSnippet(item))) : undefined,
  };
}

function deserializeMustangReposWwwSnippetsSnippetsRanklabFeatures(data: any): MustangReposWwwSnippetsSnippetsRanklabFeatures {
  return {
    ...data,
    displaySnippet: data["displaySnippet"] !== undefined ? deserializeQualityPreviewRanklabSnippet(data["displaySnippet"]) : undefined,
    snippets: data["snippets"] !== undefined ? data["snippets"].map((item: any) => (deserializeQualityPreviewRanklabSnippet(item))) : undefined,
  };
}

/**
 * Tidbit token rendered in generating snippet/title.
 */
export interface MustangSnippetsRenderedToken {
  /**
   * Is the rendered token bolded (insided )
   */
  bolded?: boolean;
  /**
   * Byte offset range in the rendered text that corresponds to this token.
   * [byte_offset_begin, byte_offset_end) inclusive
   */
  byteOffsetBegin?: number;
  /**
   * exclusive
   */
  byteOffsetEnd?: number;
  /**
   * Section and TokenPos of the token.
   */
  section?:  | "UNKNOWN" | "BODY_WITH_SOFT_TOKEN" | "GWD" | "META";
  tokenPos?: bigint;
}

function serializeMustangSnippetsRenderedToken(data: any): MustangSnippetsRenderedToken {
  return {
    ...data,
    tokenPos: data["tokenPos"] !== undefined ? String(data["tokenPos"]) : undefined,
  };
}

function deserializeMustangSnippetsRenderedToken(data: any): MustangSnippetsRenderedToken {
  return {
    ...data,
    tokenPos: data["tokenPos"] !== undefined ? BigInt(data["tokenPos"]) : undefined,
  };
}

/**
 * Globally unique identifier for a virtual network.
 */
export interface NetFabricRpcVirtualNetworkId {
  /**
   * required
   */
  id?: number;
}

/**
 * The proto that holds the complete call path info of the QRewrite client
 * (e.g. the QUS's phase like "RBT","QBT"; the QUS's candidate type like
 * "Identity"; and the ACE's candidate type like "FuzzyMatcher"). Next ID: 5 ACE
 * tags
 */
export interface NlpLoggingQRewriteClientCallPathInfo {
  /**
   * Indicates the type of candidate rewritten by QRewrite. This field is
   * filled within QRewrite instead of QRewrite clients, and we add this here so
   * this proto is able to hold all tags to form the identifier.
   */
  qrewriteCandidateId?: QualityQrewriteCandidateId;
  /**
   * QUS tags Indicates the type of the candidate in QUS that sends the
   * QRewrite request.
   */
  qusCandidateId?: QualityQrewriteCandidateId;
  /**
   * Upstream call path before QUS.
   */
  qusClientCallPathInfo?: NlpLoggingQusClientCallPathInfo;
  /**
   * Indicates which QUS phase sends the QRewrite request. Note if the QRewrite
   * response is reused in succeeding phases, this field should not be
   * overridden and it is always the phase that initially sends the RPC.
   */
  qusPhase?:  | "QU_PHASE_UNSPECIFIED" | "QU_PHASE_REQUEST" | "QU_PHASE_QREWRITE" | "QU_PHASE_QBT" | "QU_PHASE_PROBE_QUERY" | "QU_PHASE_MULTI_ACCOUNT" | "QU_PHASE_CQBT" | "QU_PHASE_QBT_RESOLUTION" | "QU_PHASE_HIGH_PRECISION" | "QU_PHASE_COMBINED_RBT_RESOLUTION" | "QU_PHASE_ANALYZER_INPUT";
}

function serializeNlpLoggingQRewriteClientCallPathInfo(data: any): NlpLoggingQRewriteClientCallPathInfo {
  return {
    ...data,
    qusClientCallPathInfo: data["qusClientCallPathInfo"] !== undefined ? serializeNlpLoggingQusClientCallPathInfo(data["qusClientCallPathInfo"]) : undefined,
  };
}

function deserializeNlpLoggingQRewriteClientCallPathInfo(data: any): NlpLoggingQRewriteClientCallPathInfo {
  return {
    ...data,
    qusClientCallPathInfo: data["qusClientCallPathInfo"] !== undefined ? deserializeNlpLoggingQusClientCallPathInfo(data["qusClientCallPathInfo"]) : undefined,
  };
}

/**
 * The proto that holds the complete call path info of the QUS client (e.g. the
 * candidate type like "Identity", "FuzzyMatcher"; The intent generator like
 * "QUS_IG" in ACE).
 */
export interface NlpLoggingQusClientCallPathInfo {
  /**
   * rewriter_type forms part of a unique key to be used to label QUS Requests
   * from ACE. The need to distinguish between the variety of calls from AS into
   * QUS is for two reasons: (a) currently, assistant eval can do NLU Eval only
   * on certain rewrites (b) later AS Hermetic and NLU Eval can be integrated In
   * the furure, the unique key will be expanded to add intent_generator_type or
   * something similar. There are ongoing discussions to confirm these plans
   */
  rewriterType?:  | "UNKNOWN_REWRITER_TYPE" | "GENIE" | "FUZZY_MATCHER_HC" | "FUZZY_MATCHER" | "FUZZY_MATCHER_ADDITIONAL_1" | "FUZZY_MATCHER_ADDITIONAL_2" | "IDENTITY" | "MONDEGREEN_ASSISTANT" | "MONDEGREEN" | "SYNTHETIC" | "SPEECH_RECOGNITION" | "SPEECH_MISRECOGNITION" | "SPELL_CORRECTION" | "AUTO_TRANSLATION" | "AUTO_TRANSLATION_ARGUMENT_TRANSFER";
  /**
   * The timestamp when QUS request is built in ACE. For now we don't care
   * about the actual meaning of this tag, and only want to guarantee its
   * uniqueness per QUS call.
   */
  temporaryAceTag?: bigint;
}

function serializeNlpLoggingQusClientCallPathInfo(data: any): NlpLoggingQusClientCallPathInfo {
  return {
    ...data,
    temporaryAceTag: data["temporaryAceTag"] !== undefined ? String(data["temporaryAceTag"]) : undefined,
  };
}

function deserializeNlpLoggingQusClientCallPathInfo(data: any): NlpLoggingQusClientCallPathInfo {
  return {
    ...data,
    temporaryAceTag: data["temporaryAceTag"] !== undefined ? BigInt(data["temporaryAceTag"]) : undefined,
  };
}

export interface NlpMeaningMeaningRemodeling {
  /**
   * This field can be set to true to indicate that the associated part of the
   * schema is being deleted as part of the remodeling.
   */
  deletion?: boolean;
  /**
   * The remodeling ID. Each remodeling has a unique ID that is used to
   * associate changes with that remodeling.
   */
  id?: bigint;
}

function serializeNlpMeaningMeaningRemodeling(data: any): NlpMeaningMeaningRemodeling {
  return {
    ...data,
    id: data["id"] !== undefined ? String(data["id"]) : undefined,
  };
}

function deserializeNlpMeaningMeaningRemodeling(data: any): NlpMeaningMeaningRemodeling {
  return {
    ...data,
    id: data["id"] !== undefined ? BigInt(data["id"]) : undefined,
  };
}

/**
 * This is the FunctionCall counterpart to the "MeaningRemodelings" structure.
 * When present, it is used for typechecking the FunctionCall against the schema
 * with the remodelings enabled.
 */
export interface NlpMeaningMeaningRemodelingControl {
  remodelingId?: bigint[];
}

function serializeNlpMeaningMeaningRemodelingControl(data: any): NlpMeaningMeaningRemodelingControl {
  return {
    ...data,
    remodelingId: data["remodelingId"] !== undefined ? data["remodelingId"].map((item: any) => (String(item))) : undefined,
  };
}

function deserializeNlpMeaningMeaningRemodelingControl(data: any): NlpMeaningMeaningRemodelingControl {
  return {
    ...data,
    remodelingId: data["remodelingId"] !== undefined ? data["remodelingId"].map((item: any) => (BigInt(item))) : undefined,
  };
}

/**
 * This proto will be added as a field to part of a schema to indicate it is
 * being remodeled.
 */
export interface NlpMeaningMeaningRemodelings {
  remodeling?: NlpMeaningMeaningRemodeling[];
}

function serializeNlpMeaningMeaningRemodelings(data: any): NlpMeaningMeaningRemodelings {
  return {
    ...data,
    remodeling: data["remodeling"] !== undefined ? data["remodeling"].map((item: any) => (serializeNlpMeaningMeaningRemodeling(item))) : undefined,
  };
}

function deserializeNlpMeaningMeaningRemodelings(data: any): NlpMeaningMeaningRemodelings {
  return {
    ...data,
    remodeling: data["remodeling"] !== undefined ? data["remodeling"].map((item: any) => (deserializeNlpMeaningMeaningRemodeling(item))) : undefined,
  };
}

/**
 * Associates remodeling data with a semantic type name.
 */
export interface NlpMeaningSemanticTypeNameMeaningRemodelings {
  /**
   * Semantic type name.
   */
  name?: string;
  remodelings?: NlpMeaningMeaningRemodelings;
}

function serializeNlpMeaningSemanticTypeNameMeaningRemodelings(data: any): NlpMeaningSemanticTypeNameMeaningRemodelings {
  return {
    ...data,
    remodelings: data["remodelings"] !== undefined ? serializeNlpMeaningMeaningRemodelings(data["remodelings"]) : undefined,
  };
}

function deserializeNlpMeaningSemanticTypeNameMeaningRemodelings(data: any): NlpMeaningSemanticTypeNameMeaningRemodelings {
  return {
    ...data,
    remodelings: data["remodelings"] !== undefined ? deserializeNlpMeaningMeaningRemodelings(data["remodelings"]) : undefined,
  };
}

/**
 * Representation of a phrase in the document with a particular annotation.
 * Provides the ability to annotate arbitrary spans in the document. This is
 * intended for representing spans that SAFT does NOT consider to be mentions of
 * entities within a SAFT document.
 */
export interface NlpSaftAnnotatedPhrase {
  /**
   * Annotation for this phrase.
   */
  info?: Proto2BridgeMessageSet;
  /**
   * Contains start and end pointers to the token array for this span.
   */
  phrase?: NlpSaftPhrase;
}

/**
 * Constituency parse tree node with tokens as the leaf nodes.
 */
export interface NlpSaftConstituencyNode {
  /**
   * An arbitrary number of children, ordered from left to right; empty for
   * preterminals. Represented via indices into Document.constituency_node.
   */
  child?: number[];
  /**
   * The label of the current node.
   */
  label?: string;
  /**
   * A phrase that contains information about the span and the (optional) head
   * token. For terminal nodes the head of the phrase holds the word.
   */
  phrase?: NlpSaftPhrase;
}

/**
 * A document contains the raw text contents of the document as well as an
 * analysis. The document can be split into tokens which can contain information
 * about POS tags and dependency relations. The document can also contain
 * entities and mentions of these entities in the document. Next available id:
 * 36
 */
export interface NlpSaftDocument {
  /**
   * Annotated phrases in the document that are not semantically well-defined
   * mentions of entities.
   */
  annotatedPhrase?: NlpSaftAnnotatedPhrase[];
  /**
   * Generic annotations.
   */
  annotations?: Proto2BridgeMessageSet;
  /**
   * Document author(s).
   */
  author?: string[];
  /**
   * Document's byline date, if available: this is the date that will be shown
   * in the snippets in web search results. It is stored as the number of
   * seconds since epoch. See segindexer/compositedoc.proto
   */
  bylineDate?: bigint;
  /**
   * Constituency parse tree nodes for the sentences in this document.
   */
  constituencyNode?: NlpSaftConstituencyNode[];
  /**
   * The root node of the constituency tree for each sentence. If non-empty,
   * the list of roots will be aligned with the sentences in the document. Note
   * that some sentences may not have been parsed for various reasons; these
   * sentences will be annotated with placeholder "stub parses". For details,
   * see //nlp/saft/components/constituents/util/stub-parse.h.
   */
  constituencyRoot?: number[];
  /**
   * Age of the content of the document. For details, see:
   * quality/historical/shingle/signals/contentage.proto The format has been
   * translated to a canonical timestamp (seconds since epoch).
   */
  contentage?: bigint;
  /**
   * Stores minimum of first time google successfully crawled a document, or
   * indexed the document with contents (i.e, not roboted). It is stored as the
   * number of seconds since epoch. See
   * quality/historical/signals/firstseen/firstseen.proto
   */
  contentFirstseen?: bigint;
  /**
   * Optional document content_type (from webutil/http/content-type.proto).
   * Used for setting the content_type when converting the SAFT Document to a
   * CompositeDoc. Will be inferred if not given here.
   */
  contentType?: number;
  /**
   * Document anchor date in YYYYMMDDhhmmss format.
   */
  date?: string;
  /**
   * Identifier for document.
   */
  docid?: string;
  /**
   * Entities in the document.
   */
  entity?: NlpSaftEntity[];
  /**
   * Entity labels used in this document. This field is used to define labels
   * for the Entity::entity_type_probability field, which contains corresponding
   * probabilities. WARNING: This field is deprecated.
   * go/saft-replace-deprecated-entity-type
   */
  entityLabel?: string[];
  /**
   * Focus entity. For lexicon articles, like Wikipedia pages, a document is
   * often about a certain entity. This is the local entity id of the focus
   * entity for the document.
   */
  focusEntity?: number;
  /**
   * Flag for indicating that the document is a gold-standard document. This
   * can be used for putting additional weight on human-labeled documents in
   * contrast to automatically labeled annotations.
   */
  golden?: boolean;
  /**
   * HTTP header for document. If the HTTP headers field is set it should be
   * the complete header including the HTTP status line and the trailing cr/nl.
   * HTTP headers are not required to be valid UTF-8. Per the HTTP/1.1 Syntax
   * (RFC7230) standard, non-ASCII octets should be treated as opaque data.
   */
  httpHeaders?: Uint8Array;
  /**
   * The hyperlinks in the document. Multiple hyperlinks are sorted in
   * left-to-right order.
   */
  hyperlink?: NlpSaftHyperlink[];
  /**
   * Generic labeled spans (produced by the span labeling framework,
   * go/saft-span-labeling). The map key identifies spans of the same type. By
   * convention, it should be of the form "team_name/span_type_name".
   */
  labeledSpans?: {
    [key: string]: NlpSaftLabeledSpans
  };
  /**
   * Document language (default is English). This field's value maps cleanly to
   * the i18n.languages.Language proto enum (i18n::languages::Language in C++).
   */
  language?: number;
  /**
   * Last significant update of the page content, in the same format as the
   * contentage field, and also derived from ContentAge.last_significant_update
   * in quality/historical/shingle/signals/contentage.proto.
   */
  lastSignificantUpdate?: bigint;
  /**
   * Measures in the documents. This covers both time expressions as well as
   * physical quantities.
   */
  measure?: NlpSaftMeasure[];
  /**
   * True if this document contains privacy sensitive data. When the document
   * is transferred in RPC calls the RPC should use SSL_PRIVACY_AND_INTEGRITY
   * security level.
   */
  privacySensitive?: boolean;
  /**
   * Relations between entities in the document.
   */
  relation?: NlpSaftRelation[];
  /**
   * True if some RPC which touched this document had an error.
   */
  rpcError?: boolean;
  /**
   * The semantic nodes for the document represent arbitrary types of
   * higher-level abstractions beyond entity mention coreference and binary
   * relations between entities. These may include: n-ary relations, semantic
   * frames or events. The semantic nodes for a document are the nodes in a
   * directed acyclic graph, with an adjacency list representation.
   */
  semanticNode?: NlpSaftSemanticNode[];
  /**
   * Sub-sections for document for dividing a document into volumes, parts,
   * chapters, sections, etc.
   */
  subsection?: NlpSaftDocument[];
  /**
   * Document's syntactic date (e.g. date explicitly mentioned in the URL of
   * the document or in the document title). It is stored as the number of
   * seconds since epoch. See
   * quality/timebased/syntacticdate/proto/syntactic-date.proto
   */
  syntacticDate?: bigint;
  /**
   * Raw text contents of document. (In docjoin attachments from the SAFT
   * goldmine annotator this field will be empty.)
   */
  text?: string;
  /**
   * Optional document title.
   */
  title?: string;
  /**
   * Tokenization of the document.
   */
  token?: NlpSaftToken[];
  topic?: NlpSaftDocumentTopic[];
  /**
   * Whether to enable component tracing during analysis of this document. See
   * http://go/saft-tracing for details.
   */
  trace?: boolean;
  /**
   * Source document URL.
   */
  url?: string;
}

function serializeNlpSaftDocument(data: any): NlpSaftDocument {
  return {
    ...data,
    bylineDate: data["bylineDate"] !== undefined ? String(data["bylineDate"]) : undefined,
    contentage: data["contentage"] !== undefined ? String(data["contentage"]) : undefined,
    contentFirstseen: data["contentFirstseen"] !== undefined ? String(data["contentFirstseen"]) : undefined,
    entity: data["entity"] !== undefined ? data["entity"].map((item: any) => (serializeNlpSaftEntity(item))) : undefined,
    httpHeaders: data["httpHeaders"] !== undefined ? encodeBase64(data["httpHeaders"]) : undefined,
    lastSignificantUpdate: data["lastSignificantUpdate"] !== undefined ? String(data["lastSignificantUpdate"]) : undefined,
    subsection: data["subsection"] !== undefined ? data["subsection"].map((item: any) => (serializeNlpSaftDocument(item))) : undefined,
    syntacticDate: data["syntacticDate"] !== undefined ? String(data["syntacticDate"]) : undefined,
  };
}

function deserializeNlpSaftDocument(data: any): NlpSaftDocument {
  return {
    ...data,
    bylineDate: data["bylineDate"] !== undefined ? BigInt(data["bylineDate"]) : undefined,
    contentage: data["contentage"] !== undefined ? BigInt(data["contentage"]) : undefined,
    contentFirstseen: data["contentFirstseen"] !== undefined ? BigInt(data["contentFirstseen"]) : undefined,
    entity: data["entity"] !== undefined ? data["entity"].map((item: any) => (deserializeNlpSaftEntity(item))) : undefined,
    httpHeaders: data["httpHeaders"] !== undefined ? decodeBase64(data["httpHeaders"] as string) : undefined,
    lastSignificantUpdate: data["lastSignificantUpdate"] !== undefined ? BigInt(data["lastSignificantUpdate"]) : undefined,
    subsection: data["subsection"] !== undefined ? data["subsection"].map((item: any) => (deserializeNlpSaftDocument(item))) : undefined,
    syntacticDate: data["syntacticDate"] !== undefined ? BigInt(data["syntacticDate"]) : undefined,
  };
}

/**
 * Document topic(s).
 */
export interface NlpSaftDocumentTopic {
  /**
   * Topic name or identifier.
   */
  name?: string;
  /**
   * Topic score.
   */
  score?: number;
}

/**
 * Named entities in the document.
 */
export interface NlpSaftEntity {
  /**
   * Antecedent for entity. This is used to make coreference chains before the
   * mentions in the document are grouped by entity.
   */
  antecedent?: number;
  /**
   * Entity type (e.g. PER, ORG, LOC). WARNING: This field is deprecated.
   * go/saft-replace-deprecated-entity-type
   */
  entityType?: string;
  /**
   * Probability distribution over entity types. These values correspond to
   * Document.entity_label values: doc.entity[e].entity_type_probability[n] is
   * the probability that the correct label for doc.entity[e] is
   * doc.entity_label[n]. These probabilities sum to 1.0 (with possible rounding
   * error). WARNING: This field is deprecated.
   * go/saft-replace-deprecated-entity-type
   */
  entityTypeProbability?: number[];
  /**
   * Gender for entity.
   */
  gender?:  | "MASCULINE" | "FEMININE" | "NEUTER" | "PLURAL";
  /**
   * Application-specific information about this entity.
   */
  info?: Proto2BridgeMessageSet;
  /**
   * Mentions of the entity in the document.
   */
  mention?: NlpSaftMention[];
  /**
   * Representative entity name.
   */
  name?: string;
  /**
   * Profile for entity.
   */
  profile?: NlpSaftEntityProfile;
  /**
   * Referent information for discourse context entities that are not mentioned
   * in the document. These can be merged with mentioned entities during
   * analysis if they are deemed to be coreferent. Entities with referents
   * should not have any mentions if they do not corefer with anything. For
   * example, when adding context entities to an input document prior to SAFT
   * analysis, those entities should have a referent and no mentions.
   */
  referent?: NlpSaftReferent;
  /**
   * Representative mention, as an index into mention.
   */
  representativeMention?: number;
  /**
   * Score indicating the saliency (centrality) of this entity to the document.
   */
  salience?: number;
  /**
   * Entity types of the entity. These can include SAFT types (/saft/location,
   * /saft/art, /saft/other/living_thing, etc), collections types
   * (/collection/tv_personalities, /collection/statistical_regions, etc), and
   * more. This refers to the type of the entity itself: in "She is on TV",
   * "She" refers to a specific actor, with type "/collection/tv_personalities".
   * Cf. Mention.Type, which is the type of the referring mention.
   */
  type?: NlpSaftEntityType[];
}

function serializeNlpSaftEntity(data: any): NlpSaftEntity {
  return {
    ...data,
    mention: data["mention"] !== undefined ? data["mention"].map((item: any) => (serializeNlpSaftMention(item))) : undefined,
    profile: data["profile"] !== undefined ? serializeNlpSaftEntityProfile(data["profile"]) : undefined,
  };
}

function deserializeNlpSaftEntity(data: any): NlpSaftEntity {
  return {
    ...data,
    mention: data["mention"] !== undefined ? data["mention"].map((item: any) => (deserializeNlpSaftMention(item))) : undefined,
    profile: data["profile"] !== undefined ? deserializeNlpSaftEntityProfile(data["profile"]) : undefined,
  };
}

/**
 * An entity profile contains a summary of the information about a single
 * unique entity. Next available index: 46.
 */
export interface NlpSaftEntityProfile {
  alternate?: NlpSaftEntityProfileAlternate[];
  /**
   * Generic annotations.
   */
  annotations?: Proto2BridgeMessageSet;
  /**
   * List of attributes for the entity.
   */
  attribute?: NlpSaftEntityProfileAttribute[];
  /**
   * Canonical entity name.
   */
  canonicalName?: string;
  collectionScoreType?:  | "COLLECTION_GIVEN_ENTITY" | "ENTITY_GIVEN_COLLECTION";
  /**
   * Disambiguation phrase. The combination of entity name and disambiguation
   * phrase should be unique within the corpus.
   */
  disambiguation?: string;
  /**
   * Entity embeding vector, representing the entity in a dense low-dimensional
   * embedding space.
   */
  embedding?: number[];
  /**
   * Profile frame in binary SLING encoding.
   */
  frame?: Uint8Array;
  /**
   * Gender of the entity.
   */
  gender?:  | "MASCULINE" | "FEMININE" | "NEUTER" | "PLURAL";
  /**
   * Unique global id for entity.
   */
  id?: bigint;
  /**
   * External identifiers for entity.
   */
  identifier?: NlpSaftIdentifier[];
  keyword?: NlpSaftEntityProfileKeyword[];
  /**
   * Freebase MID for entity. This field should be the same as FREEBASE_MID
   * identifier for the entity profile.
   */
  mid?: string;
  /**
   * Representative name for entity.
   */
  name?: string;
  /**
   * Language for the name and disambiguation.
   */
  nameLanguage?: number;
  /**
   * Nature of the entity.
   */
  nature?:  | "UNKNOWN" | "CONCEPT" | "THING" | "ESTABLISHMENT" | "INDIVIDUAL" | "GIVEN_NAME" | "FAMILY_NAME";
  reference?: NlpSaftEntityProfileReference[];
  related?: NlpSaftEntityProfileRelated[];
  /**
   * Entity type.
   */
  type?: string;
}

function serializeNlpSaftEntityProfile(data: any): NlpSaftEntityProfile {
  return {
    ...data,
    alternate: data["alternate"] !== undefined ? data["alternate"].map((item: any) => (serializeNlpSaftEntityProfileAlternate(item))) : undefined,
    attribute: data["attribute"] !== undefined ? data["attribute"].map((item: any) => (serializeNlpSaftEntityProfileAttribute(item))) : undefined,
    frame: data["frame"] !== undefined ? encodeBase64(data["frame"]) : undefined,
    id: data["id"] !== undefined ? String(data["id"]) : undefined,
    related: data["related"] !== undefined ? data["related"].map((item: any) => (serializeNlpSaftEntityProfileRelated(item))) : undefined,
  };
}

function deserializeNlpSaftEntityProfile(data: any): NlpSaftEntityProfile {
  return {
    ...data,
    alternate: data["alternate"] !== undefined ? data["alternate"].map((item: any) => (deserializeNlpSaftEntityProfileAlternate(item))) : undefined,
    attribute: data["attribute"] !== undefined ? data["attribute"].map((item: any) => (deserializeNlpSaftEntityProfileAttribute(item))) : undefined,
    frame: data["frame"] !== undefined ? decodeBase64(data["frame"] as string) : undefined,
    id: data["id"] !== undefined ? BigInt(data["id"]) : undefined,
    related: data["related"] !== undefined ? data["related"].map((item: any) => (deserializeNlpSaftEntityProfileRelated(item))) : undefined,
  };
}

/**
 * Alternative names for entity.
 */
export interface NlpSaftEntityProfileAlternate {
  count?: number;
  /**
   * see nlp/saft/resolution/name-form.h for values
   */
  form?: number;
  /**
   * frame in SLING encoding
   */
  frame?: Uint8Array;
  language?: number;
  name?: string;
  /**
   * (1 << SRC_DEFAULT)
   */
  sources?: number;
}

function serializeNlpSaftEntityProfileAlternate(data: any): NlpSaftEntityProfileAlternate {
  return {
    ...data,
    frame: data["frame"] !== undefined ? encodeBase64(data["frame"]) : undefined,
  };
}

function deserializeNlpSaftEntityProfileAlternate(data: any): NlpSaftEntityProfileAlternate {
  return {
    ...data,
    frame: data["frame"] !== undefined ? decodeBase64(data["frame"] as string) : undefined,
  };
}

export interface NlpSaftEntityProfileAttribute {
  /**
   * Boolean attribute value, e.g. for IsDeceased.
   */
  boolValue?: boolean;
  /**
   * Double attribute value, e.g. for height/weight.
   */
  floatValue?: number;
  /**
   * Integer attribute value, e.g. IntId("April").
   */
  intValue?: bigint;
  /**
   * Language, in case the attribute value is a string.
   */
  language?: number;
  /**
   * String name of the type of attribute, e.g. /birth/date
   */
  type?: string;
  /**
   * Any id of the type of the attribute, e.g. IntId(/birth/date)
   */
  typeId?: number;
  /**
   * String attribute value, e.g. "April 2010" or "3,235,121".
   */
  value?: string;
  /**
   * The type of the value.
   */
  valueType?:  | "ATTRIBUTE_TYPE_STRING" | "ATTRIBUTE_TYPE_INT" | "ATTRIBUTE_TYPE_FLOAT" | "ATTRIBUTE_TYPE_BOOL" | "ATTRIBUTE_TYPE_DATETIME";
}

function serializeNlpSaftEntityProfileAttribute(data: any): NlpSaftEntityProfileAttribute {
  return {
    ...data,
    intValue: data["intValue"] !== undefined ? String(data["intValue"]) : undefined,
  };
}

function deserializeNlpSaftEntityProfileAttribute(data: any): NlpSaftEntityProfileAttribute {
  return {
    ...data,
    intValue: data["intValue"] !== undefined ? BigInt(data["intValue"]) : undefined,
  };
}

/**
 * Keywords and key phrases for entity.
 */
export interface NlpSaftEntityProfileKeyword {
  count?: number;
  language?: number;
  /**
   * Score associated with the keyword. For fine-grained types this is a
   * probability.
   */
  score?: number;
  term?: string;
  type?:  | "CONTEXT" | "MENTION" | "HEADLINE" | "TOPIC" | "TEMPORAL" | "FREEBASE_TYPE" | "FREEBASE_NOTABLE_TYPE" | "FREEBASE_NOTABLE_FOR" | "FINE_TYPE" | "KG_COLLECTION" | "HYPERNYM";
}

/**
 * References to entity.
 */
export interface NlpSaftEntityProfileReference {
  docid?: string;
  entity?: number;
}

/**
 * Related entities.
 */
export interface NlpSaftEntityProfileRelated {
  /**
   * Number of occurrences.
   */
  count?: number;
  /**
   * Inverse relations can be marked in a bidirectional graph.
   */
  inverse?: boolean;
  /**
   * Optional integer id for the relation.
   */
  relationId?: number;
  /**
   * Optional external identifier for the relation.
   */
  relationIdentifier?: NlpSaftIdentifier;
  /**
   * Score for related entity, i.e. p(e->r | e).
   */
  score?: number;
  /**
   * Profile id of related entity.
   */
  targetId?: bigint;
  /**
   * Optional external identifier for the target entity.
   */
  targetIdentifier?: NlpSaftIdentifier;
  /**
   * Name of related entity.
   */
  targetName?: string;
  /**
   * Type of relation.
   */
  type?: string;
}

function serializeNlpSaftEntityProfileRelated(data: any): NlpSaftEntityProfileRelated {
  return {
    ...data,
    targetId: data["targetId"] !== undefined ? String(data["targetId"]) : undefined,
  };
}

function deserializeNlpSaftEntityProfileRelated(data: any): NlpSaftEntityProfileRelated {
  return {
    ...data,
    targetId: data["targetId"] !== undefined ? BigInt(data["targetId"]) : undefined,
  };
}

/**
 * A generic type description for an entity.
 */
export interface NlpSaftEntityType {
  /**
   * This field can be used to specify if the entity type has been annotated or
   * predicted from a specific mention of the entity. However, the entity type
   * does still apply to the entity as a whole, and not just a specific mention.
   */
  basedOnMention?: number;
  /**
   * A domain name for the set that this particular type belongs to.
   */
  domain?:  | "UNSPECIFIED" | "SAFT" | "SAFT_FINE" | "SAFT_FINE_MENTION" | "COLLECTIONS" | "FREEBASE" | "FIGER" | "ISA";
  /**
   * Application-specific information about this entity type.
   */
  info?: Proto2BridgeMessageSet;
  /**
   * The type name, like "/saft/person". See README.entity-types for the
   * inventory of SAFT type tags.
   */
  name?: string;
  /**
   * A score for this type.
   */
  score?: number;
}

/**
 * A link on an HTML page.
 */
export interface NlpSaftHyperlink {
  /**
   * Clean anchor text (no HTML markup).
   */
  anchorText?: string;
  /**
   * note: inclusive
   */
  byteEnd?: number;
  /**
   * begin/end options are for goldmine AnnotationsFinder to locate the offsets
   * of saft tokens. Start is inclusive by default and end is marked. The
   * indices of the first and last byte covered by the hyperlink.
   */
  byteStart?: number;
  /**
   * The indices of the first and last token covered by the hyperlink.
   */
  phrase?: NlpSaftPhrase;
  /**
   * (Absolute) URL that the links to.
   */
  url?: string;
}

/**
 * External identifier. An external identifier is a persistent identifier for
 * an object within a domain.
 */
export interface NlpSaftIdentifier {
  /**
   * Domain for the identifier.
   */
  domain?:  | "WIKIPEDIA_ARTICLE_NAME" | "WEBREFERENCES_ID" | "FREEBASE_MID" | "WIKIPEDIA_ARTICLE_ID" | "CANONICAL_URL" | "FREEBASE_TOPIC" | "FREEBASE_MID_CHAIN" | "FREEBASE_ID" | "OYSTER_FEATURE_ID" | "WORDNET_SENSE_KEY" | "EXACT_STRING_MATCH" | "GOOGLE_PLAY_ID" | "GOOGLE_PLAY_DEVELOPER" | "GOOGLE_PLAY_TITLE" | "OXFORD_ID" | "NOUN_COMPOUND";
  /**
   * Identifier within domain.
   */
  id?: string;
}

/**
 * A generic span, possibly with an associated label. The span may be defined
 * by either byte-level or token-level boundaries.
 */
export interface NlpSaftLabeledSpan {
  /**
   * note: inclusive
   */
  byteEnd?: number;
  /**
   * The indices of the first and last byte covered by the span.
   */
  byteStart?: number;
  /**
   * The label associated with the span.
   */
  label?: string;
  /**
   * Optionally stores alternative labels with associated scores for the span.
   */
  labelScores?: {
    [key: string]: number
  };
  /**
   * A score associated with the span.
   */
  score?: number;
  /**
   * note: inclusive
   */
  tokenEnd?: number;
  /**
   * The indices of the first and last token covered by the span.
   */
  tokenStart?: number;
}

/**
 * A list of labeled spans of the same type.
 */
export interface NlpSaftLabeledSpans {
  labeledSpan?: NlpSaftLabeledSpan[];
}

/**
 * Measures in the documents. This covers both time expressions as well as
 * physical quantities.
 */
export interface NlpSaftMeasure {
  /**
   * Canonical value for measurement.
   */
  canonical?: number;
  /**
   * Granularity for measurement.
   */
  granularity?: number;
  /**
   * Application-specific information about this measure.
   */
  info?: Proto2BridgeMessageSet;
  /**
   * Phrase containing the measure.
   */
  phrase?: NlpSaftPhrase;
  type?:  | "NUMBER" | "PERCENT" | "ORDINAL" | "DATE" | "TIME" | "PERIOD" | "CURRENCY" | "LENGTH" | "AREA" | "VOLUME" | "MASS" | "TEMPERATURE" | "ANGLE" | "BRIGHTNESS" | "CHARGE" | "DATA" | "DATA_RATE" | "DURATION" | "ENERGY" | "FREQUENCY" | "FUEL_EFFICIENCY" | "POWER" | "PRESSURE" | "SPEED" | "VOLTAGE" | "RESISTANCE" | "FORCE";
  unit?: string;
  /**
   * Measurement value and unit.
   */
  value?: string;
}

/**
 * Mentions of the entity in the document.
 */
export interface NlpSaftMention {
  /**
   * Estimate of the confidence that this mention is in the correct cluster.
   * Zero means this mention is probably in the wrong cluster, 1 means this
   * mention is probably in the correct cluster. See
   * nlp/saft/components/coreference/coreference-confidence.h for details about
   * what "correct cluster" might mean.
   */
  confidence?: number;
  /**
   * Application-specific information about this mention.
   */
  info?: Proto2BridgeMessageSet;
  kind?:  | "UNSPECIFIED_KIND" | "REFERENTIAL" | "ATTRIBUTIVE" | "MODIFIER";
  nestingRelation?:  | "UNSPECIFIED_RELATION" | "ALIAS" | "NESTED_MODIFIER" | "EPONYM" | "CONJUNCTION" | "IN_CREATIVE_WORK" | "SPECIFIED_HEAD";
  /**
   * Phrase for the mention.
   */
  phrase?: NlpSaftPhrase;
  /**
   * Mention-level resolution. This is used for encoding the meaning of the
   * mention rather than the entity. For example, definite references and
   * appositions are resolved to the mid for the concept rather than the entity.
   */
  resolution?: NlpSaftMentionResolution;
  role?:  | "UNSPECIFIED" | "CONJUNCTION_ITEM";
  type?:  | "NAM" | "NOM" | "PRE" | "PRO" | "CMC" | "NRP" | "VRB" | "IMP";
}

function serializeNlpSaftMention(data: any): NlpSaftMention {
  return {
    ...data,
    resolution: data["resolution"] !== undefined ? serializeNlpSaftMentionResolution(data["resolution"]) : undefined,
  };
}

function deserializeNlpSaftMention(data: any): NlpSaftMention {
  return {
    ...data,
    resolution: data["resolution"] !== undefined ? deserializeNlpSaftMentionResolution(data["resolution"]) : undefined,
  };
}

/**
 * Mention resolution for encoding the concept id (e.g. mid) for a mention.
 */
export interface NlpSaftMentionResolution {
  /**
   * Profile for mention information.
   */
  profile?: NlpSaftEntityProfile;
  type?:  | "MATCH" | "BROADER_MATCH";
}

function serializeNlpSaftMentionResolution(data: any): NlpSaftMentionResolution {
  return {
    ...data,
    profile: data["profile"] !== undefined ? serializeNlpSaftEntityProfile(data["profile"]) : undefined,
  };
}

function deserializeNlpSaftMentionResolution(data: any): NlpSaftMentionResolution {
  return {
    ...data,
    profile: data["profile"] !== undefined ? deserializeNlpSaftEntityProfile(data["profile"]) : undefined,
  };
}

/**
 * Message that stores information about the morphology of a token.
 */
export interface NlpSaftMorphology {
  /**
   * A list of morphology attribute-value pairs.
   */
  attrValue?:  | "OTHER" | "ATTR_ANIMACY" | "UNSP_ANIMACY" | "ANIMATE" | "INANIMATE" | "IRRATIONAL" | "RATIONAL" | "PERSONAL" | "ATTR_ASPECT" | "UNSP_ASPECT" | "PERFECT" | "IMPERFECT" | "PROGRESSIVE" | "ATTR_CASE" | "UNSP_CASE" | "NOMINATIVE" | "ACCUSATIVE" | "DATIVE" | "GENITIVE" | "PREPOSITIONAL" | "INSTRUMENTAL" | "VOCATIVE" | "ADVERBIAL" | "COMPLEMENTIVE" | "LOCATIVE" | "OBLIQUE" | "PARTITIVE" | "REFLEXIVE_CASE" | "RELATIVE_CASE" | "DIRECT_CASE" | "ERGATIVE" | "ATTR_DEFINITENESS" | "UNSP_DEFINITENESS" | "DEFINITE" | "INDEFINITE" | "ATTR_DEGREE" | "UNSP_DEGREE" | "COMPARATIVE" | "SUPERLATIVE" | "POSITIVE" | "ABSOLUTE_DEGREE" | "RELATIVE_DEGREE" | "ATTR_FORM" | "UNSP_FORM" | "ADNOMIAL" | "AUXILIARY" | "COMPLEMENTIZER" | "FINAL_ENDING" | "GERUND" | "IRREALIS" | "LONG_FORM" | "ORDER_FORM" | "REALIS" | "SHORT_FORM" | "SPECIFIC_FORM" | "ATTR_GENDER_AGR" | "UNSP_GENDER_AGR" | "FEMININE_AGR" | "MASCULINE_AGR" | "NEUTER_AGR" | "ATTR_GENDER" | "UNSP_GENDER" | "FEMININE" | "MASCULINE" | "NEUTER" | "PLURALE_TANTUM" | "COMMON" | "ATTR_MOOD" | "UNSP_MOOD" | "CONDITIONAL_MOOD" | "IMPERATIVE" | "INDICATIVE" | "INTERROGATIVE" | "JUSSIVE" | "SUBJUNCTIVE" | "SUBJUNCTIVE1" | "SUBJUNCTIVE2" | "OPTATIVE" | "ATTR_NUMBER_AGR" | "UNSP_NUMBER_AGR" | "SINGULAR_AGR" | "PLURAL_AGR" | "ATTR_NUMBER" | "UNSP_NUMBER" | "SINGULAR" | "PLURAL" | "DUAL" | "ATTR_PERSON" | "UNSP_PERSON" | "FIRST" | "SECOND" | "THIRD" | "REFLEXIVE_PERSON" | "ATTR_PROPER" | "UNSP_PROPER" | "NOT_PROPER" | "PROPER" | "ATTR_RECIPROCITY" | "UNSP_RECIPROCITY" | "NON_RECIPROCAL" | "RECIPROCAL" | "ATTR_TENSE" | "UNSP_TENSE" | "CONDITIONAL_TENSE" | "FUTURE" | "PAST" | "PRESENT" | "PLUPERFECT" | "IMPERFECT_TENSE" | "ATTR_VOICE" | "UNSP_VOICE" | "ACTIVE" | "CAUSATIVE" | "PASSIVE" | "ATTR_GENDER_ANTECEDENT" | "UNSP_GENDER_ANTECEDENT" | "FEMININE_ANTECEDENT" | "MASCULINE_ANTECEDENT" | "NEUTER_ANTECEDENT" | "ATTR_NUMBER_ANTECEDENT" | "UNSP_NUMBER_ANTECEDENT" | "SINGULAR_ANTECEDENT" | "PLURAL_ANTECEDENT" | "ATTR_HONORIFIC" | "UNSP_HONORIFIC" | "HONORIFIC" | "ATTR_FORMALITY" | "UNSP_FORMALITY" | "FORMAL" | "INFORMAL" | "ATTR_INFLECTION_TYPE" | "UNSP_INFLECTION_TYPE" | "WEAK_INFLECTION" | "STRONG_INFLECTION" | "MIXED_INFLECTION"[];
}

/**
 * A document phrase marks a range of tokens in a document as a phrase. The
 * indices are token positions in the document.
 */
export interface NlpSaftPhrase {
  end?: number;
  facet?:  | "EXPLICIT" | "SUBJ" | "DOBJ";
  /**
   * The head token in the phrase is the id of the top-most token within the
   * phrase. It either has an arc from outside the phrase going to it, or it is
   * a root token of the sentence. A value of -1 indicates that the head has not
   * yet been computed for the phrase (not the same semantics as the head of a
   * token!). Note that even when it is uniquely defined, there is no guarantee
   * that the head is set for entities and measurements within a document: you
   * may need to explicitly compute it.
   */
  head?: number;
  /**
   * First and last token in the phrase. The phrase goes from start to end
   * (inclusive).
   */
  start?: number;
}

/**
 * A referent contains information about what a discourse context entity is
 * referring to. It acts like a canonical mention of the entity.
 */
export interface NlpSaftReferent {
  /**
   * Distance of this referent from the markables in the Document. Smaller
   * values imply that the referent is more accessible to be an antecedent for a
   * markable in the Document. The expectation is that this field would increase
   * with every new Document in which this referent is not mentioned.
   */
  distance?: number;
  explicitness?:  | "NAMED" | "DEFINITE" | "INDEFINITE";
  /**
   * Application-specific information about this referent.
   */
  info?: Proto2BridgeMessageSet;
  /**
   * Entity name phrase. The phrase indices are relative to the token array
   * above. The phrase should normally cover all the tokens in the name and the
   * head must be set to be the head token of the name.
   */
  phrase?: NlpSaftPhrase;
  /**
   * Prominence score for referent. This is roughly equivalent to the number of
   * previous mentions of the referent.
   */
  prominence?: number;
  role?:  | "CONTEXT" | "NARRATOR" | "ADDRESSEE" | "SUBJECT";
  /**
   * Tokenized representation for the canonical name of the referent entity.
   */
  token?: NlpSaftToken[];
}

/**
 * Relations between entities in the document. A relation is between two
 * different entities in the document. A relation can have a number of mentions
 * in the document. Next available id: 11
 */
export interface NlpSaftRelation {
  /**
   * External identifier for relation.
   */
  identifier?: NlpSaftIdentifier;
  /**
   * Application-specific information about this relation.
   */
  info?: Proto2BridgeMessageSet;
  kind?:  | "ENTITY" | "ATTRIBUTE";
  /**
   * Mentions of the relation in the document.
   */
  mention?: NlpSaftRelationMention[];
  /**
   * Relation score.
   */
  score?: number;
  /**
   * Source and target entity indices. These are indices into the entity array
   * in the document. If this is an attribute relation the target is the index
   * of a measure in the document.
   */
  source?: number;
  target?: number;
  /**
   * Relation type.
   */
  type?: string;
  /**
   * Relation type id.
   */
  typeId?: number;
}

/**
 * Mentions of relations in the document. A relation mention is between a
 * mention of the source entity and a mention of the target entity.
 */
export interface NlpSaftRelationMention {
  /**
   * Application-specific information about this relation mention.
   */
  info?: Proto2BridgeMessageSet;
  /**
   * Phrase in the document that indicates the relation mention.
   */
  phrase?: NlpSaftPhrase;
  /**
   * Source and target mention indices. These are indices into the mention
   * arrays for their respective entities. The target is not used for
   * attributes.
   */
  source?: number;
  /**
   * The info of the source models or systems of the relation mention.
   */
  sourceInfo?: string[];
  target?: number;
}

/**
 * Semantic node for annotating semantic constructions in documents. A set of
 * SemanticNode instances represents a directed acyclic graph with an adjacency
 * list representation. Each node can optionally be connected to some existing
 * type system, such as PropBank. Each node can optionally be connected to one
 * or more concrete elements in a SAFT document, specifically, an entity
 * mention, a measure and/or a token span (Phrase). Next available id: 23
 */
export interface NlpSaftSemanticNode {
  /**
   * The arcs from this node. For example, if this node is the root of a
   * subgraph representing a predicate-argument structure, this node will
   * typically refer to the predicate, and there will typically be one arc per
   * argument.
   */
  arc?: NlpSaftSemanticNodeArc[];
  /**
   * Confidence score for the annotation.
   */
  confidence?: number;
  /**
   * Human-readable description of the information in the subgraph represented
   * by this node. This field is only meant for display purposes.
   */
  description?: string;
  /**
   * The entity and mention fields specify a unique entity mention referred to
   * by this semantic node.
   */
  entity?: number;
  /**
   * Indicates whether the semantic node is not explicit (grounded) in the text
   * (e.g. pro-drop for a text author or an implicit predicate node for
   * interpreting a compound noun), rather than any explicit phrase or text
   * inside the document.
   */
  implicit?: boolean;
  /**
   * Application-specific information about this node.
   */
  info?: Proto2BridgeMessageSet;
  /**
   * Encodes the kind of this node and, possibly, the entire subgraph rooted at
   * this node. For example, if this node represents a predicate-argument
   * structure in PropBank, then this node's kind will be PROPBANK, its phrase
   * field will be set to correspond to the span of tokens corresponding to the
   * predicate (such as a verb) and it will have one arc per argument. If the
   * kind is MONOTONIC this node corresponds to a semantic graph node, and arcs
   * correspond to semantic graph edges outgoing from the node. If the kind
   * field is not set, then this node is not directly connected to any type
   * system. In such a case, this node may still optionally have a concrete
   * "payload" in the form of references to an entity mention, measure or span
   * of tokens (Phrase) in a SAFT document. The values or existence of the kind
   * field need not be identical in any subgraph. For example, even if this
   * node's kind field is not set, it may still be the destination node of an
   * arc from some other node whose kind field is set.
   */
  kind?:  | "PROPBANK" | "MONOTONIC" | "FRAMENET" | "OPEN_RELATION" | "PATTERN_CLUSTERS" | "OED_WORD_SENSE" | "EVENT" | "NAME" | "TIME_EXPRESSION" | "MOLECULE" | "WORDNET" | "HYPERNYM" | "DIALOGUE" | "ANAPHOR" | "SENSE_ANTECEDENT" | "NOUN_COMPOUND" | "ISTA";
  /**
   * The index of the measure referred to by this semantic node.
   */
  measure?: number;
  mention?: number;
  /**
   * Phrase (span of text) for this node. This field does not need to be set,
   * but if it is, this node has a textual "payload" corresponding to the
   * specified token span. For example, if this node is the root of a subgraph
   * corresponding to a predicate-argument structure, then the phrase field will
   * be set to be the span of tokens corresponding to the predicate (e.g., a
   * verb).
   */
  phrase?: NlpSaftPhrase;
  /**
   * Arbitrary type string for this semantic node, or for the subgraph rooted
   * at this node. This type string might come from an external resource, type
   * system or ontology that contains a predefined set of types.
   */
  type?: string;
  /**
   * Arbitrary value string for this semantic node.
   */
  value?: string;
}

/**
 * An arc contained by a source node pointing to a destination node in a
 * directed acyclic graph.
 */
export interface NlpSaftSemanticNodeArc {
  /**
   * Human-readable description of this arc's type (for display purposes).
   */
  description?: string;
  /**
   * Indicates the arc is for an implicit semantic relation between nodes, for
   * example one that does not correspond to a grammatical relation in the text.
   */
  implicit?: boolean;
  /**
   * Application-specific information about this arc.
   */
  info?: Proto2BridgeMessageSet;
  /**
   * Index of the semantic node pointed to by this arc.
   */
  semanticNode?: number;
  /**
   * Arc type (akin to an edge label, or semantic operator).
   */
  type?: string;
}

/**
 * A document token marks a span of bytes in the document text as a token or
 * word. Next available index: 16.
 */
export interface NlpSaftToken {
  breakLevel?:  | "NO_BREAK" | "SPACE_BREAK" | "LINE_BREAK" | "SENTENCE_BREAK" | "PARAGRAPH_BREAK" | "SECTION_BREAK" | "CHAPTER_BREAK";
  /**
   * Whether the break skipped over non-tag text (excluding script/style).
   */
  breakSkippedText?: boolean;
  /**
   * Coarse-grained word category for token. See README.categories for category
   * inventory.
   */
  category?: string;
  end?: number;
  /**
   * Head of this token in the dependency tree: the id of the token which has
   * an arc going to this one. If it is the root token of a sentence, then it is
   * set to -1.
   */
  head?: number;
  /**
   * Annotation for this token.
   */
  info?: Proto2BridgeMessageSet;
  /**
   * Label for dependency relation between this token and its head. See
   * README.labels for label inventory.
   */
  label?: string;
  /**
   * Word lemma. This is only filled if the lemma is different from the word
   * form.
   */
  lemma?: string;
  /**
   * Morphology information.
   */
  morph?: NlpSaftMorphology;
  /**
   * A string representation (typically four letters, sometimes longer) of the
   * token's Unicode script code, based on BCP 47/CLDR, capitalized according to
   * ISO 15924. See i18n/identifiers/scriptcode.h for details.
   */
  scriptCode?: string;
  /**
   * [start, end] describe the inclusive byte range of the UTF-8 encoded token
   * in document.text. End gives the index of the last byte, which may be a
   * UTF-8 continuation byte, and the length in bytes is end - start + 1.
   * begin/end options are for goldmine AnnotationsFinder to locate the offsets
   * of saft tokens. Start is inclusive by default and end is marked.
   */
  start?: number;
  /**
   * Part-of-speech tag for token. See README.tags for tag inventory.
   */
  tag?: string;
  /**
   * Confidence score for the tag prediction -- should be interpreted as a
   * probability estimate that the tag is correct.
   */
  tagConfidence?: number;
  textProperties?: number;
  /**
   * Token word form. This may not be identical to the original. For example,
   * in goldmine annotation we do UTF-8 normalization and punctuation
   * normalization. The punctuation normalization includes inferring the
   * directionality of straight doublequotes -- that is, we map " to open quote
   * (``) or close quote (''), and sometimes we get it wrong. SAFT processing in
   * other contexts (such as queries in qrewrite) involves different
   * normalizations.
   */
  word?: string;
}

/**
 * A copy of the text of an article along with references to internal figures
 * and external citations, datasets, etc. Next available ID: 19
 */
export interface NlpSciencelitArticleData {
  /**
   * All the text in this article, separated into Sections and Paragraphs. See
   * nlp_sciencelit.ScaleSetExtensions for the extensions to ScaleSet used.
   */
  analyzedText?: NlxDataSchemaScaleSet;
  articleId?: NlpSciencelitArticleId[];
  /**
   * All references from this article (Bibliography).
   */
  citation?: NlpSciencelitCitationData[];
  /**
   * The result of selecting the earliest date from various metadata (PMC,
   * PubMed Metadata, scholar citations).
   */
  earliestPubDate?: string;
  metadata?: NlpSciencelitArticleMetadata;
  nonAbstractWordCount?: bigint;
  /**
   * Path of the source document from which this was parsed.
   */
  parsedFrom?: string;
  /**
   * All dates from the PMC article metadata Year/Mon/Day.
   */
  pubDate?: NlpSciencelitPubDate[];
  /**
   * All figure captions within this article.
   */
  referencedBlock?: NlpSciencelitReferencedBlock[];
  /**
   * Citation for this article.
   */
  scholarCitation?: ScienceCitation;
  /**
   * DocJoins with full text article.
   */
  scholarDocument?: CompositeDoc[];
  /**
   * May also add the Scholar index signal information:
   */
  scholarSignal?: ScienceIndexSignal;
  /**
   * Source of this article data (e.g., PubMed, scholar index, other source.).
   */
  source?: string;
  title?: string;
  /**
   * Number of words in the entire article and everywhere outside of abstract
   * sections.
   */
  wordCount?: bigint;
}

function serializeNlpSciencelitArticleData(data: any): NlpSciencelitArticleData {
  return {
    ...data,
    citation: data["citation"] !== undefined ? data["citation"].map((item: any) => (serializeNlpSciencelitCitationData(item))) : undefined,
    metadata: data["metadata"] !== undefined ? serializeNlpSciencelitArticleMetadata(data["metadata"]) : undefined,
    nonAbstractWordCount: data["nonAbstractWordCount"] !== undefined ? String(data["nonAbstractWordCount"]) : undefined,
    scholarCitation: data["scholarCitation"] !== undefined ? serializeScienceCitation(data["scholarCitation"]) : undefined,
    scholarDocument: data["scholarDocument"] !== undefined ? data["scholarDocument"].map((item: any) => (serializeCompositeDoc(item))) : undefined,
    scholarSignal: data["scholarSignal"] !== undefined ? serializeScienceIndexSignal(data["scholarSignal"]) : undefined,
    wordCount: data["wordCount"] !== undefined ? String(data["wordCount"]) : undefined,
  };
}

function deserializeNlpSciencelitArticleData(data: any): NlpSciencelitArticleData {
  return {
    ...data,
    citation: data["citation"] !== undefined ? data["citation"].map((item: any) => (deserializeNlpSciencelitCitationData(item))) : undefined,
    metadata: data["metadata"] !== undefined ? deserializeNlpSciencelitArticleMetadata(data["metadata"]) : undefined,
    nonAbstractWordCount: data["nonAbstractWordCount"] !== undefined ? BigInt(data["nonAbstractWordCount"]) : undefined,
    scholarCitation: data["scholarCitation"] !== undefined ? deserializeScienceCitation(data["scholarCitation"]) : undefined,
    scholarDocument: data["scholarDocument"] !== undefined ? data["scholarDocument"].map((item: any) => (deserializeCompositeDoc(item))) : undefined,
    scholarSignal: data["scholarSignal"] !== undefined ? deserializeScienceIndexSignal(data["scholarSignal"]) : undefined,
    wordCount: data["wordCount"] !== undefined ? BigInt(data["wordCount"]) : undefined,
  };
}

/**
 * Article IDs associated with an article (e.g., PMID, DOI, PMC).
 */
export interface NlpSciencelitArticleId {
  id?: string;
  idType?: string;
}

/**
 * Next available ID: 20.
 */
export interface NlpSciencelitArticleMetadata {
  /**
   * Abstract of article from metadata.
   */
  abstract?: NlpSciencelitTokenizedText;
  articleId?: NlpSciencelitArticleId[];
  /**
   * Author of article.
   */
  author?: NlpSciencelitAuthor[];
  /**
   * Datasets referenced from this article.
   */
  dataset?: NlpSciencelitDataset[];
  /**
   * Most recent date YYYY-MM-DD.
   */
  dateStr?: string;
  /**
   * Citation for flagged for deletion by source.
   */
  deleted?: boolean;
  /**
   * Mesh Terms.
   */
  heading?: NlpSciencelitMeshHeading[];
  issue?: string;
  /**
   * Title of journal. For books: Journal = Publisher Volume = Collection
   */
  journal?: string;
  language?: string;
  /**
   * Last entry revision date YYYY-MM-DD.
   */
  lastRevisedDateStr?: string;
  metadataSource?:  | "UNKNOWN" | "PUBMED" | "PMC" | "SCHOLAR" | "CORD"[];
  /**
   * Source Pubmed/Medline XML file.
   */
  parsedFrom?: string;
  /**
   * PMID of article (for non-pubmed data, this is the docid).
   */
  pmid?: string;
  publicationType?: NlpSciencelitPublicationType[];
  /**
   * Optional ScaM restrict tokens to be added to all GFVs generated from this
   * article's data.
   */
  scamRestrictTokens?: ResearchScamV3Restrict;
  /**
   * Title of article.
   */
  title?: string;
  /**
   * URL(s) for the document. If possible, order by decreasing desirability.
   */
  url?: string[];
  volume?: string;
}

function serializeNlpSciencelitArticleMetadata(data: any): NlpSciencelitArticleMetadata {
  return {
    ...data,
    dataset: data["dataset"] !== undefined ? data["dataset"].map((item: any) => (serializeNlpSciencelitDataset(item))) : undefined,
    scamRestrictTokens: data["scamRestrictTokens"] !== undefined ? serializeResearchScamV3Restrict(data["scamRestrictTokens"]) : undefined,
  };
}

function deserializeNlpSciencelitArticleMetadata(data: any): NlpSciencelitArticleMetadata {
  return {
    ...data,
    dataset: data["dataset"] !== undefined ? data["dataset"].map((item: any) => (deserializeNlpSciencelitDataset(item))) : undefined,
    scamRestrictTokens: data["scamRestrictTokens"] !== undefined ? deserializeResearchScamV3Restrict(data["scamRestrictTokens"]) : undefined,
  };
}

export interface NlpSciencelitAuthor {
  firstName?: string;
  lastName?: string;
}

/**
 * Next available ID: 8
 */
export interface NlpSciencelitCitationData {
  articleId?: NlpSciencelitArticleId[];
  author?: NlpSciencelitAuthor[];
  externalLink?: string;
  fullText?: string;
  /**
   * Reference used in text (e.g., PMC rid).
   */
  reference?: string;
  /**
   * Scholar citation information from scholar index.
   */
  scholarCitation?: ScienceCitation;
  /**
   * Optional information about the publication.
   */
  title?: string;
}

function serializeNlpSciencelitCitationData(data: any): NlpSciencelitCitationData {
  return {
    ...data,
    scholarCitation: data["scholarCitation"] !== undefined ? serializeScienceCitation(data["scholarCitation"]) : undefined,
  };
}

function deserializeNlpSciencelitCitationData(data: any): NlpSciencelitCitationData {
  return {
    ...data,
    scholarCitation: data["scholarCitation"] !== undefined ? deserializeScienceCitation(data["scholarCitation"]) : undefined,
  };
}

export interface NlpSciencelitDataset {
  association?:  | "UNKNOWN" | "DATABANK" | "CITATION" | "MATCH";
  datasetMetadata?: ResearchScienceSearchReconciledMetadata;
}

function serializeNlpSciencelitDataset(data: any): NlpSciencelitDataset {
  return {
    ...data,
    datasetMetadata: data["datasetMetadata"] !== undefined ? serializeResearchScienceSearchReconciledMetadata(data["datasetMetadata"]) : undefined,
  };
}

function deserializeNlpSciencelitDataset(data: any): NlpSciencelitDataset {
  return {
    ...data,
    datasetMetadata: data["datasetMetadata"] !== undefined ? deserializeResearchScienceSearchReconciledMetadata(data["datasetMetadata"]) : undefined,
  };
}

/**
 * A full Mesh Heading containing a descriptor and optionally multiple
 * qualifiers.
 * https://www.nlm.nih.gov/bsd/licensee/elements_descriptions.html#meshheadinglist
 */
export interface NlpSciencelitMeshHeading {
  meshDescriptor?: NlpSciencelitSubjectHeading;
  meshQualifier?: NlpSciencelitSubjectHeading[];
}

/**
 * Pubdate extracted from PMC article metadata.
 */
export interface NlpSciencelitPubDate {
  dateStr?: string;
  /**
   * "ppub" for a print ISSN and "epub" for an electronic ISSN.
   */
  pubType?: string;
}

export interface NlpSciencelitPublicationType {
  /**
   * Display name for the publication type, e.g. "Journal Article"
   */
  name?: string;
  /**
   * MeSH unique identifiers for publication types, e.g. "D016428"
   */
  ui?: string;
}

/**
 * Data associate with the ReferencesBlock. Next available ID: 5
 */
export interface NlpSciencelitReferencedBlock {
  /**
   * Caption tokens - all text in the caption other than the block.
   */
  caption?: NlpSciencelitTokenizedText;
  /**
   * Reference used from the text to point to this figure.
   */
  reference?: string;
  /**
   * Title tokens - these come from a block within a caption.
   */
  title?: NlpSciencelitTokenizedText;
  /**
   * Type of figure (table, figure, etc.).
   */
  type?: string;
}

export interface NlpSciencelitRetrievalQueryEncodingDebugInfo {
  /**
   * The query encoding sent to scam for retrieval.
   */
  scamQueryEncoding?: ResearchScamGenericFeatureVector;
}

function serializeNlpSciencelitRetrievalQueryEncodingDebugInfo(data: any): NlpSciencelitRetrievalQueryEncodingDebugInfo {
  return {
    ...data,
    scamQueryEncoding: data["scamQueryEncoding"] !== undefined ? serializeResearchScamGenericFeatureVector(data["scamQueryEncoding"]) : undefined,
  };
}

function deserializeNlpSciencelitRetrievalQueryEncodingDebugInfo(data: any): NlpSciencelitRetrievalQueryEncodingDebugInfo {
  return {
    ...data,
    scamQueryEncoding: data["scamQueryEncoding"] !== undefined ? deserializeResearchScamGenericFeatureVector(data["scamQueryEncoding"]) : undefined,
  };
}

/**
 * Returned by Delver API in SearchResult.debug_info.
 */
export interface NlpSciencelitRetrievalSearchResultDebugInfo {
  /**
   * Only set if RequestOptions.debug_return_article_data is true.
   */
  articleData?: NlpSciencelitArticleData;
  goldDocid?: string[];
  goldSnippets?: string[];
  /**
   * Not set by server; only used by evals.
   */
  isGold?: boolean;
  /**
   * See SearchResultInternal.reranking_score.
   */
  rerankingScore?: number;
  /**
   * See SearchResultInternal.reverse_reranking_order.
   */
  reverseRerankingOrder?: number;
  /**
   * See SearchResultInternal.section_ir_score.
   */
  sectionIrScore?: {
    [key: string]: number
  };
}

function serializeNlpSciencelitRetrievalSearchResultDebugInfo(data: any): NlpSciencelitRetrievalSearchResultDebugInfo {
  return {
    ...data,
    articleData: data["articleData"] !== undefined ? serializeNlpSciencelitArticleData(data["articleData"]) : undefined,
  };
}

function deserializeNlpSciencelitRetrievalSearchResultDebugInfo(data: any): NlpSciencelitRetrievalSearchResultDebugInfo {
  return {
    ...data,
    articleData: data["articleData"] !== undefined ? deserializeNlpSciencelitArticleData(data["articleData"]) : undefined,
  };
}

/**
 * Optionally returned by Delver API in the response's debug_info field.
 */
export interface NlpSciencelitRetrievalSearchResultSetDebugInfo {
  queryEncoding?: NlpSciencelitRetrievalQueryEncodingDebugInfo;
  scamResponse?: ResearchScamQueryResponse;
}

function serializeNlpSciencelitRetrievalSearchResultSetDebugInfo(data: any): NlpSciencelitRetrievalSearchResultSetDebugInfo {
  return {
    ...data,
    queryEncoding: data["queryEncoding"] !== undefined ? serializeNlpSciencelitRetrievalQueryEncodingDebugInfo(data["queryEncoding"]) : undefined,
    scamResponse: data["scamResponse"] !== undefined ? serializeResearchScamQueryResponse(data["scamResponse"]) : undefined,
  };
}

function deserializeNlpSciencelitRetrievalSearchResultSetDebugInfo(data: any): NlpSciencelitRetrievalSearchResultSetDebugInfo {
  return {
    ...data,
    queryEncoding: data["queryEncoding"] !== undefined ? deserializeNlpSciencelitRetrievalQueryEncodingDebugInfo(data["queryEncoding"]) : undefined,
    scamResponse: data["scamResponse"] !== undefined ? deserializeResearchScamQueryResponse(data["scamResponse"]) : undefined,
  };
}

/**
 * Returned by Delver API in Snippet.debug_info.
 */
export interface NlpSciencelitRetrievalSnippetDebugInfo {
  /**
   * Which highlights have sentence overlap with gold snippets. Not ordered.
   * Might only be set for the first gold highlight.
   */
  goldHighlightSentenceIndices?: number[];
  /**
   * Map of highlight index to best overlap with any gold snippet [0,1].
   */
  highlightIdxToOverlap?: {
    [key: string]: number
  };
  /**
   * Map of highlight index to best overlap with any gold sentence [0,1].
   */
  highlightIdxToSentenceOverlap?: {
    [key: string]: number
  };
  /**
   * Not set by server; only used by certain evals. Might only be set for the
   * first gold snippet.
   */
  isGold?: boolean;
  /**
   * Byte index of text within the full section text (or within title).
   */
  offsetWithinSection?: number;
  /**
   * Section within the document. -1 if title.
   */
  sectionIndex?: number;
  /**
   * IR score of the section the snippet is coming from.
   */
  sectionIrScore?: number;
  /**
   * BLEU score for the entire snippet.
   */
  snippetBleuScore?: number;
}

/**
 * A subject heading from Mesh
 */
export interface NlpSciencelitSubjectHeading {
  id?: string;
  majorTopic?: boolean;
  term?: string;
}

/**
 * Tokenized text with optional original representation.
 */
export interface NlpSciencelitTokenizedText {
  text?: string;
  token?: string[];
}

/**
 * Annotators whose semantics are represented via a protocol message should add
 * to that message a field or extension of this type and set it using
 * Annotator::PopulateAnnotationEvalData to enable span-based evaluation metrics
 * in training. Evaluation is done based on token spans. The byte span aligns
 * with the token span and is used when saving examples. Background: In some
 * settings, the examples used to induce/train a grammar do not specify complete
 * semantics of an annotation. For example, some examples that come from Ewok
 * specify only the span associated with each annotation. This message allows
 * evaluation metrics to test the span by embedding it in the semantics.
 * LINT.IfChange
 */
export interface NlpSemanticParsingAnnotationEvalData {
  /**
   * Additional spans after the first. Empty in all additional_spans.
   */
  additionalSpans?: NlpSemanticParsingAnnotationEvalData[];
  numBytes?: number;
  numTokens?: number;
  /**
   * Byte position within the utterance. Safe to use across different
   * components of the NLU stack as long as said components have access to the
   * same query.
   */
  startByte?: number;
  /**
   * Token position. This is cleared when normalizing examples for storage
   * because tokenization changes over time. DO NOT use these two fields across
   * components that use different tokenizations.
   */
  startToken?: number;
}

/**
 * The App annotator annotates potential app name in the parser's input and
 * outputs the proto with the details about app(s).
 */
export interface NlpSemanticParsingAppAnnotation {
  /**
   * The app_info is to store specific information about installed/uninstalled
   * apps annotated by app annotator servlet. It contains app name, package
   * name, confidence, and source.
   */
  appInfo?: QualityActionsAppInfo[];
}

function serializeNlpSemanticParsingAppAnnotation(data: any): NlpSemanticParsingAppAnnotation {
  return {
    ...data,
    appInfo: data["appInfo"] !== undefined ? data["appInfo"].map((item: any) => (serializeQualityActionsAppInfo(item))) : undefined,
  };
}

function deserializeNlpSemanticParsingAppAnnotation(data: any): NlpSemanticParsingAppAnnotation {
  return {
    ...data,
    appInfo: data["appInfo"] !== undefined ? data["appInfo"].map((item: any) => (deserializeQualityActionsAppInfo(item))) : undefined,
  };
}

/**
 * AbsoluteDateTime represents the resolved date/time expressions that need no
 * further calculation. It has a section for date and a section for time. The
 * date section will always be filled; if the time section is filled, hour is
 * always filled; for (minute, second, partial_second), they are optional with a
 * zero default value. But if partial_second is filled, (minute, second) must be
 * filled, even they are 0s; if second is filled, minute must be filled. Next
 * field#: 22.
 */
export interface NlpSemanticParsingDatetimeAbsoluteDateTime {
  /**
   * allow_personal determines if personal datetimes are allowed to be used in
   * the resolution of the personal datetime. If allow_personal is false and a
   * personal date exists, the entire parse will be thrown out.
   */
  allowPersonal?: boolean;
  day?: number;
  /**
   * Deprecated fields. Do NOT use.
   */
  deleted11?:  | "NONE" | "YEAR" | "YEAR_MONTH" | "YEAR_MONTH_DAY";
  /**
   * season, quarters and holidays will be soon handled as fetched relative
   * datetimes and will be removed from the AbsoluteDateTime message.
   */
  holiday?: NlpSemanticParsingDatetimeHoliday;
  /**
   * Time is 24-hour military time.
   */
  hour?: number;
  /**
   * Note: This is marked as deprecated as we are moving into explicit parses
   * using the `meridiem` field, and leave the inference over implicit parses to
   * the grounding/resolution libraries.
   */
  hourState?:  | "UNAMBIGUOUS" | "AMBIGUOUS" | "CHANGEABLE";
  /**
   * |is_bc| is true if and only the date is Before Christ/Common Era. If
   * |is_bc| is true, only year is meaningful in this proto, as Gregorian
   * calendar is only meaningful for A.D. date/times.
   */
  isBc?: boolean;
  /**
   * For expressions such as "am", "pm". Note: the name "meridiem" has been
   * taken by a field in message ResolutionProperties. Examples: * "9 am": point
   * { hour: 9 meridiem: AM hour_state: UNAMBIGUOUS }
   */
  meridiem?:  | "INVALID_MERIDIEM" | "AM" | "PM";
  minute?: number;
  /**
   * For expressions such as "around 2 pm".
   */
  modifier?:  | "NO_MOD" | "BEFORE" | "AFTER" | "ON_OR_BEFORE" | "ON_OR_AFTER" | "LESS_THAN" | "MORE_THAN" | "EQUAL_OR_LESS" | "EQUAL_OR_MORE" | "START" | "MID" | "END" | "APPROX" | "ADD" | "SUBTRACT";
  month?:  | "NO_MONTH" | "JANUARY" | "FEBRUARY" | "MARCH" | "APRIL" | "MAY" | "JUNE" | "JULY" | "AUGUST" | "SEPTEMBER" | "OCTOBER" | "NOVEMBER" | "DECEMBER";
  /**
   * If present then: 1) the incoming non-Gregorian datetime will be converted
   * to Gregorian. 2) exported DateTimeProperty fields will contain the
   * converted Gregorian datetime. 3) DateTimeProperty.source_calendar will be
   * set to the calendar-system that was used to specify the non-Gregorian date.
   */
  nonGregorianDate?: NlpSemanticParsingDatetimeNonGregorianDate;
  partialSecond?: number;
  properties?: NlpSemanticParsingDatetimeDateTimeProperty;
  quarter?:  | "INVALID_QUARTER" | "FIRST_QUARTER" | "SECOND_QUARTER" | "THIRD_QUARTER" | "FOURTH_QUARTER";
  /**
   * Modifier that return the appropriate subrange. For more information, see
   * the description of RangeOfDateTimeModifier. Example: * *early* 2020 *
   * *early* on March 20th When a point have a range_modifier field, the
   * resolution library will expand the point into the widest range in contains.
   * For example, in the case of a single date point like "April 22nd, 2022",
   * the point will be transformed into a range with: - "begin: April 22nd 2022
   * 00:00:00h" - "end: April 22nd 2022 23:59:59h" The modifier will then be
   * applied over that range.
   */
  rangeModifier?:  | "RANGE_MODIFIER_NONE" | "RANGE_MODIFIER_EARLY" | "RANGE_MODIFIER_MIDDLE" | "RANGE_MODIFIER_LATE";
  season?:  | "INVALID_SEASON" | "SPRING" | "SUMMER" | "FALL" | "WINTER" | "EARLY_SPRING" | "MID_SPRING" | "LATE_SPRING" | "EARLY_SUMMER" | "MID_SUMMER" | "LATE_SUMMER" | "EARLY_FALL" | "MID_FALL" | "LATE_FALL" | "EARLY_WINTER" | "MID_WINTER" | "LATE_WINTER";
  second?: number;
  /**
   * A string representation of the timezone information, see
   * i18n/identifiers/timezones.{h,cc}.
   */
  timezone?: string;
  /**
   * The |weekday| field is populated to indicate that a day-of-the-week is
   * explicitly mentioned in an absolute date utterance, such as [Tuesday, July
   * 6th, 2021]. Note that when a day-of-the-week is included in other,
   * non-absolute-date expressions, such as [on Tuesday], then this this field
   * is not populated (and in fact an AbsoluteDateTime is not used at all.)
   * Note: This field is populated only when the original expression contains a
   * day-of-the-week. It is not populated by the grounding library to indicate
   * that the date happens to be a Tuesday. Examples: * "Tuesday, July 6th 2021"
   * --> the day of the week is part of an absolute date expression, so this
   * field is populated: point { year: 2021 month: JULY day: 6 weekday: TUESDAY
   * } * "on Tuesday" --> the day of the week is not part of an absolute date
   * expression, so it is interpreted as a relative datetime: relative { fetched
   * { target { weekday: TUESDAY } } }
   */
  weekday?:  | "NO_DAY_OF_WEEK" | "SUNDAY" | "MONDAY" | "TUESDAY" | "WEDNESDAY" | "THURSDAY" | "FRIDAY" | "SATURDAY" | "WEEKEND";
  /**
   * Date.
   */
  year?: number;
}

function serializeNlpSemanticParsingDatetimeAbsoluteDateTime(data: any): NlpSemanticParsingDatetimeAbsoluteDateTime {
  return {
    ...data,
    properties: data["properties"] !== undefined ? serializeNlpSemanticParsingDatetimeDateTimeProperty(data["properties"]) : undefined,
  };
}

function deserializeNlpSemanticParsingDatetimeAbsoluteDateTime(data: any): NlpSemanticParsingDatetimeAbsoluteDateTime {
  return {
    ...data,
    properties: data["properties"] !== undefined ? deserializeNlpSemanticParsingDatetimeDateTimeProperty(data["properties"]) : undefined,
  };
}

/**
 * Example: "Remind me to go to the store on (Friday) (9am)" would output two
 * non-overlapping and unrelated annotations. One would have a start_date =
 * Friday and the other would have start_time = 9am. It's possible for Friday to
 * be one of several upcoming Friday's, so start_date is a repeated field. Next
 * ID: 10
 */
export interface NlpSemanticParsingDateTimeAnnotation {
  dateType?:  | "UNKNOWN_DATE_TYPE" | "TODAY" | "TOMORROW" | "WEEKEND" | "WEEK";
  endDate?: string[];
  endTime?: string[];
  endWeekday?:  | "UNKNOWN_DAY" | "SUNDAY" | "MONDAY" | "TUESDAY" | "WEDNESDAY" | "THURSDAY" | "FRIDAY" | "SATURDAY";
  rawText?: string;
  /**
   * NOTE: None of these are co-indexed. If the query is 'morning', there could
   * be multiple start_time's, start_date's, end_date's, and end_time's, and
   * they do not correspond to one another in any structured way.
   */
  startDate?: string[];
  startTime?: string[];
  startWeekday?:  | "UNKNOWN_DAY" | "SUNDAY" | "MONDAY" | "TUESDAY" | "WEDNESDAY" | "THURSDAY" | "FRIDAY" | "SATURDAY";
  timeType?:  | "UNKNOWN_TIME_TYPE" | "MORNING" | "AFTERNOON" | "EVENING" | "NIGHT";
}

/**
 * The top-level DATE/TIME representation. It can represent either (1) one or
 * multiple Date/Time ranges, or (2) one or multiple of Date/Time points, or (3)
 * a recurrent date/time expression. Next available ID: 12. Only one of |range|,
 * |point| and |recurrent| will be set: |range| contains a list of resolved
 * Date/Time ranges. |point| contains a list of resolved Date/Time points.
 * |recurrent| contains the representation for periodical dates/times. |range|
 * and |point| are repeated to accommodate the need when the date/time
 * expression under one non-terminal is resolved to a list of correct values.
 * For example, "Mondays in April, 2014" may have 4 correct dates.
 */
export interface NlpSemanticParsingDatetimeDateTime {
  /**
   * For temporal expressions that consist of components with different types,
   * the elements in the composition are nested according to the order they
   * should be grounded/resolved. For example, "tomorrow at 8am" has a relative
   * component [tomorrow] and an absolute datetime component [8am] so the
   * annotation will be represented in the following way, indicating that the
   * relative datetime for tomorrow should be grounded first, and then resolve
   * the actual 8am point for that given date: point { hour: 8 hour_state:
   * UNAMBIGUOUS properties { time_format: AM_PM_TOKEN } } composition_element {
   * relative { fetched { ordinal: 1 target { unit: DAY } base_type:
   * CURRENT_DATETIME } } grounding_stage: UNGROUNDED } grounding_stage:
   * UNGROUNDED_COMPOSITION The composition_element field will be populated only
   * when the grounding_stage is set to UNGROUNDED_COMPOSITION and it will hold
   * the nested DateTime value for the rest the compositional expression. More
   * details in: go/datetime-resolution-decoupling.
   */
  compositionElement?: NlpSemanticParsingDatetimeDateTime;
  /**
   * Deprecated fields. Do NOT use.
   */
  deleted7?: boolean;
  deleted8?: boolean;
  /**
   * This field of the DateTime message should not in general be used by
   * outside clients of the grammar. It is intended to be used internally in
   * Aqua for evaluation purposes. The rationale is that token counts depend on
   * the particular tokenization used in Aqua which may be different from the
   * one used by the client and may change from time to time. Outside clients
   * should not create a dependency on the current tokenization used in Aqua.
   */
  evalData?: NlpSemanticParsingAnnotationEvalData;
  groundingStage?:  | "UNKNOWN_GROUNDING_STAGE" | "UNGROUNDED" | "UNGROUNDED_COMPOSITION" | "RESOLVED" | "PARTIALLY_GROUNDED" | "FULLY_GROUNDED";
  point?: NlpSemanticParsingDatetimeAbsoluteDateTime[];
  properties?: NlpSemanticParsingDatetimeResolutionProperties;
  /**
   * Note that there is a difference between this scenario and an ambiguous
   * date/time expression. The latter is resolved to multiple proto messages,
   * not multiple values within one proto message. To be concrete, consider
   * "Monday" in "Monday football". It is ambiguous and can be reasonably
   * resolved to "Monday last week," "Monday this week" and "Monday next week."
   * The 3 values are represented as 3 separate DateTime messages, not 3 values
   * within one DateTime message.
   */
  range?: NlpSemanticParsingDatetimeRange[];
  recurrent?: NlpSemanticParsingDatetimeRecurrent;
  relative?: NlpSemanticParsingDatetimeRelativeDateTime;
  /**
   * See comments of Span.
   */
  span?: NlpSemanticParsingDatetimeSpan;
}

function serializeNlpSemanticParsingDatetimeDateTime(data: any): NlpSemanticParsingDatetimeDateTime {
  return {
    ...data,
    compositionElement: data["compositionElement"] !== undefined ? serializeNlpSemanticParsingDatetimeDateTime(data["compositionElement"]) : undefined,
    point: data["point"] !== undefined ? data["point"].map((item: any) => (serializeNlpSemanticParsingDatetimeAbsoluteDateTime(item))) : undefined,
    properties: data["properties"] !== undefined ? serializeNlpSemanticParsingDatetimeResolutionProperties(data["properties"]) : undefined,
    range: data["range"] !== undefined ? data["range"].map((item: any) => (serializeNlpSemanticParsingDatetimeRange(item))) : undefined,
    recurrent: data["recurrent"] !== undefined ? serializeNlpSemanticParsingDatetimeRecurrent(data["recurrent"]) : undefined,
    relative: data["relative"] !== undefined ? serializeNlpSemanticParsingDatetimeRelativeDateTime(data["relative"]) : undefined,
  };
}

function deserializeNlpSemanticParsingDatetimeDateTime(data: any): NlpSemanticParsingDatetimeDateTime {
  return {
    ...data,
    compositionElement: data["compositionElement"] !== undefined ? deserializeNlpSemanticParsingDatetimeDateTime(data["compositionElement"]) : undefined,
    point: data["point"] !== undefined ? data["point"].map((item: any) => (deserializeNlpSemanticParsingDatetimeAbsoluteDateTime(item))) : undefined,
    properties: data["properties"] !== undefined ? deserializeNlpSemanticParsingDatetimeResolutionProperties(data["properties"]) : undefined,
    range: data["range"] !== undefined ? data["range"].map((item: any) => (deserializeNlpSemanticParsingDatetimeRange(item))) : undefined,
    recurrent: data["recurrent"] !== undefined ? deserializeNlpSemanticParsingDatetimeRecurrent(data["recurrent"]) : undefined,
    relative: data["relative"] !== undefined ? deserializeNlpSemanticParsingDatetimeRelativeDateTime(data["relative"]) : undefined,
  };
}

/**
 * DateTimeProperty contains various metadata about the DateTime
 * interpretation. Next field: 13
 */
export interface NlpSemanticParsingDatetimeDateTimeProperty {
  dateFormat?:  | "DEFAULT_DATE_FORMAT" | "NUM_MONTH_DAY" | "NUM_DAY_MONTH";
  expandYearToCurrent?: boolean;
  hourStatus?:  | "HOUR_NONE" | "HOUR_UNAMBIGUOUS" | "HOUR_AMBIGUOUS_ORIGINAL" | "HOUR_AMBIGUOUS_INFERRED";
  inferredDateValue?:  | "NONE" | "YEAR" | "YEAR_MONTH" | "YEAR_MONTH_DAY";
  /**
   * Note: this may be changed to a repeated field in the future.
   */
  metadata?:  | "NO_METADATA" | "HOLIDAY" | "ORDINAL" | "WEEKEND" | "DECADE" | "MONTH" | "DAY_OF_WEEK" | "YEAR_NUMBER" | "MONTH_YEAR" | "PERSONAL" | "SEASON" | "WEE_HOURS_INFERRED" | "PROACTIVE_DEFAULT_TIME" | "PROACTIVE_DEFAULT_DATE" | "PROACTIVE_DEFAULT_DATETIME" | "HOUR_NUMBER" | "ASTRONOMICAL_EVENT" | "RECURRENT_UNKNOWN_FREQUENCY";
  /**
   * Metadata about the personal reference if the date was generated from a
   * personal reference.
   */
  personalReferenceMetadata?: CopleyPersonalReferenceMetadata;
  relationToReference?:  | "UNDEFINED" | "CLOSEST_FUTURE" | "CLOSEST_PAST" | "OTHER_FUTURE" | "OTHER_PAST";
  /**
   * Expresses the relative DateTime query that gave rise to these grounded
   * semantics.
   */
  relative?: NlpSemanticParsingDatetimeRelativeDateTime;
  sourceCalendar?:  | "GREGORIAN" | "BUDDHIST" | "CHINESE" | "COPTIC" | "ETHIOPIC" | "HEBREW" | "INDIAN_NATIONAL" | "ISLAMIC" | "JAPANESE" | "PERSIAN" | "ISLAMIC_UMALQURA";
  /**
   * If the annotation was created by using personal data, we record the
   * provenance for that data here.
   */
  sourceTypeList?: CopleySourceTypeList;
  timeFormat?:  | "DEFAULT" | "SEPARATED_HMS" | "AM_PM_TOKEN" | "WITH_TIMEWORD"[];
  /**
   * True iff the timezone value in AbsoluteDateTime is explicit in the
   * annotated text or not. In the following examples the timezone is explicit:
   * Query Timezone -------------------------- -------- 10pst Pacific Standard
   * Time 10 utc UTC 10 sydney time Australia Eastern Time
   */
  timezoneIsExplicit?: boolean;
}

function serializeNlpSemanticParsingDatetimeDateTimeProperty(data: any): NlpSemanticParsingDatetimeDateTimeProperty {
  return {
    ...data,
    relative: data["relative"] !== undefined ? serializeNlpSemanticParsingDatetimeRelativeDateTime(data["relative"]) : undefined,
    sourceTypeList: data["sourceTypeList"] !== undefined ? serializeCopleySourceTypeList(data["sourceTypeList"]) : undefined,
  };
}

function deserializeNlpSemanticParsingDatetimeDateTimeProperty(data: any): NlpSemanticParsingDatetimeDateTimeProperty {
  return {
    ...data,
    relative: data["relative"] !== undefined ? deserializeNlpSemanticParsingDatetimeRelativeDateTime(data["relative"]) : undefined,
    sourceTypeList: data["sourceTypeList"] !== undefined ? deserializeCopleySourceTypeList(data["sourceTypeList"]) : undefined,
  };
}

/**
 * To represent unanchored durations - the length of a date/time expression not
 * related to calendar in local context. E.g., "play first (DURATION: 5 minutes)
 * of Yellow Submarine", "it takes (DURATION: more than 3 days) to finish." In
 * contrast, queries like: "wake me up in 5 minutes" will be resolved to a
 * AbsoluteDateTime since the query indicates that the reference is now. A
 * duration can be turned into a range if either end is anchored.
 */
export interface NlpSemanticParsingDatetimeDuration {
  /**
   * This field of the Duration message should not in general be used by
   * outside clients of the grammar. It is intended to be used internally in
   * Aqua for evaluation purposes. The rationale is that token counts depend on
   * the particular tokenization used in Aqua which may be different from the
   * one used by the client and may change from time to time. Outside clients
   * should not create a dependency on the current tokenization used in Aqua.
   */
  evalData?: NlpSemanticParsingAnnotationEvalData;
  /**
   * For expressions such as "about 2 hrs".
   */
  modifier?:  | "NO_MOD" | "BEFORE" | "AFTER" | "ON_OR_BEFORE" | "ON_OR_AFTER" | "LESS_THAN" | "MORE_THAN" | "EQUAL_OR_LESS" | "EQUAL_OR_MORE" | "START" | "MID" | "END" | "APPROX" | "ADD" | "SUBTRACT";
  quantity?: NlpSemanticParsingDatetimeQuantity;
  /**
   * See comments of Span.
   */
  span?: NlpSemanticParsingDatetimeSpan;
}

/**
 * This message is defined to be a representation of events that could interact
 * with datetimes expressions through composition by shifting or fetching. For
 * "native" datetime events like sunset, sunrise, etc the type is enough, but
 * this should be extended as needed to represent richer event information.
 */
export interface NlpSemanticParsingDatetimeEvent {
  holiday?:  | "UNKNOWN_HOLIDAY" | "AIDS_DAY" | "AIR_FORCES_DAY" | "ALL_SAINTS_DAY" | "ALL_SOULDS_DAY" | "ANZAC_DAY" | "APARECIDA_DAY" | "APPLE_SAVIOUR_DAY" | "ARBOR_DAY" | "ARMED_FORCES_DAY" | "ARMISTICE_DAY" | "ASCENSION_DAY" | "ASH_WEDNESDAY" | "ASSUMPTION_OF_MARY" | "ATATURK_DAY" | "BERCHTOLDS_DAY" | "BLACK_DAY" | "BLACK_FRIDAY" | "BRAZIL_PROCLAMATION_DAY" | "CABOTAGE_DAY" | "CAMBODIAN_CORONATION_DAY" | "CANDLEMAS" | "CARINTHIAN_PLEBISCITE_DAY" | "CHAKRI_DAY" | "CHILDRENS_DAY" | "CHINA_COMMUNIST_PARTY_DAY" | "CHINA_GRAVE_SWEEPING_FESTIVAL" | "CHINA_HUMILIATION_DAY" | "LUNAR_NEW_YEAR" | "CHRISTMAS" | "CHRISTMAS_EVE" | "CHULA_MEMORIAL_DAY" | "CIVIL_SERVANT_DAY" | "COLUMBUS_DAY" | "COMING_OF_AGE_DAY" | "CONFUCIUS_DAY" | "CONSTITUTION_MEMORIAL_DAY" | "CONSUMERS_DAY" | "COPTIC_CHRISTMAS" | "CORPUS_CRISTI" | "CULTURE_DAY" | "CYBER_MONDAY" | "CZECH_FREEDOM_DEMOCRACY_DAY" | "DOCTORS_DAY" | "EARTH_DAY" | "EASTER" | "EASTERN_ANNUNCIATION_DAY" | "EASTER_MONDAY" | "ELECTION_DAY" | "ELECTION_DAY_RUNOFF" | "EPIPHANY" | "FATHERLAND_DEFENDER_DAY" | "FATHERS_DAY" | "FIRST_ADVENT_SUNDAY" | "FLAG_DAY" | "FLEMISH_COMMUNITY_DAY" | "FOOLS_DAY" | "FOURTH_ADVENT_SUNDAY" | "FREEDOM_DAY" | "FRENCH_COMMUNITY_DAY" | "GERMAN_COMMUNITY_DAY" | "GOOD_FRIDAY" | "GRAND_FATHERS_DAY" | "GRAND_MOTHERS_DAY" | "GRAND_PARENTS_DAY" | "GREAT_PRAYER_DAY" | "GREENERY_DAY" | "GROUNDHOG_DAY" | "HALLOWEEN" | "HEALTH_DAY" | "HIDIRELLEZ" | "HOLY_SATURDAY" | "HONEY_SAVIOUR_DAY" | "HONG_KONG_HANDOVER_DAY" | "HUMAN_RIGHTS_DAY" | "IMMACULATE_CONCEPTION_DAY" | "INDEPENDENCE_DAY" | "INDEPENDENCE_MOVEMENT_DAY" | "INTERCESSION_DAY" | "INTERNATIONAL_WORKERS_DAY" | "INTERNATIONA_WOMEN_DAY" | "JAPANESE_EMPERORS_BIRTHDAY" | "JESUS_BAPTISM" | "JOHN_HUS_DAY" | "JOURNALIST_DAY" | "KINGS_DAY" | "KING_OF_CAMBODIAS_BIRTHDAY" | "KING_OF_CAMBODIA_FATHERS_BIRTHDAY" | "KING_OF_CAMBODIA_MOTHERS_BIRTHDAY" | "KING_RAMA_IX_DEATH_ANNIVERSARY" | "KING_RAMA_X_BIRTHDAY" | "KNOWLEDGE_DAY" | "KOREAN_ALPHABET_DAY" | "KOREAN_MEMORIAL_DAY" | "KUPALA_NIGHT" | "KVEN_NATIONAL_DAY" | "LABOUR_DAY" | "LABOUR_THANKSGIVING_DAY" | "LIBERATION_DAY" | "LITTLE_CHRISTMAS_EVE" | "MACAU_DAY" | "MARDI_GRAS" | "MARTIAL_DAY" | "MARTIN_LUTHER_KING_DAY" | "MAUNDY_THURSDAY" | "MAY_DAY" | "MEDICINE_DAY" | "MELBOURNE_CUP" | "MEMORIAL_DAY" | "MIDSUMMER_DAY" | "MIDSUMMER_EVE" | "MOTHERING_SUNDAY" | "MOTHERS_DAY" | "NATIONAL_DAY" | "NATIONAL_FOUNDATION_DAY" | "NEW_YEAR" | "NEW_YEARS_EVE" | "NURSE_DAY" | "OBON_FESTIVAL" | "OCEAN_DAY" | "OCTOBER_REVOLUTION_DAY" | "ORTHODOX_CHRISTMAS" | "ORTHODOX_EASTER" | "ORTHODOX_NEW_YEAR" | "ORTHODOX_NEW_YEARS_EVE" | "PALM_SUNDAY" | "PARATROOPERS_DAY" | "PARENTS_DAY" | "PARIS_PEACE_AGREEMENTS_DAY" | "PARLIAMNET_DAY" | "PEACE_DAY" | "PENTECOST" | "PENTECOST_EVE" | "PEPERO_DAY" | "PERSIAN_NEW_YEAR" | "PLOUGHING_CEREMONY_DAY" | "POLICE_DAY" | "POLISH_MAY_HOLIDAYS" | "PORTUGAL_PROCLAMATION_DAY" | "PRESIDENT_DAY" | "REFORMATION_DAY" | "REMEMBRANCE_AND_SORROW_DAY" | "REMEMBRANCE_DAY" | "REPENTANCE_AND_PRAYER_DAY" | "REPUBLIC_DAY" | "RESPECT_FOR_THE_ELDERLY_DAY" | "ROSE_DAY" | "RUSSIAN_GUARD_DAY" | "SAINT_CYRIL_METHODIUS_DAY" | "SAINT_FLORIAN_DAY" | "SAINT_FRANCIS_DAY" | "SAINT_JOHN_DAY" | "SAINT_JOHN_EVE" | "SAINT_JOSEPH" | "SAINT_LEOPOLD_DAY" | "SAINT_LUCY_DAY" | "SAINT_MARTIN_DAY" | "SAINT_NICHOLAS_DAY" | "SAINT_OLAF_DAY" | "SAINT_RUPERT_DAY" | "SAINT_STEPHEN_DAY" | "SAMI_NATIONAL_DAY" | "SCOUTING_DAY" | "SECOND_ADVENT_SUNDAY" | "SECOND_CHRISTMAS_DAY" | "SHOWA_DAY" | "SINAI_DAY" | "SINGLES_DAY" | "SONGKRAN_DAY" | "SPORTS_DAY" | "SUNFLOWER_MOVEMENT_DAY" | "TATIANA_DAY" | "TEACHERS_DAY" | "THAI_CORONATION_DAY" | "THAI_PONGAL_DAY" | "THANKSGIVING_DAY" | "THIRD_ADVENT_SUNDAY" | "TIRADENTES_DAY" | "UNITY_DAY" | "VALENTINE_DAY" | "VETERANS_DAY" | "VICTORY_DAY" | "VIETNAMESE_REUNIFICATION_DAY" | "VIETNAM_COMMUNIST_PARTY_DAY" | "VIETNAM_REWVOLUATIONARY_PRESS_DAY" | "WALPURGIS_NIGHT" | "WENCESLAUS_DAY" | "WESTERN_ANNUNCIATION_DAY" | "WHITE_DAY" | "WHIT_MONDAY" | "WOMEN_RIGHTS_DAY" | "YOUTH_DAY";
  moonEvent?: NlpSemanticParsingDatetimeMoonEventInfo;
  sunEvent?:  | "INVALID_SUN_EVENT" | "SUNRISE" | "SUNSET" | "DAWN" | "DUSK";
  type?:  | "INVALID_EVENT" | "ASTRONOMICAL_EVENT" | "HOLIDAY_EVENT";
}

/**
 * For a more detailed presentation on what's a fetching operation, see
 * go/datetime-meaning-schemas. Examples to illustrate how the proto is used: I.
 * Fetching day-of-weeks: a) query: "1st 2 Mondays of April" proto: ordinal: 1
 * target {weekday: MONDAY} count: 2 range: {begin {year: RESOLVED_YEAR month:
 * APRIL day: 1} {end {year: RESOLVED_YEAR month: APRIL day: 30} b) query: "1st
 * and last Monday of April" proto: ordinal: 1 ordinal: -1 target {weekday:
 * MONDAY} range: {begin {year: RESOLVED_YEAR month: APRIL day: 1} {end {year:
 * RESOLVED_YEAR month: APRIL day: 30} c) query: "next Monday" proto: ordinal: 1
 * target {weekday: MONDAY} d) query: "last 2 Mondays" proto: ordinal: -1 count:
 * 2 target {weekday: MONDAY} e) query: "this Monday" proto: ordinal: 0 target
 * {weekday: MONDAY} f) query: "the monday after next" proto: ordinal: 2 target
 * {weekday: MONDAY} g) query: "third Monday in April" proto: ordinal: 3 target
 * {weekday: MONDAY} range: {begin {year: RESOLVED_YEAR month: APRIL day: 1}
 * {end {year: RESOLVED_YEAR month: APRIL day: 30} h) query: "the monday before
 * last" proto: ordinal: -2 target {weekday: MONDAY} i) query: "the second to
 * the last monday in April" proto: ordinal: -2 target {weekday: MONDAY} range:
 * {begin {year: RESOLVED_YEAR month: APRIL day: 1} {end {year: RESOLVED_YEAR
 * month: APRIL day: 30} II. Fetching date/time unit: a) query: "1st 2 weeks of
 * April" proto: ordinal: 1 target {unit: WEEK} count: 2 range: {begin {year:
 * RESOLVED_YEAR month: APRIL day: 1} {end {year: RESOLVED_YEAR month: APRIL
 * day: 30} b) query: "1st and last week of April" proto: ordinal: 1 ordinal: -1
 * target {unit: WEEK} range: {begin {year: RESOLVED_YEAR month: APRIL day: 1}
 * {end {year: RESOLVED_YEAR month: APRIL day: 30} c) query: "next year" proto:
 * ordinal: 1 target {unit: YEAR} d) query: "last 2 weeks" proto: ordinal: -1
 * count: 2 target {unit: WEEK} e) query: "this month" proto: ordinal: 0 target
 * {unit: MONTH} f) query: "the week after next" proto: ordinal: 2 target {unit:
 * WEEK} g) query: "third week in April" proto: ordinal: 3 target {unit: WEEK}
 * range: {begin {year: RESOLVED_YEAR month: APRIL day: 1} {end {year:
 * RESOLVED_YEAR month: APRIL day: 30} h) query: "the week before last" proto:
 * ordinal: -2 target {unit: WEEK} i) query: "the second to the last week in
 * April" proto: ordinal: -2 target {unit: WEEK} range: {begin {year:
 * RESOLVED_YEAR month: APRIL day: 1} {end {year: RESOLVED_YEAR month: APRIL
 * day: 30} Next field: 9
 */
export interface NlpSemanticParsingDatetimeFetchedRelativeDateTime {
  baseType?:  | "UNKNOWN" | "CURRENT_DATETIME" | "EXPLICIT_PRONOUN";
  /**
   * How many to fetch (e.g. [next weekend] vs. [next two weeks])
   */
  count?: number;
  /**
   * Can be used to tag relative datetime expressions with metadata information
   * in the grammar.
   */
  metadata?:  | "NO_METADATA" | "HOLIDAY" | "ORDINAL" | "WEEKEND" | "DECADE" | "MONTH" | "DAY_OF_WEEK" | "YEAR_NUMBER" | "MONTH_YEAR" | "PERSONAL" | "SEASON" | "WEE_HOURS_INFERRED" | "PROACTIVE_DEFAULT_TIME" | "PROACTIVE_DEFAULT_DATE" | "PROACTIVE_DEFAULT_DATETIME" | "HOUR_NUMBER" | "ASTRONOMICAL_EVENT" | "RECURRENT_UNKNOWN_FREQUENCY";
  /**
   * Encodes expressions like next (+1), last (-1), after next (+2), this (0).
   */
  ordinal?: number[];
  /**
   * The restriction range on which fetching is operated, e.g., "April" in
   * "first Tuesday in/of April." If this field is missing, the operation is
   * done relative to the base_type (or if not given, to the query's reference
   * datetime). When the fetching operation is performed relative to a reference
   * time point, positive ordinal values represent upcoming instances from the
   * reference point, negative ordinal values represent previous instances from
   * the reference point. Similarly, ordinal=0 represents a reference to the
   * "current instance", which may vary depending on the target. E.g. "this
   * week" is simply defined as the week range that contains the current
   * reference time point, but "this " can be ambiguous and its resolution will
   * depend on language/locale conventions ("this monday" in some languages
   * refers to the closest upcoming instance of Monday, while in other languages
   * it represents the Monday instance within the current week).
   */
  range?: NlpSemanticParsingDatetimeRange;
  /**
   * Modifier that return the appropriate subrange. For more information, see
   * the description of RangeOfDateTimeModifier. Example: * *early* next week *
   * *late* next Monday
   */
  rangeModifier?:  | "RANGE_MODIFIER_NONE" | "RANGE_MODIFIER_EARLY" | "RANGE_MODIFIER_MIDDLE" | "RANGE_MODIFIER_LATE";
  /**
   * If the underlying range comes from a relative datetime expression, encode
   * the expression here instead.
   */
  relativeRange?: NlpSemanticParsingDatetimeResolutionProperties;
  /**
   * The target to be fetched. This could be a named day-of-week or month
   * (e.g., "Monday", "April"), or a date/time unit (e.g., "day", "week",
   * "month").
   */
  target?: NlpSemanticParsingDatetimeTargetToFetch;
}

function serializeNlpSemanticParsingDatetimeFetchedRelativeDateTime(data: any): NlpSemanticParsingDatetimeFetchedRelativeDateTime {
  return {
    ...data,
    range: data["range"] !== undefined ? serializeNlpSemanticParsingDatetimeRange(data["range"]) : undefined,
    relativeRange: data["relativeRange"] !== undefined ? serializeNlpSemanticParsingDatetimeResolutionProperties(data["relativeRange"]) : undefined,
  };
}

function deserializeNlpSemanticParsingDatetimeFetchedRelativeDateTime(data: any): NlpSemanticParsingDatetimeFetchedRelativeDateTime {
  return {
    ...data,
    range: data["range"] !== undefined ? deserializeNlpSemanticParsingDatetimeRange(data["range"]) : undefined,
    relativeRange: data["relativeRange"] !== undefined ? deserializeNlpSemanticParsingDatetimeResolutionProperties(data["relativeRange"]) : undefined,
  };
}

/**
 * List of holidays that are not fixed absolute or relative dates on the
 * Gregorian calendar.
 */
export interface NlpSemanticParsingDatetimeHoliday {
  /**
   * There are 3 types of holidays supported by the datetime subgrammar: 1)
   * NonFixedHolidayEnum: e.g., "easter", "chinese new year". 2)
   * FetchedRelativeDateTime: e.g., "Thanksgiving" => [4th Thursday of November]
   * 3) HolidayByMonthDay: e.g., "xmas" => [December 25] Each holiday of the
   * first type is resolved by a C++ function; the 2nd and 3rd type of holidays
   * are mapped to AbsoluteDateTime and FetchedRelativeDateTime, respectively,
   * in grammar and are not needed to be represented in proto.
   */
  nonFixed?:  | "UNKNOWN_NON_FIXED_HOLIDAY" | "EASTER" | "CHINESE_NEW_YEAR" | "ORTHODOX_EASTER" | "MARDI_GRAS" | "ASH_WEDNESDAY" | "GOOD_FRIDAY" | "EASTER_MONDAY" | "PENTECOST" | "CORPUS_CRISTI" | "WHIT_MONDAY" | "PALM_SUNDAY" | "MAUNDY_THURSDAY" | "ASCENSION_DAY" | "GREAT_PRAYER_DAY" | "HOLY_SATURDAY" | "PENTECOST_EVE" | "MOTHERING_SUNDAY";
}

export interface NlpSemanticParsingDatetimeMoonEventInfo {
  phase?:  | "UNKNOWN_MOON_PHASE" | "NEW_MOON" | "WAXING_CRESCENT" | "FIRST_QUARTER_PHASE" | "WAXING_GIBBOUS" | "FULL_MOON" | "WANING_GIBBOUS" | "LAST_QUARTER_PHASE" | "WANING_CRESCENT";
  type?:  | "INVALID_MOON_EVENT" | "MOONRISE" | "MOONSET";
}

/**
 * Non-Gregorian dates are similar to AbsoluteDateTime, but use non-Gregorian
 * calendars.
 */
export interface NlpSemanticParsingDatetimeNonGregorianDate {
  chineseMonth?:  | "UNKNOWN_CHINESE_MONTH" | "FIRST_MONTH" | "SECOND_MONTH" | "THIRD_MONTH" | "FOURTH_MONTH" | "FIFTH_MONTH" | "SIXTH_MONTH" | "SEVENTH_MONTH" | "EIGHTH_MONTH" | "NINTH_MONTH" | "TENTH_MONTH" | "ELEVENTH_MONTH" | "TWELFTH_MONTH";
  /**
   * The day is the offset within the month, same as in Gregorian calendars.
   */
  day?: number;
  hebrewMonth?:  | "UNKNOWN_HEBREW_MONTH" | "TISHRI" | "HESHVAN" | "KISLEV" | "TEVET" | "SHEVAT" | "ADAR_1" | "ADAR" | "NISAN" | "IYAR" | "SIVAN" | "TAMUZ" | "AV" | "ELUL";
  islamicMonth?:  | "UNKNOWN_ISLAMIC_MONTH" | "MUHARRAM" | "SAFAR" | "RABI_AL_AWWAL" | "RABI_AL_THANI" | "JUMADA_AL_AWWAL" | "JUMADA_AL_THANI" | "RAJAB" | "SHABAN" | "RAMADAN" | "SHAWWAL" | "ZUL_QAADAH" | "ZUL_HIJJAH";
  /**
   * The year is relative to the calendar (e.g. 5777 for Hebrew calendar).
   */
  year?: number;
}

export interface NlpSemanticParsingDatetimeQuantity {
  /**
   * For internal use - DateTime subgrammar users should look at
   * Duration.modifier. = MORE in [3 more days].
   */
  modifier?:  | "NO_MOD" | "BEFORE" | "AFTER" | "ON_OR_BEFORE" | "ON_OR_AFTER" | "LESS_THAN" | "MORE_THAN" | "EQUAL_OR_LESS" | "EQUAL_OR_MORE" | "START" | "MID" | "END" | "APPROX" | "ADD" | "SUBTRACT";
  /**
   * = 3 in "3 milliseconds".
   */
  number?: number;
  /**
   * This field keeps the span info of the number element in a quantity
   * expression, which is useful for downstream components to obtain the number
   * annotations inside a quantity when necessary.
   */
  numberSpan?: NlpSemanticParsingAnnotationEvalData;
  /**
   * Quantities are typically converted into milliseconds, regardless of the
   * units the user used. Sometimes this loses crucial information, e.g., "5
   * days" vs "5 nights". When quantities are converted to milliseconds,
   * 'symbolic_quantity' will contain the sequence of units that the user
   * actually supplied. This can be more than one element in cases like "one
   * minute and 30 seconds". In cases where 'symbolic_quantity' has more than
   * one element, THERE IS NO GUARANTEED ORDER between elements.
   */
  symbolicQuantity?: NlpSemanticParsingDatetimeQuantity[];
  /**
   * = MILLISECOND in "3 milliseconds".
   */
  unit?:  | "NO_UNIT" | "NANOSECOND" | "MICROSECOND" | "MILLISECOND" | "SECOND" | "MINUTE" | "HOUR" | "DAY" | "WEEK" | "TEN_DAY" | "HALF_MONTH" | "MONTH" | "QUARTER" | "HALF_YEAR" | "YEAR" | "DECADE" | "CENTURY" | "MILLENNIUM" | "NIGHT";
}

/**
 * Range has 4 use cases: 1. with an explicit begin and an explicit end, e.g.
 * "from Monday to Wednesday." Both |begin| and |end| are filled in this case.
 * 2. a point date/time expression is used as a range at a finer granularity.
 * E.g., in "first Monday of this month", "this month" is used as a range. In
 * this case, only |begin| will be filled and the |end| will be filled during
 * the grounding process. 3. a fuzzy date/time range such as "morning" or
 * "evening." 4. with a relative begin and a relative end, e.g. "from yesterday
 * to next Monday." Note: this may be used in a mixture of exact/relative begin
 * and end. Next available ID: 14.
 */
export interface NlpSemanticParsingDatetimeRange {
  /**
   * Deprecated fields. Do NOT use.
   */
  begin?: NlpSemanticParsingDatetimeAbsoluteDateTime;
  beginRelative?: NlpSemanticParsingDatetimeRelativeDateTime;
  /**
   * if |duration| is set, one field from start or finish must be populated,
   * but not both. |exclusive| value is still relevant to decide if the
   * endpoints of the range are included in the range (value defined in the
   * start/finish fields as well as the datetime value resulting of offseting
   * the duration over the given range endpoint).
   */
  duration?: NlpSemanticParsingDatetimeQuantity;
  end?: NlpSemanticParsingDatetimeAbsoluteDateTime;
  endRelative?: NlpSemanticParsingDatetimeRelativeDateTime;
  exclusive?: boolean;
  finish?: NlpSemanticParsingDatetimeDateTime;
  fuzzyRange?:  | "NO_FUZZY_RANGE" | "FUZZY_RANGE_MORNING" | "FUZZY_RANGE_AFTERNOON" | "FUZZY_RANGE_EVENING" | "FUZZY_RANGE_NIGHT" | "FUZZY_RANGE_EVE" | "FUZZY_RANGE_DAYTIME" | "FUZZY_RANGE_DAWN" | "FUZZY_RANGE_DUSK" | "FUZZY_RANGE_NIGHTTIME" | "FUZZY_RANGE_EARLY_MORNING" | "FUZZY_RANGE_MID_MORNING" | "FUZZY_RANGE_LATE_MORNING" | "FUZZY_RANGE_EARLY_AFTERNOON" | "FUZZY_RANGE_MID_AFTERNOON" | "FUZZY_RANGE_LATE_AFTERNOON" | "FUZZY_RANGE_EARLY_EVENING" | "FUZZY_RANGE_MID_EVENING" | "FUZZY_RANGE_LATE_EVENING" | "FUZZY_RANGE_LATE_NIGHT" | "DELETED_11";
  metadata?:  | "NO_METADATA" | "HOLIDAY" | "ORDINAL" | "WEEKEND" | "DECADE" | "MONTH" | "DAY_OF_WEEK" | "YEAR_NUMBER" | "MONTH_YEAR" | "PERSONAL" | "SEASON" | "WEE_HOURS_INFERRED" | "PROACTIVE_DEFAULT_TIME" | "PROACTIVE_DEFAULT_DATE" | "PROACTIVE_DEFAULT_DATETIME" | "HOUR_NUMBER" | "ASTRONOMICAL_EVENT" | "RECURRENT_UNKNOWN_FREQUENCY";
  properties?: NlpSemanticParsingDatetimeResolutionProperties;
  /**
   * Modifier that return the appropriate subrange. For more information, see
   * the description of RangeOfDateTimeModifier. Example: * *late* morning
   */
  rangeModifier?:  | "RANGE_MODIFIER_NONE" | "RANGE_MODIFIER_EARLY" | "RANGE_MODIFIER_MIDDLE" | "RANGE_MODIFIER_LATE";
  /**
   * |start| and |finish| are inclusive unless exclusive field is true. the
   * values in start and finish can be an absolute point, a relative or another
   * range. Recurrences and repeated values are not expected/allowed.
   */
  start?: NlpSemanticParsingDatetimeDateTime;
  /**
   * The field is set if the range is the result of resolving/grounding a
   * relative datetime expression referring to a part of the day. E.g.
   * "morning", "afternoon", "evening", "night", "tonight", etc.
   */
  symbolicValue?:  | "NO_SYMBOLIC_DATETIME" | "SYMBOLIC_MORNING" | "SYMBOLIC_AFTERNOON" | "SYMBOLIC_EVENING" | "SYMBOLIC_NIGHT" | "DELETED_5";
}

function serializeNlpSemanticParsingDatetimeRange(data: any): NlpSemanticParsingDatetimeRange {
  return {
    ...data,
    begin: data["begin"] !== undefined ? serializeNlpSemanticParsingDatetimeAbsoluteDateTime(data["begin"]) : undefined,
    beginRelative: data["beginRelative"] !== undefined ? serializeNlpSemanticParsingDatetimeRelativeDateTime(data["beginRelative"]) : undefined,
    end: data["end"] !== undefined ? serializeNlpSemanticParsingDatetimeAbsoluteDateTime(data["end"]) : undefined,
    endRelative: data["endRelative"] !== undefined ? serializeNlpSemanticParsingDatetimeRelativeDateTime(data["endRelative"]) : undefined,
    finish: data["finish"] !== undefined ? serializeNlpSemanticParsingDatetimeDateTime(data["finish"]) : undefined,
    properties: data["properties"] !== undefined ? serializeNlpSemanticParsingDatetimeResolutionProperties(data["properties"]) : undefined,
    start: data["start"] !== undefined ? serializeNlpSemanticParsingDatetimeDateTime(data["start"]) : undefined,
  };
}

function deserializeNlpSemanticParsingDatetimeRange(data: any): NlpSemanticParsingDatetimeRange {
  return {
    ...data,
    begin: data["begin"] !== undefined ? deserializeNlpSemanticParsingDatetimeAbsoluteDateTime(data["begin"]) : undefined,
    beginRelative: data["beginRelative"] !== undefined ? deserializeNlpSemanticParsingDatetimeRelativeDateTime(data["beginRelative"]) : undefined,
    end: data["end"] !== undefined ? deserializeNlpSemanticParsingDatetimeAbsoluteDateTime(data["end"]) : undefined,
    endRelative: data["endRelative"] !== undefined ? deserializeNlpSemanticParsingDatetimeRelativeDateTime(data["endRelative"]) : undefined,
    finish: data["finish"] !== undefined ? deserializeNlpSemanticParsingDatetimeDateTime(data["finish"]) : undefined,
    properties: data["properties"] !== undefined ? deserializeNlpSemanticParsingDatetimeResolutionProperties(data["properties"]) : undefined,
    start: data["start"] !== undefined ? deserializeNlpSemanticParsingDatetimeDateTime(data["start"]) : undefined,
  };
}

/**
 * expressions: "every Monday after December 1" "every morning starting from
 * this Friday". Note: if a recurrent DATE/TIME expression is bounded (limited
 * by a finite interval or a finite count), e.g., "every monday in the next 3
 * months", "... at 11:00am every Monday for 4 times" the grammar will resolve
 * it to a finite number of |range|s. Next available ID: 17.
 */
export interface NlpSemanticParsingDatetimeRecurrent {
  /**
   * How many times it repeats.
   */
  countRestriction?: number;
  /**
   * An arbitrary exception to the recurrence. This can be an absolute point, a
   * relative, a range or a recurrent expression. Examples: * "every Tuesday
   * except for July 13th 2021" * "every Tuesday except for July 13th and
   * November 2nd" * "every second Monday except during the summer" * "everyday
   * except Thursdays" * "every Friday, except from October 1st to October 22nd"
   */
  exception?: NlpSemanticParsingDatetimeDateTime[];
  /**
   * |frequency| is used to represent the frequency of the recurrence over a
   * given recurrent period. E.g. "twice a week", "once a month". An unknown
   * frequency is represented with 0, as in just "repeating".
   */
  frequency?: number;
  metadata?:  | "NO_METADATA" | "HOLIDAY" | "ORDINAL" | "WEEKEND" | "DECADE" | "MONTH" | "DAY_OF_WEEK" | "YEAR_NUMBER" | "MONTH_YEAR" | "PERSONAL" | "SEASON" | "WEE_HOURS_INFERRED" | "PROACTIVE_DEFAULT_TIME" | "PROACTIVE_DEFAULT_DATE" | "PROACTIVE_DEFAULT_DATETIME" | "HOUR_NUMBER" | "ASTRONOMICAL_EVENT" | "RECURRENT_UNKNOWN_FREQUENCY";
  /**
   * |period| and |unit| specify how often |start_point| or |start_range|
   * repeats. |period| should not be 0.
   */
  period?: number;
  rangeRestriction?: NlpSemanticParsingDatetimeRange;
  relativeRangeRestriction?: NlpSemanticParsingDatetimeRelativeDateTime;
  /**
   * A recurrent expression can be restricted by either a datetime
   * |restriction| or |count_restriction| below. The restriction datetime can be
   * expressed as an explicit range a relative datetime expression, a datetime
   * point or a recurrent datetime. E.g. "every monday [next month]", "every
   * second tuesday [this year]", etc. If |period| is > 0 and |restriction| is
   * not set, repeat indefinitely. Note that this can support recurrent
   * expressions as |restriction| as well. For example in the expression "every
   * monday on [every other month]" where [every other month] is a restriction
   * expressed as a recurrent datetime.
   */
  restriction?: NlpSemanticParsingDatetimeDateTime;
  /**
   * |start| is used to represent the starting points, ranges or relative
   * datetims in a recurrent expression, for example: "every morning", (range)
   * "everyday at 5 pm", (point) "every second monday" (relative) |start| should
   * never contain a recurrent element.
   */
  start?: NlpSemanticParsingDatetimeDateTime[];
  /**
   * DO NOT USE: deprecated fields soon to be removed.
   */
  startPoint?: NlpSemanticParsingDatetimeAbsoluteDateTime[];
  startRange?: NlpSemanticParsingDatetimeRange[];
  startRelative?: NlpSemanticParsingDatetimeRelativeDateTime[];
  /**
   * The target to be fetched. This could be a named day-of-week or month
   * (e.g., "Monday", "April"), or a date/time unit (e.g., "day", "week",
   * "month").
   */
  target?: NlpSemanticParsingDatetimeTargetToFetch;
  /**
   * |time_interval| is a time amount or duration, used to described the time
   * interval between the instances of the recurrence. (e.g. "every 3 hours",
   * "every 35 minutes", "every 2 months and 15 days", etc)
   */
  timeInterval?: NlpSemanticParsingDatetimeQuantity;
  unit?:  | "NO_UNIT" | "NANOSECOND" | "MICROSECOND" | "MILLISECOND" | "SECOND" | "MINUTE" | "HOUR" | "DAY" | "WEEK" | "TEN_DAY" | "HALF_MONTH" | "MONTH" | "QUARTER" | "HALF_YEAR" | "YEAR" | "DECADE" | "CENTURY" | "MILLENNIUM" | "NIGHT";
}

function serializeNlpSemanticParsingDatetimeRecurrent(data: any): NlpSemanticParsingDatetimeRecurrent {
  return {
    ...data,
    exception: data["exception"] !== undefined ? data["exception"].map((item: any) => (serializeNlpSemanticParsingDatetimeDateTime(item))) : undefined,
    rangeRestriction: data["rangeRestriction"] !== undefined ? serializeNlpSemanticParsingDatetimeRange(data["rangeRestriction"]) : undefined,
    relativeRangeRestriction: data["relativeRangeRestriction"] !== undefined ? serializeNlpSemanticParsingDatetimeRelativeDateTime(data["relativeRangeRestriction"]) : undefined,
    restriction: data["restriction"] !== undefined ? serializeNlpSemanticParsingDatetimeDateTime(data["restriction"]) : undefined,
    start: data["start"] !== undefined ? data["start"].map((item: any) => (serializeNlpSemanticParsingDatetimeDateTime(item))) : undefined,
    startPoint: data["startPoint"] !== undefined ? data["startPoint"].map((item: any) => (serializeNlpSemanticParsingDatetimeAbsoluteDateTime(item))) : undefined,
    startRange: data["startRange"] !== undefined ? data["startRange"].map((item: any) => (serializeNlpSemanticParsingDatetimeRange(item))) : undefined,
    startRelative: data["startRelative"] !== undefined ? data["startRelative"].map((item: any) => (serializeNlpSemanticParsingDatetimeRelativeDateTime(item))) : undefined,
  };
}

function deserializeNlpSemanticParsingDatetimeRecurrent(data: any): NlpSemanticParsingDatetimeRecurrent {
  return {
    ...data,
    exception: data["exception"] !== undefined ? data["exception"].map((item: any) => (deserializeNlpSemanticParsingDatetimeDateTime(item))) : undefined,
    rangeRestriction: data["rangeRestriction"] !== undefined ? deserializeNlpSemanticParsingDatetimeRange(data["rangeRestriction"]) : undefined,
    relativeRangeRestriction: data["relativeRangeRestriction"] !== undefined ? deserializeNlpSemanticParsingDatetimeRelativeDateTime(data["relativeRangeRestriction"]) : undefined,
    restriction: data["restriction"] !== undefined ? deserializeNlpSemanticParsingDatetimeDateTime(data["restriction"]) : undefined,
    start: data["start"] !== undefined ? data["start"].map((item: any) => (deserializeNlpSemanticParsingDatetimeDateTime(item))) : undefined,
    startPoint: data["startPoint"] !== undefined ? data["startPoint"].map((item: any) => (deserializeNlpSemanticParsingDatetimeAbsoluteDateTime(item))) : undefined,
    startRange: data["startRange"] !== undefined ? data["startRange"].map((item: any) => (deserializeNlpSemanticParsingDatetimeRange(item))) : undefined,
    startRelative: data["startRelative"] !== undefined ? data["startRelative"].map((item: any) => (deserializeNlpSemanticParsingDatetimeRelativeDateTime(item))) : undefined,
  };
}

/**
 * This provides a semi-abstract description for relative datetime expressions.
 * - ShiftedRelativeDateTime encodes datetimes that arise from before/after
 * expressions (e.g. [three days ago], [2 days after March 1st]). -
 * FetchedRelativeDateTime encodes expressions that are retrieval-type
 * statements (e.g. [next weekend], [the last two Mondays]). Next field: 5
 */
export interface NlpSemanticParsingDatetimeRelativeDateTime {
  fetched?: NlpSemanticParsingDatetimeFetchedRelativeDateTime;
  metadata?:  | "NO_METADATA" | "HOLIDAY" | "ORDINAL" | "WEEKEND" | "DECADE" | "MONTH" | "DAY_OF_WEEK" | "YEAR_NUMBER" | "MONTH_YEAR" | "PERSONAL" | "SEASON" | "WEE_HOURS_INFERRED" | "PROACTIVE_DEFAULT_TIME" | "PROACTIVE_DEFAULT_DATE" | "PROACTIVE_DEFAULT_DATETIME" | "HOUR_NUMBER" | "ASTRONOMICAL_EVENT" | "RECURRENT_UNKNOWN_FREQUENCY";
  /**
   * When a relative datetime which resolves into a range is being used as the
   * endpoint of a range (begin_relative/end_relative), its begin/end will be
   * taken accordingly unless this modifier indicates the opposite:
   * begin_relative with relative range and modifier == AFTER means that its end
   * will be taken as the beginning of the resulting range. Similarly,
   * end_relative with a relative range and modifier == BEFORE means that its
   * begin will be taken as the end of the resulting range. E.g. "after next
   * month" will be a range with a begin_relative that will take the end of
   * "next month" as its starting point (exclusive). values other than AFTER and
   * BEFORE in the specific conditions explained here will be ignored and have
   * no effect in the resolution of RelativeDateTimes.
   */
  modifier?:  | "NO_MOD" | "BEFORE" | "AFTER" | "ON_OR_BEFORE" | "ON_OR_AFTER" | "LESS_THAN" | "MORE_THAN" | "EQUAL_OR_LESS" | "EQUAL_OR_MORE" | "START" | "MID" | "END" | "APPROX" | "ADD" | "SUBTRACT";
  shifted?: NlpSemanticParsingDatetimeShiftedRelativeDateTime;
}

function serializeNlpSemanticParsingDatetimeRelativeDateTime(data: any): NlpSemanticParsingDatetimeRelativeDateTime {
  return {
    ...data,
    fetched: data["fetched"] !== undefined ? serializeNlpSemanticParsingDatetimeFetchedRelativeDateTime(data["fetched"]) : undefined,
    shifted: data["shifted"] !== undefined ? serializeNlpSemanticParsingDatetimeShiftedRelativeDateTime(data["shifted"]) : undefined,
  };
}

function deserializeNlpSemanticParsingDatetimeRelativeDateTime(data: any): NlpSemanticParsingDatetimeRelativeDateTime {
  return {
    ...data,
    fetched: data["fetched"] !== undefined ? deserializeNlpSemanticParsingDatetimeFetchedRelativeDateTime(data["fetched"]) : undefined,
    shifted: data["shifted"] !== undefined ? deserializeNlpSemanticParsingDatetimeShiftedRelativeDateTime(data["shifted"]) : undefined,
  };
}

/**
 * Encapsulates metadata about the query span resolved here.
 */
export interface NlpSemanticParsingDatetimeResolutionProperties {
  /**
   * Simple enum container for exporting meridiem mentions. Note: this is
   * marked as deprecated as we are moving to properly parse expressions with
   * explicit meridiem information.
   */
  meridiem?:  | "INVALID_MERIDIEM" | "AM" | "PM";
  /**
   * Encodes whether the datetime was phrased in a specific way, see enum
   * above.
   */
  metadata?:  | "NO_METADATA" | "HOLIDAY" | "ORDINAL" | "WEEKEND" | "DECADE" | "MONTH" | "DAY_OF_WEEK" | "YEAR_NUMBER" | "MONTH_YEAR" | "PERSONAL" | "SEASON" | "WEE_HOURS_INFERRED" | "PROACTIVE_DEFAULT_TIME" | "PROACTIVE_DEFAULT_DATE" | "PROACTIVE_DEFAULT_DATETIME" | "HOUR_NUMBER" | "ASTRONOMICAL_EVENT" | "RECURRENT_UNKNOWN_FREQUENCY";
  /**
   * Expresses the relative DateTime query that gave rise to these grounded
   * semantics.
   */
  relative?: NlpSemanticParsingDatetimeRelativeDateTime;
}

function serializeNlpSemanticParsingDatetimeResolutionProperties(data: any): NlpSemanticParsingDatetimeResolutionProperties {
  return {
    ...data,
    relative: data["relative"] !== undefined ? serializeNlpSemanticParsingDatetimeRelativeDateTime(data["relative"]) : undefined,
  };
}

function deserializeNlpSemanticParsingDatetimeResolutionProperties(data: any): NlpSemanticParsingDatetimeResolutionProperties {
  return {
    ...data,
    relative: data["relative"] !== undefined ? deserializeNlpSemanticParsingDatetimeRelativeDateTime(data["relative"]) : undefined,
  };
}

export interface NlpSemanticParsingDatetimeShiftedRelativeDateTime {
  /**
   * The base could be an absolute datetime point for example: "March 1", a
   * relative datetime point, for example: "2 days before March 1" or a symbolic
   * base type, for example: CURRENT_DATETIME. This could also be used to
   * combine EXPLICIT_PRONOUN with the actual value of that reference being
   * setup as a datetime point in base or relative_base
   */
  base?: NlpSemanticParsingDatetimeAbsoluteDateTime;
  baseType?:  | "UNKNOWN" | "CURRENT_DATETIME" | "EXPLICIT_PRONOUN";
  /**
   * Can be used to tag relative datetime expressions with metadata information
   * in the grammar.
   */
  metadata?:  | "NO_METADATA" | "HOLIDAY" | "ORDINAL" | "WEEKEND" | "DECADE" | "MONTH" | "DAY_OF_WEEK" | "YEAR_NUMBER" | "MONTH_YEAR" | "PERSONAL" | "SEASON" | "WEE_HOURS_INFERRED" | "PROACTIVE_DEFAULT_TIME" | "PROACTIVE_DEFAULT_DATE" | "PROACTIVE_DEFAULT_DATETIME" | "HOUR_NUMBER" | "ASTRONOMICAL_EVENT" | "RECURRENT_UNKNOWN_FREQUENCY";
  relativeBase?: NlpSemanticParsingDatetimeResolutionProperties;
  shiftAmount?: NlpSemanticParsingDatetimeQuantity;
  /**
   * If true, shifting to the past; if false, shifting to the future.
   */
  shiftPast?: boolean;
}

function serializeNlpSemanticParsingDatetimeShiftedRelativeDateTime(data: any): NlpSemanticParsingDatetimeShiftedRelativeDateTime {
  return {
    ...data,
    base: data["base"] !== undefined ? serializeNlpSemanticParsingDatetimeAbsoluteDateTime(data["base"]) : undefined,
    relativeBase: data["relativeBase"] !== undefined ? serializeNlpSemanticParsingDatetimeResolutionProperties(data["relativeBase"]) : undefined,
  };
}

function deserializeNlpSemanticParsingDatetimeShiftedRelativeDateTime(data: any): NlpSemanticParsingDatetimeShiftedRelativeDateTime {
  return {
    ...data,
    base: data["base"] !== undefined ? deserializeNlpSemanticParsingDatetimeAbsoluteDateTime(data["base"]) : undefined,
    relativeBase: data["relativeBase"] !== undefined ? deserializeNlpSemanticParsingDatetimeResolutionProperties(data["relativeBase"]) : undefined,
  };
}

/**
 * The byte offset and text of a span.
 */
export interface NlpSemanticParsingDatetimeSpan {
  numBytes?: number;
  /**
   * 0-based start byte offset of the span.
   */
  startByte?: number;
  /**
   * The text of the span: a substring of ParserInput's canonical_input.
   */
  text?: string;
}

/**
 * Next field: 9
 */
export interface NlpSemanticParsingDatetimeTargetToFetch {
  event?: NlpSemanticParsingDatetimeEvent;
  fuzzyRange?:  | "NO_FUZZY_RANGE" | "FUZZY_RANGE_MORNING" | "FUZZY_RANGE_AFTERNOON" | "FUZZY_RANGE_EVENING" | "FUZZY_RANGE_NIGHT" | "FUZZY_RANGE_EVE" | "FUZZY_RANGE_DAYTIME" | "FUZZY_RANGE_DAWN" | "FUZZY_RANGE_DUSK" | "FUZZY_RANGE_NIGHTTIME" | "FUZZY_RANGE_EARLY_MORNING" | "FUZZY_RANGE_MID_MORNING" | "FUZZY_RANGE_LATE_MORNING" | "FUZZY_RANGE_EARLY_AFTERNOON" | "FUZZY_RANGE_MID_AFTERNOON" | "FUZZY_RANGE_LATE_AFTERNOON" | "FUZZY_RANGE_EARLY_EVENING" | "FUZZY_RANGE_MID_EVENING" | "FUZZY_RANGE_LATE_EVENING" | "FUZZY_RANGE_LATE_NIGHT" | "DELETED_11";
  month?:  | "NO_MONTH" | "JANUARY" | "FEBRUARY" | "MARCH" | "APRIL" | "MAY" | "JUNE" | "JULY" | "AUGUST" | "SEPTEMBER" | "OCTOBER" | "NOVEMBER" | "DECEMBER";
  quarter?:  | "INVALID_QUARTER" | "FIRST_QUARTER" | "SECOND_QUARTER" | "THIRD_QUARTER" | "FOURTH_QUARTER";
  reference?:  | "INVALID" | "CURRENT_DATETIME" | "CURRENT_TIME" | "CURRENT_DATE" | "RECENT" | "LATEST" | "NEXT_DAY" | "PREVIOUS_DAY" | "DAY_AFTER_NEXT" | "DAY_BEFORE_PREVIOUS";
  season?:  | "INVALID_SEASON" | "SPRING" | "SUMMER" | "FALL" | "WINTER" | "EARLY_SPRING" | "MID_SPRING" | "LATE_SPRING" | "EARLY_SUMMER" | "MID_SUMMER" | "LATE_SUMMER" | "EARLY_FALL" | "MID_FALL" | "LATE_FALL" | "EARLY_WINTER" | "MID_WINTER" | "LATE_WINTER";
  /**
   * Unnamed target: "week", "month" etc. E.g., "1st week of April".
   */
  unit?:  | "NO_UNIT" | "NANOSECOND" | "MICROSECOND" | "MILLISECOND" | "SECOND" | "MINUTE" | "HOUR" | "DAY" | "WEEK" | "TEN_DAY" | "HALF_MONTH" | "MONTH" | "QUARTER" | "HALF_YEAR" | "YEAR" | "DECADE" | "CENTURY" | "MILLENNIUM" | "NIGHT";
  /**
   * Named target: only one of the following is expected.
   */
  weekday?:  | "NO_DAY_OF_WEEK" | "SUNDAY" | "MONDAY" | "TUESDAY" | "WEDNESDAY" | "THURSDAY" | "FRIDAY" | "SATURDAY" | "WEEKEND"[];
}

export interface NlpSemanticParsingDatetimeTimeZone {
  timezone?: string;
}

export interface NlpSemanticParsingEntitySourceData {
  /**
   * Indicates backends from which parts of an entity were retrieved.
   */
  entitySources?:  | "UNKNOWN_ENTITY_SOURCE" | "QREF_PERSONAL_WALDREF" | "QREF_PERSONAL_TOPIC_SERVER" | "MYENTITIES_MODEL_T"[];
}

/**
 * Status indicating whether the user has finished expressing their intended
 * semantics during a streaming interaction. Semantics are partially expressed
 * when later, unprompted user input is expected to modify the semantics. Future
 * inputs are typically additional speech or continued modification of argument
 * text in form field. These inputs can trigger modifications including adding
 * arguments, changing the intent, or modifying existing arguments. Sensing this
 * status can be done both directly and indirectly. Fluid Actions directly
 * detects this status as the user moves between, or enters and leaves, argument
 * form fields. Understanding indirectly detects this status by the pace of the
 * user's speech, the semantics of the language, and the user's intonation. See
 * go/streaming-nlu-fulfilment-protocol-v1 for details about how it is used in
 * the Streaming NLU Fulfillment protocol.
 */
export interface NlpSemanticParsingExpressionStatus {
  status?:  | "EXPRESSION_STATUS_UNSPECIFIED" | "PARTIAL" | "COMPLETE" | "LIKELY_COMPLETE";
  /**
   * Completeness probability as calculated by the parser's completeness layer.
   */
  textCompletenessProbability?: number;
}

/**
 * A list of amenity constraints. There is an implicit AND relationship between
 * the different constraints.
 */
export interface NlpSemanticParsingLocalAmenities {
  /**
   * Applied amenity constraints. Nothing should be inferred about the ordering
   * of the values in this field.
   */
  type?:  | "UNKNOWN_TYPE" | "AIR_CONDITIONED" | "BAR" | "BEACH" | "BREAKFAST" | "FREE_BREAKFAST" | "FREE_PARKING" | "FREE_WIFI" | "GYM" | "HEATED_POOL" | "HOT_TUB" | "IN_ROOM_HOT_TUB" | "INDOOR_POOL" | "KID_FRIENDLY" | "NON_SMOKING" | "PET_FRIENDLY" | "POOL" | "RESTAURANT" | "SMOKING" | "TRUCK_PARKING" | "WIFI" | "DEAL" | "LAST_MINUTE" | "ALL_INCLUSIVE" | "PARKING" | "SPA" | "FREE_PET_FRIENDLY" | "WIFI_IN_ROOM" | "ALL_INCLUSIVE_ONLY" | "ROOM_SERVICE" | "OUTDOOR_POOL" | "HAS_24_HOUR_FRONT_DESK" | "FREE_GYM" | "MASSAGE" | "SAUNA" | "KIDS_ACTIVITIES" | "KIDS_CLUB" | "SUITE" | "BALCONY" | "BATHTUB" | "HOUSEKEEPING" | "DAILY_HOUSEKEEPING" | "DOG_FRIENDLY" | "THERMAL_POOL" | "TREADMILL" | "PRIVATE_BEACH" | "VIEW_OF_CITY" | "VIEW_OF_GARDEN" | "VIEW_OF_LAKE" | "VIEW_OF_LANDMARK" | "VIEW_OF_OCEAN" | "VIEW_OF_POOL" | "VIEW_OF_VALLEY" | "CASINO" | "KITCHEN" | "AVAILABLE_FOR_ESSENTIAL_WORKERS" | "FREE_CANCELLATION"[];
}

/**
 * Conceptually this describes one location. Technically, this is a sequence of
 * location elements with the intention that at least one element in the
 * sequence is an actual location (rather than a modifier).
 */
export interface NlpSemanticParsingLocalBasicLocation {
  element?: NlpSemanticParsingLocalLocationElement[];
}

function serializeNlpSemanticParsingLocalBasicLocation(data: any): NlpSemanticParsingLocalBasicLocation {
  return {
    ...data,
    element: data["element"] !== undefined ? data["element"].map((item: any) => (serializeNlpSemanticParsingLocalLocationElement(item))) : undefined,
  };
}

function deserializeNlpSemanticParsingLocalBasicLocation(data: any): NlpSemanticParsingLocalBasicLocation {
  return {
    ...data,
    element: data["element"] !== undefined ? data["element"].map((item: any) => (deserializeNlpSemanticParsingLocalLocationElement(item))) : undefined,
  };
}

/**
 * A high-level categorization of business types. Used for location elements
 * that are either BUSINESS_NAME or BUSINESS_CATEGORY. The business types
 * roughly correspond to QRef collections and should be interpreted broadly.
 * E.g., hotel also include motels, youth hostels, and guest houses; restaurants
 * includes bars and cafes, etc. Business types can be populated by QRef
 * collections; other population is done by grammar categories from
 * local_categories.grammar. It is expected that some business organizations
 * will match more than one business type. E.g., Safeway is both a grocery store
 * and a pharmacy. Next ID: 43 NOTE(oksana): LocalCategoryReliable grammar
 * over-rides a few business type queries to include hyper_reliable location
 * element. If you change this, please make sure that LocalCategoryReliable
 * grammar reflects this too. LINT.IfChange
 */
export interface NlpSemanticParsingLocalBusinessType {
  airline?: boolean;
  airport?: boolean;
  bank?: boolean;
  bikeSharingStation?: boolean;
  busStop?: boolean;
  clothingStore?: boolean;
  /**
   * If the element implies a cuisine type then we include the gcid string when
   * available. Currently this happens for BUSINESS_CATEGORY type. The field is
   * repeated to model categories like "mandarin buffet restaurant" with
   * multiple cuisine gcid's: mandarin_restaurant and buffet_restaurant.
   */
  cuisineGcid?: string[];
  departmentStore?: boolean;
  drugDropOff?: boolean;
  electricVehicleChargingStation?: boolean;
  electronicStore?: boolean;
  /**
   * This field is used to determine the emergency type of the element, which
   * is specified by the grammar parse in
   * (http://cs/file:googledata/localsearch/quality/grammar/local_patterns.asciipb).
   * e.g. "coronavirus_treatment_locations" TODO(b/151330576) Deprecate the
   * emergency field and replace with normal triggering.
   */
  emergency?: string;
  foodPantry?: boolean;
  gasStation?: boolean;
  groceryStore?: boolean;
  hairdresser?: boolean;
  hardwareStore?: boolean;
  hospital?: boolean;
  /**
   * Also youth hostels, guest houses, etc.
   */
  hotel?: boolean;
  parking?: boolean;
  petStore?: boolean;
  pharmacy?: boolean;
  /**
   * This is used for transit stations annotated by QRef. The transit_station
   * business_type above is only used for business categories, and therefore is
   * used downstream to find nearby stations rather than a particular station,
   * and so cannot be present in a Location that is a specific station from
   * QRef. For these cases, this business_type is used instead. e.g. "grand
   * central" "millbrae station" "union station" will have business_type
   * qref_transit_station
   */
  qrefTransitStation?: boolean;
  /**
   * Also bars and cafes
   */
  restaurant?: boolean;
  retail?: boolean;
  /**
   * Pre-k to high school
   */
  school?: boolean;
  shoppingCenter?: boolean;
  soupKitchen?: boolean;
  sportStore?: boolean;
  subwayStation?: boolean;
  telecom?: boolean;
  toyStore?: boolean;
  trainStation?: boolean;
  /**
   * A particular line in a transit system, e.g., "3 train", "Red Line", "Cirle
   * Line", etc.
   */
  transitLine?: boolean;
  /**
   * Operator of a transit line, e.g., "MTA", "BART", "CTA", etc.
   */
  transitOperator?: boolean;
  /**
   * The different types of transit station business types will be used to
   * figure out which vehicle types to use when querying Tripfinder's
   * SearchStations service. The stations in that backend seem to be divided
   * into HEAVY_RAIL, SUBWAY, and TRAM. There isn't a very reliable division
   * between intercity rail and commuter rail -- Amtrak, LIRR, PATH, and NJ
   * Transit are all classified as HEAVY_RAIL. That's why in these types we make
   * a distinction between train and subway, and not train and muni_rail,
   * (unlike TransitMode in the TravelAction proto).
   */
  transitStation?: boolean;
  /**
   * Also colleges
   */
  university?: boolean;
  /**
   * All of the vehicle types serviced by this business or business category.
   * e.g. VEHICLE_TYPE_RAIL and VEHICLE_TYPE__BUS for "transit stop". This
   * allows downstream to serve different result types for transit station
   * categories in different languages. e.g. In en-US "train station" seeks both
   * railway station and subway station results. But the equivalent word in
   * French/Italian/German seeks only railway stations.
   */
  vehicleType?:  | "VEHICLE_TYPE_ANY" | "VEHICLE_TYPE_RAIL" | "VEHICLE_TYPE_METRO_RAIL" | "VEHICLE_TYPE_SUBWAY" | "VEHICLE_TYPE_TRAM" | "VEHICLE_TYPE_MONORAIL" | "VEHICLE_TYPE_HEAVY_RAIL" | "VEHICLE_TYPE_COMMUTER_TRAIN" | "VEHICLE_TYPE_HIGH_SPEED_TRAIN" | "VEHICLE_TYPE_LONG_DISTANCE_TRAIN" | "VEHICLE_TYPE_BUS" | "VEHICLE_TYPE_INTERCITY_BUS" | "VEHICLE_TYPE_TROLLEYBUS" | "VEHICLE_TYPE_SHARE_TAXI" | "VEHICLE_TYPE_FERRY" | "VEHICLE_TYPE_CABLE_CAR" | "VEHICLE_TYPE_GONDOLA_LIFT" | "VEHICLE_TYPE_FUNICULAR" | "VEHICLE_TYPE_SPECIAL" | "VEHICLE_TYPE_HORSE_CARRIAGE" | "VEHICLE_TYPE_AIRPLANE"[];
  /**
   * Stadiums, theaters, cinemas, etc.
   */
  venue?: boolean;
}

/**
 * ChainMemberConstraint for chain filtering enabled queries.
 */
export interface NlpSemanticParsingLocalChainMemberConstraint {
  /**
   * Specifies which parent chain mids to filter by.
   */
  chainIds?: string[];
}

export interface NlpSemanticParsingLocalCompoundLocation {
  joiner?: NlpSemanticParsingLocalJoiner;
  location1?: NlpSemanticParsingLocalLocation;
  /**
   * If location_2 is absent, it should likely be interpreted as an implicit
   * "here". For example, "nearest Starbucks" will be represented as a compound
   * location with "Starbucks" as location_1, "nearest" as the joiner, and empty
   * location_2.
   */
  location2?: NlpSemanticParsingLocalLocation;
}

function serializeNlpSemanticParsingLocalCompoundLocation(data: any): NlpSemanticParsingLocalCompoundLocation {
  return {
    ...data,
    location1: data["location1"] !== undefined ? serializeNlpSemanticParsingLocalLocation(data["location1"]) : undefined,
    location2: data["location2"] !== undefined ? serializeNlpSemanticParsingLocalLocation(data["location2"]) : undefined,
  };
}

function deserializeNlpSemanticParsingLocalCompoundLocation(data: any): NlpSemanticParsingLocalCompoundLocation {
  return {
    ...data,
    location1: data["location1"] !== undefined ? deserializeNlpSemanticParsingLocalLocation(data["location1"]) : undefined,
    location2: data["location2"] !== undefined ? deserializeNlpSemanticParsingLocalLocation(data["location2"]) : undefined,
  };
}

/**
 * Contact information for the |contact_location| field in LocationElement.
 */
export interface NlpSemanticParsingLocalContactLocation {
  /**
   * Contact as a location.
   */
  contact?: NlpSemanticParsingModelsCommunicationRecipient;
  /**
   * The type of contact address (home, work, etc).
   */
  contactType?: NlpSemanticParsingModelsCommunicationPhoneType;
}

function serializeNlpSemanticParsingLocalContactLocation(data: any): NlpSemanticParsingLocalContactLocation {
  return {
    ...data,
    contact: data["contact"] !== undefined ? serializeNlpSemanticParsingModelsCommunicationRecipient(data["contact"]) : undefined,
  };
}

function deserializeNlpSemanticParsingLocalContactLocation(data: any): NlpSemanticParsingLocalContactLocation {
  return {
    ...data,
    contact: data["contact"] !== undefined ? deserializeNlpSemanticParsingModelsCommunicationRecipient(data["contact"]) : undefined,
  };
}

/**
 * Constraint for cuisine type, such as "chinese", "italian", "thai",
 * "burgers", etc.
 */
export interface NlpSemanticParsingLocalCuisineConstraint {
  cuisineGcid?: string;
}

export interface NlpSemanticParsingLocalEvChargingStationConnectorConstraint {
  connectorType?:  | "OTHER" | "J_1772" | "MENNEKES" | "CHADEMO" | "CCS_COMBO_1" | "CCS_COMBO_2" | "TESLA_ROADSTER" | "TESLA_S_HPWC" | "TESLA" | "GB_T" | "WALL_OUTLET";
}

/**
 * There is an implicit AND relation if multiple EVCS constraint types are
 * specified.
 */
export interface NlpSemanticParsingLocalEvChargingStationSpeedConstraint {
  chargingSpeed?:  | "UNKNOWN_CHARGING_SPEED" | "FAST_CHARGING_SPEED" | "VERY_FAST_CHARGING_SPEED";
}

export interface NlpSemanticParsingLocalExtent {
  /**
   * True for values like "a few".
   */
  nonSpecificValue?: boolean;
  units?:  | "METER" | "KILOMETER" | "FOOT" | "YARD" | "MILE" | "BLOCK" | "MINUTE" | "HOUR" | "OTHER_UNITS";
  /**
   * String representation, e.g., for debug.
   */
  unitsString?: string;
  /**
   * For approximate values such as "a few" or "several", we populate |value|
   * with a specific numeric value which is a generous (i.e., high)
   * interpretation of the text, and we set |non_specific_value| to true.
   */
  value?: number;
  /**
   * Can hold numbers as well as "a few".
   */
  valueString?: string;
}

export interface NlpSemanticParsingLocalGcidConstraint {
  /**
   * GCID - with the 'gcid:' prefix.
   */
  gcid?: string;
}

/**
 * Constraint for the health insurance network of a provider.
 */
export interface NlpSemanticParsingLocalHealthInsuranceConstraint {
  network?:  | "UNKNOWN_HEALTH_INSURANCE" | "ACCEPTS_MEDICARE" | "ACCEPTS_MEDICAID";
}

/**
 * Hotel Type used by the hotels team to differentiate sub classes of
 * accommodations. For any questions please contact hotel-search-quality@. Next
 * ID: 48
 */
export interface NlpSemanticParsingLocalHotelType {
  /**
   * Basic accommodation types variations.
   */
  allInclusiveResort?: boolean;
  beachResort?: boolean;
  bedAndBreakfast?: boolean;
  boutiqueHotel?: boolean;
  businessHotel?: boolean;
  /**
   * Other accommodation types.
   */
  cabin?: boolean;
  campsite?: boolean;
  capsuleHotel?: boolean;
  casinoAccommodation?: boolean;
  castleHotel?: boolean;
  chalet?: boolean;
  commonLodgingHouse?: boolean;
  condoHotel?: boolean;
  conventionHotel?: boolean;
  cottage?: boolean;
  ecoHotel?: boolean;
  extendedStayHotel?: boolean;
  farmstay?: boolean;
  gite?: boolean;
  golfResort?: boolean;
  guesthouse?: boolean;
  guestRanch?: boolean;
  hostel?: boolean;
  /**
   * Basic accommodation types.
   */
  hotel?: boolean;
  houseboat?: boolean;
  inn?: boolean;
  /**
   * Japanese accommodation types.
   */
  japaneseInn?: boolean;
  japaneseInnWithHotSpring?: boolean;
  lodge?: boolean;
  lodging?: boolean;
  loveHotel?: boolean;
  motel?: boolean;
  mountainHut?: boolean;
  /**
   * Any other lodging related type.
   */
  other?: boolean;
  pension?: boolean;
  resort?: boolean;
  safariLodge?: boolean;
  seasideResort?: boolean;
  servicedApartment?: boolean;
  skiResort?: boolean;
  suite?: boolean;
  vacationApartment?: boolean;
  vacationHouse?: boolean;
  /**
   * Vacation rental accommodation types.
   */
  vacationRental?: boolean;
  villa?: boolean;
  wellnessAndSpaAccommodation?: boolean;
  youthHostel?: boolean;
}

/**
 * Message containing information about hyper-reliable categories.
 * go/local-hyper-reliable
 */
export interface NlpSemanticParsingLocalHyperReliableData {
  /**
   * Whether a location is a commodity (distance is an important metric),
   * neutral or non-commodity (distance is not important). Commodity locations
   * are "atm", "gas station", etc. Non-commodity locations are "restaurant",
   * "hotel", etc, and all others are neutral. The value is 1 for commodity
   * queries, 0 for non-commodity queries, no-value for neutral queries (when
   * the field doesn't exist in the grammar). The reason it is a float is to
   * prepare for future changes when we expand the signal value from discrete
   * classes to a score, and the score will be in the range of [0,1].
   */
  commodityStrength?: number;
  gcidsynsOverride?: NlpSemanticParsingLocalHyperReliableDataGCIDSynsOverride[];
  hyperReliable?: boolean;
  /**
   * Categories used for retrieval and used in Artemis diversity tiers as
   * restricts. See https://ariane.googleplex.com/launch/190585 for details.
   */
  retrievalGcids?: string[];
}

/**
 * Set only when hyper_reliable is true. These are gcids and scores for
 * hyper-reliable categories in ariane/182060. These are overridden for a few
 * hyper-reliable categories, and may not be present everywhere.
 */
export interface NlpSemanticParsingLocalHyperReliableDataGCIDSynsOverride {
  gcidScore?: number;
  hyperReliableGcid?: string;
}

/**
 * Flags indiciating the specific implicit intent, e.g. dining, travel, etc.
 * Next ID = 13
 */
export interface NlpSemanticParsingLocalImplicitLocalCategory {
  airport?: boolean;
  bank?: boolean;
  chargingStation?: boolean;
  gasStation?: boolean;
  gym?: boolean;
  hairSalon?: boolean;
  hospital?: boolean;
  hotel?: boolean;
  laundromat?: boolean;
  movieTheater?: boolean;
  postOffice?: boolean;
  spa?: boolean;
}

export interface NlpSemanticParsingLocalJoiner {
  numBytes?: number;
  numBytesForConversion?: number;
  /**
   * The raw input span corresponding to this joiner.
   */
  startByte?: number;
  /**
   * Byte data added for conversion between this proto and IntentQuery in
   * LooseParser. Must not be used for downstream triggering.
   */
  startByteForConversion?: number;
  /**
   * The original joiner string from the tokenized query. Particularly
   * important if the type is OTHER.
   */
  text?: string;
  type?:  | "IN" | "NEAR" | "NEAREST" | "BETWEEN" | "JUNCTION" | "UNION" | "OTHER_JOINER" | "EMPTY_JOINER";
}

/**
 * This message holds all info the local assistant team will need to lookup a
 * LocalResult in search.
 */
export interface NlpSemanticParsingLocalLocalResultId {
  featureId?: GeostoreFeatureIdProto;
  /**
   * The full address of the result. This should be a verbose address string
   * that geocodes reliably.
   */
  geocodingAddress?: string;
  /**
   * The knowledge graph reference of the result.
   */
  kgMid?: string;
  /**
   * The position of the result.
   */
  position?: GeostorePointProto;
  /**
   * The position of the result, if it can't be expressed as a pointproto.
   */
  rect?: GeostoreRectProto;
}

function serializeNlpSemanticParsingLocalLocalResultId(data: any): NlpSemanticParsingLocalLocalResultId {
  return {
    ...data,
    featureId: data["featureId"] !== undefined ? serializeGeostoreFeatureIdProto(data["featureId"]) : undefined,
  };
}

function deserializeNlpSemanticParsingLocalLocalResultId(data: any): NlpSemanticParsingLocalLocalResultId {
  return {
    ...data,
    featureId: data["featureId"] !== undefined ? deserializeGeostoreFeatureIdProto(data["featureId"]) : undefined,
  };
}

/**
 * There are a few types of locations: - Basic locations are sequences of
 * location elements which can be either actual locations or modifiers. E.g.,
 * "Mountain View CA 94040" may be the sequence "Mountain View" (an actual
 * location), "CA" (an actual location, and "94040" (a numeric modifier). -
 * Compound locations: these are two locations combined by a joiner. E.g.,
 * "Target in Mountain View CA 94040" has the joiner "in" and two basic
 * locations ("Target", and "Mountain View CA 94040"). Note that the definition
 * is recursive, e.g., "Parking garage near Target in Mountain View". - Vicinity
 * location: indicates an area around a certain location. The area can be
 * defined by time or space. E.g., "within 1 hour of Palo Alto", "10 blocks from
 * Union Square", "a few miles from here". Next ID: 14 LINT.IfChange()
 */
export interface NlpSemanticParsingLocalLocation {
  /**
   * Exactly one of the location types should be populated.
   */
  basicLocation?: NlpSemanticParsingLocalBasicLocation;
  compoundLocation?: NlpSemanticParsingLocalCompoundLocation;
  /**
   * DEPRECATED. Instead, use LocationElement.contact_location.
   */
  contactLocation?: NlpSemanticParsingLocalContactLocation;
  /**
   * True if the location is merged, for example by CombineLocationsFn.
   */
  isMerged?: boolean;
  /**
   * The constraint includes various constraints on the location such as
   * amenities, price range, ratings, or attributes such as new, cheap, etc.
   * These constraints are a part of the location but are not modeled as
   * location elements and are not included in the location text. The
   * (debatable) motivation is that they do not stand on their own and are not
   * an intrinsic part of the location. Note on texts and spans. For a location
   * such as "kid friendly hotels with an indoor pool" we expect to get a basic
   * location with a single location element and two constraints: - For the
   * location element: - Both text and span match "hotels" - For the first
   * constraint: - Both text and span match "kid friendly" - For the second
   * constraint: - Both text and span match "indoor pool" - For the full
   * location: - text: "hotels" - span covers "kid friendly hotels with an
   * indoor pool"
   */
  locationConstraint?: NlpSemanticParsingLocalLocationConstraint[];
  numBytes?: number;
  /**
   * A LocalResult corresponding to the location the user specified, populated
   * by local dialog (generally following a search). This field will only be set
   * if the location is unambiguous, possibly following a series of
   * disambiguation turns of dialog.
   */
  resolvedLocalResult?: QualityDialogManagerLocalResult;
  /**
   * The span, in the raw input, which corresponds to this location, expressed
   * as a byte offset and byte size. This allows the extraction of the location
   * string as it appears in the raw text.
   */
  startByte?: number;
  /**
   * A string representation of the location. Depending on the annotators and
   * the location itself the string may represent the raw query, the
   * pre-processed query, or something else. As a non-trivial example, for
   * [target address mountain view] we will generate the text "target mountain
   * view" without "address". We make a best-effort to come up with a good
   * string, but make no formal guarantees. You should never present this text
   * directly to outside users.
   */
  text?: string;
  /**
   * A location info including featureId and lat/lng that uniquely identifies
   * the location the user specified.
   */
  userSpecifiedLocation?: KnowledgeVerticalsWeatherProtoUserSpecifiedLocation;
  vicinityLocation?: NlpSemanticParsingLocalVicinityLocation;
}

function serializeNlpSemanticParsingLocalLocation(data: any): NlpSemanticParsingLocalLocation {
  return {
    ...data,
    basicLocation: data["basicLocation"] !== undefined ? serializeNlpSemanticParsingLocalBasicLocation(data["basicLocation"]) : undefined,
    compoundLocation: data["compoundLocation"] !== undefined ? serializeNlpSemanticParsingLocalCompoundLocation(data["compoundLocation"]) : undefined,
    contactLocation: data["contactLocation"] !== undefined ? serializeNlpSemanticParsingLocalContactLocation(data["contactLocation"]) : undefined,
    resolvedLocalResult: data["resolvedLocalResult"] !== undefined ? serializeQualityDialogManagerLocalResult(data["resolvedLocalResult"]) : undefined,
    userSpecifiedLocation: data["userSpecifiedLocation"] !== undefined ? serializeKnowledgeVerticalsWeatherProtoUserSpecifiedLocation(data["userSpecifiedLocation"]) : undefined,
    vicinityLocation: data["vicinityLocation"] !== undefined ? serializeNlpSemanticParsingLocalVicinityLocation(data["vicinityLocation"]) : undefined,
  };
}

function deserializeNlpSemanticParsingLocalLocation(data: any): NlpSemanticParsingLocalLocation {
  return {
    ...data,
    basicLocation: data["basicLocation"] !== undefined ? deserializeNlpSemanticParsingLocalBasicLocation(data["basicLocation"]) : undefined,
    compoundLocation: data["compoundLocation"] !== undefined ? deserializeNlpSemanticParsingLocalCompoundLocation(data["compoundLocation"]) : undefined,
    contactLocation: data["contactLocation"] !== undefined ? deserializeNlpSemanticParsingLocalContactLocation(data["contactLocation"]) : undefined,
    resolvedLocalResult: data["resolvedLocalResult"] !== undefined ? deserializeQualityDialogManagerLocalResult(data["resolvedLocalResult"]) : undefined,
    userSpecifiedLocation: data["userSpecifiedLocation"] !== undefined ? deserializeKnowledgeVerticalsWeatherProtoUserSpecifiedLocation(data["userSpecifiedLocation"]) : undefined,
    vicinityLocation: data["vicinityLocation"] !== undefined ? deserializeNlpSemanticParsingLocalVicinityLocation(data["vicinityLocation"]) : undefined,
  };
}

/**
 * All the possible location constraints. This message is associated with a
 * location and can be nested accordingly. E.g., for a compound location the
 * constraint may be associated with the entire location or with either of the
 * two internal locations (loc_1 and loc_2). There is an implicit AND relation
 * between the different constraints. Next ID: 25.
 */
export interface NlpSemanticParsingLocalLocationConstraint {
  /**
   * LINT.IfChange
   */
  amenities?: NlpSemanticParsingLocalAmenities;
  chainMember?: NlpSemanticParsingLocalChainMemberConstraint;
  cuisine?: NlpSemanticParsingLocalCuisineConstraint;
  /**
   * Used for populating ElectricVehicleConnectorRefinement from QBF
   * go/evcs-qbf-connector
   */
  evcsConnectorConstraint?: NlpSemanticParsingLocalEvChargingStationConnectorConstraint;
  evcsSpeedConstraint?: NlpSemanticParsingLocalEvChargingStationSpeedConstraint;
  /**
   * Used for GCID filter. Unlike other grammar, for now this is populated in
   * Superroot (currently based on QBLD classification, and an allowlist of
   * GCID).
   */
  gcidConstraint?: NlpSemanticParsingLocalGcidConstraint;
  /**
   * Used for health insurance filter populator.
   */
  healthInsurance?: NlpSemanticParsingLocalHealthInsuranceConstraint;
  /**
   * Some constraints are also hyper-reliable, such as [brunch] and [coffee].
   */
  hyperReliableData?: NlpSemanticParsingLocalHyperReliableData;
  menuItem?: NlpSemanticParsingLocalMenuItem;
  new?: boolean;
  numBytes?: number;
  open24Hours?: boolean;
  price?: NlpSemanticParsingLocalPriceConstraint;
  quality?: NlpSemanticParsingLocalQualityConstraint;
  rooms?: NlpSemanticParsingLocalRoomConstraint;
  scalableAttribute?: NlpSemanticParsingLocalScalableAttribute;
  service?: NlpSemanticParsingLocalServiceConstraint;
  /**
   * The span, in the raw input, which corresponds to this constraint,
   * expressed as a byte offset and byte size.
   */
  startByte?: number;
  text?: string;
  /**
   * Experimental, may change.
   */
  ungroundedConstraint?: boolean;
  /**
   * Used to remove all constraints, e.g. [forget all the filters]
   */
  unspecified?: boolean;
  /**
   * Used for vaccine refinement: go/covid-vaccine-refinement.
   */
  vaccineType?:  | "UNKNOWN_VACCINE_TYPE" | "COVAXIN" | "JOHNSON_AND_JOHNSON" | "MODERNA" | "OXFORD_ASTRAZENECA" | "PFIZER" | "SPUTNIK" | "ZYCOV_D" | "COVISHIELD" | "CORBEVAX" | "PFIZER_BOOSTER" | "MODERNA_BOOSTER";
  visitHistory?: NlpSemanticParsingLocalVisitHistoryConstraint;
}

/**
 * Next ID: 26 LINT.IfChange
 */
export interface NlpSemanticParsingLocalLocationElement {
  /**
   * For elements with a NICKNAME alias location, this field will hold all
   * matching alias icons, which are used in search to resolve the location.
   */
  aliasIcon?: PersonalizationMapsAliasIcon[];
  /**
   * The following fields (alias_location, qref_location, and saft_location)
   * should have at most one non-empty value between them.
   */
  aliasLocation?:  | "UNDEFINED" | "HERE" | "HOME" | "WORK" | "NICKNAME" | "NEXT_DESTINATION";
  /**
   * Set only when type is BUSINESS_NAME or BUSINESS_CATEGORY.
   */
  businessType?: NlpSemanticParsingLocalBusinessType;
  contactLocation?: NlpSemanticParsingLocalContactLocation;
  /**
   * This will hold semantics from the dialog_referents subgrammar with offsets
   * and indices relating to a list of results shown to the user. This field is
   * repeated while in the future we could support multiple item list selection.
   * i.e. [the starbucks] where multiple entries in the results will be
   * indicated here
   */
  dialogReferents?: NlpSemanticParsingModelsDialogReferentsDialogReferents[];
  /**
   * Set only when type is DIRECTIONAL_MODIFIER.
   */
  directionalModifier?:  | "NORTH" | "SOUTH" | "EAST" | "WEST" | "NORTHEAST" | "SOUTHEAST" | "NORTHWEST" | "SOUTHWEST" | "DOWNTOWN" | "INBOUND" | "UPTOWN" | "OUTBOUND" | "CLOCKWISE" | "COUNTERCLOCKWISE";
  /**
   * DEPRECATED. See basic_location.element.type == LOCATION_REFERENT to
   * determine this instead. Populated by a type VISITED local action, this
   * field is used to indicate a location element is a general-case
   * $PT_visited_location string.
   */
  genericLocation?: boolean;
  /**
   * Set only when business_type is hotel.
   */
  hotelType?: NlpSemanticParsingLocalHotelType;
  hyperReliableData?: NlpSemanticParsingLocalHyperReliableData;
  implicitLocalCategory?: NlpSemanticParsingLocalImplicitLocalCategory;
  /**
   * A field used to store the ID of a specific location entity, especially one
   * not extracted via QRef. For example, - a location selected by the users via
   * a dialog follow-up query like [the second one]. Will only be populated in
   * the LocalSemanticsServlet, not in the grammar. - a location resolved based
   * on a full search, e.g., following the geocoding step for a directions
   * query. This field is also used by NoramlizeLocationForFingerprinting as the
   * canonical place to store FeatureIds.
   */
  localResultId?: NlpSemanticParsingLocalLocalResultId;
  /**
   * Represents zip codes, street numbers, etc. that were detected directly by
   * the grammar (and not, e.g., by QRef). DEPRECATED. We ran into problems with
   * zip codes having leading zeroes. Now we store numbers only in the text
   * field.
   */
  number?: number;
  numBytes?: number;
  /**
   * A collection of QRefAnnotations repesenting Reference and Resolution data
   * for Personal References. See go/copley-local and go/copley-annotator.
   */
  personalReferenceLocation?: NlpSemanticParsingPersonalReferenceAnnotation;
  qrefLocation?: NlpSemanticParsingQRefAnnotation;
  saftLocation?: NlpSemanticParsingSaftMentionAnnotation;
  source?:  | "GRAMMAR" | "QREF" | "SAFT" | "GENIE" | "DIALOG" | "NIMBLE" | "ATTENTIONAL_ENTITY" | "LES" | "UNGROUNDED";
  /**
   * The byte span, in the raw query, which corresponds to this location
   * element.
   */
  startByte?: number;
  /**
   * A string representation of the location element. Typical, this field will
   * be populated by the MakeLocationElementFn semantic function with the
   * substring of the raw_query defined by start_byte and num_bytes. However,
   * the field can also be populated explicitly in the grammar, in which case
   * MakeLocationElementFn leaves it alone.
   */
  text?: string;
  /**
   * Train number associated with /collection/geo/transit_line. Populated when
   * user requests specific instance of a transit line. For example, long
   * distance trains in India have two numbers for each train, one for up
   * direction and other for down. And user use these numbers in queries along
   * with name to specify the specific trip of the train. More details in
   * go/number-transit-line-queries.
   */
  transitLineNumber?: string;
  type?:  | "PLACE_NAME" | "BUSINESS_NAME" | "BUSINESS_CATEGORY" | "ALIAS" | "GEO_MODIFIER" | "DIRECTIONAL_MODIFIER" | "NUMBER_MODIFIER" | "DETERMINER" | "ZIP_CODE" | "PERSONAL_MODIFIER" | "TEXT" | "PUNCTUATION" | "STREET_NAME" | "HIGHWAY_NAME" | "OLC" | "CONTACT" | "CONTACT_AND_ALIAS" | "PERSONAL_PLACE_NAME" | "PERSONAL_REFERENCE" | "UNGROUNDED_LOCATION" | "LATITUDE_LONGITUDE" | "DIALOG_REFERENT" | "LOCATION_REFERENT";
}

function serializeNlpSemanticParsingLocalLocationElement(data: any): NlpSemanticParsingLocalLocationElement {
  return {
    ...data,
    aliasIcon: data["aliasIcon"] !== undefined ? data["aliasIcon"].map((item: any) => (serializePersonalizationMapsAliasIcon(item))) : undefined,
    contactLocation: data["contactLocation"] !== undefined ? serializeNlpSemanticParsingLocalContactLocation(data["contactLocation"]) : undefined,
    localResultId: data["localResultId"] !== undefined ? serializeNlpSemanticParsingLocalLocalResultId(data["localResultId"]) : undefined,
    personalReferenceLocation: data["personalReferenceLocation"] !== undefined ? serializeNlpSemanticParsingPersonalReferenceAnnotation(data["personalReferenceLocation"]) : undefined,
    qrefLocation: data["qrefLocation"] !== undefined ? serializeNlpSemanticParsingQRefAnnotation(data["qrefLocation"]) : undefined,
  };
}

function deserializeNlpSemanticParsingLocalLocationElement(data: any): NlpSemanticParsingLocalLocationElement {
  return {
    ...data,
    aliasIcon: data["aliasIcon"] !== undefined ? data["aliasIcon"].map((item: any) => (deserializePersonalizationMapsAliasIcon(item))) : undefined,
    contactLocation: data["contactLocation"] !== undefined ? deserializeNlpSemanticParsingLocalContactLocation(data["contactLocation"]) : undefined,
    localResultId: data["localResultId"] !== undefined ? deserializeNlpSemanticParsingLocalLocalResultId(data["localResultId"]) : undefined,
    personalReferenceLocation: data["personalReferenceLocation"] !== undefined ? deserializeNlpSemanticParsingPersonalReferenceAnnotation(data["personalReferenceLocation"]) : undefined,
    qrefLocation: data["qrefLocation"] !== undefined ? deserializeNlpSemanticParsingQRefAnnotation(data["qrefLocation"]) : undefined,
  };
}

/**
 * Specifies intent that corresponds to a menu item which is used as a location
 * constraint, e.g. [restaurants that serve thai curry] or as a standalone
 * categorical element, e.g. [thai curry].
 */
export interface NlpSemanticParsingLocalMenuItem {
  /**
   * This ID corresponds to the name of the menu item in the query. For example
   * [restaurants that serve thai curry] has menu_item_id = "thai curry".
   */
  menuItemId?: string;
}

export interface NlpSemanticParsingLocalPriceConstraint {
  cheap?: boolean;
  /**
   * The currency codes are expected to be string from the list in
   * i18n/identifiers/currencycode.*
   */
  currencyCode?: string;
  expensive?: boolean;
  maxPrice?: number;
  minPrice?: number;
  moderatelyPriced?: boolean;
  /**
   * The user mentioned something about price, but didn't mention a specific
   * constraint. This is used to indicate an intent to remove all price
   * constraints, in queries like [forget the price].
   */
  unspecified?: boolean;
}

/**
 * Quality constraints about the establishment. In the future we can add to
 * this message Zagat ratings, user reviews, etc. Next ID: 6.
 */
export interface NlpSemanticParsingLocalQualityConstraint {
  best?: boolean;
  highlyRated?: boolean;
  stars?: NlpSemanticParsingLocalStarRatings;
  starType?:  | "HOTEL_CLASS" | "USER_RATING";
  /**
   * The user mentioned something about quality, but didn't mention a specific
   * constraint. This is used to indicate an intent to remove all quality
   * constraints, in queries like [forget the rating].
   */
  unspecified?: boolean;
}

/**
 * Constraints for the occupancy of a hotel or vacation rental.
 */
export interface NlpSemanticParsingLocalRoomConstraint {
  /**
   * It is possible to have fractional bathrooms.
   */
  minNumBathrooms?: number;
  minNumBedrooms?: number;
}

/**
 * Specifies intent that corresponds to a scalable attribute. This may be used
 * as a location constraint, e.g. [restaurants with outdoor seating] or as a
 * standalone categorical element, e.g. [happy hour] or [happy hour ny]. See
 * go/scalable-attributes for details about scalable attributes. NOTE(oksana):
 * LocalCategoryReliable grammar over-rides a few scalable attribute queries to
 * include hyper_reliable location element. If you change this, please make sure
 * that LocalCategoryReliable grammar reflects this too. LINT.IfChange This ID
 * corresponds to the id field in
 * //geostore/attributes/proto/config.proto:AttributeConfigProto This field
 * holds the human readable ID for the KG topic that represents the attribute.
 * Example: "/geo/type/establishment_poi/serves_breakfast"
 */
export interface NlpSemanticParsingLocalScalableAttribute {
  attributeId?: string;
}

export interface NlpSemanticParsingLocalServiceConstraint {
  serviceType?:  | "SERVICE_TYPE_UNSPECIFIED" | "ACCESS" | "BRUNCH" | "DELIVERY" | "DRIVE_THROUGH" | "KITCHEN" | "HAPPY_HOUR" | "PICKUP" | "SENIOR_ONLY" | "TAKEOUT";
}

/**
 * Star ratings constraints, mostly relevant for hotels. There is an implicit
 * OR relation between these. E.g., for "three star or four star hotel" both
 * three and four would be set to true. Next Available ID: 13.
 */
export interface NlpSemanticParsingLocalStarRatings {
  five?: boolean;
  four?: boolean;
  fourAndAHalf?: boolean;
  one?: boolean;
  oneAndAHalf?: boolean;
  orFewer?: boolean;
  /**
   * If this field is set, exactly one of the star classes above should be set,
   * and the interpretation should be that at least that many stars should be
   * present.
   */
  orMore?: boolean;
  three?: boolean;
  threeAndAHalf?: boolean;
  two?: boolean;
  twoAndAHalf?: boolean;
  unspecified?: boolean;
}

export interface NlpSemanticParsingLocalVicinityLocation {
  /**
   * If the base is missing then clients should assume that it implicitly means
   * "here". E.g., "within five miles" really means "within five miles from
   * here"
   */
  base?: NlpSemanticParsingLocalLocation;
  /**
   * The text between the extent and the base, e.g., for "50 miles from here"
   * the connector is "from".
   */
  connector?: string;
  extent?: NlpSemanticParsingLocalExtent;
}

function serializeNlpSemanticParsingLocalVicinityLocation(data: any): NlpSemanticParsingLocalVicinityLocation {
  return {
    ...data,
    base: data["base"] !== undefined ? serializeNlpSemanticParsingLocalLocation(data["base"]) : undefined,
  };
}

function deserializeNlpSemanticParsingLocalVicinityLocation(data: any): NlpSemanticParsingLocalVicinityLocation {
  return {
    ...data,
    base: data["base"] !== undefined ? deserializeNlpSemanticParsingLocalLocation(data["base"]) : undefined,
  };
}

/**
 * Constraint for visited, as in if a location has been visited before.
 */
export interface NlpSemanticParsingLocalVisitHistoryConstraint {
  visitedType?:  | "UNKNOWN_VISITED_TYPE" | "VISITED" | "NOT_VISITED";
}

/**
 * The type of contact (mobile, home, work, etc). NOTE: Unfortunately the name
 * of this message is a misnomer. Contact type would be a better name.
 */
export interface NlpSemanticParsingModelsCommunicationPhoneType {
  /**
   * Required, but should only be used inside Aqua and must not be used by
   * outside clients!!
   */
  evalData?: NlpSemanticParsingAnnotationEvalData;
  /**
   * Whether the annotation is from $Text.
   */
  isAnnotatedFromText?: boolean;
  /**
   * Normalized (canonicalized) text, e.g. "mobile".
   */
  normalizedText?: string;
  /**
   * Original text in query, e.g. "cell".
   */
  originalText?: string;
  /**
   * DEPRECATED. Used original_text instead.
   */
  rawText?: string;
}

/**
 * It can be a contact (person name), a business name, an email address or a
 * phone number. NOTE: Unfortunately the name of this message is not generic
 * enough. Contact would be a better name.
 */
export interface NlpSemanticParsingModelsCommunicationRecipient {
  calendarEvent?: AssistantApiCoreTypesCalendarEvent;
  calendarEventWrapper?: AssistantApiCoreTypesCalendarEventWrapper;
  /**
   * Contact details (e.g. gaia_id, phone, etc). Replaces 'focus_name' above.
   */
  contact?: NlpSemanticParsingModelsPersonPerson;
  /**
   * Required, but should only be used inside Aqua and must not be used by
   * outside clients!!
   */
  evalData?: NlpSemanticParsingAnnotationEvalData;
  isAnnotatedFromText?: boolean;
  /**
   * Deprecated in favor of recipient.contact.name_annotation_source.
   */
  nameAnnotationSource?:  | "UNKNOWN_NAME_ANNOTATOR" | "FOCUS_NAME" | "DEVICE_CONTACT" | "SAFT_PERSON" | "NAME_DETECTION_PERSON" | "NAME_PERSON" | "MANUAL_RULES" | "SAFT_POS" | "TEXT";
  numberAnnotationSource?:  | "UNKNOWN_NUMBER_ANNOTATOR" | "PHONE_NUMBER_ANNOTATOR" | "NUMBER_ANNOTATOR" | "MANUAL";
  /**
   * NOTE: for CONTACT recipient, this is *NOT* the real raw text of the
   * recipient span of historical reasons. Major differences includes: -
   * stripping possessive suffix, e.g. "John's" -> "John" - stripping
   * prefix/suffix/title, e.g. "Mr. John" -> "John" - uninflect name for
   * languages like Russian, e.g. "" -> "" Currently this is the
   * same as .contact.name, and is used as the string shown to the user on
   * clientside UI. If you're looking for real raw text, use .contact.raw_text
   */
  rawText?: string;
  recipientType?:  | "CONTACT" | "BUSINESS" | "EMAIL_ADDRESS" | "PHONE_NUMBER" | "AMBIGUOUS" | "CALENDAR_EVENT" | "CALENDAR_EVENT_WRAPPER";
  /**
   * A reference to a person by relationship name. eg. my father.
   */
  relationship?: NlpSemanticParsingModelsCommunicationRelationshipArgument;
  sensitiveNumBytes?: number;
  /**
   * The beginning and end of the recipient name that should be removed before
   * logging.
   */
  sensitiveStartByte?: number;
}

function serializeNlpSemanticParsingModelsCommunicationRecipient(data: any): NlpSemanticParsingModelsCommunicationRecipient {
  return {
    ...data,
    calendarEvent: data["calendarEvent"] !== undefined ? serializeAssistantApiCoreTypesCalendarEvent(data["calendarEvent"]) : undefined,
    contact: data["contact"] !== undefined ? serializeNlpSemanticParsingModelsPersonPerson(data["contact"]) : undefined,
  };
}

function deserializeNlpSemanticParsingModelsCommunicationRecipient(data: any): NlpSemanticParsingModelsCommunicationRecipient {
  return {
    ...data,
    calendarEvent: data["calendarEvent"] !== undefined ? deserializeAssistantApiCoreTypesCalendarEvent(data["calendarEvent"]) : undefined,
    contact: data["contact"] !== undefined ? deserializeNlpSemanticParsingModelsPersonPerson(data["contact"]) : undefined,
  };
}

/**
 * A relationship contact.
 */
export interface NlpSemanticParsingModelsCommunicationRelationshipArgument {
  /**
   * The alias of the relationship in the query, e.g. "mom".
   */
  alias?: string;
  /**
   * The canonical format of the relationship, e.g. "Mother".
   */
  canonical?: string;
  /**
   * Mid for an entity that has lexical data (a LexiconEntry). See
   * https://g3doc.corp.google.com/nlp/generation/g3doc/lexical_data.md for for
   * more information about lexical data. This is the canonical mid for this
   * entity (eg. it would be /m/0lbxz for "mother" in EN even if user referred
   * to "mom").
   */
  canonicalLexicalMid?: string;
}

/**
 * The device to perform an action. Both device_type and device_name are
 * optional and they can coexist: [on my phone]: device_type = PHONE [on my
 * nexus 4]: device_name = "nexus 4" [on my nexus phone]: device_type = PHONE,
 * device_name = "nexus"
 */
export interface NlpSemanticParsingModelsDevice {
  /**
   * The name of the device (Nexus 5, Nexus 10, etc).
   */
  deviceName?: NlpSemanticParsingModelsDeviceName;
  /**
   * The type of the device (phone, tablet, watch, etc).
   */
  deviceType?:  | "UNKNOWN" | "PHONE" | "TABLET" | "WATCH";
}

/**
 * The name of the device (Nexus 5, Nexus 10, etc).
 */
export interface NlpSemanticParsingModelsDeviceName {
  /**
   * Required, but should only be used inside Aqua and must not be used by
   * outside clients!!
   */
  evalData?: NlpSemanticParsingAnnotationEvalData;
  rawText?: string;
}

/**
 * Will be used by dialog_referent subgrammar to emit types annotations from
 * DialogReferentsAnnotator and $DialogReferentOrdinal rules.
 */
export interface NlpSemanticParsingModelsDialogReferentsDialogReferents {
  evalData?: NlpSemanticParsingAnnotationEvalData;
  /**
   * The field mentioned in the user's utterance, if any.
   */
  field?: NlpSemanticParsingModelsDialogReferentsListSelection;
  /**
   * Used for a grammar mention of an index.
   */
  index?: number;
  /**
   * Represents a tied referent in a different field of the same label
   */
  next?: NlpSemanticParsingModelsDialogReferentsDialogReferents;
  /**
   * The requested value(s) for selection from a list of alternatives.
   */
  selection?: NlpSemanticParsingModelsDialogReferentsListSelection[];
  /**
   * Set when the user's utterance refers to the (an) overall task/goal of the
   * dialog (e.g. "the meeting starts at 10 am" mentions the goal, "meeting").
   * The field is repeated in case the user ambiguously identifies a task (two
   * tasks named 'meeting').
   */
  taskMention?: NlpSemanticParsingModelsDialogReferentsListSelection[];
}

/**
 * Represents the user's selection from a list of alternatives.
 */
export interface NlpSemanticParsingModelsDialogReferentsListSelection {
  evalData?: NlpSemanticParsingAnnotationEvalData;
  /**
   * A unique identifier that is the canonical value for the chosen list item.
   * If we are selecting among fields, this is the field_id specified in the
   * corresponding DialogField.
   */
  id?: string;
  /**
   * If true, semantic function should look at watch actions in the following
   * display entity if the first one is not playable. This is useful for "Play
   * it" on entity page.
   */
  looseOffsetRestriction?: boolean;
  /**
   * The offset within the list, if know. If the list of values wasn't known
   * (e.g. from the discourse context) then the offset is a zero-based mapping
   * of the ordinal value of the selection ("first one" maps to zero; "last one"
   * to minus one).
   */
  offset?: number;
  /**
   * When the user selects a list value by name then this is the matched text
   * from the utterance. Note that, if the list of values is known, then the
   * aqua annotator should have mapped it to an offset.
   */
  rawText?: string;
}

/**
 * Example: "The White Album"
 */
export interface NlpSemanticParsingModelsMediaAlbumTitle {
  /**
   * Annotations from custom media annotator.
   */
  annotationList?: NlpSemanticParsingModelsMediaMediaAnnotationList;
  /**
   * Required, but should only be used inside Aqua and must not be used by
   * outside clients!!
   */
  evalData?: NlpSemanticParsingAnnotationEvalData;
  /**
   * If true, indicates the user wants their favorite album. Like [play my
   * favorite album my Eminem]
   */
  favorite?: boolean;
  /**
   * If true, indicates the user wants the first album. Like [play adele's
   * first album]
   */
  first?: boolean;
  /**
   * Is annotated by Nimble for the media Fast Path.
   */
  isFromFastPath?: boolean;
  /**
   * If true, indicates the user wants the latest album. Like, [play adele's
   * latest album]
   */
  latest?: boolean;
  /**
   * More from this album.
   */
  playMore?: boolean;
  qref?: NlpSemanticParsingQRefAnnotation;
  /**
   * Required, corresponds to the raw text, like "The White Album."
   */
  rawText?: string;
}

function serializeNlpSemanticParsingModelsMediaAlbumTitle(data: any): NlpSemanticParsingModelsMediaAlbumTitle {
  return {
    ...data,
    annotationList: data["annotationList"] !== undefined ? serializeNlpSemanticParsingModelsMediaMediaAnnotationList(data["annotationList"]) : undefined,
    qref: data["qref"] !== undefined ? serializeNlpSemanticParsingQRefAnnotation(data["qref"]) : undefined,
  };
}

function deserializeNlpSemanticParsingModelsMediaAlbumTitle(data: any): NlpSemanticParsingModelsMediaAlbumTitle {
  return {
    ...data,
    annotationList: data["annotationList"] !== undefined ? deserializeNlpSemanticParsingModelsMediaMediaAnnotationList(data["annotationList"]) : undefined,
    qref: data["qref"] !== undefined ? deserializeNlpSemanticParsingQRefAnnotation(data["qref"]) : undefined,
  };
}

/**
 * Represents a music recording (usually a song). Each populated field can be
 * thought of as additional constraint about the song's identity. For instance,
 * if no fields are set, then this represents "some song." If only the
 * music_artist is set, then it represents "some song by the specified
 * music_artist." Inspired (but not strictly adhered to)
 * http://schema.org/MusicRecording Next ID: 22
 */
export interface NlpSemanticParsingModelsMediaAudio {
  album?: NlpSemanticParsingModelsMediaAlbumTitle;
  artist?: NlpSemanticParsingModelsMediaMusicArtist;
  /**
   * Like an audio book. "Listen to (moby dick) audiobook"
   */
  book?: NlpSemanticParsingModelsMediaBook;
  /**
   * A date time constraint for audio entity, for example, "jazz station 1980".
   */
  dateTime?: NlpSemanticParsingDatetimeDateTime;
  /**
   * Constraining the query to some detail about the episode. Example: "listen
   * to episode (13) of this american life with (mike birbiglia)" would have the
   * 2 constraints in parens.
   */
  episodeConstraint?: NlpSemanticParsingModelsMediaEpisodeConstraint[];
  /**
   * Soundtrack or theme song (see score_type param that indicates whether the
   * user refers to a soundtrack or a theme song) of the game. "Play soundtrack
   * from (Deus Ex Human Revolution)".
   */
  game?: NlpSemanticParsingModelsMediaGame;
  genericMusic?: NlpSemanticParsingModelsMediaGenericMusic;
  genre?: NlpSemanticParsingModelsMediaMusicGenre;
  /**
   * Soundtrack or theme song (see score_type param that indicates whether the
   * user refers to a soundtrack or a theme song) of the movie. E.g. "Play (Let
   * It Go) from (Disney's Frozen)"
   */
  movie?: NlpSemanticParsingModelsMediaMovie;
  /**
   * News topic. "Listen to news about (Ukraine)"
   */
  newsTopic?: NlpSemanticParsingModelsMediaNewsTopic;
  /**
   * True when the query does not contains an explict audio name. E.g. When
   * user says "play" or "listen to".
   */
  noExplicitAudio?: boolean;
  playlist?: NlpSemanticParsingModelsMediaMusicPlaylist;
  /**
   * Podcast feeds. "Listen to (This American Life)"
   */
  podcast?: NlpSemanticParsingModelsMediaPodcast;
  radio?: NlpSemanticParsingModelsMediaRadio;
  /**
   * E.g. "play NPR radio", "Play BBC radio".
   */
  radioNetwork?: NlpSemanticParsingModelsMediaRadioNetwork;
  /**
   * The query for backends to use in search. e.g. for an user query of "play
   * kids song video on tv" from assistant, this field would be "kids song".
   * Note: there is no guarantee this field is populated; when it is not,
   * backends should fall back to "raw_text" fields in song, artist, album etc.
   */
  rawText?: string;
  /**
   * If any of movie, game or tv show fields is populated this field indicates
   * specific score type requested in the query. E.g. for [play soundtrack from
   * frozen] this field is SOUNDTRACK, for [play frozen song] this field is
   * THEME_SONG.
   */
  scoreType?:  | "UNKNOWN" | "SOUNDTRACK" | "THEME_SONG";
  /**
   * Constraining the query to some detail about the season. Example: "listen
   * to season 2 of serial"
   */
  seasonConstraint?: NlpSemanticParsingModelsMediaSeasonConstraint;
  song?: NlpSemanticParsingModelsMediaSong;
  /**
   * Optional tags associated with how the media entity should be played. For
   * example, this can be set to SEED_RADIO to signify that the user wants to
   * play a radio station seeded by the entity.
   */
  tag?:  | "UNKNOWN_TAG" | "SEED_RADIO" | "VIDEO_TAG" | "TOP_TRACKS" | "RECORDED" | "LIVE" | "FOLLOWED_BY_SEED_RADIO"[];
  /**
   * Soundtrack or theme song (see score_type param that indicates whether the
   * user refers to a soundtrack or a theme song) of the tv show. E.g. "Play
   * soundtrack from (Friends)".
   */
  tvShow?: NlpSemanticParsingModelsMediaTVShow;
}

function serializeNlpSemanticParsingModelsMediaAudio(data: any): NlpSemanticParsingModelsMediaAudio {
  return {
    ...data,
    album: data["album"] !== undefined ? serializeNlpSemanticParsingModelsMediaAlbumTitle(data["album"]) : undefined,
    artist: data["artist"] !== undefined ? serializeNlpSemanticParsingModelsMediaMusicArtist(data["artist"]) : undefined,
    book: data["book"] !== undefined ? serializeNlpSemanticParsingModelsMediaBook(data["book"]) : undefined,
    dateTime: data["dateTime"] !== undefined ? serializeNlpSemanticParsingDatetimeDateTime(data["dateTime"]) : undefined,
    episodeConstraint: data["episodeConstraint"] !== undefined ? data["episodeConstraint"].map((item: any) => (serializeNlpSemanticParsingModelsMediaEpisodeConstraint(item))) : undefined,
    game: data["game"] !== undefined ? serializeNlpSemanticParsingModelsMediaGame(data["game"]) : undefined,
    genericMusic: data["genericMusic"] !== undefined ? serializeNlpSemanticParsingModelsMediaGenericMusic(data["genericMusic"]) : undefined,
    genre: data["genre"] !== undefined ? serializeNlpSemanticParsingModelsMediaMusicGenre(data["genre"]) : undefined,
    movie: data["movie"] !== undefined ? serializeNlpSemanticParsingModelsMediaMovie(data["movie"]) : undefined,
    playlist: data["playlist"] !== undefined ? serializeNlpSemanticParsingModelsMediaMusicPlaylist(data["playlist"]) : undefined,
    podcast: data["podcast"] !== undefined ? serializeNlpSemanticParsingModelsMediaPodcast(data["podcast"]) : undefined,
    radio: data["radio"] !== undefined ? serializeNlpSemanticParsingModelsMediaRadio(data["radio"]) : undefined,
    radioNetwork: data["radioNetwork"] !== undefined ? serializeNlpSemanticParsingModelsMediaRadioNetwork(data["radioNetwork"]) : undefined,
    song: data["song"] !== undefined ? serializeNlpSemanticParsingModelsMediaSong(data["song"]) : undefined,
    tvShow: data["tvShow"] !== undefined ? serializeNlpSemanticParsingModelsMediaTVShow(data["tvShow"]) : undefined,
  };
}

function deserializeNlpSemanticParsingModelsMediaAudio(data: any): NlpSemanticParsingModelsMediaAudio {
  return {
    ...data,
    album: data["album"] !== undefined ? deserializeNlpSemanticParsingModelsMediaAlbumTitle(data["album"]) : undefined,
    artist: data["artist"] !== undefined ? deserializeNlpSemanticParsingModelsMediaMusicArtist(data["artist"]) : undefined,
    book: data["book"] !== undefined ? deserializeNlpSemanticParsingModelsMediaBook(data["book"]) : undefined,
    dateTime: data["dateTime"] !== undefined ? deserializeNlpSemanticParsingDatetimeDateTime(data["dateTime"]) : undefined,
    episodeConstraint: data["episodeConstraint"] !== undefined ? data["episodeConstraint"].map((item: any) => (deserializeNlpSemanticParsingModelsMediaEpisodeConstraint(item))) : undefined,
    game: data["game"] !== undefined ? deserializeNlpSemanticParsingModelsMediaGame(data["game"]) : undefined,
    genericMusic: data["genericMusic"] !== undefined ? deserializeNlpSemanticParsingModelsMediaGenericMusic(data["genericMusic"]) : undefined,
    genre: data["genre"] !== undefined ? deserializeNlpSemanticParsingModelsMediaMusicGenre(data["genre"]) : undefined,
    movie: data["movie"] !== undefined ? deserializeNlpSemanticParsingModelsMediaMovie(data["movie"]) : undefined,
    playlist: data["playlist"] !== undefined ? deserializeNlpSemanticParsingModelsMediaMusicPlaylist(data["playlist"]) : undefined,
    podcast: data["podcast"] !== undefined ? deserializeNlpSemanticParsingModelsMediaPodcast(data["podcast"]) : undefined,
    radio: data["radio"] !== undefined ? deserializeNlpSemanticParsingModelsMediaRadio(data["radio"]) : undefined,
    radioNetwork: data["radioNetwork"] !== undefined ? deserializeNlpSemanticParsingModelsMediaRadioNetwork(data["radioNetwork"]) : undefined,
    song: data["song"] !== undefined ? deserializeNlpSemanticParsingModelsMediaSong(data["song"]) : undefined,
    tvShow: data["tvShow"] !== undefined ? deserializeNlpSemanticParsingModelsMediaTVShow(data["tvShow"]) : undefined,
  };
}

/**
 * Metadata for an audiobook.
 */
export interface NlpSemanticParsingModelsMediaAudiobookInfo {
  /**
   * The MID of the audiobook entity (/book/book_edition).
   */
  audiobookMid?: string;
  authors?: string[];
  /**
   * The MID of the book entity (/book/book) which this audiobook is associated
   * with.
   */
  bookMid?: string;
  narrators?: string[];
}

/**
 * Example: "East of Eden"
 */
export interface NlpSemanticParsingModelsMediaBook {
  /**
   * Annotations from custom media annotator.
   */
  annotationList?: NlpSemanticParsingModelsMediaMediaAnnotationList;
  /**
   * Required, but should only be used inside Aqua and must not be used by
   * outside clients!!
   */
  evalData?: NlpSemanticParsingAnnotationEvalData;
  /**
   * Annotation comes from a text annotator. Needed to boost recall. Typically
   * need to be verified in superroot, and have separate scoring.
   */
  isAnnotatedFromText?: boolean;
  /**
   * If true, indicates the user wants the latest book. Like, [play Dan Brown's
   * latest book]
   */
  latest?: boolean;
  qref?: NlpSemanticParsingQRefAnnotation;
  /**
   * Required, corresponds to the raw text, like "East of Eden"
   */
  rawText?: string;
}

function serializeNlpSemanticParsingModelsMediaBook(data: any): NlpSemanticParsingModelsMediaBook {
  return {
    ...data,
    annotationList: data["annotationList"] !== undefined ? serializeNlpSemanticParsingModelsMediaMediaAnnotationList(data["annotationList"]) : undefined,
    qref: data["qref"] !== undefined ? serializeNlpSemanticParsingQRefAnnotation(data["qref"]) : undefined,
  };
}

function deserializeNlpSemanticParsingModelsMediaBook(data: any): NlpSemanticParsingModelsMediaBook {
  return {
    ...data,
    annotationList: data["annotationList"] !== undefined ? deserializeNlpSemanticParsingModelsMediaMediaAnnotationList(data["annotationList"]) : undefined,
    qref: data["qref"] !== undefined ? deserializeNlpSemanticParsingQRefAnnotation(data["qref"]) : undefined,
  };
}

/**
 * Media device. Like, Chromecast, TV or Chirp. When emitted from the
 * cast_device domain, you should expect it to be one of 3 different forms: 1)
 * Personal Device: The annotation comes from a device we found in the user's
 * home. device_id and name should be set, cast_device_type is set if device
 * type is mentioned in query. e.g. "Dima's Pineapple Chirp" device_id: FOOBAR
 * name: "Dima's Pineapple" cast_device_type: CHIRP 2) Common Device Name: The
 * annotation comes from a model of the common names of user's device. name and
 * cast_device_type should be set but device_id will not be. cast_device_type
 * can be UNKNOWN. e.g. "John's Living Room" name: "John's Living Room"
 * cast_device_type: UNKNOWN 3) Device Type: The annotation comes from a model
 * of common cast device types. Only cast_device_type will be set. e.g. "TV" or
 * "chromecast" cast_device_type: CHROMECAST Next ID: 9
 */
export interface NlpSemanticParsingModelsMediaCastDeviceAnnotation {
  castDeviceSource?:  | "COMMON_DEVICE_NAME" | "PERSONAL_DEVICE" | "DEVICE_TYPE";
  /**
   * This field is populated when the user says [play X on $cast_device] and we
   * know the type of $cast_device but cannot identify the exact device.
   */
  castDeviceType?:  | "UNKNOWN" | "CHROMECAST" | "AUDIOCAST" | "CHIRP" | "TV" | "SPEAKER" | "CAR" | "ORIGINATING_DEVICE" | "SMART_DISPLAY";
  /**
   * The timestamp that the device is linked with the user in milliseconds.
   * This is inherited from the corresponding assistant DeviceSettings as is.
   */
  creationTimestampMs?: bigint;
  /**
   * DEPRECATED: Please use device_identifier instead.
   */
  deviceId?: string;
  /**
   * The identification of the device. This field is populated when the user
   * says [play X on $device_name] and $device_name matches one of the devices
   * linked to user's account. } oneof Media Device
   */
  deviceIdentifier?: AssistantApiCoreTypesDeviceId;
  name?: string;
  /**
   * This field is populated when the user metioned quantification in the
   * query. E.g., "2" or "all".
   */
  quantification?: NlpSemanticParsingModelsMediaQuantification;
}

function serializeNlpSemanticParsingModelsMediaCastDeviceAnnotation(data: any): NlpSemanticParsingModelsMediaCastDeviceAnnotation {
  return {
    ...data,
    creationTimestampMs: data["creationTimestampMs"] !== undefined ? String(data["creationTimestampMs"]) : undefined,
  };
}

function deserializeNlpSemanticParsingModelsMediaCastDeviceAnnotation(data: any): NlpSemanticParsingModelsMediaCastDeviceAnnotation {
  return {
    ...data,
    creationTimestampMs: data["creationTimestampMs"] !== undefined ? BigInt(data["creationTimestampMs"]) : undefined,
  };
}

/**
 * Represents a localized price. Next ID: 3
 */
export interface NlpSemanticParsingModelsMediaCost {
  /**
   * Contains the standard code for the given type of currency. The value must
   * represent a valid i18n_identifiers::CurrencyCode.
   */
  currencyCode?: string;
  /**
   * Contains the price in a particular currency.
   */
  price?: number;
}

/**
 * Provider deeplink and associated metadata, in particular restrictions on
 * platform and user's subscription. Next ID: 18
 */
export interface NlpSemanticParsingModelsMediaDeeplinkInfo {
  /**
   * The type of the deeplink. Sometimes the deeplink is not only used for
   * playing media, but also used for other actions. For example, the deeplink
   * could be for playing a movie trailer from YouTube or recording a movie from
   * YouTube TV.
   */
  actionType?:  | "UNSPECIFIED" | "PLAY" | "PLAY_TRAILER" | "RECORD";
  /**
   * The upper-case, III country code, e.g., "US", in which the deeplink cannot
   * play. For possible values, see: google3/i18n/identifiers/regioncode.h
   * google3/java/com/google/i18n/identifiers/RegionCode.java For details on
   * converting to and from ISO country codes, see
   * http://iii-howto#GettingCanonRegionCodes.
   */
  blacklistedCountry?: string[];
  /**
   * The upper-case, III country code, e.g., "US", in which the deeplink can
   * play. If unset or has "earth" (b/72566951), means the deeplink can be used
   * world-wide except in |blacklisted_country| list. For possible values, see:
   * google3/i18n/identifiers/regioncode.h
   * google3/java/com/google/i18n/identifiers/RegionCode.java For details on
   * converting to and from ISO country codes, see
   * http://iii-howto#GettingCanonRegionCodes.
   */
  country?: string[];
  /**
   * Deeplink to the media. This deeplink is meant to be send to the provider
   * app on available platforms without any modifications. Required.
   */
  deeplink?: string;
  /**
   * Some providers give us an opaque, unstable deeplink to use at
   * execution-time. E.g. see
   * http://go/collab-ranking-nl-uri#heading=h.ndmdfw388tk3 Such a deeplink is
   * not useful for logging, caching, comparing to other candidate deeplinks,
   * etc. So most fulfillment code will want the traditional, stable deeplink
   * that can be interpreted, parsed, cached, etc (found in the "deeplink"
   * field, above). But this opaque, unstable deeplink (if non-empty) must be
   * included in the music initiation clientop.
   */
  deeplinkForExecution?: string;
  /**
   * Indicate whether the deeplink is compatible with credentials. If true, CCS
   * will not send the credentials to cast app. Currently this field is only
   * used for voice-follow on cases on smart displays.
   */
  incompatibleWithCredentials?: boolean;
  /**
   * List of offers that allow user to access the deeplink, that is if the list
   * contains PREMIUM_SUBSCRIPTION and BASIC_SUBSCRIPTION users that have either
   * premium or basic subscription can use the deeplink. If the list is empty it
   * means that there are no subscription restrictions.
   */
  offer?:  | "UNKNOWN_SUBSCRIPTION" | "NO_ACCOUNT_REQUIRED" | "FREE" | "BASIC_SUBSCRIPTION" | "PREMIUM_SUBSCRIPTION" | "PAY_PER_USE"[];
  /**
   * This field is only used when "offer" includes a PAY_PER_USE. When "offer"
   * includes a PAY_PER_USE, paid_offer_detail will contain offers for BUY and
   * RENT offer_types with associated cost info.
   */
  paidOfferDetail?: NlpSemanticParsingModelsMediaPaidOfferDetail[];
  /**
   * List of platforms that support the deeplink. If the list is empty it means
   * that there are no platform restrictions.
   */
  platform?:  | "UNKNOWN_PLATFORM" | "ANDROID_PLATFORM" | "CAST_AUDIO" | "CAST_VIDEO" | "IOS_PLATFORM" | "DESKTOP_WEB" | "MOBILE_WEB" | "CHROMECAST" | "ANDROID_TV" | "KAIOS_PLATFORM" | "MEDIA_3P_DEVICE"[];
  /**
   * Document scores which are used for ranking action links. Document scores
   * might come from CDOC in Raffia or other indexing systems. For example, for
   * web pages, the score shows how likely the web page (composite doc) which
   * generated this link refers to the given entity or how close a particular
   * entity is with the given composite doc. For the larger design, please see
   * go/ma_dedup. For PACIFIC_COLLAB_RANKING deeplink, the score is the
   * normalized confidence score returned by partner for fulfillment candidate.
   * For pivot candidates, the score is calculated with the index of the
   * alternative results.
   */
  score?: number;
  /**
   * Name of subscription packages which are granted access to this deeplink.
   * This is to match exactly the end users authentication system. This is to be
   * used if the offer is BASIC_SUBSCRIPTION or PREMIUM_SUBSCRIPTION. There can
   * be multiple packages -- the user needs only to authenticate with a single
   * package. For more information please see: go/subscription-package
   */
  subscriptionPackageName?: string[];
  /**
   * Tags associated with the content played by this deeplink. In the common
   * case, the deeplink is supposed to specify a music entity within the
   * provider's inventory, and the provider app should decide the actual content
   * based on the user's account profile (e.g., for a deeplink to an artist,
   * playing tracks from the artist or similar artists, and for a song, playing
   * the official album recording of the song). But in some cases, the deeplink
   * belong to special content. For example, for an artist a seed radio based on
   * the artist, and a live or karaoke version of a song. We use this field to
   * mark such special content types.
   */
  tag?:  | "UNKNOWN_TAG" | "SEED_RADIO" | "VIDEO_TAG" | "TOP_TRACKS" | "RECORDED" | "LIVE" | "FOLLOWED_BY_SEED_RADIO"[];
  /**
   * A time window in which the deeplink is valid. If not set, the deeplink is
   * considered valid.
   */
  validTimeWindow?: NlpSemanticParsingModelsMediaDeeplinkInfoTimeWindow;
  /**
   * DEPRECATED: This field is ignored by understanding and fulfillment.
   */
  vuiId?: string;
  /**
   * Additional info specific to YouTube Deeplink (if applicable).
   */
  youtubeDeeplinkInfo?: NlpSemanticParsingModelsMediaYouTubeDeeplinkInfo;
}

function serializeNlpSemanticParsingModelsMediaDeeplinkInfo(data: any): NlpSemanticParsingModelsMediaDeeplinkInfo {
  return {
    ...data,
    validTimeWindow: data["validTimeWindow"] !== undefined ? serializeNlpSemanticParsingModelsMediaDeeplinkInfoTimeWindow(data["validTimeWindow"]) : undefined,
  };
}

function deserializeNlpSemanticParsingModelsMediaDeeplinkInfo(data: any): NlpSemanticParsingModelsMediaDeeplinkInfo {
  return {
    ...data,
    validTimeWindow: data["validTimeWindow"] !== undefined ? deserializeNlpSemanticParsingModelsMediaDeeplinkInfoTimeWindow(data["validTimeWindow"]) : undefined,
  };
}

/**
 * Represents a time window expressed as a time range.
 */
export interface NlpSemanticParsingModelsMediaDeeplinkInfoTimeWindow {
  /**
   * Time in seconds since epoch.
   */
  endTimestamp?: bigint;
  /**
   * Time in seconds since epoch.
   */
  startTimestamp?: bigint;
}

function serializeNlpSemanticParsingModelsMediaDeeplinkInfoTimeWindow(data: any): NlpSemanticParsingModelsMediaDeeplinkInfoTimeWindow {
  return {
    ...data,
    endTimestamp: data["endTimestamp"] !== undefined ? String(data["endTimestamp"]) : undefined,
    startTimestamp: data["startTimestamp"] !== undefined ? String(data["startTimestamp"]) : undefined,
  };
}

function deserializeNlpSemanticParsingModelsMediaDeeplinkInfoTimeWindow(data: any): NlpSemanticParsingModelsMediaDeeplinkInfoTimeWindow {
  return {
    ...data,
    endTimestamp: data["endTimestamp"] !== undefined ? BigInt(data["endTimestamp"]) : undefined,
    startTimestamp: data["startTimestamp"] !== undefined ? BigInt(data["startTimestamp"]) : undefined,
  };
}

/**
 * Example: "the episode with all of the comedians". A free-form text
 * description of a media.
 */
export interface NlpSemanticParsingModelsMediaDescription {
  /**
   * Required, but should only be used inside Aqua and must not be used by
   * outside clients!!
   */
  evalData?: NlpSemanticParsingAnnotationEvalData;
  rawText?: string;
}

/**
 * Example: "latest" would constrain the episode to a certain ordinal.
 */
export interface NlpSemanticParsingModelsMediaEpisodeConstraint {
  /**
   * The absolute index of the episode. 1 is the first element and -1 is the
   * last element in the sequence, -2 is the second-to-last element, and so on.
   * Examples: "first episode" => 1 "3rd episode" => 3 "last episode" => -1
   */
  absoluteIndex?: number;
  /**
   * Date/time of the message. This could be an absolute date/time (e.g. find
   * my message from monday) or a date/time range (e.g. find my message in the
   * past four hours). This constrains *when* the episode came out.
   */
  dateTime?: NlpSemanticParsingDatetimeDateTime;
  /**
   * A description of the episode. Example: For the query: [listen to this
   * american life about cars] the description would be "cars"
   */
  description?: NlpSemanticParsingModelsMediaDescription;
  /**
   * Required, but should only be used inside Aqua and must not be used by
   * outside clients!!
   */
  evalData?: NlpSemanticParsingAnnotationEvalData;
  rawText?: string;
  /**
   * The relative index of the episode. Examples: "previous episode" => -1
   * "current episode" => 0 "next episode" => 1
   */
  relativeIndex?: number;
}

function serializeNlpSemanticParsingModelsMediaEpisodeConstraint(data: any): NlpSemanticParsingModelsMediaEpisodeConstraint {
  return {
    ...data,
    dateTime: data["dateTime"] !== undefined ? serializeNlpSemanticParsingDatetimeDateTime(data["dateTime"]) : undefined,
  };
}

function deserializeNlpSemanticParsingModelsMediaEpisodeConstraint(data: any): NlpSemanticParsingModelsMediaEpisodeConstraint {
  return {
    ...data,
    dateTime: data["dateTime"] !== undefined ? deserializeNlpSemanticParsingDatetimeDateTime(data["dateTime"]) : undefined,
  };
}

/**
 * Defines a frequency for a terrestrial radio station. For instance, 99.1 FM,
 * 730 AM, etc. Next ID: 4
 */
export interface NlpSemanticParsingModelsMediaFrequency {
  /**
   * The broadcast band used by the radio station.
   */
  band?:  | "AM" | "FM" | "DAB" | "UNSET";
  /**
   * Frequency in MHz (for FM) and KHz (for AM).
   */
  value?: number;
}

/**
 * Example: "Deus Ex Human Revolution"
 */
export interface NlpSemanticParsingModelsMediaGame {
  /**
   * Required, but should only be used inside Aqua and must not be used by
   * outside clients!!
   */
  evalData?: NlpSemanticParsingAnnotationEvalData;
  /**
   * Annotation comes from a text annotator. Needed to boost recall. Typically
   * need to be verified in superroot, and have separate scoring.
   */
  isAnnotatedFromText?: boolean;
  qref?: NlpSemanticParsingQRefAnnotation;
  /**
   * Required, corresponds to the raw text, like "Deus Ex Human Revolution"
   */
  rawText?: string;
}

function serializeNlpSemanticParsingModelsMediaGame(data: any): NlpSemanticParsingModelsMediaGame {
  return {
    ...data,
    qref: data["qref"] !== undefined ? serializeNlpSemanticParsingQRefAnnotation(data["qref"]) : undefined,
  };
}

function deserializeNlpSemanticParsingModelsMediaGame(data: any): NlpSemanticParsingModelsMediaGame {
  return {
    ...data,
    qref: data["qref"] !== undefined ? deserializeNlpSemanticParsingQRefAnnotation(data["qref"]) : undefined,
  };
}

/**
 * Example: "my library", "some music".
 */
export interface NlpSemanticParsingModelsMediaGenericMusic {
  /**
   * Annotations from custom media annotator. Deprecated - generic music
   * deeplinks should be added to the Provider config, not to the grammar.
   */
  annotationList?: NlpSemanticParsingModelsMediaMediaAnnotationList;
  /**
   * Required, but should only be used inside Aqua and must not be used by
   * outside clients!!
   */
  evalData?: NlpSemanticParsingAnnotationEvalData;
  /**
   * New music.
   */
  newMusic?: boolean;
  /**
   * Required, corresponds to the raw text, like "my tracks"
   */
  rawText?: string;
  type?:  | "UNKNOWN" | "MUSIC" | "LIBRARY" | "PROVIDER_SPECIFIC" | "PLAY_PROVIDER" | "RESUME_PROVIDER" | "NEW_MUSIC" | "STREAM" | "HISTORY" | "POSTS" | "LIKES" | "TRACKS" | "ALBUMS" | "ARTISTS" | "THUMBPRINT_RADIO" | "SOMETHING_ELSE" | "FLOW" | "SHUFFLE_RADIO" | "PLAYLISTS" | "RECENTLY_PLAYED";
}

function serializeNlpSemanticParsingModelsMediaGenericMusic(data: any): NlpSemanticParsingModelsMediaGenericMusic {
  return {
    ...data,
    annotationList: data["annotationList"] !== undefined ? serializeNlpSemanticParsingModelsMediaMediaAnnotationList(data["annotationList"]) : undefined,
  };
}

function deserializeNlpSemanticParsingModelsMediaGenericMusic(data: any): NlpSemanticParsingModelsMediaGenericMusic {
  return {
    ...data,
    annotationList: data["annotationList"] !== undefined ? deserializeNlpSemanticParsingModelsMediaMediaAnnotationList(data["annotationList"]) : undefined,
  };
}

/**
 * An object representing a latitude/longitude pair. More info in
 * https://cs.corp.google.com/piper///depot/google3/google/type/latlng.proto
 */
export interface NlpSemanticParsingModelsMediaLatLng {
  /**
   * The latitude in degrees. It must be in the range [-90.0, +90.0].
   */
  latitude?: number;
  /**
   * The longitude in degrees. It must be in the range [-180.0, +180.0].
   */
  longitude?: number;
}

/**
 * Annotation for media entities. Next ID: 17
 */
export interface NlpSemanticParsingModelsMediaMediaAnnotation {
  /**
   * Name of the artist (if applicable). Used for songs and albums.
   */
  artistName?: string;
  /**
   * Additional info specific to an audiobook (if applicable).
   */
  audiobookInfo?: NlpSemanticParsingModelsMediaAudiobookInfo;
  /**
   * Type of the media content. This field is not always populated, but only
   * when this annotation is used to represent an individual media item, e.g.,
   * when it is the value of an intent argument storing a media object to play.
   */
  contentType?:  | "MEDIA_CONTENT_TYPE_UNSPECIFIED" | "MUSIC_TRACK" | "MUSIC_ARTIST" | "MUSIC_ALBUM" | "PUBLIC_PLAYLIST" | "PERSONAL_PLAYLIST" | "MUSIC_PERSONALIZED_MIX" | "MUSIC_GENRE_MIX" | "MUSIC_SEED_RADIO" | "MUSIC_STATION" | "RADIO_STATION" | "RADIO_NETWORK" | "PODCAST_SERIES" | "PODCAST_GENERIC" | "PODCAST_GENRE" | "PODCAST_TOPIC" | "PODCAST_RESUME" | "PODCAST_EPISODE" | "VIDEO" | "MUSIC_VIDEO" | "VIDEO_RECOMMENDED_PLAYLIST" | "MUSIC_VIDEO_PERSONALIZED_PLAYLIST" | "TV_SHOW" | "TV_SHOW_SEASON" | "TV_SHOW_EPISODE" | "MOVIE" | "YOUTUBE_CHANNEL" | "TV_CHANNEL" | "SPORTS_TEAM_GAME" | "AUDIO_BOOK" | "AUDIO_STORY" | "YOUTUBE_VIDEO_PLAYLIST" | "TV_ARTIST" | "NEWS" | "VIDEO_GAME" | "DIRECTOR" | "ACTOR" | "MOVIE_SERIES" | "APP";
  /**
   * Images of the media.
   */
  image?: AssistantApiCoreTypesImage[];
  /**
   * Name of the media. Required.
   */
  name?: string;
  /**
   * Additional info specific to a news audio/video stream (if applicable).
   */
  newsInfo?: NlpSemanticParsingModelsMediaNewsInfo;
  /**
   * The personal ingestion engine.
   */
  personalDataIngestionEngine?:  | "UNKNOWN_INGESTION_ENGINE" | "PINTS" | "PACIFIC";
  /**
   * Visibility setting of the retrieved playlist.
   */
  playlistVisibility?:  | "UNSPECIFIED" | "VISIBILITY_PUBLIC" | "VISIBILITY_PRIVATE" | "VISIBILITY_UNLISTED";
  /**
   * Additional info specific to podcast stream (if applicable).
   */
  podcastInfo?: NlpSemanticParsingModelsMediaPodcastInfo;
  primaryEntityMid?: string;
  /**
   * List of providers and their deeplinks.
   */
  providerInfo?: NlpSemanticParsingModelsMediaMediaProviderInfo[];
  /**
   * Purchase info for purchased or preordered movies, episodes, seasons, tv
   * shows.
   */
  purchaseInfo?: NlpSemanticParsingModelsMediaPurchaseInfo;
  /**
   * Only one of these fields should be set depending on the type of the
   * content. oneof content_specific_info { Additional info specific to a radio
   * station (if applicable).
   */
  radioInfo?: NlpSemanticParsingModelsMediaRadioInfo;
  /**
   * Rental info for rented movies.
   */
  rentalInfo?: NlpSemanticParsingModelsMediaRentalInfo;
  source?:  | "UNKNOWN_SOURCE" | "USER_CREATED" | "FAVORITES" | "RECENT" | "PUBLIC" | "USER_OWNED" | "PROVIDER_CURATED" | "CLIENT_REPORTED";
  /**
   * Additional info specific to YouTube playlist (if applicable).
   */
  youtubePlaylistInfo?: NlpSemanticParsingModelsMediaYouTubePlaylistInfo;
}

function serializeNlpSemanticParsingModelsMediaMediaAnnotation(data: any): NlpSemanticParsingModelsMediaMediaAnnotation {
  return {
    ...data,
    image: data["image"] !== undefined ? data["image"].map((item: any) => (serializeAssistantApiCoreTypesImage(item))) : undefined,
    newsInfo: data["newsInfo"] !== undefined ? serializeNlpSemanticParsingModelsMediaNewsInfo(data["newsInfo"]) : undefined,
    podcastInfo: data["podcastInfo"] !== undefined ? serializeNlpSemanticParsingModelsMediaPodcastInfo(data["podcastInfo"]) : undefined,
    providerInfo: data["providerInfo"] !== undefined ? data["providerInfo"].map((item: any) => (serializeNlpSemanticParsingModelsMediaMediaProviderInfo(item))) : undefined,
    purchaseInfo: data["purchaseInfo"] !== undefined ? serializeNlpSemanticParsingModelsMediaPurchaseInfo(data["purchaseInfo"]) : undefined,
    rentalInfo: data["rentalInfo"] !== undefined ? serializeNlpSemanticParsingModelsMediaRentalInfo(data["rentalInfo"]) : undefined,
    youtubePlaylistInfo: data["youtubePlaylistInfo"] !== undefined ? serializeNlpSemanticParsingModelsMediaYouTubePlaylistInfo(data["youtubePlaylistInfo"]) : undefined,
  };
}

function deserializeNlpSemanticParsingModelsMediaMediaAnnotation(data: any): NlpSemanticParsingModelsMediaMediaAnnotation {
  return {
    ...data,
    image: data["image"] !== undefined ? data["image"].map((item: any) => (deserializeAssistantApiCoreTypesImage(item))) : undefined,
    newsInfo: data["newsInfo"] !== undefined ? deserializeNlpSemanticParsingModelsMediaNewsInfo(data["newsInfo"]) : undefined,
    podcastInfo: data["podcastInfo"] !== undefined ? deserializeNlpSemanticParsingModelsMediaPodcastInfo(data["podcastInfo"]) : undefined,
    providerInfo: data["providerInfo"] !== undefined ? data["providerInfo"].map((item: any) => (deserializeNlpSemanticParsingModelsMediaMediaProviderInfo(item))) : undefined,
    purchaseInfo: data["purchaseInfo"] !== undefined ? deserializeNlpSemanticParsingModelsMediaPurchaseInfo(data["purchaseInfo"]) : undefined,
    rentalInfo: data["rentalInfo"] !== undefined ? deserializeNlpSemanticParsingModelsMediaRentalInfo(data["rentalInfo"]) : undefined,
    youtubePlaylistInfo: data["youtubePlaylistInfo"] !== undefined ? deserializeNlpSemanticParsingModelsMediaYouTubePlaylistInfo(data["youtubePlaylistInfo"]) : undefined,
  };
}

/**
 * List of MediaAnnotation. Media annotators should use the MediaAnnotationList
 * to annotate spans instead of MediaAnnotation. This prevents exponential
 * explosion of interpretations (consider [play $song by $artist on $device])
 * and allows us to have simpler tests for grammar.
 */
export interface NlpSemanticParsingModelsMediaMediaAnnotationList {
  annotation?: NlpSemanticParsingModelsMediaMediaAnnotation[];
}

function serializeNlpSemanticParsingModelsMediaMediaAnnotationList(data: any): NlpSemanticParsingModelsMediaMediaAnnotationList {
  return {
    ...data,
    annotation: data["annotation"] !== undefined ? data["annotation"].map((item: any) => (serializeNlpSemanticParsingModelsMediaMediaAnnotation(item))) : undefined,
  };
}

function deserializeNlpSemanticParsingModelsMediaMediaAnnotationList(data: any): NlpSemanticParsingModelsMediaMediaAnnotationList {
  return {
    ...data,
    annotation: data["annotation"] !== undefined ? data["annotation"].map((item: any) => (deserializeNlpSemanticParsingModelsMediaMediaAnnotation(item))) : undefined,
  };
}

/**
 * A media provider and the deeplinks provided by the provider.
 * MediaProviderInfo is an abstraction for topics of multiple media related KG
 * types under /base/mediaasset domain and /media_common. It's often eligible
 * for topics of media related KG types like /broadcast/radio_station,
 * /film/film, /music/artist, /music/album, /music/recording_cluster,
 * /music/recording, /tv/tv_program, etc. See go/media-pq for design details.
 * Next ID: 6
 */
export interface NlpSemanticParsingModelsMediaMediaProviderInfo {
  /**
   * Deeplinks provided by the provider. If empty it indicates that the media
   * is unavailable with the provider, e.g. due to country restrictions or
   * limited catalog.
   */
  deeplinkInfo?: NlpSemanticParsingModelsMediaDeeplinkInfo[];
  /**
   * The unique and reverse unique provider enumerator in KG (e.g.,
   * "ORANGE_SPAIN" for /g/11h6nkfyrm). It is more stable than the KG mid. See
   * go/kema-api#keys. Some mids cannot have the enumerator property due to
   * historical reason (e.g., multiple media providers were created for iTunes
   * and only ""/g/11fhyxjwt5" has provider enumerator as "ITUNES_NEW" in KG).
   * These entities need to have hard-coded key (e.g., "/m/019g58" has key
   * "ITUNES") kept outside of KG.
   */
  kgProviderKey?: string;
  /**
   * Media ID of a MediaItem in a MediaBrowseTree (MBT). This field is used to
   * play a specific media item from MBT using playFromMediaId API.
   */
  mediaId?: string;
  /**
   * The machine ID (MID) of the media provider.
   */
  providerMid?: string;
  /**
   * The name of the media provider.
   */
  providerName?: string;
}

function serializeNlpSemanticParsingModelsMediaMediaProviderInfo(data: any): NlpSemanticParsingModelsMediaMediaProviderInfo {
  return {
    ...data,
    deeplinkInfo: data["deeplinkInfo"] !== undefined ? data["deeplinkInfo"].map((item: any) => (serializeNlpSemanticParsingModelsMediaDeeplinkInfo(item))) : undefined,
  };
}

function deserializeNlpSemanticParsingModelsMediaMediaProviderInfo(data: any): NlpSemanticParsingModelsMediaMediaProviderInfo {
  return {
    ...data,
    deeplinkInfo: data["deeplinkInfo"] !== undefined ? data["deeplinkInfo"].map((item: any) => (deserializeNlpSemanticParsingModelsMediaDeeplinkInfo(item))) : undefined,
  };
}

/**
 * Example: "Casablanca"
 */
export interface NlpSemanticParsingModelsMediaMovie {
  /**
   * Annotations from custom media annotator.
   */
  annotationList?: NlpSemanticParsingModelsMediaMediaAnnotationList;
  /**
   * Required, but should only be used inside Aqua and must not be used by
   * outside clients!!
   */
  evalData?: NlpSemanticParsingAnnotationEvalData;
  /**
   * Annotation comes from a text annotator. Needed to boost recall. Typically
   * need to be verified in superroot, and have separate scoring.
   */
  isAnnotatedFromText?: boolean;
  /**
   * Is annotated by Nimble for the media Fast Path.
   */
  isFromFastPath?: boolean;
  providerMetadata?: NlpSemanticParsingModelsMediaProviderMetadata[];
  qref?: NlpSemanticParsingQRefAnnotation;
  /**
   * Required, corresponds to the raw text, like "Casablanca"
   */
  rawText?: string;
}

function serializeNlpSemanticParsingModelsMediaMovie(data: any): NlpSemanticParsingModelsMediaMovie {
  return {
    ...data,
    annotationList: data["annotationList"] !== undefined ? serializeNlpSemanticParsingModelsMediaMediaAnnotationList(data["annotationList"]) : undefined,
    qref: data["qref"] !== undefined ? serializeNlpSemanticParsingQRefAnnotation(data["qref"]) : undefined,
  };
}

function deserializeNlpSemanticParsingModelsMediaMovie(data: any): NlpSemanticParsingModelsMediaMovie {
  return {
    ...data,
    annotationList: data["annotationList"] !== undefined ? deserializeNlpSemanticParsingModelsMediaMediaAnnotationList(data["annotationList"]) : undefined,
    qref: data["qref"] !== undefined ? deserializeNlpSemanticParsingQRefAnnotation(data["qref"]) : undefined,
  };
}

/**
 * Example: "The Beatles"
 */
export interface NlpSemanticParsingModelsMediaMusicArtist {
  /**
   * Annotations from custom media annotator.
   */
  annotationList?: NlpSemanticParsingModelsMediaMediaAnnotationList;
  /**
   * Required, but should only be used inside Aqua and must not be used by
   * outside clients!!
   */
  evalData?: NlpSemanticParsingAnnotationEvalData;
  /**
   * If true, indicates the user wants their favorite album. Like [play my
   * favorite album my Eminem]
   */
  favorite?: boolean;
  /**
   * Is annotated by Nimble for the media Fast Path.
   */
  isFromFastPath?: boolean;
  /**
   * More from this artist.
   */
  playMore?: boolean;
  qref?: NlpSemanticParsingQRefAnnotation;
  /**
   * Required, corresponds to the raw text, like "The Beatles"
   */
  rawText?: string;
}

function serializeNlpSemanticParsingModelsMediaMusicArtist(data: any): NlpSemanticParsingModelsMediaMusicArtist {
  return {
    ...data,
    annotationList: data["annotationList"] !== undefined ? serializeNlpSemanticParsingModelsMediaMediaAnnotationList(data["annotationList"]) : undefined,
    qref: data["qref"] !== undefined ? serializeNlpSemanticParsingQRefAnnotation(data["qref"]) : undefined,
  };
}

function deserializeNlpSemanticParsingModelsMediaMusicArtist(data: any): NlpSemanticParsingModelsMediaMusicArtist {
  return {
    ...data,
    annotationList: data["annotationList"] !== undefined ? deserializeNlpSemanticParsingModelsMediaMediaAnnotationList(data["annotationList"]) : undefined,
    qref: data["qref"] !== undefined ? deserializeNlpSemanticParsingQRefAnnotation(data["qref"]) : undefined,
  };
}

/**
 * Example: "British Invasion"
 */
export interface NlpSemanticParsingModelsMediaMusicGenre {
  /**
   * Annotations from custom media annotator.
   */
  annotationList?: NlpSemanticParsingModelsMediaMediaAnnotationList;
  /**
   * Required, but should only be used inside Aqua and must not be used by
   * outside clients!!
   */
  evalData?: NlpSemanticParsingAnnotationEvalData;
  /**
   * More from this genre.
   */
  playMore?: boolean;
  qref?: NlpSemanticParsingQRefAnnotation;
  /**
   * Required, corresponds to the raw text, like "British Invasion"
   */
  rawText?: string;
}

function serializeNlpSemanticParsingModelsMediaMusicGenre(data: any): NlpSemanticParsingModelsMediaMusicGenre {
  return {
    ...data,
    annotationList: data["annotationList"] !== undefined ? serializeNlpSemanticParsingModelsMediaMediaAnnotationList(data["annotationList"]) : undefined,
    qref: data["qref"] !== undefined ? serializeNlpSemanticParsingQRefAnnotation(data["qref"]) : undefined,
  };
}

function deserializeNlpSemanticParsingModelsMediaMusicGenre(data: any): NlpSemanticParsingModelsMediaMusicGenre {
  return {
    ...data,
    annotationList: data["annotationList"] !== undefined ? deserializeNlpSemanticParsingModelsMediaMediaAnnotationList(data["annotationList"]) : undefined,
    qref: data["qref"] !== undefined ? deserializeNlpSemanticParsingQRefAnnotation(data["qref"]) : undefined,
  };
}

/**
 * Example: "gym playlist"
 */
export interface NlpSemanticParsingModelsMediaMusicPlaylist {
  /**
   * Annotations from custom media annotator.
   */
  annotationList?: NlpSemanticParsingModelsMediaMediaAnnotationList;
  /**
   * Required, but should only be used inside Aqua and must not be used by
   * outside clients!!
   */
  evalData?: NlpSemanticParsingAnnotationEvalData;
  /**
   * Annotation comes from a text annotator. Needed to boost recall. Typically
   * need to be verified in superroot, and have separate scoring.
   */
  isAnnotatedFromText?: boolean;
  /**
   * If the model is confident that this is a bizarre long-tail mood-based
   * playlist, it can send a signal to downstream systems (that might do things
   * like generate random music) Example: * [play music for brushing my teeth
   * with the lights off on tuesday] This is pretty much an 'easter egg' -- it
   * is not critical.
   */
  longtailMood?: boolean;
  /**
   * Optional, some canonical name for the playlist.
   */
  normalizedText?: string;
  /**
   * Needed for proto conformance in Semantic Parsing.
   */
  qref?: NlpSemanticParsingQRefAnnotation;
  /**
   * Required, corresponds to the raw text, like "80s remix" (tokenized)
   */
  rawText?: string;
  special?:  | "NONE" | "THUMBS_UP" | "LAST_ADDED" | "FREE_AND_PURCHASED";
}

function serializeNlpSemanticParsingModelsMediaMusicPlaylist(data: any): NlpSemanticParsingModelsMediaMusicPlaylist {
  return {
    ...data,
    annotationList: data["annotationList"] !== undefined ? serializeNlpSemanticParsingModelsMediaMediaAnnotationList(data["annotationList"]) : undefined,
    qref: data["qref"] !== undefined ? serializeNlpSemanticParsingQRefAnnotation(data["qref"]) : undefined,
  };
}

function deserializeNlpSemanticParsingModelsMediaMusicPlaylist(data: any): NlpSemanticParsingModelsMediaMusicPlaylist {
  return {
    ...data,
    annotationList: data["annotationList"] !== undefined ? deserializeNlpSemanticParsingModelsMediaMediaAnnotationList(data["annotationList"]) : undefined,
    qref: data["qref"] !== undefined ? deserializeNlpSemanticParsingQRefAnnotation(data["qref"]) : undefined,
  };
}

export interface NlpSemanticParsingModelsMediaNewsInfo {
  /**
   * The docid of the news result from News360 backend.
   */
  docid?: bigint;
  /**
   * Indicates how the type of the news result.
   */
  newsContentType?:  | "NEWS_CONTENT_TYPE_UNSPECIFIED" | "AMP_ARTICLE_ONLY";
  /**
   * Publication time of the news, in seconds (unix epoch).
   */
  publicationTime?: AssistantApiTimestamp;
  /**
   * The publisher of the news.
   */
  publisher?: string;
}

function serializeNlpSemanticParsingModelsMediaNewsInfo(data: any): NlpSemanticParsingModelsMediaNewsInfo {
  return {
    ...data,
    docid: data["docid"] !== undefined ? String(data["docid"]) : undefined,
    publicationTime: data["publicationTime"] !== undefined ? serializeAssistantApiTimestamp(data["publicationTime"]) : undefined,
  };
}

function deserializeNlpSemanticParsingModelsMediaNewsInfo(data: any): NlpSemanticParsingModelsMediaNewsInfo {
  return {
    ...data,
    docid: data["docid"] !== undefined ? BigInt(data["docid"]) : undefined,
    publicationTime: data["publicationTime"] !== undefined ? deserializeAssistantApiTimestamp(data["publicationTime"]) : undefined,
  };
}

/**
 * Example: "ukraine" in a query like "read me news about Ukraine"
 */
export interface NlpSemanticParsingModelsMediaNewsTopic {
  /**
   * Required, but should only be used inside Aqua and must not be used by
   * outside clients!!
   */
  evalData?: NlpSemanticParsingAnnotationEvalData;
  rawText?: string;
}

/**
 * Represents BUY and RENT offers and associated cost info. Next ID: 3
 */
export interface NlpSemanticParsingModelsMediaPaidOfferDetail {
  /**
   * Represents the price of this offer according to the locale and region.
   */
  cost?: NlpSemanticParsingModelsMediaCost[];
  /**
   * Specifies the type of offer.
   */
  paidOfferType?:  | "UNKNOWN_PAID_OFFER_TYPE" | "RENT" | "BUY";
}

/**
 * Example: "This American Life"
 */
export interface NlpSemanticParsingModelsMediaPodcast {
  /**
   * Required, but should only be used inside Aqua and must not be used by
   * outside clients!!
   */
  evalData?: NlpSemanticParsingAnnotationEvalData;
  /**
   * Annotation comes from a text annotator. Needed to boost recall. Typically
   * need to be verified in superroot, and have separate scoring.
   */
  isAnnotatedFromText?: boolean;
  /**
   * Optional, some canonical name for the playlist.
   */
  normalizedText?: string;
  qref?: NlpSemanticParsingQRefAnnotation;
  /**
   * Required, corresponds to the raw text, like "this american life"
   */
  rawText?: string;
}

function serializeNlpSemanticParsingModelsMediaPodcast(data: any): NlpSemanticParsingModelsMediaPodcast {
  return {
    ...data,
    qref: data["qref"] !== undefined ? serializeNlpSemanticParsingQRefAnnotation(data["qref"]) : undefined,
  };
}

function deserializeNlpSemanticParsingModelsMediaPodcast(data: any): NlpSemanticParsingModelsMediaPodcast {
  return {
    ...data,
    qref: data["qref"] !== undefined ? deserializeNlpSemanticParsingQRefAnnotation(data["qref"]) : undefined,
  };
}

export interface NlpSemanticParsingModelsMediaPodcastInfo {
  /**
   * An internal identifier for the wernicke database that identifies a cluster
   * of multiple sources for a particular podcast.
   */
  clusterId?: string;
  /**
   * GUID of the given podcast episode.
   */
  episodeGuid?: string;
  /**
   * The url for the rss feed providing this podcast.
   */
  feedUrl?: string;
  /**
   * Podcast recommendations features. These features are used to train models
   * for reranking podcast recommendations. Full list of features:
   * http://shortn/_bg6NvzYs6F This won't be sent to clients. It will only be
   * annotated for crust results
   */
  podcastRecsFeatures?: SuperrootPodcastsRecommendationsPodcastRecsFeatures;
  title?: string;
}

function serializeNlpSemanticParsingModelsMediaPodcastInfo(data: any): NlpSemanticParsingModelsMediaPodcastInfo {
  return {
    ...data,
    podcastRecsFeatures: data["podcastRecsFeatures"] !== undefined ? serializeSuperrootPodcastsRecommendationsPodcastRecsFeatures(data["podcastRecsFeatures"]) : undefined,
  };
}

function deserializeNlpSemanticParsingModelsMediaPodcastInfo(data: any): NlpSemanticParsingModelsMediaPodcastInfo {
  return {
    ...data,
    podcastRecsFeatures: data["podcastRecsFeatures"] !== undefined ? deserializeSuperrootPodcastsRecommendationsPodcastRecsFeatures(data["podcastRecsFeatures"]) : undefined,
  };
}

/**
 * Provider metadata associated with video.
 */
export interface NlpSemanticParsingModelsMediaProviderMetadata {
  /**
   * URL like https://www.netflix.com/title/70305883 -- this is used as a
   * deeplink to play the video.
   */
  deeplinkUrl?: string;
  /**
   * Provider MID.
   */
  providerMid?: string;
}

export interface NlpSemanticParsingModelsMediaPurchaseInfo {
  orderType?:  | "ORDER_TYPE_UNSPECIFIED" | "PREORDER" | "REGULAR";
  /**
   * The time at which the item is purchased.
   */
  purchaseTimestampSec?: bigint;
}

function serializeNlpSemanticParsingModelsMediaPurchaseInfo(data: any): NlpSemanticParsingModelsMediaPurchaseInfo {
  return {
    ...data,
    purchaseTimestampSec: data["purchaseTimestampSec"] !== undefined ? String(data["purchaseTimestampSec"]) : undefined,
  };
}

function deserializeNlpSemanticParsingModelsMediaPurchaseInfo(data: any): NlpSemanticParsingModelsMediaPurchaseInfo {
  return {
    ...data,
    purchaseTimestampSec: data["purchaseTimestampSec"] !== undefined ? BigInt(data["purchaseTimestampSec"]) : undefined,
  };
}

/**
 * The quantification of device(s) in the query. For example, "three speakers",
 * "all TVs", etc. Usually, we should have either lexical field or number field.
 * However, there are some special words which we will set both fields. For
 * example, "all 3" will have the semantic: {lexical=ALL, number=3}. Note that
 * "both" is simply modeled as {lexical=ALL}.
 */
export interface NlpSemanticParsingModelsMediaQuantification {
  lexical?:  | "NONE" | "ALL";
  /**
   * Numerical quantification. E.g., "three speakers".
   */
  number?: number;
}

/**
 * Example: "107.7 the bone"
 */
export interface NlpSemanticParsingModelsMediaRadio {
  /**
   * Annotations from custom media annotator.
   */
  annotationList?: NlpSemanticParsingModelsMediaMediaAnnotationList;
  /**
   * Required, but should only be used inside Aqua and must not be used by
   * outside clients!!
   */
  evalData?: NlpSemanticParsingAnnotationEvalData;
  /**
   * If true, indicates the user wants their favorite radio station to be
   * played. Ex: [play my favorites on radio]
   */
  favorite?: boolean;
  /**
   * This proto may only be partially filled depending on the query. ## Some
   * examples (all of them have open_intent): ## | Query
   * |radio.raw_text|radio.frequency.band|radio.frequency.value| |[play kqed
   * fm]| [kqed fm] | [fm] | N/A | |[play 88.5 fm]| [88.5 fm] | [fm] | 88.5 | |
   * [play 88.5 | [88.5] | N/A | 88.5 | ## | [play fm] | [fm] | [fm] | N/A |
   */
  frequency?: NlpSemanticParsingModelsMediaFrequency;
  /**
   * Annotation comes from a text annotator. Needed to boost recall. Typically
   * need to be verified in superroot, and have separate scoring.
   */
  isAnnotatedFromText?: boolean;
  /**
   * Is annotated by Nimble for the media Fast Path.
   */
  isFromFastPath?: boolean;
  qref?: NlpSemanticParsingQRefAnnotation;
  /**
   * Required, corresponds to the raw text, like "107.7"
   */
  rawText?: string;
}

function serializeNlpSemanticParsingModelsMediaRadio(data: any): NlpSemanticParsingModelsMediaRadio {
  return {
    ...data,
    annotationList: data["annotationList"] !== undefined ? serializeNlpSemanticParsingModelsMediaMediaAnnotationList(data["annotationList"]) : undefined,
    qref: data["qref"] !== undefined ? serializeNlpSemanticParsingQRefAnnotation(data["qref"]) : undefined,
  };
}

function deserializeNlpSemanticParsingModelsMediaRadio(data: any): NlpSemanticParsingModelsMediaRadio {
  return {
    ...data,
    annotationList: data["annotationList"] !== undefined ? deserializeNlpSemanticParsingModelsMediaMediaAnnotationList(data["annotationList"]) : undefined,
    qref: data["qref"] !== undefined ? deserializeNlpSemanticParsingQRefAnnotation(data["qref"]) : undefined,
  };
}

/**
 * Metadata for a radio station (both terrestrial and internet). Next ID: 4
 */
export interface NlpSemanticParsingModelsMediaRadioInfo {
  /**
   * Frequency of the terrestrial radio station.
   */
  frequency?: NlpSemanticParsingModelsMediaFrequency;
  /**
   * Location of the radio station.
   */
  location?: NlpSemanticParsingModelsMediaLatLng;
  /**
   * Popularity of the radio station. This will be used in ranking of the radio
   * stations. This value should be between 0 (least popular) and 5 (most
   * popular).
   */
  popularity?: number;
}

/**
 * Example: "npr", "bbc", etc.
 */
export interface NlpSemanticParsingModelsMediaRadioNetwork {
  /**
   * Annotations from custom media annotator.
   */
  annotationList?: NlpSemanticParsingModelsMediaMediaAnnotationList;
  /**
   * Required, but should only be used inside Aqua and must not be used by
   * outside clients!!
   */
  evalData?: NlpSemanticParsingAnnotationEvalData;
  qref?: NlpSemanticParsingQRefAnnotation;
  /**
   * Required, corresponds to the raw text, like "npr"
   */
  rawText?: string;
}

function serializeNlpSemanticParsingModelsMediaRadioNetwork(data: any): NlpSemanticParsingModelsMediaRadioNetwork {
  return {
    ...data,
    annotationList: data["annotationList"] !== undefined ? serializeNlpSemanticParsingModelsMediaMediaAnnotationList(data["annotationList"]) : undefined,
    qref: data["qref"] !== undefined ? serializeNlpSemanticParsingQRefAnnotation(data["qref"]) : undefined,
  };
}

function deserializeNlpSemanticParsingModelsMediaRadioNetwork(data: any): NlpSemanticParsingModelsMediaRadioNetwork {
  return {
    ...data,
    annotationList: data["annotationList"] !== undefined ? deserializeNlpSemanticParsingModelsMediaMediaAnnotationList(data["annotationList"]) : undefined,
    qref: data["qref"] !== undefined ? deserializeNlpSemanticParsingQRefAnnotation(data["qref"]) : undefined,
  };
}

export interface NlpSemanticParsingModelsMediaRentalInfo {
  /**
   * Time period for users to continue watching.
   */
  activatePeriodSec?: bigint;
  /**
   * Time period for users to begin watching.
   */
  grantPeriodSec?: bigint;
  /**
   * The time at which the item is purchased.
   */
  purchaseTimestampSec?: bigint;
  /**
   * Time until which ownership is granted
   */
  validUntilTimestampSec?: bigint;
}

function serializeNlpSemanticParsingModelsMediaRentalInfo(data: any): NlpSemanticParsingModelsMediaRentalInfo {
  return {
    ...data,
    activatePeriodSec: data["activatePeriodSec"] !== undefined ? String(data["activatePeriodSec"]) : undefined,
    grantPeriodSec: data["grantPeriodSec"] !== undefined ? String(data["grantPeriodSec"]) : undefined,
    purchaseTimestampSec: data["purchaseTimestampSec"] !== undefined ? String(data["purchaseTimestampSec"]) : undefined,
    validUntilTimestampSec: data["validUntilTimestampSec"] !== undefined ? String(data["validUntilTimestampSec"]) : undefined,
  };
}

function deserializeNlpSemanticParsingModelsMediaRentalInfo(data: any): NlpSemanticParsingModelsMediaRentalInfo {
  return {
    ...data,
    activatePeriodSec: data["activatePeriodSec"] !== undefined ? BigInt(data["activatePeriodSec"]) : undefined,
    grantPeriodSec: data["grantPeriodSec"] !== undefined ? BigInt(data["grantPeriodSec"]) : undefined,
    purchaseTimestampSec: data["purchaseTimestampSec"] !== undefined ? BigInt(data["purchaseTimestampSec"]) : undefined,
    validUntilTimestampSec: data["validUntilTimestampSec"] !== undefined ? BigInt(data["validUntilTimestampSec"]) : undefined,
  };
}

/**
 * Example: "season 2" of serial
 */
export interface NlpSemanticParsingModelsMediaSeasonConstraint {
  /**
   * The absolute index of the season. 1 is the first element and -1 is the
   * last element in the sequence, -2 is the second-to-last element, and so on.
   * Examples: "first season" => 1 "3rd season" => 3 "last season" => -1
   */
  absoluteIndex?: number;
  /**
   * Required, but should only be used inside Aqua and must not be used by
   * outside clients!!
   */
  evalData?: NlpSemanticParsingAnnotationEvalData;
  rawText?: string;
  /**
   * The relative index of the season. Examples: "previous season" => -1
   * "current season" => 0 "next season" => 1
   */
  relativeIndex?: number;
}

/**
 * Example: "Hey Jude"
 */
export interface NlpSemanticParsingModelsMediaSong {
  /**
   * Annotations from custom media annotator.
   */
  annotationList?: NlpSemanticParsingModelsMediaMediaAnnotationList;
  /**
   * Required, but should only be used inside Aqua and must not be used by
   * outside clients!!
   */
  evalData?: NlpSemanticParsingAnnotationEvalData;
  /**
   * If true, indicates the user wants their favorite album. Like [play my
   * favorite song]
   */
  favorite?: boolean;
  /**
   * If true, indicates the user wants the first song. Like [play adele's first
   * song]
   */
  first?: boolean;
  /**
   * Annotation comes from a text annotator. Needed to boost recall. Typically
   * need to be verified in superroot, and have separate scoring.
   */
  isAnnotatedFromText?: boolean;
  /**
   * Is annotated by Nimble for the media Fast Path.
   */
  isFromFastPath?: boolean;
  /**
   * If true, indicates the user wants the latest song. Like, [play adele's
   * latest song]
   */
  latest?: boolean;
  /**
   * Optional, indicates this reference came from QRef.
   */
  qref?: NlpSemanticParsingQRefAnnotation;
  /**
   * Required, corresponds to the raw text, like "Hey Jude."
   */
  rawText?: string;
}

function serializeNlpSemanticParsingModelsMediaSong(data: any): NlpSemanticParsingModelsMediaSong {
  return {
    ...data,
    annotationList: data["annotationList"] !== undefined ? serializeNlpSemanticParsingModelsMediaMediaAnnotationList(data["annotationList"]) : undefined,
    qref: data["qref"] !== undefined ? serializeNlpSemanticParsingQRefAnnotation(data["qref"]) : undefined,
  };
}

function deserializeNlpSemanticParsingModelsMediaSong(data: any): NlpSemanticParsingModelsMediaSong {
  return {
    ...data,
    annotationList: data["annotationList"] !== undefined ? deserializeNlpSemanticParsingModelsMediaMediaAnnotationList(data["annotationList"]) : undefined,
    qref: data["qref"] !== undefined ? deserializeNlpSemanticParsingQRefAnnotation(data["qref"]) : undefined,
  };
}

/**
 * Example: "Breaking Bad"
 */
export interface NlpSemanticParsingModelsMediaTVShow {
  /**
   * Annotations from custom media annotator.
   */
  annotationList?: NlpSemanticParsingModelsMediaMediaAnnotationList;
  /**
   * Required, but should only be used inside Aqua and must not be used by
   * outside clients!!
   */
  evalData?: NlpSemanticParsingAnnotationEvalData;
  /**
   * Is annotated by Nimble for the media Fast Path.
   */
  isFromFastPath?: boolean;
  providerMetadata?: NlpSemanticParsingModelsMediaProviderMetadata[];
  qref?: NlpSemanticParsingQRefAnnotation;
  /**
   * Required, corresponds to the raw text, like "Breaking Bad"
   */
  rawText?: string;
}

function serializeNlpSemanticParsingModelsMediaTVShow(data: any): NlpSemanticParsingModelsMediaTVShow {
  return {
    ...data,
    annotationList: data["annotationList"] !== undefined ? serializeNlpSemanticParsingModelsMediaMediaAnnotationList(data["annotationList"]) : undefined,
    qref: data["qref"] !== undefined ? serializeNlpSemanticParsingQRefAnnotation(data["qref"]) : undefined,
  };
}

function deserializeNlpSemanticParsingModelsMediaTVShow(data: any): NlpSemanticParsingModelsMediaTVShow {
  return {
    ...data,
    annotationList: data["annotationList"] !== undefined ? deserializeNlpSemanticParsingModelsMediaMediaAnnotationList(data["annotationList"]) : undefined,
    qref: data["qref"] !== undefined ? deserializeNlpSemanticParsingQRefAnnotation(data["qref"]) : undefined,
  };
}

/**
 * Provide the deeplink information specific to YouTube PMAs. Next ID: 3
 */
export interface NlpSemanticParsingModelsMediaYouTubeDeeplinkInfo {
  /**
   * See go/yt-clicktracking. Serialized
   * youtube.api.innertube.InnerTubeClickTrackingProto.
   */
  clickTrackingId?: string;
  /**
   * For YouTube Channels, by default the deeplink is set to be the playlist of
   * all uploads from the channel. This field is used for YouTube in-app browse
   * when we need the YouTube channel's main page url. We will use the
   * uploader_channel_id to construct the needed channel deeplink.
   */
  uploaderChannelId?: string;
}

export interface NlpSemanticParsingModelsMediaYouTubePlaylistInfo {
  /**
   * Count of videos in the YouTube playlist that are playable in WoodStock.
   * For performance reasons the maximum value this field can reach is capped,
   * see: kMaxVideosPerPlaylistForSearchMetadata.
   */
  numVidsPlayableInWoodstock?: bigint;
  /**
   * Total number of videos present in the retrieved playlist.
   */
  videoCount?: number;
}

function serializeNlpSemanticParsingModelsMediaYouTubePlaylistInfo(data: any): NlpSemanticParsingModelsMediaYouTubePlaylistInfo {
  return {
    ...data,
    numVidsPlayableInWoodstock: data["numVidsPlayableInWoodstock"] !== undefined ? String(data["numVidsPlayableInWoodstock"]) : undefined,
  };
}

function deserializeNlpSemanticParsingModelsMediaYouTubePlaylistInfo(data: any): NlpSemanticParsingModelsMediaYouTubePlaylistInfo {
  return {
    ...data,
    numVidsPlayableInWoodstock: data["numVidsPlayableInWoodstock"] !== undefined ? BigInt(data["numVidsPlayableInWoodstock"]) : undefined,
  };
}

export interface NlpSemanticParsingModelsMoneyCurrency {
  /**
   * KG Currency mid
   */
  freebaseMid?: string;
}

/**
 * Represent a money quantity
 */
export interface NlpSemanticParsingModelsMoneyMoney {
  amount?: NlpSemanticParsingNumberNumber;
  currency?: NlpSemanticParsingModelsMoneyCurrency;
}

/**
 * Corresponds to an entry in our hand-curated Nimble table of providers.
 */
export interface NlpSemanticParsingModelsNarrativeNewsNewsProvider {
  /**
   * Annotation data for the provider.
   */
  data?: QualityActionsNewsProviderAnnotationData;
  /**
   * Required, but should only be used inside Aqua and must not be used by
   * outside clients!!
   */
  evalData?: NlpSemanticParsingAnnotationEvalData;
  rawText?: string;
}

/**
 * OnDevice describes the device(s) to perform an action. This message type can
 * be imported in action messages as an argument.
 */
export interface NlpSemanticParsingModelsOnDevice {
  /**
   * The device(s) to perform an action.
   */
  device?: NlpSemanticParsingModelsDevice[];
}

export interface NlpSemanticParsingModelsPersonPerson {
  /**
   * Alternative names like "John" for "Joan", with info such as
   * RecognitionAlternateSource indicating where is it from.
   */
  alternativeNameInfo?: QualityQrewriteAlternativeNameInfo[];
  /**
   * Alternative names, e.g., names with similar pronunciation, Kathy and
   * Cathy.
   */
  alternativeNames?: string[];
  annotationSource?:  | "PERSONAL_CONTACT" | "RELATIONSHIP" | "NAMES" | "NAME_DETECTION" | "SAFT" | "PERSONAL_KNOWLEDGE_GRAPH" | "PRESENCE_PEOPLE_SEARCH" | "LOOSE_TEXT"[];
  /**
   * Contact metadata. Only available for personal contact.
   */
  contactData?: QualityQrewritePersonalContactData[];
  /**
   * Required, but should only be used inside Aqua. Must not be used by outside
   * clients!!
   */
  evalData?: NlpSemanticParsingAnnotationEvalData;
  /**
   * Whether the person is from personal contacts (e.g. Focus contacts or
   * device contacts) or the person is constructed from a Gaia profile visible
   * to the user (e.g. via Family Service).
   */
  isPersonalContact?: boolean;
  /**
   * Indicates whether $Person is used for person-group reference. If true,
   * then the PersonalContactData in repeated contact_data field probably
   * correspond to a group of different persons, where $Person is used to
   * represent family, kids, parents, etc.
   */
  isPersonGroupReference?: boolean;
  /**
   * The name of the person without normalizations, preserves casing of the raw
   * text, but removes possible prefix/suffix. For example: raw_text: "Mr. John"
   * normalized_text: "john" name: "John" raw_text: "Tll" normalized_text:
   * "tuell" name: "Tll"
   */
  name?: string;
  /**
   * Normalized text produced by annotator. Some annotators generate a
   * normalized version to help better match with contact list.
   */
  normalizedText?: string;
  /**
   * Contains information about a Copley Person reference (go/copley-people).
   * Note that this contains no information about the resolved people (e.g.
   * names, phone numbers) but only about the user's reference. Resolution
   * metadata is stored in contact_data.pkg_person.
   */
  pkgSemantics?: NlpSemanticParsingQRefAnnotation;
  rawText?: string;
}

function serializeNlpSemanticParsingModelsPersonPerson(data: any): NlpSemanticParsingModelsPersonPerson {
  return {
    ...data,
    contactData: data["contactData"] !== undefined ? data["contactData"].map((item: any) => (serializeQualityQrewritePersonalContactData(item))) : undefined,
    pkgSemantics: data["pkgSemantics"] !== undefined ? serializeNlpSemanticParsingQRefAnnotation(data["pkgSemantics"]) : undefined,
  };
}

function deserializeNlpSemanticParsingModelsPersonPerson(data: any): NlpSemanticParsingModelsPersonPerson {
  return {
    ...data,
    contactData: data["contactData"] !== undefined ? data["contactData"].map((item: any) => (deserializeQualityQrewritePersonalContactData(item))) : undefined,
    pkgSemantics: data["pkgSemantics"] !== undefined ? deserializeNlpSemanticParsingQRefAnnotation(data["pkgSemantics"]) : undefined,
  };
}

/**
 * Recurrence rule for specifying date- and time-based repetition for tasks.
 * Next id: 12.
 */
export interface NlpSemanticParsingModelsRecurrence {
  /**
   * Optional. Specifies when in the day the task should occur. Applies to all
   * frequencies DAILY and greater. If absent, the repeating tasks are
   * considered "all day" type.
   */
  dailyPattern?: NlpSemanticParsingModelsRecurrenceDailyPattern;
  /**
   * This field of the Recurrence message should not in general be used by
   * outside clients of the grammar. It is intended to be used internally in
   * Aqua for evaluation purposes. The rationale is that token counts depend on
   * the particular tokenization used in Aqua which may be different from the
   * one used by the client and may change from time to time. Outside clients
   * should not create a dependency on the current tokenization used in Aqua.
   */
  evalData?: NlpSemanticParsingAnnotationEvalData;
  /**
   * Multiplier on the frequency of the recurrence. Use this to specify
   * patterns that recur every X days, months, years, etc. Example: [remind me
   * to call mom every 2nd week]. Default is 1 (every day, every month, every
   * year). Floating point numbers are understood and rounded to the nearest
   * integer. E.g. "every 2.8 months" => (every 3)
   */
  every?: number;
  /**
   * Required. The high-level frequency of the recurrence.
   */
  frequency?:  | "DAILY" | "WEEKLY" | "MONTHLY" | "YEARLY" | "UNKNOWN";
  /**
   * Specify a monthly recurrence. Valid and required for MONTHLY frequencies
   * only.
   */
  monthlyPattern?: NlpSemanticParsingModelsRecurrenceMonthlyPattern;
  /**
   * How many times the task should be repeated within the frequency interval.
   * Floating point numbers are understood and rounded to the nearest integer.
   * E.g. "3.8 times per week" => (num_instances_in_frequency 4)
   */
  numInstancesInFrequency?: number;
  /**
   * Required. The end condition for the recurrence.
   */
  recurrenceEnd?: NlpSemanticParsingModelsRecurrenceRecurrenceEnd;
  /**
   * Required. The start of the recurrence.
   */
  recurrenceStart?: NlpSemanticParsingModelsRecurrenceRecurrenceStart;
  /**
   * Optional time included with some types of recurrence phrases, such as
   * "every morning".
   */
  time?: NlpSemanticParsingDatetimeDateTime;
  /**
   * Specify a weekly recurrence. Valid and required for WEEKLY frequencies
   * only.
   */
  weeklyPattern?: NlpSemanticParsingModelsRecurrenceWeeklyPattern;
  /**
   * Specify a yearly recurrence. Valid only for YEARLY frequencies.
   */
  yearlyPattern?: NlpSemanticParsingModelsRecurrenceYearlyPattern;
}

function serializeNlpSemanticParsingModelsRecurrence(data: any): NlpSemanticParsingModelsRecurrence {
  return {
    ...data,
    recurrenceEnd: data["recurrenceEnd"] !== undefined ? serializeNlpSemanticParsingModelsRecurrenceRecurrenceEnd(data["recurrenceEnd"]) : undefined,
    recurrenceStart: data["recurrenceStart"] !== undefined ? serializeNlpSemanticParsingModelsRecurrenceRecurrenceStart(data["recurrenceStart"]) : undefined,
    time: data["time"] !== undefined ? serializeNlpSemanticParsingDatetimeDateTime(data["time"]) : undefined,
  };
}

function deserializeNlpSemanticParsingModelsRecurrence(data: any): NlpSemanticParsingModelsRecurrence {
  return {
    ...data,
    recurrenceEnd: data["recurrenceEnd"] !== undefined ? deserializeNlpSemanticParsingModelsRecurrenceRecurrenceEnd(data["recurrenceEnd"]) : undefined,
    recurrenceStart: data["recurrenceStart"] !== undefined ? deserializeNlpSemanticParsingModelsRecurrenceRecurrenceStart(data["recurrenceStart"]) : undefined,
    time: data["time"] !== undefined ? deserializeNlpSemanticParsingDatetimeDateTime(data["time"]) : undefined,
  };
}

/**
 * Pattern for when in the day the repeating task should trigger. Applies to
 * all frequencies greater than or equal to DAILY. Exactly one of the containing
 * fields should be set (i.e. a specific time or period).
 */
export interface NlpSemanticParsingModelsRecurrenceDailyPattern {
  dayPeriod?: NlpSemanticParsingDateTimeAnnotation;
  timeOfDay?: NlpSemanticParsingDateTimeAnnotation;
}

/**
 * Pattern for a MONTHLY recurrence. A MONTHLY recurrence may be specified in
 * four different ways. These fields should be set in a mutually exclusive way,
 * i.e.: ((month_day OR last_day) XOR (week_day AND (week_day_number OR
 * last_week))) 1. Absolute days of the month (i.e. the 1st and 15th) or
 * relative day from the end of the month (i.e. -1 for last day, -2 for
 * second-to-last day). Set month_day. 2. [Deprecated] Relative last day of the
 * month. Represented as a boolean since the last absolute day number is
 * dependent on the month. This is just a short-cut for month_day=-1 and is
 * deprecated. Set last_day=true. 3. The nth (or nth-last) specific weekday of
 * the month. For example, the 3rd Wednesday of the month. This represents the
 * 3rd instance of a Wednesday of the month, regardless of what weekday the
 * month started on. It does not necessarily mean the Wednesday on the 3rd week
 * of the month. 4. [Deprecated] The last specific weekday of the month. For
 * example, the last Thursday of the month. This is a short-cut for
 * week_day_number=-1.
 */
export interface NlpSemanticParsingModelsRecurrenceMonthlyPattern {
  /**
   * Special flag to indicate the last day of the month, equivalent to setting
   * month_day to -1. Deprecated, use month_day=-1 instead.
   */
  lastDay?: boolean;
  /**
   * Special flag to indicate a week_day in the last week of the month, as this
   * cannot be captured by week_day_number. Deprecated, use week_day_number=-1
   * instead.
   */
  lastWeek?: boolean;
  /**
   * Absolute day of the month (if positive) or relative day from the end of
   * the month (if negative). Example: 2nd and 20th of the month [2, 20].
   * Example: Last day of the month [-1]. Positive values should correspond to
   * actual calendar day number (indexing starts at 1).
   */
  monthDay?: number[];
  /**
   * For capturing the nth weekday of the month. Use together with
   * week_day_number or last_week to specify n.
   */
  weekDay?:  | "MONDAY" | "TUESDAY" | "WEDNESDAY" | "THURSDAY" | "FRIDAY" | "SATURDAY" | "SUNDAY";
  /**
   * The nth occurrence of week_day to match. I.e. For 3rd Wednesday of the
   * month, week_day = WEDNESDAY and week_day_number = 3. Values beyond the end
   * of the month are skipped. If negative, this is interpreted as the
   * nth-to-last occurrence of the week day in the month. I.e. for last Thursday
   * of the month, week_day = THURSDAY and week_day_number = -1.
   */
  weekDayNumber?: number;
}

/**
 * The end of the recurrence can be represented in one of three ways. 1. An
 * abstract DateTime. (inclusive) 2. An absolute timestamp, in milliseconds from
 * UTC epoch. 3. A number of occurrences. Exactly one of the fields
 * [end_date_time, end_millis, num_occurrences] in this message must be set.
 * Repeating tasks for which the user did not specify an end date are
 * automatically given a reasonable end conditions by the system and auto_renew
 * will be set to true. Similarly, if the user- provided end date is too far in
 * the future to reasonably create all instances, the server will set an
 * auto_renew_until end condition.
 */
export interface NlpSemanticParsingModelsRecurrenceRecurrenceEnd {
  /**
   * Should be used in cases where the size of the recurrence is infinite (no
   * end date specified), in which case we rely on an offline process to extend.
   * Set by server only, setting it on a new recurrence will throw an exception.
   */
  autoRenew?: boolean;
  /**
   * Used in cases where the recurrence is too large to create in a single
   * transaction. In this case we create a manageable number of instances
   * initially and rely on an offline process to continually extend the
   * recurrence until this date. Set by server only, setting it on a new
   * recurrence will throw an exception.
   */
  autoRenewUntil?: NlpSemanticParsingDateTimeAnnotation;
  endDateTime?: NlpSemanticParsingDateTimeAnnotation;
  /**
   * Deprecated - prefer end_date_time.absolute_time_ms.
   */
  endMillis?: bigint;
  /**
   * Note that auto-renewing is not supported in conjunction with
   * num_occurrences. Therefore we impose a hard limit of 1000 when using this
   * field.
   */
  numOccurrences?: number;
}

function serializeNlpSemanticParsingModelsRecurrenceRecurrenceEnd(data: any): NlpSemanticParsingModelsRecurrenceRecurrenceEnd {
  return {
    ...data,
    endMillis: data["endMillis"] !== undefined ? String(data["endMillis"]) : undefined,
  };
}

function deserializeNlpSemanticParsingModelsRecurrenceRecurrenceEnd(data: any): NlpSemanticParsingModelsRecurrenceRecurrenceEnd {
  return {
    ...data,
    endMillis: data["endMillis"] !== undefined ? BigInt(data["endMillis"]) : undefined,
  };
}

/**
 * The start of the recurrence can be represented either as a DateTime or a
 * timestamp in milliseconds from UTC epoch. Exactly one of the fields of this
 * message must be set.
 */
export interface NlpSemanticParsingModelsRecurrenceRecurrenceStart {
  /**
   * Only the year/month/day portion are used to find the start date of the
   * recurrence. To specify a time or period of each instance, use DailyPattern.
   */
  startDateTime?: NlpSemanticParsingDateTimeAnnotation;
  /**
   * Deprecated - prefer start_date_time.absolute_time_ms.
   */
  startMillis?: bigint;
}

function serializeNlpSemanticParsingModelsRecurrenceRecurrenceStart(data: any): NlpSemanticParsingModelsRecurrenceRecurrenceStart {
  return {
    ...data,
    startMillis: data["startMillis"] !== undefined ? String(data["startMillis"]) : undefined,
  };
}

function deserializeNlpSemanticParsingModelsRecurrenceRecurrenceStart(data: any): NlpSemanticParsingModelsRecurrenceRecurrenceStart {
  return {
    ...data,
    startMillis: data["startMillis"] !== undefined ? BigInt(data["startMillis"]) : undefined,
  };
}

/**
 * Pattern for a WEEKLY recurrence. You must specify at least one week_day.
 */
export interface NlpSemanticParsingModelsRecurrenceWeeklyPattern {
  /**
   * Set of weekdays the recurrence applies to.
   */
  weekDay?:  | "MONDAY" | "TUESDAY" | "WEDNESDAY" | "THURSDAY" | "FRIDAY" | "SATURDAY" | "SUNDAY"[];
  weeklyPatternEnd?:  | "MONDAY" | "TUESDAY" | "WEDNESDAY" | "THURSDAY" | "FRIDAY" | "SATURDAY" | "SUNDAY";
  weeklyPatternStart?:  | "MONDAY" | "TUESDAY" | "WEDNESDAY" | "THURSDAY" | "FRIDAY" | "SATURDAY" | "SUNDAY";
}

/**
 * Pattern for a YEARLY recurrence. A YEARLY recurrence is specified using a
 * monthly pattern and a set of months the pattern applies to. Some examples:
 * "Every January 16" : monthly_pattern { month_day = 16; } year_month =
 * JANUARY; "Last day of every April and August" : monthly_pattern { last_day =
 * true; } year_month = APRIL, AUGUST
 */
export interface NlpSemanticParsingModelsRecurrenceYearlyPattern {
  /**
   * The monthly pattern to recur.
   */
  monthlyPattern?: NlpSemanticParsingModelsRecurrenceMonthlyPattern;
  /**
   * The months of the year to apply the pattern.
   */
  yearMonth?:  | "JANUARY" | "FEBRUARY" | "MARCH" | "APRIL" | "MAY" | "JUNE" | "JULY" | "AUGUST" | "SEPTEMBER" | "OCTOBER" | "NOVEMBER" | "DECEMBER"[];
}

/**
 * A brand can be any combination of text or mid.
 */
export interface NlpSemanticParsingModelsShoppingAssistantBrandPhrase {
  mid?: string;
  rawText?: string;
}

/**
 * A merchant that sells products.
 */
export interface NlpSemanticParsingModelsShoppingAssistantMerchant {
  /**
   * This field should not be used by clients of the grammar. It is intended to
   * be used internally in Aqua for metric and regression tests.
   */
  evalData?: NlpSemanticParsingAnnotationEvalData;
  /**
   * Merchant Center identifier for LIA merchants.
   */
  localMerchantId?: bigint;
  mcid?: NlpSemanticParsingModelsShoppingAssistantMerchantMerchantCenterId[];
  /**
   * Merchant Center identifier for GSX merchants. Deprecated: use
   * MerchantCenterId.
   */
  merchantId?: bigint[];
  /**
   * Optional. Knowledge Graph identifier for the merchant.
   */
  mid?: string;
  /**
   * A name for the merchant. Example: Walmart
   */
  name?: string;
}

function serializeNlpSemanticParsingModelsShoppingAssistantMerchant(data: any): NlpSemanticParsingModelsShoppingAssistantMerchant {
  return {
    ...data,
    localMerchantId: data["localMerchantId"] !== undefined ? String(data["localMerchantId"]) : undefined,
    mcid: data["mcid"] !== undefined ? data["mcid"].map((item: any) => (serializeNlpSemanticParsingModelsShoppingAssistantMerchantMerchantCenterId(item))) : undefined,
    merchantId: data["merchantId"] !== undefined ? data["merchantId"].map((item: any) => (String(item))) : undefined,
  };
}

function deserializeNlpSemanticParsingModelsShoppingAssistantMerchant(data: any): NlpSemanticParsingModelsShoppingAssistantMerchant {
  return {
    ...data,
    localMerchantId: data["localMerchantId"] !== undefined ? BigInt(data["localMerchantId"]) : undefined,
    mcid: data["mcid"] !== undefined ? data["mcid"].map((item: any) => (deserializeNlpSemanticParsingModelsShoppingAssistantMerchantMerchantCenterId(item))) : undefined,
    merchantId: data["merchantId"] !== undefined ? data["merchantId"].map((item: any) => (BigInt(item))) : undefined,
  };
}

/**
 * Note: A merchant may have multiple merchant center ids, and each one can
 * have multiple purposes. The existing fields merchant_id, local_merchant_id
 * fields are not enough to capture this. Instead we will have a repeated field
 * name mcid with this structure.
 */
export interface NlpSemanticParsingModelsShoppingAssistantMerchantMerchantCenterId {
  id?: bigint;
  isGsx?: boolean;
  isLocal?: boolean;
  isPla?: boolean;
}

function serializeNlpSemanticParsingModelsShoppingAssistantMerchantMerchantCenterId(data: any): NlpSemanticParsingModelsShoppingAssistantMerchantMerchantCenterId {
  return {
    ...data,
    id: data["id"] !== undefined ? String(data["id"]) : undefined,
  };
}

function deserializeNlpSemanticParsingModelsShoppingAssistantMerchantMerchantCenterId(data: any): NlpSemanticParsingModelsShoppingAssistantMerchantMerchantCenterId {
  return {
    ...data,
    id: data["id"] !== undefined ? BigInt(data["id"]) : undefined,
  };
}

/**
 * A product for sale from a particular merchant, possibly available at a
 * specific store.
 */
export interface NlpSemanticParsingModelsShoppingAssistantOffer {
  /**
   * The offer document id as used in Shopping's metadata.
   */
  docid?: bigint;
  /**
   * The merchant selling the product.
   */
  merchant?: NlpSemanticParsingModelsShoppingAssistantMerchant;
  /**
   * The price of the product sold by the merchant.
   */
  price?: NlpSemanticParsingModelsMoneyMoney;
  /**
   * The product for sale.
   */
  product?: NlpSemanticParsingModelsShoppingAssistantProduct;
  /**
   * Optional. The physical store where the product can be purchased.
   */
  store?: NlpSemanticParsingModelsShoppingAssistantStore;
}

function serializeNlpSemanticParsingModelsShoppingAssistantOffer(data: any): NlpSemanticParsingModelsShoppingAssistantOffer {
  return {
    ...data,
    docid: data["docid"] !== undefined ? String(data["docid"]) : undefined,
    merchant: data["merchant"] !== undefined ? serializeNlpSemanticParsingModelsShoppingAssistantMerchant(data["merchant"]) : undefined,
    product: data["product"] !== undefined ? serializeNlpSemanticParsingModelsShoppingAssistantProduct(data["product"]) : undefined,
    store: data["store"] !== undefined ? serializeNlpSemanticParsingModelsShoppingAssistantStore(data["store"]) : undefined,
  };
}

function deserializeNlpSemanticParsingModelsShoppingAssistantOffer(data: any): NlpSemanticParsingModelsShoppingAssistantOffer {
  return {
    ...data,
    docid: data["docid"] !== undefined ? BigInt(data["docid"]) : undefined,
    merchant: data["merchant"] !== undefined ? deserializeNlpSemanticParsingModelsShoppingAssistantMerchant(data["merchant"]) : undefined,
    product: data["product"] !== undefined ? deserializeNlpSemanticParsingModelsShoppingAssistantProduct(data["product"]) : undefined,
    store: data["store"] !== undefined ? deserializeNlpSemanticParsingModelsShoppingAssistantStore(data["store"]) : undefined,
  };
}

/**
 * A phrase parsed from a user query.
 */
export interface NlpSemanticParsingModelsShoppingAssistantPhrase {
  brand?: NlpSemanticParsingModelsShoppingAssistantBrandPhrase;
  offer?: NlpSemanticParsingModelsShoppingAssistantOffer;
  product?: NlpSemanticParsingModelsShoppingAssistantProductPhrase;
  unrecognized?: NlpSemanticParsingModelsShoppingAssistantUnrecognizedPhrase;
}

function serializeNlpSemanticParsingModelsShoppingAssistantPhrase(data: any): NlpSemanticParsingModelsShoppingAssistantPhrase {
  return {
    ...data,
    offer: data["offer"] !== undefined ? serializeNlpSemanticParsingModelsShoppingAssistantOffer(data["offer"]) : undefined,
    product: data["product"] !== undefined ? serializeNlpSemanticParsingModelsShoppingAssistantProductPhrase(data["product"]) : undefined,
  };
}

function deserializeNlpSemanticParsingModelsShoppingAssistantPhrase(data: any): NlpSemanticParsingModelsShoppingAssistantPhrase {
  return {
    ...data,
    offer: data["offer"] !== undefined ? deserializeNlpSemanticParsingModelsShoppingAssistantOffer(data["offer"]) : undefined,
    product: data["product"] !== undefined ? deserializeNlpSemanticParsingModelsShoppingAssistantProductPhrase(data["product"]) : undefined,
  };
}

/**
 * A product that can be purchased.
 */
export interface NlpSemanticParsingModelsShoppingAssistantProduct {
  /**
   * The shopping catalog identifier.
   */
  catalogId?: bigint;
  /**
   * The highes price this product is available for.
   */
  maxPrice?: NlpSemanticParsingModelsMoneyMoney;
  /**
   * TODO(ppoudyal) Add logging for media_product.
   */
  mediaProduct?: NlpSemanticParsingModelsShoppingAssistantProductMediaProduct;
  /**
   * Optional. Knowledge Graph identifier for the product.
   */
  mid?: string;
  /**
   * The lowest price this product is available for.
   */
  minPrice?: NlpSemanticParsingModelsMoneyMoney;
  /**
   * Title of the product. Example: Moto X Blue 64GB Note: This refers to only
   * the catalog title not user specified phrase
   */
  title?: string;
}

function serializeNlpSemanticParsingModelsShoppingAssistantProduct(data: any): NlpSemanticParsingModelsShoppingAssistantProduct {
  return {
    ...data,
    catalogId: data["catalogId"] !== undefined ? String(data["catalogId"]) : undefined,
  };
}

function deserializeNlpSemanticParsingModelsShoppingAssistantProduct(data: any): NlpSemanticParsingModelsShoppingAssistantProduct {
  return {
    ...data,
    catalogId: data["catalogId"] !== undefined ? BigInt(data["catalogId"]) : undefined,
  };
}

/**
 * Whether the product being described fits into specific categories (e.g.,
 * "video games").
 */
export interface NlpSemanticParsingModelsShoppingAssistantProductClassification {
  /**
   * TODO(ppoudyal) Expand confidence to cases where the product phrase might
   * be a book/movie/video_game but isn't just a title The score (between 0 - 1)
   * measuring the confidence that product
   */
  bookConfidence?: number;
  /**
   * TODO(ppoudyal) Deprecate is_video_game once the score covers all cases
   * covered by $VideoGameProductPhrase The product phrase contains a video game
   * title.
   */
  isVideoGame?: boolean;
  /**
   * phrase mentions a book title The score (between 0 - 1) measuring the
   * confidence that product
   */
  movieConfidence?: number;
  /**
   * phrase mentions a movie title The score (between 0 - 1) measuring the
   * confidence that product
   */
  videoGameConfidence?: number;
}

/**
 * An expression parsed from a user query that describes a product or set of
 * products.
 */
export interface NlpSemanticParsingModelsShoppingAssistantProductExpression {
  /**
   * This field should not be used by clients of the grammar. It is intended to
   * be used internally in Aqua for metric and regression tests.
   */
  evalData?: NlpSemanticParsingAnnotationEvalData;
  grammaticalGender?:  | "UNKNOWN_GENDER" | "FEMININE" | "MASCULINE";
  grammaticalNumber?:  | "UNKNOWN_NUMBER" | "PLURAL" | "SINGULAR" | "DUAL";
  /**
   * Ordered list of phrases that the user used to describe a product.
   */
  phrases?: NlpSemanticParsingModelsShoppingAssistantPhrase[];
  productClassification?: NlpSemanticParsingModelsShoppingAssistantProductClassification;
  /**
   * Associated shopping list item info. Only set when the product is come from
   * a shopping list item.
   */
  shoppingListItemInfo?: NlpSemanticParsingModelsShoppingAssistantShoppingListItemInfo;
}

function serializeNlpSemanticParsingModelsShoppingAssistantProductExpression(data: any): NlpSemanticParsingModelsShoppingAssistantProductExpression {
  return {
    ...data,
    phrases: data["phrases"] !== undefined ? data["phrases"].map((item: any) => (serializeNlpSemanticParsingModelsShoppingAssistantPhrase(item))) : undefined,
  };
}

function deserializeNlpSemanticParsingModelsShoppingAssistantProductExpression(data: any): NlpSemanticParsingModelsShoppingAssistantProductExpression {
  return {
    ...data,
    phrases: data["phrases"] !== undefined ? data["phrases"].map((item: any) => (deserializeNlpSemanticParsingModelsShoppingAssistantPhrase(item))) : undefined,
  };
}

/**
 * A media product that can be purchased
 */
export interface NlpSemanticParsingModelsShoppingAssistantProductMediaProduct {
  /**
   * The author of the media
   */
  author?: NlpSemanticParsingModelsShoppingAssistantProductMediaProductMediaAttributeValue;
  /**
   * The genre of the media
   */
  genre?: NlpSemanticParsingModelsShoppingAssistantProductMediaProductMediaAttributeValue;
  /**
   * The title of the media Example: The assasin's creed
   */
  mediaTitle?: NlpSemanticParsingModelsShoppingAssistantProductMediaProductMediaAttributeValue;
  /**
   * Order in media series (series title is given by the product title)
   */
  orderInSeries?: NlpSemanticParsingModelsShoppingAssistantProductMediaProductMediaAttributeValue;
  /**
   * The topic of the media
   */
  topic?: NlpSemanticParsingModelsShoppingAssistantProductMediaProductMediaAttributeValue;
}

export interface NlpSemanticParsingModelsShoppingAssistantProductMediaProductMediaAttributeValue {
  /**
   * The knowledge graph identifier for the attribute
   */
  mid?: string;
  /**
   * Raw text of the media attribute (eg. author)
   */
  rawText?: string;
}

/**
 * A product can be any combination of raw_text and metadata (including mid,
 * shopping product catalog title/id, and media attributes). A product phrase
 * refers to a product at the catalog entry level and/or a media product. Media
 * product contains information about author and media title TODO(ppoudyal) Add
 * genre and order_in_series to MediaProduct
 */
export interface NlpSemanticParsingModelsShoppingAssistantProductPhrase {
  metadata?: NlpSemanticParsingModelsShoppingAssistantProduct;
  rawText?: string;
}

function serializeNlpSemanticParsingModelsShoppingAssistantProductPhrase(data: any): NlpSemanticParsingModelsShoppingAssistantProductPhrase {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? serializeNlpSemanticParsingModelsShoppingAssistantProduct(data["metadata"]) : undefined,
  };
}

function deserializeNlpSemanticParsingModelsShoppingAssistantProductPhrase(data: any): NlpSemanticParsingModelsShoppingAssistantProductPhrase {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? deserializeNlpSemanticParsingModelsShoppingAssistantProduct(data["metadata"]) : undefined,
  };
}

export interface NlpSemanticParsingModelsShoppingAssistantShoppingListItemInfo {
  itemId?: string;
  listId?: string;
}

/**
 * A merchant's physical store.
 */
export interface NlpSemanticParsingModelsShoppingAssistantStore {
  /**
   * Local store identifier.
   */
  id?: bigint;
  /**
   * The location of the store.
   */
  location?: NlpSemanticParsingLocalLocation;
  /**
   * A name for the store. Example: Walmart - Cranberry
   */
  name?: string;
}

function serializeNlpSemanticParsingModelsShoppingAssistantStore(data: any): NlpSemanticParsingModelsShoppingAssistantStore {
  return {
    ...data,
    id: data["id"] !== undefined ? String(data["id"]) : undefined,
    location: data["location"] !== undefined ? serializeNlpSemanticParsingLocalLocation(data["location"]) : undefined,
  };
}

function deserializeNlpSemanticParsingModelsShoppingAssistantStore(data: any): NlpSemanticParsingModelsShoppingAssistantStore {
  return {
    ...data,
    id: data["id"] !== undefined ? BigInt(data["id"]) : undefined,
    location: data["location"] !== undefined ? deserializeNlpSemanticParsingLocalLocation(data["location"]) : undefined,
  };
}

/**
 * A span in a user query that could not be identified as any other type of
 * `Phrase`.
 */
export interface NlpSemanticParsingModelsShoppingAssistantUnrecognizedPhrase {
  rawText?: string;
}

export interface NlpSemanticParsingNumberFractionNumber {
  denominator?: NlpSemanticParsingNumberSimpleNumber;
  /**
   * Fields for fraction numbers
   */
  numerator?: NlpSemanticParsingNumberSimpleNumber;
  /**
   * This field is used to indicate the number of digits after the decimal
   * point in the normalized_value field in number.proto, which contains the
   * floating point representation of the fraction
   */
  precision?: number;
  /**
   * This field is set only for mixed fraction
   */
  wholeNumber?: NlpSemanticParsingNumberSimpleNumber;
}

/**
 * Next ID: 9
 */
export interface NlpSemanticParsingNumberNumber {
  /**
   * Span info of the annotation - mostly used for evaluation purpose. Note:
   * this data must never be used outside Aqua because it relies on the internal
   * tokenization used in Aqua that could change over time.
   */
  evalData?: NlpSemanticParsingAnnotationEvalData;
  fractionNumber?: NlpSemanticParsingNumberFractionNumber;
  /**
   * An optional field that holds whether the number_type number is a
   * normalized spelled-out number or not. This field will not be set in cases
   * when this information is not available.
   */
  isSpelledOut?: boolean;
  /**
   * NumberModifier is used to capture when the expression is not an absolute
   * number, but a number expression to represent an
   * increase/decrease/comparison. E.g. [10 more percent], [5 less].
   */
  modifier?:  | "UNKNOWN" | "ADD" | "SUBTRACT";
  /**
   * Contains a normalized string representation of the numeric value that has:
   * * No digit grouping delimiter (e.g. "," in english). * Decimal mark (if
   * present) as "." (dot). For fraction_number, this contains the floating
   * point representation of the fraction. The number of digits after the
   * decimal point is defined in the precision field of fraction_number.proto.
   */
  normalizedValue?: string;
  /**
   * The raw text of the annotation.
   */
  rawText?: string;
  simpleNumber?: NlpSemanticParsingNumberSimpleNumber;
  /**
   * We expect this field to be set only when is_spelled_out is true.
   */
  spelledOutType?:  | "UNKNOWN_SPELLED_OUT_TYPE" | "FULL_NUMBER" | "LIST_OF_SINGLE_DIGITS" | "SHORTHAND" | "COMBINED";
}

/**
 * Next ID: 8
 */
export interface NlpSemanticParsingNumberSimpleNumber {
  /**
   * The type of decimal mark that was present before normalization. Note:
   * different locales may use different decimal marks.
   */
  decimalMark?:  | "NO_DELIMITER" | "DOT" | "COMMA" | "SPACE";
  /**
   * The type of digit grouping delimiter that was present before
   * normalization. Note: different locales may use different digit grouping
   * delimiters.
   */
  groupingDelimiter?:  | "NO_DELIMITER" | "DOT" | "COMMA" | "SPACE";
  /**
   * We expect this field to be set only when grouping_delimiter is set.
   */
  groupingSystem?:  | "UNKNOWN_GROUPING_SYSTEM" | "GROUPBY_3_DIGITS" | "GROUPBY_4_DIGITS" | "GROUPBY_INDIAN_SYSTEM";
  /**
   * Contains a normalized string representation of the numeric value that has:
   * * No digit grouping delimiter (e.g. "," in english). * Decimal mark (if
   * present) as "." (dot). This field is kept for backward compatibility. The
   * field is also available in number.proto
   */
  normalizedValue?: string;
  /**
   * Stores prefix output by the GRM number grammar (http://b/28623478).
   */
  prefix?: string;
  /**
   * Stores suffix output
   */
  suffix?: string;
  type?:  | "UNKNOWN_NUMBER_TYPE" | "INT" | "FLOAT" | "ORDINAL" | "PERCENTAGE";
}

/**
 * This message should be wire-equivalent to the Entity proto defined in
 * nlp/semantic_parsing/models/personal_intelligence.proto. The message is
 * cloned here to allow legacy intents to extract entities to slots; trying to
 * add Entity to knowledge_answers::intent_query::ArgumentValue creates a BUILD
 * dependency loop. For the proto used for GwsLogs, see
 * logs/proto/knowledge/interpretation/personal_intelligence.proto.
 */
export interface NlpSemanticParsingPersonalIntelligenceEntity {
  /**
   * Used if the entity is an airline with an airline annotation.
   */
  airlineConfig?: TravelFlightsAirlineConfig;
  /**
   * Required, but should only be used inside Aqua. Must not be used by outside
   * clients!!
   */
  evalData?: NlpSemanticParsingAnnotationEvalData;
  /**
   * raw string representation
   */
  name?: string;
  qrefAnnotation?: NlpSemanticParsingQRefAnnotation;
}

function serializeNlpSemanticParsingPersonalIntelligenceEntity(data: any): NlpSemanticParsingPersonalIntelligenceEntity {
  return {
    ...data,
    qrefAnnotation: data["qrefAnnotation"] !== undefined ? serializeNlpSemanticParsingQRefAnnotation(data["qrefAnnotation"]) : undefined,
  };
}

function deserializeNlpSemanticParsingPersonalIntelligenceEntity(data: any): NlpSemanticParsingPersonalIntelligenceEntity {
  return {
    ...data,
    qrefAnnotation: data["qrefAnnotation"] !== undefined ? deserializeNlpSemanticParsingQRefAnnotation(data["qrefAnnotation"]) : undefined,
  };
}

/**
 * A collection of any number of QRefAnnotations that designate a Copley
 * Personal Reference and its Resolutions. This is used to handle personalized
 * intents such as "navigate to my hotel" or "when is my mom's anniversary". See
 * go/copley. This Annotation may contain only a reference with no resolutions
 * for the failure case (go/copley-punts). TODO(bhorst) Rename this to remove
 * the Copley codename.
 */
export interface NlpSemanticParsingPersonalReferenceAnnotation {
  /**
   * A Copley Personal Reference represents a user's reference to a something
   * that could be personal entity, e.g. "my hotel", "mom", "brunch".
   */
  reference?: NlpSemanticParsingQRefAnnotation;
  /**
   * A Copley Personal Resolution represents the resolution of a Reference,
   * e.g. if the user has a reservation at The Kendall Hotel, the reference "my
   * hotel" could be resolved to The Kendall Hotel, and there would be a
   * QRefAnnotation containing the mid and other data. It is possible for there
   * to be zero resolutions for a given reference.
   */
  resolutions?: NlpSemanticParsingQRefAnnotation[];
}

function serializeNlpSemanticParsingPersonalReferenceAnnotation(data: any): NlpSemanticParsingPersonalReferenceAnnotation {
  return {
    ...data,
    reference: data["reference"] !== undefined ? serializeNlpSemanticParsingQRefAnnotation(data["reference"]) : undefined,
    resolutions: data["resolutions"] !== undefined ? data["resolutions"].map((item: any) => (serializeNlpSemanticParsingQRefAnnotation(item))) : undefined,
  };
}

function deserializeNlpSemanticParsingPersonalReferenceAnnotation(data: any): NlpSemanticParsingPersonalReferenceAnnotation {
  return {
    ...data,
    reference: data["reference"] !== undefined ? deserializeNlpSemanticParsingQRefAnnotation(data["reference"]) : undefined,
    resolutions: data["resolutions"] !== undefined ? data["resolutions"].map((item: any) => (deserializeNlpSemanticParsingQRefAnnotation(item))) : undefined,
  };
}

/**
 * In simple cases, each NLU slot will contain one or multiple possible values.
 * But in the case of a composite entity - slots can have a complex tree
 * structure. Each slot can represent a List parameter. List parameters are only
 * allowed at the top level, i.e. lists can't ne nested in maps. Next Id: 9
 * LINT.IfChange
 */
export interface NlpSemanticParsingProtoActionsOnGoogleAogSlot {
  /**
   * ID of the entity of this slot.
   */
  entityId?: string;
  /**
   * Number of bytes of this slot in resolved query.
   */
  numBytes?: number;
  /**
   * Part of input text, matched by that slot. In the case of composite slots,
   * each slot should have its own original.
   */
  original?: string;
  /**
   * Name of parameter of this slot.
   */
  parameterName?: string;
  /**
   * Represents a "list parameter". Each parameter may be declared as a list
   * and have multiple slot values, referenced by a single alias. Each slot
   * value in a list may contain multiple possible values. For example: aqua
   * return 3 dates if the year is not specified in a query - one for the
   * current year, one for the past year, and one for the following year. If
   * user defines a list parameter with type @sys.date, and the query contains
   * multiple dates - we should return a list of possible values for each date
   * from the query, i.e. it will be a list of list of dates.
   */
  slotList?: NlpSemanticParsingProtoActionsOnGoogleSlotList;
  /**
   * Represents a structured value. Used in composite entities. Composite
   * entities can have arbitrary structure.
   */
  slotMap?: NlpSemanticParsingProtoActionsOnGoogleSlotMap;
  /**
   * Start byte position of this slot in resolved query.
   */
  startByte?: number;
  /**
   * One or more possible values. This field does not represent a list
   * parameter.
   */
  value?: NlpSemanticParsingProtoActionsOnGoogleSlotValue;
}

/**
 * Represents datetime. It can be @sys.date, @sys.time or, in some cases,
 * @sys.date-time. Our platform doesn't track seconds, so this field is omitted.
 * Number of seconds should be considered 0. Hour and minute can be 0 in case of
 * dates. In case of time and dateTime, hours and minutes will represent actual
 * time, even if both of them are 0.
 */
export interface NlpSemanticParsingProtoActionsOnGoogleDateTime {
  /**
   * Date value. Note, that month and day are 1 based. If this DateTime is a
   * PARTIAL datetime, then fields have value -1, which means these fields are
   * inferred rather than derived directly from query.
   */
  date?: GoogleTypeDate;
  /**
   * Property of this DateTime value that can be used to match user
   * specification of parameters, e.g. date.recent.
   */
  property?: NlpSemanticParsingProtoActionsOnGoogleDateTimeProperty;
  /**
   * Time value. Only hours and minutes are used. Hours are in 24h format.
   */
  time?: GoogleTypeTimeOfDay;
  /**
   * Timezone field specified only if this DateTime has type TIME or DATETIME.
   */
  timeZone?: GoogleTypeTimeZone;
}

/**
 * Represents properties about a matched DateTime value. Will only be populated
 * for @sys.date-time, @sys.date and @sys.time.
 */
export interface NlpSemanticParsingProtoActionsOnGoogleDateTimeProperty {
  /**
   * Since datetime is a superset of date, time and date&time, this field is
   * used to indicate which type the associated DateTime object belongs to.
   */
  datetimeType?:  | "UNSPECIFIED_TYPE" | "DATE" | "TIME" | "DATETIME";
  /**
   * The relative relationship between this DateTime value and
   * DateTime&Timezone info provided in ClassifyRequest.
   */
  relativeDatetimeType?:  | "UNSPECIFIED_RELATIVE_TYPE" | "RECENT" | "FUTURE_OR_NOW" | "PARTIAL";
}

/**
 * Oneof doesn't allow list, this message is used to inject list as a possible
 * value into Slot.
 */
export interface NlpSemanticParsingProtoActionsOnGoogleSlotList {
  slots?: NlpSemanticParsingProtoActionsOnGoogleAogSlot[];
}

/**
 * Oneof doesn't allow maps, this message is used to inject map as a possible
 * value into Slot.
 */
export interface NlpSemanticParsingProtoActionsOnGoogleSlotMap {
  slots?: {
    [key: string]: NlpSemanticParsingProtoActionsOnGoogleAogSlot
  };
}

/**
 * Contains one or more possible values.
 */
export interface NlpSemanticParsingProtoActionsOnGoogleSlotValue {
  values?: NlpSemanticParsingProtoActionsOnGoogleSlotValueSingleValue[];
}

/**
 * Represents an actual value.
 */
export interface NlpSemanticParsingProtoActionsOnGoogleSlotValueSingleValue {
  /**
   * Represents date or time.
   */
  dateTimeValue?: NlpSemanticParsingProtoActionsOnGoogleDateTime;
  /**
   * Represents a string value.
   */
  stringValue?: string;
  /**
   * This field is only populated by on-device Heron. This field should not be
   * populated by any other service.
   */
  typeValue?: NlpSemanticParsingProtoActionsOnGoogleTypedValue;
}

/**
 * Used by on-device Heron. Contains information about the type of slot value
 * returned.
 */
export interface NlpSemanticParsingProtoActionsOnGoogleTypedValue {
  /**
   * Represents a boolean value.
   */
  boolValue?: boolean;
  /**
   * Represents date or time.
   */
  dateTimeValue?: NlpSemanticParsingProtoActionsOnGoogleDateTime;
  /**
   * Represents number value. In accordance to ParamValue
   * fields(https://source.corp.google.com/piper///depot/google3/third_party/java_src/appactions/proto/app_actions_data.proto;rcl=431529042;l=12)
   */
  numberValue?: number;
  /**
   * Represents a string value.
   */
  stringValue?: string;
}

/**
 * The QRefAnnotator annotates spans of input with freebase-ids and
 * collection-information. NEXT ID TO USE: 41
 */
export interface NlpSemanticParsingQRefAnnotation {
  /**
   * Whether this qref annotation was created by CloseAnswers on Postref.
   * Annotations of this type don't correspond to a particular mention of the
   * entity on the query but rather to an interpretation of the full query.
   */
  addedByCloseAnswers?: boolean;
  /**
   * A copy of the span of canonical (raw) parser input text corresponding to
   * this annotation.
   */
  annotatedSpan?: string;
  /**
   * Attribute ID of a personal_summary_node_child.
   */
  attributeId?: string;
  /**
   * The ID of the cluster (set entity) this entity belongs to.
   */
  clusterId?: string;
  /**
   * Cluster set qref confidence score.
   */
  clusterSetScore?: number;
  /**
   * The set of mids that are members of the same cluster.
   */
  clusterSiblingMid?: string[];
  collectionMembership?: NlpSemanticParsingQRefAnnotationCollectionMembership[];
  /**
   * The confidence (in [0, 1]) of the entity being correctly annotated.
   */
  confidenceScore?: number;
  /**
   * DEPRECATED: Equivalent ids (e.g. de-duped mids) for this entity.
   */
  deprecatedEquivalentMids?: string[];
  /**
   * DEPRECATED: Higher level id's that support the given id. This field has
   * been deprecated in favor of related_entity. b/27363861
   */
  deprecatedMdvcSupportingMid?: string[];
  /**
   * Copy the display info. This can be used by annotators to give grammars a
   * canonical name for an entity. For instance, the media grammar could use it
   * to output the same canonical name for "rock music" and "rock".
   */
  displayName?: string;
  /**
   * The index of the entity from which this annotation is obtained, within the
   * WebrefEntities message in the interpretation defined by
   * interpretation_number, above.
   */
  entityNumber?: number;
  /**
   * The relationship information from QRef. Only included if the QRefAnnotator
   * is initialised with include_annotated_relationships.
   */
  entityRelationship?: NlpSemanticParsingQRefAnnotationEntityRelationship[];
  /**
   * Holds information about the backends which contributed to this entity.
   */
  entitySourceData?: NlpSemanticParsingEntitySourceData;
  /**
   * The mid of the entity in freebase associated with this span.
   */
  freebaseMid?: string;
  /**
   * The Gaia ID for this entity. This is populated generally for people and
   * businesses.
   */
  gaiaId?: bigint;
  /**
   * The shopping global product cluster id(s) of the annotated entity (in KG,
   * the key(s) of type /business/variant_cluster).
   */
  globalProductClusterId?: bigint[];
  /**
   * The index of the QueryJoin interpretation from which this annotation was
   * obtained. This field is not used for entities coming from low-confidence
   * annotations, since such entities are not included in any interpretation.
   */
  interpretationNumber?: number;
  /**
   * True if this entity is an mdvc dimension of some other annotated entity.
   * Only included if the QRefAnnotator is initialised with
   * include_annotated_relationships.
   */
  isMdvcDimension?: boolean;
  /**
   * Whether this annotation originates from nimble. (go/nimble-annotator)
   */
  isNimbleAnnotation?: boolean;
  /**
   * The center point of this location. This is either directly provided by the
   * FeatureProto.center field or the centroid using the points of the polygon
   * in the FeatureProto.
   */
  location?: GeostorePointProto;
  /**
   * The location type of the entity, as an int32 representing a TypeCategory
   * enum value. For example, this could be TYPE_LOCALITY (37) or TYPE_COUNTRY
   * (33). We store this type as an int because including FeatureProto would
   * cause java/com/google/ads/adh/pipeline/bigquery:ProtoCatalog to become too
   * large, resulting in OOM errors.
   */
  locationType?: number;
  /**
   * Whether this entity is low confidence. Not used. Currently whitelisted
   * entities below min_confidence threshold are marked as low confidence and
   * maybe not trusted by downstreams.
   */
  lowConfidence?: boolean;
  matchedLightweightToken?: RepositoryWebrefLightweightTokensMatchedLightweightToken[];
  /**
   * Nested annotations that represent subparts of the given mdvc full
   * annotation. An MDVC full annotation is outputted as the summary node as the
   * root node, and all the children of it as leaves (mdvc_child). QRef outputs
   * a graph of relationships between the mdvc enties, and for mdvc full the
   * aquatator nests the relevant children inside the summary node's proto.
   */
  mdvcChild?: NlpSemanticParsingQRefAnnotation[];
  /**
   * The set of verticals this summary node belongs to.
   */
  mdvcVerticals?: string[];
  /**
   * A list of any implied entities merged into this annotation during parsing.
   * Order is derivation-dependent.
   */
  mergedImpliedEntity?: NlpSemanticParsingQRefAnnotation[];
  merlotCategory?: NlpSemanticParsingQRefAnnotationMerlotCategoryData[];
  /**
   * Metadata to be passed through from the AnnotationContext API.
   */
  otherMetadata?: Proto2BridgeMessageSet;
  /**
   * The geo oyster_id of the entity, relevant only for locations. Only
   * included if the QRefAnnotator is initialised with include_oyster_id.
   */
  oysterId?: GeostoreFeatureIdProto;
  /**
   * Personal summary nodes are compound entities made up of entities and their
   * attributes, where the entities can be compound too. E.g., "my father's
   * mother" can have a summary node annotation of "Mother(Father(Myself))".
   */
  personalSummaryNodeChild?: NlpSemanticParsingQRefAnnotation[];
  /**
   * The shopping product line id(s) of the annotated
   * /business/shopping_product_line entity.
   */
  productLineId?: bigint[];
  /**
   * The confidence (in [0, 1]) that the annotation is reference that implies
   * another entity. (eg "my hotel" in "navigate to my hotel" is reference to
   * explicit hotel from user hotel reservation).
   */
  referenceScore?: number;
  /**
   * Mids related to the given entity
   */
  relatedEntity?: NlpSemanticParsingRelatedEntity[];
  /**
   * The confidence (in [0, 1]) that the annotation was created on an implicit
   * mention (eg my hotel) as opposed to an explicit mention (eg: the westin
   * copley square)
   */
  resolutionScore?: number;
  /**
   * If the annotation was created by using personal data, we record the
   * provenance for that data here.
   */
  sourceTypeList?: CopleySourceTypeList;
  subCluster?: NlpSemanticParsingQRefAnnotationSubCluster[];
}

function serializeNlpSemanticParsingQRefAnnotation(data: any): NlpSemanticParsingQRefAnnotation {
  return {
    ...data,
    gaiaId: data["gaiaId"] !== undefined ? String(data["gaiaId"]) : undefined,
    globalProductClusterId: data["globalProductClusterId"] !== undefined ? data["globalProductClusterId"].map((item: any) => (String(item))) : undefined,
    matchedLightweightToken: data["matchedLightweightToken"] !== undefined ? data["matchedLightweightToken"].map((item: any) => (serializeRepositoryWebrefLightweightTokensMatchedLightweightToken(item))) : undefined,
    mdvcChild: data["mdvcChild"] !== undefined ? data["mdvcChild"].map((item: any) => (serializeNlpSemanticParsingQRefAnnotation(item))) : undefined,
    mergedImpliedEntity: data["mergedImpliedEntity"] !== undefined ? data["mergedImpliedEntity"].map((item: any) => (serializeNlpSemanticParsingQRefAnnotation(item))) : undefined,
    oysterId: data["oysterId"] !== undefined ? serializeGeostoreFeatureIdProto(data["oysterId"]) : undefined,
    personalSummaryNodeChild: data["personalSummaryNodeChild"] !== undefined ? data["personalSummaryNodeChild"].map((item: any) => (serializeNlpSemanticParsingQRefAnnotation(item))) : undefined,
    productLineId: data["productLineId"] !== undefined ? data["productLineId"].map((item: any) => (String(item))) : undefined,
    sourceTypeList: data["sourceTypeList"] !== undefined ? serializeCopleySourceTypeList(data["sourceTypeList"]) : undefined,
  };
}

function deserializeNlpSemanticParsingQRefAnnotation(data: any): NlpSemanticParsingQRefAnnotation {
  return {
    ...data,
    gaiaId: data["gaiaId"] !== undefined ? BigInt(data["gaiaId"]) : undefined,
    globalProductClusterId: data["globalProductClusterId"] !== undefined ? data["globalProductClusterId"].map((item: any) => (BigInt(item))) : undefined,
    matchedLightweightToken: data["matchedLightweightToken"] !== undefined ? data["matchedLightweightToken"].map((item: any) => (deserializeRepositoryWebrefLightweightTokensMatchedLightweightToken(item))) : undefined,
    mdvcChild: data["mdvcChild"] !== undefined ? data["mdvcChild"].map((item: any) => (deserializeNlpSemanticParsingQRefAnnotation(item))) : undefined,
    mergedImpliedEntity: data["mergedImpliedEntity"] !== undefined ? data["mergedImpliedEntity"].map((item: any) => (deserializeNlpSemanticParsingQRefAnnotation(item))) : undefined,
    oysterId: data["oysterId"] !== undefined ? deserializeGeostoreFeatureIdProto(data["oysterId"]) : undefined,
    personalSummaryNodeChild: data["personalSummaryNodeChild"] !== undefined ? data["personalSummaryNodeChild"].map((item: any) => (deserializeNlpSemanticParsingQRefAnnotation(item))) : undefined,
    productLineId: data["productLineId"] !== undefined ? data["productLineId"].map((item: any) => (BigInt(item))) : undefined,
    sourceTypeList: data["sourceTypeList"] !== undefined ? deserializeCopleySourceTypeList(data["sourceTypeList"]) : undefined,
  };
}

export interface NlpSemanticParsingQRefAnnotationCollectionMembership {
  /**
   * Identifier of the collection. Usually something like
   * "/collection/us_states".
   */
  collectionId?: string;
  /**
   * A value in [0, 1] indicating the relevance of the collection given this
   * entity. NOTE: This field is deprecated and will stop being populated soon.
   * In the meantime, it will always be populated with 1.0.
   */
  collectionScore?: number;
}

export interface NlpSemanticParsingQRefAnnotationEntityRelationship {
  /**
   * The index of the other entity in the relationship.
   */
  entityIndex?: number;
  /**
   * True if this entity is implied by the other (includes geo contains).
   */
  impliedBy?: boolean;
  /**
   * True if this entity implies the other (includes geo contained by).
   */
  implies?: boolean;
  /**
   * Names of the relationship links.
   */
  linkPropertyName?: string[];
}

/**
 * Merlot category information. As of Sep2015, this is derived from collection
 * membership, but as that information is planned for deprecation and may need
 * to be replaced as a source for this data, it is extracted separately.
 */
export interface NlpSemanticParsingQRefAnnotationMerlotCategoryData {
  categoryId?: number;
  confidence?: number;
}

/**
 * Keeps track of any individual clusters this mid is a member of. Cluster_id
 * and cluster_sibling_mid stores the cluster all together, while the subcluster
 * keeps track of each individual cluster information separately.
 */
export interface NlpSemanticParsingQRefAnnotationSubCluster {
  clusterId?: string;
  clusterSetScore?: number;
  clusterSiblingMid?: string[];
}

/**
 * A message that stores relations between this annotation and another entity.
 * Stores the mid and the kind of relationship. These links may be consumed
 * downstream for various purposes, including support transfer and other
 * business logic. An example is for the Honda Civic entity. It may have an
 * mdvc_relation that is a generalization_of the 2015 Honda Civic entity. So the
 * Honda Civic would have the following: RelatedEntity { mid = 2015 Honda Civic
 * Mid mdvc_relation = GENERALIZATION_OF } It has no equivalent_relation because
 * it is by default NO_EQUIVALENT. The Honda Civic entity might then have a
 * separate relation to the Old Honda Civic entity, as they are considered the
 * same entity, or the following relation: RelatedEntity { mid = Old Honda Civic
 * Mid equivalent_relation = EQUIVALENT }
 */
export interface NlpSemanticParsingRelatedEntity {
  /**
   * Denotes whether or not the related entity is derived from cluster support
   * transfer.
   */
  clusterSupportTransferRelation?:  | "NO_CLUSTER_SUPPORT" | "CLUSTER_SUPPORT";
  /**
   * Denotes whether or not the related entity composes a compound entity
   * together with other related entities.
   */
  composedFromRelation?:  | "NONE_COMPOSED_FROM" | "COMPOSED_FROM";
  /**
   * Whether or not the given mid is related to the other mid. Equivalent mids
   * are usually mutually exclusive with other kinds of relations.
   */
  equivalentRelation?:  | "NO_EQUIVALENT" | "EQUIVALENT" | "MUNIN_SYNONYM" | "SYNONYM";
  /**
   * The mdvc relation with the related mid.
   */
  mdvcRelation?:  | "NO_MDVC" | "GENERALIZATION_OF" | "SPECIALIZATION_OF" | "HAS_DIMENSION_VALUE" | "IS_DIMENSION_OF";
  /**
   * Mid that is related.
   */
  mid?: string;
  /**
   * Denotes whether or not there was support transfer between the two
   * entities.
   */
  supportTransferRelation?:  | "NO_SUPPORT_TRANSFER" | "SUPPORT_TRANSFER_TARGET" | "SUPPORT_TRANSFER_SOURCE" | "MENTION_TRANSFER_TARGET" | "MENTION_TRANSFER_SOURCE" | "SUPPORT_SHARE_TARGET" | "SUPPORT_SHARE_SOURCE";
  /**
   * Set if the related entity is the source of an STBR rule and the target is
   * not this one.
   */
  targetIsStbrSource?: boolean;
}

/**
 * Identifies a coreference mention (pronoun or nominal) resolved to an entity.
 */
export interface NlpSemanticParsingSaftCoreference {
  /**
   * Categories can be either a $PronounMention or $NominalMention.
   */
  category?: string;
  /**
   * The substring of the raw query spanned by this annotation.
   */
  rawText?: string;
  /**
   * The name of the entity this mentions refers to.
   */
  referentText?: string;
}

/**
 * Identifies a measure, like '53 pounds' in a query.
 */
export interface NlpSemanticParsingSaftMeasure {
  /**
   * Defines the category of measure, like $Mass.
   */
  category?: string;
  /**
   * The substring of the raw query spanned by this annotation.
   */
  rawText?: string;
  /**
   * The numerical value of the measure.
   */
  value?: number;
}

/**
 * SaftMentionAnnotation(s) are used to identify a sub-span of the input with
 * some semantic relevance, for example PER (Person), LOC (Locations) or measure
 * etc. Each SaftMentionAnnotation will have exactly one non-empty field.
 */
export interface NlpSemanticParsingSaftMentionAnnotation {
  /**
   * Annotations for spans that are resolved coreference mentions.
   */
  coreference?: NlpSemanticParsingSaftCoreference;
  /**
   * Annotations for spans like "san francisco giants".
   */
  entity?: NlpSemanticParsingSaftSpan;
  /**
   * Annotations for spans "53 pounds".
   */
  measure?: NlpSemanticParsingSaftMeasure;
  /**
   * Annotations for spans like "the president of the United States".
   */
  title?: NlpSemanticParsingSaftSpan;
}

/**
 * The lowest common denominator of a SAFT annotation is simply the definition
 * of some |category| for a sub-span of the |raw_text| of the query.
 */
export interface NlpSemanticParsingSaftSpan {
  /**
   * Categories can be either syntactic (NNS for fine-grained-POS) or semantics
   * ($Mass for measures).
   */
  category?: string;
  /**
   * The substring of the raw query spanned by this annotation.
   */
  rawText?: string;
}

/**
 * A single byte, such as that from a utf8-encoded character sequence.
 */
export interface NlxDataSchemaByte {
  /**
   * The document that contains this character.
   */
  document?: MultiscalePointerIndex;
}

/**
 * A single Unicode character.
 */
export interface NlxDataSchemaCharacter {
  /**
   * The document that contains this character.
   */
  document?: MultiscalePointerIndex;
  /**
   * The paragraph that contains this character.
   */
  paragraph?: MultiscalePointerIndex;
  /**
   * The sentence that contains this character.
   */
  sentence?: MultiscalePointerIndex;
  /**
   * The character itself. Must contain valid UTF-8. Must be exactly one
   * Unicode character.
   */
  text?: string;
  /**
   * The token that contains this character.
   */
  token?: MultiscalePointerIndex;
}

/**
 * A single document.
 */
export interface NlxDataSchemaDocument {
  /**
   * The author(s) of this document.
   */
  author?: MultiscalePointerIndex[];
  /**
   * The bytes in this document.
   */
  bytes?: MultiscalePointerSpan;
  /**
   * The characters in this document.
   */
  characters?: MultiscalePointerSpan;
  /**
   * The identifier of this document.
   */
  id?: string;
  /**
   * A set of BCP-47 codes indicating the language(s) of this document.
   */
  languageCode?: string[];
  /**
   * The language spans in this document.
   */
  languageSpans?: MultiscalePointerSpan;
  /**
   * The mentions in this document.
   */
  mentions?: MultiscalePointerSpan;
  /**
   * The paragraphs in this document.
   */
  paragraphs?: MultiscalePointerSpan;
  /**
   * The sentences in this document.
   */
  sentences?: MultiscalePointerSpan;
  /**
   * The text of this document. Must contain valid UTF-8.
   */
  text?: string;
  /**
   * The tokens in this document.
   */
  tokens?: MultiscalePointerSpan;
  /**
   * The url of this document.
   */
  url?: string;
}

/**
 * An entity, which may occur multiple times in the text.
 */
export interface NlxDataSchemaEntity {
  /**
   * Entity gender. Default label set is 'masculine', 'feminine', or 'neuter'.
   * (Perhaps in the future we can split 'neuter' into 'inanimate', 'unknown',
   * and 'non-binary'.)
   */
  gender?: string;
  /**
   * Machine identifier, such as those from the Freebase database (or similar
   * entity database).
   */
  mid?: string;
  /**
   * Free-form entity name.
   */
  name?: string;
  /**
   * Entity type, typically something like person/location/organization. The
   * schema for types is not specified. If this entity has a MID, use the mid
   * field instead or in conjunction with the type.
   */
  type?: string[];
}

/**
 * A span of text that is written using a specified language (or languages).
 * language_spans do not need to cover all of the characters in a text -- in
 * particular, some pieces of text may not use any language. Depending on the
 * model used to generate them, multilingual text can be encoded using
 * overlapping or non- overlapping language_spans; and using one or multiple
 * language_codes per language_span.
 */
export interface NlxDataSchemaLanguageSpan {
  /**
   * The bytes in this span.
   */
  bytes?: MultiscalePointerSpan;
  /**
   * The characters in this span.
   */
  characters?: MultiscalePointerSpan;
  /**
   * The document that contains this span.
   */
  document?: MultiscalePointerIndex;
  /**
   * A set of BCP-47 codes indicating the language(s) of this span of text.
   */
  languageCode?: string[];
}

/**
 * A mention of an entity. A single entity might be mentioned multiple times.
 */
export interface NlxDataSchemaMention {
  /**
   * The bytes in this mention.
   */
  bytes?: MultiscalePointerSpan;
  /**
   * The document that contains this mention.
   */
  document?: MultiscalePointerIndex;
  /**
   * The entity that this mention refers to.
   */
  entity?: MultiscalePointerIndex;
  /**
   * Mention kind, typically 'referential', 'attributive', or 'modifier'.
   */
  kind?: string;
  /**
   * The mention text itself. Must contain valid UTF-8.
   */
  text?: string;
  /**
   * The token(s) in this mention. This may not be present, or have zero length
   * if representing an implicit mention, as in the prodrop case.
   */
  tokens?: MultiscalePointerSpan;
  /**
   * Mention type, typically 'named' (for name mentions) or 'nominal'. More
   * types include 'pronominal', 'conjoined' for conjoined mention construction,
   * and 'non-referential' for non-referential pronoun mentions.
   */
  type?: string;
}

/**
 * A single paragraph.
 */
export interface NlxDataSchemaParagraph {
  /**
   * The bytes in this paragraph.
   */
  bytes?: MultiscalePointerSpan;
  /**
   * The characters in this paragraph.
   */
  characters?: MultiscalePointerSpan;
  /**
   * The document that contains this paragraph.
   */
  document?: MultiscalePointerIndex;
  /**
   * The sentences in this paragraph.
   */
  sentences?: MultiscalePointerSpan;
  /**
   * The text of this paragraph. Must contain valid UTF-8.
   */
  text?: string;
  /**
   * The tokens in this paragraph.
   */
  tokens?: MultiscalePointerSpan;
}

/**
 * Standard NLX data schema.
 */
export interface NlxDataSchemaScaleSet {
  byte?: NlxDataSchemaByte[];
  /**
   * Metadata for which layer (scale) fields are present. WARNING: CURRENT
   * USAGE IS AD HOC, DO NOT RELY ON THESE BEING POPULATED CORRECTLY. This
   * should improve in v2.
   */
  byteDocumentPresence?: MultiscaleFieldPresence;
  /**
   * Metadata for which layers (scales) are present. WARNING: CURRENT USAGE IS
   * AD HOC, DO NOT RELY ON THESE BEING POPULATED CORRECTLY. This should improve
   * in v2.
   */
  bytePresence?: MultiscaleLayerPresence;
  character?: NlxDataSchemaCharacter[];
  characterDocumentPresence?: MultiscaleFieldPresence;
  characterParagraphPresence?: MultiscaleFieldPresence;
  characterPresence?: MultiscaleLayerPresence;
  characterSentencePresence?: MultiscaleFieldPresence;
  characterTextPresence?: MultiscaleFieldPresence;
  characterTokenPresence?: MultiscaleFieldPresence;
  document?: NlxDataSchemaDocument[];
  documentAuthorPresence?: MultiscaleFieldPresence;
  documentBytesPresence?: MultiscaleFieldPresence;
  documentCharactersPresence?: MultiscaleFieldPresence;
  documentIdPresence?: MultiscaleFieldPresence;
  documentLanguageCodePresence?: MultiscaleFieldPresence;
  documentLanguageSpansPresence?: MultiscaleFieldPresence;
  documentMentionsPresence?: MultiscaleFieldPresence;
  documentParagraphsPresence?: MultiscaleFieldPresence;
  documentPresence?: MultiscaleLayerPresence;
  documentSentencesPresence?: MultiscaleFieldPresence;
  documentTextPresence?: MultiscaleFieldPresence;
  documentTokensPresence?: MultiscaleFieldPresence;
  documentUrlPresence?: MultiscaleFieldPresence;
  entity?: NlxDataSchemaEntity[];
  entityGenderPresence?: MultiscaleFieldPresence;
  entityMidPresence?: MultiscaleFieldPresence;
  entityNamePresence?: MultiscaleFieldPresence;
  entityPresence?: MultiscaleLayerPresence;
  entityTypePresence?: MultiscaleFieldPresence;
  languageSpan?: NlxDataSchemaLanguageSpan[];
  languageSpanBytesPresence?: MultiscaleFieldPresence;
  languageSpanCharactersPresence?: MultiscaleFieldPresence;
  languageSpanDocumentPresence?: MultiscaleFieldPresence;
  languageSpanLanguageCodePresence?: MultiscaleFieldPresence;
  languageSpanPresence?: MultiscaleLayerPresence;
  mention?: NlxDataSchemaMention[];
  mentionBytesPresence?: MultiscaleFieldPresence;
  mentionDocumentPresence?: MultiscaleFieldPresence;
  mentionEntityPresence?: MultiscaleFieldPresence;
  mentionKindPresence?: MultiscaleFieldPresence;
  mentionPresence?: MultiscaleLayerPresence;
  mentionTextPresence?: MultiscaleFieldPresence;
  mentionTokensPresence?: MultiscaleFieldPresence;
  mentionTypePresence?: MultiscaleFieldPresence;
  paragraph?: NlxDataSchemaParagraph[];
  paragraphBytesPresence?: MultiscaleFieldPresence;
  paragraphCharactersPresence?: MultiscaleFieldPresence;
  paragraphDocumentPresence?: MultiscaleFieldPresence;
  paragraphPresence?: MultiscaleLayerPresence;
  paragraphSentencesPresence?: MultiscaleFieldPresence;
  paragraphTextPresence?: MultiscaleFieldPresence;
  paragraphTokensPresence?: MultiscaleFieldPresence;
  sentence?: NlxDataSchemaSentence[];
  sentenceBytesPresence?: MultiscaleFieldPresence;
  sentenceCharactersPresence?: MultiscaleFieldPresence;
  sentenceDocumentPresence?: MultiscaleFieldPresence;
  sentenceParagraphPresence?: MultiscaleFieldPresence;
  sentencePresence?: MultiscaleLayerPresence;
  sentenceTextPresence?: MultiscaleFieldPresence;
  sentenceTokensPresence?: MultiscaleFieldPresence;
  token?: NlxDataSchemaToken[];
  tokenBytesPresence?: MultiscaleFieldPresence;
  tokenCharactersPresence?: MultiscaleFieldPresence;
  tokenDependencyHeadPresence?: MultiscaleFieldPresence;
  tokenDependencyLabelPresence?: MultiscaleFieldPresence;
  tokenDependencyPresence?: MultiscaleFieldPresence;
  tokenDocumentPresence?: MultiscaleFieldPresence;
  tokenParagraphPresence?: MultiscaleFieldPresence;
  tokenPosPresence?: MultiscaleFieldPresence;
  tokenPresence?: MultiscaleLayerPresence;
  tokenSentencePresence?: MultiscaleFieldPresence;
  tokenTextPresence?: MultiscaleFieldPresence;
}

/**
 * A single sentence or utterance.
 */
export interface NlxDataSchemaSentence {
  /**
   * The bytes in this sentence.
   */
  bytes?: MultiscalePointerSpan;
  /**
   * The characters in this sentence.
   */
  characters?: MultiscalePointerSpan;
  /**
   * The document that contains this sentence.
   */
  document?: MultiscalePointerIndex;
  /**
   * The paragraph that contains this sentence.
   */
  paragraph?: MultiscalePointerIndex;
  /**
   * The text of this sentence. Must contain valid UTF-8.
   */
  text?: string;
  /**
   * The tokens in this sentence.
   */
  tokens?: MultiscalePointerSpan;
}

/**
 * A word, punctuation mark, or other small piece of text.
 */
export interface NlxDataSchemaToken {
  /**
   * The bytes in this token.
   */
  bytes?: MultiscalePointerSpan;
  /**
   * The characters in this token.
   */
  characters?: MultiscalePointerSpan;
  /**
   * DEPRECATED: PLEASE USE dependency_head AND dependency_label FIELDS. One
   * edge of the dependency parse.
   */
  dependency?: NlxDataSchemaTokenDependencyEdge;
  /**
   * The head of this token. By default, the root of the sentence is its own
   * head; it should also have deprel as 'root'.
   */
  dependencyHead?: MultiscalePointerIndex;
  /**
   * Relation label for this dependency. Generally this should be using the
   * Universal Dependencies label format, using fine-grained labels like
   * nsubj:pass.
   */
  dependencyLabel?: string;
  /**
   * The document that contains this token.
   */
  document?: MultiscalePointerIndex;
  /**
   * The paragraph that contains this token.
   */
  paragraph?: MultiscalePointerIndex;
  /**
   * Coarse part-of-speech tag.
   */
  pos?: string;
  /**
   * The sentence that contains this token.
   */
  sentence?: MultiscalePointerIndex;
  /**
   * The text of this token. Must contain valid UTF-8.
   */
  text?: string;
}

/**
 * DEPRECATED: PLEASE USE dependency_head AND dependency_label FIELDS. One edge
 * of the dependency parse.
 */
export interface NlxDataSchemaTokenDependencyEdge {
  /**
   * Relation label for this dependency. Generally this should be using the
   * Universal Dependencies label format, using fine- grained labels like
   * nsubj:pass.
   */
  deprel?: string;
  /**
   * The head of this token. By default, the root of the sentence is its own
   * head; it should also have deprel as 'root'.
   */
  head?: MultiscalePointerIndex;
}

/**
 * Message representing a versioned NSR score used for experimentation. This
 * protobuf is copied from quality_nsr::NSRVersionedItem.
 */
export interface NSRVersionedItem {
  /**
   * The NSR value corresponding to this version.
   */
  value?: number;
  /**
   * The version id.
   */
  versionId?: number;
}

/**
 * Metadata describing an 'item' (article) in a Woodwing file.
 */
export interface OceanDataDocinfoWoodwingItemMetadata {
  author?: string;
  category?: string;
  description?: string;
  title?: string;
}

/**
 * Ocean data in docserver results (whole documents)
 */
export interface OceanDocInfo {
  /**
   * data returned with search docresults (snippets)
   */
  docTag?: OceanDocTag;
}

function serializeOceanDocInfo(data: any): OceanDocInfo {
  return {
    ...data,
    docTag: data["docTag"] !== undefined ? serializeOceanDocTag(data["docTag"]) : undefined,
  };
}

function deserializeOceanDocInfo(data: any): OceanDocInfo {
  return {
    ...data,
    docTag: data["docTag"] !== undefined ? deserializeOceanDocTag(data["docTag"]) : undefined,
  };
}

/**
 * ============> Next available number: 102 (ksridhara) <================
 */
export interface OceanDocTag {
  /**
   * TODO(leonid) Deprecate these Authors string for front end.
   */
  authors?: string;
  /**
   * A bitmap containing all available download formats (values defined in
   * AvaialableDownloadFormats enum) NOTE: Only populated for Volume level docs
   */
  availableDownloads?: number;
  blockSnippet?: boolean;
  bookspecific?: OceanDocTagBookSpecific;
  catalogspecific?: OceanDocTagCatalogSpecific;
  /**
   * The content type of the document. See BoundVolumeSource::ContentType in
   * ocean/data/volume_types.protodevel for possible values.
   */
  contentType?: number;
  contributor?: OceanDocTagContributor[];
  /**
   * cover page (PrintedAsSeen string), to generate results snippet thumbnail
   * image urls
   */
  coverPage?: string;
  /**
   * The size (in pixels) of the full-resolution clean images used for the
   * cover page. The width and height will be zero if no image for that page.
   */
  coverPageSize?: OceanImageSize;
  /**
   * this is in ONIX format.
   */
  DEPRECATEDApplicationDate?: string;
  /**
   * this is in ONIX format.
   */
  DEPRECATEDIssueDate?: string;
  DEPRECATEDPatentAssignee?: string;
  /**
   * patent-specific fields. ALL DEPRECATED, moved into PatentSpecific group,
   * above.
   */
  DEPRECATEDPatentNumber?: string;
  /**
   * Percent rights granted by publisher. This should only be set, and
   * definitely should only be considered, if source_type ==
   * BoundVolumeSource::PUBLISHER. '0' may mean we have no info on publisher
   * rights so we have to just assume 0%. Deprecated as this is taken into
   * account by viewability
   */
  DEPRECATEDPublisherPercentVisible?: number;
  /**
   * Editors string for front end.
   */
  editors?: string;
  encryptedExpressionId?: string;
  encryptedVolumeId?: string;
  /**
   * DEPRECATED! Being replaced in favor of viewability, below. geo restrict
   * info (from OceanRights::geo_restrict) In CAv2: geo restrict info (from
   * ocean::VolumeImprintRights::geo_restrict)
   */
  geoRestrict?: string[];
  /**
   * Text quality as defined in
   * CA_VolumeScoreResult::OACapabilities::TextQualityAssessment Note - This is
   * only populated if good_text() and is_ge_quality() are true
   */
  goodTextDetail?: number;
  /**
   * List of locales for which this book can be bought from a publisher, and
   * read as a Google eBook. Each locale is a lowercase, two-letter country-code
   * (eg "ca"), and is copied from PublisherGrantability.Locale.locale, defined
   * in ocean/data/docinfo/volume_viewability.proto.
   */
  grantableLocale?: string[];
  /**
   * Set to true if volume has ge quality
   */
  isGeQuality?: boolean;
  /**
   * whether this a landing page chosen at indexing time.
   */
  isLandingPage?: boolean;
  magazinespecific?: OceanDocTagMagazineSpecific;
  /**
   * metadata_cover_exists will be set if there's a metadata-provided cover
   * thumbnail. the thumbnail will be used for scanless books or when a scanned
   * book is in metadata-only view.
   */
  metadataCoverExists?: boolean;
  /**
   * The size (in pixels) of the metadata cover image.
   */
  metadataCoverSize?: OceanImageSize;
  newspaperspecific?: OceanDocTagNewspaperSpecific;
  /**
   * Number of pages in this volume (usually as specified in metadata)
   */
  numPages?: number;
  /**
   * A bitmap indicating whether content may be objectionable NOTE: Only
   * populated for volume level docs
   */
  objectionableContentBitmap?: number;
  /**
   * pageid of the page (OceanTypes::PageIdType)
   */
  pageid?: number;
  /**
   * page_number of the page (OceanTypes::PageNumberType) In CAv2: page_number
   * of the page ocean::PageNumber::T
   */
  pageNumber?: number;
  /**
   * the page rank value of the book page
   */
  pagerank?: number;
  patentspecific?: OceanDocTagPatentSpecific;
  /**
   * Price information for a volume (per locale). Note existence of a price for
   * a locale implies that the book is sellable for that locale.
   */
  price?: OceanGEPrice;
  /**
   * printed page number (OceanPrintedPageNumber; from
   * OceanPageInfoMap::Page::printed_page_number)
   */
  printedPageNumber?: string;
  /**
   * the URL of the reference page (About this book)
   */
  refPageUrl?: string;
  /**
   * the URL for the "search in book"
   */
  searchInBookUrl?: string;
  segmentTime?: number;
  /**
   * The source type of the document. See BoundVolumeSource::SourceType in
   * ocean/data/volume_types.protodevel for possible values.
   */
  sourceType?: number;
  /**
   * In CAv2 only: structured page number (printed number as we understand it)
   * (result of ocean::StructuredPageNumberProto::AppendToString)
   */
  structuredPageNumber?: string;
  /**
   * Bitmap indicating top-level subjects associated with this document. See
   * ocean/metadata/subjects/util.h for more detail.
   */
  subjectBitmap?: Uint8Array;
  /**
   * Sub title string for front end
   */
  subTitle?: string;
  /**
   * the URL of the cover page.
   */
  thumbnailUrl?: string;
  /**
   * Title string for front end.
   */
  title?: string;
  /**
   * Bibkey to be used as part of the URL (to make them persistent in some
   * sense). This is obtained by doing a GetURLKey() on the bibdata which
   * returns the main bibkey associated with the volume based on priority. This
   * is parseable into an OceanVolumeBibKey (ocean/metadata/bibkeys.h) Note:
   * This should ideally be a required field longer term but for now keeping it
   * optional for compatibility. In case of this being absent, we don't include
   * the key in the URL (just use volumeId as before). Note: For content type
   * books, this key is supplemented by other bibkeys for this volumes(the field
   * is aux_bibkeys)
   */
  urlKey?: string;
  /**
   * using_actual_cover will be set if we are using the actual cover of the
   * book (instead of the table of content, etc.). This is particularly useful
   * to identify books where we inserted a generated cover via Coverups.
   */
  usingActualCover?: boolean;
  /**
   * Volume viewability, which defines how/if the volume should be displayed in
   * various locales.
   */
  viewability?: OceanVolumeViewability;
  volumeType?: number;
  /**
   * The version of the volume (serialized form). ONLY populated for Volume
   * level docs
   */
  volumeVersion?: string;
  workcluster?: OceanDocTagWorkCluster;
}

function serializeOceanDocTag(data: any): OceanDocTag {
  return {
    ...data,
    bookspecific: data["bookspecific"] !== undefined ? serializeOceanDocTagBookSpecific(data["bookspecific"]) : undefined,
    magazinespecific: data["magazinespecific"] !== undefined ? serializeOceanDocTagMagazineSpecific(data["magazinespecific"]) : undefined,
    price: data["price"] !== undefined ? serializeOceanGEPrice(data["price"]) : undefined,
    subjectBitmap: data["subjectBitmap"] !== undefined ? encodeBase64(data["subjectBitmap"]) : undefined,
    viewability: data["viewability"] !== undefined ? serializeOceanVolumeViewability(data["viewability"]) : undefined,
    workcluster: data["workcluster"] !== undefined ? serializeOceanDocTagWorkCluster(data["workcluster"]) : undefined,
  };
}

function deserializeOceanDocTag(data: any): OceanDocTag {
  return {
    ...data,
    bookspecific: data["bookspecific"] !== undefined ? deserializeOceanDocTagBookSpecific(data["bookspecific"]) : undefined,
    magazinespecific: data["magazinespecific"] !== undefined ? deserializeOceanDocTagMagazineSpecific(data["magazinespecific"]) : undefined,
    price: data["price"] !== undefined ? deserializeOceanGEPrice(data["price"]) : undefined,
    subjectBitmap: data["subjectBitmap"] !== undefined ? decodeBase64(data["subjectBitmap"] as string) : undefined,
    viewability: data["viewability"] !== undefined ? deserializeOceanVolumeViewability(data["viewability"]) : undefined,
    workcluster: data["workcluster"] !== undefined ? deserializeOceanDocTagWorkCluster(data["workcluster"]) : undefined,
  };
}

/**
 * Book specific fields.
 */
export interface OceanDocTagBookSpecific {
  /**
   * These are other bibkeys for this book beside the url_key, which is the
   * primary key. For example, a book may have ISBN, OCLC num etc. In that case
   * ISBN is the url_key and the OCLC number is the auxillary bibkey. The
   * aux_bibkeys should have the same form as the url_key
   */
  auxBibkeys?: string[];
  imprint?: string;
  numberingrange?: OceanDocTagBookSpecificNumberingRange[];
  numRatingHalfStars?: number;
  /**
   * publisher id, if available
   */
  partnerId?: bigint;
  /**
   * Set if the book is one of several editions or versions. Used by OFE to
   * show numbered editions. The value is copied from clustering information.
   * See also ocean/metadata/proto/bibdata_components.proto The value there is
   * from metadata records by ocean/metadata/parsing/parse_utils.cc, and is a
   * 1-based value.
   */
  productEditionNumber?: number;
  /**
   * In the format yyyy.mm.dd, or possibly just yyyy.
   */
  publicationDate?: string;
  publisherName?: string;
  /**
   * Subject (from Bisac)
   */
  subject?: string;
}

function serializeOceanDocTagBookSpecific(data: any): OceanDocTagBookSpecific {
  return {
    ...data,
    numberingrange: data["numberingrange"] !== undefined ? data["numberingrange"].map((item: any) => (serializeOceanDocTagBookSpecificNumberingRange(item))) : undefined,
    partnerId: data["partnerId"] !== undefined ? String(data["partnerId"]) : undefined,
  };
}

function deserializeOceanDocTagBookSpecific(data: any): OceanDocTagBookSpecific {
  return {
    ...data,
    numberingrange: data["numberingrange"] !== undefined ? data["numberingrange"].map((item: any) => (deserializeOceanDocTagBookSpecificNumberingRange(item))) : undefined,
    partnerId: data["partnerId"] !== undefined ? BigInt(data["partnerId"]) : undefined,
  };
}

/**
 * These are copies of MetadataNumberingRange's from
 * ocean/metadata/metadata_range.proto. They should be used for rendering volume
 * numbering information in search results (as this protobuf is the only piece
 * of data available at that point). The numbering can look like "Volume 1" or
 * "Parts A-D" Schema is volume/part/etc, type arabic number/roman
 * number/letter/etc (these are both enums from
 * ocean/metadata/metadata_enums.proto). In most cases there is only one
 * numbering range (e.g. "Volume 1, Issue 2"), but in general the ranges may be
 * disjoint (e.g. "Volumes 2, 3 and 7")
 */
export interface OceanDocTagBookSpecificNumberingRange {
  endNumbering?: bigint[];
  numberingSchema?: number[];
  numberType?: number[];
  startNumbering?: bigint[];
}

function serializeOceanDocTagBookSpecificNumberingRange(data: any): OceanDocTagBookSpecificNumberingRange {
  return {
    ...data,
    endNumbering: data["endNumbering"] !== undefined ? data["endNumbering"].map((item: any) => (String(item))) : undefined,
    startNumbering: data["startNumbering"] !== undefined ? data["startNumbering"].map((item: any) => (String(item))) : undefined,
  };
}

function deserializeOceanDocTagBookSpecificNumberingRange(data: any): OceanDocTagBookSpecificNumberingRange {
  return {
    ...data,
    endNumbering: data["endNumbering"] !== undefined ? data["endNumbering"].map((item: any) => (BigInt(item))) : undefined,
    startNumbering: data["startNumbering"] !== undefined ? data["startNumbering"].map((item: any) => (BigInt(item))) : undefined,
  };
}

/**
 * catalog-specific fields.
 */
export interface OceanDocTagCatalogSpecific {
  /**
   * Is this the latest issue of this catalog series? This is required to
   * filter results if the latest restrict is on.
   */
  latest?: boolean;
  /**
   * time_t date corresponding to the catalog publication date. Approximate
   * when the catalog does not have an exact "date" of publication, e.g. For
   * "Spring 2002", year, month and day are 2002, 03 and 21, respectivley. This
   * value is used to compare catalog issues to determine the latest. The value
   * is stored in seconds-since-epoch, 1/1/1970. This is not a problem for
   * catalogs because we are not dealing with any catalogs from before the 70's.
   */
  publicationDate?: number;
  /**
   * String to be displayed as catalog publication time, e.g. "Spring 2002".
   */
  publicationTimeToDisplay?: string;
}

/**
 * The composite descriptor of the contributors that should be known to search
 * and front end. Both fields are required. Replaces authors and editors
 * strings.
 */
export interface OceanDocTagContributor {
  name?: string;
  /**
   * ContributionType enum from ocean/metadata/metadata_enums.proto Note that
   * we pick only the "highest-ranking" contribution (i.e. writer and editor
   * would collapse to "writer".
   */
  type?: number;
}

/**
 * Magazine-specific fields. See
 * https://www.corp.google.com/eng/designdocs/scanning/magazines/designdoc.html
 * for magazine design doc.
 */
export interface OceanDocTagMagazineSpecific {
  /**
   * A human-readable date for display in the UI. Unlike "publication_date_"
   * above, this should not be parsed into structured data, but should only be
   * displayed as is.
   */
  displayDate?: string;
  /**
   * Description specific to a magazine issue, such as featured articles and
   * article summaries.
   */
  issueDescription?: string;
  issueEnd?: number;
  issueStart?: number;
  /**
   * Items within a magazine issue.
   */
  item?: OceanDataDocinfoWoodwingItemMetadata[];
  otherNumberingEnd?: number;
  /**
   * NOTE: These should to be values from MetadataNumberingSchema; when this
   * becomes a proto2, we can use MetadataEnums values.
   */
  otherNumberingSchema?: number;
  /**
   * For season or quarter dates.
   */
  otherNumberingStart?: number;
  /**
   * For each page of a magazine, maps to the item index of "item".
   */
  pageToItem?: number[];
  publicationDateEnd?: string;
  publicationDateStart?: string;
  /**
   * This is used to render the metadata line of the snippet and should be
   * present in all magazine documents.
   */
  serialTitle?: string;
  serialVolumeid?: bigint;
  volume?: number;
}

function serializeOceanDocTagMagazineSpecific(data: any): OceanDocTagMagazineSpecific {
  return {
    ...data,
    serialVolumeid: data["serialVolumeid"] !== undefined ? String(data["serialVolumeid"]) : undefined,
  };
}

function deserializeOceanDocTagMagazineSpecific(data: any): OceanDocTagMagazineSpecific {
  return {
    ...data,
    serialVolumeid: data["serialVolumeid"] !== undefined ? BigInt(data["serialVolumeid"]) : undefined,
  };
}

/**
 * Newspaper-specific fields.
 */
export interface OceanDocTagNewspaperSpecific {
  /**
   * Newspaper Article Roll Coordinates used to figure out the location of the
   * article wrt the page. It is of the form x,y.
   */
  articleRollCoords?: string;
  /**
   * Atlantis specific. Deprecated.
   */
  newspaperDate?: number;
  newspaperName?: string;
  /**
   * Atlantis specific. Deprecated.
   */
  newspaperUrl?: string;
  /**
   * These fields are only populated for Santorini (newspapers on goovols)
   * formatted newspapers, not for Atlantis: YYYY.MM.DD format.
   */
  publicationDate?: string;
  /**
   * Atlantis specific. Deprecated.
   */
  publisher?: string;
}

/**
 * Patent specific fields. Currently empty, but need to move the fields below
 * into here at a later date
 */
export interface OceanDocTagPatentSpecific {
  /**
   * this is in ONIX format.
   */
  applicationDate?: string;
  /**
   * 2-letter language of the document such as "en" or "fr" This field was
   * created for plumbing in the OFE API intl patent flow, and is probably not
   * otherwise filled in.
   */
  contentLanguage?: string;
  docType?: number;
  /**
   * Just the number, no bibkey prefix. Called 'doc number' b/c it could be
   * patent number for patents, application number for applications.
   */
  documentNumber?: string;
  /**
   * US and Int'l patent classification codes for "related patents".
   */
  domesticClassification?: string[];
  internationalClassification?: string[];
  /**
   * this is in ONIX format.
   */
  issueDate?: string;
  patentAssignee?: string;
  /**
   * For applications, the 'publication number' Something like US20071234567A1:
   * 'US' prefix, 4 digit year, 7 digit serial number, 2 character code, all
   * stuck together.
   */
  publicationNumber?: string;
  /**
   * Path identifying the image used for the thumbnail of this patent. e.g.
   * "EP1234567B1/imgf0001.png" The client is expected to fill in the rest of
   * the url such as:
   * https://patentimages.storage.googleapis.com/thumbnails/EP1234567B1/imgf0001.png
   */
  relativeThumbnailPath?: string;
  tenCharUsClassification?: string[];
}

/**
 * Details of the work cluster for this Volume.
 */
export interface OceanDocTagWorkCluster {
  clusterSize?: number;
  workId?: bigint;
}

function serializeOceanDocTagWorkCluster(data: any): OceanDocTagWorkCluster {
  return {
    ...data,
    workId: data["workId"] !== undefined ? String(data["workId"]) : undefined,
  };
}

function deserializeOceanDocTagWorkCluster(data: any): OceanDocTagWorkCluster {
  return {
    ...data,
    workId: data["workId"] !== undefined ? BigInt(data["workId"]) : undefined,
  };
}

/**
 * A container proto to store prices for GE
 */
export interface OceanGEMoney {
  /**
   * amount in micros. 1 is represented 1000000
   */
  amountInMicros?: bigint;
  /**
   * The currency codes come from google3/i18n/identifiers/currencycode.h.
   */
  currencyCode?: string;
}

function serializeOceanGEMoney(data: any): OceanGEMoney {
  return {
    ...data,
    amountInMicros: data["amountInMicros"] !== undefined ? String(data["amountInMicros"]) : undefined,
  };
}

function deserializeOceanGEMoney(data: any): OceanGEMoney {
  return {
    ...data,
    amountInMicros: data["amountInMicros"] !== undefined ? BigInt(data["amountInMicros"]) : undefined,
  };
}

/**
 * GE sale related data
 */
export interface OceanGEPrice {
  locale?: OceanGEPriceLocale[];
}

function serializeOceanGEPrice(data: any): OceanGEPrice {
  return {
    ...data,
    locale: data["locale"] !== undefined ? data["locale"].map((item: any) => (serializeOceanGEPriceLocale(item))) : undefined,
  };
}

function deserializeOceanGEPrice(data: any): OceanGEPrice {
  return {
    ...data,
    locale: data["locale"] !== undefined ? data["locale"].map((item: any) => (deserializeOceanGEPriceLocale(item))) : undefined,
  };
}

export interface OceanGEPriceLocale {
  /**
   * The two character ISO country code
   */
  locale?: string;
  /**
   * Price used for sale by the OFE
   */
  offerPrice?: OceanGEMoney;
  /**
   * The time (in secs from epoch) the content goes on sale (only set when the
   * book is not already sellable at the time of indexing).
   */
  onSaleTimeSecs?: bigint;
}

function serializeOceanGEPriceLocale(data: any): OceanGEPriceLocale {
  return {
    ...data,
    offerPrice: data["offerPrice"] !== undefined ? serializeOceanGEMoney(data["offerPrice"]) : undefined,
    onSaleTimeSecs: data["onSaleTimeSecs"] !== undefined ? String(data["onSaleTimeSecs"]) : undefined,
  };
}

function deserializeOceanGEPriceLocale(data: any): OceanGEPriceLocale {
  return {
    ...data,
    offerPrice: data["offerPrice"] !== undefined ? deserializeOceanGEMoney(data["offerPrice"]) : undefined,
    onSaleTimeSecs: data["onSaleTimeSecs"] !== undefined ? BigInt(data["onSaleTimeSecs"]) : undefined,
  };
}

/**
 * Size info of an image.
 */
export interface OceanImageSize {
  /**
   * pixels
   */
  height?: number;
  /**
   * pixels
   */
  width?: number;
}

/**
 * How a volume may be viewed in a particular locale. Next available ID: 25
 * (ikkwong)
 */
export interface OceanLocaleViewability {
  /**
   * These capture "commercial" contract related access rights provided by
   * partners for a volume.
   */
  accessRights?: OceanVolumeAccessRights;
  /**
   * Are we allowed to add all the front matter to the preview in addition to
   * the preview amount that is from percent_book_shown? This means the front
   * matter becomes freely previewable and does not count towards the
   * previewable amount based on the percentage.
   */
  allowAddingFrontmatterToPreview?: boolean;
  /**
   * By default, we allow continuous browse. PFE provides a means for partners
   * to opt out entirely or just specific books.
   */
  allowContinuousBrowse?: boolean;
  /**
   * whether OFE should display this volume in syndicated search results
   */
  allowRetailSyndication?: boolean;
  /**
   * The bibkey upon which this viewability information is based.
   */
  bibkey?: string;
  /**
   * Whether we can show ads with this book in this locale.
   */
  canDisplayAds?: boolean;
  /**
   * In future, we will generate epub iff can_download_epub = true irrespective
   * of viewability or download pdf state.
   */
  canDownloadEpub?: boolean;
  /**
   * In future, we will generate PDF iff can_download_pdf = true irrespective
   * of viewability.
   */
  canDownloadPdf?: boolean;
  /**
   * Whether to show library links for the books in this imprint.
   */
  canShowLibraryLinks?: boolean;
  /**
   * Whether we can show photos for this book in this locale.
   */
  canShowPhotos?: boolean;
  /**
   * It should be OK to use metadata covers normally, but we allow publishers
   * to explicitly disallow them.
   */
  canUseMetadataCover?: boolean;
  /**
   * The client who provided the rights for this bibkey, and who should receive
   * revenue derived from this book in this locale. This will only be present
   * when we receive explicit rights from a publisher.
   */
  clientId?: string;
  /**
   * Volume related access rights that are computed by Goovols Syncher from
   * partner and book metadata. This complements VolumeAccessRights. This
   * message is used to capture "commerical" contracts that are computed from
   * other sources. Any future computed rights that are not related to volume
   * access should go into a new message.
   */
  computedAccessRights?: OceanVolumeComputedAccessRights;
  dates?: OceanLocaleViewabilityDates;
  /**
   * Volume display specific attributes are kept in display_details
   */
  displayDetails?: OceanVolumeDisplayDetails;
  /**
   * This only applies when view_type == VIEW_METADATA and controls whether
   * we're allowed to include scanned info (keywords, toc, etc). in the
   * metadata-view. For books in metadata view because they have been opted out,
   * this would be false.
   */
  metadataViewMayIncludeInfoFromScans?: boolean;
  /**
   * This only applies when view_type == VIEW_METADATA and controls whether
   * we're allowed to include a text sample even for a metadata view book.
   */
  metadataViewSampleAllowed?: boolean;
  /**
   * How much of the book can be viewed in this locale. Will be 100 for
   * VIEW_FULL; 0 for VIEW_SNIPPET_, VIEW_NONE and VIEW_METADATA; and some value
   * between 0 and 100 (exclusive) for VIEW_PARTIAL.
   */
  percentBookShown?: number;
  /**
   * If present, this is the rights policy's determination of the public domain
   * status. (Of course, this determination is generally conservative (i.e.
   * false negatives are likely), though exactly how conservative may depend on
   * parameters to the rights policy.) If absent, public domain status can be
   * inferred from view_type and view_reason, but that isn't quite perfectly
   * reliable: view_type should always be VIEW_FULL for public domain, but
   * view_reason might be REASON_PUBLIC_DOMAIN (definitely public domain,
   * obviously), some other value, or absent. In the future, new viewabilities
   * should always have this field whenever possible.
   */
  publicDomain?: boolean;
  sourcedetails?: OceanLocaleViewabilitySourceDetails;
  /**
   * The reason for the view_type.
   */
  viewReason?:  | "REASON_UNKNOWN" | "REASON_NO_SOURCE" | "REASON_KILLED" | "REASON_CONTENT_TYPE" | "REASON_SCANLESS" | "REASON_OPTED_OUT" | "REASON_QUALITY" | "REASON_INSUFFICIENT_PAGES" | "REASON_PARTNER" | "REASON_REFERENCE" | "REASON_COPYRIGHT" | "REASON_PUBLIC_DOMAIN" | "REASON_NEW_COURTESY" | "REASON_LIBRARY_RESTRICT" | "REASON_INDEXING_OVERRIDE" | "REASON_UPLIFTED" | "REASON_OUTSTANDING_QUESTIONS" | "REASON_NO_VALID_SCANJOBS" | "REASON_OPEN_ACCESS_DEPRECATED";
  /**
   * The viewability specified for this locale.
   */
  viewType?:  | "VIEW_NONE" | "VIEW_METADATA" | "VIEW_SNIPPET" | "VIEW_FIXED" | "VIEW_PARTIAL" | "VIEW_FULL";
}

function serializeOceanLocaleViewability(data: any): OceanLocaleViewability {
  return {
    ...data,
    dates: data["dates"] !== undefined ? serializeOceanLocaleViewabilityDates(data["dates"]) : undefined,
    sourcedetails: data["sourcedetails"] !== undefined ? serializeOceanLocaleViewabilitySourceDetails(data["sourcedetails"]) : undefined,
  };
}

function deserializeOceanLocaleViewability(data: any): OceanLocaleViewability {
  return {
    ...data,
    dates: data["dates"] !== undefined ? deserializeOceanLocaleViewabilityDates(data["dates"]) : undefined,
    sourcedetails: data["sourcedetails"] !== undefined ? deserializeOceanLocaleViewabilitySourceDetails(data["sourcedetails"]) : undefined,
  };
}

/**
 * Viewability related dates.
 */
export interface OceanLocaleViewabilityDates {
  /**
   * If specified, the LocaleViewability will become effective on this date.
   * This field is used to allow pre-indexing of future books which will become
   * viewable and searchable according to the LocaleViewability on the specified
   * date. Before the effective date, the volume will have scanless-like
   * VIEW_METADATA viewability. For details, see the design document at
   * http://go/oceanviewabilityeffectivedate. The date is expressed as the
   * number of seconds since the Unix epoch.
   */
  effectiveDate?: bigint;
}

function serializeOceanLocaleViewabilityDates(data: any): OceanLocaleViewabilityDates {
  return {
    ...data,
    effectiveDate: data["effectiveDate"] !== undefined ? String(data["effectiveDate"]) : undefined,
  };
}

function deserializeOceanLocaleViewabilityDates(data: any): OceanLocaleViewabilityDates {
  return {
    ...data,
    effectiveDate: data["effectiveDate"] !== undefined ? BigInt(data["effectiveDate"]) : undefined,
  };
}

/**
 * How did we derive this viewability for this locale+volume? For "partner"
 * books, this includes details about the "Imprint" that provided the rights.
 * These details specify things such as preferred buy-the-book-url to show in
 * the frontend.
 */
export interface OceanLocaleViewabilitySourceDetails {
  imprint?: OceanVolumeImprint;
}

function serializeOceanLocaleViewabilitySourceDetails(data: any): OceanLocaleViewabilitySourceDetails {
  return {
    ...data,
    imprint: data["imprint"] !== undefined ? serializeOceanVolumeImprint(data["imprint"]) : undefined,
  };
}

function deserializeOceanLocaleViewabilitySourceDetails(data: any): OceanLocaleViewabilitySourceDetails {
  return {
    ...data,
    imprint: data["imprint"] !== undefined ? deserializeOceanVolumeImprint(data["imprint"]) : undefined,
  };
}

/**
 * Per-doc data in the Ocean index. Ocean indexing details are in
 * https://www/eng/designdocs/scanning/ocean-indexing.html
 */
export interface OceanPerDocData {
  /**
   * rights, mask-availability, porn, etc.
   */
  flags?: bigint;
  numPages?: number;
  pageid?: number;
  /**
   * 1-based
   */
  pageNumber?: number;
  volumeid?: bigint;
}

function serializeOceanPerDocData(data: any): OceanPerDocData {
  return {
    ...data,
    flags: data["flags"] !== undefined ? String(data["flags"]) : undefined,
    volumeid: data["volumeid"] !== undefined ? String(data["volumeid"]) : undefined,
  };
}

function deserializeOceanPerDocData(data: any): OceanPerDocData {
  return {
    ...data,
    flags: data["flags"] !== undefined ? BigInt(data["flags"]) : undefined,
    volumeid: data["volumeid"] !== undefined ? BigInt(data["volumeid"]) : undefined,
  };
}

export interface OceanVolumeAccessRights {
  /**
   * If false, then we can only provide text layer generated from publisher
   * provided epub.
   */
  allowAutoGeneratedText?: boolean;
  /**
   * Whether we can show info cards inside this book.
   */
  canShowInfoCards?: boolean;
  /**
   * Whether we can show photos inside this book.
   */
  canShowPhotos?: boolean;
  /**
   * Maximum number of Adobe Digital Editions device per sale item allowed. 0
   * means no download allowed. -1 means unlimited download.
   */
  numAdeDeviceAllowed?: number;
  /**
   * Maximum number of Adobe id per sale item allowed. 0 means no download
   * allowed. -1 means unlimited download.
   */
  numAdobeIdAllowed?: number;
  /**
   * Max. number of Google eBooks downloads allowed. This is related to
   * iPhone/iPad/Androrid/WebReader reading, not to epub/pdf downloads. 0 means
   * no download allowed. This is related to bug #3094719.
   */
  numDownloadsAllowed?: number;
  /**
   * Number of readers can read the Google eBooks simultaneously
   */
  numSimultaneousAccess?: number;
  /**
   * Download type for offline reading
   */
  offlineDownload?:  | "NO_DOWNLOAD" | "DRM_FREE_DOWNLOAD" | "ACS4_DOWNLOAD";
  /**
   * How much of a volume we allow user to extract as text (for copy+paste)
   */
  percentCopyable?: number;
  /**
   * How much of a volume we allow user to print
   */
  percentPrintable?: number;
  /**
   * True iff restrict view only to epub text. Don't show page images if this
   * is true. Some pubs don't have copyright for page layout and fonts.
   */
  restrictOnlyToText?: boolean;
  /**
   * Whether we sell fixed layout as image only.
   */
  sellFixedLayoutAsImageOnly?: boolean;
  /**
   * Whether text to speech is allowed
   */
  textToSpeech?: boolean;
  /**
   * Whether we treat this book as public domain.
   */
  treatAsPublicDomain?: boolean;
}

/**
 * Volume related access rights that are computed by Goovols Syncher from
 * partner and book metadata. This complements VolumeAccessRights. Next
 * available ID: 4 (kblass)
 */
export interface OceanVolumeComputedAccessRights {
  /**
   * Whether this book can be shared with family members.
   */
  canFamilyShare?: boolean;
  /**
   * Whether the panelization feature is enabled for internal users only.
   */
  panelizationFeatureInternalOnly?: boolean;
  /**
   * Whether the book is viewable for internal users only.
   */
  viewableInternalOnly?: boolean;
}

/**
 * This message describes display attributes. The attributes which are
 * applicable to OFE not indexing (mustang), should be added in this proto.
 */
export interface OceanVolumeDisplayDetails {
  /**
   * The creative commons license specified, Please refer
   * ocean.CreativeCommonsLicenseType.Type for enum values Not exposed in
   * Partner Frontend anymore.
   */
  ccLicense?: number;
}

/**
 * Commercial information for a volume (data from the Imprint
 * PublishersVolumeInfo table in the db). An imprint is a subdivision of a
 * publisher (for example, Bantam Books is an imprint of Randon House), or can
 * even be just a grouping of volumes with common commercial attributes.
 */
export interface OceanVolumeImprint {
  /**
   * These capture "commercial" contract related access rights provided by
   * partners for a volume.
   */
  accessRights?: OceanVolumeAccessRights;
  /**
   * Id used in the google ads system
   */
  adsId?: string;
  /**
   * Are we allowed to add all the front matter to the preview in addition to
   * the preview amount that is from percent_book_shown?
   */
  allowAddingFrontmatterToPreview?: boolean;
  /**
   * By default, we allow continuous browse. PFE provides a means for partners
   * to opt out entirely or just specific books. This will be deprecated once
   * UpdateVolumesReqHandler returns VolumeViewability.
   */
  allowContinuousBrowse?: boolean;
  /**
   * By default, we allow retailer syndication. PFE provides a means for
   * partner to opt out. This will be deprecated once UpdateVolumesReqHandler
   * returns VolumeViewability.
   */
  allowRetailSyndication?: boolean;
  /**
   * Beware: the author strings are not in fixed format..these can be comma
   * separated or 'and' separated or have extra terms like 'et al' and sometimes
   * have weird ones like 'no author' as these are fed in via a somewhat
   * flexible free text tool.
   */
  author?: string;
  /**
   * Commercial info comes with book identifiers like ISBN(or some bibkey),
   * Title, Author. Passing these along as well with the commercials for better
   * book identification/link up with rights.
   */
  bibkey?: string;
  /**
   * Text to display in the buy-the-book blurb
   */
  buyTheBookText?: string;
  /**
   * ISBN/ISSN-parameterized URL to the imprint's site for buying a book. For
   * ISBN-parameterized links, the ISBN value will be substituted in the
   * cannonical 13-digit form.
   */
  buyTheBookUrl?: string;
  /**
   * iff true volume is available as Google Edition. This will be deprecated
   * once UpdateVolumesReqHandler returns VolumeViewability.
   */
  canDownloadEpub?: boolean;
  /**
   * iff true and VIEW_TYPE=FULL_VIEW, then we will allow PDF download This
   * will be deprecated once UpdateVolumesReqHandler returns VolumeViewability.
   */
  canDownloadPdf?: boolean;
  /**
   * Whether to show library links for the books in this imprint. This will be
   * deprecated once UpdateVolumesReqHandler returns VolumeViewability.
   */
  canShowLibraryLinks?: boolean;
  /**
   * It should be OK to use metadata covers normally, but we allow publishers
   * to explicitly disallow them. This will be deprecated once
   * UpdateVolumesReqHandler returns VolumeViewability.
   */
  canUseMetadataCover?: boolean;
  /**
   * Whether to disable other btb links for the books in this imprint. Show
   * only btb link from this partner and remove everything else.
   */
  disableOtherBuyTheBookLinks?: boolean;
  /**
   * Volume display specific attributes are kept in display_details This will
   * be deprecated once UpdateVolumesReqHandler returns VolumeViewability.
   */
  displayDetails?: OceanVolumeDisplayDetails;
  /**
   * The ISBN supplied by publisher (or Google) for the Google Edition e-book.
   * One day it should be an attribute of the tome cluster.
   */
  geBibkey?: string;
  /**
   * The imprint id from the ocean devel db for this imprint.
   */
  imprintId?: bigint;
  imprintName?: string;
  /**
   * URL to the imprint's website, to go to upon a click on the logo
   */
  imprintUrl?: string;
  logoHeight?: number;
  /**
   * URL/location for the imprint's logo to display
   */
  logoLocation?: string;
  /**
   * The logo image's geometry
   */
  logoWidth?: number;
  /**
   * Percentage of book we are allowed to display This will be deprecated once
   * UpdateVolumesReqHandler returns VolumeViewability.
   */
  percentBookShown?: number;
  promotionalText?: string;
  /**
   * We may allow imprints to run promotional campaigns. The following fields
   * capture the blurb to display and the URL (ISBN-parameterized) link to
   * provide.
   */
  promotionalUrl?: string;
  /**
   * Sometimes the Publisher/Imprint Name the book is published under is
   * different from the current name and we may have this information.
   */
  publishedImprintName?: string;
  /**
   * Need a unique identifier for PFE records, using PVI ID
   */
  pviRowid?: bigint;
  title?: string;
  /**
   * Some records are deactivated, suppressed or excluded; we still want to
   * hear about them, but we aren't going to be using their bibdata
   */
  useBibdata?: boolean;
  verticalType?:  | "BOOK" | "JOURNAL" | "MAGAZINE" | "NEWSPAPER";
}

function serializeOceanVolumeImprint(data: any): OceanVolumeImprint {
  return {
    ...data,
    imprintId: data["imprintId"] !== undefined ? String(data["imprintId"]) : undefined,
    pviRowid: data["pviRowid"] !== undefined ? String(data["pviRowid"]) : undefined,
  };
}

function deserializeOceanVolumeImprint(data: any): OceanVolumeImprint {
  return {
    ...data,
    imprintId: data["imprintId"] !== undefined ? BigInt(data["imprintId"]) : undefined,
    pviRowid: data["pviRowid"] !== undefined ? BigInt(data["pviRowid"]) : undefined,
  };
}

export interface OceanVolumeViewability {
  /**
   * The viewability for any locale that is not explicitly listed.
   */
  defaultViewability?: OceanLocaleViewability;
  DEPRECATEDDefaultViewType?: number;
  /**
   * DEPRECATED: Viewability-Limbo was a state that prevented indexing from
   * running if the viewability of a volume had dropped significantly. It was
   * removed during viewability refactoring: http://go/viewability
   */
  inViewabilityLimbo?: boolean;
  locale?: OceanVolumeViewabilityLocale[];
  /**
   * Whether the volume viewability was updated by the indexer as opposed to a
   * direct update in goovols. The absense of this bit will indicate to the
   * indexer that it should not short-circuit indexing side effects that should
   * occur when viewability changes.
   */
  updatedByIndexer?: boolean;
}

function serializeOceanVolumeViewability(data: any): OceanVolumeViewability {
  return {
    ...data,
    defaultViewability: data["defaultViewability"] !== undefined ? serializeOceanLocaleViewability(data["defaultViewability"]) : undefined,
    locale: data["locale"] !== undefined ? data["locale"].map((item: any) => (serializeOceanVolumeViewabilityLocale(item))) : undefined,
  };
}

function deserializeOceanVolumeViewability(data: any): OceanVolumeViewability {
  return {
    ...data,
    defaultViewability: data["defaultViewability"] !== undefined ? deserializeOceanLocaleViewability(data["defaultViewability"]) : undefined,
    locale: data["locale"] !== undefined ? data["locale"].map((item: any) => (deserializeOceanVolumeViewabilityLocale(item))) : undefined,
  };
}

export interface OceanVolumeViewabilityLocale {
  DEPRECATEDViewType?: number;
  /**
   * The two-character ISO country code for the locale.
   */
  locale?: string;
  /**
   * The viewability specified for this locale.
   */
  viewability?: OceanLocaleViewability;
}

function serializeOceanVolumeViewabilityLocale(data: any): OceanVolumeViewabilityLocale {
  return {
    ...data,
    viewability: data["viewability"] !== undefined ? serializeOceanLocaleViewability(data["viewability"]) : undefined,
  };
}

function deserializeOceanVolumeViewabilityLocale(data: any): OceanVolumeViewabilityLocale {
  return {
    ...data,
    viewability: data["viewability"] !== undefined ? deserializeOceanLocaleViewability(data["viewability"]) : undefined,
  };
}

/**
 * Bounding box of patch containing line, word or symbol.
 */
export interface OcrPhotoBoundingBox {
  /**
   * Angle of rotation of (in degrees, clockwise is positive) of the box about
   * the top-left corner.
   */
  angle?: number;
  /**
   * Sequence of rotated boxes that tightly enclose the text.
   */
  curvedBox?: OcrPhotoCurvedBoundingBox;
  /**
   * Box height (bottom pixels at top + height - 1).
   */
  height?: number;
  /**
   * x coordinate of top-left corner
   */
  left?: number;
  /**
   * y coordinate of top-left corner
   */
  top?: number;
  /**
   * Box width (rightmost pixels at left + width - 1).
   */
  width?: number;
}

/**
 * Copy of ocr/goodoc/layout-common.proto:CurvedBoundingBox, temporary
 * duplicated here to allow for on-device builds.
 */
export interface OcrPhotoCurve {
  /**
   * The sequence of points that approximate the curve.
   */
  points?: OcrPhotoCurvePoint[];
}

export interface OcrPhotoCurvedBoundingBox {
  /**
   * The curve of points along the middle of the text line.
   */
  midLineCurve?: OcrPhotoCurve;
  /**
   * If top_to_bottom is true, this is the width of the curved box. Otherwise,
   * it is the height of the curved box.
   */
  thickness?: number;
  /**
   * If true, the curve is interpreted as top to bottom of the line image.
   * Otherwise, it is from left to right.
   */
  topToBottom?: boolean;
}

export interface OcrPhotoCurvePoint {
  x?: number;
  /**
   * NOTE: if we wish to support perspective (varying thickness), later on we
   * could extend this message with a thickness field. In that case,
   * CurvedBoundingBox.thickness() would be used as a default if
   * !Point.has_thickness().
   */
  y?: number;
}

/**
 * Text with bounding box.
 */
export interface OcrPhotoTextBox {
  /**
   * ID of the text block that this line belongs to.
   */
  blockId?: number;
  /**
   * Text bounding box.
   */
  box?: OcrPhotoBoundingBox;
  /**
   * Content type for this box.
   */
  contentType?:  | "TEXT" | "HANDWRITTEN_TEXT" | "IMAGE" | "LINE_DRAWING" | "SEPARATOR" | "UNREADABLE_TEXT" | "FORMULA" | "HANDWRITTEN_FORMULA" | "NOT_ANNOTATED" | "SIGNATURE" | "UNKNOWN" | "CUSTOM";
  /**
   * Optional width of characters in the text.
   */
  symbolWidths?: number[];
  /**
   * Text string.
   */
  text?: string;
}

/**
 * This proto is used as the key for official pages data. WARNING WARNING
 * WARNING WARNING WARNING PAY ATTENTION HERE! The query field contains a
 * specially NORMALIZED query, NOT a raw one. You can get a normalized query in
 * several ways: 1. from an squery with NormalizedQueryFromSquery 2. from a
 * CJK-segmented and punctuation-stripped query with NormalizeText (NOTE:
 * navboost queries are already CJK-segmented and punctuation-stripped, you can
 * just pass them to NormalizeText) 3. from user text/query with
 * CanonicalizeText (this will do the CJK segmenting, punctuation stripping and
 * character normalization for you) All of these functions are in
 * ./utils/external-utils.h
 */
export interface OfficialPagesOfficialKey {
  country?: string;
  language?: number;
  query?: string;
}

export interface OfficialPagesQuerySet {
  queries?: OfficialPagesOfficialKey[];
  /**
   * This is the fingerprint of the OfficialKey queries in the queries field.
   * The index of a fingerprint in this field corresponds to the index of the
   * fingerprinted query in the queries field. The fingerprint is produced with
   * the QueryCountryLanguageFingerprint function in external-utils.h
   */
  queryCountryLanguageFingerprints?: bigint[];
}

function serializeOfficialPagesQuerySet(data: any): OfficialPagesQuerySet {
  return {
    ...data,
    queryCountryLanguageFingerprints: data["queryCountryLanguageFingerprints"] !== undefined ? data["queryCountryLanguageFingerprints"].map((item: any) => (String(item))) : undefined,
  };
}

function deserializeOfficialPagesQuerySet(data: any): OfficialPagesQuerySet {
  return {
    ...data,
    queryCountryLanguageFingerprints: data["queryCountryLanguageFingerprints"] !== undefined ? data["queryCountryLanguageFingerprints"].map((item: any) => (BigInt(item))) : undefined,
  };
}

export interface OrionDocEntitiesProto {
  docid?: bigint;
  /**
   * This is encoded using EntityCandidate::Encode
   */
  encodedEntity?: number[];
}

function serializeOrionDocEntitiesProto(data: any): OrionDocEntitiesProto {
  return {
    ...data,
    docid: data["docid"] !== undefined ? String(data["docid"]) : undefined,
  };
}

function deserializeOrionDocEntitiesProto(data: any): OrionDocEntitiesProto {
  return {
    ...data,
    docid: data["docid"] !== undefined ? BigInt(data["docid"]) : undefined,
  };
}

export interface PairwiseQScoringData {
  confidenceValue?: number;
  value?: number;
}

/**
 * Message representing a versioned PairwiseQ scores used for experimentation.
 * This protobuf is copied from quality_nsr_pairwiseq::PairwiseQVersionedItem.
 */
export interface PairwiseQVersionedItem {
  /**
   * The PairwiseQ confidence value corresponding to this version.
   */
  confidenceValue?: number;
  /**
   * The PairwiseQ value corresponding to this version.
   */
  value?: number;
  /**
   * The version id.
   */
  versionId?: number;
}

export interface PeoplestackFlexorgsProtoInternalExternal {
  /**
   * All evaluations are done within the context of a given application, e.g.,
   * "Gmail" and should not be reused in other apps.
   */
  application?:  | "UNKNOWN_APPLICATION" | "GPLUS" | "GPLUS_WEB" | "GPLUS_ARES_FEATURE_PROVIDER" | "GPLUS_PHOTOS" | "GPLUS_HANGOUT" | "GPLUS_EVENTS" | "GPLUS_SQUARES" | "GPLUS_NOTIFICATIONS" | "GPLUS_GAMES" | "GPLUS_WHATS_HOT" | "GPLUS_LOCAL" | "GPLUS_PLUS_PAGES" | "GPLUS_PLUS_PAGES_RSS" | "GPLUS_PROFILE" | "GPLUS_FIND_PEOPLE" | "GPLUS_PHOTO_EDITOR" | "GPLUS_SOCIALCAST" | "GPLUS_INTERACTION_EVENTS" | "GPLUS_ENTITY_TRANSFER" | "GPLUS_LIS" | "GPLUS_DRAWBRIDGE" | "GPLUS_DASHER" | "GPLUS_DASHER_TAKEOUT" | "PAISA_MERCHANT_CONSOLE" | "GEO_DATA_UPLOAD_STAGING" | "GEO_DATA_UPLOAD" | "GOOGLE_PLAY_SERVICES" | "GOOGLE_SETTINGS" | "THIRD_PARTY" | "PICASA_PHOTOS" | "GMAIL_HANGOUT" | "FOUNTAIN" | "FOUNTAIN_YOUTUBE" | "YOUTUBE_LEGACY_COMMENT_MIGRATION" | "FOUNTAIN_YOUTUBE_DISCUSS" | "FOUNTAIN_YOUTUBE_MESSAGES" | "YOUTUBE_AUTOSHARES" | "FOUNTAIN_YOUTUBE_LEGACY_GDATA" | "YOUTUBE_CHOWN_PIPELINE" | "FOUNTAIN_YOUTUBE_ACTIVITY_LOG" | "FOUNTAIN_YOUTUBE_ADMIN" | "YOUTUBE_HELD_COMMENT_EXPIRY" | "ONEMARKET_CALENDAR" | "FOCUS_FRONTEND" | "URL_SHAREBOX" | "READER" | "GOOGLE_MAIL" | "PLUS_SHARE" | "YOUTUBE" | "CHECKIN" | "FRAMES" | "PHOTOS_CHROMEAPP" | "MOBILE_BASIC" | "GLASSWARE" | "GAMES" | "THIRD_PARTY_STREAM_EVERYWHERE_SINGLE_POST_WIDGET" | "PLAY_STORE" | "GMAIL_INBOX_POSTS" | "GMAIL_RECENT_POSTS" | "SIDECAR" | "GOOGLE_QUICK_SEARCH_BOX" | "WALLET" | "FRAMELESS_SHAREBOX" | "YOUTUBE_CAPTURE" | "YOUTUBE_WATCH_PAGE_SHARE" | "YOUTUBE_REACTR" | "YOUTUBE_MANGO" | "YOUTUBE_REACTR_TAKEOUT" | "YOUTUBE_COMMENTS_NOTIFICATION" | "YOUTUBE_COMMENTS_TIMED" | "YOUTUBE_COMMENTS_ENGAGEMENT_P13N" | "YOUTUBE_COMMENTS_LEGAL_TAKEOUT" | "YOUTUBE_COMMENTS_INDEXING" | "YOUTUBE_COMMENTS_NEWEST_FIRST" | "YOUTUBE_COMMENTS_BACKEND" | "YOUTUBE_SUBSCRIPTIONS_FEEDS" | "YOUTUBE_COMMENT_API" | "GHUB_COMMENTS" | "GOOGLE_KEEP" | "VEGA" | "SOCIAL_REVIEWS" | "PLAY_MOVIES" | "GMAIL" | "GMAIL_GO" | "HELPOUTS" | "MAPS" | "MAPS_ENGINE_MOBILE" | "CALENDAR" | "PLAY_NEWSSTAND" | "FITNESS" | "WEAR_HEALTH" | "WEAR_HEALTH_PROVISIONING" | "PLAY_BOOKS" | "INSTORE" | "PLAY_MUSIC" | "GOOGLE_CHROME" | "LOCATION_FLARE" | "NEWS_WEATHER" | "PROMOTED_POSTS" | "CLOUD_PRINT" | "CLOUD_DEVICES" | "CPANEL" | "DRIVE" | "CLASSROOM" | "STORIES" | "GOOGLE_ANALYTICS" | "LOCATION_SAMPLE" | "BIGTOP" | "GOOGLE_CAST" | "AUTHZEN" | "PARENTS" | "SEARCH" | "NEWS" | "DOCS" | "PHOTOS" | "PHOTOS_TAKEOUT" | "PHOTOS_ABUSE" | "SIMBA_MOBILE" | "GOOGLE_JOBS" | "CLOUD_PLATFORM" | "CLOUD_PLATFORM_WEB" | "FIREFOX_BROWSER" | "MOVIEMAKER" | "MOVIEMAKER_PHOTOS" | "GOOGLE_STARS" | "SNAPSEED" | "BLOGGER" | "DEVICE_POLICY" | "DOUBLECLICK_CREATIVE_PREVIEW" | "UNICORN" | "ADWORDS_MOBILE" | "FAMILY_COMPASS" | "AUTH_GRANT_CREDENTIAL" | "HALLWAY" | "FAMILY_CAMERA" | "ENDER" | "MAPS_VIEWS" | "TABLESCAPE" | "TOPAZ" | "FIBER" | "ATARI" | "RIDEMATCH" | "GMONEY" | "GOOGLE_EXPRESS" | "CONSUMER_PHOTO_EDITOR" | "JETSTREAM" | "SOCIAL_SERENDIPITY" | "ONE_TODAY" | "PROFILES" | "SOCIAL_POLLS" | "SPACES" | "ADWORDS_EXPRESS" | "IDENTITY" | "IDENTITY_FRONTEND_VISUAL_ELEMENTS" | "YOUTUBE_BACKSTAGE" | "YOUTUBE_BACKSTAGE_ADMIN" | "YOUTUBE_UNPLUGGED" | "YOUTUBE_MUSIC" | "HUB" | "ANDROID_EDU_PROVISIONING" | "ANDROID_WEAR" | "CHROMECAST" | "ONTHEGO" | "ADSENSE" | "PROJECT_FI" | "JAM" | "HUDDLE" | "CAR_APP" | "TAILORMADE" | "ACTIVITY_LOG" | "SPACES_ACTIVITY_LOG" | "PHOTOS_ACTIVITY_LOG" | "MEMEGEN" | "SOCIETY" | "SOCIETY_CHAT" | "HIGHLIGHT" | "YOUTUBE_LIVE" | "YOUTUBE_LIVE_ACTIVITY_LOG" | "YOUTUBE_LIVE_TAKEOUT" | "CARDBOARD_CAMERA" | "PLAY_DEVELOPER_CONSOLE" | "MIXX" | "CHROME_REMOTE_DESKTOP" | "HOT_LANE" | "CONTACTS" | "CONTACTSHEET" | "HOVERCARD" | "DORY" | "SPECTRUM" | "DYNAMITE" | "DASHER_USER_HUB" | "CULTURAL" | "BOOND" | "EXPEDITIONS" | "PHOTO_ALBUM_ARCHIVE" | "GAMMAGO" | "FIREBALL" | "SUPPLY_CHAIN_CENTRAL" | "PAISA" | "SANDCLOCK" | "ACCOUNT_SETTINGS_MOBILE" | "GOOGLE_VOICE" | "WING_MARKETPLACE" | "CHIME" | "LIFESCIENCE_FRONTENDS" | "WYLO_TODAY" | "NAKSHA_CONSUMER" | "ENTERPRISE_ENROLLMENT" | "IMPROV" | "TRANSLATE" | "SOCIAL_ENGAGE" | "CORPCAM" | "ANDROID_CONTACTS" | "CURATOR" | "TRAVEL_BOOKING" | "SOCIAL_DISCOVERY" | "GPOST" | "PAIDTASKS" | "PRIMER" | "LOCAL_DISCOVERY" | "BASELINE" | "QUARTZ" | "DPANEL" | "TRIPS" | "HOME_SERVICES" | "SOCIALGOOD" | "LOUPE" | "UGC_LIVE_COMMENTS" | "FAMILY_LINK" | "G3DOC" | "MOMA" | "DASHER_ADMIN_CONSOLE" | "DASHER_COMMERCE_CONSOLE" | "TRAVEL_VACATIONS" | "TRENDS" | "TASKS" | "VIMES" | "SECURITY_EVENT_MANAGER" | "VR_EVA" | "MINDSEARCH" | "MINDSEARCH_ADMIN" | "ANDROID_AUTO" | "CLOUDCAST_TEXTCHAT" | "APPS_ASSISTANT_OVERLAY" | "SEARCH_CONSOLE" | "CHROME_WEB_STORE" | "SAVE" | "FOOD_ORDERING" | "SOCIAL_RECOVERY" | "ANDROID_ONBOARD_WEB" | "WEAR_HOME" | "FACT_CHECK_EXPLORER" | "ALLO" | "FAMILY_LINK_HELPER" | "PROXY_GAL_PROVIDER" | "ONEGOOGLE" | "ONEGOOGLE_ASYNC" | "WICKED" | "SHEETS" | "SLIDES" | "ASSISTANT_EXPLORE_WEB" | "ASSISTANT_SETTINGS_WEB_UI" | "ANDROID_DIALER" | "KLOPFKLOPF" | "LAGEPLAN" | "SCIENCE_JOURNAL" | "HIRE" | "ZANDRIA" | "DASHER_RESELLER_FRONTEND" | "ZOOMSIGHTS" | "UGC_LIVE_COMMENTS_TAKEOUT" | "GUARDIAN" | "GUARDIAN_CORP" | "GOOGLE_MY_BUSINESS" | "PRESTO_ALP" | "PRESTO_FE" | "KIDS_HOME" | "OPA" | "SUBSCRIBEWITHGOOGLE_CLIENT" | "REVEAL" | "ANDROID_NATIVE_ONBOARDING" | "AMP_ACTIONS" | "SPOT" | "MEDICAL_SCRIBE" | "MEDICAL_SCRIBE_TASKING" | "DASHER_RULES_FRONTEND" | "ANDROID_TV_LAUNCHERX" | "ANDROID_TV_SETUP_WIZARD" | "SOS_LIVE_COMMENTS" | "GMAIL_LOCKER_UI" | "POLYGLOT" | "PLX" | "GROUPS_UI" | "MSV" | "WOLVERINE" | "MIC" | "FORMS" | "ARCORE" | "ANDROID_EMERGENCY" | "LENSLET" | "MEDICAL_LABELING" | "G_SUITE_ADD_ONS" | "LOCATION_HISTORY_CONSENT_ANDROID_LIBRARY" | "PAYMENTS_WEB_5" | "APPS_PLATFORM_CONSOLE" | "INTROSPECT" | "NGA" | "SUPPLY_CHAIN_HW_CHP2" | "DUC_COMPANION" | "AUTOMON" | "TV_LIVE_COMMENTS" | "GUP_PEEPS" | "FOCUS_SYNC_ADAPTER_V1" | "NOVA" | "NOVA_STAGING" | "DASHER_DATA_CLASSIFICATION_FRONTEND" | "GOOGLE_ADMIN" | "MESSAGE_PROCESSOR" | "EMAIL_PROCESSOR" | "ENGAGE_PIPELINE" | "AUTO_DOC_PROBER" | "DOC_PROBER" | "FRAMES_DELETE_SYNC" | "EMBEDS_MIGRATION" | "SOCIAL_REVIEWS_SYNC" | "GUNS" | "POSTBOX_ONEOFF" | "PLUS_API_ONEOFF" | "STANZA_ACTIVITY_POST_DELETE_SYNC" | "GRAPH_PROBER" | "STANZA_PERIODIC" | "MADISON_PERIODIC" | "PAPYRUS_PERIODIC" | "PHOTOS_BACKEND" | "REDBOX_BACKEND" | "PHOTOS_FIFE" | "ABUSEIAM" | "ARES" | "STREAM_INDEXING" | "STANZA_INDEXING" | "STANZA" | "STANZA_MOONSHINE_INDEXING" | "STREAM_ACTIONS" | "STREAM_CONFIG" | "STREAM_SERVICE" | "STREAM_DELETE" | "KWYJIBO" | "STANZA_TEST" | "TEST_APPLICATION" | "SOCIAL_ANNOTATION_SERVICE" | "ANNOTATION_SERVICE_STANZA_LISTENER" | "SBE_PLAYGROUND" | "EXPO" | "ANDROID_VR_HOME" | "YOUTUBE_BLARNEY_STONE" | "SOCIAL_EVENTS" | "EMERGENCY_ASSIST" | "ADS_INTEGRITY_ENFORCER" | "ADS_INTEGRITY_ENFORCEMENT_MANAGER" | "ADS_INTEGRITY_EXPLORER" | "ADS_INTEGRITY_REVIEWER" | "GPLUS_COLLEXION_PIPELINE" | "GPLUS_OFFLINE" | "PAPYRUS" | "YOUTUBE_ADMIN" | "YOUTUBE_ADMIN_REVIEW_QUEUE_PACING" | "YOUTUBE_TNS_VERTICAL_MANAGER" | "YOUTUBE_DECIDER" | "YOUTUBE_TNS_ACTION" | "YOUTUBE_EXTERNAL_LINKS" | "FOCUS_BACKEND_BATCH" | "TEAMSPACES" | "ASSISTANT_OPA" | "TRASNLATION_MEMORY_MANAGER" | "THREADIT" | "RESOURCE_SYMPHONY" | "L10N_INFRA_SHARED" | "WORK_TRACKER" | "ARIANE" | "COLAB_INTERNAL" | "COLAB_EXTERNAL" | "TALENT_GROW" | "ROCKET_LABS" | "MY_GOOGLE_FAMILIES" | "DATA_STUDIO" | "LEGAL_CONTRACTS" | "BRIEF" | "HARDWARE_MFG_DATA_VENUS" | "BETTERBUG" | "DCMS" | "PLAY_BOOKS_PUBENG" | "YAQS" | "PROSPER" | "CAMPAIGN_AUTOMATION_TOOL" | "HIRING" | "DATACENTER_SOFTWARE" | "MARKETING_WORKFLOWS" | "YOUTUBE_PARENT_TOOLS" | "RELIABILITY_INSIGHTS_PST" | "CUSTOMER_CARE_PORTAL" | "FUSION" | "PRODUCTION2020_UIE" | "SPEAKEASY" | "GPAY_RELEASE_OPS" | "SKILLSSTACK" | "WHOSTORY" | "BETTANY" | "BASECAMP" | "CULTURE_EVENTS_CALENDAR" | "DATABRIDGE_CONSOLE" | "COMMSTAR" | "CDDB" | "MONOSPACE" | "MY_ACCOUNT" | "NUDGEIT_CAMPAIGN_MANAGER" | "DEPRECATED_QUICKSTART_FLUME" | "DUO_CLIENT" | "ALBERT" | "PEOPLE_PLAYGROUND" | "GPLUS_POST_RECOMMENDER" | "IMAGES" | "GOOGLE_STORE" | "GCONNECT_MUSTARD" | "MADDEN" | "MOBDOG" | "GBOARD" | "RECORDER" | "UNMAPPED_LEGACY_GPLUS_SOURCE" | "PODIUM" | "GSA_FUSE" | "HONEYPHISH" | "SOCIAL_ANNOTATION_SERVICE_BACKFILL" | "CONTACT_HR" | "PAISA_WANDER" | "NEXTGENRETAIL_SELF_ORDER" | "UNSET_APPLICATION" | "UNKNOWN_FIRST_PARTY_APPLICATION" | "WABEL" | "VIDEO_HANGOUT" | "VIDEO_HANGOUT_LITE" | "VIDEO_HANGOUT_GVC" | "VIDEO_HANGOUT_PRESENT" | "VIDEO_HANGOUT_HOA" | "VIDEO_HANGOUT_TEE" | "VIDEO_HANGOUT_SDK" | "VIDEO_HANGOUT_ENVOY" | "BABEL" | "BABEL_NOVA" | "WABEL_MEDIACALL" | "HANGOUT_START_PAGE" | "EXPRESS_LANE" | "MEETINGS_ANDROID" | "EXPRESS_LANE_BOQ" | "RTC_FLEET_MGMT" | "STAX" | "RIGEL" | "PHOTOS_SCANNER" | "PHOTOS_LIBRARY_API" | "PHOTOS_PARTNER_API" | "VAULT" | "PROF" | "TOTAL" | "TOTAL_ZERO_PARTY" | "TOTAL_FIRST_PARTY" | "TOTAL_THIRD_PARTY" | "TOTAL_INTERNAL" | "TOTAL_UNKNOWN" | "TOTAL_MINUS_YOUTUBE" | "TOTAL_FIRST_PARTY_WITH_PRIMARY_INTENT_TO_SHARE_TO_GPLUS" | "TOTAL_FIRST_PARTY_WITH_SECONDARY_INTENT_TO_SHARE_TO_GPLUS" | "TOTAL_GPLUS" | "TOTAL_SOCIAL_APPS" | "CROWD_COMPUTE" | "KHAZANA" | "LIGHTER_GMM" | "LIGHTER_GMB" | "MYACTIVITY" | "BLOG_COMPASS" | "CONCORD" | "NAVSTAR" | "SETTINGS_INTELLIGENCE" | "TOPAZ_TEAMS" | "GEMAGENT" | "DUMBLEDORE" | "GOOGLE_ONE" | "NBU_GCONNECT_KIMCHI" | "FASTDASH" | "AQUARIUS_LAPIS" | "DASHER_REPORTING" | "GCONNECT_PICARD" | "GOOGLE_JACQUARD" | "GOOGLE_GO" | "BUGANIZER" | "DOCOS_MENTIONS" | "TRIX_WAFFLE" | "SHARE_SERVICE" | "ANDROID_SAFETY" | "CLOUDCAST_TEXTCHAT_TAKEOUT" | "ASSISTANT_GO" | "FLOURISH" | "ALECS" | "NANDHI" | "GOOGLE_RECORDER" | "CONTACT_STORE" | "PROFILE_CARD" | "ESPRESSO" | "PEOPLE_COMPANION" | "PHOTOS_GO" | "YETI" | "BLOOM" | "FIELD_OFFICER" | "URBAN_MOBILITY" | "FAMILYCARE" | "INTUITIVE_PLATFORM" | "NBU_CRICKET_WORLD_CUP" | "INTEGRATION_PLATFORM" | "CROS_SCALING_STAGING" | "CROS_SCALING_PROD" | "ASSISTANT_PROACTIVE_SUGGESTIONS" | "PRIVACY_ONE" | "PAISA_MERCHANT" | "ASSISTJS" | "TRAVEL_HOTELIER" | "PHOTOS_KINDYGRAM" | "ANDROID_MESSAGES" | "TRAVEL_HOTEL_EDITOR" | "VISTAAR" | "VISTAAR_DEV" | "GSUITE_GROWTH" | "ELDAR" | "GMB_ANDROID" | "SHOPPING_LIST" | "EARTH" | "PAISA_CREDIT_INSTANT_LOAN" | "ASSISTANT_GO_WEB" | "SHOWTIME_EVENTS" | "KONARK" | "EXO_REFSERVER" | "MONITORING_PLATFORM" | "AUTOCAP" | "PAYMENTS_ORCHESTRATION" | "GMB_IOS" | "ASSISTANT_KAIOS" | "ADMOB_MOBILE" | "SCREENERS" | "MILTON" | "GHIRE" | "TRANSLATE_COMMUNITY_UI" | "ROAD_MAPPER" | "NEST" | "ROLLOUTS_UI" | "SHOPPING_PROPERTY" | "SHOPPING_PROPERTY_NONPROD" | "PAYMENTS_MERCHANT_VERTICALS_GAS" | "PAISA_MOVIES" | "HUB_CALL" | "WAYMO_SIMULATION_RESULTS" | "GSUITE_WORKFLOWS" | "FINANCE_WORKFLOWS" | "PAYMENTS_MERCHANT_VERTICALS_PARKING_UI" | "TRAVEL" | "GABBLE" | "APPS_EDU" | "MYFI" | "CHOMCHOM" | "ASSISTANT_TOOLCHAIN" | "YOUTUBE_ANSIBLE" | "YOUTUBE_CI_KAPLA" | "GANTRY" | "PAYMENTS_MERCHANT_CONSOLE" | "SPLINTER" | "KINTARO" | "MDM_ADMIN_CONSOLE" | "PAYMENTS_CONSUMER_CORE" | "INCIDENT_MANAGEMENT" | "ONEGOOGLE_MOBILE" | "ANURA" | "FINANCE_FGC" | "PODCASTS_MANAGER" | "FILES" | "YOUTUBE_POST_API" | "GSUITE_HUB" | "TV_LAUNCHER" | "PAIDTASKS_FRONTEND" | "ONE_REVIEWER_TOOL" | "MEET_QUALITY_TOOL" | "TRAVEL_PLANNING" | "MEET" | "PAISA_FOOD" | "TINYTASK_TASKER" | "FIELDOFFICER" | "LENS_WEB" | "HERALD" | "PAISA_MICROAPPS_WEB" | "BUG_OBSERVER" | "ATLAS" | "DHARMA" | "SNIPIT" | "PREMIUM_ASSISTANT" | "ONEREVIEWERTOOL" | "CORONADO" | "SYSTEM1" | "PUMICE" | "BACKLIGHT" | "GLOSSARY_MANAGER" | "UPGRADEPARTY" | "ONEDEV_WORKFLOW" | "AVALANCHE" | "KORMO_SEEKER" | "ASSISTANT_PROFILE_YOURPEOPLE" | "SMART_DISPLAY_WEB" | "DESKBOOKING" | "PAYMENTS_MERCHANT_VERTICALS_FOOD" | "VALUABLES_MERCHANT_CENTER" | "OFFSEC" | "SCHEDULE" | "PAISA_SOCIAL_CAMPAIGNS" | "WORDFLOW" | "HEALTH_PLANFORCARE" | "DEEPMIND_ALPHASCHEDULE" | "HOOLICHAT_UI" | "YOUTUBE_CREATOR_STUDIO" | "BRICKS" | "PAYMENTS_MERCHANT_DATA_BUSINESS_INSIGHT" | "RECALL" | "NEST_GREENENERGY" | "FRAP" | "PAYMENTS_MERCHANT_VERTICALS_GROCERY" | "REVIEWS_WIDGET_API" | "INCIDENTFLOW" | "AREA120_PROMODAY" | "PINPOINT" | "TRANSCONSOLE" | "MARKETPLACE" | "SPORK" | "DASHER_SUSTAINABILITY";
  /**
   * * There can be multiple states based on the context: 1. AUTOCOMPLETE +
   * Gmail - context 1 2. AUTOCOMPLETE + Chat/Dynamite - context 2 3. "SOME
   * OTHER ACTION" + Gmail - context 3 A client should identify whether a
   * patrticular context is present in the list and only if one is found - use
   * the state that goes alogn with the context, otherwise the client should
   * default to whatever is the safe assumption about "internality/externality"
   * the application should be making (likely, consider everything not
   * explicitly "internal" as "external").
   */
  stateStatus?: PeoplestackFlexorgsProtoInternalExternalStateStatus[];
}

export interface PeoplestackFlexorgsProtoInternalExternalStateStatus {
  contextType?:  | "INTERNAL_EXTERNAL_CONTEXT_UNSPECIFIED" | "AUTOCOMPLETE";
  state?:  | "INTERNAL_EXTERNAL_STATE_UNSPECIFIED" | "INTERNAL" | "EXTERNAL" | "NOT_APPLICABLE";
}

/**
 * ===========================================================================
 * # Make sure you read the comments in the bottom before you add any new field.
 * NB: As noted in the comments, this protocol buffer is used in both indexing
 * and serving. In mustang serving implementations we only decode perdocdata
 * during the search phase, and so this protocol should only contain data used
 * during search. See
 * mustang/repos_www/attachments.proto:{MustangBasicInfo,MustangContentInfo} for
 * protocols used during search and/or docinfo. Next available tag deprecated,
 * use this (and look for commented out fields):
 * blaze-bin/net/proto_compiler/protocol-compiler --freetags \
 * indexer/perdocdata/perdocdata.proto Next tag: 220
 */
export interface PerDocData {
  /**
   * AppsLink contains Android application IDs in outlinks. It is used to
   * improve results ranking within applications universal. See
   * http://go/apps-universal for the project details.
   */
  appsLink?: QualityCalypsoAppsLink;
  /**
   * For indexing Asteroid Belt intent scores. See go/asteroid-belt for
   * details.
   */
  asteroidBeltIntents?: QualityOrbitAsteroidBeltDocumentIntentScores;
  authorObfuscatedGaiaStr?: string[];
  biasingdata?: BiasingPerDocData;
  /**
   * A replacement for BiasingPerDocData that is more space efficient. Once
   * this is live everywhere, biasingdata will be deprecated.
   */
  biasingdata2?: BiasingPerDocData2;
  BlogData?: BlogPerDocData;
  /**
   * The body words over tokens ratios for the beginning part and whole doc.
   * NB: To save space, field body_words_to_tokens_ratio_total is not set if it
   * has the same value as body_words_to_tokens_ratio_begin (e.g., short docs).
   */
  bodyWordsToTokensRatioBegin?: number;
  bodyWordsToTokensRatioTotal?: number;
  /**
   * the book citation data for each web page, the average size is about 10
   * bytes
   */
  BookCitationData?: BookCitationPerDocData;
  /**
   * Brainloc contains location information for the document. See ariane/273189
   * for details.
   */
  brainloc?: QualityGeoBrainlocBrainlocAttachment;
  /**
   * A measure of commerciality of the document Score > 0 indicates document is
   * commercial (i.e. sells something) Computed by
   * repository/pageclassifiers/parsehandler-commercial.cc
   */
  commercialScore?: number;
  compressedQualitySignals?: CompressedQualitySignals;
  /**
   * Compressed URL string used for SETI.
   */
  compressedUrl?: Uint8Array;
  contentAttributions?: ContentAttributions;
  /**
   * This field stores the country information for the document in the form of
   * CountryAttachment.
   */
  countryInfo?: CountryCountryAttachment;
  /**
   * For crawler-ID variations, the crawling context applied to the document.
   * See go/url, and the description in google3/indexing/crawler_id
   */
  crawlerIdProto?: LogsProtoIndexingCrawlerIdCrawlerIdProto;
  /**
   * This field is used internally by the docjoiner to forward the crawl
   * pageranks from original canonicals to canonicals we actually chose; outside
   * sources should not set it, and it should not be present in actual docjoins
   * or the index.
   */
  crawlPagerank?: number;
  crowdingdata?: CrowdingPerDocData;
  /**
   * Stores dates-related info (e.g. page is old based on its date
   * annotations). Used in FreshnessTwiddler. Use encode/decode functions from
   * quality/timebased/utils/dates-info-helper-inl.h
   */
  datesInfo?: bigint;
  /**
   * The obfuscated google profile gaia id(s) of the author(s) of the document.
   * This field is deprecated, use the string version.
   */
  DEPRECATEDAuthorObfuscatedGaia?: bigint[];
  DEPRECATEDQuarantineWhitelist?: boolean;
  /**
   * Contains desktop interstitials signal for VOLT ranking change.
   */
  desktopInterstitials?: IndexingMobileInterstitialsProtoDesktopInterstitials;
  /**
   * The document spam score is represented as a 7-bits, going from 0 to 127.
   */
  DocLevelSpamScore?: number;
  /**
   * 16-bit
   */
  domainAge?: number;
  /**
   * Free form debug info. NB2: consider carefully what to save here. It's easy
   * to eat lots of gfs space with debug info that nobody needs...
   */
  Event?: PerDocDebugEvent[];
  /**
   * Date for Events. A web page might list multiple events with different
   * dates. We only take one date (start date) per event.
   */
  eventsDate?: bigint[];
  /**
   * This field is available only in the docjoins: it is cleared before
   * building per-doc data in both Mustang and Teragoogle. (MessageSet is
   * inefficient in space for serving data) Use this for all new fields that
   * aren't needed during serving. Currently this field contains: * UrlSignals
   * for the document level spam classifier (when the doclevelspamscore is set).
   * * PerDocLangidData and realtimespam::ClassifierResult for the document
   * level fresh spam classifier (when the doc-level fresh spam score is
   * generated). * MicroblogDocQualitySignals for document-level microblog spam
   * classifier. This only exists in Firebird for now. *
   * spam_buckets::BucketsData for a document-structure hash
   */
  extraData?: Proto2BridgeMessageSet;
  /**
   * Contains Site signal information for Firefly ranking change. See
   * http://ariane/313938 for more details.
   */
  fireflySiteSignal?: QualityCopiaFireflySiteSignal;
  /**
   * Stores scores of freshness-related classifiers: freshbox article score,
   * live blog score and host-level article score. The encoding/decoding API is
   * in quality/freshness/freshbox/goldmine/freshbox_annotation_encoder.h. To
   * use this field, you MUST join g/pq-classifiers-announce and add your use
   * case at http://shortn/_RYXS2lX2IV.
   */
  freshboxArticleScores?: number;
  /**
   * Stores freshness and aging related data, such as time-related quality
   * metrics predicted from url-pattern level signals. Use the encoding decoding
   * API in quality/freshness/docclassifier/aging/encoded-pattern-signals.h This
   * field is deprecated.
   */
  freshnessEncodedSignals?: bigint;
  /**
   * Contains encoded FringeQueryPrior information. Unlikely to be meaningful
   * for anyone other than fringe-ranking team. Contact fringe-ranking team if
   * any questions, but do NOT use directly without consulting them.
   */
  fringeQueryPrior?: QualityFringeFringeQueryPriorPerDocData;
  /**
   * geo data; approx 24 bytes for 23M U.S. pages
   */
  geodata?: string;
  /**
   * The gibberish score is represented in 7 bits, going from 0 to 127.
   */
  GibberishScore?: number;
  /**
   * 16 bytes of groups2 data: used only in groups2 index
   */
  GroupsData?: GroupsPerDocData;
  homePageInfo?: number;
  /**
   * The page-rank of the homepage of the site. Copied from the
   * cdoc.doc().pagerank_ns() of the homepage.
   */
  homepagePagerankNs?: number;
  /**
   * The earliest firstseen date of all pages in this host/domain. These data
   * are used in twiddler to sandbox fresh spam in serving time. It is 16 bit
   * and the time is day number after 2005-12-31, and all the previous time are
   * set to 0. If this url's host_age == domain_age, then omit domain_age Please
   * use //spam/content/siteage-util.h to convert the day between epoch second.
   * Regarding usage of Sentinel values: We would like to check if a value
   * exists in scoring bundle while using in Ranklab AST. For this having a
   * sentinel value will help us know if the field exists or has a sentinel
   * value (in the case it does not exist). 16-bit
   */
  hostAge?: number;
  /**
   * Site rank computed for host-level sitechunks. This value encodes nsr,
   * site_pr and new_nsr. See quality_nsr::util::ConvertNsrDataToHostNsr and
   * go/nsr.
   */
  hostNsr?: number;
  imagedata?: ImagePerDocData;
  /**
   * This field indicates whether the document is in the newsstand corpus.
   */
  inNewsstand?: boolean;
  /**
   * Is this document considered spam by the anchor bayes classifier?
   */
  IsAnchorBayesSpam?: boolean;
  /**
   * Set by the FreshDocs instant doc joiner. See
   * //indexing/instant/hotdocs/README and http://go/freshdocs-hotdocs.
   */
  isHotdoc?: boolean;
  kaltixdata?: KaltixPerDocData;
  /**
   * The keyword stuffing score is represented in 7 bits, going from 0 to 127.
   */
  KeywordStuffingScore?: number;
  /**
   * For indexing k'nex annotations for FreshDocs.
   */
  knexAnnotation?: SocialPersonalizationKnexAnnotation;
  /**
   * Plausible languages in order of decreasing plausibility. Language values
   * are small, IE < 127 so this should compress to one byte each.
   */
  languages?: number[];
  /**
   * Last significant update of the document. This is sourced from the
   * quality_timebased.LastSignificantUpdate proto as computed by the
   * LSUSelector from various signals. The value is a UNIX timestamp in seconds.
   */
  lastSignificantUpdate?: bigint;
  /**
   * Metadata about last significant update. Currently this only encodes the
   * quality_timebased.LastSignificantUpdate.source field which contains the
   * info on the source of the signal. NOTE: Please do not read the value
   * directly. Use helpers from
   * quality/timebased/lastsignificantupdate/lsu-helper.h instead.
   */
  lastSignificantUpdateInfo?: bigint;
  /**
   * Info on how to launch a mobile app to consume this document's content, if
   * applicable (see go/calypso).
   */
  launchAppInfo?: QualityRichsnippetsAppsProtosLaunchAppInfoPerDocData;
  liveResultsData?: WeboftrustLiveResultsDocAttachments;
  /**
   * Information on localized clusters, which is the relationship of translated
   * and/or localized pages.
   */
  localizedCluster?: IndexingDupsLocalizedLocalizedCluster;
  /**
   * Additional metadata for lowend mobile documents in the Google index.
   */
  MobileData?: MobilePerDocData;
  /**
   * If not 0, we should not show the image in overlay mode in image snippets
   */
  noimageframeoverlayreason?: number;
  /**
   * Stripped site-level signals, not present in the explicit nsr_* fields, nor
   * compressed_quality_signals.
   */
  nsrDataProto?: QualityNsrNsrData;
  /**
   * This field is propagated to shards. In addition, it is populated at
   * serving time by go/web-signal-joins.
   */
  nsrIsCovidLocalAuthority?: boolean;
  /**
   * This field is propagated to shards. It will also be populated at serving
   * time by go/web-signal-joins (see b/168114815).
   */
  nsrIsElectionAuthority?: boolean;
  /**
   * This field is propagated to shards. It will also be populated at serving
   * time by go/web-signal-joins (see b/170607253). Bit indicating whether this
   * site is video-focused, but not hosted on any major known video hosting
   * domains.
   */
  nsrIsVideoFocusedSite?: boolean;
  /**
   * SiteChunk computed for nsr. It some cases it can use more information than
   * just url (e.g. youtube channels). See NsrAnnotator for details. If
   * sitechunk is longer than --populate_nsr_sitechunk_max_length (default=100),
   * it will not get populated. This field might be compressed and needs to be
   * decoded with quality_nsr::util::DecodeNsrSitechunk. See go/nsr-chunks for
   * more details. This field contains only nontrivial primary chunks.
   */
  nsrSitechunk?: string;
  /**
   * Total number of urls encoded in the url section = # of alternate urls + 1
   */
  numUrls?: number;
  /**
   * 28 bytes per page, only in the Ocean index
   */
  oceandata?: OceanPerDocData;
  /**
   * Onsite prominence measures the importance of the document within its site.
   * It is computed by propagating simulated traffic from the homepage and high
   * craps click pages. It is a 13-bit int.
   */
  onsiteProminence?: number;
  origin?: number;
  /**
   * The original content score is represented as a 7-bits, going from 0 to
   * 127. Only pages with little content have this field. The actual original
   * content score ranges from 0 to 512. It is encoded with
   * quality_q2::OriginalContentUtil::EncodeOriginalContentScore(). To decode
   * the value, use
   * quality_q2::OriginalContentUtil::DecodeOriginalContentScore().
   */
  OriginalContentScore?: number;
  /**
   * The number of hard tokens in the title.
   */
  originalTitleHardTokenCount?: number;
  /**
   * Experimental pageranks (DEPRECATED; only pagerank in MustangBasicInfo is
   * used).
   */
  pagerank?: number;
  pagerank0?: number;
  pagerank1?: number;
  pagerank2?: number;
  /**
   * String that encodes the position ranges for different regions of the
   * document. See "indexer/pageregion.h" for an explanation, and how to decode
   * the string
   */
  pageregions?: string;
  pageTags?: number[];
  phildata?: PhilPerDocData;
  /**
   * Additional metadata for Premium document in the Google index.
   */
  PremiumData?: PremiumPerDocData;
  /**
   * This field stores information about product sites.
   */
  productSitesInfo?: QualityProductProductSiteData;
  /**
   * bitmask of QuarantineBits (or'd together) used to store quarantine related
   * information. For example: QUARANTINE_WHITELIST | QUARANTINE_URLINURL.
   */
  QuarantineInfo?: number;
  /**
   * The set of (query, country, language) triples for which this document is
   * considered to be the official page. For example, www.britneyspears.com
   * would be official for ("britney spears", "us", 0) and others (0 is
   * English).
   */
  queriesForWhichOfficial?: OfficialPagesQuerySet;
  /**
   * Top two document language BCP-47 codes as generated by the
   * RosettaLanguageAnnotator in the decreasing order of probability.
   */
  rosettaLanguages?: string[];
  /**
   * Application information associated to the document.
   */
  rsApplication?: RepositoryAnnotationsRdfaRdfaRichSnippetsApplication;
  /**
   * Primary video's audio language classified by S3 based Automatic Language
   * Identification (only for watch pages).
   */
  s3AudioLanguage?: S3AudioLanguageS3AudioLanguage;
  /**
   * Top document language as generated by SAFT LangID. For now we store bare
   * minimum: just the top 1 language value, converted to the language enum, and
   * only when different from the first value in 'languages'.
   */
  saftLanguageInt?: number[];
  /**
   * DEPRECATED
   * ---------------------------------------------------------------- Please do
   * not use these fields in any new code. experimental
   */
  ScaledExptIndyRank?: number;
  /**
   * experimental
   */
  ScaledExptIndyRank2?: number;
  /**
   * experimental
   */
  ScaledExptIndyRank3?: number;
  ScaledExptSpamScoreEric?: number;
  ScaledExptSpamScoreYoram?: number;
  /**
   * The independence rank is represented as a 16-bit integer, which is
   * multiplied by (max_indy_rank / 65536) to produce actual independence rank
   * values. max_indy_rank is typically 0.84.
   */
  ScaledIndyRank?: number;
  /**
   * End DEPRECATED
   * ------------------------------------------------------------ Link age score
   * is represented as a 7-bit integer, going from 0 to 127.
   */
  ScaledLinkAgeSpamScore?: number;
  /**
   * Selection tier rank is a language normalized score ranging from 0-32767
   * over the serving tier (Base, Zeppelins, Landfills) for this document. This
   * is converted back to fractional position within the index tier by
   * scaled_selection_tier_rank/32767.
   */
  scaledSelectionTierRank?: number;
  ScaledSpamScoreEric?: number;
  /**
   * Spamscores are represented as a 7-bit integer, going from 0 to 127.
   */
  ScaledSpamScoreYoram?: number;
  /**
   * Scholar/Science Document type: <0 == not a Science Document -- default 0
   * == Science doc fully visible >0 == Science doc but limited visibility, the
   * number is the visible terms
   */
  scienceDoctype?: number;
  /**
   * Deprecated 2016/01/14.
   */
  scienceHoldingsIds?: bigint[];
  /**
   * SemanticDate, estimated date of the content of a document based on the
   * contents of the document (via parsing), anchors and related documents. Date
   * is encoded as a 32-bits UNIX date (1970 Jan 1 epoch). Confidence is encoded
   * using a SemanticDate specific format. For details of encoding, please refer
   * to quality/freshness/docclassifier/semanticdate/public/semantic_date.proto
   */
  semanticDate?: number;
  /**
   * DEPRECATED: semantic_date_confidence replaced by semantic_date_info.
   */
  semanticDateConfidence?: number;
  /**
   * Info is encoded using a SemanticDate specific format. Contains confidence
   * scores for day/month/year components as well as various meta data required
   * by the freshness twiddlers.
   */
  semanticDateInfo?: number;
  /**
   * A set of cluster ids which are generated in Alexandria and used to de-dup
   * results at serving time.
   */
  servingTimeClusterIds?: IndexingDocjoinerServingTimeClusterIds;
  shingleInfo?: ShingleInfoPerDocData;
  /**
   * Additional metadata for smartphone documents in the Google index.
   */
  smartphoneData?: SmartphonePerDocData;
  smearingMaxTotalOffdomainAnchors?: number;
  /**
   * For Social Search we store the fingerprint of the SG node name. This is
   * used in one of the superroot's PRE_DOC twiddlers as a lookup key for the
   * full Social Search data. PRE_DOC = twiddlers firing before the DocInfo
   * request is sent to the mustang backend.
   */
  socialgraphNodeNameFp?: bigint;
  /**
   * Site level scores coming from spambrain.
   */
  spambrainData?: SpamBrainData;
  /**
   * The document total spam score identified by spambrain, going from 0 to 1.
   */
  spambrainTotalDocSpamScore?: number;
  /**
   * Actions based on Cookbook recipes that match the page.
   */
  spamCookbookAction?: SpamCookbookAction;
  /**
   * Contains hacked site signals which will be used in query time joins. As of
   * Oct'19, the field is stored in a separate corpus. It'll only be populated
   * for in-flight requests between retrieve and full-score in perdocdata. So no
   * extra storage is needed on muppet side.
   */
  spamMuppetSignals?: SpamMuppetjoinsMuppetSignals;
  /**
   * The spamrank measures the likelihood that this document links to known
   * spammers. Its value is between 0 and 65535.
   */
  spamrank?: number;
  /**
   * For SpamTokens content scores. Used in SiteBoostTwiddler to determine
   * whether a page is UGC Spam. See go/spamtokens-dd for details.
   */
  spamtokensContentScore?: number;
  /**
   * The spamword score is represented in 7-bits, going from 0 to 127.
   */
  SpamWordScore?: number;
  /**
   * Tag-site-ness of a page, repesented in 7-bits range from 0 to 100. Smaller
   * value means worse tag page.
   */
  TagPageScore?: number;
  /**
   * Encoded Document Time Sensitivity signal.
   */
  timeSensitivity?: number;
  /**
   * Number of hard tokens originally in title without counting the stopwords.
   */
  titleHardTokenCountWithoutStopwords?: number;
  ToolBarData?: ToolBarPerDocData;
  /**
   * A copy of the value stored in /namespace/indexing/wwwglobal//fakepr/* for
   * this document. A value of
   * quality_bakery::FakeprUtils::kUnknownToolbarPagerank indicates that we
   * don't have toolbar pagerank for this document. A value between 0 and 10
   * (inclusive) means that this is the toolbar pagerank of the page. Finally,
   * if this value is not set it means that the toolbar pagerank is equivalent
   * to:
   * quality_bakery::FakeprUtils::EstimatePreDemotionFromPagerankNearestSeeds(
   * basic_info.pagerank_ns()) called on the MustangBasicInfo attachment for the
   * same document.
   */
  toolbarPagerank?: number;
  /**
   * Top petacat of the site. Used in SiteboostTwiddler to determine
   * result/query matching.
   */
  topPetacatTaxId?: number;
  topPetacatWeight?: number;
  /**
   * This field stores information about good travel sites.
   */
  travelGoodSitesInfo?: QualityTravelGoodSitesData;
  /**
   * For now, the count of matching trendspam queries.
   */
  trendspamScore?: number;
  /**
   * This field is propagated to shards. Stores clustering information on a
   * site level for the Tundra project.
   */
  tundraClusterId?: number;
  /**
   * The uac spam score is represented in 7 bits, going from 0 to 127.
   * Threshold is 64. Score >= 64 is considered as uac spam.
   */
  uacSpamScore?: number;
  /**
   * These two fingerprints are used for de-duping results in a twiddler. They
   * should only be populated by freshdocs, and will only be present for
   * documents that are chosen to be canonicals in a cluster whose previous
   * canonical is also in the index. Additionally, url_after_redirects_fp is
   * only present if it is different from a fingerprint of the URL.
   */
  urlAfterRedirectsFp?: bigint;
  /**
   * Contains url poisoning data for suppressing spam documents.
   */
  urlPoisoningData?: UrlPoisoningData;
  /**
   * For indexing v2 k'nex, see/go/knex-v2-doc-annotation for details.
   */
  v2KnexAnnotation?: QualitySherlockKnexAnnotation;
  videoCorpusDocid?: bigint;
  videodata?: VideoPerDocData;
  /**
   * Audio-based language classified by Automatic Language Identification (only
   * for watch pages).
   */
  videoLanguage?: QualityVidyaVideoLanguageVideoLanguage;
  /**
   * Contains page UX signals for VOLT ranking change. See
   * http://ariane/4025970 for more details.
   */
  voltData?: IndexingMobileVoltVoltPerDocData;
  /**
   * Language classified by the WatchPageLanguage Model
   * (go/watchpage-language). Only present for watch pages.
   */
  watchpageLanguageResult?: WatchpageLanguageWatchPageLanguageResult;
  webmirrorEcnFp?: bigint;
  /**
   * WebRef entities associated to the document. See go/webref for details.
   */
  webrefEntities?: RepositoryWebrefWebrefMustangAttachment;
  WhirlpoolDiscount?: number;
  /**
   * Stores scores of ymyl health classifier as defined at
   * go/ymyl-classifier-dd. To use this field, you MUST join
   * g/pq-classifiers-announce and add your use case at
   * http://shortn/_nfg9oAldou.
   */
  ymylHealthScore?: number;
  /**
   * Stores scores of ymyl news classifier as defined at go/ymyl-classifier-dd.
   * To use this field, you MUST join g/pq-classifiers-announce and add your use
   * case at http://shortn/_nfg9oAldou.
   */
  ymylNewsScore?: number;
}

function serializePerDocData(data: any): PerDocData {
  return {
    ...data,
    biasingdata: data["biasingdata"] !== undefined ? serializeBiasingPerDocData(data["biasingdata"]) : undefined,
    BlogData: data["BlogData"] !== undefined ? serializeBlogPerDocData(data["BlogData"]) : undefined,
    BookCitationData: data["BookCitationData"] !== undefined ? serializeBookCitationPerDocData(data["BookCitationData"]) : undefined,
    compressedQualitySignals: data["compressedQualitySignals"] !== undefined ? serializeCompressedQualitySignals(data["compressedQualitySignals"]) : undefined,
    compressedUrl: data["compressedUrl"] !== undefined ? encodeBase64(data["compressedUrl"]) : undefined,
    contentAttributions: data["contentAttributions"] !== undefined ? serializeContentAttributions(data["contentAttributions"]) : undefined,
    countryInfo: data["countryInfo"] !== undefined ? serializeCountryCountryAttachment(data["countryInfo"]) : undefined,
    crowdingdata: data["crowdingdata"] !== undefined ? serializeCrowdingPerDocData(data["crowdingdata"]) : undefined,
    datesInfo: data["datesInfo"] !== undefined ? String(data["datesInfo"]) : undefined,
    DEPRECATEDAuthorObfuscatedGaia: data["DEPRECATEDAuthorObfuscatedGaia"] !== undefined ? data["DEPRECATEDAuthorObfuscatedGaia"].map((item: any) => (String(item))) : undefined,
    desktopInterstitials: data["desktopInterstitials"] !== undefined ? serializeIndexingMobileInterstitialsProtoDesktopInterstitials(data["desktopInterstitials"]) : undefined,
    Event: data["Event"] !== undefined ? data["Event"].map((item: any) => (serializePerDocDebugEvent(item))) : undefined,
    eventsDate: data["eventsDate"] !== undefined ? data["eventsDate"].map((item: any) => (String(item))) : undefined,
    fireflySiteSignal: data["fireflySiteSignal"] !== undefined ? serializeQualityCopiaFireflySiteSignal(data["fireflySiteSignal"]) : undefined,
    freshnessEncodedSignals: data["freshnessEncodedSignals"] !== undefined ? String(data["freshnessEncodedSignals"]) : undefined,
    GroupsData: data["GroupsData"] !== undefined ? serializeGroupsPerDocData(data["GroupsData"]) : undefined,
    knexAnnotation: data["knexAnnotation"] !== undefined ? serializeSocialPersonalizationKnexAnnotation(data["knexAnnotation"]) : undefined,
    lastSignificantUpdate: data["lastSignificantUpdate"] !== undefined ? String(data["lastSignificantUpdate"]) : undefined,
    lastSignificantUpdateInfo: data["lastSignificantUpdateInfo"] !== undefined ? String(data["lastSignificantUpdateInfo"]) : undefined,
    launchAppInfo: data["launchAppInfo"] !== undefined ? serializeQualityRichsnippetsAppsProtosLaunchAppInfoPerDocData(data["launchAppInfo"]) : undefined,
    liveResultsData: data["liveResultsData"] !== undefined ? serializeWeboftrustLiveResultsDocAttachments(data["liveResultsData"]) : undefined,
    localizedCluster: data["localizedCluster"] !== undefined ? serializeIndexingDupsLocalizedLocalizedCluster(data["localizedCluster"]) : undefined,
    nsrDataProto: data["nsrDataProto"] !== undefined ? serializeQualityNsrNsrData(data["nsrDataProto"]) : undefined,
    oceandata: data["oceandata"] !== undefined ? serializeOceanPerDocData(data["oceandata"]) : undefined,
    PremiumData: data["PremiumData"] !== undefined ? serializePremiumPerDocData(data["PremiumData"]) : undefined,
    queriesForWhichOfficial: data["queriesForWhichOfficial"] !== undefined ? serializeOfficialPagesQuerySet(data["queriesForWhichOfficial"]) : undefined,
    rsApplication: data["rsApplication"] !== undefined ? serializeRepositoryAnnotationsRdfaRdfaRichSnippetsApplication(data["rsApplication"]) : undefined,
    scienceHoldingsIds: data["scienceHoldingsIds"] !== undefined ? data["scienceHoldingsIds"].map((item: any) => (String(item))) : undefined,
    servingTimeClusterIds: data["servingTimeClusterIds"] !== undefined ? serializeIndexingDocjoinerServingTimeClusterIds(data["servingTimeClusterIds"]) : undefined,
    smartphoneData: data["smartphoneData"] !== undefined ? serializeSmartphonePerDocData(data["smartphoneData"]) : undefined,
    socialgraphNodeNameFp: data["socialgraphNodeNameFp"] !== undefined ? String(data["socialgraphNodeNameFp"]) : undefined,
    urlAfterRedirectsFp: data["urlAfterRedirectsFp"] !== undefined ? String(data["urlAfterRedirectsFp"]) : undefined,
    urlPoisoningData: data["urlPoisoningData"] !== undefined ? serializeUrlPoisoningData(data["urlPoisoningData"]) : undefined,
    videoCorpusDocid: data["videoCorpusDocid"] !== undefined ? String(data["videoCorpusDocid"]) : undefined,
    videodata: data["videodata"] !== undefined ? serializeVideoPerDocData(data["videodata"]) : undefined,
    voltData: data["voltData"] !== undefined ? serializeIndexingMobileVoltVoltPerDocData(data["voltData"]) : undefined,
    webmirrorEcnFp: data["webmirrorEcnFp"] !== undefined ? String(data["webmirrorEcnFp"]) : undefined,
    webrefEntities: data["webrefEntities"] !== undefined ? serializeRepositoryWebrefWebrefMustangAttachment(data["webrefEntities"]) : undefined,
  };
}

function deserializePerDocData(data: any): PerDocData {
  return {
    ...data,
    biasingdata: data["biasingdata"] !== undefined ? deserializeBiasingPerDocData(data["biasingdata"]) : undefined,
    BlogData: data["BlogData"] !== undefined ? deserializeBlogPerDocData(data["BlogData"]) : undefined,
    BookCitationData: data["BookCitationData"] !== undefined ? deserializeBookCitationPerDocData(data["BookCitationData"]) : undefined,
    compressedQualitySignals: data["compressedQualitySignals"] !== undefined ? deserializeCompressedQualitySignals(data["compressedQualitySignals"]) : undefined,
    compressedUrl: data["compressedUrl"] !== undefined ? decodeBase64(data["compressedUrl"] as string) : undefined,
    contentAttributions: data["contentAttributions"] !== undefined ? deserializeContentAttributions(data["contentAttributions"]) : undefined,
    countryInfo: data["countryInfo"] !== undefined ? deserializeCountryCountryAttachment(data["countryInfo"]) : undefined,
    crowdingdata: data["crowdingdata"] !== undefined ? deserializeCrowdingPerDocData(data["crowdingdata"]) : undefined,
    datesInfo: data["datesInfo"] !== undefined ? BigInt(data["datesInfo"]) : undefined,
    DEPRECATEDAuthorObfuscatedGaia: data["DEPRECATEDAuthorObfuscatedGaia"] !== undefined ? data["DEPRECATEDAuthorObfuscatedGaia"].map((item: any) => (BigInt(item))) : undefined,
    desktopInterstitials: data["desktopInterstitials"] !== undefined ? deserializeIndexingMobileInterstitialsProtoDesktopInterstitials(data["desktopInterstitials"]) : undefined,
    Event: data["Event"] !== undefined ? data["Event"].map((item: any) => (deserializePerDocDebugEvent(item))) : undefined,
    eventsDate: data["eventsDate"] !== undefined ? data["eventsDate"].map((item: any) => (BigInt(item))) : undefined,
    fireflySiteSignal: data["fireflySiteSignal"] !== undefined ? deserializeQualityCopiaFireflySiteSignal(data["fireflySiteSignal"]) : undefined,
    freshnessEncodedSignals: data["freshnessEncodedSignals"] !== undefined ? BigInt(data["freshnessEncodedSignals"]) : undefined,
    GroupsData: data["GroupsData"] !== undefined ? deserializeGroupsPerDocData(data["GroupsData"]) : undefined,
    knexAnnotation: data["knexAnnotation"] !== undefined ? deserializeSocialPersonalizationKnexAnnotation(data["knexAnnotation"]) : undefined,
    lastSignificantUpdate: data["lastSignificantUpdate"] !== undefined ? BigInt(data["lastSignificantUpdate"]) : undefined,
    lastSignificantUpdateInfo: data["lastSignificantUpdateInfo"] !== undefined ? BigInt(data["lastSignificantUpdateInfo"]) : undefined,
    launchAppInfo: data["launchAppInfo"] !== undefined ? deserializeQualityRichsnippetsAppsProtosLaunchAppInfoPerDocData(data["launchAppInfo"]) : undefined,
    liveResultsData: data["liveResultsData"] !== undefined ? deserializeWeboftrustLiveResultsDocAttachments(data["liveResultsData"]) : undefined,
    localizedCluster: data["localizedCluster"] !== undefined ? deserializeIndexingDupsLocalizedLocalizedCluster(data["localizedCluster"]) : undefined,
    nsrDataProto: data["nsrDataProto"] !== undefined ? deserializeQualityNsrNsrData(data["nsrDataProto"]) : undefined,
    oceandata: data["oceandata"] !== undefined ? deserializeOceanPerDocData(data["oceandata"]) : undefined,
    PremiumData: data["PremiumData"] !== undefined ? deserializePremiumPerDocData(data["PremiumData"]) : undefined,
    queriesForWhichOfficial: data["queriesForWhichOfficial"] !== undefined ? deserializeOfficialPagesQuerySet(data["queriesForWhichOfficial"]) : undefined,
    rsApplication: data["rsApplication"] !== undefined ? deserializeRepositoryAnnotationsRdfaRdfaRichSnippetsApplication(data["rsApplication"]) : undefined,
    scienceHoldingsIds: data["scienceHoldingsIds"] !== undefined ? data["scienceHoldingsIds"].map((item: any) => (BigInt(item))) : undefined,
    servingTimeClusterIds: data["servingTimeClusterIds"] !== undefined ? deserializeIndexingDocjoinerServingTimeClusterIds(data["servingTimeClusterIds"]) : undefined,
    smartphoneData: data["smartphoneData"] !== undefined ? deserializeSmartphonePerDocData(data["smartphoneData"]) : undefined,
    socialgraphNodeNameFp: data["socialgraphNodeNameFp"] !== undefined ? BigInt(data["socialgraphNodeNameFp"]) : undefined,
    urlAfterRedirectsFp: data["urlAfterRedirectsFp"] !== undefined ? BigInt(data["urlAfterRedirectsFp"]) : undefined,
    urlPoisoningData: data["urlPoisoningData"] !== undefined ? deserializeUrlPoisoningData(data["urlPoisoningData"]) : undefined,
    videoCorpusDocid: data["videoCorpusDocid"] !== undefined ? BigInt(data["videoCorpusDocid"]) : undefined,
    videodata: data["videodata"] !== undefined ? deserializeVideoPerDocData(data["videodata"]) : undefined,
    voltData: data["voltData"] !== undefined ? deserializeIndexingMobileVoltVoltPerDocData(data["voltData"]) : undefined,
    webmirrorEcnFp: data["webmirrorEcnFp"] !== undefined ? BigInt(data["webmirrorEcnFp"]) : undefined,
    webrefEntities: data["webrefEntities"] !== undefined ? deserializeRepositoryWebrefWebrefMustangAttachment(data["webrefEntities"]) : undefined,
  };
}

/**
 * Free form debug information from various components.
 */
export interface PerDocDebugEvent {
  /**
   * depends on the source
   */
  Message?: string;
  /**
   * source tag, helps interpret value/message
   */
  Source?: string;
  /**
   * seconds since the epoch
   */
  Timestamp?: number;
  /**
   * depends on the source
   */
  Value?: bigint;
}

function serializePerDocDebugEvent(data: any): PerDocDebugEvent {
  return {
    ...data,
    Value: data["Value"] !== undefined ? String(data["Value"]) : undefined,
  };
}

function deserializePerDocDebugEvent(data: any): PerDocDebugEvent {
  return {
    ...data,
    Value: data["Value"] !== undefined ? BigInt(data["Value"]) : undefined,
  };
}

/**
 * A unique association of an AliasType and a number to identify this alias.
 */
export interface PersonalizationMapsAliasAliasId {
  /**
   * A unique identifier for this alias, this identifier is unique to the type
   * of this Alias. This means that aliases of different types can have the same
   * sub_id, hence always use the full AliasId message to refer to an alias, not
   * this field only. Because HOME and WORK aliases are unique, aliases of type
   * HOME or WORK always have sub_id 0.
   */
  subId?: bigint;
  type?:  | "UNKNOWN_ALIAS_TYPE" | "HOME" | "WORK" | "CONTACT" | "NICKNAME";
}

function serializePersonalizationMapsAliasAliasId(data: any): PersonalizationMapsAliasAliasId {
  return {
    ...data,
    subId: data["subId"] !== undefined ? String(data["subId"]) : undefined,
  };
}

function deserializePersonalizationMapsAliasAliasId(data: any): PersonalizationMapsAliasAliasId {
  return {
    ...data,
    subId: data["subId"] !== undefined ? BigInt(data["subId"]) : undefined,
  };
}

/**
 * A subset of an Alias that is stored on kansas max. It is used in Search for
 * alias resolution and in Maps to show icons quickly on basetiles.
 */
export interface PersonalizationMapsAliasIcon {
  /**
   * The id of the alias associated with this point. This is used to query for
   * details for the info window and to display different icons depending on the
   * AliasType contained in this message.
   */
  aliasId?: PersonalizationMapsAliasAliasId;
  /**
   * If this is a dropped pin alias, the leaf (level 30) S2 cell ID
   * corresponding to the aliased lat/lng. Calculated once and stored here so
   * that it can safely be used as an identifier across clients without risk of
   * rounding differences leading to different values.
   */
  droppedPinS2cellId?: bigint;
  /**
   * The featureid that was associated with the alias when it was saved. If
   * this is not set the lat/lng in 'point' is the aliased entity, i.e. this is
   * a dropped pin alias.
   */
  featureId?: GeostoreFeatureIdProto;
  /**
   * For non-address feature aliases (e.g. businesses), the name of the feature
   * (formatted from the FeatureProto) when it was saved.
   */
  featureName?: string;
  /**
   * The type of the feature associated with the alias.
   */
  featureType?:  | "TYPE_ANY" | "TYPE_TRANSPORTATION" | "TYPE_ROUTE" | "TYPE_DEPRECATED_HIGHWAY_DO_NOT_USE" | "TYPE_HIGHWAY" | "TYPE_HIGHWAY_1" | "TYPE_HIGHWAY_2" | "TYPE_HIGHWAY_3" | "TYPE_HIGHWAY_4" | "TYPE_HIGHWAY_5" | "TYPE_HIGHWAY_6" | "TYPE_HIGHWAY_7" | "TYPE_HIGHWAY_8" | "TYPE_HIGHWAY_9" | "TYPE_BICYCLE_ROUTE" | "TYPE_TRAIL" | "TYPE_SEGMENT" | "TYPE_ROAD" | "TYPE_RAILWAY" | "TYPE_STANDARD_TRACK" | "TYPE_JR_TRACK" | "TYPE_NARROW_TRACK" | "TYPE_MONORAIL_TRACK" | "TYPE_SUBWAY_TRACK" | "TYPE_LIGHT_RAIL_TRACK" | "TYPE_BROAD_TRACK" | "TYPE_HIGH_SPEED_RAIL" | "TYPE_TROLLEY_TRACK" | "TYPE_FERRY" | "TYPE_FERRY_BOAT" | "TYPE_FERRY_TRAIN" | "TYPE_VIRTUAL_SEGMENT" | "TYPE_INTERSECTION" | "TYPE_TRANSIT" | "TYPE_TRANSIT_STATION" | "TYPE_BUS_STATION" | "TYPE_TRAMWAY_STATION" | "TYPE_TRAIN_STATION" | "TYPE_SUBWAY_STATION" | "TYPE_FERRY_TERMINAL" | "TYPE_AIRPORT" | "TYPE_AIRPORT_CIVIL" | "TYPE_AIRPORT_MILITARY" | "TYPE_AIRPORT_MIXED" | "TYPE_HELIPORT" | "TYPE_SEAPLANE_BASE" | "TYPE_AIRSTRIP" | "TYPE_CABLE_CAR_STATION" | "TYPE_GONDOLA_LIFT_STATION" | "TYPE_FUNICULAR_STATION" | "TYPE_SPECIAL_STATION" | "TYPE_HORSE_CARRIAGE_STATION" | "TYPE_MONORAIL_STATION" | "TYPE_SEAPORT" | "TYPE_TRANSIT_STOP" | "TYPE_TRANSIT_TRIP" | "TYPE_TRANSIT_DEPARTURE" | "TYPE_TRANSIT_LEG" | "TYPE_TRANSIT_LINE" | "TYPE_TRANSIT_AGENCY_DEPRECATED_VALUE" | "TYPE_TRANSIT_TRANSFER" | "TYPE_SEGMENT_PATH" | "TYPE_ROAD_SIGN" | "TYPE_INTERSECTION_GROUP" | "TYPE_PATHWAY" | "TYPE_RESTRICTION_GROUP" | "TYPE_TOLL_CLUSTER" | "TYPE_POLITICAL" | "TYPE_COUNTRY" | "TYPE_ADMINISTRATIVE_AREA" | "TYPE_ADMINISTRATIVE_AREA1" | "TYPE_US_STATE" | "TYPE_GB_COUNTRY" | "TYPE_JP_TODOUFUKEN" | "TYPE_ADMINISTRATIVE_AREA2" | "TYPE_GB_FORMER_POSTAL_COUNTY" | "TYPE_GB_TRADITIONAL_COUNTY" | "TYPE_ADMINISTRATIVE_AREA3" | "TYPE_ADMINISTRATIVE_AREA4" | "TYPE_ADMINISTRATIVE_AREA5" | "TYPE_ADMINISTRATIVE_AREA6" | "TYPE_ADMINISTRATIVE_AREA7" | "TYPE_ADMINISTRATIVE_AREA8" | "TYPE_ADMINISTRATIVE_AREA9" | "TYPE_COLLOQUIAL_AREA" | "TYPE_RESERVATION" | "TYPE_LOCALITY" | "TYPE_GB_POST_TOWN" | "TYPE_JP_GUN" | "TYPE_JP_SHIKUCHOUSON" | "TYPE_JP_SUB_SHIKUCHOUSON" | "TYPE_COLLOQUIAL_CITY" | "TYPE_SUBLOCALITY" | "TYPE_US_BOROUGH" | "TYPE_GB_DEPENDENT_LOCALITY" | "TYPE_JP_OOAZA" | "TYPE_JP_KOAZA" | "TYPE_JP_GAIKU" | "TYPE_GB_DOUBLE_DEPENDENT_LOCALITY" | "TYPE_JP_CHIBAN" | "TYPE_JP_EDABAN" | "TYPE_SUBLOCALITY1" | "TYPE_SUBLOCALITY2" | "TYPE_SUBLOCALITY3" | "TYPE_SUBLOCALITY4" | "TYPE_SUBLOCALITY5" | "TYPE_NEIGHBORHOOD" | "TYPE_CONSTITUENCY" | "TYPE_DESIGNATED_MARKET_AREA" | "TYPE_SCHOOL_DISTRICT" | "TYPE_LAND_PARCEL" | "TYPE_DISPUTED_AREA" | "TYPE_POLICE_JURISDICTION" | "TYPE_STATISTICAL_AREA" | "TYPE_CONSTITUENCY_FUTURE" | "TYPE_PARK" | "TYPE_GOLF_COURSE" | "TYPE_LOCAL_PARK" | "TYPE_NATIONAL_PARK" | "TYPE_US_NATIONAL_PARK" | "TYPE_US_NATIONAL_MONUMENT" | "TYPE_NATIONAL_FOREST" | "TYPE_PROVINCIAL_PARK" | "TYPE_PROVINCIAL_FOREST" | "TYPE_CAMPGROUNDS" | "TYPE_HIKING_AREA" | "TYPE_BUSINESS" | "TYPE_GOVERNMENT" | "TYPE_BORDER_CROSSING" | "TYPE_CITY_HALL" | "TYPE_COURTHOUSE" | "TYPE_EMBASSY" | "TYPE_LIBRARY" | "TYPE_SCHOOL" | "TYPE_UNIVERSITY" | "TYPE_EMERGENCY" | "TYPE_HOSPITAL" | "TYPE_PHARMACY" | "TYPE_POLICE" | "TYPE_FIRE" | "TYPE_DOCTOR" | "TYPE_DENTIST" | "TYPE_VETERINARIAN" | "TYPE_TRAVEL_SERVICE" | "TYPE_LODGING" | "TYPE_RESTAURANT" | "TYPE_GAS_STATION" | "TYPE_PARKING" | "TYPE_POST_OFFICE" | "TYPE_REST_AREA" | "TYPE_CASH_MACHINE" | "TYPE_CAR_RENTAL" | "TYPE_CAR_REPAIR" | "TYPE_SHOPPING" | "TYPE_GROCERY" | "TYPE_TOURIST_DESTINATION" | "TYPE_ECO_TOURIST_DESTINATION" | "TYPE_BIRD_WATCHING" | "TYPE_FISHING" | "TYPE_HUNTING" | "TYPE_NATURE_RESERVE" | "TYPE_TEMPLE" | "TYPE_CHURCH" | "TYPE_GURUDWARA" | "TYPE_HINDU_TEMPLE" | "TYPE_MOSQUE" | "TYPE_SYNAGOGUE" | "TYPE_STADIUM" | "TYPE_BAR" | "TYPE_MOVIE_RENTAL" | "TYPE_COFFEE" | "TYPE_GOLF" | "TYPE_BANK" | "TYPE_DOODLE" | "TYPE_GROUNDS" | "TYPE_AIRPORT_GROUNDS" | "TYPE_BUILDING_GROUNDS" | "TYPE_CEMETERY" | "TYPE_HOSPITAL_GROUNDS" | "TYPE_INDUSTRIAL" | "TYPE_MILITARY" | "TYPE_SHOPPING_CENTER" | "TYPE_SPORTS_COMPLEX" | "TYPE_UNIVERSITY_GROUNDS" | "TYPE_DEPRECATED_TARMAC" | "TYPE_ENCLOSED_TRAFFIC_AREA" | "TYPE_PARKING_LOT" | "TYPE_PARKING_GARAGE" | "TYPE_OFF_ROAD_AREA" | "TYPE_BORDER" | "TYPE_BUILDING" | "TYPE_GEOCODED_ADDRESS" | "TYPE_NATURAL_FEATURE" | "TYPE_TERRAIN" | "TYPE_SAND" | "TYPE_BEACH" | "TYPE_DUNE" | "TYPE_ROCKY" | "TYPE_ICE" | "TYPE_GLACIER" | "TYPE_BUILT_UP_AREA" | "TYPE_VEGETATION" | "TYPE_SHRUBBERY" | "TYPE_WOODS" | "TYPE_AGRICULTURAL" | "TYPE_GRASSLAND" | "TYPE_TUNDRA" | "TYPE_DESERT" | "TYPE_SALT_FLAT" | "TYPE_WATER" | "TYPE_OCEAN" | "TYPE_BAY" | "TYPE_BIGHT" | "TYPE_LAGOON" | "TYPE_SEA" | "TYPE_STRAIT" | "TYPE_INLET" | "TYPE_FJORD" | "TYPE_LAKE" | "TYPE_SEASONAL_LAKE" | "TYPE_RESERVOIR" | "TYPE_POND" | "TYPE_RIVER" | "TYPE_RAPIDS" | "TYPE_DISTRIBUTARY" | "TYPE_CONFLUENCE" | "TYPE_WATERFALL" | "TYPE_SPRING" | "TYPE_GEYSER" | "TYPE_HOT_SPRING" | "TYPE_SEASONAL_RIVER" | "TYPE_WADI" | "TYPE_ESTUARY" | "TYPE_WETLAND" | "TYPE_WATER_NAVIGATION" | "TYPE_FORD" | "TYPE_CANAL" | "TYPE_HARBOR" | "TYPE_CHANNEL" | "TYPE_REEF" | "TYPE_REEF_FLAT" | "TYPE_REEF_GROWTH" | "TYPE_REEF_EXTENT" | "TYPE_REEF_ROCK_SUBMERGED" | "TYPE_IRRIGATION" | "TYPE_DAM" | "TYPE_DRINKING_WATER" | "TYPE_CURRENT" | "TYPE_WATERING_HOLE" | "TYPE_TECTONIC" | "TYPE_WATERING_HOLE_DEPRECATED" | "TYPE_VOLCANO" | "TYPE_LAVA_FIELD" | "TYPE_FISSURE" | "TYPE_FAULT" | "TYPE_LAND_MASS" | "TYPE_CONTINENT" | "TYPE_ISLAND" | "TYPE_ATOLL" | "TYPE_OCEAN_ROCK_EXPOSED" | "TYPE_CAY" | "TYPE_PENINSULA" | "TYPE_ISTHMUS" | "TYPE_ELEVATED" | "TYPE_PEAK" | "TYPE_NUNATAK" | "TYPE_SPUR" | "TYPE_PASS" | "TYPE_PLATEAU" | "TYPE_RIDGE" | "TYPE_RAVINE" | "TYPE_CRATER" | "TYPE_KARST" | "TYPE_CLIFF" | "TYPE_VISTA" | "TYPE_DIGITAL_ELEVATION_MODEL" | "TYPE_UPLAND" | "TYPE_TERRACE" | "TYPE_SLOPE" | "TYPE_CONTOUR_LINE" | "TYPE_PAN" | "TYPE_UNSTABLE_HILLSIDE" | "TYPE_MOUNTAIN_RANGE" | "TYPE_UNDERSEA" | "TYPE_SUBMARINE_SEAMOUNT" | "TYPE_SUBMARINE_RIDGE" | "TYPE_SUBMARINE_GAP" | "TYPE_SUBMARINE_PLATEAU" | "TYPE_SUBMARINE_DEEP" | "TYPE_SUBMARINE_VALLEY" | "TYPE_SUBMARINE_BASIN" | "TYPE_SUBMARINE_SLOPE" | "TYPE_SUBMARINE_CLIFF" | "TYPE_SUBMARINE_PLAIN" | "TYPE_SUBMARINE_FRACTURE_ZONE" | "TYPE_CAVE" | "TYPE_ROCK" | "TYPE_ARCHIPELAGO" | "TYPE_POSTAL" | "TYPE_POSTAL_CODE" | "TYPE_POSTAL_CODE_PREFIX" | "TYPE_PREMISE" | "TYPE_SUB_PREMISE" | "TYPE_SUITE" | "TYPE_POST_TOWN" | "TYPE_POSTAL_ROUND" | "TYPE_META_FEATURE" | "TYPE_DATA_SOURCE" | "TYPE_LOCALE" | "TYPE_TIMEZONE" | "TYPE_BUSINESS_CHAIN" | "TYPE_PHONE_NUMBER_PREFIX" | "TYPE_PHONE_NUMBER_AREA_CODE" | "TYPE_BUSINESS_CORRIDOR" | "TYPE_ADDRESS_TEMPLATE" | "TYPE_TRANSIT_AGENCY" | "TYPE_FUTURE_GEOMETRY" | "TYPE_EVENT" | "TYPE_EARTHQUAKE" | "TYPE_HURRICANE" | "TYPE_WEATHER_CONDITION" | "TYPE_TRANSIENT" | "TYPE_ENTRANCE" | "TYPE_CARTOGRAPHIC" | "TYPE_HIGH_TENSION" | "TYPE_SKI_TRAIL" | "TYPE_SKI_LIFT" | "TYPE_SKI_BOUNDARY" | "TYPE_WATERSHED_BOUNDARY" | "TYPE_TARMAC" | "TYPE_WALL" | "TYPE_PICNIC_AREA" | "TYPE_PLAY_GROUND" | "TYPE_TRAIL_HEAD" | "TYPE_GOLF_TEEING_GROUND" | "TYPE_GOLF_PUTTING_GREEN" | "TYPE_GOLF_ROUGH" | "TYPE_GOLF_SAND_BUNKER" | "TYPE_GOLF_FAIRWAY" | "TYPE_GOLF_HOLE" | "TYPE_DEPRECATED_GOLF_SHOP" | "TYPE_CAMPING_SITE" | "TYPE_DESIGNATED_BARBECUE_PIT" | "TYPE_DESIGNATED_COOKING_AREA" | "TYPE_CAMPFIRE_PIT" | "TYPE_WATER_FOUNTAIN" | "TYPE_LITTER_RECEPTACLE" | "TYPE_LOCKER_AREA" | "TYPE_ANIMAL_ENCLOSURE" | "TYPE_CARTOGRAPHIC_LINE" | "TYPE_ESTABLISHMENT" | "TYPE_ESTABLISHMENT_GROUNDS" | "TYPE_ESTABLISHMENT_BUILDING" | "TYPE_ESTABLISHMENT_POI" | "TYPE_ESTABLISHMENT_SERVICE" | "TYPE_CELESTIAL" | "TYPE_ROAD_MONITOR" | "TYPE_PUBLIC_SPACES_AND_MONUMENTS" | "TYPE_STATUE" | "TYPE_TOWN_SQUARE" | "TYPE_LEVEL" | "TYPE_COMPOUND" | "TYPE_COMPOUND_GROUNDS" | "TYPE_COMPOUND_BUILDING" | "TYPE_COMPOUND_SECTION" | "TYPE_TERMINAL_POINT" | "TYPE_REGULATED_AREA" | "TYPE_LOGICAL_BORDER" | "TYPE_DO_NOT_USE_RESERVED_TO_CATCH_GENERATED_FILES" | "TYPE_UNKNOWN";
  /**
   * One-line geocoded address that this lat/lng represents at the time this
   * alias was created by the user.
   */
  formattedAddress?: string;
  /**
   * Free-text alias if alias type is NICKNAME. Otherwise unset. Limited to 40
   * characters.
   */
  nickname?: string;
  /**
   * lat/lng the icon is to be shown at.
   */
  point?: GeostorePointProto;
  /**
   * The id of the sticker asset chosen by the user to replace the default
   * asset for the alias.
   */
  stickerId?: number;
  /**
   * If the feature associated with the alias has synthetic_geometry.
   */
  syntheticFeature?: boolean;
  /**
   * [INTERNAL ONLY] Last update of bigtable by kansas, in microseconds.
   * Volatile only and not saved in kansas column. inmemory only because >= 16.
   */
  timestamp?: bigint;
}

function serializePersonalizationMapsAliasIcon(data: any): PersonalizationMapsAliasIcon {
  return {
    ...data,
    aliasId: data["aliasId"] !== undefined ? serializePersonalizationMapsAliasAliasId(data["aliasId"]) : undefined,
    droppedPinS2cellId: data["droppedPinS2cellId"] !== undefined ? String(data["droppedPinS2cellId"]) : undefined,
    featureId: data["featureId"] !== undefined ? serializeGeostoreFeatureIdProto(data["featureId"]) : undefined,
    timestamp: data["timestamp"] !== undefined ? String(data["timestamp"]) : undefined,
  };
}

function deserializePersonalizationMapsAliasIcon(data: any): PersonalizationMapsAliasIcon {
  return {
    ...data,
    aliasId: data["aliasId"] !== undefined ? deserializePersonalizationMapsAliasAliasId(data["aliasId"]) : undefined,
    droppedPinS2cellId: data["droppedPinS2cellId"] !== undefined ? BigInt(data["droppedPinS2cellId"]) : undefined,
    featureId: data["featureId"] !== undefined ? deserializeGeostoreFeatureIdProto(data["featureId"]) : undefined,
    timestamp: data["timestamp"] !== undefined ? BigInt(data["timestamp"]) : undefined,
  };
}

/**
 * Metadata related to LocalDiscoverySettings,e.g., dietary_restriction,
 * cuisine and ingredient.
 */
export interface PersonalizationSettingsApiProtoLocalDiscoveryLocalDiscoverySettingsMetadata {
  /**
   * Contexts regarding the preferences from OPA_RECIPES.
   */
  opaRecipesContext?: PersonalizationSettingsApiProtoLocalDiscoveryOpaRecipesContext;
  /**
   * The UI entry point from which the entity preference was set.
   */
  uiEntryPoint?:  | "UNKNOWN_ENTRY_POINT" | "GEO_DISCOVERY" | "OPA_SETTINGS" | "OPA_RECIPES" | "OPA_RESTAURANTS";
}

/**
 * LINT.IfChange Contexts regarding the preferences from OPA_RECIPES. For
 * example, users can click a recipes and say they don't like one cuisine.
 * OpaRecipesContext will contain the doc_id/url of that recipes.
 */
export interface PersonalizationSettingsApiProtoLocalDiscoveryOpaRecipesContext {
  /**
   * The recipe doc id where the setting comes from.
   */
  docId?: string;
  /**
   * The recipe url where the setting comes from.
   */
  url?: string;
}

export interface PhilPerDocData {
  /**
   * phil data , approx 70 bytes for top 500M
   */
  PhilString?: string;
  PhilVersion?: number;
}

export interface PhotosAnimationMetadata {
  /**
   * The duration of the animation or movie (not including any looping), in
   * milliseconds. If there is only a single frame (and thus not animated), the
   * duration will be 0.
   */
  durationMs?: bigint;
  /**
   * The number of times the animation plays. If 0, the animation will loop
   * indefinitely. If positive, this number includes the initial playthrough.
   * For example, a value of 3 means that each frame is shown 3 times.
   */
  loopCount?: number;
  numFrames?: bigint;
}

function serializePhotosAnimationMetadata(data: any): PhotosAnimationMetadata {
  return {
    ...data,
    durationMs: data["durationMs"] !== undefined ? String(data["durationMs"]) : undefined,
    numFrames: data["numFrames"] !== undefined ? String(data["numFrames"]) : undefined,
  };
}

function deserializePhotosAnimationMetadata(data: any): PhotosAnimationMetadata {
  return {
    ...data,
    durationMs: data["durationMs"] !== undefined ? BigInt(data["durationMs"]) : undefined,
    numFrames: data["numFrames"] !== undefined ? BigInt(data["numFrames"]) : undefined,
  };
}

/**
 * Metadata pertaining to nested Dynamic Depth metadata. Currently this message
 * is used to indicate the presence of dynamic depth.
 */
export interface PhotosDynamicDepthMetadata {
}

export interface PhotosFourCMetadata {
  caption?: string;
  copyright?: string;
  creator?: string[];
  credit?: string;
}

/**
 * Metadata in the GDepth XMP block. Note that GDepth::Data is not copied into
 * this message.
 */
export interface PhotosGDepthMetadata {
  /**
   * Depth map far plane distance.
   */
  far?: number;
  /**
   * Depth map format.
   */
  format?: string;
  /**
   * Depth map source image height.
   */
  imageHeight?: number;
  /**
   * Depth map source image width.
   */
  imageWidth?: number;
  /**
   * Depth map mime type.
   */
  mime?: string;
  /**
   * Depth map near plane distance.
   */
  near?: number;
  /**
   * Depth map units of distance.
   */
  units?: string;
}

/**
 * Next tag value: 381.
 */
export interface PhotosImageMetadata {
  actionadvised?: string;
  addlmodelinfo?: string;
  advisory?: string[];
  altitude?: number;
  animationMetadata?: PhotosAnimationMetadata;
  aperturefnumber?: number;
  aperturevalue?: number;
  artworkorobject?: string[];
  audioduration?: string;
  audiooutcue?: string;
  audiosamplingrate?: string;
  audiosamplingresolution?: string;
  audiotype?: string;
  author?: string;
  authorposition?: string;
  /**
   * Indicates whether auto-enhance has been applied to the image.
   */
  autoenhance?: boolean;
  baseurl?: string;
  /**
   * The number of bits per pixel used to express a color. Most images have
   * 8-bit depth and Photos/thumbnailer currently do not support more than 8
   * bits (except RAW).
   */
  bitDepth?: number;
  /**
   * Start of reflected fields. These do not duplicate the above fields.
   */
  bitspersample?: number;
  brightnessvalue?: number;
  burstuuid?: string;
  cameraid?: string;
  /**
   * Exif camera make
   */
  cameramake?: string;
  /**
   * Exif camera model
   */
  cameramodel?: string;
  /**
   * Caption embedded in IPTC
   */
  caption?: string;
  captionwriter?: string;
  capturesoftware?: string;
  category?: string;
  ccdwidth?: number;
  celllength?: number;
  cellwidth?: number;
  certificate?: string;
  /**
   * A typed representation that translates the values from ycbcrsubsampling.
   */
  chromasubsampling?:  | "UNKNOWN_CHROMA_SUBSAMPLING" | "YCBCR410" | "YCBCR411" | "YCBCR420" | "YCBCR422" | "YCBCR444";
  ciadrcity?: string;
  ciadrctry?: string;
  ciadrextadr?: string[];
  ciadrpcode?: string;
  ciadrregion?: string;
  ciemailwork?: string;
  citelwork?: string;
  city?: string;
  ciurlwork?: string;
  colormap?: number;
  /**
   * Indicates whether or not the source image had an embedded color profile.
   */
  colorprofile?: boolean;
  colorspace?: number;
  compressedbitsperpixel?: number;
  compressionlevel?: number;
  contact?: string;
  contentlocationcode?: string[];
  contentlocationname?: string[];
  contrast?: number;
  contributor?: string[];
  copyrightnotice?: string;
  country?: string;
  countrycode?: string;
  coverage?: string;
  createdate?: string;
  credits?: string;
  croppedareaimageheightpixels?: number;
  croppedareaimagewidthpixels?: number;
  croppedarealeftpixels?: number;
  croppedareatoppixels?: number;
  customrendered?: number;
  cvterm?: string[];
  date?: string;
  datecreated?: string;
  datesent?: string;
  datetime?: string;
  datetimedigitized?: string;
  /**
   * 0 = no daylight savings, 1 = daylight savings enabled. Note that this
   * field only represents whether the setting in the camera was turned on or
   * off. It must not be used to modify the timestamp of the photo. That is, the
   * capture time is already completely determined by exif_time, timezoneoffset
   * and timezoneminutes.
   */
  daylightsavings?: number[];
  DEPRECATEDBlendingtype?: string;
  /**
   * This field was originally marked incorrectly as optional (rather than
   * repeated). In order to fix it, the first field has been marked as
   * deprecated and replaced with a field with a new name and tag number.
   */
  DEPRECATEDGpstimestamp?: number;
  DEPRECATEDIscolor?: number;
  DEPRECATEDLargestvalidinteriorrectheight?: number;
  DEPRECATEDLargestvalidinteriorrectleft?: number;
  DEPRECATEDLargestvalidinteriorrecttop?: number;
  DEPRECATEDLargestvalidinteriorrectwidth?: number;
  DEPRECATEDProcess?: number;
  destination?: string[];
  /**
   * +/- 90 inclusive
   */
  destinationLatitude?: number;
  /**
   * +/- 180 inclusive
   */
  destinationLongitude?: number;
  digimageguid?: string;
  digitalsourcefiletype?: string;
  digitalsourcetype?: string;
  digitalzoomratio?: number;
  distance?: number;
  /**
   * DynamicDepth (go/dynamic-depth) metadata is described in the metadata of
   * sub-images in the container. The presence of this field can be used to
   * determine that an image is in the dynamic depth format.
   */
  dynamicDepthMetadata?: PhotosDynamicDepthMetadata;
  editorialupdate?: string;
  editstatus?: string;
  envelopenumber?: string;
  envelopepriority?: string;
  event?: string;
  /**
   * 4C metadata (caption, copyright, creator, credit) specific to each of the
   * three metadata segments (EXIF, XMP, IPTC). These are used to keep separate
   * the 4C data from each segment so that we can properly preserve the
   * per-segment 4C data on write (when PreserveLevel is set appropriately).
   */
  exif4c?: PhotosFourCMetadata;
  /**
   * Timestamp embedded in the image. The value comes from the first valid
   * date-time field extracted from the metadata in the order: 1) datecreated
   * (ie. DateTimeOriginal) 2) datetimedigitized (ie. DateTimeDigitized) 3)
   * datetime (ie. DateTime or last modified date) The type of this field is
   * equivalent to a time_t (ie. number of seconds since the epoch - 00:00
   * hours, Jan 1, 1970) except that it is an int64 rather than an int.
   */
  exifTime?: bigint;
  /**
   * The exif_time_utc field is a UTC-based alternative to the exif_time field,
   * which is in local time, rather than UTC. If they were not separate, clients
   * would be unable to distinguish if the source were UTC- or local-based.
   */
  exifTimeUtc?: bigint;
  /**
   * The exif_time_utc_source indicates the source from which the exif_time_utc
   * field is calculated.
   */
  exifTimeUtcSource?:  | "EXIF_TIME_SOURCE_UNKNOWN" | "GPS_DATE_TIME_STAMP";
  expirationdate?: string;
  expirationtime?: string;
  exposurebias?: number;
  exposureindex?: number;
  exposurelockused?: boolean;
  exposuremode?: number;
  exposureprogram?: number;
  exposuretime?: number;
  extrasamples?: number;
  fillorder?: number;
  firmware?: string;
  firstphotodate?: string;
  fixtureidentifier?: string;
  flashcompensation?: number;
  flashenergy?: number;
  flashreturn?: number;
  flashused?: number;
  focallength?: number;
  focallengthin35mmfilm?: number;
  focalplaneunits?: number;
  focalplanexres?: number;
  format?: string;
  freebytecounts?: bigint;
  freeoffsets?: number;
  fullpanoheightpixels?: number;
  fullpanowidthpixels?: number;
  function?: boolean;
  gaincontrol?: number;
  gaudiomime?: string;
  /**
   * A unique String. The property should be present and identical for all
   * images that make up a burst. It should be unique across devices (UUID
   * recommended). Unlike GCreations:CameraBurstId, we should use images with
   * this property to create auto collages and animations.
   */
  gcameraburstid?: string;
  /**
   * A value of 1 indicates that this was the primary (best shot) at capture
   * time. Within Photos we should only treat this image as the best shot if the
   * user hasnt made an explicit choice. Defining the initial primary allows
   * consistency between OEMs, Photos clients, and the Photos backend. This
   * value is optional, cameras are not required to set it on any photo in a
   * burst. Clients will default to the 0th frame, but may run an algorithm to
   * pick a better default.
   */
  gcameraburstprimary?: number;
  /**
   * The possible values are: Animation, Collage, Pano, Movies. Photos
   * will avoid creating the listed types using the containing image or video.
   * The property is optional. The property can be included multiple times to
   * disable creation of multiple different types.
   */
  gcameradisableautocreation?: string[];
  /**
   * The following XMP metadata are used specifically for MicroVideo. More
   * information about MicroVideo format can be found at
   * go/photos-microvideo-format A value of 1 indicates that this file was a
   * MicroVideo at capture time. Otherwise, this is not a MicroVideo (not set or
   * 0).
   */
  gcameramicrovideo?: number;
  /**
   * The offset in bytes from the end of the file to the point where the
   * appended mp4 begins (equivalent to the length of the compressed mp4). This
   * field might be provided in the original MicroVideo from client, but it
   * might become invalid when the image component is edited, so it is expected
   * that the thumbnailer will validate it and find the correct value (by
   * scanning through the JPEG) if it is invalid. In other words, only a valid
   * offset should be returned by thumbnailer.
   */
  gcameramicrovideooffset?: number;
  /**
   * The presentation timestamp in microseconds of the video frame
   * corresponding to the image still. Value may be -1 to denote
   * unset/unspecified.
   */
  gcameramicrovideopresentationtimestampus?: number;
  /**
   * Indicates the file format version of the MicroVideo (initially 1).
   */
  gcameramicrovideoversion?: number;
  /**
   * An indication that this item should be treated as a Motion Photo. 0 -> Not
   * Motion Photo, 1 -> Motion Photo, everything else is undefined per the spec.
   * If it's a motion photo, the previous gcamera fields should be ignored.
   */
  gcameramotionphoto?: number;
  /**
   * The presentation timestamp in microseconds of the video frame
   * corresponding to the image still. Value may be -1 to denote
   * unset/unspecified.
   */
  gcameramotionphotopresentationtimestampus?: number;
  /**
   * Indicates the Motion Photo version of the spec (initially 1).
   */
  gcameramotionphotoversion?: number;
  /**
   * Camera creations metadata. The opaque id string created by the OEM. For
   * bursts, this field should not be present. Instead, the two properties below
   * will allow Photos to identify and provide special treatment for bursts.
   */
  gcameraspecialtypeid?: string;
  gcreationscameraburstid?: string;
  /**
   * String representation of creation type. Should be one of
   * {"GCameraCollage", "GCameraAnimation", "GCameraGroupSmiles",
   * "GPhotosCollage", "GPhotosAnimation"}.
   */
  gcreationstype?: string;
  gdepthMetadata?: PhotosGDepthMetadata;
  gimagemime?: string;
  /**
   * This is in UTC time. Format is YYYY:mm:dd.
   */
  gpsdatestamp?: string;
  gpsdestbearing?: number;
  gpsdestbearingref?: string;
  gpsdestdistance?: number;
  gpsdestdistanceref?: string;
  gpsdestlatitude?: number;
  gpsdestlatituderef?: string;
  gpsdestlongitude?: number;
  gpsdestlongituderef?: string;
  gpsdifferential?: number;
  gpsdop?: number;
  gpsimgdirection?: number;
  gpsimgdirectionref?: string;
  gpsmapdatum?: string;
  gpsmeasuremode?: string;
  gpssatellites?: string;
  gpsspeed?: number;
  gpsspeedref?: string;
  gpsstatus?: string;
  /**
   * This is in UTC Time. Contains three floats: hour, minute and second.
   * Supports subsecond resolution.
   */
  gpstime?: number[];
  gpstrack?: number;
  gpstrackref?: string;
  grayresponsecurve?: number;
  grayresponseunit?: number;
  /**
   * The image has an alpha channel (potential transparency). If the image is
   * decoded, this will be updated to indicate whether there is any active
   * transparency. Formats supporting alpha: png, webp, gif, heif.
   */
  hasAlpha?: boolean;
  headline?: string;
  height?: number;
  hostcomputer?: string;
  identifier?: string[];
  imagenumber?: string;
  imageorientation?: string;
  imagetype?: string;
  initialhorizontalfovdegrees?: number;
  initialverticalfovdegrees?: number;
  initialviewheadingdegrees?: number;
  initialviewpitchdegrees?: number;
  initialviewrolldegrees?: number;
  instructions?: string;
  intellectualgenre?: string;
  interoperabilityindex?: string;
  iptc4c?: PhotosFourCMetadata;
  iptclastedited?: string;
  /**
   * The image is a Multi-Picture Object.
   */
  ismpformat?: boolean;
  isoequivalent?: number;
  keyword?: string[];
  label?: string;
  language?: string[];
  languageidentifier?: string;
  lastphotodate?: string;
  /**
   * GPS Info: +/- 90 inclusive
   */
  latitude?: number;
  lens?: string;
  lensid?: string;
  lensinfo?: string;
  lightsource?: number;
  location?: string;
  locationshown?: string[];
  /**
   * +/- 180 inclusive
   */
  longitude?: number;
  marked?: boolean;
  maxaperturevalue?: number;
  maxavailheight?: number;
  maxavailwidth?: number;
  maxsamplevalue?: number;
  metadatadate?: string;
  meteringmode?: number;
  /**
   * This is similar to gcameramicrovideooffset, except it stores the
   * unverified value that was provided in the motion photo file. This field is
   * not part of the XMP or spec. It is used to ensure we preserve data from the
   * original file when offset is modified.
   */
  microvideooriginaloffset?: number;
  /**
   * Mime type of image
   */
  mimeType?: number;
  minormodelagedisclosure?: string;
  minsamplevalue?: number;
  mode?: number;
  modelage?: number[];
  modelreleaseid?: string[];
  modelreleasestatus?: string;
  modifydate?: string;
  /**
   * The Motion Photo Video Data (MPVD) box header of a HEIF motion photo. It
   * is used for reconstructing the original moton photo bytes. See
   * go/photos-be-heic-motion-photos for more details.
   */
  motionphotovideodataboxheader?: Uint8Array;
  nickname?: string;
  objectattributereference?: string[];
  objectcycle?: string;
  objecttypereference?: string;
  offsettime?: string;
  offsettimedigitized?: string;
  offsettimeoriginal?: string;
  organisationinimagecode?: string[];
  organisationinimagename?: string[];
  /**
   * Exif camera orientation. "1" means "no rotation".
   */
  orientation?: number;
  originatingprogram?: string;
  owner?: string[];
  ownername?: string;
  panoramaMetadata?: PhotosPanoramaMetadata;
  personinimage?: string[];
  photometricinterpretation?: number;
  planarconfiguration?: number;
  poseheadingdegrees?: number;
  posepitchdegrees?: number;
  poserolldegrees?: number;
  primarychromaticities?: number;
  productid?: string[];
  programversion?: string;
  projectiontype?: string;
  propertyreleaseid?: string[];
  propertyreleasestatus?: string;
  publisher?: string[];
  rating?: number;
  redeyemode?: boolean;
  referenceblackwhite?: number;
  referencedate?: string[];
  referencenumber?: string[];
  referenceservice?: string[];
  relatedimagefileformat?: string;
  relatedimageheight?: bigint;
  relatedimagewidth?: bigint;
  relatedsoundfile?: string;
  relation?: string[];
  releasedate?: string;
  releasetime?: string;
  resolutionunit?: number;
  /**
   * being returned to caller Use values defined in "MIME_TYPE" This field is
   * deprecated. Rotation is now accomplished via ImageInfo.exif_orientation and
   * ImageInfo.edit_list. Number of degrees (0, 90, 180,
   */
  rotate?: number;
  rowsperstrip?: bigint;
  samplesperpixel?: number;
  saturation?: number;
  scene?: string[];
  scenecapturetype?: number;
  sensingmethod?: number;
  sensorheight?: number;
  sensorwidth?: number;
  serialnumber?: string;
  serviceidentifier?: string;
  sharpness?: number;
  shutterspeedvalue?: number;
  software?: string;
  source?: string;
  sourcephotoscount?: number;
  spectralsensitivity?: string;
  state?: string;
  stitchingsoftware?: string;
  stripbytecounts?: bigint;
  stripoffsets?: bigint;
  subjectarea?: number;
  subjectcode?: string[];
  subjectdistancerange?: number;
  subjectlocation?: number;
  subjectreference?: string[];
  sublocation?: string;
  subsectime?: string;
  subsectimedigitized?: string;
  subsectimeoriginal?: string;
  supplementalcategory?: string[];
  thresholding?: number;
  /**
   * The build CL for the version of thumbnailer that built this image.
   */
  thumbnailerBuildCl?: number;
  timesent?: string;
  /**
   * Remaining minutes of offset.
   */
  timezoneminutes?: number[];
  /**
   * The elements in the timezone and daylight savings field arrays correspond
   * to the following date/time fields: 0) datecreated (ie. DateTimeOriginal) 1)
   * datetime (ie. DateTime or last modified date) 2) datetimedigitized (ie.
   * DateTimeDigitized) If the field does not exist, then there is no valid time
   * zone information for that date/time field. Offset in hours.
   */
  timezoneoffset?: number[];
  title?: string;
  transmissionreference?: string;
  type?: string[];
  /**
   * For unique hash:
   */
  uniqueid?: string;
  uno?: string;
  urgency?: string;
  url?: string;
  usageterms?: string;
  /**
   * GPano-related fields. A handful of these have been deprecated due to a
   * change in the spec since its initial design.
   */
  usepanoramaviewer?: boolean;
  version?: string;
  webstatement?: string;
  whitebalance?: number;
  whitepoint?: number;
  /**
   * width and height are before any rotation (including EXIF orientation).
   */
  width?: number;
  xmp4c?: PhotosFourCMetadata;
  xresolution?: number;
  ycbcrcoefficients?: number;
  ycbcrpositioning?: number;
  ycbcrsubsampling?: number;
  yresolution?: number;
}

function serializePhotosImageMetadata(data: any): PhotosImageMetadata {
  return {
    ...data,
    animationMetadata: data["animationMetadata"] !== undefined ? serializePhotosAnimationMetadata(data["animationMetadata"]) : undefined,
    exifTime: data["exifTime"] !== undefined ? String(data["exifTime"]) : undefined,
    exifTimeUtc: data["exifTimeUtc"] !== undefined ? String(data["exifTimeUtc"]) : undefined,
    freebytecounts: data["freebytecounts"] !== undefined ? String(data["freebytecounts"]) : undefined,
    motionphotovideodataboxheader: data["motionphotovideodataboxheader"] !== undefined ? encodeBase64(data["motionphotovideodataboxheader"]) : undefined,
    relatedimageheight: data["relatedimageheight"] !== undefined ? String(data["relatedimageheight"]) : undefined,
    relatedimagewidth: data["relatedimagewidth"] !== undefined ? String(data["relatedimagewidth"]) : undefined,
    rowsperstrip: data["rowsperstrip"] !== undefined ? String(data["rowsperstrip"]) : undefined,
    stripbytecounts: data["stripbytecounts"] !== undefined ? String(data["stripbytecounts"]) : undefined,
    stripoffsets: data["stripoffsets"] !== undefined ? String(data["stripoffsets"]) : undefined,
  };
}

function deserializePhotosImageMetadata(data: any): PhotosImageMetadata {
  return {
    ...data,
    animationMetadata: data["animationMetadata"] !== undefined ? deserializePhotosAnimationMetadata(data["animationMetadata"]) : undefined,
    exifTime: data["exifTime"] !== undefined ? BigInt(data["exifTime"]) : undefined,
    exifTimeUtc: data["exifTimeUtc"] !== undefined ? BigInt(data["exifTimeUtc"]) : undefined,
    freebytecounts: data["freebytecounts"] !== undefined ? BigInt(data["freebytecounts"]) : undefined,
    motionphotovideodataboxheader: data["motionphotovideodataboxheader"] !== undefined ? decodeBase64(data["motionphotovideodataboxheader"] as string) : undefined,
    relatedimageheight: data["relatedimageheight"] !== undefined ? BigInt(data["relatedimageheight"]) : undefined,
    relatedimagewidth: data["relatedimagewidth"] !== undefined ? BigInt(data["relatedimagewidth"]) : undefined,
    rowsperstrip: data["rowsperstrip"] !== undefined ? BigInt(data["rowsperstrip"]) : undefined,
    stripbytecounts: data["stripbytecounts"] !== undefined ? BigInt(data["stripbytecounts"]) : undefined,
    stripoffsets: data["stripoffsets"] !== undefined ? BigInt(data["stripoffsets"]) : undefined,
  };
}

export interface PhotosPanoramaMetadata {
  sphericalPanorama?: boolean;
  /**
   * True if the image is a VR180 image. See go/3d180 for details.
   */
  vr180Panorama?: boolean;
}

/**
 * Bounding box coordinates are relative to the width and height of the image.
 * For example, if image is 100x200 and NormalizedBoundingBox is , the bounding
 * box coordinates will be (10, 40) to (50, 180). Note parts of the bounding box
 * may fall outside the image.
 */
export interface PhotosVisionGroundtruthdbNormalizedBoundingBox {
  xmax?: number;
  xmin?: number;
  ymax?: number;
  ymin?: number;
}

export interface PhotosVisionObjectrecFeatureVector {
  /**
   * For single precision floating point data
   */
  floatData?: number[];
}

/**
 * The geo-location of a single point, or of the "center" of a group of points.
 */
export interface PhotosVisionObjectrecGeoLocation {
  /**
   * Altitude of the point above the earth's surface, in meters.
   */
  altitudeMeters?: number;
  /**
   * Country code string.
   */
  countryCode?: string;
  /**
   * Indicates if the lat/lon above is assumed to come from a GPS device.
   */
  fromGps?: boolean;
  /**
   * Latitude in degrees north. Values south of the equator are negative.
   */
  lat?: number;
  /**
   * When applied to a single point, represents the estimated error bounds of
   * manual geotagging. The estimate is based on size of the bounding box of the
   * map used for manual geotagging. When applied to a group of points, the
   * error bounds represent the dispersion around the group center (lat/lon
   * above). The dispersion in this case is computed as half the interquartile
   * range. Reference: http://en.wikipedia.org/wiki/Interquartile_range (lat +/-
   * lat_error_bound, lng +/- lng_error_bound).
   */
  latErrorBound?: number;
  /**
   * Longitude in degrees east. Values west of 0 deg are negative.
   */
  lon?: number;
  lonErrorBound?: number;
}

/**
 * Global feature for the image.
 */
export interface PhotosVisionObjectrecGlobalFeature {
  /**
   * Optional info provided by the feature extractor.
   */
  additionalInfo?: Uint8Array;
  featureVector?: PhotosVisionObjectrecFeatureVector;
  quantizedFeatureVector?: PhotosVisionObjectrecQuantizedFeatureVector;
  /**
   * Tag for this global feature. E.g., "DELG", "SBv4" or "DELG_region1".
   */
  tag?: string;
  version?: string;
}

function serializePhotosVisionObjectrecGlobalFeature(data: any): PhotosVisionObjectrecGlobalFeature {
  return {
    ...data,
    additionalInfo: data["additionalInfo"] !== undefined ? encodeBase64(data["additionalInfo"]) : undefined,
    quantizedFeatureVector: data["quantizedFeatureVector"] !== undefined ? serializePhotosVisionObjectrecQuantizedFeatureVector(data["quantizedFeatureVector"]) : undefined,
  };
}

function deserializePhotosVisionObjectrecGlobalFeature(data: any): PhotosVisionObjectrecGlobalFeature {
  return {
    ...data,
    additionalInfo: data["additionalInfo"] !== undefined ? decodeBase64(data["additionalInfo"] as string) : undefined,
    quantizedFeatureVector: data["quantizedFeatureVector"] !== undefined ? deserializePhotosVisionObjectrecQuantizedFeatureVector(data["quantizedFeatureVector"]) : undefined,
  };
}

/**
 * ImageTemplate contains local and/or global features generated from one
 * image. User-defined members can be set to any value within the constraints
 * outlined below. Algorithms usually pass these through without evaluation,
 * unless documented otherwise. Next id: 29
 */
export interface PhotosVisionObjectrecImageTemplate {
  /**
   * Name of the author or image source. User-defined. Must be NULL-terminated.
   */
  authorName?: string;
  /**
   * Identifier for which corpus the image belongs to. Currently Cyclone uses
   * this field in: -
   * photos_vision_objectrec.SpatialMatcherRequest.residual_template to select
   * which spatial matcher should be applied to the candidate matches -
   * photos_vision_objectrec.CustomCorpusQuantizer to map a custom corpus to one
   * or more posting lists
   */
  corpus?: string;
  /**
   * The geolocation of the image. Assumed to represent the location where the
   * photo was taken from.
   */
  geoLocation?: PhotosVisionObjectrecGeoLocation;
  globalFeature?: PhotosVisionObjectrecGlobalFeature[];
  imageHeight?: number;
  /**
   * Unique identifier for the image used to compute this template.
   */
  imageId?: bigint;
  /**
   * URL or filename of the image used to compute this template. User-defined.
   * Must contain only ASCII characters and be NULL-terminated.
   */
  imageUrl?: string;
  /**
   * Dimension of the image used to compute this template.
   */
  imageWidth?: number;
  info?: Uint8Array;
  /**
   * Tags pertaining to this image. User-defined. Must be NULL-terminated.
   */
  objectInfo?: string[];
  /**
   * Name of the object/scene depicted. User-defined. Must contain only ASCII
   * characters and be NULL-terminated.
   */
  objectName?: string;
  /**
   * Opaque template data. May be used to pass through additional data from
   * template sources to processing modules, that is not already covered by
   * other members of this PB. It is the responsibility of processing modules to
   * verify that the data is in a compatible format.
   */
  opaqueData?: Uint8Array;
  /**
   * Region-of-interest: The bounding box of the object or scene depicted in
   * the image.
   */
  roi?: PhotosVisionObjectrecROI;
  subset?: PhotosVisionObjectrecImageTemplateSubSet[];
  /**
   * Feature version.
   */
  version?: string;
}

function serializePhotosVisionObjectrecImageTemplate(data: any): PhotosVisionObjectrecImageTemplate {
  return {
    ...data,
    globalFeature: data["globalFeature"] !== undefined ? data["globalFeature"].map((item: any) => (serializePhotosVisionObjectrecGlobalFeature(item))) : undefined,
    imageId: data["imageId"] !== undefined ? String(data["imageId"]) : undefined,
    info: data["info"] !== undefined ? encodeBase64(data["info"]) : undefined,
    opaqueData: data["opaqueData"] !== undefined ? encodeBase64(data["opaqueData"]) : undefined,
    subset: data["subset"] !== undefined ? data["subset"].map((item: any) => (serializePhotosVisionObjectrecImageTemplateSubSet(item))) : undefined,
  };
}

function deserializePhotosVisionObjectrecImageTemplate(data: any): PhotosVisionObjectrecImageTemplate {
  return {
    ...data,
    globalFeature: data["globalFeature"] !== undefined ? data["globalFeature"].map((item: any) => (deserializePhotosVisionObjectrecGlobalFeature(item))) : undefined,
    imageId: data["imageId"] !== undefined ? BigInt(data["imageId"]) : undefined,
    info: data["info"] !== undefined ? decodeBase64(data["info"] as string) : undefined,
    opaqueData: data["opaqueData"] !== undefined ? decodeBase64(data["opaqueData"] as string) : undefined,
    subset: data["subset"] !== undefined ? data["subset"].map((item: any) => (deserializePhotosVisionObjectrecImageTemplateSubSet(item))) : undefined,
  };
}

/**
 * Each SubSet contains LocalDescriptors of a specific type. The type indicates
 * which algorithm has been used to generate the descriptors. No enum is defined
 * for the descriptor_type. For most applications it is sufficient to know if
 * two descriptors are of the same or a different type, while ignoring the
 * details of their generation. The descriptor type '0' is reserved and must not
 * be used.
 */
export interface PhotosVisionObjectrecImageTemplateSubSet {
  descriptor?: PhotosVisionObjectrecLocalDescriptor[];
  descriptorType?: number;
  /**
   * Used to indicate if the descriptor is binary or not. When decompressing
   * feature this is useful to decide calling different decompression functions.
   */
  isBinaryDescriptor?: boolean;
  /**
   * Used to store the number of descriptors for statistical purposes, if the
   * descriptors themselves are not stored.
   */
  numDescriptors?: number;
}

function serializePhotosVisionObjectrecImageTemplateSubSet(data: any): PhotosVisionObjectrecImageTemplateSubSet {
  return {
    ...data,
    descriptor: data["descriptor"] !== undefined ? data["descriptor"].map((item: any) => (serializePhotosVisionObjectrecLocalDescriptor(item))) : undefined,
  };
}

function deserializePhotosVisionObjectrecImageTemplateSubSet(data: any): PhotosVisionObjectrecImageTemplateSubSet {
  return {
    ...data,
    descriptor: data["descriptor"] !== undefined ? data["descriptor"].map((item: any) => (deserializePhotosVisionObjectrecLocalDescriptor(item))) : undefined,
  };
}

/**
 * LocalDescriptor holds interest point data and an optional local descriptor
 * vector.
 */
export interface PhotosVisionObjectrecLocalDescriptor {
  /**
   * Optional affine matrix. Supersedes scale and orientation if present. r' =
   * affine_matrix.r + (x,y) defines an affine transform from the normalized
   * image patch (in which the interest point is centered at the origin with
   * scale 1) to the image. If the affine matrix is set, the following
   * approximations are recommended: scale = sqrt(0.5 * (xx*xx + xy*xy + yx*yx +
   * yy*yy)); orientation = atan2(yx - xy, xx + yy); If not present, the affine
   * matrix can be computed from scale and orientation as: xx = scale *
   * cos(orientation); xy = scale * -sin(orientation); yx = scale *
   * sin(orientation); yy = scale * cos(orientation);
   */
  affineMatrix?: PhotosVisionObjectrecMatrix2D;
  data?: Uint8Array;
  /**
   * data_factor and data represent the local descriptor vector in a compressed
   * format, using only 8 bit per value. Each byte of the data string yields one
   * component of the local descriptor by bit-casting it to an int8 and
   * multiplying it by data_factor. Protocol buffers do not support int8
   * directly.
   */
  dataFactor?: number;
  /**
   * Unquantized feature vector (float).
   */
  featureVector?: PhotosVisionObjectrecFeatureVector;
  /**
   * Opaque descriptor data. May be used to pass through descriptor data from
   * descriptor sources to processing modules, that is not already covered by
   * data/data_factor and/or cannot be expressed as a vector of numbers. It is
   * the responsibility of processing modules to verify that the data is in a
   * compatible format.
   */
  opaqueData?: Uint8Array;
  /**
   * Orientation is optional, as some interest point detectors don't compute
   * it. The range of orientation is [-pi,pi).
   */
  orientation?: number;
  /**
   * Each interest point must have a characteristic scale > 0.
   */
  scale?: number;
  /**
   * The strength or weight, indicating the relative significance of this
   * point.
   */
  strength?: number;
  /**
   * The position in the image with sub-pixel accuracy. The center of the upper
   * left pixel has coordinates (0.0, 0.0). Thus the range for x and y is (-0.5,
   * width - 0.5) x (-0.5, height - 0.5).
   */
  x?: number;
  y?: number;
}

function serializePhotosVisionObjectrecLocalDescriptor(data: any): PhotosVisionObjectrecLocalDescriptor {
  return {
    ...data,
    data: data["data"] !== undefined ? encodeBase64(data["data"]) : undefined,
    opaqueData: data["opaqueData"] !== undefined ? encodeBase64(data["opaqueData"]) : undefined,
  };
}

function deserializePhotosVisionObjectrecLocalDescriptor(data: any): PhotosVisionObjectrecLocalDescriptor {
  return {
    ...data,
    data: data["data"] !== undefined ? decodeBase64(data["data"] as string) : undefined,
    opaqueData: data["opaqueData"] !== undefined ? decodeBase64(data["opaqueData"] as string) : undefined,
  };
}

/**
 * A 2x2 float matrix.
 */
export interface PhotosVisionObjectrecMatrix2D {
  xx?: number;
  xy?: number;
  yx?: number;
  yy?: number;
}

/**
 * Quantized/compressed feature vector (8 bit per value). Can be decoded by
 * multiplying data_factor to each data byte.
 */
export interface PhotosVisionObjectrecQuantizedFeatureVector {
  data?: Uint8Array;
  dataFactor?: number;
}

function serializePhotosVisionObjectrecQuantizedFeatureVector(data: any): PhotosVisionObjectrecQuantizedFeatureVector {
  return {
    ...data,
    data: data["data"] !== undefined ? encodeBase64(data["data"]) : undefined,
  };
}

function deserializePhotosVisionObjectrecQuantizedFeatureVector(data: any): PhotosVisionObjectrecQuantizedFeatureVector {
  return {
    ...data,
    data: data["data"] !== undefined ? decodeBase64(data["data"] as string) : undefined,
  };
}

/**
 * A region of interest in the image.
 */
export interface PhotosVisionObjectrecROI {
  xMax?: number;
  xMin?: number;
  yMax?: number;
  yMin?: number;
}

/**
 * A protocol buffer to store the url, referer and porn flag for a url. and an
 * optional image score. Next available tag id: 51.
 */
export interface PornFlagData {
  /**
   * Aggregated brain_porn_scores for navboost co-clicked images. Historical:
   * this signal is deprecated and no longer populated as of 2020-12-01. Refer
   * to b/172897542 for more information.
   */
  coclickBrainScores?: ImageSafesearchContentBrainPornAnnotation;
  /**
   * Score predicting how likely an image is offensive or suggestive about CSAI
   * (child sexual abuse imagery).
   */
  csaiScore?: number;
  /**
   * DebugInfo stores debug information from the overall classifier. This
   * allows for instance to update counters related to blacklisting without
   * running the full classifier again.
   */
  debugInfo?: ImagePornDebugInfo[];
  /**
   * Final offensive score based on image salient terms and image OCR vulgar
   * and offensive scores.
   */
  finalOffensiveScore?: number;
  /**
   * Final violence score based on some image signals (brain pixel score,
   * co-clicked images violence score, navboost queries score, etc.).
   */
  finalViolenceScore?: number;
  /**
   * A string that indicates the version of SafeSearch classifier used to
   * compute final_violence_score.
   */
  finalViolenceScoreVersion?: string;
  /**
   * A proto that stores SafeSearch internal signals that are not exported to
   * clients. SafeSearch team does not provide any guarantees about the presence
   * or the semantics of these signals in the future.
   */
  internalSignals?: SafesearchInternalImageSignals;
  /**
   * number of faces
   */
  numberFaces?: number;
  /**
   * Information about image OCR text. For details see
   * image/safesearch/content/public/ocr_annotation.proto.
   */
  ocrAnnotation?: ImageSafesearchContentOCRAnnotation;
  /**
   * Vulgar score of the text found by OCR in the image.
   */
  ocrVulgarScore?: number;
  /**
   * QuimbyCongas-based detection of offensive symbols in the image (currently
   * swastika and Nazi yellow badge).
   */
  offensiveSymbolDetection?: ImageSafesearchContentOffensiveSymbolDetection;
  /**
   * Binary version of the PhotoDNA hash (144 bytes long). If not set
   * (has_photodna_hash() == false) it means that it was not computed, if empty
   * (has_photodna_hash() == true && photodna_hash() == "") it means that the
   * computation failed (cannot be computed for images smaller than 50 x 50).
   */
  photodnaHash?: Uint8Array;
  /**
   * This field is set to true when we are pretty confident that the image is
   * porn (with higher precision than the img_porn_moderate restrict). In
   * particular, it means that the image might be demoted for non-porn queries
   * when SafeSearch is Off.
   */
  pornWithHighConfidence?: boolean;
  /**
   * QBST-based image offensive score, Navboost based
   */
  qbstOffensiveScore?: number;
  /**
   * QBST-based image spoof score, Navboost based, unrelated to the pixel-based
   * score in PornAnnotation.
   */
  qbstSpoofScore?: number;
  /**
   * Query statistics from Navboost logs. For more details see
   * classifier/porn/proto/image_porn_classifier_signals.proto.
   */
  queryStats?: ClassifierPornQueryStats;
  /**
   * Aggregated navboost query violence score.
   */
  queryTextViolenceScore?: number;
  /**
   * url of the referer page
   */
  referer?: string;
  /**
   * Information about referrers and their porn classification. For details see
   * classifier/porn/proto/image_porn_classifier_signals.proto.
   */
  referrerCounts?: ClassifierPornReferrerCounts;
  /**
   * Starburst-based score predicting sexualization level of the image.
   */
  semanticSexualizationScore?: number;
  /**
   * url of the image
   */
  url?: string;
  /**
   * Information about the URL porn scores for image URLs associated with this
   * image.
   */
  urlPornScores?: ClassifierPornAggregatedUrlPornScores;
}

function serializePornFlagData(data: any): PornFlagData {
  return {
    ...data,
    photodnaHash: data["photodnaHash"] !== undefined ? encodeBase64(data["photodnaHash"]) : undefined,
  };
}

function deserializePornFlagData(data: any): PornFlagData {
  return {
    ...data,
    photodnaHash: data["photodnaHash"] !== undefined ? decodeBase64(data["photodnaHash"] as string) : undefined,
  };
}

/**
 * Next free ID: 32
 */
export interface PostalAddress {
  /**
   * These correspond to the "AddressLine" elements in xAL, which are used to
   * hold unstructured text. This is an addendum to the structured values; when
   * the address is formatted, the provided lines are prepended to the formatted
   * version of the street component fields for Western countries, and appended
   * for CJK countries. These lines are in display order. Formerly users of
   * PostalAddress were discouraged from mixing address_line with structured
   * address elements. Mixing is now encouraged if address_line has to be used
   * at all.
   */
  addressLine?: string[];
  /**
   * Top-level administrative subdivision of this country. Examples: US state,
   * IT region, UK constituent nation, JP prefecture.
   */
  administrativeAreaName?: string;
  /**
   * Name corresponding to country code. Optional. This can usually be inferred
   * from country_name_code.
   */
  countryName?: string;
  /**
   * xAL does not specify a scheme for country codes. We strongly recommend ISO
   * 3166-1-alpha-2 (two letter codes, as used in DNS) if you use this field.
   * (Use "GB", not "UK".)
   */
  countryNameCode?: string;
  /**
   * Dependent locality or sublocality. Used for UK dependent localities, or
   * neighborhoods or boroughs in other locations. If trying to represent a UK
   * double-dependent locality, include both the double-dependent locality and
   * the dependent locality in this field, e.g. "Whaley, Langwith".
   */
  dependentLocalityName?: string;
  /**
   * Dependent thoroughfares are used to define UK-style dependent
   * thoroughfares, and secondary streets in addresses in other locales,
   * including intersections. Formatting is locale-dependent.
   */
  dependentThoroughfareName?: string;
  /**
   * NEW: The firm or organization. This goes at a finer granularity than
   * address_lines in the address. Omit if not needed.
   */
  firmName?: string;
  /**
   * Required to support the suppression of country names from formatted
   * results for addresses within geo-politically disputed areas. Note that we
   * cannot achieve this by not setting the country, as this would prevent us
   * from selecting a suitable formatting template. Addresses converted from
   * Oyster, by the standard conversion libraries, will have this field set if
   * the address lies within a geo-politically disputed area (ie, contained
   * within features of type TYPE_DISPUTED_AREA) even if the disputed area
   * itself is not a visible part of the formatted address. An example of a
   * disputed area is "No Man's Land" near Jerusalem which has the flag
   * FLAG_NEVER_DISPLAY set for all its names. See: go/disputed-areas-2014 for
   * more information.
   */
  isDisputed?: boolean;
  /**
   * Language of the address. May affect address formatting for multi- lingual
   * countries. Also allows storing multilingual location names as repeated
   * PostalAddress. Not in xAL. Use language codes which are accepted by
   * i18n_identifiers::LanguageCodeCoverter::FromOther(). Examples include "en"
   * and "de-CH".
   */
  languageCode?: string;
  /**
   * Locality. This is something of a fuzzy term, but it generally refers to
   * the city/town portion of an address. In regions of the world where
   * localities are not well defined or do not fit into this structure well (for
   * example, Japan), leave locality_name empty and use address_line. Examples:
   * US city, IT comune, UK post town.
   */
  localityName?: string;
  /**
   * Despite the name, postal_code_number values are frequently alphanumeric.
   * Examples: "94043", "SW1W", "SW1W 9TQ".
   */
  postalCodeNumber?: string;
  /**
   * Used for postal-code suffixes, such as the 4-digit extension of a US ZIP+4
   * code.
   */
  postalCodeNumberExtension?: string;
  /**
   * This corresponds to PostBoxNumber in xAL format. In xAL format, it's
   * nested inside PostBox, which also contains a "Type" field to distinguish
   * between PO Box, Private Bag etc. Current support in this proto is for PO
   * Box only. Note that although this is modelled as a string, it should have
   * the number only, with any necessary punctuation (such as "-"). For example,
   * for "P.O. Box 123", this field would hold "123" - the template displaying
   * this would prepend P.O. Box when formatting if necessary.
   */
  postBoxNumber?: string;
  /**
   * The "premise" is something like a house or building.
   */
  premiseName?: string;
  /**
   * NEW: The recipient. This goes at a finer granularity than address_lines in
   * the address. Not present in xAL. Omit if not needed.
   */
  recipientName?: string;
  /**
   * This corresponds to the SortingCode sub-element of the xAL
   * PostalServiceElements element. Use is very country-specific. Where it is
   * used, the value is either a string like "CEDEX", optionally followed by a
   * number (e.g. "CEDEX 7"), or just a number alone, representing the "sector
   * code" (Jamaica), "delivery area indicator" (Malawi) or "post office
   * indicator" (e.g. Cte d'Ivoire).
   */
  sortingCode?: string;
  /**
   * Second-level administrative subdivision of this country. Examples: US
   * county, IT province, UK county.
   */
  subAdministrativeAreaName?: string;
  /**
   * The "subpremise" is something like an apartment or suite. xAL offers more
   * structured premise and subpremise values, but we don't.
   */
  subPremiseName?: string;
  /**
   * Name of thoroughfare. Intersections should be represented with this field
   * or address_line. Examples: "Amphitheatre Parkway", "N Shoreline Blvd &
   * Charleston Rd"
   */
  thoroughfareName?: string;
  /**
   * Thoroughfare numbers (street numbers) can be very complex indeed. xAL
   * defines fancy structures like "ThoroughfareNumberRange" to represent the
   * details, but we haven't included that yet. It is worth noting that this
   * needs to be a string, not a number. Example: "1600"
   */
  thoroughfareNumber?: string;
}

/**
 * The restricts that are computed before building a Mustang index.
 */
export interface PrecomputedRestricts {
  restricts?:  | "INVALID" | "COLOR_BLACK" | "COLOR_BLUE" | "COLOR_BROWN" | "COLOR_GRAY" | "COLOR_GREEN" | "COLOR_ORANGE" | "COLOR_PINK" | "COLOR_PURPLE" | "COLOR_RED" | "COLOR_TEAL" | "COLOR_WHITE" | "COLOR_YELLOW" | "HAS_SIMILAR" | "ALL" | "CLIPART" | "CLIPART_HR" | "LINEART" | "PHOTO" | "ANIMATED" | "TRANSPARENT" | "PANORAMIC" | "STOCK" | "MONO" | "TOLERANT_GRAY" | "COLOR" | "NOT_UNIVERSAL" | "PORTRAIT" | "FACES_ONE" | "FACES_TWO" | "FACES_SEVERAL" | "FACES_MANY" | "FACE_MALE" | "FACE_FEMALE" | "_img_porn_moderate" | "_img_porn_strict" | "_img_porn_very_strict" | "_image_aspect_16x10" | "_image_aspect_16x9" | "_image_aspect_4x3" | "_image_aspect_square" | "_image_aspect_nearsquare" | "_image_aspect_tall" | "_image_aspect_xtall" | "_image_aspect_wide" | "_image_aspect_xwide" | "_image_size_atleast_400x300" | "_image_size_atleast_640x480" | "_image_size_atleast_800x600" | "_image_size_atleast_1024x768" | "_image_size_atleast_1280x800" | "_image_size_atleast_1440x900" | "_image_size_atleast_2MP" | "_image_size_atleast_4MP" | "_image_size_atleast_6MP" | "_image_size_atleast_8MP" | "_image_size_atleast_10MP" | "_image_size_atleast_12MP" | "_image_size_atleast_15MP" | "_image_size_atleast_20MP" | "_image_size_atleast_40MP" | "_image_size_atleast_70MP" | "_image_size_atleast_140MP" | "_image_size_icon" | "_image_size_small" | "_image_size_medium" | "FILETYPE_JPG" | "FILETYPE_GIF" | "FILETYPE_PNG" | "FILETYPE_BMP" | "FILETYPE_SVG" | "FILETYPE_WEBP" | "FILETYPE_ICO" | "FILETYPE_CRAW" | "FILETYPE_HEIF" | "CC_LICENSE" | "NON_CC_LICENSE" | "BEST" | "ICON" | "SMALL" | "MEDIUM" | "LARGE" | "XLARGE" | "XXLARGE" | "_imagehuge" | "DEPRECATED_65" | "DEPRECATED_72"[];
}

/**
 * Per-doc data for premium documents in the Google index.
 */
export interface PremiumPerDocData {
  /**
   * type froogle/currency/currency.h
   */
  Currency?: number;
  /**
   * publishing date (seconds since 1970,
   */
  Date?: bigint;
  /**
   * entitlement data
   */
  Entitlement?: number[];
  /**
   * True if a free document is archival in nature.
   */
  IsArchival?: boolean;
  /**
   * User is entitled to see the premium content for free.
   */
  IsEntitled?: boolean;
  /**
   * price * 100 if available
   */
  Price?: number;
  /**
   * negative values for prior dates) FP of the Premium publication name
   */
  Publication?: bigint;
}

function serializePremiumPerDocData(data: any): PremiumPerDocData {
  return {
    ...data,
    Date: data["Date"] !== undefined ? String(data["Date"]) : undefined,
    Publication: data["Publication"] !== undefined ? String(data["Publication"]) : undefined,
  };
}

function deserializePremiumPerDocData(data: any): PremiumPerDocData {
  return {
    ...data,
    Date: data["Date"] !== undefined ? BigInt(data["Date"]) : undefined,
    Publication: data["Publication"] !== undefined ? BigInt(data["Publication"]) : undefined,
  };
}

/**
 * Additional options for
 * contentWarehouse#projectsLocationsDocumentSchemasList.
 */
export interface ProjectsLocationsDocumentSchemasListOptions {
  /**
   * The maximum number of document schemas to return. The service may return
   * fewer than this value. If unspecified, at most 50 document schemas will be
   * returned. The maximum value is 1000; values above 1000 will be coerced to
   * 1000.
   */
  pageSize?: number;
  /**
   * A page token, received from a previous `ListDocumentSchemas` call. Provide
   * this to retrieve the subsequent page. When paginating, all other parameters
   * provided to `ListDocumentSchemas` must match the call that provided the
   * page token.
   */
  pageToken?: string;
}

/**
 * Additional options for contentWarehouse#projectsLocationsRuleSetsList.
 */
export interface ProjectsLocationsRuleSetsListOptions {
  /**
   * The maximum number of rule sets to return. The service may return fewer
   * than this value. If unspecified, at most 50 rule sets will be returned. The
   * maximum value is 1000; values above 1000 will be coerced to 1000.
   */
  pageSize?: number;
  /**
   * A page token, received from a previous `ListRuleSets` call. Provide this
   * to retrieve the subsequent page. When paginating, all other parameters
   * provided to `ListRuleSets` must match the call that provided the page
   * token.
   */
  pageToken?: string;
}

/**
 * Additional options for contentWarehouse#projectsLocationsSynonymSetsList.
 */
export interface ProjectsLocationsSynonymSetsListOptions {
  /**
   * The maximum number of synonymSets to return. The service may return fewer
   * than this value. If unspecified, at most 50 rule sets will be returned. The
   * maximum value is 1000; values above 1000 will be coerced to 1000.
   */
  pageSize?: number;
  /**
   * A page token, received from a previous `ListSynonymSets` call. Provide
   * this to retrieve the subsequent page. When paginating, all other parameters
   * provided to `ListSynonymSets` must match the call that provided the page
   * token.
   */
  pageToken?: string;
}

/**
 * This is proto2's version of MessageSet.
 */
export interface Proto2BridgeMessageSet {
}

/**
 * Available tags: 14+
 */
export interface PseudoVideoData {
  /**
   * ASR model MPM version.
   */
  AsrModel?: string;
  /**
   * This should be the MustangDocId, we need to figure out how to generate a
   * uint64 given the int64 we have in data_set
   */
  DocKey?: bigint;
  /**
   * Language of the recognizer used to generate transcript.
   */
  Lang?: string;
  /**
   * This is the videodocid associate to the
   * http://video.google.com/videoplay?docid= NUMBER
   */
  MustangDocId?: string;
  s3Mode?: string;
  /**
   * S3 ASR model info.
   */
  s3ModelInfoLabel?: string;
  transcript?: PseudoVideoDataTranscript;
  /**
   * URL for document.
   */
  Url?: string;
}

function serializePseudoVideoData(data: any): PseudoVideoData {
  return {
    ...data,
    DocKey: data["DocKey"] !== undefined ? String(data["DocKey"]) : undefined,
  };
}

function deserializePseudoVideoData(data: any): PseudoVideoData {
  return {
    ...data,
    DocKey: data["DocKey"] !== undefined ? BigInt(data["DocKey"]) : undefined,
  };
}

/**
 * A time-coded transcription of the document's audio track.
 */
export interface PseudoVideoDataTranscript {
  /**
   * The complete transcription text.
   */
  Text?: string;
  timestamp?: PseudoVideoDataTranscriptTimestamp[];
}

/**
 * Mapping of time/character correspondences. Used to map found snippets to the
 * time and thumbnail nearest that snippet.
 */
export interface PseudoVideoDataTranscriptTimestamp {
  CharOffset?: number;
  /**
   * quantized to values in range 0-127
   */
  Confidence?: number;
  TimeOffset?: number;
}

/**
 * PToken expresses policy-relevant properties of the data objects being
 * processed and stored in Google's production systems. See go/ptoken to learn
 * more. PTokens are intentionally opaque: go/ptokens-are-opaque. The following
 * should be considered implementation details. Next ID: 8 INTERNAL: If both the
 * Scalar and the Compound extensions are populated, we use the Compound and
 * discard the Scalar. In principle, this should never happen.
 */
export interface PtokenPToken {
}

/**
 * Information of the app to be annotated for the query. It contains the name
 * of the app, the package name associated with it. It also contains the
 * confidence associated with {app, package} pair. This confidence is calculated
 * from different signals like navboost, ranking etc. which later is used for
 * ranking the apps for a particular query. The source of this app information
 * is also indicated. This app info can either be from installed app (collected
 * from device content) or from the fastmap. LINT.IfChange
 */
export interface QualityActionsAppInfo {
  /**
   * The list of android intents that the app is capable of executing.
   */
  androidIntent?: string[];
  /**
   * This is the string matched from the query.
   */
  appName?: string;
  /**
   * Category of this package.
   */
  category?: QualityActionsAppUnderstandingCategory;
  confidence?: number;
  /**
   * This is the display name of the app as shown below the app icon.
   */
  displayName?: string;
  /**
   * URL for the website associated with this app.
   */
  fallbackUrl?: string;
  /**
   * Note that the package_name could be empty for two reasons: - The AppInfo
   * is annotated by device content. - The ngram exists in app name fastmap, but
   * there are a lot of packages associated with it. e.g., there could be a lot
   * of apps for app name "recipes app".
   */
  packageName?: string;
  /**
   * For the future source, use the field in source_data.source().
   */
  source?:  | "UNKNOWN_SOURCE" | "DEVICE_CONTENT" | "FASTMAP" | "NAVBOOST" | "MARMOT" | "WHITELIST" | "PLAY_APPS_SEARCH" | "ASSISTANT_DEVICE_MODEL_CONTEXT" | "DEVICE_ATTRIBUTE" | "TELEPORT_SEARCH" | "FOREGROUND_SEARCH" | "IMPLICIT_SEARCH" | "MEDIA_PROVIDER" | "TELEPORT" | "AGGRESSIVE_IMPLICIT_SEARCH" | "EMPTY_SEARCH";
  sourceData?: QualityActionsAppInfoSourceData[];
}

function serializeQualityActionsAppInfo(data: any): QualityActionsAppInfo {
  return {
    ...data,
    sourceData: data["sourceData"] !== undefined ? data["sourceData"].map((item: any) => (serializeQualityActionsAppInfoSourceData(item))) : undefined,
  };
}

function deserializeQualityActionsAppInfo(data: any): QualityActionsAppInfo {
  return {
    ...data,
    sourceData: data["sourceData"] !== undefined ? data["sourceData"].map((item: any) => (deserializeQualityActionsAppInfoSourceData(item))) : undefined,
  };
}

/**
 * This deprecates the above: * confidence=3 * source=4 This allows us to merge
 * AppInfo data per package_name.
 */
export interface QualityActionsAppInfoSourceData {
  allowListSourceData?: QualityActionsAppInfoSourceDataAllowListSourceData;
  /**
   * Confidence from navboost.
   */
  confidence?: number;
  /**
   * Number of installs from marmot.
   */
  install?: bigint;
  isCategorical?: boolean;
  mediaProviderSourceData?: QualityActionsAppInfoSourceDataMediaProviderSourceData;
  source?:  | "UNKNOWN_SOURCE" | "DEVICE_CONTENT" | "FASTMAP" | "NAVBOOST" | "MARMOT" | "WHITELIST" | "PLAY_APPS_SEARCH" | "ASSISTANT_DEVICE_MODEL_CONTEXT" | "DEVICE_ATTRIBUTE" | "TELEPORT_SEARCH" | "FOREGROUND_SEARCH" | "IMPLICIT_SEARCH" | "MEDIA_PROVIDER" | "TELEPORT" | "AGGRESSIVE_IMPLICIT_SEARCH" | "EMPTY_SEARCH";
  /**
   * Signals present when the source is TELEPORT.
   */
  teleportSourceData?: AssistantTeleportTeleportNicknameSignals;
}

function serializeQualityActionsAppInfoSourceData(data: any): QualityActionsAppInfoSourceData {
  return {
    ...data,
    install: data["install"] !== undefined ? String(data["install"]) : undefined,
  };
}

function deserializeQualityActionsAppInfoSourceData(data: any): QualityActionsAppInfoSourceData {
  return {
    ...data,
    install: data["install"] !== undefined ? BigInt(data["install"]) : undefined,
  };
}

/**
 * Additional signals when the source is ATV's allow list.
 */
export interface QualityActionsAppInfoSourceDataAllowListSourceData {
  /**
   * Whether the app is in the pre-release stage and only available for
   * testing.
   */
  preReleaseMode?: boolean;
  /**
   * Whether app compatibility is unknown. This field is needed for apps like
   * apple tv that have different package names on different devices. Play
   * Gateway Service (PGS) lookup is needed to validate that the app is
   * available on the user's device. go/app-fulfillment-quality
   */
  unknownAppDeviceCompatibility?: boolean;
}

/**
 * The MEDIA_PROVIDER source can further specify information about the content
 * served by the app.
 */
export interface QualityActionsAppInfoSourceDataMediaProviderSourceData {
  /**
   * The unique provider key/enumeration string as used in KG. See also
   * /base/mediaasset/provider/provider_enumerator.
   */
  providerKey?: string;
  /**
   * The type of content served by the App. See also
   * chrome.dongle.pints.ProviderType.
   */
  providerType?: string;
}

/**
 * Category that this app falls into.
 */
export interface QualityActionsAppUnderstandingCategory {
  category?:  | "MUSIC" | "GAME" | "NEWS" | "VIDEO" | "CHAT";
  confidence?: number;
}

export interface QualityActionsCustomizedNotification {
  /**
   * Buttons on the notification
   */
  buttons?: QualityActionsCustomizedNotificationButton[];
  /**
   * Surface type for the notification
   */
  surfaceType?:  | "UNSPECIFIED" | "PHONE" | "SMART_DISPLAY";
  /**
   * Tap action on the notification body. This overwrites the default tap
   * action on reminder trigger notification (which on mobile, is the reminders
   * hub page).
   */
  tapAction?: QualityActionsCustomizedNotificationPayload;
  /**
   * Notification text
   */
  text?: string;
}

export interface QualityActionsCustomizedNotificationButton {
  /**
   * REQUIRED. text for the button label
   */
  label?: string;
  /**
   * REQUIRED. tap action for the button
   */
  tapAction?: QualityActionsCustomizedNotificationPayload;
}

export interface QualityActionsCustomizedNotificationPayload {
  /**
   * Currently for payload we only support raw string url. More structured
   * options may be added in the future
   */
  url?: string;
}

/**
 * Aqua annotation data for news provider. This proto is added as an extension
 * to NimbleAnnotationData.semantics_proto for nimble annotation.
 */
export interface QualityActionsNewsProviderAnnotationData {
  providers?: QualityActionsNewsProviderAnnotationDataProvider[];
}

/**
 * NextId: 6
 */
export interface QualityActionsNewsProviderAnnotationDataProvider {
  /**
   * List of supported locales for this provider. Must follow the format from
   * go/iii, e.g.: 'en', 'en-US', 'en-GB', etc. Short forms without regions
   * codes, such as, 'en' match all possible regions: en-US, en-GB, en-IN, etc.
   */
  locales?: string[];
  /**
   * The official name of the provider. Used in TTS and should be localized.
   */
  officialName?: string;
  /**
   * TTS hint for the pronunciation of the name. Should be left blank unless
   * TTS performs poorly on official_name. Example: Without hinting, TTS
   * mispronounces "The Daily 202" as "the daily two hundred and two". Feeding
   * tts the string "the daily two oh two" produces correct TTS.
   */
  officialNamePronunciation?: string;
  /**
   * The provider id used for news source URL lookup in Kansas. See b/27250779
   * for details.
   */
  providerId?: number;
  /**
   * A score of how confident the annotated span is a news provider. For
   * example, a high score is assigned for span "bbc news", but a low score for
   * span "bbc", which only triggers narrative news aqua parse for a query with
   * explicit news intent, e.g [play news from bbc].
   */
  score?: number;
}

/**
 * Next id: 32
 */
export interface QualityActionsReminder {
  /**
   * OPTIONAL. True if the reminder is archived. Not present implies false.
   */
  archived?: boolean;
  /**
   * OPTIONAL. The time when this reminder is archived. Deprecated. Use
   * `archived_timestamp` instead.
   */
  archivedTime?: AssistantApiDateTime;
  /**
   * OPTIONAL. When the reminder was completed (only present when archived ==
   * true). Maps to apps_intelligence.dialog.Task's complete_time field.
   */
  archivedTimestamp?: Date;
  /**
   * REQUIRED. async_interaction_type of the reminder trigger notification
   */
  asyncInteractionType?:  | "TYPE_UNSPECIFIED" | "ASSISTANT_EXPLORE_LINKS" | "REMINDER" | "REMINDER_ASSIGNABLE_NOTIFY" | "REMINDER_CHIRP" | "REMINDER_DRAGONGLASS" | "REMINDER_LOCATION_BASED" | "SHARED_REMINDER" | "SHARED_REMINDER_LOCATION_BASED" | "REMINDER_FORESIGHT" | "REMINDER_FORESIGHT_TAP_TO_PAYLOAD" | "REMINDER_FORESIGHT_LONG_ANSWER" | "REMINDER_FORESIGHT_WHEN_IS" | "REMINDER_FORESIGHT_UPCOMING_DATES" | "REMINDER_FORESIGHT_PORKY_PIG" | "REMINDER_SNAPSHOT_CALENDAR_EVENT" | "REMINDER_SNAPSHOT_PKG_ANNIVERSARY" | "REMINDER_SNAPSHOT_PKG_BIRTHDAY" | "REMINDER_SNAPSHOT_PKG_MY_BIRTHDAY" | "REMINDER_ARIS" | "REMINDER_LOCATION_BASED_ARIS" | "REMINDER_SHARED_ARIS" | "REMINDER_FORESIGHT_WHEN_IS_ARIS" | "REMINDER_FORESIGHT_PORKY_PIG_ARIS" | "REMINDER_FORESIGHT_TAP_TO_PAYLOAD_ARIS" | "REMINDER_FORESIGHT_LONG_ANSWER_ARIS" | "REMINDER_FORESIGHT_ARIS" | "REMINDER_CHIRP_ARIS" | "REMINDER_DRAGONGLASS_ARIS" | "REMINDER_PROACTIVE_API" | "REMINDER_POST_TASK_MIGRATION" | "REMINDER_VOLUNTARY_TASK_MIGRATION" | "REMINDER_NOTIFICATION_ENABLE_FIRST_NOTICE" | "REMINDER_NOTIFICATION_ENABLE_NOTICE" | "REMINDER_ONE_OFF_DUP_NOTIFICATION_POST_MIGRATION" | "CROSS_SURFACE" | "CROSS_SURFACE_MOVIE_SHOWTIMES" | "CROSS_SURFACE_EVENTS" | "CROSS_SURFACE_SPORTS_LEAGUE_STANDINGS" | "CROSS_SURFACE_THIRD_PARTY_HANDOFF" | "CROSS_SURFACE_SPORTS_TEAM_STANDINGS" | "CROSS_SURFACE_EXPLICIT_SEND_TO_PHONE" | "CROSS_SURFACE_LOCAL_CATEGORICAL" | "CROSS_SURFACE_LOCAL_DIRECTIONS" | "CROSS_SURFACE_LOCAL_DISTANCE" | "CROSS_SURFACE_MEDIA_SONG_DETAILS" | "CROSS_SURFACE_MEDIA_ARTIST_DETAILS" | "CROSS_SURFACE_TRANSLATION" | "CROSS_SURFACE_SHOPPING_LIST" | "CROSS_SURFACE_LOCAL_PHONE_NUMBER" | "CROSS_SURFACE_LOCAL_SHOPPING" | "CROSS_SURFACE_LOCAL_STATION_KP" | "CROSS_SURFACE_LOCAL_TAXI_DIRECTIONS" | "CROSS_SURFACE_TRANSACTIONS_THIRD_PARTY" | "CROSS_SURFACE_TRANSACTIONS" | "CROSS_SURFACE_TRANSACTIONS_ASYNC_RESUME" | "CROSS_SURFACE_REMOTE_DEVICE_ACTIONS_AUTH" | "CROSS_SURFACE_DONATIONS" | "CROSS_SURFACE_FOOD_ORDERING" | "CROSS_SURFACE_NOTES_AND_LISTS" | "CROSS_SURFACE_DIETARY_RESTRICTIONS" | "CROSS_SURFACE_AE_ACCOUNT_LINKING" | "BTW_VM_UPGRADE" | "BTW_NOTIFY" | "BTW_TOPICAL_TOUR" | "BTW_FAMILY_BELL" | "BTW_WARM_WORDS" | "EDIT_DIETARY_PREFERENCES" | "GOOGLE_NOW" | "GOOGLE_NOW_CHROMEOS" | "PRICE_DROP" | "PROACTIVE_FLIGHT" | "PROACTIVE_FLIGHT_DELAYED_CANCELLED" | "PROACTIVE_FLIGHT_WEATHER" | "PROACTIVE_FLIGHT_LANDING" | "PROACTIVE_HOTEL" | "PROACTIVE_PACKAGE" | "PROACTIVE_BILL" | "PROACTIVE_COUPON_EXPIRES_SOON" | "PROACTIVE_PPT" | "ZEROSTATE_BILL" | "PROACTIVE_EVENT" | "PROACTIVE_TRANSPORT" | "PROACTIVE_INFERRED_REMINDER" | "GROCERY_DELIVERY" | "GROCERY_PICKUP" | "PROACTIVE_SMARTSPACE" | "NARRATIVE_NEWS" | "BROADCAST_CUSTOM" | "BROADCAST_CANNED" | "REPLY_BROADCAST_PHONE" | "REPLY_BROADCAST_CHIRP" | "TELL_MY_FAMILY" | "TELL_MY_FAMILY_ALLOW_GUEST_USE" | "FAMILY_CHECK_IN" | "SUBSCRIPTIONS_WEATHER" | "SUBSCRIPTIONS_WEATHER_CURRENT_CONTEXT" | "SUBSCRIPTIONS_NEWS" | "SUBSCRIPTIONS_FUN_CONTENT" | "SUBSCRIPTIONS_JOKE" | "SUBSCRIPTIONS_OTHER" | "SUBSCRIPTIONS_DAILY_PHRASES" | "SUBSCRIPTIONS_ANIMAL_OF_THE_DAY" | "KEEP_SUBSCRIPTIONS_WEATHER" | "KEEP_SUBSCRIPTIONS_NEWS" | "KEEP_SUBSCRIPTIONS_FUN_CONTENT" | "KEEP_SUBSCRIPTIONS_JOKE" | "KEEP_SUBSCRIPTIONS_OTHER" | "KEEP_SUBSCRIPTIONS_DAILY_PHRASES" | "PROACTIVE_SPORTS_UPDATE" | "GROWTH" | "GROWTH_AUTOMOBILE_PAYFORGAS_PROMO" | "MOBILE_ACTIVATION" | "SIMON_ACTIONS" | "SIMON_WEB_ANSWERS" | "SIMON_CURRENCY" | "SIMON_WEATHER" | "SIMON_ACTIONS_TRAINING_DATA" | "HOMEBOY" | "WHERE_IS_MY_FAMILY_LIFE360" | "WHERE_IS_PERSON_GEO" | "FEATURE_AWARENESS_COMMUNICATION_HABITS" | "FEATURE_AWARENESS_MUSIC_HABITS" | "PHOTO_FRAME_SETUP_PROMOTIONAL" | "ASSISTANT_PIE_SWIPE_EDUCATION" | "ASSISTANT_PIE_OPEN_APP" | "ASSISTANT_PIE_AGGRESSIVE" | "ASSISTANT_PIE_HOMESCREEN_ENTRY_POINT" | "ROUTINES" | "ROUTINES_ALARM_DISMISSAL_TRIGGER_TIP" | "ROUTINES_CLOUD_EXECUTION_REPORT" | "ROUTINES_SCHEDULED_MANIFOLD" | "ROUTINES_LOCATION_TRIGGER" | "ROUTINES_LOCATION_NOTIFICATION" | "ROUTINES_SCHEDULED_ON_PHONE_NOTIFICATION" | "ROUTINES_TRIGGER_ON_MOBILE" | "ROUTINE_HOME_APP_CARDS" | "ROUTINES_DISABLE_COMMUTE_ACTION_TIP" | "ROUTINE_SPECIAL_NEWS_OPT_IN_TIP" | "ROUTINES_WFH_ROUTINE_TIP" | "ROUTINES_ELECTION_NEWS_OPT_IN_TIP" | "ROUTINE_ALARM_DISMISSAL_TRIGGER_NOT_TRIGGERED" | "ROUTINES_SCHEDULE_DISCOVERY" | "ROUTINES_PROMOTE_GM" | "ROUTINES_PROMOTE_GN" | "ROUTINES_PROMOTE_DISMISS_ALARM" | "FAMILY_BELL" | "IFTTT" | "LIVE_CARD_SETTINGS" | "LIVE_CARD_INSTALL_ASSISTANT" | "LIVE_CARD_DISCLOSURE" | "LIVE_CARD_TERMS_AND_CONDITIONS" | "LIVE_CARD_WEB_ANSWERS" | "LIVE_CARD_HEALTH" | "LIVE_CARD_NEWS" | "LIVE_CARD_RESERVE_HOTEL" | "LIVE_CARD_SHOPPING_SETTINGS" | "LIVE_CARD_SHOPPING_VIEW_CART" | "LIVE_CARD_MAPS_DIRECTIONS" | "LIVE_CARD_ATTRIBUTION" | "LIVE_CARD_HANDOFF_ACTIVITY" | "LIVE_CARD_HANDOFF_LINK_ACCOUNT" | "LIVE_CARD_HANDOFF_PLAY_STORE_PURCHASE" | "LIVE_CARD_KP_ANSWERS" | "LIVE_CARD_BLUELINK_TTS" | "LIVE_CARD_VOICE_RETRAIN" | "LIVE_CARD_ENABLE_PERSONAL_RESULTS" | "LIVE_CARD_ENABLE_DEVICE_CONTACTS" | "LIVE_CARD_INFORMATIONAL" | "LIVE_CARD_HELP_PAGES" | "LIVE_CARD_SHOPPING_LIST" | "LIVE_CARD_SPEEDDIAL_MISSING_CONTACT" | "LIVE_CARD_SPEEDDIAL_PROMO_UNVERIFIED_USER" | "LIVE_CARD_SPEEDDIAL_REMOVE_CONTACTS" | "LIVE_CARD_SPEEDDIAL_SHOW_CONTACTS" | "LIVE_CARD_REVIEW_SUMMARY" | "LIVE_CARD_LINE_SETTINGS" | "LIVE_CARD_LOCATE_DEVICE_NOTIFICATION_SETTINGS" | "LIVE_CARD_APP_INTERACTION_SETTINGS" | "SHARE_MEETING" | "SHARE_MEETING_LIVE_CARD" | "LINK_ZOOM" | "CREATE_DUO_GROUP" | "PRIVACY_ACTIONS" | "LIVE_CARD_FAMILY_BELL" | "LIVE_CARD_FAMILY_BELL_IOS" | "FAMILY_BELL_RING" | "FAMILY_BELL_GET_READY" | "THIRD_PARTY_ORDER_STATUS_UPDATE" | "THIRD_PARTY_ALERT" | "THIRD_PARTY_SUBSCRIPTION" | "THIRD_PARTY_SMART_DISPLAY_CARD" | "PROFILE_GRANT_NOTIFICATION" | "PROFILE_TELL_ME_MORE_NOTIFICATION" | "HOME_AUTOMATION_DEVICE_NOTIFICATION" | "CHANGE_DEFAULT_MEDIA_PROVIDER" | "DOWNLOAD_NOT_INSTALLED_PROVIDER" | "PROMOTE_PLAY_RADIO_ROUTINE" | "MEDIA_CROSS_DEVICE_PROMOTION" | "MEDIA_LINK_3P_PROVIDER_NOTIFICATION" | "MEDIA_PREFERRED_PODCAST_PROVIDER_NOTIFICATION" | "MEDIA_INITIATION" | "VOICE_DELIGHT_DELAYED_ACTION" | "WRAPPED_REMOTE_INTERACTION" | "ASYNC_INTERACTION" | "REENGAGEMENT_NOTIFICATION" | "BLUE_GINGER_RESPONSE" | "BLUE_GINGER_SURVEY" | "SMARTHOME_DOORBELL" | "SMARTHOME_ALARM" | "SMARTHOME_ASYNCHRONOUS" | "SMARTHOME_BROADCAST" | "SMARTHOME_FOLLOW_UP" | "SMARTHOME_PHONES" | "COMMUNICATION_MISSED_CALL" | "VUI_CONSENT_MISSING_DI" | "VUI_CONSENT_MISSING_THIRD_PARTY_DISCLOSURE" | "WEB_ANSWERS_NOTIFICATION" | "PERSONAL_INTELLIGENCE_NOTIFICATION" | "PERSONAL_INTELLIGENCE_LIVE_CARD" | "LENS_REMINDER" | "IQS_NOTIFICATION" | "ASSISTANT_SURVEY" | "ASSISTANT_SURVEY_IMPORTANCE_MIN" | "ASSISTANT_SURVEY_PRIORITY_LOW" | "WHEREABOUTS_CHECKIN" | "TRAVEL_ASSISTANT_FLIGHT_CHECKIN" | "DIALER_AUTH" | "MODES_POI" | "HEADY_CONCISE_ANSWERS_ATTRIBUTION" | "HEADY_CONCISE_ANSWERS_EXPLORATION" | "HEADY_ELENCHUS_ATTRIBUTION" | "HEADY_ELENCHUS_EXPLORATION" | "HEADY_GENERATED_ANSWERS_ATTRIBUTION" | "HEADY_GENERATED_ANSWERS_EXPLORATION" | "HEADY_INTERACTIVE_QUESTIONS_ATTRIBUTION" | "HEADY_INTERACTIVE_QUESTIONS_EXPLORATION" | "HEADY_KP_DESCRIPTION_ATTRIBUTION" | "HEADY_KP_DESCRIPTION_EXPLORATION" | "HEADY_READ_WEBANSWER_ATTRIBUTION" | "HEADY_READ_WEBANSWER_EXPLORATION" | "HEADY_SMART_PUNTS_WEBANSWERS" | "HEADY_TELLMEMORE_ATTRIBUTION" | "HEADY_TELLMEMORE_EXPLORATION" | "HEADY_VOICE_SUGGESTIONS_ATTRIBUTION" | "HEADY_VOICE_SUGGESTIONS_EXPLORATION" | "HEADY_WEBANSWERS_LIST_ATTRIBUTION" | "HEADY_WEBANSWERS_LIST_EXPLORATION" | "COMMUNICATION_VIDEO_MESSAGE" | "HEALTH_ASSISTANT_ADD_GOAL_PARTNER" | "HEALTH_ASSISTANT_SUGGEST_GOAL_PARTNER" | "HEALTH_ASSISTANT_EDUCATIONAL" | "HEALTH_ASSISTANT_GOAL_REMINDER" | "HEALTH_ASSISTANT_WEATHER_REMINDER" | "HEALTH_ASSISTANT_GOAL_FOLLOWUP" | "HEALTH_ASSISTANT_ORGANIZATIONAL" | "HEALTH_ASSISTANT_WEEKLY_REPORT" | "HEALTH_ASSISTANT_WEEKLY_FEEDBACK" | "ASSISTANT_SPEAKERS_MOBILE_NOTIFICATION" | "ASSISTANT_SPEAKERS_ACTION_RENDER_HARD" | "ASSISTANT_SPEAKERS_CHURNOUT_ANSWER_OTHER" | "ASSISTANT_SPEAKERS_CHURNOUT_DEVICE_MEDIA_CONTROL" | "ASSISTANT_SPEAKERS_CHURNOUT_ALARM" | "ASSISTANT_SPEAKERS_CHURNOUT_LIST" | "ASSISTANT_SPEAKERS_CHURNOUT_PERSONALITY_CURATED_CONTENT" | "ASSISTANT_SPEAKERS_ONBOARD" | "ASSISTANT_SPEAKERS_ONBOARD_ANSWER" | "ASSISTANT_SPEAKERS_ONBOARD_VOLUME_CONTROL" | "ASSISTANT_SPEAKERS_ONBOARD_ALARM" | "ASSISTANT_SPEAKERS_ONBOARD_LIST" | "ASSISTANT_SPEAKERS_ONBOARD_JOKE" | "ASSISTANT_SPEAKERS_ONBOARD_ACTION_RENDER" | "ALARM_EXPIRATION" | "SCREENLESS_WCYD_PERSONALIZED_SUGGESTION_EXPLANATION_LIVECARD" | "FAMILY_SHARING" | "SUPPORT_ARTICLE" | "LOCKSCREEN_PERSONAL_RESULTS_SETTING" | "ASSISTANT_ON_LOCKSCREEN_SETTING" | "SKIP_VOICE_RECOGNITION_SETTING" | "MULTI_DEVICE_NOTIFICATION_FEEDBACK" | "MULTI_DEVICE_FEEDBACK_CHIRP" | "DRAGONGLASS_SPORT_MODULE" | "DEVICES_PLATFORM" | "DRAGONGLASS_CONCIERGE_CARD" | "BLUE_STEEL_SETUP" | "ZEROSTATE_VIP_BIRTHDAY" | "ZEROSTATE_ANNIVERSARY" | "ZEROSTATE_OWN_BIRTHDAY" | "ZEROSTATE_VIP_BIRTHDAY_ONE_WEEK_BEFORE" | "ZEROSTATE_VIP_BIRTHDAY_ONE_DAY_BEFORE" | "ZEROSTATE_STARRED_CONTACT_BIRTHDAY_ONE_WEEK_BEFORE" | "ZEROSTATE_STARRED_CONTACT_BIRTHDAY_ONE_DAY_BEFORE" | "ZEROSTATE_OWN_BIRTHDAY_ONE_WEEK_BEFORE" | "ZEROSTATE_OWN_BIRTHDAY_ONE_DAY_BEFORE" | "ZEROSTATE_CALENDAR_ANNIVERSARY" | "ZEROSTATE_CALENDAR_VIP_BIRTHDAY_ONE_WEEK_BEFORE" | "ZEROSTATE_CALENDAR_VIP_BIRTHDAY_ONE_DAY_BEFORE" | "ASSISTANT_FAMILY_READ_ALONG" | "BEQUT" | "ASSISTJS_ACTIONS_LINKS" | "ZEROSTATE_INTEPRETER_DOWNLOAD_PACK" | "PROACTIVE_API" | "TRANSACTIONS_VOICE_MATCH_OPTIN" | "TRANSACTIONS_VOICE_MATCH" | "TRANSACTIONS_VOICE_MATCH_OPTIN_FOR_GAMES" | "LIVE_CARD_XTALK" | "DO_IT_AGAIN" | "DO_IT_AGAIN_WEATHER" | "DO_IT_AGAIN_GOOGLE_HOME" | "DO_IT_AGAIN_FREQUENT_ACTIONS" | "DO_IT_AGAIN_BOOSTED" | "DO_IT_AGAIN_CROSS_DEVICE" | "DO_IT_AGAIN_INITIAL" | "DO_IT_AGAIN_CONFIRMATION" | "SUBSCRIPTIONS_DO_IT_AGAIN" | "CALENDAR_MEETING_MISSING_ROOM" | "CALENDAR_NEWLY_ADDED_MEETING" | "FOOD_REORDERING" | "HEALTH_AND_FITNESS_MEDITATION" | "HEALTH_AND_FITNESS_SLEEP_COACHING" | "HEALTH_AND_FITNESS_WELLNESS_SETTING" | "ZEROSTATE_ON_MY_WAY_HOME" | "ZEROSTATE_ON_MY_WAY_HOME_DISCOVERY" | "SMART_DISPLAY_WEB_URL_CLICK" | "GEO_TRAFFIC_TO_PLACE" | "GEO_TIME_TO_LEAVE" | "GEO_TTL_CALENDAR_EVENT" | "GEO_TTL_RESERVED_RESTAURANT" | "GEO_TTL_RESERVED_SOCIAL_EVENT" | "GEO_TTL_FLIGHT_PASSENGER_DEPARTURE" | "GEO_AAP_GROCERY_STORE" | "GEO_AAP_BEAUTY_WELLNESS" | "GEO_AAP_RESTAURANT" | "GEO_AAP_TRANSIT" | "GEO_AAP_APP_RECOMMENDATIONS" | "GEO_AAP_HYBRID_HOTSEAT" | "GEO_AAP_LANDMARK" | "GEO_AAP_SHOPPING_CENTER" | "GEO_AAP_HOTEL" | "GEO_AAP_RESTAURANT_DEAL" | "GEO_AAP_CHAIN_DEAL" | "GEO_AAP_EXPERIMENT" | "APP_ACTIONS_SHORTCUTS" | "APP_ACTIONS_HEADSUP_NOTIFICATION" | "APP_ACTIONS_PERSONAL_INVENTORY_NOTIFICATION" | "WARM_WORDS_TRIGGERING_SURVEY" | "PHOX_NEW_MOVIE_RECOMMENDATION" | "PHOX_NEW_TASK_RECOMMENDATION" | "GSA_NLS_PERMISSION" | "UPDATE_STICKY_NOTES" | "INDIAN_PREMIER_LEAGUE_PROMO_CAMPAIGN" | "FELA_CAMPAIGN_INTRO" | "FELA_CAMPAIGN_REENGAGEMENT" | "FELA_CAMPAIGN_WON" | "LOBBY_HIGHLIGHTS" | "MORRIS_OOBE" | "MORRIS_OOBE_FROM_GMM_OPT_IN" | "MORRIS_OOBE_FROM_GMM_NOT_NOW" | "MORRIS_DRIVING_SCREEN_OOBE_NEW_USER" | "MORRIS_DRIVING_SCREEN_OOBE_ALL_PERMISSIONS" | "MORRIS_DRIVING_SCREEN_OOBE_AR_PERMISSION" | "MORRIS_DRIVING_SCREEN_OOBE_NA_PERMISSION" | "MORRIS_DRIVING_SCREEN_OOBE_BT_PERMISSION" | "MORRIS_DRIVING_SCREEN_AR" | "MORRIS_DRIVING_SCREEN_BT" | "MORRIS_MICRO" | "AAE_ENABLE_CONTACT_UPLOAD_PERMISSION" | "PHOX_OPTIN_DISCOVERABILITY" | "VM_UPGRADE_PUNT" | "INVITE_GUEST_USER" | "FAMILY_NUDGE_SHARED_REMINDERS" | "BIOGRAPHER_PROACTIVE" | "ASPIRE_REMINDER" | "ASPIRE_CONNECT" | "ASPIRE_CELEBRATE" | "PRIVACY_GROWTH" | "LOCATE_DEVICE" | "BIRTHDAY_COUNTDOWN" | "PROACTIVE_RECIPES" | "CUSTOM_PRONUNCIATION_CONTACT_NO_MATCH" | "CUSTOM_PRONUNCIATION_CALL_HANG_UP" | "AE_USER_ONBOARDING_NETFLIX" | "AE_USER_ONBOARDING_ZOOM" | "SNAPSHOT_MORNING_PROMO_CAMPAIGN" | "PROACTIVE_API_WHAT_CAN_YOU_DO" | "VOICE_ENROLLMENT_ON_DEVICE" | "ENABLE_ACCOUNT_AGENDA_QUERIES" | "CREATE_EVENT_EDUCATIONAL" | "ZEROSTATE_CONVERSATION_STARTERS" | "ZEROSTATE_REFRESH_MAGICAL" | "UNUSED_DEVICE_CLEANUP" | "REMOTE_VEHICLE_ACTION_SETUP_PROMOTION" | "FAMILY_NUDGE_ELVIS" | "AADC_MINOR_MOMENT" | "PAYMENTS_SETTINGS" | "SMARTSPACE_HOLIDAY_ALARMS" | "CROSS_DEVICE_TIMER" | "CROSS_DEVICE_TIMER_FCM_PING" | "MEMORY_AWARENESS" | "MEMORY_SHORTCUT" | "MEMORY_TAP_SAVE" | "SHELDON_DISCLOSURE" | "PROACTIVE_API_FASTTRACK" | "PERSONAL_RESULTS_OPTIN" | "HEADPHONE_PERSONAL_RESULTS_OPTIN" | "UNIT_TESTING";
  /**
   * OPTIONAL. Attachments associated with this Reminder. If the attachment has
   * different behavior on different surfaces (e.g., deeplinks), specify
   * multiple attachments here, and specify the surface types and links in the
   * inner fields. There should be at most one attachment for each surface.
   */
  attachment?: AssistantRemindersAttachment[];
  /**
   * OPTIONAL. Populated only for assignable reminders (E.g. "buy milk"). It
   * will be used in the post-execution card-rendering. If not poulated, i.e. in
   * non-assignable mode, caller should fallback to use $title.
   */
  bareTitle?: string;
  /**
   * OPTIONAL. The reminders "client" id. This ID uniquely identifies a
   * reminder instance and may be generated by any client that writes to our
   * Reminder backend.
   */
  clientId?: string;
  /**
   * REQUIRED. The type of this attachment. This is used for frontends (e.g.,
   * Hubpage) to customize UX. And also for customized VE logging.
   */
  clientType?: QualityDialogManagerReminderClientType;
  /**
   * OPTIONAL. The create time of this reminder. This field is propagated only
   * for the reminders fetched from backend.
   */
  createTime?: AssistantApiDateTime;
  /**
   * OPTIONAL. The create time of this reminder. This field is propagated only
   * only for the reminders fetched from backend.
   */
  createTimestamp?: Date;
  /**
   * OPTIONAL. Creator of a reminder (owned by the current user). Used in
   * shared reminder RUD operations.
   */
  creator?: QualityActionsReminderPerson;
  /**
   * OPTIONAL. Contains fields needed to build the customized notification card
   * 
   */
  customizedNotificationCard?: QualityActionsCustomizedNotification[];
  /**
   * A representation of the Gregorian calendar date and timezone-relative time
   * a reminder is scheduled for. This contains the date and time of either a
   * single reminder or the upcoming instance of a recurring reminder.
   */
  datetime?: AssistantApiDateTime;
  /**
   * OPTIONAL. Full-length description of the reminder.
   */
  description?: string;
  documentAssignmentSource?: QualityActionsReminderDocument;
  dynamiteGroupAssignmentSource?: QualityActionsReminderDynamiteGroup;
  /**
   * DEPRECATED. Use `client_id` or `server_id` instead.
   */
  id?: string;
  location?: QualityActionsReminderLocation;
  /**
   * OPTIONAL. Associated logs to be plumbed through along with a reminder.
   */
  log?: AssistantLogsReminderLog;
  /**
   * OPTIONAL. Memory record payload which is associated with this reminder.
   * This will be set for all Assistant reminders created after the first launch
   * of the Reminder Memory integration, see go/reminders-memory for more
   * details. Also, this might apply to all other types of reminders.
   */
  memoryPayload?: AssistantRemindersMemoryPayload;
  /**
   * OPTIONAL. True if the reminder is notifying on the device that is making
   * the request to the server.
   */
  notifying?: boolean;
  /**
   * OPTIONAL. Populated if the reminder is based off of a personal reference,
   * e.g. [my hotel] when the user has a hotel reservation. Contains the
   * information needed for suggestion chip attribution, e.g. a link back to the
   * email reservation.
   */
  personalReferenceMetadata?: CopleySourceTypeList;
  /**
   * OPTIONAL. Recipient of a reminder (created by the current user). Used for
   * shared reminder CRUD operations.
   */
  recipient?: QualityActionsReminderPerson;
  recurrence?: QualityActionsReminderRecurrenceInfo;
  /**
   * OPTIONAL. The reminders backend "server" id. Only filled in some
   * scenarios, e.g. to generate the reminders hubpage detailed-reminder view.
   */
  serverId?: string;
  symbolicTime?:  | "UNSET" | "MORNING" | "AFTERNOON" | "EVENING" | "NIGHT";
  /**
   * REQUIRED. The main textual representation of the reminder with the final
   * title. For assignable reminders, this would be e.g. "From John: buy milk".
   */
  title?: string;
  /**
   * OPTIONAL. The last updated time of this reminder. This field is propagated
   * only for the reminders fetched from ARIS (go/aris-dd).
   */
  updateTimestamp?: Date;
}

function serializeQualityActionsReminder(data: any): QualityActionsReminder {
  return {
    ...data,
    archivedTimestamp: data["archivedTimestamp"] !== undefined ? data["archivedTimestamp"].toISOString() : undefined,
    createTimestamp: data["createTimestamp"] !== undefined ? data["createTimestamp"].toISOString() : undefined,
    creator: data["creator"] !== undefined ? serializeQualityActionsReminderPerson(data["creator"]) : undefined,
    location: data["location"] !== undefined ? serializeQualityActionsReminderLocation(data["location"]) : undefined,
    log: data["log"] !== undefined ? serializeAssistantLogsReminderLog(data["log"]) : undefined,
    personalReferenceMetadata: data["personalReferenceMetadata"] !== undefined ? serializeCopleySourceTypeList(data["personalReferenceMetadata"]) : undefined,
    recipient: data["recipient"] !== undefined ? serializeQualityActionsReminderPerson(data["recipient"]) : undefined,
    updateTimestamp: data["updateTimestamp"] !== undefined ? data["updateTimestamp"].toISOString() : undefined,
  };
}

function deserializeQualityActionsReminder(data: any): QualityActionsReminder {
  return {
    ...data,
    archivedTimestamp: data["archivedTimestamp"] !== undefined ? new Date(data["archivedTimestamp"]) : undefined,
    createTimestamp: data["createTimestamp"] !== undefined ? new Date(data["createTimestamp"]) : undefined,
    creator: data["creator"] !== undefined ? deserializeQualityActionsReminderPerson(data["creator"]) : undefined,
    location: data["location"] !== undefined ? deserializeQualityActionsReminderLocation(data["location"]) : undefined,
    log: data["log"] !== undefined ? deserializeAssistantLogsReminderLog(data["log"]) : undefined,
    personalReferenceMetadata: data["personalReferenceMetadata"] !== undefined ? deserializeCopleySourceTypeList(data["personalReferenceMetadata"]) : undefined,
    recipient: data["recipient"] !== undefined ? deserializeQualityActionsReminderPerson(data["recipient"]) : undefined,
    updateTimestamp: data["updateTimestamp"] !== undefined ? new Date(data["updateTimestamp"]) : undefined,
  };
}

/**
 * Message representing a Document (i.e. Google Docs, Sheets, Slides) This is
 * currently only used to indicate the existence of said document and can be
 * later extended to include more document information as needed.
 */
export interface QualityActionsReminderDocument {
}

/**
 * Message representing a Dynamite Group (AKA Google Chat space) This is
 * currently only used to indicate the existence of said group and can be later
 * extended to include more group information as needed.
 */
export interface QualityActionsReminderDynamiteGroup {
}

/**
 * A representation of reminder-triggering locations. They may be specific,
 * resolved locations, non-specific location groups, or personal aliases. Next
 * id: 12
 */
export interface QualityActionsReminderLocation {
  categoryInfo?: QualityActionsReminderLocationCategoryInfo;
  chainInfo?: QualityActionsReminderLocationChainInfo;
  /**
   * Optional additional information about the types of the custom location.
   * This field is not stored in backend, and is only used to plumb NLP
   * information to fulfillment UI.
   */
  customLocationType?:  | "UNKNOWN_TYPE" | "BUSINESS" | "PLACE" | "ADDRESS";
  /**
   * An address string that is suitable for displaying to the user in an
   * application interface. It can be detailed, or brief. e.g. "80 Absolute Ave,
   * Unit 1708, Mississauga, ON" e.g. "151 Charles Street West"
   */
  displayAddress?: string;
  /**
   * Filled if location_type is CUSTOM and this is a resolved instance of a
   * business (not for specific address locations).
   */
  geoFeatureId?: GeostoreFeatureIdProto;
  lat?: number;
  lng?: number;
  locationType?:  | "UNKNOWN" | "HOME" | "WORK" | "CHAIN" | "CATEGORICAL" | "CUSTOM";
  /**
   * Descriptive name, e.g. "43rd st new york", a user-edited place name (e.g.
   * "Gym"), or a reverse geocoded business name. This can be any string.
   */
  name?: string;
  /**
   * Deprecated in favor of Reminder.personal_reference_metadata.
   */
  personalLocationMetadata?: CopleySourceTypeList;
  /**
   * A localized, shortened version of the address, suitable for TTS. This
   * originates in the LocationFrame.
   */
  ttsAddress?: string;
}

function serializeQualityActionsReminderLocation(data: any): QualityActionsReminderLocation {
  return {
    ...data,
    chainInfo: data["chainInfo"] !== undefined ? serializeQualityActionsReminderLocationChainInfo(data["chainInfo"]) : undefined,
    geoFeatureId: data["geoFeatureId"] !== undefined ? serializeGeostoreFeatureIdProto(data["geoFeatureId"]) : undefined,
    personalLocationMetadata: data["personalLocationMetadata"] !== undefined ? serializeCopleySourceTypeList(data["personalLocationMetadata"]) : undefined,
  };
}

function deserializeQualityActionsReminderLocation(data: any): QualityActionsReminderLocation {
  return {
    ...data,
    chainInfo: data["chainInfo"] !== undefined ? deserializeQualityActionsReminderLocationChainInfo(data["chainInfo"]) : undefined,
    geoFeatureId: data["geoFeatureId"] !== undefined ? deserializeGeostoreFeatureIdProto(data["geoFeatureId"]) : undefined,
    personalLocationMetadata: data["personalLocationMetadata"] !== undefined ? deserializeCopleySourceTypeList(data["personalLocationMetadata"]) : undefined,
  };
}

/**
 * If LocationType is CATEGORICAL, this is info about the category. For
 * example, the category "Grocery Stores" includes chains such as Safeway and
 * Whole Foods.
 */
export interface QualityActionsReminderLocationCategoryInfo {
  /**
   * A (localized) display string describing the category. This is s generic
   * string describing the category, and may be different than the term the user
   * actually said, e.g. name: "supermarket", display_name: "Grocery Stores"
   */
  displayName?: string;
  locationCategory?:  | "UNKNOWN_CATEGORY" | "GROCERY_STORES" | "ELECTRONICS_STORES" | "HARDWARE_STORES" | "PET_STORES" | "PHARMACIES" | "SHOPPING_CENTERS" | "SPORTING_GOODS_STORES" | "TOY_STORES";
}

/**
 * If LocationType is CHAIN, this is info about the chain.
 */
export interface QualityActionsReminderLocationChainInfo {
  /**
   * The freebase mid of the chain entity.
   */
  chainMid?: string;
  /**
   * The geostore.NameProto.text (corresponding to the user's language) at the
   * time of reminder creation. In most cases, this is the same as name, but
   * there may be corner cases where they differ, e.g. name: "bestbuy",
   * chain_name: "Best Buy".
   */
  chainName?: string;
  /**
   * The (corporate entity) chain's MapFacts feature id.
   */
  featureId?: GeostoreFeatureIdProto;
}

function serializeQualityActionsReminderLocationChainInfo(data: any): QualityActionsReminderLocationChainInfo {
  return {
    ...data,
    featureId: data["featureId"] !== undefined ? serializeGeostoreFeatureIdProto(data["featureId"]) : undefined,
  };
}

function deserializeQualityActionsReminderLocationChainInfo(data: any): QualityActionsReminderLocationChainInfo {
  return {
    ...data,
    featureId: data["featureId"] !== undefined ? deserializeGeostoreFeatureIdProto(data["featureId"]) : undefined,
  };
}

/**
 * A representation of a person other than the current user, who may have
 * created the reminder for the current user, or will receive it from them.
 */
export interface QualityActionsReminderPerson {
  /**
   * REQUIRED. Their full name, which will be shown/spoken when referring to
   * this person informally, e.g. "You have 2 reminders from Dave Smith."
   */
  displayName?: string;
  /**
   * OPTIONAL. Their email address.
   */
  emailAddress?: string;
  /**
   * REQUIRED. Their gaia id (used by the backend for CRUD operations).
   */
  gaiaId?: bigint;
  /**
   * REQUIRED. Their given name, which will be shown/spoken when referring to
   * this person informally, e.g. "You have 2 reminders from Dave."
   */
  givenName?: string;
  /**
   * OPTIONAL. The URL of the photo. This field is read from photo field from
   * go/people-api. Also see go/khdgk for URL formats. This field might be
   * missing if user does not have photo URL available.
   */
  photoUrl?: string;
}

function serializeQualityActionsReminderPerson(data: any): QualityActionsReminderPerson {
  return {
    ...data,
    gaiaId: data["gaiaId"] !== undefined ? String(data["gaiaId"]) : undefined,
  };
}

function deserializeQualityActionsReminderPerson(data: any): QualityActionsReminderPerson {
  return {
    ...data,
    gaiaId: data["gaiaId"] !== undefined ? BigInt(data["gaiaId"]) : undefined,
  };
}

/**
 * Recurrence rule for specifying time-based repeating reminders.
 */
export interface QualityActionsReminderRecurrenceInfo {
  /**
   * OPTIONAL. Client-assigned-id for the recurring reminder
   */
  clientId?: string;
  /**
   * The recurrence pattern.
   */
  recurrence?: AssistantApiRecurrence;
  /**
   * An id which uniquely identifies a recurrence series.
   */
  recurrenceId?: string;
  /**
   * REQUIRED. Server-assigned-id for the recurring reminder
   */
  serverId?: string;
}

/**
 * Ringtone information used for the notification of timer and alarm.
 */
export interface QualityActionsRingtone {
  /**
   * The delay between each two sounds.
   */
  pauseDuration?: AssistantApiDuration;
  /**
   * The sound urls will be used to play.
   */
  soundUrl?: string[];
}

function serializeQualityActionsRingtone(data: any): QualityActionsRingtone {
  return {
    ...data,
    pauseDuration: data["pauseDuration"] !== undefined ? serializeAssistantApiDuration(data["pauseDuration"]) : undefined,
  };
}

function deserializeQualityActionsRingtone(data: any): QualityActionsRingtone {
  return {
    ...data,
    pauseDuration: data["pauseDuration"] !== undefined ? deserializeAssistantApiDuration(data["pauseDuration"]) : undefined,
  };
}

/**
 * The room in which an alarm or timer resides
 */
export interface QualityActionsRoom {
  homegraphId?: string;
  name?: string;
}

/**
 * Conceptually, timers are clocks that count down from an initial duration and
 * notify when they reach 0. In practice, as a timer is running, it holds a
 * stable expiration time and computes the remaining duration using the current
 * time. When a timer is paused, it holds a stable remaining duration.
 */
export interface QualityActionsTimer {
  /**
   * The time when this timer was created
   */
  creationTime?: AssistantApiTimestamp;
  /**
   * Identifies the device this timer belongs to.
   */
  device?: AssistantApiSettingsDeviceSettings;
  /**
   * When not paused: the time the timer is (or was) scheduled to expire, in
   * milliseconds since the Unix epoch. This should be deprecated and replaced
   * by the expire_timer_time with DateTime type once DateTime proto includes
   * unix timestamp (b/63636831).
   */
  expireTime?: bigint;
  /**
   * This is currently being only used only for the response generation when
   * the user describe the expired datatime as a search constraint. We will used
   * it for everything else once that for filtering once DateTime proto includes
   * unix timestamp (b/63636831) and expire_time is deprecated.
   */
  expireTimerTime?: NlpSemanticParsingDatetimeDateTime;
  /**
   * A string key used as an identifier to this timer, unique for a given
   * Provider.
   */
  id?: string;
  /**
   * The label, provided by a user, associated with this timer.
   */
  label?: string;
  /**
   * The time when this timer was last updated (creation, paused, resumed,
   * etc.)
   */
  lastUpdated?: AssistantApiTimestamp;
  /**
   * The duration of the timer when it was started, in milliseconds.
   */
  originalDuration?: bigint;
  /**
   * The duration set for the timer. The DateTimeModifier field is ignored.
   * This field is currently only experimental until we switch the Dialog code
   * and gramnar to the new format.
   */
  originalTimerDuration?: NlpSemanticParsingDatetimeDuration;
  /**
   * The provider that owns this alarm. For Android, this includes the app that
   * owns this alarm, where an intent should be sent to modify it.
   */
  provider?: AssistantApiCoreTypesProvider;
  /**
   * When PAUSED: the remaining duration in milliseconds.
   */
  remainingDuration?: bigint;
  /**
   * The duration remained for the timer. This is needed because there is no
   * expiration date for paused timer. The DateTimeModifier field is ignored.
   * This field is currently only experimental until we switch the Dialog code
   * and gramnar to the new format.
   */
  remainingTimerDuration?: NlpSemanticParsingDatetimeDuration;
  /**
   * The ringtone will be played when the timer fires, it will replace the beep
   * sound if it is not empty.
   */
  ringtone?: QualityActionsRingtone;
  /**
   * Ringtone Task Metadata information used to generate sound for firing the
   * timer.
   */
  ringtoneTaskMetadata?: AssistantApiCoreTypesGovernedRingtoneTaskMetadata;
  /**
   * Contains info about the room the timer is in
   */
  room?: QualityActionsRoom;
  /**
   * The current status of the timer.
   */
  status?:  | "UNKNOWN_TIMER_STATUS" | "RUNNING" | "PAUSED" | "EXPIRED" | "RESET";
  /**
   * Whether or not the device will vibrate when the timer fires.
   */
  vibrate?: boolean;
}

function serializeQualityActionsTimer(data: any): QualityActionsTimer {
  return {
    ...data,
    creationTime: data["creationTime"] !== undefined ? serializeAssistantApiTimestamp(data["creationTime"]) : undefined,
    device: data["device"] !== undefined ? serializeAssistantApiSettingsDeviceSettings(data["device"]) : undefined,
    expireTime: data["expireTime"] !== undefined ? String(data["expireTime"]) : undefined,
    expireTimerTime: data["expireTimerTime"] !== undefined ? serializeNlpSemanticParsingDatetimeDateTime(data["expireTimerTime"]) : undefined,
    lastUpdated: data["lastUpdated"] !== undefined ? serializeAssistantApiTimestamp(data["lastUpdated"]) : undefined,
    originalDuration: data["originalDuration"] !== undefined ? String(data["originalDuration"]) : undefined,
    provider: data["provider"] !== undefined ? serializeAssistantApiCoreTypesProvider(data["provider"]) : undefined,
    remainingDuration: data["remainingDuration"] !== undefined ? String(data["remainingDuration"]) : undefined,
    ringtone: data["ringtone"] !== undefined ? serializeQualityActionsRingtone(data["ringtone"]) : undefined,
    ringtoneTaskMetadata: data["ringtoneTaskMetadata"] !== undefined ? serializeAssistantApiCoreTypesGovernedRingtoneTaskMetadata(data["ringtoneTaskMetadata"]) : undefined,
  };
}

function deserializeQualityActionsTimer(data: any): QualityActionsTimer {
  return {
    ...data,
    creationTime: data["creationTime"] !== undefined ? deserializeAssistantApiTimestamp(data["creationTime"]) : undefined,
    device: data["device"] !== undefined ? deserializeAssistantApiSettingsDeviceSettings(data["device"]) : undefined,
    expireTime: data["expireTime"] !== undefined ? BigInt(data["expireTime"]) : undefined,
    expireTimerTime: data["expireTimerTime"] !== undefined ? deserializeNlpSemanticParsingDatetimeDateTime(data["expireTimerTime"]) : undefined,
    lastUpdated: data["lastUpdated"] !== undefined ? deserializeAssistantApiTimestamp(data["lastUpdated"]) : undefined,
    originalDuration: data["originalDuration"] !== undefined ? BigInt(data["originalDuration"]) : undefined,
    provider: data["provider"] !== undefined ? deserializeAssistantApiCoreTypesProvider(data["provider"]) : undefined,
    remainingDuration: data["remainingDuration"] !== undefined ? BigInt(data["remainingDuration"]) : undefined,
    ringtone: data["ringtone"] !== undefined ? deserializeQualityActionsRingtone(data["ringtone"]) : undefined,
    ringtoneTaskMetadata: data["ringtoneTaskMetadata"] !== undefined ? deserializeAssistantApiCoreTypesGovernedRingtoneTaskMetadata(data["ringtoneTaskMetadata"]) : undefined,
  };
}

/**
 * Proto populated into shards and copied to superroot. Message storing a
 * versioned TopicEmbeddings scores. This is copied from TopicEmbeddings in
 * docjoins.
 */
export interface QualityAuthorityTopicEmbeddingsVersionedItem {
  pageEmbedding?: Uint8Array;
  /**
   * Compressed site/page embeddings.
   */
  siteEmbedding?: Uint8Array;
  /**
   * Number denoting how much a site is focused on one topic.
   */
  siteFocusScore?: number;
  /**
   * The measure of how far page_embeddings deviate from the site_embedding.
   */
  siteRadius?: number;
  versionId?: number;
}

function serializeQualityAuthorityTopicEmbeddingsVersionedItem(data: any): QualityAuthorityTopicEmbeddingsVersionedItem {
  return {
    ...data,
    pageEmbedding: data["pageEmbedding"] !== undefined ? encodeBase64(data["pageEmbedding"]) : undefined,
    siteEmbedding: data["siteEmbedding"] !== undefined ? encodeBase64(data["siteEmbedding"]) : undefined,
  };
}

function deserializeQualityAuthorityTopicEmbeddingsVersionedItem(data: any): QualityAuthorityTopicEmbeddingsVersionedItem {
  return {
    ...data,
    pageEmbedding: data["pageEmbedding"] !== undefined ? decodeBase64(data["pageEmbedding"] as string) : undefined,
    siteEmbedding: data["siteEmbedding"] !== undefined ? decodeBase64(data["siteEmbedding"] as string) : undefined,
  };
}

export interface QualityCalypsoAppsLink {
  applicationId?: string[];
}

/**
 * Contains the needed information for serving a single LiveOp/LiveEvent on AU.
 * Next ID: 9
 */
export interface QualityCalypsoAppsUniversalAuLiveOpDetail {
  /**
   * Key is country, and value is the schedule information in that country.
   */
  countryLevelScheduleInformation?: {
    [key: string]: QualityCalypsoAppsUniversalAuLiveOpEvent
  };
  /**
   * Fallback option for the LiveOp format. We will try en-US -> en -> any
   * locale and get the first one that is available.
   */
  defaultFormatInformation?: QualityCalypsoAppsUniversalAuLiveOpFormat;
  /**
   * Fallback option for the LiveOp event scheduling information. Will use
   * earliest start time and last end time from PDC LiveOps data dump.
   */
  defaultScheduleInformation?: QualityCalypsoAppsUniversalAuLiveOpEvent;
  /**
   * android
   */
  eventId?: string;
  /**
   * [REQUIRED] type of live op event.
   */
  eventType?:  | "TYPE_UNKNOWN" | "MAJOR_UPDATE" | "SALE" | "EVENT" | "CROSSOVER" | "PRE_REG_UPDATE" | "LOYALTY" | "FIRST_PARTY_PROMOTION" | "AUTO_GENERATED_SALE" | "NEW_RELEASE" | "IAP_SKU_SALE" | "OFFER" | "IAP_SKU_DEALS" | "FEATURED_PRODUCTS";
  /**
   * ios
   */
  eventUrl?: string;
  /**
   * Key is locale, and value is the format information for that locale.
   */
  localeLevelFormatInformation?: {
    [key: string]: QualityCalypsoAppsUniversalAuLiveOpFormat
  };
  priority?: string;
}

function serializeQualityCalypsoAppsUniversalAuLiveOpDetail(data: any): QualityCalypsoAppsUniversalAuLiveOpDetail {
  return {
    ...data,
    countryLevelScheduleInformation: data["countryLevelScheduleInformation"] !== undefined ? Object.fromEntries(Object.entries(data["countryLevelScheduleInformation"]).map(([k, v]: [string, any]) => ([k, serializeQualityCalypsoAppsUniversalAuLiveOpEvent(v)]))) : undefined,
    defaultScheduleInformation: data["defaultScheduleInformation"] !== undefined ? serializeQualityCalypsoAppsUniversalAuLiveOpEvent(data["defaultScheduleInformation"]) : undefined,
  };
}

function deserializeQualityCalypsoAppsUniversalAuLiveOpDetail(data: any): QualityCalypsoAppsUniversalAuLiveOpDetail {
  return {
    ...data,
    countryLevelScheduleInformation: data["countryLevelScheduleInformation"] !== undefined ? Object.fromEntries(Object.entries(data["countryLevelScheduleInformation"]).map(([k, v]: [string, any]) => ([k, deserializeQualityCalypsoAppsUniversalAuLiveOpEvent(v)]))) : undefined,
    defaultScheduleInformation: data["defaultScheduleInformation"] !== undefined ? deserializeQualityCalypsoAppsUniversalAuLiveOpEvent(data["defaultScheduleInformation"]) : undefined,
  };
}

/**
 * Contains the schedule for a single live-op event. Next ID: 4
 */
export interface QualityCalypsoAppsUniversalAuLiveOpEvent {
  /**
   * [REQUIRED] End time in UTC for the live-op event.
   */
  endTimestampMillis?: bigint;
  /**
   * If specified, a live-op event must be shown only after this preview-time
   * (in UTC). Otherwise, the event can be shown at any time as long as its
   * before the end time.
   */
  previewTimestampMillis?: bigint;
  /**
   * [REQUIRED] Start time in UTC for the live-op event.
   */
  startTimestampMillis?: bigint;
}

function serializeQualityCalypsoAppsUniversalAuLiveOpEvent(data: any): QualityCalypsoAppsUniversalAuLiveOpEvent {
  return {
    ...data,
    endTimestampMillis: data["endTimestampMillis"] !== undefined ? String(data["endTimestampMillis"]) : undefined,
    previewTimestampMillis: data["previewTimestampMillis"] !== undefined ? String(data["previewTimestampMillis"]) : undefined,
    startTimestampMillis: data["startTimestampMillis"] !== undefined ? String(data["startTimestampMillis"]) : undefined,
  };
}

function deserializeQualityCalypsoAppsUniversalAuLiveOpEvent(data: any): QualityCalypsoAppsUniversalAuLiveOpEvent {
  return {
    ...data,
    endTimestampMillis: data["endTimestampMillis"] !== undefined ? BigInt(data["endTimestampMillis"]) : undefined,
    previewTimestampMillis: data["previewTimestampMillis"] !== undefined ? BigInt(data["previewTimestampMillis"]) : undefined,
    startTimestampMillis: data["startTimestampMillis"] !== undefined ? BigInt(data["startTimestampMillis"]) : undefined,
  };
}

/**
 * Contains the format information for a single LiveOp/LiveEvent. Next ID: 11
 */
export interface QualityCalypsoAppsUniversalAuLiveOpFormat {
  deeplink?: string;
  description?: string;
  /**
   * iOS only, kind of event type
   */
  eyebrow?: string;
  imageUrl?: string;
  originalImageUrl?: string;
  squareImageUrl?: string;
  /**
   * iOS only, sort of start schedule
   */
  status?: string;
  title?: string;
  videoId?: string;
  videoUrl?: string;
}

/**
 * Stores all possible LiveOps/LiveEvents that are eligible to be shown for an
 * app.
 */
export interface QualityCalypsoAppsUniversalAuLiveOpsDetailInfo {
  liveOpEvents?: QualityCalypsoAppsUniversalAuLiveOpDetail[];
  packageName?: string;
}

function serializeQualityCalypsoAppsUniversalAuLiveOpsDetailInfo(data: any): QualityCalypsoAppsUniversalAuLiveOpsDetailInfo {
  return {
    ...data,
    liveOpEvents: data["liveOpEvents"] !== undefined ? data["liveOpEvents"].map((item: any) => (serializeQualityCalypsoAppsUniversalAuLiveOpDetail(item))) : undefined,
  };
}

function deserializeQualityCalypsoAppsUniversalAuLiveOpsDetailInfo(data: any): QualityCalypsoAppsUniversalAuLiveOpsDetailInfo {
  return {
    ...data,
    liveOpEvents: data["liveOpEvents"] !== undefined ? data["liveOpEvents"].map((item: any) => (deserializeQualityCalypsoAppsUniversalAuLiveOpDetail(item))) : undefined,
  };
}

export interface QualityCalypsoAppsUniversalImage {
  fifeUrl?: string;
  height?: number;
  width?: number;
}

export interface QualityCalypsoAppsUniversalImageData {
  /**
   * iOS cover image, which includes the uni image from UAM only.
   */
  enhancedImage?: QualityCalypsoAppsUniversalImage;
  /**
   * aka. promotional image / cover image.
   */
  featureGraphic?: QualityCalypsoAppsUniversalImage;
  screenshot?: QualityCalypsoAppsUniversalImage[];
}

/**
 * Proto message containing site-level signal for search stack. Because
 * firefly_stats.proto depends on "//segindexer:compositedoc_proto", we cannot
 * make perdocdata contain it.
 */
export interface QualityCopiaFireflySiteSignal {
  dailyClicks?: bigint;
  dailyGoodClicks?: bigint;
  dataTimeSec?: bigint;
  firstBoostedTimeSec?: bigint;
  impressionsInBoostedPeriod?: bigint;
  latestBylineDateSec?: bigint;
  latestFirstseenSec?: bigint;
  numOfArticles8?: bigint;
  /**
   * number of articles (lattice article score is 0.8 or more) sliced by 30
   * days (num_of_articles_by_periods[0] is the newest).
   */
  numOfArticlesByPeriods?: bigint[];
  numOfGamblingPages?: bigint;
  numOfUrls?: bigint;
  /**
   * number of urls sliced by 30 days (num_of_urls_by_periods[0] is the
   * newest).
   */
  numOfUrlsByPeriods?: bigint[];
  recentImpForQuotaSystem?: bigint;
  /**
   * Hash value of the site. This will be used by our experiment and analysis.
   */
  siteFp?: bigint;
  totalImpressions?: bigint;
}

function serializeQualityCopiaFireflySiteSignal(data: any): QualityCopiaFireflySiteSignal {
  return {
    ...data,
    dailyClicks: data["dailyClicks"] !== undefined ? String(data["dailyClicks"]) : undefined,
    dailyGoodClicks: data["dailyGoodClicks"] !== undefined ? String(data["dailyGoodClicks"]) : undefined,
    dataTimeSec: data["dataTimeSec"] !== undefined ? String(data["dataTimeSec"]) : undefined,
    firstBoostedTimeSec: data["firstBoostedTimeSec"] !== undefined ? String(data["firstBoostedTimeSec"]) : undefined,
    impressionsInBoostedPeriod: data["impressionsInBoostedPeriod"] !== undefined ? String(data["impressionsInBoostedPeriod"]) : undefined,
    latestBylineDateSec: data["latestBylineDateSec"] !== undefined ? String(data["latestBylineDateSec"]) : undefined,
    latestFirstseenSec: data["latestFirstseenSec"] !== undefined ? String(data["latestFirstseenSec"]) : undefined,
    numOfArticles8: data["numOfArticles8"] !== undefined ? String(data["numOfArticles8"]) : undefined,
    numOfArticlesByPeriods: data["numOfArticlesByPeriods"] !== undefined ? data["numOfArticlesByPeriods"].map((item: any) => (String(item))) : undefined,
    numOfGamblingPages: data["numOfGamblingPages"] !== undefined ? String(data["numOfGamblingPages"]) : undefined,
    numOfUrls: data["numOfUrls"] !== undefined ? String(data["numOfUrls"]) : undefined,
    numOfUrlsByPeriods: data["numOfUrlsByPeriods"] !== undefined ? data["numOfUrlsByPeriods"].map((item: any) => (String(item))) : undefined,
    recentImpForQuotaSystem: data["recentImpForQuotaSystem"] !== undefined ? String(data["recentImpForQuotaSystem"]) : undefined,
    siteFp: data["siteFp"] !== undefined ? String(data["siteFp"]) : undefined,
    totalImpressions: data["totalImpressions"] !== undefined ? String(data["totalImpressions"]) : undefined,
  };
}

function deserializeQualityCopiaFireflySiteSignal(data: any): QualityCopiaFireflySiteSignal {
  return {
    ...data,
    dailyClicks: data["dailyClicks"] !== undefined ? BigInt(data["dailyClicks"]) : undefined,
    dailyGoodClicks: data["dailyGoodClicks"] !== undefined ? BigInt(data["dailyGoodClicks"]) : undefined,
    dataTimeSec: data["dataTimeSec"] !== undefined ? BigInt(data["dataTimeSec"]) : undefined,
    firstBoostedTimeSec: data["firstBoostedTimeSec"] !== undefined ? BigInt(data["firstBoostedTimeSec"]) : undefined,
    impressionsInBoostedPeriod: data["impressionsInBoostedPeriod"] !== undefined ? BigInt(data["impressionsInBoostedPeriod"]) : undefined,
    latestBylineDateSec: data["latestBylineDateSec"] !== undefined ? BigInt(data["latestBylineDateSec"]) : undefined,
    latestFirstseenSec: data["latestFirstseenSec"] !== undefined ? BigInt(data["latestFirstseenSec"]) : undefined,
    numOfArticles8: data["numOfArticles8"] !== undefined ? BigInt(data["numOfArticles8"]) : undefined,
    numOfArticlesByPeriods: data["numOfArticlesByPeriods"] !== undefined ? data["numOfArticlesByPeriods"].map((item: any) => (BigInt(item))) : undefined,
    numOfGamblingPages: data["numOfGamblingPages"] !== undefined ? BigInt(data["numOfGamblingPages"]) : undefined,
    numOfUrls: data["numOfUrls"] !== undefined ? BigInt(data["numOfUrls"]) : undefined,
    numOfUrlsByPeriods: data["numOfUrlsByPeriods"] !== undefined ? data["numOfUrlsByPeriods"].map((item: any) => (BigInt(item))) : undefined,
    recentImpForQuotaSystem: data["recentImpForQuotaSystem"] !== undefined ? BigInt(data["recentImpForQuotaSystem"]) : undefined,
    siteFp: data["siteFp"] !== undefined ? BigInt(data["siteFp"]) : undefined,
    totalImpressions: data["totalImpressions"] !== undefined ? BigInt(data["totalImpressions"]) : undefined,
  };
}

/**
 * Various external IDs that we may have for a given LocalResult. These IDs can
 * map to the corresponding result in other Google systems (KnowledgeGraph) or
 * in third-party systems (OpenTable).
 */
export interface QualityDialogManagerExternalIds {
  /**
   * This field tells us whether this LocalResult supports any of the services
   * that Blue Ginger offers.
   */
  blueGingerSupportedServices?: BlueGingerClientVisibleProtoBlueGingerSupportedServices;
  knowledgeGraphMid?: string;
  /**
   * Google-internal actions supported by go/madden for this LocalResult.
   */
  maddenSupportedActions?: GeoOndemandAssistantSupportedActions;
  openTableRestaurantId?: string;
}

export interface QualityDialogManagerLocalIntentOptions {
  /**
   * LINT.ThenChange(
   * //depot/google3/googledata/nlp/generation/messages/assistant/\
   * dialog_LOCAL_LocalAssistantSchema/\
   * dialog.LOCAL.LocalAssistantSchema_zxx.genx.textpb,
   * //depot/google3/quality/dialog_manager/verticals/local/assistant/\
   * suggestion_chip_util.cc)
   */
  intent?:  | "UNKNOWN" | "ADDRESS" | "CALL" | "DIRECTIONS" | "HOURS" | "INTERNAL_FOOD_ORDERING" | "NEXT" | "MENU" | "PHONE_NUMBER" | "RESERVATIONS"[];
}

/**
 * A generic representation of a local result returned by a local backend. Next
 * ID: 33
 */
export interface QualityDialogManagerLocalResult {
  /**
   * This field can represent different areas depending on the country. For
   * example in the US it is state but in Canada it would be a province.
   */
  adminArea1?: string;
  /**
   * The set of available intents changes with result. An intersection of
   * available_intents and allowed_intents (See: local_config.proto), is shown
   * to the user.
   */
  availableIntents?: QualityDialogManagerLocalIntentOptions;
  /**
   * Bitset of business types this result falls into. Many fields in this
   * message may be unset - expect good coverage for restaurants and hotels for
   * now, but not for other verticals.
   */
  businessType?: NlpSemanticParsingLocalBusinessType;
  country?: string;
  /**
   * The two-letter ISO 3166-1 country code of this result. Generated by
   * FindFeatureCountryCode
   * http://google3/geostore/base/public/country.h?l=39&rcl=154898119 so it
   * should always be populated, but technically there is no guarantee.
   */
  countryCode?: string;
  /**
   * For a directions result, this field will be the distance from the origin
   * to this result using the best measure we have available - the distance
   * along a route, if we have one, or just the crow's flight distance. For a
   * local result, this field will be the crow's flight distance from the user
   * to the result.
   */
  distanceMeters?: bigint;
  /**
   * The standard units of the location where the user is based (not their
   * current location). For example, miles for a user from the US, kilometers
   * for the UK. A US user currently in the UK should have units read in miles.
   */
  distanceUnits?:  | "UNIT_UNKNOWN" | "UNIT_NONE" | "UNIT_DEGREES" | "UNIT_DEGREES_CELSIUS" | "UNIT_DEGREES_FAHRENHEIT" | "UNIT_DEGREES_KELVIN" | "UNIT_MILLISECONDS" | "UNIT_SECONDS" | "UNIT_MINUTES" | "UNIT_HOURS" | "UNIT_DAYS" | "UNIT_MILLIMETERS" | "UNIT_CENTIMETERS" | "UNIT_METERS" | "UNIT_YARDS" | "UNIT_KILOMETERS" | "UNIT_MILES" | "UNIT_SCANDINAVIAN_MILES" | "UNIT_METERS_PER_SECOND" | "UNIT_KILOMETERS_PER_HOUR" | "UNIT_MILES_PER_HOUR" | "UNIT_PERCENT" | "UNIT_FEET" | "UNIT_INCHES" | "UNIT_HOURS_MINUTES_SECONDS" | "UNIT_HOURS_MINUTES" | "UNIT_SPORTS_SCORE" | "UNIT_WEEKS" | "UNIT_MONTHS" | "UNIT_YEARS" | "UNIT_CALORIES" | "UNIT_DAYS_HOURS_MINUTES_SECONDS" | "UNIT_WEEKS_DAYS_HOURS_MINUTES_SECONDS" | "UNIT_ACRES" | "UNIT_SQUARE_MILES" | "UNIT_HECTARES" | "UNIT_SQUARE_KILOMETERS" | "UNIT_SQUARE_CENTIMETERS" | "UNIT_BAR" | "UNIT_KILOPASCAL" | "UNIT_PSI" | "UNIT_POUND" | "UNIT_KILOGRAM" | "UNIT_SHORT_TON" | "UNIT_LONG_TON" | "UNIT_METRIC_TON" | "UNIT_OUNCE" | "UNIT_GRAM";
  /**
   * Various external IDs that we may have for this result.
   */
  externalIds?: QualityDialogManagerExternalIds;
  featureType?:  | "UNKNOWN_TYPE" | "ESTABLISHMENT" | "GEOCODE_ADDRESS" | "GEOCODE_INTERSECTION" | "GEOCODE_ROUTE";
  /**
   * Internal Food ordering action (i.e food ordering via Google) metadata.
   */
  internalFoodOrderingMetadata?: LocalsearchProtoInternalFoodOrderingActionMetadata;
  /**
   * If true, this LocalResult is located in the same state as the user's
   * location.
   */
  inUserAdminArea1?: boolean;
  /**
   * If true, this LocalResult is located in the same country as the user's
   * location.
   */
  inUserCountry?: boolean;
  /**
   * Whether this result is in the same city or town that the user is in.
   */
  inUserLocality?: boolean;
  /**
   * If the original query had a chain intent, and this result is for a
   * business chain.
   */
  isBusinessChain?: boolean;
  /**
   * City/Town.
   */
  locality?: string;
  /**
   * The name of the result, extracted from its FeatureProto's name field.
   */
  name?: string;
  /**
   * Neighborhood within a city. This field is not likely to be set for towns
   * or smaller cities.
   */
  neighborhood?: string;
  /**
   * All info we will need to lookup this result in search.
   */
  resultId?: NlpSemanticParsingLocalLocalResultId;
  streetName?: string;
  streetNumber?: string;
  /**
   * A list of text synonyms the user could use to refer to the result.
   */
  synonym?: string[];
  /**
   * The address of this result formatted for TTS output. This formatting
   * removes acronyms like 2-letter state codes as they cannot be spoken well.
   */
  ttsAddress?: string;
}

function serializeQualityDialogManagerLocalResult(data: any): QualityDialogManagerLocalResult {
  return {
    ...data,
    distanceMeters: data["distanceMeters"] !== undefined ? String(data["distanceMeters"]) : undefined,
    internalFoodOrderingMetadata: data["internalFoodOrderingMetadata"] !== undefined ? serializeLocalsearchProtoInternalFoodOrderingActionMetadata(data["internalFoodOrderingMetadata"]) : undefined,
    resultId: data["resultId"] !== undefined ? serializeNlpSemanticParsingLocalLocalResultId(data["resultId"]) : undefined,
  };
}

function deserializeQualityDialogManagerLocalResult(data: any): QualityDialogManagerLocalResult {
  return {
    ...data,
    distanceMeters: data["distanceMeters"] !== undefined ? BigInt(data["distanceMeters"]) : undefined,
    internalFoodOrderingMetadata: data["internalFoodOrderingMetadata"] !== undefined ? deserializeLocalsearchProtoInternalFoodOrderingActionMetadata(data["internalFoodOrderingMetadata"]) : undefined,
    resultId: data["resultId"] !== undefined ? deserializeNlpSemanticParsingLocalLocalResultId(data["resultId"]) : undefined,
  };
}

/**
 * Define Reminder Client Type. This field is for the purposes of 1) UX
 * Customization: Reminder frontends can be configured to have a slightly
 * different UX (e.g., A customized button on Hubpage. A customized notification
 * layout.) 2) Metrics: Client can count how many Reminders with a certain
 * client type are retrieved/mutated. (e.g., VEIDs in go/oparaw.) 3) Index:
 * ListReminder can list all Reminders with a certain client type. 4) Visibility
 * control: some frontends (identified by provenance type, shortn/_xVC9nY2Eb8)
 * only have access to a subset of client types.
 */
export interface QualityDialogManagerReminderClientType {
  type?:  | "UNSPECIFIED" | "ASSISTANT" | "FORESIGHT" | "FORESIGHT_TAP_TO_PAYLOAD" | "NBA_ALL_STAR_VOTING" | "FORESIGHT_LONG_ANSWER" | "FORESIGHT_WHEN_IS" | "FORESIGHT_PORKY_PIG" | "NOTES_AND_LISTS_SUGGESTION_CHIP" | "FAMILY_NOTES" | "PEOPLE_INTELLIGENCE";
}

/**
 * Set of per-document markup restrictions based on go/eucd-indexing-design.
 * Used for EUCD and global preview compliance. Next ID: 17
 */
export interface QualityDniDocPreviewRestrictions {
  /**
   * Publish date set by webmaster. See detailed description here:
   * http://shortn/_1eC0zzjR7k. Note that this will currently only be set for
   * canonical documents where byline date could be extracted.
   */
  bylineDateSecs?: bigint;
  /**
   * The time that the info in this attachment was computed during crawl, in
   * microseconds.
   */
  crawlTsUsec?: bigint;
  /**
   * Whether this document comes from a domain that is affected by Extended
   * News Previews (ENP) and its status (approved/rejected).
   */
  extendedNewsPreviewsDomain?: QualityDniExtendedNewsPreviews;
  /**
   * Whether the favicon for a given domain should be displayed.
   * FAVICON_DISPLAY_UNSPECIFIED - Display the favicon DISABLE_FAVICON - the
   * favicon should not be rendered by the feature
   */
  faviconDisplay?:  | "FAVICON_DISPLAY_UNSPECIFIED" | "DISABLE_FAVICON";
  /**
   * Firstseen date populated by indexing. It works as fallback to byline_date
   * if it doesn't exist. Note that this will currently only be set for
   * canonical documents where firstseen date could be populated.
   */
  firstseenDateSecs?: number;
  /**
   * Only be true when the page itself is an AMP page. For paired AMP, the
   * canonical page will have this bit as false.
   */
  isAmp?: boolean;
  isEucdDomain?: boolean;
  /**
   * The max number of snippet characters allowed. Based on document markup. No
   * limit if value is less than 0, Google could use any length of snippets.
   * Default value 0 is the strictest restriction, to avoid violating mistakenly
   * If not set, there is no snippet length policy to enforce. Features must
   * first check has_max_snippet_length to avoid applying an overly strict
   * policy.
   */
  maxSnippetLength?: number;
  /**
   * Same as the max_snippet_length, max_thumbnail_size, max_video_preview_secs
   * listed above. But values are based on publisher's preferences from Search
   * Console's robots meta tag tool.
   */
  maxSnippetLengthFromPublisher?: number;
  maxSnippetLengthPublisherDefault?: number;
  /**
   * The max thumbnail size allowed. Based on document markup Default value
   * NONE is the strictest restriction, to avoid violating mistakenly. If not
   * set, there is no thumbnail policy to enforce.
   */
  maxThumbnailSize?:  | "THUMBNAIL_UNSPECIFIED" | "NONE" | "STANDARD" | "LARGE";
  maxThumbnailSizeFromPublisher?:  | "THUMBNAIL_UNSPECIFIED" | "NONE" | "STANDARD" | "LARGE";
  maxThumbnailSizePublisherDefault?: number;
  /**
   * The max seconds of video preview allowed. Based on document markup. No
   * limit if value is less than 0, Google could show any seconds of video.
   * Default value 0 is the strictest restriction, to avoid violating mistakenly
   * If not set, there is no preview length policy to enforce. Features must
   * first check has_max_video_preview_secs to avoid applying an overly strict
   * policy.
   */
  maxVideoPreviewSecs?: number;
  maxVideoPreviewSecsFromPublisher?: number;
  maxVideoPreviewSecsPublisherDefault?: number;
}

function serializeQualityDniDocPreviewRestrictions(data: any): QualityDniDocPreviewRestrictions {
  return {
    ...data,
    bylineDateSecs: data["bylineDateSecs"] !== undefined ? String(data["bylineDateSecs"]) : undefined,
    crawlTsUsec: data["crawlTsUsec"] !== undefined ? String(data["crawlTsUsec"]) : undefined,
  };
}

function deserializeQualityDniDocPreviewRestrictions(data: any): QualityDniDocPreviewRestrictions {
  return {
    ...data,
    bylineDateSecs: data["bylineDateSecs"] !== undefined ? BigInt(data["bylineDateSecs"]) : undefined,
    crawlTsUsec: data["crawlTsUsec"] !== undefined ? BigInt(data["crawlTsUsec"]) : undefined,
  };
}

/**
 * When making changes to this proto, make sure to run: blaze test
 * commerce/datastore/tools/codegen:code_generator_test blaze run
 * commerce/datastore/tools/codegen:code_generator See
 * http://go/cds-schema-council for details. LINT.IfChange
 */
export interface QualityDniExtendedNewsPreviews {
  /**
   * Publisher's country code (ISO-3166) Used in V0.
   */
  countryCode?:  | "UNKNOWN_TWO_CHARACTER_COUNTRY_CODE" | "AD" | "AE" | "AF" | "AG" | "AI" | "AL" | "AM" | "AN" | "AO" | "AQ" | "AR" | "AS" | "AT" | "AU" | "AW" | "AX" | "AZ" | "BA" | "BB" | "BD" | "BE" | "BF" | "BG" | "BH" | "BI" | "BJ" | "BL" | "BM" | "BN" | "BO" | "BQ" | "BR" | "BS" | "BT" | "BV" | "BW" | "BY" | "BZ" | "CA" | "CC" | "CD" | "CF" | "CG" | "CH" | "CI" | "CK" | "CL" | "CM" | "CN" | "CO" | "CR" | "CS" | "CU" | "CV" | "CW" | "CX" | "CY" | "CZ" | "DE" | "DJ" | "DK" | "DM" | "DO" | "DZ" | "EC" | "EE" | "EG" | "EH" | "ER" | "ES" | "ET" | "EU" | "FI" | "FJ" | "FK" | "FM" | "FO" | "FR" | "FX" | "GA" | "GB" | "GD" | "GE" | "GF" | "GG" | "GH" | "GI" | "GL" | "GM" | "GN" | "GP" | "GQ" | "GR" | "GS" | "GT" | "GU" | "GW" | "GY" | "HK" | "HM" | "HN" | "HR" | "HT" | "HU" | "ID" | "IE" | "IL" | "IM" | "IN" | "IO" | "IQ" | "IR" | "IS" | "IT" | "JE" | "JM" | "JO" | "JP" | "KE" | "KG" | "KH" | "KI" | "KM" | "KN" | "KP" | "KR" | "KW" | "KY" | "KZ" | "LA" | "LB" | "LC" | "LI" | "LK" | "LR" | "LS" | "LT" | "LU" | "LV" | "LY" | "MA" | "MC" | "MD" | "ME" | "MF" | "MG" | "MH" | "MK" | "ML" | "MM" | "MN" | "MO" | "MP" | "MQ" | "MR" | "MS" | "MT" | "MU" | "MV" | "MW" | "MX" | "MY" | "MZ" | "NA" | "NC" | "NE" | "NF" | "NG" | "NI" | "NL" | "NO" | "NP" | "NR" | "NU" | "NZ" | "OM" | "PA" | "PE" | "PF" | "PG" | "PH" | "PK" | "PL" | "PM" | "PN" | "PR" | "PS" | "PT" | "PW" | "PY" | "QA" | "RE" | "RO" | "RS" | "RU" | "RW" | "SA" | "SB" | "SC" | "SD" | "SE" | "SG" | "SH" | "SI" | "SJ" | "SK" | "SL" | "SM" | "SN" | "SO" | "SR" | "SS" | "ST" | "SV" | "SX" | "SY" | "SZ" | "TC" | "TD" | "TF" | "TG" | "TH" | "TJ" | "TK" | "TL" | "TM" | "TN" | "TO" | "TR" | "TT" | "TV" | "TW" | "TZ" | "UA" | "UG" | "UK" | "UM" | "US" | "UY" | "UZ" | "VA" | "VC" | "VE" | "VG" | "VI" | "VN" | "VU" | "WF" | "WS" | "YE" | "YT" | "YU" | "ZA" | "ZM" | "ZW" | "ZZ" | "NORDICS";
  /**
   * List of countries that desnippet the publisher. ISO 3166-1-alpha-2 country
   * code (such as FR). See go/iiuse#region-identifiers. Used in V1.
   */
  desnippetedCountryCode?: string[];
  /**
   * Search Console Signals that modifies how policy are calculated. Didn't add
   * `wmconsole.EnpDesnippetingOverrideRules` direcly to avoid cicular
   * dependency issue: go/enp-v2#bookmark=id.dvb1qcltabv9 ENPv2 proto
   * (EnpDesnippetingOverrideRules):
   * google3/crawler/wmconsole/proto/config_enp_desnippeting_override_rules.proto
   */
  policyCriteriaBase64?: string;
  /**
   * ENP status.
   */
  status?:  | "STATUS_UNSPECIFIED" | "GOOGLE_DEFAULT" | "DEPRECATED_DO_NOT_USE_SHOW_SNIPPET_5" | "ENP_REJECTED" | "DEPRECATED_DO_NOT_USE_DESNIPPET_6" | "INELIGIBLE_DOMAIN" | "QA_DESNIPPET" | "SHOW_SNIPPET" | "DESNIPPET";
  /**
   * The default version is V0 (for backward compatibility).
   */
  version?:  | "VERSION_UNSPECIFIED" | "V0" | "V1" | "V2";
}

/**
 * PerDocData for fringe-query-prior (built into the shards for eventual
 * consumption at Fringe classification time). Not stored in DocJoins. NEXT ID:
 * 11
 */
export interface QualityFringeFringeQueryPriorPerDocData {
  encodedCalibratedFringeSitePriorScore?: number;
  /**
   * An encoding of the Chard XLQ-hoax prediction in [0,1].
   */
  encodedChardXlqHoaxPrediction?: number;
  /**
   * An encoding of the Chard XLQ-YMYL prediction in [0,1].
   */
  encodedChardXlqYmylPrediction?: number;
  /**
   * An estimate of the vulnerability of this doc to show fringe content, based
   * on the context around the document. Can be interpreted as a 'safe' QScore
   * threshold to use (see go/doc-fringe-vulnerability for more info). Encoded
   * for compactness and to restrict visibility. Please contact fringe-ranking@
   * to get access to quality_fringe::DocumentFringeVulnerabilityEncoding to
   * decode this field.
   */
  encodedDocumentFringeVulnerability?: number;
  /**
   * Highest entity prior seen for document's Headline and SingleTopic entities
   * (see go/topicality-score for definitions of entity topicalities).
   * Represents probability that a query is fringe, given that the entity is in
   * the result set with topicality >= Headline. Scores scaled to integers
   * between 0 and 1000 for compactness. Scores must be interpreted through
   * FringeQueryPriorEncoding::Decode API.
   */
  encodedEntityPriorScore?: number;
  /**
   * Probability that a query is fringe, given this document is in the result
   * set. Scores scaled to integers between 0 and 1000 for compactness. Scores
   * must be interpreted through FringeQueryPriorEncoding::Decode API.
   */
  encodedFringePriorScore?: number;
  /**
   * Probability that a query is fringe, given this document's site is in the
   * result set. Scores scaled to integers between 0 and 1000 for compactness.
   * Scores must be interpreted through FringeQueryPriorEncoding::Decode API.
   */
  encodedFringeSitePriorScore?: number;
  /**
   * Probability that a query is fringe, given this document's site is in the
   * result set. Does not use signals with a dependency on the QueryFringeScore
   * of a document. Scores scaled to integers between 0 and 1000 for
   * compactness. Scores must be interpreted through
   * FringeQueryPriorEncoding::Decode API. Will NOT be present if the
   * fringe_site_prior_score_for_qfs_training is not significantly different
   * from the site_prior_score.
   */
  encodedFringeSitePriorScoreForQfsTraining?: number;
  /**
   * A combined encoding of the pXLQ score in [0,1] and the confidence with
   * which that score should be interpreted in [0,1].
   */
  encodedPredictedXlqScoreAndConfidence?: number;
  /**
   * A score in [0, 1] representing the similarity of this doc to known
   * fringe-vulnerable 'seeds'. See go/fringe-proximity for more information.
   * Encoded for compactness and to restrict visibility.
   */
  encodedProximityScore?: number;
}

export interface QualityGenieComplexQueriesComplexQueriesOutputRewrite {
  entities?: QualityGenieComplexQueriesComplexQueriesOutputRewriteEntity[];
  rewriteType?:  | "UNKNOWN" | "SIMPLE_SPLIT_LOW_CONFIDENCE" | "SIMPLE_SPLIT" | "COMPLEX_SPLIT_LOW_CONFIDENCE" | "COMPLEX_SPLIT_HIGH_CONFIDENCE" | "COMPARATIVE" | "HARDCODED_SPLIT_BY_REGEX";
  textualRewrite?: string;
}

export interface QualityGenieComplexQueriesComplexQueriesOutputRewriteEntity {
  mid?: string;
  name?: string;
}

/**
 * Compressed version of quality_geo_brainloc.goldmine.BrainlocAnnotation for
 * indexing. (See BrainlocAnnotation for detailed documentation.) Next ID: 10
 */
export interface QualityGeoBrainlocBrainlocAttachment {
  brainlocVersion?: number;
  topCitiesRawScores?: number[];
  /**
   * Compressed top locations and their scores. *Locations are stored using
   * their model vocab IDs. *Location scores are stored using 14 bits of
   * precision (2 bytes).
   */
  topCitiesVocabIds?: number[];
  topCountiesRawScores?: number[];
  topCountiesVocabIds?: number[];
  topCountriesRawScores?: number[];
  topCountriesVocabIds?: number[];
  topStatesRawScores?: number[];
  topStatesVocabIds?: number[];
}

export interface QualityLabelsGoogleLabelData {
  label?: QualityLabelsGoogleLabelDataLabel[];
}

function serializeQualityLabelsGoogleLabelData(data: any): QualityLabelsGoogleLabelData {
  return {
    ...data,
    label: data["label"] !== undefined ? data["label"].map((item: any) => (serializeQualityLabelsGoogleLabelDataLabel(item))) : undefined,
  };
}

function deserializeQualityLabelsGoogleLabelData(data: any): QualityLabelsGoogleLabelData {
  return {
    ...data,
    label: data["label"] !== undefined ? data["label"].map((item: any) => (deserializeQualityLabelsGoogleLabelDataLabel(item))) : undefined,
  };
}

export interface QualityLabelsGoogleLabelDataLabel {
  /**
   * If global_label_value is present, confidence is ignored. confidence is
   * DEPRECATED.
   */
  confidence?: number;
  /**
   * A byte-size value representing 64 * (1 + global_label_value). Use this
   * instead of global_label_value to save on label storage. See
   * quality_prose::LabelValueToBucket() for more info.
   */
  globalLabelBucket?: number;
  globalLabelValue?: number;
  /**
   * At least one of label_id and label_name must be filled in
   */
  labelId?: number;
  labelName?: string;
  provider?: QualityLabelsGoogleLabelDataLabelProvider[];
  providerId?: bigint[];
}

function serializeQualityLabelsGoogleLabelDataLabel(data: any): QualityLabelsGoogleLabelDataLabel {
  return {
    ...data,
    provider: data["provider"] !== undefined ? data["provider"].map((item: any) => (serializeQualityLabelsGoogleLabelDataLabelProvider(item))) : undefined,
    providerId: data["providerId"] !== undefined ? data["providerId"].map((item: any) => (String(item))) : undefined,
  };
}

function deserializeQualityLabelsGoogleLabelDataLabel(data: any): QualityLabelsGoogleLabelDataLabel {
  return {
    ...data,
    provider: data["provider"] !== undefined ? data["provider"].map((item: any) => (deserializeQualityLabelsGoogleLabelDataLabelProvider(item))) : undefined,
    providerId: data["providerId"] !== undefined ? data["providerId"].map((item: any) => (BigInt(item))) : undefined,
  };
}

/**
 * If Provider group is not present the provider is the legacy classifiers
 * (with id 0) and the label_value provided by Google is the global_label_value.
 */
export interface QualityLabelsGoogleLabelDataLabelProvider {
  /**
   * This field is intended to be deprecated. If id == 0 and feed is true it
   * means this label is from a feed. If id == 0 and feed is false, this label
   * is from "Google" If id != 0, feed is meaningless.
   */
  feed?: boolean;
  /**
   * We are currently using this field to indicate an id of the set of
   * classifiers that produced this label. This deviates from the original
   * intention. Also see ClassifierDescription and refer to
   * http://go/genre-labels-provider-id for further info.
   */
  id?: bigint;
  /**
   * A byte-size value representing 64 * (1 + global_label_value). Use it
   * instead of global_label_value to save on label storage.
   */
  labelBucket?: number;
  labelValue?: number;
  /**
   * This name will only sometimes be filled in! Frontends can in general
   * expect this to be filled in, but it will not usually be stored in backends.
   */
  name?: string;
}

function serializeQualityLabelsGoogleLabelDataLabelProvider(data: any): QualityLabelsGoogleLabelDataLabelProvider {
  return {
    ...data,
    id: data["id"] !== undefined ? String(data["id"]) : undefined,
  };
}

function deserializeQualityLabelsGoogleLabelDataLabelProvider(data: any): QualityLabelsGoogleLabelDataLabelProvider {
  return {
    ...data,
    id: data["id"] !== undefined ? BigInt(data["id"]) : undefined,
  };
}

export interface QualityNavboostCrapsAgingData {
  /**
   * Documents with byline date younger than month at the event time.
   */
  lastMonthBucket?: QualityNavboostCrapsAgingDataAgingAgeBucket;
  /**
   * Documents with byline date younger than week at the event time.
   */
  lastWeekBucket?: QualityNavboostCrapsAgingDataAgingAgeBucket;
  /**
   * Documents with byline date younger than year at the event time.
   */
  lastYearBucket?: QualityNavboostCrapsAgingDataAgingAgeBucket;
  /**
   * Documents with byline date older than year at the event time.
   */
  yearPlusBucket?: QualityNavboostCrapsAgingDataAgingAgeBucket;
}

export interface QualityNavboostCrapsAgingDataAgingAgeBucket {
  goodClicks?: number;
  impressions?: number;
}

/**
 * Click / impression signals for craps. The tag numbers are the same as they
 * were in the original CrapsData (below). This is deliberate.
 */
export interface QualityNavboostCrapsCrapsClickSignals {
  /**
   * Thus far this field is only used for host level unsquashed impressions.
   * When compressed (e.g., in perdocdata.proto, CompressedQualitySignals), this
   * value is represented individually and thus is generally incompatible with
   * the other values which are compressed as click-ratios.
   */
  absoluteImpressions?: number;
  badClicks?: number;
  clicks?: number;
  goodClicks?: number;
  impressions?: number;
  lastLongestClicks?: number;
  /**
   * The subset of clicks that are associated with an event from a Unicorn
   * user.
   */
  unicornClicks?: number;
  /**
   * This is not being populated for the current format - instead two instances
   * of CrapsClickSignals (squashed/unsquashed) are used. We are migrating to
   * the new format where this field will be populated.
   */
  unsquashedClicks?: number;
  /**
   * This is not being populated for the current format - instead two instances
   * of CrapsClickSignals (squashed/unsquashed) are used. We are migrating to
   * the new format where this field will be populated.
   */
  unsquashedImpressions?: number;
  unsquashedLastLongestClicks?: number;
}

/**
 * NEXT TAG: 27
 */
export interface QualityNavboostCrapsCrapsData {
  /**
   * Contains counter for Aging signal (go/freshness-aging). It's used
   * internally by Craps/Aging pipeline.
   */
  agingCounts?: QualityNavboostCrapsAgingData;
  badClicks?: number;
  clicks?: number;
  /**
   * The two-letter uppercase country slice of the CrapsData. Examples: "US",
   * "FR", "BR"
   */
  country?: string;
  /**
   * The device interface and os slice of the CrapsData.
   */
  device?: QualityNavboostCrapsCrapsDevice;
  /**
   * Contains CrapsClickSignals for specific features. (i.e. for mobile, US,
   * metro id - 123")
   */
  features?: QualityNavboostCrapsFeatureCrapsData[];
  goodClicks?: number;
  /**
   * These fields may become legacy fields; we may retire them and use the
   * squashed field (below) instead, to allow for some nesting.
   */
  impressions?: number;
  /**
   * The language slice of the CrapsData. Examples: "en", "fr", "pt-BR",
   */
  language?: string;
  /**
   * The number of clicks that were last and longest in related user queries.
   */
  lastLongestClicks?: number;
  /**
   * DO NOT USE: Use the above mobile_signals fields instead. DO NOT REMOVE:
   * Field is present in legacy protos in golden tests.
   */
  mobileData?: QualityNavboostCrapsCrapsData;
  /**
   * The portion of this CrapsData aggregated on data from tier 1/2 mobile
   * interfaces in QSessions.
   */
  mobileSignals?: QualityNavboostCrapsCrapsClickSignals;
  /**
   * Contains a packed string in network byte order, as expected by
   * CrapsIpPrior. Only populated if we looked up the ip_prior_bad_fraction at
   * retrieval time.
   */
  packedIpAddress?: Uint8Array;
  /**
   * Level of pattern. More general patterns get higher values. For URL
   * patterns this field = 0. For example, if we have
   * "http://abc.def.ghi/xyz.html" level 0 pattern will be
   * "http://abc.def.ghi/xyz.html" level 1 pattern will be "p://abc.def.ghi"
   * level 2 pattern will be "p://def.ghi"
   */
  patternLevel?: number;
  /**
   * For pattern data, this will contain stats of the SCC's of the individual
   * urls contributing to the pattern.
   */
  patternSccStats?: QualityNavboostCrapsStatsWithWeightsProto;
  query?: string;
  /**
   * This field can be used by the craps pipeline to slice up signals by
   * various attributes such as device type, country, locale etc. The slice_tag
   * can be an arbitrary string, and the CrapsData values for each slice_tag are
   * aggregated separately, together with the default empty slice_tag.
   */
  sliceTag?: string;
  /**
   * Not used yet - we will probably move the impressions / clicks /
   * good_clicks bad clicks / last longest clicks into here from top level, and
   * rename those fields to legacy.
   */
  squashed?: QualityNavboostCrapsCrapsClickSignals;
  /**
   * Used to assign a prior based on IP address. See
   * quality/navboost/craps/craps-ip-prior.h. This value is prior to the linear
   * transformation (scaling / offset / min / max) that's applied in
   * craps-penalty.cc.
   */
  unscaledIpPriorBadFraction?: number;
  /**
   * We will start using this one for the retuning rollout.
   */
  unsquashed?: QualityNavboostCrapsCrapsClickSignals;
  unsquashedMobileSignals?: QualityNavboostCrapsCrapsClickSignals;
  url?: string;
}

function serializeQualityNavboostCrapsCrapsData(data: any): QualityNavboostCrapsCrapsData {
  return {
    ...data,
    mobileData: data["mobileData"] !== undefined ? serializeQualityNavboostCrapsCrapsData(data["mobileData"]) : undefined,
    packedIpAddress: data["packedIpAddress"] !== undefined ? encodeBase64(data["packedIpAddress"]) : undefined,
  };
}

function deserializeQualityNavboostCrapsCrapsData(data: any): QualityNavboostCrapsCrapsData {
  return {
    ...data,
    mobileData: data["mobileData"] !== undefined ? deserializeQualityNavboostCrapsCrapsData(data["mobileData"]) : undefined,
    packedIpAddress: data["packedIpAddress"] !== undefined ? decodeBase64(data["packedIpAddress"] as string) : undefined,
  };
}

/**
 * CrapsDevice has the gws interface, gws tier and operating system for events
 * from QSessions.
 */
export interface QualityNavboostCrapsCrapsDevice {
  os?:  | "DEVICE_OS_UNKNOWN" | "DEVICE_OS_OTHER" | "DEVICE_OS_WINDOWS" | "DEVICE_OS_OSX" | "DEVICE_OS_LINUX" | "DEVICE_OS_ANDROID" | "DEVICE_OS_IOS";
  /**
   * An enum taken from GWSLogEntryProto that indicates what type of device a
   * request came from. This includes an entry for DESKTOP(1), MOBILE(2), and
   * TABLET(3) devices. Reference: - gwslog(608): GWSLogEntryProto.ux_interface
   */
  uxInterface?: number;
  /**
   * Indicates the device browser tier for the given request. 1 means modern
   * browsers, 3 means very old browsers, and 2 is everything in the middle. See
   * Reference: - gwslog(609): GWSLogEntryProto.ux_tier
   */
  uxTier?: number;
}

export interface QualityNavboostCrapsFeatureCrapsData {
  /**
   * Country, like "us". If not present, it's an aggregation for all countries.
   * This is the same format as one used in Glue.
   */
  country?: string;
  /**
   * Device, like "m". If not present, it's an aggregation for all devices. "m"
   * - mobile devices. "d" - destop devices.
   */
  device?: string;
  /**
   * Language, like "en". If not present, it's an aggregation for all
   * languages. This is the same format as one used in Glue.
   */
  language?: string;
  /**
   * Location id for metro and city. If not present, it's an aggregation for
   * all locations within current country.
   */
  locationId?: number;
  /**
   * CRAPS Signals for the locale.
   */
  signals?: QualityNavboostCrapsCrapsClickSignals;
}

export interface QualityNavboostCrapsStatsWithWeightsProto {
  hi?: number;
  kind?: number;
  lo?: number;
  mean?: number;
  median?: number;
  n?: number;
  pc10?: number;
  pc25?: number;
  pc75?: number;
  pc90?: number;
  stddev?: number;
  stdError?: number;
  variance?: number;
  varOfMean?: number;
  weightedN?: number;
}

/**
 * Experimental NsrTeam data. This is a proto containing versioned signals
 * which can be used to run live experiments. This proto will not be propagated
 * to MDU shards, but it will be populated at query time by go/web-signal-joins
 * inside the CompressedQualitySignals subproto of PerDocData proto. See
 * go/0DayLEs for the design doc. Note how this is only meant to be used during
 * LEs, it should *not* be used for launches.
 */
export interface QualityNsrExperimentalNsrTeamData {
  versionedSignals?: QualityNsrExperimentalNsrTeamScoringSignal[];
}

/**
 * The versioned signals used by the ExperimentalNsrTeamData proto.
 */
export interface QualityNsrExperimentalNsrTeamScoringSignal {
  valueBool?: boolean;
  valueDouble?: number;
  valueFloat?: number;
  valueInt32?: number;
  valueUint32?: number;
  versionId?: number;
}

/**
 * This is a wrapper needed for the WSJ corpus. We want the WSJ RPCs to inject
 * both the experimental_data and the keys, and as of June 2022 these need to be
 * first level members of the proto.
 */
export interface QualityNsrExperimentalNsrTeamWSJData {
  experimentalNsrTeamData?: QualityNsrExperimentalNsrTeamData;
  /**
   * The key used to lookup this data in the WSJ corpus. The WSJ data is
   * sitechunk-level, however the documents in the MDU shards are simply urls.
   * WSJ does a mapping from url -> {primary_chunk, secondary, fallbacks, etc.}
   * and retrieves all the keys from the corpus. This lookup key field will keep
   * track of which key was used for this particular lookup.
   */
  lookupKey?: string;
}

/**
 * The NsrChunksProto corresponds to the NSRChunks class. The data saved by the
 * proto and the class is the same. We provide utilities to go from one to the
 * other.
 */
export interface QualityNsrNsrChunksProto {
  /**
   * Primary NSR sitechunk. In most of the cases it's same as HOST_LEVEL_V3
   * sitechunked canonical url of the document. In rare, but important cases
   * it's based on page markup (see quality/nsr/util/sitechunker.h for details).
   */
  primaryChunk?: string;
  /**
   * Secondary NSR sitechunk. When present, it provides more granular chunking
   * than primary sitechunks (see quality/nsr/util/sitechunker.h for details).
   * Note that the NSRChunks class does not store trivial secondary chunks. Be
   * aware of this when constructing NsrChunksProto from scratch.
   */
  secondaryChunks?: string[];
}

export interface QualityNsrNsrChunksWithSourceInfo {
  nsrChunks?: QualityNsrNsrChunksProto;
  /**
   * These are annotated in the Goldmine NSR annotator.
   */
  siteChunkSource?:  | "SITE_CHUNK_SOURCE_UNKNOWN" | "SITE_CHUNK_SOURCE_WEBUTIL" | "SITE_CHUNK_SOURCE_BREADCRUMBS" | "SITE_CHUNK_SOURCE_AUTHOR" | "SITE_CHUNK_SOURCE_COOKBOOK" | "SITE_CHUNK_SOURCE_CRAWLED_SELLER_DATA";
}

/**
 * NOTE: When adding a new field to be propagated to Raffia check if
 * NsrPatternSignalSpec needs to be updated. Next ID: 52
 */
export interface QualityNsrNsrData {
  /**
   * Score from article classification of the site.
   */
  articleScore?: number;
  articleScoreV2?: number;
  /**
   * Site-level chard score: site quality predictor based on content.
   */
  chardEncoded?: number;
  chardVariance?: number;
  /**
   * An id for defining clusters of sites. Used in ecosystem experiments
   * (project Tundra).
   */
  clusterId?: number;
  clusterUplift?: QualityNsrNsrDataClusterUplift;
  /**
   * Delta site-level signal in Q* penalizing sites with a large number of
   * distracting/annoying resources loaded by the site (see go/clutter-v0).
   */
  clutterScore?: number;
  clutterScores?: QualityNsrVersionedFloatSignal[];
  directFrac?: number;
  /**
   * Categorical signals.
   */
  healthScore?: number;
  host?: string;
  /**
   * Currently corresponds to i18n_g42_bucket.
   */
  i18nBucket?: number;
  /**
   * Site-level impressions.
   */
  impressions?: number;
  /**
   * Bit to determine whether the site has the local authority covid signal, as
   * computed by go/covid-local-authority
   */
  isCovidLocalAuthority?: boolean;
  /**
   * Bit to determine whether the site has the election authority signal, as
   * computed by go/election-authority
   */
  isElectionAuthority?: boolean;
  /**
   * Bit to determine whether the site has mostly video content, but is not
   * hosted on any known video-hosting domains. Site is considered to be
   * video-focused, if it has > 50% of the URLs with watch pages (with smoothing
   * prior). ariane/4045246
   */
  isVideoFocusedSite?: boolean;
  language?: number;
  largeOrgId?: number;
  /**
   * Locality score of the site, i.e. the locality component of the
   * LocalAuthority signal (see go/pq-localauthority).
   */
  localityScore?: number;
  metadata?: QualityNsrNsrDataMetadata;
  /**
   * This field used as a temporary field for clean transitions when we need to
   * roll out Q* and NSR changes simultaneously.
   */
  newNsr?: number;
  nsr?: number;
  /**
   * If true indicates that we do not have NSR data computed for the chunk, and
   * instead the data is coming from an average of other host chunks.
   */
  nsrdataFromFallbackPatternKey?: boolean;
  /**
   * The epoch from which this NSR value is coming from.
   */
  nsrEpoch?: string;
  /**
   * This signal is used to unconditionally override NSR as a bid in Q*. Should
   * only be used in case of emergency (see go/nsr-override-bid). To have any
   * effect, the value should be present and greater than 0.001.
   */
  nsrOverrideBid?: number;
  /**
   * NSR variance logodds [0, infinity).
   */
  nsrVariance?: number;
  /**
   * Fractional signals.
   */
  pnav?: number;
  /**
   * NSR - prior. Estimate of whether the site is above/below average NSR in
   * its slice.
   */
  priorAdjustedNsr?: QualityNsrVersionedFloatSignal[];
  /**
   * Secondary NSR sitechunk. When present, it provides more granular chunking
   * than primary sitechunks (see quality/nsr/util/sitechunker.h for details).
   */
  secondarySiteChunk?: string;
  shoppingScore?: number;
  /**
   * Aggregated value of url autopilot scores for this sitechunk.
   */
  siteAutopilotScore?: number;
  /**
   * Primary NSR sitechunk. In most of the cases it's same as HOST_LEVEL_V3
   * sitechunked canonical url of the document. In rare, but important cases
   * it's based on page markup (see quality/nsr/util/sitechunker.h for details).
   */
  siteChunk?: string;
  /**
   * These are only annotated in the Goldmine NSR annotator.
   */
  siteChunkSource?:  | "SITE_CHUNK_SOURCE_UNKNOWN" | "SITE_CHUNK_SOURCE_HOST_V2" | "SITE_CHUNK_SOURCE_BREADCRUMBS" | "SITE_CHUNK_SOURCE_AUTHOR" | "SITE_CHUNK_SOURCE_COOKBOOK" | "SITE_CHUNK_SOURCE_CRAWLED_SELLER_DATA";
  /**
   * Average value of the site_link_in for pages in the sitechunk.
   */
  siteLinkIn?: number;
  /**
   * Aggregated value of url link out scores for this sitechunk.
   */
  siteLinkOut?: number;
  sitePr?: number;
  /**
   * Estimate of site's PQ rating stddev--spread of the page-level PQ ratings
   * of a site. Note this is different from nsr_variance which predicts error of
   * NSR itself from the aggregated site-level rating.
   */
  siteQualityStddev?: number;
  /**
   * The SpamBrain LAVC score, as of July 2022. See more information at
   * go/cloverfield-lavc-deck.
   */
  spambrainLavcScore?: number;
  spambrainLavcScores?: QualityNsrVersionedFloatSignal[];
  /**
   * Site-level tofu score: site quality predictor based on content.
   */
  tofu?: number;
  ugcScore?: number;
  url?: string;
  /**
   * Versioned map of ASR (authenticity) values.
   */
  versionedAsrData?: QualityNsrVersionedFloatSignal[];
  /**
   * Versioned map of NSR values for experimenting with the next release.
   */
  versionedData?: QualityNsrNSRVersionedData[];
  videoScore?: number;
  /**
   * Score of the Video LQ model.
   */
  vlq?: number;
  /**
   * NSR from a headroom model targeting low-quality video sites.
   */
  vlqNsr?: number;
  ymylNewsV2Score?: number;
}

function serializeQualityNsrNsrData(data: any): QualityNsrNsrData {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? serializeQualityNsrNsrDataMetadata(data["metadata"]) : undefined,
  };
}

function deserializeQualityNsrNsrData(data: any): QualityNsrNsrData {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? deserializeQualityNsrNsrDataMetadata(data["metadata"]) : undefined,
  };
}

/**
 * The uplift-per-cluster values used in Tundra's uplift arm.
 */
export interface QualityNsrNsrDataClusterUplift {
  /**
   * Score for the local sites arm.
   */
  local?: number;
  /**
   * Score for the small sites arm.
   */
  small?: number;
}

/**
 * Contains meta information about this data. This field is only available in
 * docjoins (and potentially MDU shards), it is not populated offline. NOTE:
 * This is a new field (Nov 2022) and we do not want clients to depend on this;
 * please contact qscore-team@ if you want to use this information.
 */
export interface QualityNsrNsrDataMetadata {
  /**
   * Encoded lookup information. The fields set above are expensive to store.
   * Storing them in docjoins is fine, but we cannot store them in MDU shards.
   * In order for the MDU shards to display field provenance information, we
   * store them as a bitfield. For details about the encoding and decoding
   * scheme, see quality_nsr::util::EncodeMetadataLookupInformation. We expect
   * this to occupy 8 bytes as long as there are less than 64 fields in NsrData
   * proto, 12 bytes between 64 and 92 fields, etc.
   */
  encodedLookupInformation?: Uint8Array;
  /**
   * Same as raffia_lookup_key_per_field. Note that the goldmine_lookups have
   * priority; if a field appears in both goldmine and raffia entries, it means
   * it was taken from goldmine. If it's missing here but present in
   * raffia_lookup_key_per_field, it was taken from raffia.
   */
  goldmineLookupKeyPerField?: {
    [key: string]: number
  };
  /**
   * The lookup keys attempted by goldmine. Note that goldmine only runs for
   * urls which can be chunked differently than raffia; in those cases, goldmine
   * related fields are empty.
   */
  goldmineLookupKeys?: string[];
  lastTimeProcessedGoldmineInSeconds?: bigint;
  /**
   * This field is populated only during MDU population, so it's *not* present
   * in docjoins, but it's present in production so that it can be displayed.
   */
  lastTimeProcessedMduInSeconds?: bigint;
  /**
   * Records the last time each system has processed the proto. These are
   * recorded as seconds from the unix epoch. Ideally these fields would be
   * google.protobuf.Timestamp, but the scoring bundle (which depends on this
   * proto) does not understand proto3 syntax. See cl/500942047 for details.
   */
  lastTimeProcessedRaffiaInSeconds?: bigint;
  /**
   * Stores the NSRChunks (computed by goldmine) which were used to populate
   * the data.
   */
  nsrChunksWithSourceInfo?: QualityNsrNsrChunksWithSourceInfo;
  raffiaLookupKey?: string;
  /**
   * Returns the raffia lookup key per each field in the NsrData proto (with
   * exclusion of the Metadata sub-message (i.e. this)). It contains information
   * like 3 : 1, meaning that the field inside NsrData with id '3' (in this case
   * 'host') has been taken by raffia from the raffia lookup key at index 1.
   */
  raffiaLookupKeyPerField?: {
    [key: string]: number
  };
  /**
   * This is an internal field set by Raffia, to indicate which lookup keys
   * have been attempted to populate the NsrData for this document. This will
   * allow us to determine which key has been used to populate each field in the
   * proto. The keys are ordered by lookup priority; raffia will give priority
   * to earlier keys, and only take fields from later keys if they are missing.
   */
  raffiaLookupKeys?: string[];
  /**
   * The url used by NsrSignalMerger
   * (http://google3/indexing/signals/signal-merger.h;l=1801;rcl=509297232) to
   * select which NsrData value to keep. The SignalMerger merges all the NsrData
   * coming from the dup url cluster, and select the NsrData value to return by
   * choosing a single url in the cluster (see NsrSignalMerger class for
   * details). NOTE: This field is populated only when there *is* a cluster. If
   * there is no cluster, this is empty and the key used is the canonical (and
   * only) url.
   */
  raffiaSignalMergerUrl?: string;
}

function serializeQualityNsrNsrDataMetadata(data: any): QualityNsrNsrDataMetadata {
  return {
    ...data,
    encodedLookupInformation: data["encodedLookupInformation"] !== undefined ? encodeBase64(data["encodedLookupInformation"]) : undefined,
    lastTimeProcessedGoldmineInSeconds: data["lastTimeProcessedGoldmineInSeconds"] !== undefined ? String(data["lastTimeProcessedGoldmineInSeconds"]) : undefined,
    lastTimeProcessedMduInSeconds: data["lastTimeProcessedMduInSeconds"] !== undefined ? String(data["lastTimeProcessedMduInSeconds"]) : undefined,
    lastTimeProcessedRaffiaInSeconds: data["lastTimeProcessedRaffiaInSeconds"] !== undefined ? String(data["lastTimeProcessedRaffiaInSeconds"]) : undefined,
  };
}

function deserializeQualityNsrNsrDataMetadata(data: any): QualityNsrNsrDataMetadata {
  return {
    ...data,
    encodedLookupInformation: data["encodedLookupInformation"] !== undefined ? decodeBase64(data["encodedLookupInformation"] as string) : undefined,
    lastTimeProcessedGoldmineInSeconds: data["lastTimeProcessedGoldmineInSeconds"] !== undefined ? BigInt(data["lastTimeProcessedGoldmineInSeconds"]) : undefined,
    lastTimeProcessedMduInSeconds: data["lastTimeProcessedMduInSeconds"] !== undefined ? BigInt(data["lastTimeProcessedMduInSeconds"]) : undefined,
    lastTimeProcessedRaffiaInSeconds: data["lastTimeProcessedRaffiaInSeconds"] !== undefined ? BigInt(data["lastTimeProcessedRaffiaInSeconds"]) : undefined,
  };
}

/**
 * Versioned NSR score data.
 */
export interface QualityNsrNSRVersionedData {
  /**
   * The corresponding NSR value.
   */
  value?: number;
  /**
   * The unique id of the version, preferably just scaled: 19.1 x 10 = 191.
   */
  versionId?: number;
}

/**
 * Next id: 17
 */
export interface QualityNsrPQData {
  /**
   * URL-level chard prediction (encoded as an int).
   */
  chard?: number;
  deltaAutopilotScore?: number;
  deltaLinkIncoming?: number;
  deltaLinkOutgoing?: number;
  /**
   * The delta score of the URL-level quality predictor.
   */
  deltaPageQuality?: number;
  /**
   * Total deltaNSR adjustment based on subchunks. This is a page-level
   * adjustment (subchunks are retrieved based on the page classification).
   */
  deltaSubchunkAdjustment?: number;
  linkIncoming?: number;
  linkOutgoing?: number;
  /**
   * The total number of offdomain anchors seen by the NSR pipeline for this
   * page.
   */
  numOffdomainAnchors?: number;
  page2vecLq?: number;
  subchunkData?: QualityNsrPQDataSubchunkData[];
  /**
   * URL-level tofu prediction.
   */
  tofu?: number;
  urlAutopilotScore?: number;
  /**
   * URL-level score of the VLQ model.
   */
  vlq?: number;
}

/**
 * Data used to compute delta_subchunk_adjustment. (I.e, the subchunks looked
 * up, with their confidences and weights). This data is not propagated to
 * ascorer.
 */
export interface QualityNsrPQDataSubchunkData {
  /**
   * Confidence associated with the chunk.
   */
  confidence?: number;
  /**
   * Subchunk delta in nsr.
   */
  deltaNsr?: number;
  /**
   * Weight with which this document belong to this subchunk (greater than 0).
   */
  pageWeight?: number;
  /**
   * Type of this chunk. Eg, ymyl_health, d2v, etc.
   */
  type?: string;
}

export interface QualityNsrVersionedFloatSignal {
  /**
   * The corresponding float value.
   */
  value?: number;
  /**
   * Unique version id.
   */
  versionId?: number;
}

export interface QualityOrbitAsteroidBeltDocumentIntentScores {
  /**
   * Map of imageid key to ImageIntentScores, for images on cdoc.doc_images
   */
  imageIntentScores?: {
    [key: string]: QualityOrbitAsteroidBeltImageIntentScores
  };
  /**
   * The 'intents' and 'scores' fields are stored as parallel lists for
   * compactness. The 'scores' field should not be accessed directly, but
   * instead through the functions in document_intent_scores_utils.
   */
  intents?:  | "NONE" | "TUTORIAL" | "MAP" | "TRANSLATE" | "LISTEN" | "PROMOTION" | "GIF" | "REGISTER" | "EVENT_LISTING" | "RANKING" | "DISCOGRAPHY" | "DIRECTIONS" | "NEWS" | "SOCIAL_MEDIA" | "FAN_FICTION" | "RECIPES" | "HOURS_OF_OPERATION" | "DEFINITION" | "REAL_ESTATE_LISTING" | "PREVIEW" | "PURCHASE" | "MENU" | "UNBOXING" | "NUTRITION_FACTS" | "TRAVEL_GUIDE" | "SPECS" | "CALCULATOR" | "DOWNLOAD" | "SCORES" | "QUOTES" | "SHOWTIMES" | "CATALOG" | "CALENDAR" | "LOCATION_FINDER" | "RENT" | "STUDY_GUIDE" | "REVIEW" | "SHEET_MUSIC" | "LOGIN" | "TRIVIA" | "CONTACT_PAGE" | "RESERVATION" | "CUSTOMER_SUPPORT" | "INTERVIEW" | "COUPON" | "FLIGHT_TRACKER" | "COMPANY_FINANCIALS" | "FORUM" | "THESAURUS" | "MANUAL" | "JOB_POSTING" | "LYRICS" | "SYMPTOMS" | "REPAIR" | "BUYING_GUIDE" | "PRODUCT_EDITORIAL_REVIEW" | "SHOPPING_MERCHANT_PRODUCT" | "SHOPPING_REVIEW_OR_BUYING_GUIDE" | "PRODUCT_REVIEW" | "PRODUCT_COMPARISON" | "PRODUCT_BUYING_GUIDE" | "SHOPAHOLIC" | "GOOGLE_SCREENSHOT" | "MUGSHOT" | "CRIME" | "SHOPPING_TOPN" | "AUTHENTICITY" | "RESERVED_FOR_NEW_ENUM_128" | "RESERVED_FOR_NEW_ENUM_129" | "RESERVED_FOR_NEW_ENUM_130" | "RESERVED_FOR_NEW_ENUM_131" | "RESERVED_FOR_NEW_ENUM_132" | "RESERVED_FOR_NEW_ENUM_133" | "RESERVED_FOR_NEW_ENUM_134" | "RESERVED_FOR_NEW_ENUM_135" | "RESERVED_FOR_NEW_ENUM_136" | "RESERVED_FOR_NEW_ENUM_137" | "RESERVED_FOR_NEW_ENUM_138" | "RESERVED_FOR_NEW_ENUM_139" | "RESERVED_FOR_NEW_ENUM_140" | "RESERVED_FOR_NEW_ENUM_141" | "RESERVED_FOR_NEW_ENUM_142" | "RESERVED_FOR_NEW_ENUM_143" | "RESERVED_FOR_NEW_ENUM_144" | "RESERVED_FOR_NEW_ENUM_145" | "RESERVED_FOR_NEW_ENUM_146" | "RESERVED_FOR_NEW_ENUM_147" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_98" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_99" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_100" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_101" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_102" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_103" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_104" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_105" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_106" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_107" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_108" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_109" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_110" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_111" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_112" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_113" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_114" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_115" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_116" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_117" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_118" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_119" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_120" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_121" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_122" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_123" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_124" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_125" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_126" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_127" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_2" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_5" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_8" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_10" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_17" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_18" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_21" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_23" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_24" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_28" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_29" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_31" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_34" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_36" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_38" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_39" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_40" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_46" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_50" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_52" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_54" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_56" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_57" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_59" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_60" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_63" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_67" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_71" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_75" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_78" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_81"[];
  /**
   * The intent scores, scaled to integers between 0 and 100 for compactness.
   */
  scores?: number[];
  /**
   * Version 0: Presence of an intent label in the 'intents' field represents
   * our best-effort classification. The 'scores' field is not meaningful.
   * Version 1: Values in the 'scores' field represent the estimated precision
   * of the classifier for a threshold at that score.
   */
  version?: number;
}

export interface QualityOrbitAsteroidBeltImageIntentScores {
  /**
   * The unique identifier for an Asteroid Belt document intent is being reused
   * here
   */
  intents?:  | "NONE" | "TUTORIAL" | "MAP" | "TRANSLATE" | "LISTEN" | "PROMOTION" | "GIF" | "REGISTER" | "EVENT_LISTING" | "RANKING" | "DISCOGRAPHY" | "DIRECTIONS" | "NEWS" | "SOCIAL_MEDIA" | "FAN_FICTION" | "RECIPES" | "HOURS_OF_OPERATION" | "DEFINITION" | "REAL_ESTATE_LISTING" | "PREVIEW" | "PURCHASE" | "MENU" | "UNBOXING" | "NUTRITION_FACTS" | "TRAVEL_GUIDE" | "SPECS" | "CALCULATOR" | "DOWNLOAD" | "SCORES" | "QUOTES" | "SHOWTIMES" | "CATALOG" | "CALENDAR" | "LOCATION_FINDER" | "RENT" | "STUDY_GUIDE" | "REVIEW" | "SHEET_MUSIC" | "LOGIN" | "TRIVIA" | "CONTACT_PAGE" | "RESERVATION" | "CUSTOMER_SUPPORT" | "INTERVIEW" | "COUPON" | "FLIGHT_TRACKER" | "COMPANY_FINANCIALS" | "FORUM" | "THESAURUS" | "MANUAL" | "JOB_POSTING" | "LYRICS" | "SYMPTOMS" | "REPAIR" | "BUYING_GUIDE" | "PRODUCT_EDITORIAL_REVIEW" | "SHOPPING_MERCHANT_PRODUCT" | "SHOPPING_REVIEW_OR_BUYING_GUIDE" | "PRODUCT_REVIEW" | "PRODUCT_COMPARISON" | "PRODUCT_BUYING_GUIDE" | "SHOPAHOLIC" | "GOOGLE_SCREENSHOT" | "MUGSHOT" | "CRIME" | "SHOPPING_TOPN" | "AUTHENTICITY" | "RESERVED_FOR_NEW_ENUM_128" | "RESERVED_FOR_NEW_ENUM_129" | "RESERVED_FOR_NEW_ENUM_130" | "RESERVED_FOR_NEW_ENUM_131" | "RESERVED_FOR_NEW_ENUM_132" | "RESERVED_FOR_NEW_ENUM_133" | "RESERVED_FOR_NEW_ENUM_134" | "RESERVED_FOR_NEW_ENUM_135" | "RESERVED_FOR_NEW_ENUM_136" | "RESERVED_FOR_NEW_ENUM_137" | "RESERVED_FOR_NEW_ENUM_138" | "RESERVED_FOR_NEW_ENUM_139" | "RESERVED_FOR_NEW_ENUM_140" | "RESERVED_FOR_NEW_ENUM_141" | "RESERVED_FOR_NEW_ENUM_142" | "RESERVED_FOR_NEW_ENUM_143" | "RESERVED_FOR_NEW_ENUM_144" | "RESERVED_FOR_NEW_ENUM_145" | "RESERVED_FOR_NEW_ENUM_146" | "RESERVED_FOR_NEW_ENUM_147" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_98" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_99" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_100" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_101" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_102" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_103" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_104" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_105" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_106" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_107" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_108" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_109" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_110" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_111" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_112" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_113" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_114" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_115" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_116" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_117" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_118" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_119" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_120" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_121" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_122" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_123" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_124" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_125" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_126" | "RESERVED_FOR_NEW_ENUM_LARGE_PLEASE_ASK_ORBIT_127" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_2" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_5" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_8" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_10" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_17" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_18" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_21" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_23" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_24" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_28" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_29" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_31" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_34" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_36" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_38" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_39" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_40" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_46" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_50" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_52" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_54" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_56" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_57" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_59" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_60" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_63" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_67" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_71" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_75" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_78" | "RESERVED_FOR_DELETED_ENUM_DO_NOT_REUSE_81"[];
  /**
   * The intent scores, scaled to integers between 0 and 100 for compactness.
   */
  scores?: number[];
}

/**
 * Information for chosen snippet. Next ID: 8
 */
export interface QualityPreviewChosenSnippetInfo {
  /**
   * Whether this snippet is a vulgar candidate.
   */
  isVulgar?: boolean;
  leadingTextType?: string;
  /**
   * The rendered snippet html.
   */
  snippetHtml?: string;
  snippetType?:  | "SNIPPET_TYPE_UNSPECIFIED" | "SEQUENCE" | "SEQUENCE_V2" | "FULL" | "FULL_V2" | "META" | "LEADING_TEXT" | "SAFT_SENTENCE" | "RADISH_SENTENCE" | "RADISH_LIST" | "RADISH_TABLE" | "ANNOTATED_FULL" | "PEREGRINE";
  /**
   * Source of the chosen snippet, decided in PORC. String value of
   * quality.porc.TextSnippetCandidate.TextSnippetSource defined at
   * google3/quality/porc/proto/text_snippet.proto
   */
  source?: string;
  tidbits?: QualityPreviewChosenSnippetInfoTidbitInfo[];
  /**
   * Whether this snippet has trailing ellipsis.
   */
  trailingEllipsis?: boolean;
}

function serializeQualityPreviewChosenSnippetInfo(data: any): QualityPreviewChosenSnippetInfo {
  return {
    ...data,
    tidbits: data["tidbits"] !== undefined ? data["tidbits"].map((item: any) => (serializeQualityPreviewChosenSnippetInfoTidbitInfo(item))) : undefined,
  };
}

function deserializeQualityPreviewChosenSnippetInfo(data: any): QualityPreviewChosenSnippetInfo {
  return {
    ...data,
    tidbits: data["tidbits"] !== undefined ? data["tidbits"].map((item: any) => (deserializeQualityPreviewChosenSnippetInfoTidbitInfo(item))) : undefined,
  };
}

/**
 * Information to identify tidbits.
 */
export interface QualityPreviewChosenSnippetInfoTidbitInfo {
  /**
   * Section name of current snippet.
   */
  sectionName?: string;
  /**
   * Separator to put before this tidbit.
   */
  separator?: string;
  /**
   * Tidbit text for validation.
   */
  tidbitText?: string;
  /**
   * Tidbit token range in the section.
   */
  tokenBegin?: bigint;
  tokenEnd?: bigint;
}

function serializeQualityPreviewChosenSnippetInfoTidbitInfo(data: any): QualityPreviewChosenSnippetInfoTidbitInfo {
  return {
    ...data,
    tokenBegin: data["tokenBegin"] !== undefined ? String(data["tokenBegin"]) : undefined,
    tokenEnd: data["tokenEnd"] !== undefined ? String(data["tokenEnd"]) : undefined,
  };
}

function deserializeQualityPreviewChosenSnippetInfoTidbitInfo(data: any): QualityPreviewChosenSnippetInfoTidbitInfo {
  return {
    ...data,
    tokenBegin: data["tokenBegin"] !== undefined ? BigInt(data["tokenBegin"]) : undefined,
    tokenEnd: data["tokenEnd"] !== undefined ? BigInt(data["tokenEnd"]) : undefined,
  };
}

/**
 * Snippet candidate related information and signal scores. This message is
 * used for both snippet scoring and ranklab features recording. Next ID: 12
 * ================== Features populated in production =======================
 */
export interface QualityPreviewRanklabSnippet {
  /**
   * Features from SnippetFlow in Superroot.
   */
  brainFeatures?: QualityPreviewSnippetBrainFeatures;
  documentFeatures?: QualityPreviewSnippetDocumentFeatures;
  /**
   * For experimental usage, not populated yet.
   */
  experimentalFeatures?: QualityPreviewSnippetExperimentalFeatures;
  /**
   * The final score of this candidate.
   */
  finalScore?: number;
  /**
   * Is this the candidate chosen by Muppet scorer.
   */
  isMuppetSelectedSnippet?: boolean;
  /**
   * Query term (original terms only) coverage features.
   */
  originalQueryTermCoverageFeatures?: QualityPreviewSnippetQueryTermCoverageFeatures;
  qualityFeatures?: QualityPreviewSnippetQualityFeatures;
  /**
   * Core set of snippet features.
   */
  queryFeatures?: QualityPreviewSnippetQueryFeatures;
  /**
   * Query term (including synonyms) coverage features.
   */
  queryTermCoverageFeatures?: QualityPreviewSnippetQueryTermCoverageFeatures;
  /**
   * Radish related information.
   */
  radishFeatures?: QualityPreviewSnippetRadishFeatures;
  /**
   * Information to identify current chosen snippet.
   */
  snippetInfo?: QualityPreviewChosenSnippetInfo;
}

function serializeQualityPreviewRanklabSnippet(data: any): QualityPreviewRanklabSnippet {
  return {
    ...data,
    snippetInfo: data["snippetInfo"] !== undefined ? serializeQualityPreviewChosenSnippetInfo(data["snippetInfo"]) : undefined,
  };
}

function deserializeQualityPreviewRanklabSnippet(data: any): QualityPreviewRanklabSnippet {
  return {
    ...data,
    snippetInfo: data["snippetInfo"] !== undefined ? deserializeQualityPreviewChosenSnippetInfo(data["snippetInfo"]) : undefined,
  };
}

/**
 * A collection of data corresponding to a single title candidate. This will be
 * used as: - a collection of signals to score and select titles in production -
 * an input for training title models NOTE: When adding a floating point value
 * for Ranklab purposes, use float32 instead of float64, because some of the
 * Ranklab library still does not fully support float64. Next ID: 67
 */
export interface QualityPreviewRanklabTitle {
  /**
   * `goldmine_final_score` value in base.
   */
  baseGoldmineFinalScore?: number;
  /**
   * The ranking index of this candidate (starting from 0) in base.
   */
  baseRank?: number;
  /**
   * Title source type.
   */
  dataSourceType?:  | "BODY" | "BODY_SWAPPED" | "OPEN_GRAPH" | "OPEN_GRAPH_HYBRID" | "ALT" | "SOURCEMETA" | "META" | "BODY_HYBRID" | "LEADING_TEXT" | "CHIMERA" | "EXPERIMENTAL" | "DEPRECATED_LEARNED" | "DEPRECATED_LOCAL" | "NUM_TITLE_TYPES";
  /**
   * Document language for this title. It is used for model inference and hence
   * flattened into RanklabTitle instead of RanklabDoc.
   */
  docLang?:  | "ENGLISH" | "DANISH" | "DUTCH" | "FINNISH" | "FRENCH" | "GERMAN" | "HEBREW" | "ITALIAN" | "JAPANESE" | "KOREAN" | "NORWEGIAN" | "POLISH" | "PORTUGUESE" | "RUSSIAN" | "SPANISH" | "SWEDISH" | "CHINESE" | "CZECH" | "GREEK" | "ICELANDIC" | "LATVIAN" | "LITHUANIAN" | "ROMANIAN" | "HUNGARIAN" | "ESTONIAN" | "TG_UNKNOWN_LANGUAGE" | "UNKNOWN_LANGUAGE" | "BULGARIAN" | "CROATIAN" | "SERBIAN" | "IRISH" | "GALICIAN" | "TAGALOG" | "TURKISH" | "UKRAINIAN" | "HINDI" | "MACEDONIAN" | "BENGALI" | "INDONESIAN" | "LATIN" | "MALAY" | "MALAYALAM" | "WELSH" | "NEPALI" | "TELUGU" | "ALBANIAN" | "TAMIL" | "BELARUSIAN" | "JAVANESE" | "OCCITAN" | "URDU" | "BIHARI" | "GUJARATI" | "THAI" | "ARABIC" | "CATALAN" | "ESPERANTO" | "BASQUE" | "INTERLINGUA" | "KANNADA" | "PUNJABI" | "SCOTS_GAELIC" | "SWAHILI" | "SLOVENIAN" | "MARATHI" | "MALTESE" | "VIETNAMESE" | "FRISIAN" | "SLOVAK" | "CHINESE_T" | "FAROESE" | "SUNDANESE" | "UZBEK" | "AMHARIC" | "AZERBAIJANI" | "GEORGIAN" | "TIGRINYA" | "PERSIAN" | "BOSNIAN" | "SINHALESE" | "NORWEGIAN_N" | "PORTUGUESE_P" | "PORTUGUESE_B" | "XHOSA" | "ZULU" | "GUARANI" | "SESOTHO" | "TURKMEN" | "KYRGYZ" | "BRETON" | "TWI" | "YIDDISH" | "SERBO_CROATIAN" | "SOMALI" | "UIGHUR" | "KURDISH" | "MONGOLIAN" | "ARMENIAN" | "LAOTHIAN" | "SINDHI" | "RHAETO_ROMANCE" | "AFRIKAANS" | "LUXEMBOURGISH" | "BURMESE" | "KHMER" | "TIBETAN" | "DHIVEHI" | "CHEROKEE" | "SYRIAC" | "LIMBU" | "ORIYA" | "ASSAMESE" | "CORSICAN" | "INTERLINGUE" | "KAZAKH" | "LINGALA" | "MOLDAVIAN" | "PASHTO" | "QUECHUA" | "SHONA" | "TAJIK" | "TATAR" | "TONGA" | "YORUBA" | "CREOLES_AND_PIDGINS_ENGLISH_BASED" | "CREOLES_AND_PIDGINS_FRENCH_BASED" | "CREOLES_AND_PIDGINS_PORTUGUESE_BASED" | "CREOLES_AND_PIDGINS_OTHER" | "MAORI" | "WOLOF" | "ABKHAZIAN" | "AFAR" | "AYMARA" | "BASHKIR" | "BISLAMA" | "DZONGKHA" | "FIJIAN" | "GREENLANDIC" | "HAUSA" | "HAITIAN_CREOLE" | "INUPIAK" | "INUKTITUT" | "KASHMIRI" | "KINYARWANDA" | "MALAGASY" | "NAURU" | "OROMO" | "RUNDI" | "SAMOAN" | "SANGO" | "SANSKRIT" | "SISWANT" | "TSONGA" | "TSWANA" | "VOLAPUK" | "ZHUANG" | "KHASI" | "SCOTS" | "GANDA" | "MANX" | "MONTENEGRIN" | "AKAN" | "IGBO" | "MAURITIAN_CREOLE" | "HAWAIIAN" | "CEBUANO" | "EWE" | "GA" | "HMONG" | "KRIO" | "LOZI" | "LUBA_LULUA" | "LUO_KENYA_AND_TANZANIA" | "NEWARI" | "NYANJA" | "OSSETIAN" | "PAMPANGA" | "PEDI" | "RAJASTHANI" | "SESELWA_CREOLE_FRENCH" | "TUMBUKA" | "VENDA" | "WARAY_PHILIPPINES" | "NUM_LANGUAGES";
  /**
   * Represents how relavant this title candidate is to the document. Ranged in
   * [0, 1], and this signal is basically calculated as Cosine-similarity
   * between salient term vector and pQ2T model of title candidate sentence.
   */
  docRelevance?: number;
  /**
   * Numbers of duplicated tokens. For example, duplicated tokens for a title
   * "dog cat cat cat" is 2 (for 2 extra "cat").
   */
  dupTokens?: number;
  /**
   * A score assigned for candidates forced by experiments.
   */
  forcedExperimentScore?: number;
  /**
   * The score for `text` computed in Goldmine (AlternativeTitlesAnnotator)
   * with additional scoring adjustments applied. Currently includes Blockbert
   * scoring.
   */
  goldmineAdjustedScore?: number;
  /**
   * =============================================================== Internal
   * boost feature signals used to compute `goldmine_page_score`. They are
   * exposed only for debugging purpose.
   */
  goldmineAnchorFactor?: number;
  goldmineAnchorSupportOnly?: number;
  goldmineBlockbertFactor?: number;
  goldmineBodyFactor?: number;
  /**
   * Deprecated: use `goldmine_page_score` instead.
   */
  goldmineFinalScore?: number;
  goldmineForeign?: number;
  goldmineGeometryFactor?: number;
  goldmineHasBoilerplateInTitle?: number;
  goldmineHasTitleNgram?: number;
  goldmineHeaderIsH1?: number;
  goldmineHeadingFactor?: number;
  goldmineIsBadTitle?: number;
  goldmineIsHeadingTag?: number;
  goldmineIsTitleTag?: number;
  goldmineIsTruncated?: number;
  goldmineLocalTitleFactor?: number;
  goldmineLocationFactor?: number;
  goldmineNavboostFactor?: number;
  goldmineOgTitleFactor?: number;
  goldmineOnPageDemotionFactor?: number;
  /**
   * The number of BoostFeatures present in AlternativeTitlesGeneator but not
   * populated above.
   */
  goldmineOtherBoostFeatureCount?: number;
  /**
   * The score for the `text` computed in Goldmine
   * (AlternativeTitlesAnnotator).
   */
  goldminePageScore?: number;
  goldmineReadabilityScore?: number;
  goldmineSalientTermFactor?: number;
  goldmineSitenameFactor?: number;
  goldmineSubHeading?: number;
  goldmineTitleTagFactor?: number;
  goldmineTrustFactor?: number;
  goldmineUrlMatchFactor?: number;
  /**
   * Whether a title contains site information.
   */
  hasSiteInfo?: boolean;
  /**
   * Whether this title candidate is truncated or not.
   */
  isTruncated?: boolean;
  /**
   * Whether a title is valid (i.e., not empty).
   */
  isValid?: boolean;
  /**
   * Numbers of body title tokens covered by this title, in range of [0, 1].
   * Not set if body title is considered "bad".
   */
  percentBodyTitleTokensCovered?: number;
  /**
   * Numbers of tokens covered by body title, in range of [0, 1]. Not set if
   * body title is considered "bad".
   */
  percentTokensCoveredByBodyTitle?: number;
  /**
   * How good or bad this title is as a `data_source_type` title type.
   */
  perTypeQuality?:  | "UNKNOWN_QUALITY" | "VERY_GOOD" | "GOOD" | "NORMAL" | "BAD";
  /**
   * Rank of this title among titles of the same `data_source_type`.
   */
  perTypeRank?: number;
  /**
   * The number of (different) terms with a query match. It may include the
   * match with any SQuery node (e.g., synonyms).
   */
  queryMatch?: number;
  /**
   * A number of matched query terms divided by the number of all terms in
   * query. Synonyms or other terms that appear in squery but not in the raw
   * query are excluded. Takes values in [0, 1].
   */
  queryMatchFraction?: number;
  /**
   * Represents how relavant this title candidate is to the query. Ranged in
   * [0, 1], and this signal is basically calculated as Cosine-similarity
   * between QBST term vector and pQ2T model of title candidate sentence.
   */
  queryRelevance?: number;
  sourceGeometry?: boolean;
  sourceHeadingTag?: boolean;
  sourceLocalTitle?: boolean;
  sourceOffdomainAnchor?: boolean;
  sourceOndomainAnchor?: boolean;
  sourceOnsiteAnchor?: boolean;
  /**
   * =============================================================== Title
   * candidate's original source information. They are populated only for
   * non-production environment for debugging purposes.
   */
  sourceTitleTag?: boolean;
  sourceTransliteratedTitle?: boolean;
  /**
   * `goldmine_final_score` value in test.
   */
  testGoldmineFinalScore?: number;
  /**
   * The ranking index of this candidate (starting from 0) in test.
   */
  testRank?: number;
  /**
   * Title text to display. Populated for debugging purpose only, and won't be
   * used for model inferences. This represetns the exact display text in SERP,
   * with modifications like truncations or site-title appending involved.
   */
  text?: string;
  /**
   * A rendered width of this title divided by the max allowed width for title.
   * Takes values in [0, 1].
   */
  widthFraction?: number;
}

/**
 * Snippet brain scores.
 */
export interface QualityPreviewSnippetBrainFeatures {
  /**
   * Is the bolding triggered.
   */
  isSnippetBrainBoldingTriggered?: boolean;
  /**
   * The score by SnippetBrain model.
   */
  modelScore?: number;
}

/**
 * Document related features used in snippets scoring. Next ID: 10
 */
export interface QualityPreviewSnippetDocumentFeatures {
  experimentalTitleSalientTermsScore?: number;
  leadingtextDistanceScore?: number;
  metaBoostScore?: number;
  salientPositionBoostScore?: number;
  salientTermsScore?: number;
  schemaOrgDescriptionBoostScore?: number;
  unstableTokensScore?: number;
}

export interface QualityPreviewSnippetExperimentalFeatures {
  isLikelyHomepage?: boolean;
  numQueryItems?: number;
  numTidbits?: number;
  numVisibleTokens?: number;
  radish?: QualityPreviewSnippetRadishFeatures;
}

/**
 * Quality related features used in snippets scoring. Next ID: 10
 */
export interface QualityPreviewSnippetQualityFeatures {
  foreignMetaScore?: number;
  hiddenRatioScore?: number;
  numTidbitsScore?: number;
  numVisibleTokensScore?: number;
  outlinkScore?: number;
  redundancyScore?: number;
  sentenceStartScore?: number;
}

/**
 * Query related features used in snippets scoring. Next ID: 7
 */
export interface QualityPreviewSnippetQueryFeatures {
  experimentalQueryTitleScore?: number;
  passageembedScore?: number;
  queryHasPassageembedEmbeddings?: boolean;
  queryScore?: number;
  radishScore?: number;
}

/**
 * Snippet query term coverage features.
 */
export interface QualityPreviewSnippetQueryTermCoverageFeatures {
  snippetQueryTermCoverage?: number;
  titleQueryTermCoverage?: number;
  titleSnippetQueryTermCoverage?: number;
}

export interface QualityPreviewSnippetRadishFeatures {
  /**
   * Answer score of the passage for this `navboost_query`.
   */
  answerScore?: number;
  /**
   * Navboost query for this radish signal.
   */
  navboostQuery?: string;
  /**
   * The ratio of overlapping tokens between the radish passage and snippet
   * candidate.
   */
  passageCoverage?: number;
  /**
   * Integer value of indexing::annotations::wa_passages::Passage::Type.
   */
  passageType?: number;
  /**
   * The index of this passage under `navboost_query`.
   */
  queryPassageIdx?: number;
  /**
   * How the similarity score is computed. Integer value of
   * mustang_repos_www_snippets::RadishSignalScoringInfo::SimilarityMethod.
   */
  similarityMethod?: number;
  /**
   * Similarity score between this `navboost_query` and the incoming query.
   */
  similarityScore?: number;
  snippetCoverage?: number;
}

/**
 * Protocol message for data related to product sites. This data is stored as
 * signals data in docjoins.
 */
export interface QualityProductProductSiteData {
  /**
   * Data for each locale.
   */
  locale?: QualityProductProductSiteDataLocaleData[];
}

/**
 * Data for one locale.
 */
export interface QualityProductProductSiteDataLocaleData {
  /**
   * Site boosting multiplier.
   */
  boostFactor?: number;
  /**
   * Whether this is a gobi site, ie, a site from a gobi domain that should be
   * boosted for a category query with this gobi domain. For example, amazon.com
   * is a gobi store domain for category query [hdtv] but some sites (like
   * askville.amazon.com) from amazon.com should not be boosted.
   */
  gobiSite?: boolean;
  /**
   * Locale for this data.
   */
  locale?: string;
}

export interface QualityProseCSEUrlInfo {
  /**
   * There were defined back in 2007, but were never used. optional string
   * label = 2; optional uint64 user = 3; optional float score = 4;
   */
  cseId?: string;
}

/**
 * Used to annotate the source of cross-account personal data. See
 * go/cross-account-understanding.
 */
export interface QualityQrewriteAccountProvenance {
  dataSources?:  | "UNKNOWN_MULTI_ACCOUNT_DATA_SOURCE" | "PRODUCTIVITY_ACCOUNT" | "ASSISTANT_SHARED_CONTACT" | "CALENDAR_EVENT_TITLES"[];
  googleAccount?: QualityQrewriteAccountProvenanceGoogleAccount;
  /**
   * Note google_account and third_party_account could both exist. For example,
   * a user could share her Spotify account with other users registered on the
   * same device.
   */
  thirdPartyAccount?: QualityQrewriteAccountProvenanceThirdPartyAccount;
}

function serializeQualityQrewriteAccountProvenance(data: any): QualityQrewriteAccountProvenance {
  return {
    ...data,
    googleAccount: data["googleAccount"] !== undefined ? serializeQualityQrewriteAccountProvenanceGoogleAccount(data["googleAccount"]) : undefined,
    thirdPartyAccount: data["thirdPartyAccount"] !== undefined ? serializeQualityQrewriteAccountProvenanceThirdPartyAccount(data["thirdPartyAccount"]) : undefined,
  };
}

function deserializeQualityQrewriteAccountProvenance(data: any): QualityQrewriteAccountProvenance {
  return {
    ...data,
    googleAccount: data["googleAccount"] !== undefined ? deserializeQualityQrewriteAccountProvenanceGoogleAccount(data["googleAccount"]) : undefined,
    thirdPartyAccount: data["thirdPartyAccount"] !== undefined ? deserializeQualityQrewriteAccountProvenanceThirdPartyAccount(data["thirdPartyAccount"]) : undefined,
  };
}

/**
 * The Google account the annotated personal data belongs to.
 */
export interface QualityQrewriteAccountProvenanceGoogleAccount {
  email?: string;
  gaiaId?: bigint;
  isDasherAccount?: boolean;
  isSecondaryAccount?: boolean;
}

function serializeQualityQrewriteAccountProvenanceGoogleAccount(data: any): QualityQrewriteAccountProvenanceGoogleAccount {
  return {
    ...data,
    gaiaId: data["gaiaId"] !== undefined ? String(data["gaiaId"]) : undefined,
  };
}

function deserializeQualityQrewriteAccountProvenanceGoogleAccount(data: any): QualityQrewriteAccountProvenanceGoogleAccount {
  return {
    ...data,
    gaiaId: data["gaiaId"] !== undefined ? BigInt(data["gaiaId"]) : undefined,
  };
}

/**
 * The 3P account the annotated personal data belongs to.
 */
export interface QualityQrewriteAccountProvenanceThirdPartyAccount {
  /**
   * Email address of the linked account (eg foo@outlook.com).
   */
  email?: string;
  /**
   * Unique identifier for the third party provider. Defined by Google via AoG.
   */
  thirdPartyProviderId?: bigint;
}

function serializeQualityQrewriteAccountProvenanceThirdPartyAccount(data: any): QualityQrewriteAccountProvenanceThirdPartyAccount {
  return {
    ...data,
    thirdPartyProviderId: data["thirdPartyProviderId"] !== undefined ? String(data["thirdPartyProviderId"]) : undefined,
  };
}

function deserializeQualityQrewriteAccountProvenanceThirdPartyAccount(data: any): QualityQrewriteAccountProvenanceThirdPartyAccount {
  return {
    ...data,
    thirdPartyProviderId: data["thirdPartyProviderId"] !== undefined ? BigInt(data["thirdPartyProviderId"]) : undefined,
  };
}

/**
 * Alternative names with info like RecognitionAlternateSource indicating where
 * is it from.
 */
export interface QualityQrewriteAlternativeNameInfo {
  matchSignal?: AssistantVerticalsCommonContactMatchSignal;
  name?: string;
  source?:  | "NONE" | "S3_HYPOTHESES" | "GENIE_QUERY_ALTERNATIVES" | "NAME_CORRECTION_LOG" | "FUZZY_CONTACT_MATCH" | "NEURAL_CONTACT_MATCH" | "NEURAL_CONTACT_MATCH_DARK_LAUNCH";
}

export interface QualityQrewriteCalendarReference {
  calendarAlias?: QualityQrewriteQRewriteAccountAwareCalendarAliasWrapper;
  contactCalendarName?: QualityQrewriteContactCalendarName;
  familyCalendarAlias?: QualityQrewriteFamilyCalendarAlias;
  primaryCalendarAlias?: QualityQrewritePrimaryCalendarAlias;
}

function serializeQualityQrewriteCalendarReference(data: any): QualityQrewriteCalendarReference {
  return {
    ...data,
    contactCalendarName: data["contactCalendarName"] !== undefined ? serializeQualityQrewriteContactCalendarName(data["contactCalendarName"]) : undefined,
  };
}

function deserializeQualityQrewriteCalendarReference(data: any): QualityQrewriteCalendarReference {
  return {
    ...data,
    contactCalendarName: data["contactCalendarName"] !== undefined ? deserializeQualityQrewriteContactCalendarName(data["contactCalendarName"]) : undefined,
  };
}

/**
 * A complete query candidate Id includes a list of Id fields. The Id field
 * order is maintained as the order by which each field is appended to the list.
 */
export interface QualityQrewriteCandidateId {
  field?: QualityQrewriteCandidateIdField[];
}

/**
 * The message represents a field in the query candidate Id.
 */
export interface QualityQrewriteCandidateIdField {
  /**
   * If needed, a servlet can use this field to assign an ID to distinguish
   * between different candidates of the same CandidateType.
   */
  index?: number;
  type?:  | "CANDIDATE_TYPE_UNSPECIFIED" | "IDENTITY" | "SPELLING" | "S3_TOP_HYPOTHESIS" | "AUTO_TRANSLATE" | "ADS_ALTERNATIVE_RUN" | "NEARBY_RETRIEVAL" | "CONTEXTUAL_REWRITE" | "SAFT_TOKENIZER" | "CONVO_FPR" | "SPOKEN_INTENT" | "AUTO_TRANSLATE_ARGUMENT_TRANSFER" | "CONTEXT_AWARE_SPEECH_RECOGNITION_REWRITE" | "MAST" | "FUZZY_MATCHER_REWRITE" | "SHOPPING_PREFERENCES_REWRITE" | "MAGI_CONTEXT_ENGINE_REWRITE";
}

export interface QualityQrewriteContactCalendarName {
  contact?: NlpSemanticParsingModelsPersonPerson;
}

function serializeQualityQrewriteContactCalendarName(data: any): QualityQrewriteContactCalendarName {
  return {
    ...data,
    contact: data["contact"] !== undefined ? serializeNlpSemanticParsingModelsPersonPerson(data["contact"]) : undefined,
  };
}

function deserializeQualityQrewriteContactCalendarName(data: any): QualityQrewriteContactCalendarName {
  return {
    ...data,
    contact: data["contact"] !== undefined ? deserializeNlpSemanticParsingModelsPersonPerson(data["contact"]) : undefined,
  };
}

export interface QualityQrewriteFamilyCalendarAlias {
  familyCalendarId?: string;
}

/**
 * Contact metadata Next Id: 36
 */
export interface QualityQrewritePersonalContactData {
  /**
   * Tracks the account owner of this contact. See
   * go/cross-account-understanding.
   */
  accountProvenance?: QualityQrewriteAccountProvenance;
  /**
   * Other metadata relating with the contact. This field is added so that the
   * value can be copied to the corresponding field
   * |additional_contact_metadata| in person.proto, that later will be logged to
   * Assistant Interaction Event footprint from client side.
   */
  additionalContactMetadata?: {
    [key: string]: any
  }[];
  /**
   * Populated only if matched_name_type is GIVEN_NAME_ALIAS or
   * FULL_NAME_ALIAS.
   */
  commonNameAliasConfidence?: number;
  /**
   * Concept id for relationships in query language, e.g. "Mother" in English,
   * "Mre" in French. It's only populated for source = RELATIONSHIP.
   */
  conceptId?: string;
  /**
   * Concept id for relationships in English, e.g. "Mother" for all non-English
   * locales. It's only populated for source = RELATIONSHIP. It is used as the
   * key to store relationship in memory (see http://go/assistant-relationship).
   * For English, this field is not filled, and we will use concept_id field as
   * the relationship key in memory.
   */
  conceptIdEn?: string;
  /**
   * TODO(shuaiwang) these are kept here temporarily because aqua regression
   * tests are still referring to them, migrating aqua regression tests to use
   * the new person_data field depends on binary change (i.e. this proto change)
   * so there's a period we need to keep both.
   */
  displayName?: string;
  familyName?: string;
  /**
   * The ffrac score of the suggested contact from Starlight.
   */
  ffracScore?: number;
  gaiaId?: bigint;
  givenName?: string;
  /**
   * Whether we have address info for this contact. IMPORTANT, READ BEFORE
   * USING THIS FIELD: - This is a temporary solution to export this info for
   * device contacts. - This could only be set for device contacts, contacts
   * from other sources won't have this bit set even if there's address
   * available inside person_data. - This will go away once Starlight supports
   * device contacts, addresses will be available inside person_data the same
   * way as Focus contacts. TODO(shuaiwang) remove after b/20412551
   */
  hasAddressForDeviceContacts?: boolean;
  hasGplusProfile?: boolean;
  /**
   * If the contact data is from on device lookup.
   */
  isFromOnDeviceLookup?: boolean;
  /**
   * Indicate the contact matches the transliterated query.
   */
  isTransliteratedMatch?: boolean;
  /**
   * If the lookup was done using relationship which is visible to guests. This
   * value will only be set if lookup was done using relationship. E.g. user has
   * a guest relationship (doctor) -> (John) And user says "call doctor", then
   * this value will be true.
   */
  isVisibleToGuestsRelationship?: boolean;
  lookupNameSource?:  | "UNKNOWN" | "SPELLING";
  /**
   * LINT.ThenChange(//depot/google3/assistant/verticals/communication/\
   * fulfillment/proto/contact_logging_enums.proto,
   * //depot/google3/assistant/api/dialog_state/values/person.proto,
   * //depot/google3/assistant/context/proto/person.proto)
   */
  matchedNameType?:  | "UNSPECIFIED" | "GIVEN_NAME" | "FAMILY_NAME" | "FULL_NAME" | "NICKNAME" | "OTHER" | "INITIAL_WITH_FAMILY_NAME" | "EMAIL_USERNAME" | "VANITY_NICKNAME" | "GIVEN_NAME_ALIAS" | "FULL_NAME_ALIAS" | "HOMOPHONE_GIVEN_NAME" | "HOMOPHONE_FAMILY_NAME" | "HOMOPHONE_FULL_NAME" | "HOMOPHONE_NICKNAME" | "GIVEN_MIDDLE_NAME" | "GIVEN_NAME_WITH_FAMILY_NAME_INITIAL" | "EMAIL_OF_FAMILY_MEMBER";
  /**
   * Alternate name from recognition that has contact matched. Need this to
   * make name correction history log consistent.
   */
  matchedRecognitionAlternateName?: string;
  /**
   * Populate only if AlternateSource is not NONE.
   */
  matchSignal?: AssistantVerticalsCommonContactMatchSignal;
  /**
   * Log version of PersonalContactData. Holds e.g. FUZZY match results. It is
   * populated in NamedContactFrame when fuzzy match is performed:
   * http://google3/quality/dialog_manager/frames/contact/named_contact_frame.cc?l=255&rcl=331994299
   * Currently only fuzzy ngram match results are logged here.
   */
  personalContactDataLog?: AssistantLogsCommunicationPersonalContactDataLog;
  /**
   * Metadata such as name, email, phone, etc.
   */
  personData?: AppsPeopleOzExternalMergedpeopleapiPerson;
  /**
   * Contains information about a Copley Person resolution (go/copley-people).
   * This field is used to propagate metadata related to the resolved person,
   * used for attribution and logging. Meaningful data (addresses, phone
   * numbers) are copied into person_data.
   */
  pkgPerson?: NlpSemanticParsingQRefAnnotation;
  pkgReferenceType?:  | "UNKNOWN_PKG_REFERENCE_TYPE" | "PKG_NAME_REFERENCE" | "PKG_RELATIONSHIP_REFERENCE";
  /**
   * Populate only if AlternateSource is not NONE.
   */
  recognitionAlternateScore?: number;
  /**
   * If not none, then it indicates the personal contact data is alternate and
   * how the alternate is fulfilled.
   */
  recognitionAlternateSource?:  | "NONE" | "S3_HYPOTHESES" | "GENIE_QUERY_ALTERNATIVES" | "NAME_CORRECTION_LOG" | "FUZZY_CONTACT_MATCH" | "NEURAL_CONTACT_MATCH" | "NEURAL_CONTACT_MATCH_DARK_LAUNCH";
  /**
   * Lexical information for relationships in query language, e.g. "Mother" in
   * English, "Mre" in French. It's only populated for source = RELATIONSHIP.
   */
  relationshipLexicalInfo?: CopleyLexicalMetadata;
  /**
   * Resolved relationship names and contact pointers from Assistant Memory.
   * This field is populated into both relationship annotation (source =
   * RELATIONSHIP) and Focus/device contacts retrieved by that contact name. The
   * data from Assistant Memory comes from two different columns:
   * ASSISTANT_SETTINGS and PWS_CONTACT_ANNOTATION. We support multiple people
   * with same relationship (e.g. multiple brothers) by using a repeated
   * relationship_memory field. Examples are at
   * go/person-subgrammar-relationship.
   */
  relationshipMemory?: QualityQrewriteRelationshipMemoryData[];
  /**
   * Gaia ID of the user this contact belongs to. Only populates if contact is
   * shared from another user. See go/shared-contacts-assistant. E.g. user A
   * triggers the request and uses user B's contact data (which is marked as
   * visible to user A). This field will be populated with user B's gaia id.
   */
  sharedContactOwnerGaiaId?: bigint;
  /**
   * LINT.ThenChange(//depot/google3/assistant/verticals/communication/\
   * fulfillment/proto/contact_logging_enums.proto,
   * //depot/google3/assistant/api/dialog_state/values/person.proto) Data source
   * of the contact data.
   */
  source?:  | "FOCUS_CONTACT" | "DEVICE_CONTACT" | "GMAIL_INFERENCE" | "S3_DECORATOR" | "RELATIONSHIP" | "VANITY" | "SIGNED_OUT_DEVICE" | "SHARED_CONTACT" | "FAMILY_MEMBER" | "SHARED_DEVICE_USER" | "ON_DEVICE_CONTACT_LOOKUP";
}

function serializeQualityQrewritePersonalContactData(data: any): QualityQrewritePersonalContactData {
  return {
    ...data,
    accountProvenance: data["accountProvenance"] !== undefined ? serializeQualityQrewriteAccountProvenance(data["accountProvenance"]) : undefined,
    gaiaId: data["gaiaId"] !== undefined ? String(data["gaiaId"]) : undefined,
    personalContactDataLog: data["personalContactDataLog"] !== undefined ? serializeAssistantLogsCommunicationPersonalContactDataLog(data["personalContactDataLog"]) : undefined,
    personData: data["personData"] !== undefined ? serializeAppsPeopleOzExternalMergedpeopleapiPerson(data["personData"]) : undefined,
    pkgPerson: data["pkgPerson"] !== undefined ? serializeNlpSemanticParsingQRefAnnotation(data["pkgPerson"]) : undefined,
    relationshipMemory: data["relationshipMemory"] !== undefined ? data["relationshipMemory"].map((item: any) => (serializeQualityQrewriteRelationshipMemoryData(item))) : undefined,
    sharedContactOwnerGaiaId: data["sharedContactOwnerGaiaId"] !== undefined ? String(data["sharedContactOwnerGaiaId"]) : undefined,
  };
}

function deserializeQualityQrewritePersonalContactData(data: any): QualityQrewritePersonalContactData {
  return {
    ...data,
    accountProvenance: data["accountProvenance"] !== undefined ? deserializeQualityQrewriteAccountProvenance(data["accountProvenance"]) : undefined,
    gaiaId: data["gaiaId"] !== undefined ? BigInt(data["gaiaId"]) : undefined,
    personalContactDataLog: data["personalContactDataLog"] !== undefined ? deserializeAssistantLogsCommunicationPersonalContactDataLog(data["personalContactDataLog"]) : undefined,
    personData: data["personData"] !== undefined ? deserializeAppsPeopleOzExternalMergedpeopleapiPerson(data["personData"]) : undefined,
    pkgPerson: data["pkgPerson"] !== undefined ? deserializeNlpSemanticParsingQRefAnnotation(data["pkgPerson"]) : undefined,
    relationshipMemory: data["relationshipMemory"] !== undefined ? data["relationshipMemory"].map((item: any) => (deserializeQualityQrewriteRelationshipMemoryData(item))) : undefined,
    sharedContactOwnerGaiaId: data["sharedContactOwnerGaiaId"] !== undefined ? BigInt(data["sharedContactOwnerGaiaId"]) : undefined,
  };
}

export interface QualityQrewritePrimaryCalendarAlias {
}

/**
 * A calendar alias wrapper used for query annotation. Aliases values are
 * defined in the extension with build visibility restrictions as they may
 * contain data from an account other than the user's primary account. This
 * proto is used as an metadata output from the QRewrite annotation. It can be
 * used for calendar aliases from different sources i.e. aliases based on the
 * domain of the account associated with the calendar
 * (go/calendar-aliases-annotation).
 */
export interface QualityQrewriteQRewriteAccountAwareCalendarAliasWrapper {
}

/**
 * Relationship->contact data provided by Assistant Memory.
 */
export interface QualityQrewriteRelationshipMemoryData {
  /**
   * The contact pointer. See http://go/assistant-contact-id.
   */
  contactPointer?: FocusBackendContactPointer;
  /**
   * The contact name copied from UserAttribute.value.
   */
  value?: string;
}

function serializeQualityQrewriteRelationshipMemoryData(data: any): QualityQrewriteRelationshipMemoryData {
  return {
    ...data,
    contactPointer: data["contactPointer"] !== undefined ? serializeFocusBackendContactPointer(data["contactPointer"]) : undefined,
  };
}

function deserializeQualityQrewriteRelationshipMemoryData(data: any): QualityQrewriteRelationshipMemoryData {
  return {
    ...data,
    contactPointer: data["contactPointer"] !== undefined ? deserializeFocusBackendContactPointer(data["contactPointer"]) : undefined,
  };
}

/**
 * Used as Mustang attachment DO NOT: - ACCESS THE PROTO FIELDS DIRECTLY - USE
 * THE DECODING LIBRARY IN
 * quality/rankembed/mustang/fixed_point_decoding_helpers.h INSTEAD. - USE
 * HARDCODED MustangRankEmbedInfo TEXT PROTOS IN TESTS! USE
 * quality/rankembed/test_utils/mustang_rankembed_info_utils.h INSTEAD.
 */
export interface QualityRankembedMustangMustangRankEmbedInfo {
  /**
   * Each uint64 encodes 8 8-bit values for the quantized document embedding
   */
  compressedDocumentEmbedding?: QualityRankembedMustangMustangRankEmbedInfoCompressedEmbedding;
  /**
   * This field replaces the above 3 "per-encoding-type-fields", where the
   * encoding type (and the embedding type) are part of the encoding, and is
   * stored in the first byte. The remaining bytes are the same as the previous
   * 3 fields, but shifted by 1 byte. - byte[0]: encoding type & embedding type
   * - byte[1....]: similar to the above depending on the encoding type.
   */
  fixedPointEncoding?: Uint8Array;
  /**
   * - byte[0]: version - bytes[1...4]: scalar - bytes[5,...]: the values, one
   * byte per 2 values
   */
  scaledFixedPoint4Encoding?: Uint8Array;
  /**
   * - byte[0]: version - bytes[1...4]: scalar - bytes[5,...]: the values, one
   * byte per value
   */
  scaledFixedPoint8Encoding?: Uint8Array;
  /**
   * - byte[0]: version - bytes[1...4]: scalar - bytes[5...8]: shift -
   * bytes[9,...]: the values, one byte per 2 values
   */
  scaledShiftedFixedPoint4Encoding?: Uint8Array;
  /**
   * First 7 bits encode the version, then each chunck of 5 bits encode the
   * index of a potential improv query (lsb to msb)
   * -------|-----|-----|-----|-----|----- version| id1 | id2 | id3 | id4 | id5
   * where id1 is the index of the first improv query in the improv debug table.
   * As of cl/270008220, this field only contains the version info. For backward
   * compatibility, version still only uses the first 7 bits, and is still
   * prepended by 5 1 bits.
   */
  versionAndImprovInfo?: number;
}

function serializeQualityRankembedMustangMustangRankEmbedInfo(data: any): QualityRankembedMustangMustangRankEmbedInfo {
  return {
    ...data,
    compressedDocumentEmbedding: data["compressedDocumentEmbedding"] !== undefined ? serializeQualityRankembedMustangMustangRankEmbedInfoCompressedEmbedding(data["compressedDocumentEmbedding"]) : undefined,
    fixedPointEncoding: data["fixedPointEncoding"] !== undefined ? encodeBase64(data["fixedPointEncoding"]) : undefined,
    scaledFixedPoint4Encoding: data["scaledFixedPoint4Encoding"] !== undefined ? encodeBase64(data["scaledFixedPoint4Encoding"]) : undefined,
    scaledFixedPoint8Encoding: data["scaledFixedPoint8Encoding"] !== undefined ? encodeBase64(data["scaledFixedPoint8Encoding"]) : undefined,
    scaledShiftedFixedPoint4Encoding: data["scaledShiftedFixedPoint4Encoding"] !== undefined ? encodeBase64(data["scaledShiftedFixedPoint4Encoding"]) : undefined,
  };
}

function deserializeQualityRankembedMustangMustangRankEmbedInfo(data: any): QualityRankembedMustangMustangRankEmbedInfo {
  return {
    ...data,
    compressedDocumentEmbedding: data["compressedDocumentEmbedding"] !== undefined ? deserializeQualityRankembedMustangMustangRankEmbedInfoCompressedEmbedding(data["compressedDocumentEmbedding"]) : undefined,
    fixedPointEncoding: data["fixedPointEncoding"] !== undefined ? decodeBase64(data["fixedPointEncoding"] as string) : undefined,
    scaledFixedPoint4Encoding: data["scaledFixedPoint4Encoding"] !== undefined ? decodeBase64(data["scaledFixedPoint4Encoding"] as string) : undefined,
    scaledFixedPoint8Encoding: data["scaledFixedPoint8Encoding"] !== undefined ? decodeBase64(data["scaledFixedPoint8Encoding"] as string) : undefined,
    scaledShiftedFixedPoint4Encoding: data["scaledShiftedFixedPoint4Encoding"] !== undefined ? decodeBase64(data["scaledShiftedFixedPoint4Encoding"] as string) : undefined,
  };
}

export interface QualityRankembedMustangMustangRankEmbedInfoCompressedEmbedding {
  /**
   * using fixed64 instead of uint64 saves ~14% is storage
   */
  packedValue?: bigint[];
  value?: bigint[];
}

function serializeQualityRankembedMustangMustangRankEmbedInfoCompressedEmbedding(data: any): QualityRankembedMustangMustangRankEmbedInfoCompressedEmbedding {
  return {
    ...data,
    packedValue: data["packedValue"] !== undefined ? data["packedValue"].map((item: any) => (String(item))) : undefined,
    value: data["value"] !== undefined ? data["value"].map((item: any) => (String(item))) : undefined,
  };
}

function deserializeQualityRankembedMustangMustangRankEmbedInfoCompressedEmbedding(data: any): QualityRankembedMustangMustangRankEmbedInfoCompressedEmbedding {
  return {
    ...data,
    packedValue: data["packedValue"] !== undefined ? data["packedValue"].map((item: any) => (BigInt(item))) : undefined,
    value: data["value"] !== undefined ? data["value"].map((item: any) => (BigInt(item))) : undefined,
  };
}

/**
 * A subset of LaunchableApplication, which is stored in the PerDocData proto
 * (indexer/perdocdata/perdocdata.proto) and thus stored in the Search Mustang
 * index. It is used to identify documents containing app links at serving time
 * by SuperRoot. A subset of LaunchableApplication is used to save on storage
 * requirements.
 */
export interface QualityRichsnippetsAppsProtosLaunchableAppPerDocData {
  indexStatus?:  | "DISCOVERED" | "VALIDATED";
  /**
   * Android package id of the application associated with this document
   * (example: 'com.imdb.mobile'), encoded with the Fingerprint2011() function.
   */
  packageIdFingerprint?: bigint;
  /**
   * A subset of the data in the PerAppInfo message, encoded to save on space.
   * See quality/calypso/utils/app_info_utils.h for encoding/decoding.
   */
  perAppInfoEncoded?: bigint;
}

function serializeQualityRichsnippetsAppsProtosLaunchableAppPerDocData(data: any): QualityRichsnippetsAppsProtosLaunchableAppPerDocData {
  return {
    ...data,
    packageIdFingerprint: data["packageIdFingerprint"] !== undefined ? String(data["packageIdFingerprint"]) : undefined,
    perAppInfoEncoded: data["perAppInfoEncoded"] !== undefined ? String(data["perAppInfoEncoded"]) : undefined,
  };
}

function deserializeQualityRichsnippetsAppsProtosLaunchableAppPerDocData(data: any): QualityRichsnippetsAppsProtosLaunchableAppPerDocData {
  return {
    ...data,
    packageIdFingerprint: data["packageIdFingerprint"] !== undefined ? BigInt(data["packageIdFingerprint"]) : undefined,
    perAppInfoEncoded: data["perAppInfoEncoded"] !== undefined ? BigInt(data["perAppInfoEncoded"]) : undefined,
  };
}

export interface QualityRichsnippetsAppsProtosLaunchAppInfoPerDocData {
  app?: QualityRichsnippetsAppsProtosLaunchableAppPerDocData[];
}

function serializeQualityRichsnippetsAppsProtosLaunchAppInfoPerDocData(data: any): QualityRichsnippetsAppsProtosLaunchAppInfoPerDocData {
  return {
    ...data,
    app: data["app"] !== undefined ? data["app"].map((item: any) => (serializeQualityRichsnippetsAppsProtosLaunchableAppPerDocData(item))) : undefined,
  };
}

function deserializeQualityRichsnippetsAppsProtosLaunchAppInfoPerDocData(data: any): QualityRichsnippetsAppsProtosLaunchAppInfoPerDocData {
  return {
    ...data,
    app: data["app"] !== undefined ? data["app"].map((item: any) => (deserializeQualityRichsnippetsAppsProtosLaunchableAppPerDocData(item))) : undefined,
  };
}

/**
 * This is a measure of how salient this country is for the document.
 */
export interface QualitySalientCountriesSalientCountry {
  /**
   * 2-letter country format.
   */
  country?: string;
  /**
   * How salient this country is for the document. [0,1] range.
   */
  salience?: number;
}

/**
 * Set of SalientCountry for a document.
 */
export interface QualitySalientCountriesSalientCountrySet {
  /**
   * Packed Country and salience optimized for index storage
   */
  packedCountry?: number[];
  packedSalience?: number[];
  salientCountry?: QualitySalientCountriesSalientCountry[];
}

/**
 * DocData contains additional salient-term-set-level information that
 * complements a SalientTermSet.
 */
export interface QualitySalientTermsDocData {
  /**
   * confidence is a measurement of how much data we had to compute the
   * SalientTermSet. Range: [0.0, 1.0]
   */
  confidence?: number;
  /**
   * head_volume_ratio is the ratio of the sum of term frequency of the top K
   * terms over the volume of all terms. Range: [0.0, 1.0]. K is defined by
   * Accumulator2Params::head_size.
   */
  headVolumeRatio?: number;
  /**
   * language is the main language of this SalientTermSet.
   */
  language?:  | "ENGLISH" | "DANISH" | "DUTCH" | "FINNISH" | "FRENCH" | "GERMAN" | "HEBREW" | "ITALIAN" | "JAPANESE" | "KOREAN" | "NORWEGIAN" | "POLISH" | "PORTUGUESE" | "RUSSIAN" | "SPANISH" | "SWEDISH" | "CHINESE" | "CZECH" | "GREEK" | "ICELANDIC" | "LATVIAN" | "LITHUANIAN" | "ROMANIAN" | "HUNGARIAN" | "ESTONIAN" | "TG_UNKNOWN_LANGUAGE" | "UNKNOWN_LANGUAGE" | "BULGARIAN" | "CROATIAN" | "SERBIAN" | "IRISH" | "GALICIAN" | "TAGALOG" | "TURKISH" | "UKRAINIAN" | "HINDI" | "MACEDONIAN" | "BENGALI" | "INDONESIAN" | "LATIN" | "MALAY" | "MALAYALAM" | "WELSH" | "NEPALI" | "TELUGU" | "ALBANIAN" | "TAMIL" | "BELARUSIAN" | "JAVANESE" | "OCCITAN" | "URDU" | "BIHARI" | "GUJARATI" | "THAI" | "ARABIC" | "CATALAN" | "ESPERANTO" | "BASQUE" | "INTERLINGUA" | "KANNADA" | "PUNJABI" | "SCOTS_GAELIC" | "SWAHILI" | "SLOVENIAN" | "MARATHI" | "MALTESE" | "VIETNAMESE" | "FRISIAN" | "SLOVAK" | "CHINESE_T" | "FAROESE" | "SUNDANESE" | "UZBEK" | "AMHARIC" | "AZERBAIJANI" | "GEORGIAN" | "TIGRINYA" | "PERSIAN" | "BOSNIAN" | "SINHALESE" | "NORWEGIAN_N" | "PORTUGUESE_P" | "PORTUGUESE_B" | "XHOSA" | "ZULU" | "GUARANI" | "SESOTHO" | "TURKMEN" | "KYRGYZ" | "BRETON" | "TWI" | "YIDDISH" | "SERBO_CROATIAN" | "SOMALI" | "UIGHUR" | "KURDISH" | "MONGOLIAN" | "ARMENIAN" | "LAOTHIAN" | "SINDHI" | "RHAETO_ROMANCE" | "AFRIKAANS" | "LUXEMBOURGISH" | "BURMESE" | "KHMER" | "TIBETAN" | "DHIVEHI" | "CHEROKEE" | "SYRIAC" | "LIMBU" | "ORIYA" | "ASSAMESE" | "CORSICAN" | "INTERLINGUE" | "KAZAKH" | "LINGALA" | "MOLDAVIAN" | "PASHTO" | "QUECHUA" | "SHONA" | "TAJIK" | "TATAR" | "TONGA" | "YORUBA" | "CREOLES_AND_PIDGINS_ENGLISH_BASED" | "CREOLES_AND_PIDGINS_FRENCH_BASED" | "CREOLES_AND_PIDGINS_PORTUGUESE_BASED" | "CREOLES_AND_PIDGINS_OTHER" | "MAORI" | "WOLOF" | "ABKHAZIAN" | "AFAR" | "AYMARA" | "BASHKIR" | "BISLAMA" | "DZONGKHA" | "FIJIAN" | "GREENLANDIC" | "HAUSA" | "HAITIAN_CREOLE" | "INUPIAK" | "INUKTITUT" | "KASHMIRI" | "KINYARWANDA" | "MALAGASY" | "NAURU" | "OROMO" | "RUNDI" | "SAMOAN" | "SANGO" | "SANSKRIT" | "SISWANT" | "TSONGA" | "TSWANA" | "VOLAPUK" | "ZHUANG" | "KHASI" | "SCOTS" | "GANDA" | "MANX" | "MONTENEGRIN" | "AKAN" | "IGBO" | "MAURITIAN_CREOLE" | "HAWAIIAN" | "CEBUANO" | "EWE" | "GA" | "HMONG" | "KRIO" | "LOZI" | "LUBA_LULUA" | "LUO_KENYA_AND_TANZANIA" | "NEWARI" | "NYANJA" | "OSSETIAN" | "PAMPANGA" | "PEDI" | "RAJASTHANI" | "SESELWA_CREOLE_FRENCH" | "TUMBUKA" | "VENDA" | "WARAY_PHILIPPINES" | "NUM_LANGUAGES";
  /**
   * signal_data contains signal-specific (e.g., body, anchors, clicks) data
   * for this SalientTermSet.
   */
  signalData?: QualitySalientTermsSignalData[];
  /**
   * virtual_volume is a measurement of how much data we had to compute the
   * SalientTermSet. Range: [0.0, +infinity)].
   */
  virtualVolume?: number;
}

/**
 * SalientTerm can be two things depending on where this message is. When right
 * under a SalientTermSet, it is a normalized term and weight pair, along with
 * other term-level data. When under another SalientTerm message, it is a
 * non-normalized original term (see original_term field).
 */
export interface QualitySalientTermsSalientTerm {
  /**
   * idf of the original_term. Used by Accumulator2. This field is only
   * available in debug mode.
   */
  idf?: number;
  /**
   * label can be two things depending on where this message is. When right
   * under a SalientTermSet, it is the normalized term returned by
   * quality_salient_terms::utils::NormalizeTerm() from salient_terms_utils.h.
   * When under another SalientTerm message, it is the original term as found in
   * a signal (see original_term field).
   */
  label?: string;
  /**
   * original_term are the different ways we found this normalized term in the
   * signals. They are in increasing idf order (the most common version first).
   * An empty string means that this original term is the same as the label
   * field in the parent SalientTerm message. NOTE: Please do not access this
   * field directly. Use quality_salient_terms::utils::OriginalTermsIterator
   * from salient_terms_utils.h instead.
   */
  originalTerm?: QualitySalientTermsSalientTerm[];
  /**
   * salience is the importance of the term as a descriptor in [0, 1] (the
   * higher the more important). This field takes precedence over weight field
   * below. NOTE: Please do not access this field directly. Use
   * quality_salient_terms::utils::GetSalience() from salient_terms_utils.h
   * instead.
   */
  salience?: number;
  /**
   * signal_term contains extra signal-specific (e.g., body, anchors, clicks)
   * data for this term.
   */
  signalTerm?: QualitySalientTermsSignalTermData[];
  /**
   * virtual_tf is the accumulated corrected term frequency from all the
   * signals. This field is only available in debug mode.
   */
  virtualTf?: number;
  /**
   * weight is the importance of the term as a descriptor in [0, 100] (the
   * higher the more important). NOTE: Please do not access this field directly.
   * Use quality_salient_terms::utils::GetSalience() from salient_terms_utils.h
   * instead. DEPRECATED: prefer salience field above.
   */
  weight?: number;
}

/**
 * SalientTermSet is a collection of terms (unigrams and bigrams) with
 * associated weights that can describe something. The "salient terms".
 */
export interface QualitySalientTermsSalientTermSet {
  /**
   * doc_data contain additional salient-term-set-level data.
   */
  docData?: QualitySalientTermsDocData;
  /**
   * salient_term is the list of terms that are good descriptors, sorted in
   * decreasing order of weight.
   */
  salientTerm?: QualitySalientTermsSalientTerm[];
  /**
   * version is the Salient Terms version used to create the SalientTermSet.
   * This is specific to web documents salient terms.
   */
  version?:  | "UNKNOWN" | "V1" | "V2" | "V2_1" | "V2_2" | "V3" | "V3_1" | "V3_2" | "V4" | "V4_1" | "V4_2" | "V5" | "V5_1" | "V5_2" | "V1_BODYONLY" | "V2_BODYONLY" | "RENAME_ME_TO_ADD_NEW_ENUM_16" | "RENAME_ME_TO_ADD_NEW_ENUM_17" | "RENAME_ME_TO_ADD_NEW_ENUM_18" | "RENAME_ME_TO_ADD_NEW_ENUM_19" | "RENAME_ME_TO_ADD_NEW_ENUM_20" | "RENAME_ME_TO_ADD_NEW_ENUM_21" | "RENAME_ME_TO_ADD_NEW_ENUM_22" | "RENAME_ME_TO_ADD_NEW_ENUM_23" | "RENAME_ME_TO_ADD_NEW_ENUM_24" | "RENAME_ME_TO_ADD_NEW_ENUM_25";
}

/**
 * SignalData stores signal-specific salient-term-set-level information. Stores
 * mostly internal data as it is one of the primary data structures used in the
 * populators.
 */
export interface QualitySalientTermsSignalData {
  /**
   * A fixed bias for this signal, the higher the stronger. This can be used to
   * balance the weight of signals independently of the confidence we give it.
   * This field is only available in debug mode.
   */
  bias?: number;
  /**
   * The measurement of how much we trust this signal. Range: [0.0, 1.0] This
   * field is available is both debug and non-debug mode.
   */
  confidence?: number;
  /**
   * Raw saliences equal to half_salience will be equal to 0.5 normalized.
   * Range: [0, volume]. This field is only available in debug mode.
   */
  halfSalience?: number;
  /**
   * The minimum TF for a term not to be considered noise. While the possible
   * range of values for this field is [0, observed_volume], it is expected to
   * be a somewhat small percentage of observed_volume (e.g. 5%). This field is
   * only available in debug mode.
   */
  noiseCorrection?: number;
  /**
   * The measurement of how much we trust this signal, calculated using the
   * observed volume. Range: [0.0, 1.0] This field is only available in debug
   * mode.
   */
  observedConfidence?: number;
  /**
   * The amount of signal we observed for a document. Range: [0.0, +infinity)
   * This field is only available in debug mode.
   */
  observedVolume?: number;
  /**
   * The amount of raw signal we observed for a document. Range: [0.0,
   * +infinity) This field is only available in debug mode.
   */
  rawVolume?: number;
  /**
   * source is the type of the signal of this SignalData.
   */
  source?:  | "BODY" | "ANCHORS" | "CLICKS" | "TITLE" | "NAME" | "DATE" | "URL" | "ENTITY_NAVBOOST" | "SYNTHETIC_BODY";
  /**
   * The amount of signal left after applying all corrections. Range: [0.0,
   * +infinity) This field is only available in debug mode.
   */
  volume?: number;
}

/**
 * SignalTermData is signal-specific term-level information. Stores mostly
 * internal data as it is one of the primary data structures used in the
 * populators.
 */
export interface QualitySalientTermsSignalTermData {
  /**
   * The deduction of bigram counts from its unigram children. This field is
   * only available in debug mode.
   */
  bigramDiscountTf?: number;
  /**
   * How much we trust this bigram. For bigrams only. Range: [0.0, 1.0] This
   * field is only available in debug mode.
   */
  bigramness?: number;
  /**
   * Measures how topical this term is to a particular signal. A term like
   * "lincoln" in the Abraham Lincoln's Wikipedia page should have a centrality
   * close to 1.0 while non-central terms like "florida" should have a
   * centrality close to 0.0. Range: [0.0, 1.0] This field is only available in
   * debug mode.
   */
  centrality?: number;
  /**
   * The final term frequency for a particular term. This field is only
   * available in debug mode.
   */
  correctedTf?: number;
  /**
   * The term frequency we were expecting for a term given its IDF. Range: [0,
   * observed_volume] This field is only available in debug mode.
   */
  expectedTf?: number;
  /**
   * Global NPMI. For bigrams only. This is a measure of the quality of bigrams
   * calculated using IDF. Range: [-1.0, 1.0] This field is only available in
   * debug mode.
   */
  globalNpmi?: number;
  /**
   * The IDF of the label of a particular term. For a canonical term, this is
   * the mean IDF of its originals, weighted by their observed TF. This field is
   * only available in debug mode.
   */
  idf?: number;
  /**
   * Whether or not this term is a bigram. This field is only available in
   * debug mode.
   */
  isBigram?: boolean;
  /**
   * Raw string that identifies a particular term. This field is only available
   * in debug mode.
   */
  label?: string;
  /**
   * Local NPMI (normalized pointwise mutual information). For bigrams only.
   * This is a measure of the quality of bigrams calculated using observed TF.
   * Range: [-1.0, 1.0] This field is only available in debug mode.
   */
  localNpmi?: number;
  /**
   * The observed term frequency in a particular signal. This field is only
   * available in debug mode.
   */
  observedTf?: number;
  /**
   * The list of the original terms for a canonical. This is used in the
   * pipeline and it is not present in the final output. This field is only
   * available in debug mode.
   */
  originalTerm?: QualitySalientTermsSignalTermData[];
  /**
   * The raw term frequency in a particular signal. This field is only
   * available in debug mode.
   */
  rawTf?: number;
  /**
   * The measure of how important this term is in this signal. Range: [0.0,
   * 1.0] This field is only available in debug mode.
   */
  salience?: number;
  /**
   * source is the type of the signal of this SignalTermData.
   */
  source?:  | "BODY" | "ANCHORS" | "CLICKS" | "TITLE" | "NAME" | "DATE" | "URL" | "ENTITY_NAVBOOST" | "SYNTHETIC_BODY";
}

export interface QualitySherlockKnexAnnotation {
  item?: QualitySherlockKnexAnnotationItem[];
}

export interface QualitySherlockKnexAnnotationItem {
  /**
   * in [0, 1].
   */
  calibratedScore?: number;
  debugName?: string;
  /**
   * in /m/ or /g/.
   */
  equivalentMid?: string;
  /**
   * in [0, 1].
   */
  score?: number;
  version?: number;
}

/**
 * This proto is a lightweight version of ShoppingAnnotation in docjoin
 * attachment. We're doing a deep copy of protos defined in ShoppingAnnotation
 * so that we can control individual fields that will sit in Muppet. Data here
 * will be used for scoring organic shopping web results and previews. Many
 * shopping related signals, e.g., product review score, are also served from
 * this attachment. Next ID: 21
 */
export interface QualityShoppingShoppingAttachment {
  /**
   * Score from the blockbert article classifier model.
   * go/article-understanding-project
   */
  datasetModelArticleScore?: number;
  datasetModelBuyingGuideScore?: number;
  /**
   * From forum and qna confidence score * 100, http://go/sdu-ugc-page-intro
   */
  datasetModelForumListScore?: number;
  datasetModelForumSingleScore?: number;
  datasetModelIndirectAvailabilityScore?: number;
  datasetModelInStoreOnlyScore?: number;
  /**
   * From indexing.ml.PageType.confidence * 100 (DatasetModelAnnotation in
   * cdoc) go/sdu-shopping-page-intro
   */
  datasetModelMultiProductScore?: number;
  datasetModelProductComparisonScore?: number;
  datasetModelProductReviewScore?: number;
  datasetModelProductTopnScore?: number;
  datasetModelQnaListScore?: number;
  datasetModelQnaSingleScore?: number;
  datasetModelSingleProductScore?: number;
  datasetModelSoldOutScore?: number;
  /**
   * From indexing.badpages.CollapserInfo.expired_shopping_page_score * 100
   */
  expiredShoppingPageScore?: number;
  /**
   * From MagicPageTypeAnnotation.multiplicity.confidence_score * 100
   * Deprecated as of July 2020 when dataset_model_multi_product_score and
   * dataset_model_single_product_score were added.
   */
  multiProductScore?: number;
  product?: QualityShoppingShoppingAttachmentProduct[];
  /**
   * From ShoppingSiteClassifier.score * 100
   */
  shoppingSiteScore?: number;
  /**
   * From ShoppingSiteClassifierShopfab.score * 100
   */
  shoppingSiteScoreShopfab?: number;
  singleProductScore?: number;
}

function serializeQualityShoppingShoppingAttachment(data: any): QualityShoppingShoppingAttachment {
  return {
    ...data,
    product: data["product"] !== undefined ? data["product"].map((item: any) => (serializeQualityShoppingShoppingAttachmentProduct(item))) : undefined,
  };
}

function deserializeQualityShoppingShoppingAttachment(data: any): QualityShoppingShoppingAttachment {
  return {
    ...data,
    product: data["product"] !== undefined ? data["product"].map((item: any) => (deserializeQualityShoppingShoppingAttachmentProduct(item))) : undefined,
  };
}

export interface QualityShoppingShoppingAttachmentLocale {
  /**
   * Use integers for fast scoring. Note: 26 is UNKNOWN_LANGUAGE_ID, 0 is
   * UNKNOWN region, see i18n::languages::Language and
   * StableInternalRegionconverter Use -1 as default for both.
   */
  languageId?: number;
  regionId?: number;
}

/**
 * Moka product attribute facet (go/gx).
 */
export interface QualityShoppingShoppingAttachmentMokaFacetValue {
  facetId?: bigint;
  measureValue?: number;
  tagId?: bigint;
}

function serializeQualityShoppingShoppingAttachmentMokaFacetValue(data: any): QualityShoppingShoppingAttachmentMokaFacetValue {
  return {
    ...data,
    facetId: data["facetId"] !== undefined ? String(data["facetId"]) : undefined,
    tagId: data["tagId"] !== undefined ? String(data["tagId"]) : undefined,
  };
}

function deserializeQualityShoppingShoppingAttachmentMokaFacetValue(data: any): QualityShoppingShoppingAttachmentMokaFacetValue {
  return {
    ...data,
    facetId: data["facetId"] !== undefined ? BigInt(data["facetId"]) : undefined,
    tagId: data["tagId"] !== undefined ? BigInt(data["tagId"]) : undefined,
  };
}

export interface QualityShoppingShoppingAttachmentOffer {
  condition?:  | "CONDITION_UNKNOWN" | "CONDITION_NEW" | "CONDITION_REFURBISHED" | "CONDITION_USED" | "CONDITION_OTHER";
  controlType?:  | "OFFER_CONTROL_TYPE_UNKNOWN" | "OFFER_CONTROL_TYPE_MERCHANT_MANAGED" | "OFFER_CONTROL_TYPE_UNMANAGED";
  /**
   * fingerprint of original offer item_urland mobile_offer_url (if present) to
   * be able to understand if offer data came from different url.
   */
  fingerprintOfOfferUrls?: bigint[];
  /**
   * image_id is sorted and distinct for efficient search during serving.
   */
  imageId?: bigint[];
  /**
   * inferred_images are sorted by inferred_image_id for efficient search
   * during serving.
   */
  inferredImages?: ShoppingWebentityShoppingAnnotationInferredImage[];
  /**
   * Is the offer Lens buildable. The corresponding field in Shopping
   * Annotation is SurfaceSelection.
   */
  isLensBuildable?: boolean;
  /**
   * information about methods used to match offer with indexed url. See
   * shopping_annotation.proto
   */
  matchingType?: bigint;
  /**
   * account_id of the merchant in shopping systems.
   */
  merchantAccountId?: bigint;
  /**
   * merchant_item_id is meaningless without the merchant_account_id.
   */
  merchantItemId?: string;
  /**
   * direct to consumer brand merchant relationship
   */
  nonDisplayableBrandMerchantRelationship?:  | "OFFER_BRAND_MERCHANT_RELATIONSHIP_UNKNOWN" | "OFFER_BRAND_MERCHANT_RELATIONSHIP_DTC_CHANNEL";
  nonDisplayableCurrency?: string;
  /**
   * Normalized riskiness score for Organic destinations. It's in range
   * [1,1000] with 1 being the worst score and 1000 being the best.
   */
  nonDisplayableOrganicScoreMillis?: number;
  offerDocid?: bigint;
  refType?:  | "REFERENCE_TYPE_UNKNOWN" | "REFERENCE_TYPE_MAIN_OFFER_PAGE" | "REFERENCE_TYPE_OUTLINK";
  soriVersionId?: ShoppingWebentityShoppingAnnotationSoriVersionId;
}

function serializeQualityShoppingShoppingAttachmentOffer(data: any): QualityShoppingShoppingAttachmentOffer {
  return {
    ...data,
    fingerprintOfOfferUrls: data["fingerprintOfOfferUrls"] !== undefined ? data["fingerprintOfOfferUrls"].map((item: any) => (String(item))) : undefined,
    imageId: data["imageId"] !== undefined ? data["imageId"].map((item: any) => (String(item))) : undefined,
    inferredImages: data["inferredImages"] !== undefined ? data["inferredImages"].map((item: any) => (serializeShoppingWebentityShoppingAnnotationInferredImage(item))) : undefined,
    matchingType: data["matchingType"] !== undefined ? String(data["matchingType"]) : undefined,
    merchantAccountId: data["merchantAccountId"] !== undefined ? String(data["merchantAccountId"]) : undefined,
    offerDocid: data["offerDocid"] !== undefined ? String(data["offerDocid"]) : undefined,
    soriVersionId: data["soriVersionId"] !== undefined ? serializeShoppingWebentityShoppingAnnotationSoriVersionId(data["soriVersionId"]) : undefined,
  };
}

function deserializeQualityShoppingShoppingAttachmentOffer(data: any): QualityShoppingShoppingAttachmentOffer {
  return {
    ...data,
    fingerprintOfOfferUrls: data["fingerprintOfOfferUrls"] !== undefined ? data["fingerprintOfOfferUrls"].map((item: any) => (BigInt(item))) : undefined,
    imageId: data["imageId"] !== undefined ? data["imageId"].map((item: any) => (BigInt(item))) : undefined,
    inferredImages: data["inferredImages"] !== undefined ? data["inferredImages"].map((item: any) => (deserializeShoppingWebentityShoppingAnnotationInferredImage(item))) : undefined,
    matchingType: data["matchingType"] !== undefined ? BigInt(data["matchingType"]) : undefined,
    merchantAccountId: data["merchantAccountId"] !== undefined ? BigInt(data["merchantAccountId"]) : undefined,
    offerDocid: data["offerDocid"] !== undefined ? BigInt(data["offerDocid"]) : undefined,
    soriVersionId: data["soriVersionId"] !== undefined ? deserializeShoppingWebentityShoppingAnnotationSoriVersionId(data["soriVersionId"]) : undefined,
  };
}

/**
 * Next ID: 18
 */
export interface QualityShoppingShoppingAttachmentPBlock {
  /**
   * Field full_title may contain duplicate info from title and list_title.
   */
  fullTitle?: string;
  /**
   * Ordering for `image_docid`, and `image_info` are the same.
   */
  imageDocid?: bigint[];
  imageInfo?: QualityShoppingShoppingAttachmentPBlockImageInfo[];
  isFreeDelivery?: boolean;
  isFreeReturn?: boolean;
  listTitle?: string;
  maxPriceValue?: number;
  minPriceValue?: number;
  price?: string;
  priceCurrency?: string;
  priceValue?: number;
  /**
   * Product info extracted by Product Blocks go/sdu-shopping-page-intro and
   * go/product-block-extraction. Here is an example of a page with a ##
   * list_title (Shoes) and 3 blocks with their own titles: | Shoes | |
   * ---------------------| | * For Running | | ---------------------| | * Men's
   * Hiking | | ---------------------| ## | * Dress Shoes | The field full_title
   * is what we constructed to best describe the product in the block. For
   * example, for the above 3 blocks, their full_titles will contain info from
   * list_title: "Shoes For Running", "Shoes Men's Hiking", "Dress Shoes". Note
   * that the list_title is not repeated for the 3rd block Real sample pages:
   * http://screen/6UaoBtwWsLfbSKg http://screen/BDHRgDonKG3KcXu,
   * http://screen/53tLwNaX8mmYzDz
   */
  title?: string;
}

function serializeQualityShoppingShoppingAttachmentPBlock(data: any): QualityShoppingShoppingAttachmentPBlock {
  return {
    ...data,
    imageDocid: data["imageDocid"] !== undefined ? data["imageDocid"].map((item: any) => (String(item))) : undefined,
  };
}

function deserializeQualityShoppingShoppingAttachmentPBlock(data: any): QualityShoppingShoppingAttachmentPBlock {
  return {
    ...data,
    imageDocid: data["imageDocid"] !== undefined ? data["imageDocid"].map((item: any) => (BigInt(item))) : undefined,
  };
}

export interface QualityShoppingShoppingAttachmentPBlockImageInfo {
  height?: number;
  width?: number;
}

export interface QualityShoppingShoppingAttachmentProduct {
  aggregateRating?: ShoppingWebentityShoppingAnnotationProductRating;
  brandEntityId?: bigint;
  catalogId?: bigint;
  globalProductClusterId?: bigint;
  locale?: QualityShoppingShoppingAttachmentLocale;
  mokaFacet?: QualityShoppingShoppingAttachmentMokaFacetValue[];
  nonDisplayableDescription?: string;
  nonDisplayableTitle?: string;
  offer?: QualityShoppingShoppingAttachmentOffer;
  /**
   * Whether an outlink points to the same domain or off-domain. Only added if
   * the relationship is known, and the Offer has ref_type of OUTLINK.
   */
  outlinkDomainRelationship?:  | "OUTLINK_TARGET_RELATIONSHIP_UNKNOWN" | "OUTLINK_TARGET_RELATIONSHIP_SAME_DOMAIN" | "OUTLINK_TARGET_RELATIONSHIP_OFF_DOMAIN";
  /**
   * Client needs to make decision on which field to use when both
   * non_displayable_title and pblock.final_title are present.
   */
  pblock?: QualityShoppingShoppingAttachmentPBlock;
  productClusterMid?: bigint;
  /**
   * Organic product popularity.
   */
  productPopularity?: number;
  /**
   * Relevance embedding from ShoppingAnnotation.Product
   */
  relevanceEmbedding?: QualityRankembedMustangMustangRankEmbedInfo[];
  /**
   * Matched/Inferred weak product identity - set only if the
   * global_product_cluster_id is missing
   */
  weakGlobalProductClusterId?: bigint;
}

function serializeQualityShoppingShoppingAttachmentProduct(data: any): QualityShoppingShoppingAttachmentProduct {
  return {
    ...data,
    aggregateRating: data["aggregateRating"] !== undefined ? serializeShoppingWebentityShoppingAnnotationProductRating(data["aggregateRating"]) : undefined,
    brandEntityId: data["brandEntityId"] !== undefined ? String(data["brandEntityId"]) : undefined,
    catalogId: data["catalogId"] !== undefined ? String(data["catalogId"]) : undefined,
    globalProductClusterId: data["globalProductClusterId"] !== undefined ? String(data["globalProductClusterId"]) : undefined,
    mokaFacet: data["mokaFacet"] !== undefined ? data["mokaFacet"].map((item: any) => (serializeQualityShoppingShoppingAttachmentMokaFacetValue(item))) : undefined,
    offer: data["offer"] !== undefined ? serializeQualityShoppingShoppingAttachmentOffer(data["offer"]) : undefined,
    pblock: data["pblock"] !== undefined ? serializeQualityShoppingShoppingAttachmentPBlock(data["pblock"]) : undefined,
    productClusterMid: data["productClusterMid"] !== undefined ? String(data["productClusterMid"]) : undefined,
    relevanceEmbedding: data["relevanceEmbedding"] !== undefined ? data["relevanceEmbedding"].map((item: any) => (serializeQualityRankembedMustangMustangRankEmbedInfo(item))) : undefined,
    weakGlobalProductClusterId: data["weakGlobalProductClusterId"] !== undefined ? String(data["weakGlobalProductClusterId"]) : undefined,
  };
}

function deserializeQualityShoppingShoppingAttachmentProduct(data: any): QualityShoppingShoppingAttachmentProduct {
  return {
    ...data,
    aggregateRating: data["aggregateRating"] !== undefined ? deserializeShoppingWebentityShoppingAnnotationProductRating(data["aggregateRating"]) : undefined,
    brandEntityId: data["brandEntityId"] !== undefined ? BigInt(data["brandEntityId"]) : undefined,
    catalogId: data["catalogId"] !== undefined ? BigInt(data["catalogId"]) : undefined,
    globalProductClusterId: data["globalProductClusterId"] !== undefined ? BigInt(data["globalProductClusterId"]) : undefined,
    mokaFacet: data["mokaFacet"] !== undefined ? data["mokaFacet"].map((item: any) => (deserializeQualityShoppingShoppingAttachmentMokaFacetValue(item))) : undefined,
    offer: data["offer"] !== undefined ? deserializeQualityShoppingShoppingAttachmentOffer(data["offer"]) : undefined,
    pblock: data["pblock"] !== undefined ? deserializeQualityShoppingShoppingAttachmentPBlock(data["pblock"]) : undefined,
    productClusterMid: data["productClusterMid"] !== undefined ? BigInt(data["productClusterMid"]) : undefined,
    relevanceEmbedding: data["relevanceEmbedding"] !== undefined ? data["relevanceEmbedding"].map((item: any) => (deserializeQualityRankembedMustangMustangRankEmbedInfo(item))) : undefined,
    weakGlobalProductClusterId: data["weakGlobalProductClusterId"] !== undefined ? BigInt(data["weakGlobalProductClusterId"]) : undefined,
  };
}

/**
 * Sitelink candidates that is generated from breadcrumbs.
 */
export interface QualitySitemapBreadcrumbTarget {
  docs?: QualitySitemapBreadcrumbTargetDoc[];
}

export interface QualitySitemapBreadcrumbTargetDoc {
  /**
   * The number of web pages that contains the url in their breadcrumbs.
   */
  count?: number;
  title?: string;
  url?: string;
}

export interface QualitySitemapCoClickTarget {
  docs?: QualitySitemapCoClickTargetDoc[];
  language?: string;
}

export interface QualitySitemapCoClickTargetDoc {
  coClickByLocale?: QualitySitemapCoClickTargetDocCoClickByLocale[];
  title?: string;
  url?: string;
}

export interface QualitySitemapCoClickTargetDocCoClickByLocale {
  coClicks?: number;
  coClicksCapped?: number;
  coClicksParent?: number;
  locale?: string;
}

/**
 * Scoring signals for computing the sitelink score. This message is currently
 * intended only for debugging. Accordingly, this is populated in CDoc but not
 * in MDU. It is enforced by the [(exclude_from_mdu) = true] annotation of the
 * corresponding fields in Target and TargetGroup.
 */
export interface QualitySitemapScoringSignals {
  annotations?:  | "UNSET" | "LOW_RELATIVE_CONFIDENCE_IMPRESSIONS"[];
  chromeTransCount?: bigint;
  chromeTransProb?: number;
  chromeWeight?: number;
  country?: string[];
  countryConfidence?: number[];
  impressions?: bigint;
  langConfidence?: number[];
  language?: string[];
  localCountryIdentifier?: string[];
  longClicks?: bigint;
  longCtr?: number;
  navboostScore?: number;
  navmenuScore?: number;
  pagerank?: number;
  recentLongCtr?: number;
  targetCdocLanguages?: number[];
  titleScore?: number;
}

function serializeQualitySitemapScoringSignals(data: any): QualitySitemapScoringSignals {
  return {
    ...data,
    chromeTransCount: data["chromeTransCount"] !== undefined ? String(data["chromeTransCount"]) : undefined,
    impressions: data["impressions"] !== undefined ? String(data["impressions"]) : undefined,
    longClicks: data["longClicks"] !== undefined ? String(data["longClicks"]) : undefined,
  };
}

function deserializeQualitySitemapScoringSignals(data: any): QualitySitemapScoringSignals {
  return {
    ...data,
    chromeTransCount: data["chromeTransCount"] !== undefined ? BigInt(data["chromeTransCount"]) : undefined,
    impressions: data["impressions"] !== undefined ? BigInt(data["impressions"]) : undefined,
    longClicks: data["longClicks"] !== undefined ? BigInt(data["longClicks"]) : undefined,
  };
}

/**
 * Information about a single sub-result.
 */
export interface QualitySitemapSubresult {
  docid?: bigint;
  itemMetadata?: QualitySitemapThirdPartyCarouselsListItemMuppetMetadata;
}

function serializeQualitySitemapSubresult(data: any): QualitySitemapSubresult {
  return {
    ...data,
    docid: data["docid"] !== undefined ? String(data["docid"]) : undefined,
  };
}

function deserializeQualitySitemapSubresult(data: any): QualitySitemapSubresult {
  return {
    ...data,
    docid: data["docid"] !== undefined ? BigInt(data["docid"]) : undefined,
  };
}

/**
 * A container for encapsulating a list of sub-results.
 */
export interface QualitySitemapSubresultList {
  subresult?: QualitySitemapSubresult[];
}

function serializeQualitySitemapSubresultList(data: any): QualitySitemapSubresultList {
  return {
    ...data,
    subresult: data["subresult"] !== undefined ? data["subresult"].map((item: any) => (serializeQualitySitemapSubresult(item))) : undefined,
  };
}

function deserializeQualitySitemapSubresultList(data: any): QualitySitemapSubresultList {
  return {
    ...data,
    subresult: data["subresult"] !== undefined ? data["subresult"].map((item: any) => (deserializeQualitySitemapSubresult(item))) : undefined,
  };
}

/**
 * Represents a single sitelink target, contains basic information used to
 * display the target (such as url and title) and to, maybe, dynamically change
 * the way targets are selected and/or ranked (such as score and is_mobile).
 * Please update the TargetInternal message if you make a change to this proto.
 * See "Note on adding new fields".
 */
export interface QualitySitemapTarget {
  DEPRECATEDSnippet?: string[];
  isGoodForMobile?: boolean;
  isMobileN1dup?: boolean;
  /**
   * The languages of the document, taken from its
   * cdoc.properties().languages()
   */
  languages?: number[];
  /**
   * The image data will be copied from the DocInfo response, and will be
   * retrieved online, so this field should not be populated during indexing.
   * This is a temporary field for experimentation.
   */
  salientImage?: WWWResultInfoSubImageDocInfo;
  score?: number;
  scoringSignals?: QualitySitemapScoringSignals;
  /**
   * Section texts used for Page Anchors Preview (go/page-anchor-preview-dd).
   */
  sectionTexts?: string[];
  /**
   * The snippet response for the target document for an empty query.
   */
  snippetResponse?: GenericSnippetResponse;
  sourceAnchor?: boolean;
  title?: string;
  twoLevelScore?: number;
  url?: string;
}

function serializeQualitySitemapTarget(data: any): QualitySitemapTarget {
  return {
    ...data,
    salientImage: data["salientImage"] !== undefined ? serializeWWWResultInfoSubImageDocInfo(data["salientImage"]) : undefined,
    scoringSignals: data["scoringSignals"] !== undefined ? serializeQualitySitemapScoringSignals(data["scoringSignals"]) : undefined,
    snippetResponse: data["snippetResponse"] !== undefined ? serializeGenericSnippetResponse(data["snippetResponse"]) : undefined,
  };
}

function deserializeQualitySitemapTarget(data: any): QualitySitemapTarget {
  return {
    ...data,
    salientImage: data["salientImage"] !== undefined ? deserializeWWWResultInfoSubImageDocInfo(data["salientImage"]) : undefined,
    scoringSignals: data["scoringSignals"] !== undefined ? deserializeQualitySitemapScoringSignals(data["scoringSignals"]) : undefined,
    snippetResponse: data["snippetResponse"] !== undefined ? deserializeGenericSnippetResponse(data["snippetResponse"]) : undefined,
  };
}

/**
 * Represents a set of targets. The group may have a label field to uniquely
 * identify this target group among others - for instance, if these targets'
 * titles were generated using an alternative title algorithm, the label can be
 * "newtitles". See "Note on adding new fields".
 */
export interface QualitySitemapTargetGroup {
  /**
   * If all the targets in this group are named anchors on the source page.
   */
  allTargetsNamedAnchors?: boolean;
  /**
   * If all the targets in this group are named topictags_scrollto on the
   * source page.
   */
  allTargetsNamedTopictagsScrollto?: boolean;
  breadcrumbTarget?: QualitySitemapBreadcrumbTarget;
  coClickTarget?: QualitySitemapCoClickTarget[];
  countryCode?: string;
  DEPRECATEDCountry?: number;
  label?: string;
  language?: number;
  modifiedByHostcardHandler?: boolean;
  scoringSignals?: QualitySitemapScoringSignals;
  Target?: QualitySitemapTarget[];
  /**
   * A list of top urls with highest two_level_score, i.e.,
   * chrome_trans_clicks.
   */
  topUrl?: QualitySitemapTopURL[];
  twoLevelTarget?: QualitySitemapTwoLevelTarget[];
}

function serializeQualitySitemapTargetGroup(data: any): QualitySitemapTargetGroup {
  return {
    ...data,
    scoringSignals: data["scoringSignals"] !== undefined ? serializeQualitySitemapScoringSignals(data["scoringSignals"]) : undefined,
    Target: data["Target"] !== undefined ? data["Target"].map((item: any) => (serializeQualitySitemapTarget(item))) : undefined,
    twoLevelTarget: data["twoLevelTarget"] !== undefined ? data["twoLevelTarget"].map((item: any) => (serializeQualitySitemapTwoLevelTarget(item))) : undefined,
  };
}

function deserializeQualitySitemapTargetGroup(data: any): QualitySitemapTargetGroup {
  return {
    ...data,
    scoringSignals: data["scoringSignals"] !== undefined ? deserializeQualitySitemapScoringSignals(data["scoringSignals"]) : undefined,
    Target: data["Target"] !== undefined ? data["Target"].map((item: any) => (deserializeQualitySitemapTarget(item))) : undefined,
    twoLevelTarget: data["twoLevelTarget"] !== undefined ? data["twoLevelTarget"].map((item: any) => (deserializeQualitySitemapTwoLevelTarget(item))) : undefined,
  };
}

/**
 * A set of metadata about a list item that is passed on to Muppet from
 * indexing.
 */
export interface QualitySitemapThirdPartyCarouselsListItemMuppetMetadata {
  /**
   * DEPRECATED. No longer populated, and not used anywhere.
   */
  urlFoundOnPage?: boolean;
}

export interface QualitySitemapTopURL {
  score?: number;
  url?: string;
}

export interface QualitySitemapTwoLevelTarget {
  firstLevelTarget?: QualitySitemapTarget;
  secondLevelTarget?: QualitySitemapTarget[];
}

function serializeQualitySitemapTwoLevelTarget(data: any): QualitySitemapTwoLevelTarget {
  return {
    ...data,
    firstLevelTarget: data["firstLevelTarget"] !== undefined ? serializeQualitySitemapTarget(data["firstLevelTarget"]) : undefined,
    secondLevelTarget: data["secondLevelTarget"] !== undefined ? data["secondLevelTarget"].map((item: any) => (serializeQualitySitemapTarget(item))) : undefined,
  };
}

function deserializeQualitySitemapTwoLevelTarget(data: any): QualitySitemapTwoLevelTarget {
  return {
    ...data,
    firstLevelTarget: data["firstLevelTarget"] !== undefined ? deserializeQualitySitemapTarget(data["firstLevelTarget"]) : undefined,
    secondLevelTarget: data["secondLevelTarget"] !== undefined ? data["secondLevelTarget"].map((item: any) => (deserializeQualitySitemapTarget(item))) : undefined,
  };
}

/**
 * A bolded range in printed snippet lines.
 */
export interface QualitySnippetsTruncationSnippetBoldedRange {
  /**
   * Bolded range [begin, end)
   */
  begin?: QualitySnippetsTruncationSnippetBoldedRangePosition;
  end?: QualitySnippetsTruncationSnippetBoldedRangePosition;
  /**
   * Only populated for debugging.
   */
  text?: string;
  type?:  | "TYPE_UNSPECIFIED" | "QUERY_TERM_MATCH" | "RADISH" | "BRAIN" | "QUOTED_TERM";
}

export interface QualitySnippetsTruncationSnippetBoldedRangePosition {
  byteOffset?: number;
  index?: number;
}

export interface QualityTimebasedLastSignificantUpdate {
  /**
   * This is stored only for debugging purposes. Please consult dates@ team
   * before making a dependency on this field.
   */
  adjustmentInfo?: QualityTimebasedLastSignificantUpdateAdjustments;
  /**
   * LastSignificantUpdate as UNIX timestamp in seconds. This is the new signal
   * (go/lsu-dd) from LSU Selector V2 (once that is enabled, see b/171879888 for
   * status), falling back to the legacy V1 signal if the HIGH_PRECISION signal
   * does not exist. Please use the 'source' field to determine where the value
   * comes from.
   */
  date?: bigint;
  /**
   * The source the signal comes from.
   */
  source?:  | "UNSET" | "LSU_LOW_PRECISION" | "LSU_HIGH_PRECISION_UPDATE_MARKUP_SUPPORTED_BY_CONTENTAGE" | "LSU_HIGH_PRECISION_UPDATE_MARKUP_SUPPORTED_BY_ANNOTATION" | "LSU_HIGH_PRECISION_ANNOTATION_WITH_UPDATE_TAG" | "LSU_HIGH_PRECISION_PUBLICATION_MARKUP_SUPPORTED_BY_CONTENTAGE" | "LSU_HIGH_PRECISION_PUBLICATION_MARKUP_SUPPORTED_BY_ANNOTATION" | "LSU_HIGH_PRECISION_ANNOTATION_WITH_PATTERN_BYLINE_TAG" | "LSU_HIGH_PRECISION_RELIABLE_CONTENT_AGE_SUPPORTED_BY_ANNOTATION" | "LSU_MEDIUM_PRECISION_FRESH_SALIENT_ANNOTATION_LOW_SUPPORT" | "LSU_MEDIUM_PRECISION_FRESH_SALIENT_ANNOTATION_MEDIUM_SUPPORT" | "LSU_MEDIUM_PRECISION_FRESH_SALIENT_ANNOTATION_HIGH_SUPPORT" | "LSU_MEDIUM_PRECISION_FRESH_SALIENT_ANNOTATION_FULL_SUPPORT" | "LSU_V1" | "LSU_V2_UPDATE_MARKUP_SUPPORTED_BY_CONTENTAGE" | "LSU_V2_UPDATE_MARKUP_SUPPORTED_BY_ANNOTATION" | "LSU_V2_ANNOTATION_WITH_UPDATE_TAG" | "LSU_V2_PUBLICATION_MARKUP_SUPPORTED_BY_CONTENTAGE" | "LSU_V2_PUBLICATION_MARKUP_SUPPORTED_BY_ANNOTATION" | "LSU_V2_ANNOTATION_WITH_PATTERN_BYLINE_TAG" | "LSU_V2_RELIABLE_CONTENT_AGE_SUPPORTED_BY_ANNOTATION";
}

function serializeQualityTimebasedLastSignificantUpdate(data: any): QualityTimebasedLastSignificantUpdate {
  return {
    ...data,
    adjustmentInfo: data["adjustmentInfo"] !== undefined ? serializeQualityTimebasedLastSignificantUpdateAdjustments(data["adjustmentInfo"]) : undefined,
    date: data["date"] !== undefined ? String(data["date"]) : undefined,
  };
}

function deserializeQualityTimebasedLastSignificantUpdate(data: any): QualityTimebasedLastSignificantUpdate {
  return {
    ...data,
    adjustmentInfo: data["adjustmentInfo"] !== undefined ? deserializeQualityTimebasedLastSignificantUpdateAdjustments(data["adjustmentInfo"]) : undefined,
    date: data["date"] !== undefined ? BigInt(data["date"]) : undefined,
  };
}

export interface QualityTimebasedLastSignificantUpdateAdjustments {
  /**
   * If the selected LSU has been adjusted, i.e. the maximum passage timestamp,
   * firstseen or contentage were assigned to LSU, the adjustment source is
   * stored here.
   */
  adjustmentSource?:  | "UNSET" | "PASSAGE_TIMESTAMP" | "FIRSTSEEN" | "CONTENT_AGE";
  /**
   * The timestamp is precise when it's derived from existing (>March 2022)
   * passage timestamp.
   */
  isUpperboundTimestampPrecise?: boolean;
  /**
   * The timestamp that was picked up by the component indicated in the
   * LastSignificantUpdateSource but was dropped due to exceeding the upper
   * bound. Set only if it is not equal to final LSU.
   */
  unboundedTimestampInSeconds?: bigint;
  /**
   * The source that produced the unbounded timestamp.
   */
  unboundedTimestampSource?:  | "UNSET" | "LSU_LOW_PRECISION" | "LSU_HIGH_PRECISION_UPDATE_MARKUP_SUPPORTED_BY_CONTENTAGE" | "LSU_HIGH_PRECISION_UPDATE_MARKUP_SUPPORTED_BY_ANNOTATION" | "LSU_HIGH_PRECISION_ANNOTATION_WITH_UPDATE_TAG" | "LSU_HIGH_PRECISION_PUBLICATION_MARKUP_SUPPORTED_BY_CONTENTAGE" | "LSU_HIGH_PRECISION_PUBLICATION_MARKUP_SUPPORTED_BY_ANNOTATION" | "LSU_HIGH_PRECISION_ANNOTATION_WITH_PATTERN_BYLINE_TAG" | "LSU_HIGH_PRECISION_RELIABLE_CONTENT_AGE_SUPPORTED_BY_ANNOTATION" | "LSU_MEDIUM_PRECISION_FRESH_SALIENT_ANNOTATION_LOW_SUPPORT" | "LSU_MEDIUM_PRECISION_FRESH_SALIENT_ANNOTATION_MEDIUM_SUPPORT" | "LSU_MEDIUM_PRECISION_FRESH_SALIENT_ANNOTATION_HIGH_SUPPORT" | "LSU_MEDIUM_PRECISION_FRESH_SALIENT_ANNOTATION_FULL_SUPPORT" | "LSU_V1" | "LSU_V2_UPDATE_MARKUP_SUPPORTED_BY_CONTENTAGE" | "LSU_V2_UPDATE_MARKUP_SUPPORTED_BY_ANNOTATION" | "LSU_V2_ANNOTATION_WITH_UPDATE_TAG" | "LSU_V2_PUBLICATION_MARKUP_SUPPORTED_BY_CONTENTAGE" | "LSU_V2_PUBLICATION_MARKUP_SUPPORTED_BY_ANNOTATION" | "LSU_V2_ANNOTATION_WITH_PATTERN_BYLINE_TAG" | "LSU_V2_RELIABLE_CONTENT_AGE_SUPPORTED_BY_ANNOTATION";
  /**
   * The upperbound value derived from passage timestamps. If present, the LSU
   * date should never exceed this value. Design doc:
   * go/lsu-max-passage-timestamp
   */
  upperboundTimestampInSeconds?: bigint;
}

function serializeQualityTimebasedLastSignificantUpdateAdjustments(data: any): QualityTimebasedLastSignificantUpdateAdjustments {
  return {
    ...data,
    unboundedTimestampInSeconds: data["unboundedTimestampInSeconds"] !== undefined ? String(data["unboundedTimestampInSeconds"]) : undefined,
    upperboundTimestampInSeconds: data["upperboundTimestampInSeconds"] !== undefined ? String(data["upperboundTimestampInSeconds"]) : undefined,
  };
}

function deserializeQualityTimebasedLastSignificantUpdateAdjustments(data: any): QualityTimebasedLastSignificantUpdateAdjustments {
  return {
    ...data,
    unboundedTimestampInSeconds: data["unboundedTimestampInSeconds"] !== undefined ? BigInt(data["unboundedTimestampInSeconds"]) : undefined,
    upperboundTimestampInSeconds: data["upperboundTimestampInSeconds"] !== undefined ? BigInt(data["upperboundTimestampInSeconds"]) : undefined,
  };
}

export interface QualityTimebasedPageType {
  /**
   * Set to true if this page is classified as a forum page.
   */
  isForumPage?: boolean;
  /**
   * Set to true if this page has a fresh repeated date sequence.
   */
  isPageWithFreshRepeatedDates?: boolean;
  /**
   * Set to true if this page is classified as a question answers page.
   */
  isQnaPage?: boolean;
}

/**
 * Next ID: 21
 */
export interface QualityTimebasedSyntacticDate {
  /**
   * The following field is set only when the byline date is different from the
   * "date" field above. Currently this happens when the byline date is within
   * the 24 hours of the crawl time, or close but not exactly the same as blog
   * post date due to time zone. The syntactic date is never later than the
   * crawl time. NOTE: If this field is set, use_as_byline_date will be
   * meaningless, and better to be cleared.
   */
  bylineDate?: bigint;
  /**
   * The number of seconds since epoch (Jan 1, 1970). This can be negative to
   * indicate a publication date that is before 1970. For example, the ones from
   * NY Times archive:
   * "http://select.nytimes.com/gst/abstract.html?res=F10B13FB3D5A10728FDDAF089"
   * "4DD405B8588F1D3&scp=91&sq=world+war+II&st=p"
   */
  date?: bigint;
  daterange?: QualityTimebasedSyntacticDateDateRange;
  debugInfo?: string;
  /**
   * If set to true, the source of the date has explicit time zone
   * specification. Note: This is only used internally and should not be
   * populated in docjoins.
   */
  fromExplicitTimeZone?: boolean;
  /**
   * Used to store extra information about the syntactic date. For now only two
   * bits are set. Please refer to the encoding/decoding functions provided in:
   * quality/timebased/syntacticdate/util.h Bit 1 = High confidence byline. This
   * bit is set if the syntactic date has a byline date and this date is
   * considered to be high confidence. Bit 2 = High confidence byline without
   * content age. This bit is set if the syntactic date has a byline date and
   * this date is considered to be high confidence without support from content
   * age.
   */
  info?: number;
  position?: QualityTimebasedSyntacticDatePosition;
  /**
   * The precision mark should be of type PRECISION_MARK.
   */
  precisionMark?: number;
  /**
   * If this is true, do not use syntactic date in date restricts.
   */
  syntacticDateNotForRestrict?: boolean;
  /**
   * Indicates the time zone offset in seconds applied to derive `date' in UTC.
   * Example: Annotation: "1pm PST" (UTC-8) => -8 * 3600 = -28800 Note: This is
   * only used internally and should not be populated in docjoins.
   */
  timeZoneOffsetSeconds?: bigint;
  /**
   * This bit is set if we believe that the syntactic date is really high
   * confidence, but does not qualify as a byline date.
   */
  trustSyntacticDateInRanking?: boolean;
  /**
   * Whether this date is good for display as the snippet byline date.
   */
  useAsBylineDate?: boolean;
  /**
   * This bit is set if the syntactic date is good to be used in site-level
   * timezone guessing statistics calculation. (The date should be absolute date
   * having a timestamp with hour and minute level information. It can come with
   * or without time zone information, which is indicated in
   * from_explicit_time_zone field defined below.)
   */
  useInTimeZoneGuessingMode?: boolean;
  /**
   * If true, the DateRange is used as date restrict, if false, the date is
   * used as date restrict. Has no effect if syntactic_date_not_for_restrict is
   * true.
   */
  useRangeInsteadOfDateForRestrict?: boolean;
}

function serializeQualityTimebasedSyntacticDate(data: any): QualityTimebasedSyntacticDate {
  return {
    ...data,
    bylineDate: data["bylineDate"] !== undefined ? String(data["bylineDate"]) : undefined,
    date: data["date"] !== undefined ? String(data["date"]) : undefined,
    daterange: data["daterange"] !== undefined ? serializeQualityTimebasedSyntacticDateDateRange(data["daterange"]) : undefined,
    timeZoneOffsetSeconds: data["timeZoneOffsetSeconds"] !== undefined ? String(data["timeZoneOffsetSeconds"]) : undefined,
  };
}

function deserializeQualityTimebasedSyntacticDate(data: any): QualityTimebasedSyntacticDate {
  return {
    ...data,
    bylineDate: data["bylineDate"] !== undefined ? BigInt(data["bylineDate"]) : undefined,
    date: data["date"] !== undefined ? BigInt(data["date"]) : undefined,
    daterange: data["daterange"] !== undefined ? deserializeQualityTimebasedSyntacticDateDateRange(data["daterange"]) : undefined,
    timeZoneOffsetSeconds: data["timeZoneOffsetSeconds"] !== undefined ? BigInt(data["timeZoneOffsetSeconds"]) : undefined,
  };
}

/**
 * If the single date (plus the precision mark) is still not good enough, we
 * will use the following fields for a date range. In this case, the fields
 * above may all be empty.
 */
export interface QualityTimebasedSyntacticDateDateRange {
  end?: bigint;
  start?: bigint;
}

function serializeQualityTimebasedSyntacticDateDateRange(data: any): QualityTimebasedSyntacticDateDateRange {
  return {
    ...data,
    end: data["end"] !== undefined ? String(data["end"]) : undefined,
    start: data["start"] !== undefined ? String(data["start"]) : undefined,
  };
}

function deserializeQualityTimebasedSyntacticDateDateRange(data: any): QualityTimebasedSyntacticDateDateRange {
  return {
    ...data,
    end: data["end"] !== undefined ? BigInt(data["end"]) : undefined,
    start: data["start"] !== undefined ? BigInt(data["start"]) : undefined,
  };
}

/**
 * The following positions are the byte offset in doc body, which is consistent
 * with the date annotations. (See
 * google3/repository/annotations/proto/annotations.proto) These are given when
 * we want to use the date as a byline date, so the snippet generating code will
 * know the positions.
 */
export interface QualityTimebasedSyntacticDatePosition {
  begin?: number;
  end?: number;
}

/**
 * Protocol message for data related to good travel sites. This data is stored
 * as signals data in docjoins.
 */
export interface QualityTravelGoodSitesData {
  i18n?: QualityTravelGoodSitesDataI18n[];
  isAggr?: boolean;
  isAttractionOfficial?: boolean;
  isEntity?: boolean;
  isHotelOfficial?: boolean;
  /**
   * Factor that determines how local anchor credit is scaled before being
   * added to global anchors.
   */
  normalizationFactor?: number;
  signal?: QualityTravelGoodSitesDataSignal[];
  site?: string;
  /**
   * Site quality score, which determines the site type.
   */
  totalScore?: number;
  type?:  | "NOT_GOOD" | "LOCAL_OKAY" | "OKAY" | "GOOD" | "OFFICIAL" | "NUM_TYPES";
}

export interface QualityTravelGoodSitesDataI18n {
  locale?: string;
  type?:  | "NOT_GOOD" | "LOCAL_OKAY" | "OKAY" | "GOOD" | "OFFICIAL" | "NUM_TYPES";
}

/**
 * Raw signals that determine the site quality score.
 */
export interface QualityTravelGoodSitesDataSignal {
  name?: string;
  value?: number;
}

/**
 * Audio-based language information about a Watch Page. For more information:
 * https://g3doc.corp.google.com/video/timedtext/g3doc/ali.md
 */
export interface QualityVidyaVideoLanguageVideoLanguage {
  /**
   * Audio language of video classified by Automatic Language Identification.
   * It corresponds to the first language (the highest confidence) in
   * ALIResults.lang_results.
   */
  language?:  | "ENGLISH" | "DANISH" | "DUTCH" | "FINNISH" | "FRENCH" | "GERMAN" | "HEBREW" | "ITALIAN" | "JAPANESE" | "KOREAN" | "NORWEGIAN" | "POLISH" | "PORTUGUESE" | "RUSSIAN" | "SPANISH" | "SWEDISH" | "CHINESE" | "CZECH" | "GREEK" | "ICELANDIC" | "LATVIAN" | "LITHUANIAN" | "ROMANIAN" | "HUNGARIAN" | "ESTONIAN" | "TG_UNKNOWN_LANGUAGE" | "UNKNOWN_LANGUAGE" | "BULGARIAN" | "CROATIAN" | "SERBIAN" | "IRISH" | "GALICIAN" | "TAGALOG" | "TURKISH" | "UKRAINIAN" | "HINDI" | "MACEDONIAN" | "BENGALI" | "INDONESIAN" | "LATIN" | "MALAY" | "MALAYALAM" | "WELSH" | "NEPALI" | "TELUGU" | "ALBANIAN" | "TAMIL" | "BELARUSIAN" | "JAVANESE" | "OCCITAN" | "URDU" | "BIHARI" | "GUJARATI" | "THAI" | "ARABIC" | "CATALAN" | "ESPERANTO" | "BASQUE" | "INTERLINGUA" | "KANNADA" | "PUNJABI" | "SCOTS_GAELIC" | "SWAHILI" | "SLOVENIAN" | "MARATHI" | "MALTESE" | "VIETNAMESE" | "FRISIAN" | "SLOVAK" | "CHINESE_T" | "FAROESE" | "SUNDANESE" | "UZBEK" | "AMHARIC" | "AZERBAIJANI" | "GEORGIAN" | "TIGRINYA" | "PERSIAN" | "BOSNIAN" | "SINHALESE" | "NORWEGIAN_N" | "PORTUGUESE_P" | "PORTUGUESE_B" | "XHOSA" | "ZULU" | "GUARANI" | "SESOTHO" | "TURKMEN" | "KYRGYZ" | "BRETON" | "TWI" | "YIDDISH" | "SERBO_CROATIAN" | "SOMALI" | "UIGHUR" | "KURDISH" | "MONGOLIAN" | "ARMENIAN" | "LAOTHIAN" | "SINDHI" | "RHAETO_ROMANCE" | "AFRIKAANS" | "LUXEMBOURGISH" | "BURMESE" | "KHMER" | "TIBETAN" | "DHIVEHI" | "CHEROKEE" | "SYRIAC" | "LIMBU" | "ORIYA" | "ASSAMESE" | "CORSICAN" | "INTERLINGUE" | "KAZAKH" | "LINGALA" | "MOLDAVIAN" | "PASHTO" | "QUECHUA" | "SHONA" | "TAJIK" | "TATAR" | "TONGA" | "YORUBA" | "CREOLES_AND_PIDGINS_ENGLISH_BASED" | "CREOLES_AND_PIDGINS_FRENCH_BASED" | "CREOLES_AND_PIDGINS_PORTUGUESE_BASED" | "CREOLES_AND_PIDGINS_OTHER" | "MAORI" | "WOLOF" | "ABKHAZIAN" | "AFAR" | "AYMARA" | "BASHKIR" | "BISLAMA" | "DZONGKHA" | "FIJIAN" | "GREENLANDIC" | "HAUSA" | "HAITIAN_CREOLE" | "INUPIAK" | "INUKTITUT" | "KASHMIRI" | "KINYARWANDA" | "MALAGASY" | "NAURU" | "OROMO" | "RUNDI" | "SAMOAN" | "SANGO" | "SANSKRIT" | "SISWANT" | "TSONGA" | "TSWANA" | "VOLAPUK" | "ZHUANG" | "KHASI" | "SCOTS" | "GANDA" | "MANX" | "MONTENEGRIN" | "AKAN" | "IGBO" | "MAURITIAN_CREOLE" | "HAWAIIAN" | "CEBUANO" | "EWE" | "GA" | "HMONG" | "KRIO" | "LOZI" | "LUBA_LULUA" | "LUO_KENYA_AND_TANZANIA" | "NEWARI" | "NYANJA" | "OSSETIAN" | "PAMPANGA" | "PEDI" | "RAJASTHANI" | "SESELWA_CREOLE_FRENCH" | "TUMBUKA" | "VENDA" | "WARAY_PHILIPPINES" | "NUM_LANGUAGES";
  /**
   * Type of detected speech.
   */
  speechClass?:  | "UNKNOWN" | "NO_SPEECH" | "HAS_SPEECH_FOR_ASR";
}

/**
 * Stores cluster scoring information for an entity Next Id: 6
 */
export interface QualityViewsExtractionClusterInfo {
  /**
   * The cluster_id represents the id of the set entity that WebRef provides.
   */
  clusterId?: string;
  /**
   * Cluster set qref confidence score.
   */
  clusterSetScore?: number;
  /**
   * The mids of cluster members that are part of the same cluster. Note that
   * cluster members may end up having their own interpretation (EntityInfo
   * which includes a ClusterInfo) or not (eg because they do not explain the
   * full query, and so aqua does not output an interpretation for them). The
   * latter case (a cluster member is output only as part of this field), is
   * equivalent to its score being 0.
   */
  clusterSiblingMid?: string[];
  /**
   * The score represents the score of the entity within the cluster.
   */
  score?: number;
  subCluster?: QualityViewsExtractionClusterInfo[];
}

/**
 * Wraps other annotations that are run over auto-generated video captions.
 */
export interface QualityWebanswersTranscriptAnnotations {
  videoTranscriptAnnotations?: QualityWebanswersVideoTranscriptAnnotations[];
}

function serializeQualityWebanswersTranscriptAnnotations(data: any): QualityWebanswersTranscriptAnnotations {
  return {
    ...data,
    videoTranscriptAnnotations: data["videoTranscriptAnnotations"] !== undefined ? data["videoTranscriptAnnotations"].map((item: any) => (serializeQualityWebanswersVideoTranscriptAnnotations(item))) : undefined,
  };
}

function deserializeQualityWebanswersTranscriptAnnotations(data: any): QualityWebanswersTranscriptAnnotations {
  return {
    ...data,
    videoTranscriptAnnotations: data["videoTranscriptAnnotations"] !== undefined ? data["videoTranscriptAnnotations"].map((item: any) => (deserializeQualityWebanswersVideoTranscriptAnnotations(item))) : undefined,
  };
}

export interface QualityWebanswersVideoTranscriptAnnotations {
  /**
   * Should precisely match the amarna_docid in ContentBasedVideoMetadata.
   */
  amarnaDocid?: string;
  /**
   * The results of ASR transcript quality analysis.
   */
  asrRepair?: IndexingVideosAsrTranscriptRepairAnnotation;
  /**
   * The language of the transcript as recorded in Amarna.
   */
  lang?: string;
  punctuatedTranscript?: string;
  saftDocument?: NlpSaftDocument;
  saftSentenceBoundary?: SentenceBoundaryAnnotations;
  /**
   * Timing information that maps sentence boundaries in the punctuated
   * transcript with timing offsets for the start and end of those sentences.
   */
  timingInfo?: QualityWebanswersVideoYouTubeCaptionTimingInfoAnnotations;
  webrefEntities?: RepositoryWebrefWebrefEntities;
}

function serializeQualityWebanswersVideoTranscriptAnnotations(data: any): QualityWebanswersVideoTranscriptAnnotations {
  return {
    ...data,
    saftDocument: data["saftDocument"] !== undefined ? serializeNlpSaftDocument(data["saftDocument"]) : undefined,
    webrefEntities: data["webrefEntities"] !== undefined ? serializeRepositoryWebrefWebrefEntities(data["webrefEntities"]) : undefined,
  };
}

function deserializeQualityWebanswersVideoTranscriptAnnotations(data: any): QualityWebanswersVideoTranscriptAnnotations {
  return {
    ...data,
    saftDocument: data["saftDocument"] !== undefined ? deserializeNlpSaftDocument(data["saftDocument"]) : undefined,
    webrefEntities: data["webrefEntities"] !== undefined ? deserializeRepositoryWebrefWebrefEntities(data["webrefEntities"]) : undefined,
  };
}

/**
 * YouTube caption timing information for http://go/video-answers.
 */
export interface QualityWebanswersVideoYouTubeCaptionTimingInfoAnnotations {
  durationMs?: number;
  instances?: QualityWebanswersVideoYouTubeCaptionTimingInfoAnnotationsInstance[];
  uploaderName?: string;
}

/**
 * Byte-offset and timing information in videos. In CompositeDoc, we will store
 * the instance per sentence.
 */
export interface QualityWebanswersVideoYouTubeCaptionTimingInfoAnnotationsInstance {
  /**
   * Byte offsets in HTML. begin is inclusive and end is exclusive.
   */
  begin?: number;
  end?: number;
  videoBeginMs?: number;
  videoEndMs?: number;
}

/**
 * Domain registration information for the document. NEXT ID TO USE: 3
 */
export interface RegistrationInfo {
  /**
   * This is the number of days since January 1st 1995 that this domain was
   * last created. This should always fit in 15 bits.
   */
  createdDate?: number;
  /**
   * This is the number of days since January 1st 1995 that this domain last
   * expired. This should always fit in 15 bits. Jan 1st 1995 was chosen by the
   * history project as a special epoch date. Both the registrationinfo dates
   * and the linkage dates are measured in days since this epoch.
   */
  expiredDate?: number;
}

/**
 * GeoTopicality of a document is a set of GeoTopics ordered by their
 * normalized scores.
 */
export interface RepositoryAnnotationsGeoTopic {
  /**
   * Stores parent/container information containing city, province & country.
   */
  address?: GeostoreAddressProto;
  /**
   * The raw scores used to calculate the normalized_score. Note that not all
   * these scores may be exposed to the users.
   */
  componentScores?: RepositoryAnnotationsGeoTopicalityScore[];
  /**
   * A score [0, 1] indicating the confidence.
   */
  confidence?: number;
  /**
   * Is this a dense city (e.g., population > 100k)?
   */
  denseCity?: boolean;
  /**
   * Sub type for POI types like ESTABLISHMENT_POI, ESTABLISHMENT_GROUNDS &
   * ESTABLISHMENT_BUILDING
   */
  establishmentType?: number;
  /**
   * Latitude and Longitude of the location.
   */
  latE7?: number;
  lngE7?: number;
  /**
   * Name of the Geographic location. This is the normalized name.
   */
  locationName?: string;
  /**
   * A score [0, 1] indicating the likelihood of the location being the
   * GeoTopicality.
   */
  normalizedScore?: number;
  /**
   * Oyster Feature ID of the location.
   */
  oysterId?: GeostoreFeatureIdProto;
  /**
   * Oyster Feature Type
   */
  oysterType?: number;
  /**
   * The sum of the normalized scores of POIs contained within a particular
   * locality.
   */
  sumContainedPoiNormalizedScores?: number;
}

function serializeRepositoryAnnotationsGeoTopic(data: any): RepositoryAnnotationsGeoTopic {
  return {
    ...data,
    address: data["address"] !== undefined ? serializeGeostoreAddressProto(data["address"]) : undefined,
    oysterId: data["oysterId"] !== undefined ? serializeGeostoreFeatureIdProto(data["oysterId"]) : undefined,
  };
}

function deserializeRepositoryAnnotationsGeoTopic(data: any): RepositoryAnnotationsGeoTopic {
  return {
    ...data,
    address: data["address"] !== undefined ? deserializeGeostoreAddressProto(data["address"]) : undefined,
    oysterId: data["oysterId"] !== undefined ? deserializeGeostoreFeatureIdProto(data["oysterId"]) : undefined,
  };
}

export interface RepositoryAnnotationsGeoTopicality {
  /**
   * The geotopics are ordered by normalized_score in descending order.
   */
  geotopics?: RepositoryAnnotationsGeoTopic[];
}

function serializeRepositoryAnnotationsGeoTopicality(data: any): RepositoryAnnotationsGeoTopicality {
  return {
    ...data,
    geotopics: data["geotopics"] !== undefined ? data["geotopics"].map((item: any) => (serializeRepositoryAnnotationsGeoTopic(item))) : undefined,
  };
}

function deserializeRepositoryAnnotationsGeoTopicality(data: any): RepositoryAnnotationsGeoTopicality {
  return {
    ...data,
    geotopics: data["geotopics"] !== undefined ? data["geotopics"].map((item: any) => (deserializeRepositoryAnnotationsGeoTopic(item))) : undefined,
  };
}

export interface RepositoryAnnotationsGeoTopicalityScore {
  rawScore?: number;
  type?:  | "TITLE_SCORE" | "LEADING_MENTIONS_SCORE" | "QUALIFIER_BOOST" | "TAG_BOOST" | "FREQUENCY_SCORE" | "AVERAGE_PARENT_BOOST" | "OVERALL_SCORE" | "ON_PAGE_NORMALIZED_SCORE" | "OFF_PAGE_NORMALIZED_SCORE" | "ANCHOR_COUNT" | "ENDMARKER_FOR_SCORES";
}

/**
 * A conceptual structure for storing sentiment snippet information in mustang.
 * Essentially an adaptation of PhraseAnnotationProperties from
 * //repository/annotations/proto/annotations.proto.
 */
export interface RepositoryAnnotationsMustangSentimentSnippetAnnotations {
  /**
   * Deprecated: use snippet_score instead
   */
  deprecatedMagnitude?: number;
  /**
   * Deprecated: use snippet_score instead
   */
  deprecatedPolarity?: number;
  end?: number;
  isTruncated?: boolean;
  phraseType?:  | "UNKNOWN" | "POSITIVE" | "NEGATIVE" | "MIXED" | "NEUTRAL";
  snippetScore?: number;
  /**
   * This protobuffer is serving double duty as both a Mustang attachment and
   * the response proto that gets returned by Mustang in the
   * WWWSnippetResponse's info MessageSet. When stored as an attachment, this
   * field will always be empty. However, when returned with the
   * WWWSnippetResponse, Mustang will print and store the actual sentiment
   * snippet's text here.
   */
  snippetText?: string;
  /**
   * begin and end are token offsets.
   */
  start?: number;
}

export interface RepositoryAnnotationsRdfaBreadcrumbs {
  /**
   * Each crumb represents one link of the breadcrumb chain.
   */
  crumb?: RepositoryAnnotationsRdfaCrumb[];
  /**
   * The URL of the document from which this breadcrumb trail was extracted.
   */
  url?: string;
}

/**
 * The information contained in a single crumb.
 */
export interface RepositoryAnnotationsRdfaCrumb {
  /**
   * The text that represented this crumb in the document.
   */
  title?: string;
  /**
   * The URL linked from this crumb.
   */
  url?: string;
}

/**
 * This structure holds data for application information for rich snippets Next
 * ID: 53
 */
export interface RepositoryAnnotationsRdfaRdfaRichSnippetsApplication {
  /**
   * Fields for internal use
   */
  applicationUrl?: string;
  appTypeData?: RepositoryAnnotationsRdfaRdfaRichSnippetsApplicationAppTypeData;
  breadcrumbs?: RepositoryAnnotationsRdfaBreadcrumbs;
  /**
   * Application information.
   */
  category?: string[];
  /**
   * These are currently used only for Google Play.
   */
  countriesSupported?: string[];
  countryPrices?: RepositoryAnnotationsRdfaRdfaRichSnippetsApplicationCountryPrice[];
  currency?: string;
  description?: string;
  /**
   * Developer console ID of the app if it exists. The ID is available for an
   * app registered to Google Developers Console, not Play Developer Console.
   */
  devConsoleId?: string;
  /**
   * Top 1 of extracted icon colors. We keep this field for backward
   * compatibility.
   */
  extractedIconColor?: number;
  /**
   * Top 10 of extracted icon colors. r = (rgb >> 16) & 0xff; g = (rgb >> 8) &
   * 0xff; b = rgb & 0xff;
   */
  extractedIconColors?: number[];
  /**
   * Tags to be indexed for filtering, e.g. "ft_popular_score_gt_1m".
   */
  filteringTag?: string[];
  genre?: string[];
  /**
   * Whether the app has editors choice tag
   */
  hasEditorsChoiceBadge?: boolean;
  /**
   * Icon and Screenshots
   */
  iconUrlHref?: string;
  iconUrlThumbnail?: string;
  /**
   * Copied from
   * google3/contentads/shared/boulder/mobile-app-data-image-data.proto.
   */
  imageData?: QualityCalypsoAppsUniversalImageData;
  /**
   * Whether the app offers in-app purchase.
   */
  inAppPurchase?: boolean;
  /**
   * Indicates if the localized data comes from default locale. This is needed
   * because the default localized data does not specify its locale. If this is
   * true, lang_locale may not be the correct locale and should be ignored.
   */
  isDefaultLangLocale?: boolean;
  /**
   * locale for the localized data, such as name, description and screenshots
   */
  langLocale?: string;
  lastUpdated?: string;
  /**
   * Unified proto for android LiveOps and iOS LiveEvents.
   */
  liveOpDetails?: QualityCalypsoAppsUniversalAuLiveOpsDetailInfo;
  localizedTrustedGenome?: RepositoryAnnotationsRdfaRdfaRichSnippetsApplicationLocalizedTrustedGenome;
  /**
   * Market Android or itunes
   */
  marketplace?: string;
  name?: string;
  numDownloads?: string;
  /**
   * See google3/quality/richsnippets/schema/data/operating_systems_rules.txt
   * for possible values.
   */
  operatingSystems?: string[];
  /**
   * Whether this App is optional result for Grid UI.
   */
  optionalResult?: boolean;
  originalRating?: string;
  physicalDeviceTags?:  | "UNKNOWN_MOBILE" | "IOS_IPHONE_OR_IPOD" | "IOS_IPAD"[];
  platformTags?:  | "UNKNOWN_BROWSER" | "CHROME" | "FIREFOX"[];
  popularScore?: number;
  /**
   * Price
   */
  price?: string;
  rankData?: RepositoryAnnotationsRdfaRdfaRichSnippetsApplicationRankData;
  /**
   * Ratings and reviews Either for this version only or for all versions to be
   * displayed.
   */
  rating?: string;
  ratingCount?: string;
  releaseDate?: string;
  reviewAuthor?: string;
  reviewCount?: string;
  /**
   * TODO(b/260128276) deprecate this field in favor of image_data.
   */
  screenUrlHref?: string[];
  screenUrlThumbnail?: string[];
  /**
   * bytes or numeric with MB or GB
   */
  size?: string;
  subcategory?: string[];
  /**
   * Whether this App supports Android TV. Note that some App supports more
   * than one platforms. So we would use boolean for a platform.
   */
  supportsAndroidTv?: boolean;
  /**
   * Whether this App supports Google Cast.
   */
  supportsChromecast?: boolean;
  totalRating?: number;
  /**
   * Rating_count including all versions of this application.
   */
  totalRatingCount?: number;
  /**
   * Trusted Genome data with categorical app information key: locale (e.g. en,
   * en_US)
   */
  trustedGenomeData?: {
    [key: string]: VendingConsumerProtoTrustedGenomeAnnotation
  };
  /**
   * Vendor
   */
  vendor?: string;
  vendorCanonicalUrl?: string;
  vendorUrl?: string;
  version?: string;
}

function serializeRepositoryAnnotationsRdfaRdfaRichSnippetsApplication(data: any): RepositoryAnnotationsRdfaRdfaRichSnippetsApplication {
  return {
    ...data,
    liveOpDetails: data["liveOpDetails"] !== undefined ? serializeQualityCalypsoAppsUniversalAuLiveOpsDetailInfo(data["liveOpDetails"]) : undefined,
    rankData: data["rankData"] !== undefined ? serializeRepositoryAnnotationsRdfaRdfaRichSnippetsApplicationRankData(data["rankData"]) : undefined,
  };
}

function deserializeRepositoryAnnotationsRdfaRdfaRichSnippetsApplication(data: any): RepositoryAnnotationsRdfaRdfaRichSnippetsApplication {
  return {
    ...data,
    liveOpDetails: data["liveOpDetails"] !== undefined ? deserializeQualityCalypsoAppsUniversalAuLiveOpsDetailInfo(data["liveOpDetails"]) : undefined,
    rankData: data["rankData"] !== undefined ? deserializeRepositoryAnnotationsRdfaRdfaRichSnippetsApplicationRankData(data["rankData"]) : undefined,
  };
}

export interface RepositoryAnnotationsRdfaRdfaRichSnippetsApplicationAppTypeData {
  /**
   * Top level app category type (GAME or APPLICATION). Copied from playwright.
   */
  playStoreAppType?: string;
}

export interface RepositoryAnnotationsRdfaRdfaRichSnippetsApplicationCountryPrice {
  countryCode?: string;
  /**
   * ISO 4217 currency code.
   */
  currencyCode?: string;
  /**
   * Price string converted from double value in a standard currency unit, like
   * '199.35' or '1400'.
   */
  price?: string;
}

export interface RepositoryAnnotationsRdfaRdfaRichSnippetsApplicationLocalizedTrustedGenome {
  /**
   * The chosen language
   */
  language?: string;
  /**
   * The TG tags matching the locale of the doc, if available
   */
  localizedTg?: VendingConsumerProtoTrustedGenomeAnnotation;
}

export interface RepositoryAnnotationsRdfaRdfaRichSnippetsApplicationRank {
  appStoreLink?: string;
  categoryId?: string;
  categoryName?: string;
  chartType?: string;
  rank?: bigint;
}

function serializeRepositoryAnnotationsRdfaRdfaRichSnippetsApplicationRank(data: any): RepositoryAnnotationsRdfaRdfaRichSnippetsApplicationRank {
  return {
    ...data,
    rank: data["rank"] !== undefined ? String(data["rank"]) : undefined,
  };
}

function deserializeRepositoryAnnotationsRdfaRdfaRichSnippetsApplicationRank(data: any): RepositoryAnnotationsRdfaRdfaRichSnippetsApplicationRank {
  return {
    ...data,
    rank: data["rank"] !== undefined ? BigInt(data["rank"]) : undefined,
  };
}

export interface RepositoryAnnotationsRdfaRdfaRichSnippetsApplicationRankData {
  /**
   * Copied from the category_id field from Playwright docs. It helps decide
   * which category to show in app ranking info.
   */
  playwrightCategoryId?: string[];
  rank?: RepositoryAnnotationsRdfaRdfaRichSnippetsApplicationRank[];
}

function serializeRepositoryAnnotationsRdfaRdfaRichSnippetsApplicationRankData(data: any): RepositoryAnnotationsRdfaRdfaRichSnippetsApplicationRankData {
  return {
    ...data,
    rank: data["rank"] !== undefined ? data["rank"].map((item: any) => (serializeRepositoryAnnotationsRdfaRdfaRichSnippetsApplicationRank(item))) : undefined,
  };
}

function deserializeRepositoryAnnotationsRdfaRdfaRichSnippetsApplicationRankData(data: any): RepositoryAnnotationsRdfaRdfaRichSnippetsApplicationRankData {
  return {
    ...data,
    rank: data["rank"] !== undefined ? data["rank"].map((item: any) => (deserializeRepositoryAnnotationsRdfaRdfaRichSnippetsApplicationRank(item))) : undefined,
  };
}

/**
 * Represents the aggregated score of the entities for a given name, aggregated
 * over all sources. Next available tag: 3.
 */
export interface RepositoryWebrefAggregatedEntityNameScores {
  entityScore?: RepositoryWebrefEntityNameScore[];
}

function serializeRepositoryWebrefAggregatedEntityNameScores(data: any): RepositoryWebrefAggregatedEntityNameScores {
  return {
    ...data,
    entityScore: data["entityScore"] !== undefined ? data["entityScore"].map((item: any) => (serializeRepositoryWebrefEntityNameScore(item))) : undefined,
  };
}

function deserializeRepositoryWebrefAggregatedEntityNameScores(data: any): RepositoryWebrefAggregatedEntityNameScores {
  return {
    ...data,
    entityScore: data["entityScore"] !== undefined ? data["entityScore"].map((item: any) => (deserializeRepositoryWebrefEntityNameScore(item))) : undefined,
  };
}

/**
 * Identifies a set of anchors in the CompositeDoc. Typically these anchors
 * were collapsed by WebRef into a single anchor and they were treated by the
 * annotator as equivalent. They all contain the same mentions (at the same
 * offsets).
 */
export interface RepositoryWebrefAnchorIndices {
  /**
   * The set of indices in the Anchors::anchor() array that belong to the
   * collapsed anchors.
   */
  index?: number[];
}

/**
 * Information about a category annotation on a name.
 */
export interface RepositoryWebrefAnnotatedCategoryInfo {
  /**
   * A debug string for the category.
   */
  debugString?: string;
  /**
   * Listiness score of the category.
   */
  listiness?: number;
  /**
   * The mid of the entity representing the category.
   */
  mid?: bigint;
}

function serializeRepositoryWebrefAnnotatedCategoryInfo(data: any): RepositoryWebrefAnnotatedCategoryInfo {
  return {
    ...data,
    mid: data["mid"] !== undefined ? String(data["mid"]) : undefined,
  };
}

function deserializeRepositoryWebrefAnnotatedCategoryInfo(data: any): RepositoryWebrefAnnotatedCategoryInfo {
  return {
    ...data,
    mid: data["mid"] !== undefined ? BigInt(data["mid"]) : undefined,
  };
}

/**
 * Debug info about the concept annotations. Note that it might not be present
 * in the output.
 */
export interface RepositoryWebrefAnnotationDebugInfo {
  /**
   * Only use for debugging, this should not be displayed to user or used for
   * any kind of logic/processing.
   */
  description?: string;
}

/**
 * Human ratings of webref annotations (document-level ratings, mention-level
 * ratings, etc.).
 */
export interface RepositoryWebrefAnnotationRatings {
  docLevelRelevanceRatings?: RepositoryWebrefDocLevelRelevanceRatings;
}

function serializeRepositoryWebrefAnnotationRatings(data: any): RepositoryWebrefAnnotationRatings {
  return {
    ...data,
    docLevelRelevanceRatings: data["docLevelRelevanceRatings"] !== undefined ? serializeRepositoryWebrefDocLevelRelevanceRatings(data["docLevelRelevanceRatings"]) : undefined,
  };
}

function deserializeRepositoryWebrefAnnotationRatings(data: any): RepositoryWebrefAnnotationRatings {
  return {
    ...data,
    docLevelRelevanceRatings: data["docLevelRelevanceRatings"] !== undefined ? deserializeRepositoryWebrefDocLevelRelevanceRatings(data["docLevelRelevanceRatings"]) : undefined,
  };
}

/**
 * Annotation statistics for each token type. Next available tag: 8.
 */
export interface RepositoryWebrefAnnotationStatsPerType {
  /**
   * The average score for the open world for: - all ranges of this
   * segment_type; - all capitalized ranges of this segment_type; - all
   * uncapitalized ranges of this segment_type.
   */
  avgOpenWorld?: number;
  avgOpenWorldCap?: number;
  avgOpenWorldUncap?: number;
  /**
   * The number of ranges with candidates that made it past primary pruning
   * for: - all ranges of this segment_type; - all capitalized ranges of this
   * segment_type; - all uncapitalized ranges of this segment_type.
   */
  numRangesWithCandidates?: bigint;
  numRangesWithCandidatesCap?: bigint;
  numRangesWithCandidatesUncap?: bigint;
  /**
   * The segment type.
   */
  tokenType?:  | "INVALID" | "CONTENT" | "URL" | "ANCHOR" | "QUERY" | "INSTANT_QUERY" | "A_HREF_TAG" | "LINK_HREF_TAG" | "IMG_ALT_TAG" | "IMG_SRC_TAG" | "META_CONTENT_TAG" | "TITLE" | "ANY" | "IMAGE_QUERY" | "CONTEXT_ENTITY" | "RESULT_ENTITY" | "CONTEXT_QUERY" | "SIMILAR_QUERIES" | "SPORE_GRAPH" | "OFFDOMAIN_ANCHOR" | "ONSITE_ANCHOR" | "NAME_CANDIDATE" | "TOPIC_LINK" | "QUERY_NAME_CANDIDATE" | "ANCHOR_NAME_CANDIDATE" | "INJECTED_NAME_CANDIDATE" | "REFERENCE_PAGE_URL" | "REFERENCE_PAGE_LINK" | "DEPRECATED_ENTITY_METADATA" | "STRONG_IDENTIFIER" | "REFERENCE_PAGE_URL_INLINK" | "REFERENCE_PAGE_LINK_INLINK" | "GEO_LINK" | "PRINCIPAL_NAME" | "NAME_BLACKLIST" | "ENTITY_CONTEXT_TOKENS" | "VIDEO_TRANSCRIPT" | "VIDEO_OCR" | "IMAGE_OCR" | "LENS" | "ONLY_LOOKUP_METADATA" | "EMBEDDED_CONTENT";
}

function serializeRepositoryWebrefAnnotationStatsPerType(data: any): RepositoryWebrefAnnotationStatsPerType {
  return {
    ...data,
    numRangesWithCandidates: data["numRangesWithCandidates"] !== undefined ? String(data["numRangesWithCandidates"]) : undefined,
    numRangesWithCandidatesCap: data["numRangesWithCandidatesCap"] !== undefined ? String(data["numRangesWithCandidatesCap"]) : undefined,
    numRangesWithCandidatesUncap: data["numRangesWithCandidatesUncap"] !== undefined ? String(data["numRangesWithCandidatesUncap"]) : undefined,
  };
}

function deserializeRepositoryWebrefAnnotationStatsPerType(data: any): RepositoryWebrefAnnotationStatsPerType {
  return {
    ...data,
    numRangesWithCandidates: data["numRangesWithCandidates"] !== undefined ? BigInt(data["numRangesWithCandidates"]) : undefined,
    numRangesWithCandidatesCap: data["numRangesWithCandidatesCap"] !== undefined ? BigInt(data["numRangesWithCandidatesCap"]) : undefined,
    numRangesWithCandidatesUncap: data["numRangesWithCandidatesUncap"] !== undefined ? BigInt(data["numRangesWithCandidatesUncap"]) : undefined,
  };
}

/**
 * Holds annotator checkpoints which record the state of the annotations. This
 * is useful for tracking down the source of diffs, in particular for
 * non-determinism.
 */
export interface RepositoryWebrefAnnotatorCheckpointFprint {
  fingerprint?: bigint;
  label?: string;
}

function serializeRepositoryWebrefAnnotatorCheckpointFprint(data: any): RepositoryWebrefAnnotatorCheckpointFprint {
  return {
    ...data,
    fingerprint: data["fingerprint"] !== undefined ? String(data["fingerprint"]) : undefined,
  };
}

function deserializeRepositoryWebrefAnnotatorCheckpointFprint(data: any): RepositoryWebrefAnnotatorCheckpointFprint {
  return {
    ...data,
    fingerprint: data["fingerprint"] !== undefined ? BigInt(data["fingerprint"]) : undefined,
  };
}

/**
 * A message to collect annotator performance data.
 */
export interface RepositoryWebrefAnnotatorProfile {
  numCandidateMentions?: number;
  numEntities?: number;
  numMentions?: number;
  numTokens?: number;
  /**
   * Root/total of the timings from all the processors that worked on the given
   * document or query.
   */
  processorTimingsRoot?: RepositoryWebrefProcessorTiming;
}

function serializeRepositoryWebrefAnnotatorProfile(data: any): RepositoryWebrefAnnotatorProfile {
  return {
    ...data,
    processorTimingsRoot: data["processorTimingsRoot"] !== undefined ? serializeRepositoryWebrefProcessorTiming(data["processorTimingsRoot"]) : undefined,
  };
}

function deserializeRepositoryWebrefAnnotatorProfile(data: any): RepositoryWebrefAnnotatorProfile {
  return {
    ...data,
    processorTimingsRoot: data["processorTimingsRoot"] !== undefined ? deserializeRepositoryWebrefProcessorTiming(data["processorTimingsRoot"]) : undefined,
  };
}

/**
 * Book editions metadata for a book entity. This metadata is a pair of
 * "/book/book_edition" mid and its ISBN number.
 */
export interface RepositoryWebrefBookEditionMetadata {
  /**
   * Use varint encoding to save space.
   */
  bookEditionIsbn?: bigint;
  bookEditionMid?: bigint;
}

function serializeRepositoryWebrefBookEditionMetadata(data: any): RepositoryWebrefBookEditionMetadata {
  return {
    ...data,
    bookEditionIsbn: data["bookEditionIsbn"] !== undefined ? String(data["bookEditionIsbn"]) : undefined,
    bookEditionMid: data["bookEditionMid"] !== undefined ? String(data["bookEditionMid"]) : undefined,
  };
}

function deserializeRepositoryWebrefBookEditionMetadata(data: any): RepositoryWebrefBookEditionMetadata {
  return {
    ...data,
    bookEditionIsbn: data["bookEditionIsbn"] !== undefined ? BigInt(data["bookEditionIsbn"]) : undefined,
    bookEditionMid: data["bookEditionMid"] !== undefined ? BigInt(data["bookEditionMid"]) : undefined,
  };
}

export interface RepositoryWebrefBootstrappingScore {
  scoreRatio?: number;
}

/**
 * High level category annotations for documents and queries.
 */
export interface RepositoryWebrefCategoryAnnotation {
  /**
   * Experimental scores to be used by Discover.
   */
  browsyTopic?: RepositoryWebrefCategoryAnnotationBrowsyTopic;
  /**
   * Title of the category. Eg "Politics", "Technology".
   */
  debugString?: string;
  /**
   * Sources asserting the category. In the future we may have one calibrated
   * confidence score.
   */
  hitcat?: RepositoryWebrefCategoryAnnotationHitCatSource;
  /**
   * Mid representation of the category. Eg "/m/05qt0". WARNING: In UDR this
   * field is not populated, use document_entity.entity.mid instead of
   * document_entity.category.mid.
   */
  mid?: string;
  /**
   * Qprime asserting this category.
   */
  shopping?: RepositoryWebrefCategoryAnnotationShoppingSignals;
}

/**
 * Experimental scores for browsy topics, see *
 * go/example-docs-with-implicit-fashion-styles * go/browsy-entities
 */
export interface RepositoryWebrefCategoryAnnotationBrowsyTopic {
  confidence?: number;
}

/**
 * The HitCat page classifier. See go/hitcat2 If you use any HitCat score,
 * please: 1. Add your use-case to go/hits-clients. 2. Subscribe to hits-users@
 * to receive general updates.
 */
export interface RepositoryWebrefCategoryAnnotationHitCatSource {
  /**
   * Confidence of the category in the range [0.0, 1.0). If a page has the
   * category "NBA" with high confidence we also expect it to have the
   * "Basketball" with high confidence. Categories with a confidence lower than
   * 0.05 are omitted. This can be interpreted as a confidence of 0, i.e. a
   * strong signal that the category is not relevant for the page. For some
   * categories this score is calibrated per-category to estimate the true
   * precision. E.g., 70% of documents retrieved within the confidence range
   * [0.7 - eps, 0.7 + eps] will be relevant when eps is close to 0.
   */
  confidence?: number;
  /**
   * Calibrated cumulative confidence guaranteeing maxmial recall for a
   * precision target. E.g., At least 90% of documents retrieved with
   * cumulative_confidence >= 0.9 will be relevant. This score is always
   * calibrated per-category to estimate the true cumulative precision and is
   * not set for uncalibrated categories.
   */
  cumulativeConfidence?: number;
  /**
   * Note: For testing the next version. May change at any time. Experimental
   * confidence of the category in the range (0.0, 1.0).
   */
  experimentalConfidence?: number;
}

/**
 * The QPrime query classifier signals.
 */
export interface RepositoryWebrefCategoryAnnotationShoppingSignals {
  /**
   * Whether QPrime asserts that particular category.
   */
  isShoppingAnnotation?: boolean;
}

/**
 * All informations about category types of the entity.
 */
export interface RepositoryWebrefCategoryInfo {
  /**
   * Contains all types relevant for this entity, along with their provenances
   * and confidences. This field basically replicates information above in a
   * unified way, so that Refcon scroing can make better use of it. If present,
   * Refcon scoring will use all_types, and ignore other fields like
   * freebase_type. Note: there is some basic conflict resolution applied when
   * all_types are computed (implemented in type-extractor.cc,
   * IsLikelyConflictingFreebase).
   */
  allTypes?: RepositoryWebrefFreebaseType[];
  freebaseType?: RepositoryWebrefFreebaseType[];
  kgCollection?: RepositoryWebrefKGCollection[];
  oysterType?: RepositoryWebrefOysterType;
  /**
   * verticals4 categories that cooccur with this entity, aggregated over D2E.
   * See where we read from CompactDocClassification in
   * http://google3/repository/webref/preprocessing/fatcat-categories.cc.
   */
  salientCategory?: RepositoryWebrefFatcatCategory[];
  wikipediaCategory?: RepositoryWebrefWikipediaCategory[];
  /**
   * WPCat CategotyResult classification.
   */
  wpCategory?: RepositoryWebrefFreebaseType[];
}

function serializeRepositoryWebrefCategoryInfo(data: any): RepositoryWebrefCategoryInfo {
  return {
    ...data,
    allTypes: data["allTypes"] !== undefined ? data["allTypes"].map((item: any) => (serializeRepositoryWebrefFreebaseType(item))) : undefined,
    freebaseType: data["freebaseType"] !== undefined ? data["freebaseType"].map((item: any) => (serializeRepositoryWebrefFreebaseType(item))) : undefined,
    wpCategory: data["wpCategory"] !== undefined ? data["wpCategory"].map((item: any) => (serializeRepositoryWebrefFreebaseType(item))) : undefined,
  };
}

function deserializeRepositoryWebrefCategoryInfo(data: any): RepositoryWebrefCategoryInfo {
  return {
    ...data,
    allTypes: data["allTypes"] !== undefined ? data["allTypes"].map((item: any) => (deserializeRepositoryWebrefFreebaseType(item))) : undefined,
    freebaseType: data["freebaseType"] !== undefined ? data["freebaseType"].map((item: any) => (deserializeRepositoryWebrefFreebaseType(item))) : undefined,
    wpCategory: data["wpCategory"] !== undefined ? data["wpCategory"].map((item: any) => (deserializeRepositoryWebrefFreebaseType(item))) : undefined,
  };
}

/**
 * Metadata about clusters. See go/webref-variants for details. Next available
 * tag: 6.
 */
export interface RepositoryWebrefClusterMetadata {
  /**
   * If true, this entity is a synthetic entity created to represent a "set" in
   * a cluster, i.e. to represent a set of entities (its children in the cluster
   * graph) when we cannot disambiguate among them. This is similar to a KG
   * Collection, but this is not in KG.
   */
  isSet?: boolean;
  /**
   * Explanation of where this cluster, and this entity, come from. All
   * entities in a cluster have this, not just entities that have been created
   * because of the cluster.
   */
  ruleInstance?: RepositoryWebrefClusterProtoRuleInstance;
}

function serializeRepositoryWebrefClusterMetadata(data: any): RepositoryWebrefClusterMetadata {
  return {
    ...data,
    ruleInstance: data["ruleInstance"] !== undefined ? serializeRepositoryWebrefClusterProtoRuleInstance(data["ruleInstance"]) : undefined,
  };
}

function deserializeRepositoryWebrefClusterMetadata(data: any): RepositoryWebrefClusterMetadata {
  return {
    ...data,
    ruleInstance: data["ruleInstance"] !== undefined ? deserializeRepositoryWebrefClusterProtoRuleInstance(data["ruleInstance"]) : undefined,
  };
}

/**
 * A rule that defines a Cluster based on a list of mids. It creates a single
 * Set, and makes it the parent of each of the mids in the list.
 */
export interface RepositoryWebrefClusterProtoMidListRule {
  /**
   * Id of this rule; this is used to generate ids for the synthetic entities
   * created for a cluster. Required.
   */
  id?: string;
  /**
   * The mids of the entities that will be made into a cluster.
   */
  mid?: string[];
}

/**
 * An instance of a "mid list" rule. Each "mid list" rule defines exactly one
 * cluster.
 */
export interface RepositoryWebrefClusterProtoMidListRuleInstance {
  role?:  | "ELEMENT" | "SET";
  /**
   * The rule that this is an instance of. Required.
   */
  rule?: RepositoryWebrefClusterProtoMidListRule;
}

/**
 * A rule that defines a Cluster based on a relation. Given a relation (a link
 * type) R, then: For each entity B that has incoming links of type R This
 * defines an instance of this rule, with argument=B We create a Set S We make B
 * a child of S For each entity A that has a link R to B, we make A a child of S
 * Next available tag: 6
 */
export interface RepositoryWebrefClusterProtoRelationRule {
  /**
   * The topic_property_name for the link that defines the relation, e.g.
   * "/tv/tv_series_episode/series". Can start with a "!" to indicate that this
   * link is reversed during extraction and we want the reversed case. Required.
   */
  relation?: string;
}

/**
 * An instance of a "relation" rule. Each "relation" rule defines a number of
 * clusters, one for each entity B that that has incoming links of a certain
 * type R; all entities with an outgoing link to B of type R are part of that
 * cluster.
 */
export interface RepositoryWebrefClusterProtoRelationRuleInstance {
  role?:  | "SOURCE" | "TARGET" | "SET";
  /**
   * The rule that this is an instance of. Required.
   */
  rule?: RepositoryWebrefClusterProtoRelationRule;
  /**
   * The one entity that the links of type R point to. Required.
   */
  target?: RepositoryWebrefWebrefEntityId;
}

function serializeRepositoryWebrefClusterProtoRelationRuleInstance(data: any): RepositoryWebrefClusterProtoRelationRuleInstance {
  return {
    ...data,
    target: data["target"] !== undefined ? serializeRepositoryWebrefWebrefEntityId(data["target"]) : undefined,
  };
}

function deserializeRepositoryWebrefClusterProtoRelationRuleInstance(data: any): RepositoryWebrefClusterProtoRelationRuleInstance {
  return {
    ...data,
    target: data["target"] !== undefined ? deserializeRepositoryWebrefWebrefEntityId(data["target"]) : undefined,
  };
}

/**
 * When we apply a rule to define a particular cluster, we have a RuleInstance.
 * Some kinds of rules for clusters define more than one cluster. In those rules
 * we say things like "for each entity X with this property, we create a cluster
 * where..."; each particular cluster that we create is the result of an
 * *instance* of that rule, where the argument X has been bound to a particular
 * entity (note that this also applies to rules that define only one cluster; in
 * that case, there are no arguments). An entity that is part of a cluster plays
 * a "role" in such a cluster. This message describes such an instantiation of a
 * rule with a role and with concrete values for the arguments.
 */
export interface RepositoryWebrefClusterProtoRuleInstance {
  /**
   * Exactly one of these *RuleInstance fields needs to be present for clusters
   * which have not been merged; it selects the specific kind of rule instance.
   * For merged clusters both fields may be present.
   */
  midList?: RepositoryWebrefClusterProtoMidListRuleInstance;
  relation?: RepositoryWebrefClusterProtoRelationRuleInstance[];
}

function serializeRepositoryWebrefClusterProtoRuleInstance(data: any): RepositoryWebrefClusterProtoRuleInstance {
  return {
    ...data,
    relation: data["relation"] !== undefined ? data["relation"].map((item: any) => (serializeRepositoryWebrefClusterProtoRelationRuleInstance(item))) : undefined,
  };
}

function deserializeRepositoryWebrefClusterProtoRuleInstance(data: any): RepositoryWebrefClusterProtoRuleInstance {
  return {
    ...data,
    relation: data["relation"] !== undefined ? data["relation"].map((item: any) => (deserializeRepositoryWebrefClusterProtoRelationRuleInstance(item))) : undefined,
  };
}

/**
 * Flattened version of possibly nested compound values. This means that the
 * `value` in here is *never* a `compound_value` and all predicate MIDs on the
 * nested path are collapsed into the repeated `predicate_encoded_mid` field.
 * When `predicate_encoded_mid` contains only one predicate, this is equivalent
 * to a CompactKgPropertyValue.
 */
export interface RepositoryWebrefCompactFlatPropertyValue {
  predicateEncodedMid?: bigint[];
  /**
   * The property corresponding to predicte_encoded_mid above. This is
   * populated in some non-serving tables.
   */
  propertyName?: string;
  value?: RepositoryWebrefCompactKgValue[];
}

function serializeRepositoryWebrefCompactFlatPropertyValue(data: any): RepositoryWebrefCompactFlatPropertyValue {
  return {
    ...data,
    predicateEncodedMid: data["predicateEncodedMid"] !== undefined ? data["predicateEncodedMid"].map((item: any) => (String(item))) : undefined,
    value: data["value"] !== undefined ? data["value"].map((item: any) => (serializeRepositoryWebrefCompactKgValue(item))) : undefined,
  };
}

function deserializeRepositoryWebrefCompactFlatPropertyValue(data: any): RepositoryWebrefCompactFlatPropertyValue {
  return {
    ...data,
    predicateEncodedMid: data["predicateEncodedMid"] !== undefined ? data["predicateEncodedMid"].map((item: any) => (BigInt(item))) : undefined,
    value: data["value"] !== undefined ? data["value"].map((item: any) => (deserializeRepositoryWebrefCompactKgValue(item))) : undefined,
  };
}

/**
 * Analog to freebase::PropertyValue
 */
export interface RepositoryWebrefCompactKgPropertyValue {
  encodedMid?: bigint;
  hrid?: string;
  value?: RepositoryWebrefCompactKgValue[];
  valueStatus?:  | "HAS_UNKNOWN_VALUE" | "HAS_NO_VALUE";
}

function serializeRepositoryWebrefCompactKgPropertyValue(data: any): RepositoryWebrefCompactKgPropertyValue {
  return {
    ...data,
    encodedMid: data["encodedMid"] !== undefined ? String(data["encodedMid"]) : undefined,
    value: data["value"] !== undefined ? data["value"].map((item: any) => (serializeRepositoryWebrefCompactKgValue(item))) : undefined,
  };
}

function deserializeRepositoryWebrefCompactKgPropertyValue(data: any): RepositoryWebrefCompactKgPropertyValue {
  return {
    ...data,
    encodedMid: data["encodedMid"] !== undefined ? BigInt(data["encodedMid"]) : undefined,
    value: data["value"] !== undefined ? data["value"].map((item: any) => (deserializeRepositoryWebrefCompactKgValue(item))) : undefined,
  };
}

/**
 * Analog to freebase::Topic
 */
export interface RepositoryWebrefCompactKgTopic {
  /**
   * Mid of the topic; only filled in if no values.
   */
  mid?: bigint;
  propertyValue?: RepositoryWebrefCompactKgPropertyValue[];
}

function serializeRepositoryWebrefCompactKgTopic(data: any): RepositoryWebrefCompactKgTopic {
  return {
    ...data,
    mid: data["mid"] !== undefined ? String(data["mid"]) : undefined,
    propertyValue: data["propertyValue"] !== undefined ? data["propertyValue"].map((item: any) => (serializeRepositoryWebrefCompactKgPropertyValue(item))) : undefined,
  };
}

function deserializeRepositoryWebrefCompactKgTopic(data: any): RepositoryWebrefCompactKgTopic {
  return {
    ...data,
    mid: data["mid"] !== undefined ? BigInt(data["mid"]) : undefined,
    propertyValue: data["propertyValue"] !== undefined ? data["propertyValue"].map((item: any) => (deserializeRepositoryWebrefCompactKgPropertyValue(item))) : undefined,
  };
}

/**
 * Analog to freebase::Value TODO(b/144526840) This representation has several
 * quality and performance issues. Next available tag number: 12
 */
export interface RepositoryWebrefCompactKgValue {
  /**
   * Present when value is bool.
   */
  boolValue?: boolean;
  /**
   * Compound values are those that contain either a number of simple valued
   * facets (such as a latitude/longitude pair), or "mediator" topics
   * representing multi-dimensional relationships between topics. See
   * metaweb/data/topictable/topic.proto for more details.
   */
  compoundValue?: RepositoryWebrefCompactKgTopic;
  /**
   * Present when value is datetime.
   */
  datetimeValue?: string;
  /**
   * Present when value is enum.
   */
  enumValue?: string;
  /**
   * Present when value is float.
   */
  floatValue?: number;
  /**
   * Present when value is an id.
   */
  idValue?: bigint;
  /**
   * Present when value is int.
   */
  intValue?: bigint;
  /**
   * Present when value is a serialized protocol buffer.
   */
  serializedProtoValue?: Uint8Array;
  /**
   * Present when value is text.
   */
  textValue?: string;
  /**
   * Present when value is URI.
   */
  uriValue?: string;
  /**
   * 32-bit fprint of uri. Can be used instead of `uri_value` to save space.
   * See `GetNormalizedUriFprint32()`.
   */
  uriValueFprint32?: number;
}

function serializeRepositoryWebrefCompactKgValue(data: any): RepositoryWebrefCompactKgValue {
  return {
    ...data,
    compoundValue: data["compoundValue"] !== undefined ? serializeRepositoryWebrefCompactKgTopic(data["compoundValue"]) : undefined,
    idValue: data["idValue"] !== undefined ? String(data["idValue"]) : undefined,
    intValue: data["intValue"] !== undefined ? String(data["intValue"]) : undefined,
    serializedProtoValue: data["serializedProtoValue"] !== undefined ? encodeBase64(data["serializedProtoValue"]) : undefined,
  };
}

function deserializeRepositoryWebrefCompactKgValue(data: any): RepositoryWebrefCompactKgValue {
  return {
    ...data,
    compoundValue: data["compoundValue"] !== undefined ? deserializeRepositoryWebrefCompactKgTopic(data["compoundValue"]) : undefined,
    idValue: data["idValue"] !== undefined ? BigInt(data["idValue"]) : undefined,
    intValue: data["intValue"] !== undefined ? BigInt(data["intValue"]) : undefined,
    serializedProtoValue: data["serializedProtoValue"] !== undefined ? decodeBase64(data["serializedProtoValue"] as string) : undefined,
  };
}

/**
 * The ArgumentValue reference to Mention.CompoundMention.Component. Next
 * available tag number: 4
 */
export interface RepositoryWebrefComponentReference {
  /**
   * Optionally the freebase_mid of the WebrefEntity which the Component
   * identifies via entity_index. This is purely to help humans diagnose the
   * WebrefEntities structure, may not always be present and should not be used
   * by production code. Use QueryJoinToMeaningStructConverter to compose a
   * proper value in place of the component reference.
   */
  debugEntity?: string;
  /**
   * The WebrefEntity referenced by `index` is equivalent to this function call
   * in this context, but not universally such that we don't want to recursively
   * expand its MRF. Use this for example if an entity corresponds to a category
   * in an Intersect: CellPhones() & RelatedTo(/m/foo), where /m/cell_phones is
   * equivalent to CellPhones() (and may or may not have an annotated span), but
   * we don't want to generally assert that /m/cell_phones == CellPhones(). This
   * cannot be an actual FunctionCall to avoid a circular dependency.
   */
  funcallName?: string;
  /**
   * The index of the Component of the CompoundMention which has the mrf_index
   * of this MRF expression in WebrefEntity. Required.
   */
  index?: number;
}

/**
 * Metadata proto to be stored in concept tables. Note: Name table only stores
 * name_type_mask for better performance. Remember to change NameToConceptEntry
 * if you add a field to this proto.
 */
export interface RepositoryWebrefConceptNameMetadata {
  /**
   * Bitfield of ConceptNameMetadata::NameType bits.
   */
  nameTypeMask?: bigint;
}

function serializeRepositoryWebrefConceptNameMetadata(data: any): RepositoryWebrefConceptNameMetadata {
  return {
    ...data,
    nameTypeMask: data["nameTypeMask"] !== undefined ? String(data["nameTypeMask"]) : undefined,
  };
}

function deserializeRepositoryWebrefConceptNameMetadata(data: any): RepositoryWebrefConceptNameMetadata {
  return {
    ...data,
    nameTypeMask: data["nameTypeMask"] !== undefined ? BigInt(data["nameTypeMask"]) : undefined,
  };
}

/**
 * Detailed scores about the topicality of an entity. Next available tag: 16
 */
export interface RepositoryWebrefDetailedEntityScores {
  /**
   * Represents how much the entity is connected/related to the other entities
   * in the document. This signal partially influences the topicality score, but
   * it is not totally aligned with it: an entity can be very related to the
   * rest of the document, but not central for understanding it. Likewise, an
   * entity can be central to understand a document, but not very related to the
   * rest of the document. The value is in [0, 1].
   */
  connectedness?: number;
  /**
   * How well the document scores for the entity. The score is unnormalized,
   * and serves as a relative ranking signal between different documents for an
   * entity.
   */
  docScore?: number;
  /**
   * If the annotation corresponds to a geo topic, this is populated with
   * GeoTopic::normalized_score.
   */
  geoTopicNormalizedScore?: number;
  /**
   * True if the entity is the author of the document. This was mainly
   * developed and tuned for news articles (e.g. /m/02x27qn on
   * "www.vogue.com/article/flint-town-netflix") but is also popluated for other
   * content (e.g. scientific articles). Important: the semantics of this field
   * may change in the future or it might be removed and replaced with a
   * different API. If you want to use this field, please reach out to
   * ke-authors@ first.
   */
  isAuthor?: boolean;
  /**
   * True if the entity is the publisher of the page (e.g. CNN on
   * "http://www.cnn.com/foo/bar").
   */
  isPublisher?: boolean;
  /**
   * Set to true iff the entity matches the full URL of the document, meaning
   * that it is a reference page or related page of the entity.
   */
  isReferencePage?: boolean;
  /**
   * If the annotation corresponds to a local entity, this is populated with
   * LocalEntityAnnotations::Instance::location_confidence.
   */
  localEntityLocationConfidence?: number;
  /**
   * Representation of the topicality score that is normalized in [0, 1] and
   * which sum over all entities in the document is 1. It represents the
   * "proportion" of the document that talks about the entity. This score is
   * less human interpretable as the bucketized topicality score
   * (EntityAnnotations.topicality_score), but is more suited for some usages
   * like aggregations.
   */
  normalizedTopicality?: number;
  /**
   * Signals used for mining new reference pages, set by the
   * reference-page-scorer processor (that is turned off by default). This field
   * is not populated, except for special reference page extraction runs.
   */
  referencePageScores?: RepositoryWebrefReferencePageScores;
  /**
   * Relevance score generated by a Machine Learning entity classifier. This
   * signal is similar to topicality, but machine learning based and supported
   * by EntitySignals, not Webref. See http://go/entityclassifier for details on
   * the classifier.
   */
  relevanceScore?: number;
}

export interface RepositoryWebrefDetailedMentionScores {
  /**
   * How much support this mention received from the results for PostRef. This
   * is populated only if explicitly requested and different from 0.
   */
  resultEntityScore?: number;
}

/**
 * Information that can be used to display the entity (e.g. title, image...).
 */
export interface RepositoryWebrefDisplayInfo {
  /**
   * Per language display name from reliable sources.
   */
  displayName?: RepositoryWebrefDisplayName[];
}

/**
 * Per language display name from reliable sources (e.g. Freebase, Wikipedia).
 * The name can be ambiguous (e.g. "Springfield" rather than "Springfield,
 * Idaho"), and is thus to be used in a context which provides sufficient
 * disambiguation. See: http://go/entity-names WARNING: This data is DEPRECATED
 * and any user-visible entity names need to be fetched from TopicServer. Note
 * that any display names included in this proto are merely a pass-through from
 * KG and have no freshness guarantees.
 */
export interface RepositoryWebrefDisplayName {
  /**
   * An encylopedia style topic name (e.g. "Dog", not "Dogs"). Corresponds to
   * Freebase /type/object/name and similar sources.
   */
  canonicalName?: string;
  /**
   * The language of this name. See http://goto/iii for all the details on the
   * language identifiers.
   */
  language?: string;
  /**
   * A name as it would be used for a news topic, an interest, the subject of a
   * story. E.g. in list of things ("Related topics: Smartphones, computers,
   * accidents". "Interests: Dogs"). *Fall back:* If the field is not populated,
   * fall back to the "canonical_name" field. This field is usually not
   * populated since (a) in most cases the subject form name is the same as the
   * canonical name, and (b) data coverage of subject-form names is currently
   * much lower than data coverage of canonical names. Note: In some languages
   * (e.g. French) the difference between canonical names and subject names is
   * larger than in English (not just plural vs. singular), but still strictly
   * grammatical (including an article, capitalization, plural vs. singular).
   * Corresponds to Freebase /freebase/linguistic_hint/subject_form.
   */
  subjectName?: string;
}

/**
 * List of PerDocRelevanceRatings for Precision@5 evals done via ewok (template
 * 2282).
 */
export interface RepositoryWebrefDocLevelRelevanceRatings {
  perDocRelevanceRatings?: RepositoryWebrefPerDocRelevanceRatings[];
}

function serializeRepositoryWebrefDocLevelRelevanceRatings(data: any): RepositoryWebrefDocLevelRelevanceRatings {
  return {
    ...data,
    perDocRelevanceRatings: data["perDocRelevanceRatings"] !== undefined ? data["perDocRelevanceRatings"].map((item: any) => (serializeRepositoryWebrefPerDocRelevanceRatings(item))) : undefined,
  };
}

function deserializeRepositoryWebrefDocLevelRelevanceRatings(data: any): RepositoryWebrefDocLevelRelevanceRatings {
  return {
    ...data,
    perDocRelevanceRatings: data["perDocRelevanceRatings"] !== undefined ? data["perDocRelevanceRatings"].map((item: any) => (deserializeRepositoryWebrefPerDocRelevanceRatings(item))) : undefined,
  };
}

/**
 * Information about the document which is not produced by webref, typically
 * copied from the docjoin. Next available tag: 15
 */
export interface RepositoryWebrefDocumentMetadata {
  /**
   * The timestamp of when the document was crawled (if known). Copied from
   * CompositeDoc.Content.CrawlTime.
   */
  crawlTime?: bigint;
  /**
   * Fingerprint of the document. We compute and set this fingerprint when
   * creating the pagesets that we use for evals. Otherwise, this field is not
   * normally set. We use the field to make sure that the human ratings that we
   * have are generated for the same version of the document, otherwise they
   * might be invalid. We do not compute the fingerprint on the fly (e.g. as a
   * fingerprint of the proto buffer serialization of the cdoc) because protocol
   * buffer serialization is not stable.
   */
  docFp?: bigint;
  /**
   * DocId of the annotated document as read from cdoc.doc().docid().
   */
  docId?: bigint;
  /**
   * Urls that forward to this url. Needed for url -> topical entity entries.
   */
  forwardingUrls?: RepositoryWebrefForwardingUrls;
  /**
   * Set to true if the document is a known disambiguation page, e.g.
   * https://en.wikipedia.org/wiki/Orange.
   */
  isDisambiguationPage?: boolean;
  /**
   * The document language, as read from doc().content().language(). This is
   * go/language-enum value.
   */
  language?:  | "ENGLISH" | "DANISH" | "DUTCH" | "FINNISH" | "FRENCH" | "GERMAN" | "HEBREW" | "ITALIAN" | "JAPANESE" | "KOREAN" | "NORWEGIAN" | "POLISH" | "PORTUGUESE" | "RUSSIAN" | "SPANISH" | "SWEDISH" | "CHINESE" | "CZECH" | "GREEK" | "ICELANDIC" | "LATVIAN" | "LITHUANIAN" | "ROMANIAN" | "HUNGARIAN" | "ESTONIAN" | "TG_UNKNOWN_LANGUAGE" | "UNKNOWN_LANGUAGE" | "BULGARIAN" | "CROATIAN" | "SERBIAN" | "IRISH" | "GALICIAN" | "TAGALOG" | "TURKISH" | "UKRAINIAN" | "HINDI" | "MACEDONIAN" | "BENGALI" | "INDONESIAN" | "LATIN" | "MALAY" | "MALAYALAM" | "WELSH" | "NEPALI" | "TELUGU" | "ALBANIAN" | "TAMIL" | "BELARUSIAN" | "JAVANESE" | "OCCITAN" | "URDU" | "BIHARI" | "GUJARATI" | "THAI" | "ARABIC" | "CATALAN" | "ESPERANTO" | "BASQUE" | "INTERLINGUA" | "KANNADA" | "PUNJABI" | "SCOTS_GAELIC" | "SWAHILI" | "SLOVENIAN" | "MARATHI" | "MALTESE" | "VIETNAMESE" | "FRISIAN" | "SLOVAK" | "CHINESE_T" | "FAROESE" | "SUNDANESE" | "UZBEK" | "AMHARIC" | "AZERBAIJANI" | "GEORGIAN" | "TIGRINYA" | "PERSIAN" | "BOSNIAN" | "SINHALESE" | "NORWEGIAN_N" | "PORTUGUESE_P" | "PORTUGUESE_B" | "XHOSA" | "ZULU" | "GUARANI" | "SESOTHO" | "TURKMEN" | "KYRGYZ" | "BRETON" | "TWI" | "YIDDISH" | "SERBO_CROATIAN" | "SOMALI" | "UIGHUR" | "KURDISH" | "MONGOLIAN" | "ARMENIAN" | "LAOTHIAN" | "SINDHI" | "RHAETO_ROMANCE" | "AFRIKAANS" | "LUXEMBOURGISH" | "BURMESE" | "KHMER" | "TIBETAN" | "DHIVEHI" | "CHEROKEE" | "SYRIAC" | "LIMBU" | "ORIYA" | "ASSAMESE" | "CORSICAN" | "INTERLINGUE" | "KAZAKH" | "LINGALA" | "MOLDAVIAN" | "PASHTO" | "QUECHUA" | "SHONA" | "TAJIK" | "TATAR" | "TONGA" | "YORUBA" | "CREOLES_AND_PIDGINS_ENGLISH_BASED" | "CREOLES_AND_PIDGINS_FRENCH_BASED" | "CREOLES_AND_PIDGINS_PORTUGUESE_BASED" | "CREOLES_AND_PIDGINS_OTHER" | "MAORI" | "WOLOF" | "ABKHAZIAN" | "AFAR" | "AYMARA" | "BASHKIR" | "BISLAMA" | "DZONGKHA" | "FIJIAN" | "GREENLANDIC" | "HAUSA" | "HAITIAN_CREOLE" | "INUPIAK" | "INUKTITUT" | "KASHMIRI" | "KINYARWANDA" | "MALAGASY" | "NAURU" | "OROMO" | "RUNDI" | "SAMOAN" | "SANGO" | "SANSKRIT" | "SISWANT" | "TSONGA" | "TSWANA" | "VOLAPUK" | "ZHUANG" | "KHASI" | "SCOTS" | "GANDA" | "MANX" | "MONTENEGRIN" | "AKAN" | "IGBO" | "MAURITIAN_CREOLE" | "HAWAIIAN" | "CEBUANO" | "EWE" | "GA" | "HMONG" | "KRIO" | "LOZI" | "LUBA_LULUA" | "LUO_KENYA_AND_TANZANIA" | "NEWARI" | "NYANJA" | "OSSETIAN" | "PAMPANGA" | "PEDI" | "RAJASTHANI" | "SESELWA_CREOLE_FRENCH" | "TUMBUKA" | "VENDA" | "WARAY_PHILIPPINES" | "NUM_LANGUAGES";
  /**
   * The (weighted) number of incoming anchors (links from other documents).
   */
  numIncomingAnchors?: number;
  /**
   * The salient terms for this document. Only set if
   * --webref_doc_metadata_copy_salient_terms is true. Same motivation as the
   * title field above.
   */
  salientTerms?: QualitySalientTermsSalientTermSet;
  /**
   * The title of the document. Only set if --webref_doc_metadata_set_title is
   * true. The idea is that we can use this to more easily learn things like:
   * title contains "restaurants" -> more likely to be a list page.
   */
  title?: string;
  /**
   * The total clicks on this document, taken from navboost data.
   */
  totalClicks?: number;
  /**
   * The url of the document.
   */
  url?: string;
}

function serializeRepositoryWebrefDocumentMetadata(data: any): RepositoryWebrefDocumentMetadata {
  return {
    ...data,
    crawlTime: data["crawlTime"] !== undefined ? String(data["crawlTime"]) : undefined,
    docFp: data["docFp"] !== undefined ? String(data["docFp"]) : undefined,
    docId: data["docId"] !== undefined ? String(data["docId"]) : undefined,
  };
}

function deserializeRepositoryWebrefDocumentMetadata(data: any): RepositoryWebrefDocumentMetadata {
  return {
    ...data,
    crawlTime: data["crawlTime"] !== undefined ? BigInt(data["crawlTime"]) : undefined,
    docFp: data["docFp"] !== undefined ? BigInt(data["docFp"]) : undefined,
    docId: data["docId"] !== undefined ? BigInt(data["docId"]) : undefined,
  };
}

/**
 * Represents a domain specific entity data.
 */
export interface RepositoryWebrefDomainSpecificRepresentation {
  /**
   * The actual domain specific data. For example it can be freebase.Topic,
   * repository_wikipedia.WikiJoin, ocean.WorkMetadata, geostore.Feature.
   */
  entityData?: Proto2BridgeMessageSet;
}

/**
 * Top level proto for enricher specific debug data that is only displayed in
 * the Webref demo and should not be used for anything production-related. Next
 * id: 4.
 */
export interface RepositoryWebrefEnricherDebugData {
  /**
   * Contains selected properties (from KG) whose values are not other entities
   * (in which case they would be represented in link_info) but scalar values,
   * possibly reachable through (multiple) CVTs.
   */
  nonMidProperties?: RepositoryWebrefCompactFlatPropertyValue[];
  /**
   * This field contains reference pages for this entity. A reference page is a
   * page that is highly topical for this entity, which can be used to mine
   * additional information about this entity. Example reference pages for Apple
   * Inc. would be the composite docs for
   * "http://en.wikipedia.org/wiki/Apple_Inc." and http://www.apple.com. For
   * actors or movies, you can also have the imdb page. Also see:
   * http://go/refx-pages.
   */
  referencePage?: RepositoryWebrefSimplifiedCompositeDoc[];
  /**
   * This field contains mined related pages for the entity. A related page is
   * a page that is moderately topical for this entity (More details:
   * http://shortn/_KCE0GfQlpJ). This is mainly used to mine additional
   * information for entities which do not have reference pages Unlike reference
   * pages, a single doc can be a related page for multiple mids.
   */
  relatedPage?: RepositoryWebrefSimplifiedCompositeDoc[];
}

function serializeRepositoryWebrefEnricherDebugData(data: any): RepositoryWebrefEnricherDebugData {
  return {
    ...data,
    nonMidProperties: data["nonMidProperties"] !== undefined ? data["nonMidProperties"].map((item: any) => (serializeRepositoryWebrefCompactFlatPropertyValue(item))) : undefined,
    referencePage: data["referencePage"] !== undefined ? data["referencePage"].map((item: any) => (serializeRepositoryWebrefSimplifiedCompositeDoc(item))) : undefined,
    relatedPage: data["relatedPage"] !== undefined ? data["relatedPage"].map((item: any) => (serializeRepositoryWebrefSimplifiedCompositeDoc(item))) : undefined,
  };
}

function deserializeRepositoryWebrefEnricherDebugData(data: any): RepositoryWebrefEnricherDebugData {
  return {
    ...data,
    nonMidProperties: data["nonMidProperties"] !== undefined ? data["nonMidProperties"].map((item: any) => (deserializeRepositoryWebrefCompactFlatPropertyValue(item))) : undefined,
    referencePage: data["referencePage"] !== undefined ? data["referencePage"].map((item: any) => (deserializeRepositoryWebrefSimplifiedCompositeDoc(item))) : undefined,
    relatedPage: data["relatedPage"] !== undefined ? data["relatedPage"].map((item: any) => (deserializeRepositoryWebrefSimplifiedCompositeDoc(item))) : undefined,
  };
}

/**
 * All annotations for a given concept (in one document collection). Available
 * tags: [10-15], [19-]
 */
export interface RepositoryWebrefEntityAnnotations {
  /**
   * The overall confidence that the entity is annotated somewhere in the
   * document or query. For WebRef it is computed as a function of the mention
   * confidences weighted by the importance of each mention, where for documents
   * a mention is of greater importance if it occurs in the title, h1 or
   * anchors. For QRef it is just the maximum of the confidence over all
   * mentions. NOTE: You probably want to use the mention-level
   * segment_mentions.mention.confidence_score field instead of this one.
   */
  confidenceScore?: number;
  debugInfo?: RepositoryWebrefAnnotationDebugInfo;
  /**
   * Additional information about how the entity relates to the page, for
   * example whether it is a business entity which published the page.
   */
  detailedEntityScores?: RepositoryWebrefDetailedEntityScores;
  /**
   * All ranges explained by the entity or any other entity it implies. Used in
   * the context of partial query interpretation (go/partial-understanding).
   */
  explainedRangeInfo?: RepositoryWebrefExplainedRangeInfo;
  /**
   * An entity is marked as implicit if there is no explicit mention of the
   * entity in the content of the page. For instance, all mentions of the entity
   * are in query, url and/or anchors; or the entity has only implicit content
   * mentions.
   */
  isImplicit?: boolean;
  /**
   * True if the entity is an MDVC summary entity, i.e. it might not be
   * mentioned directly on the query, but it is the product of resolving a set
   * of explicit annotations. E.g. "2014 FIFA World Cup" can be the summary for
   * the query: [soccer world cup in brazil] even though none of the names of
   * the entity is mentioned on the query. Summary nodes can also be synthetic,
   * i.e. have a /t/ mid, as they represent the intersection between a set of
   * regular annotations. For more information, see http://go/mdvc-output.
   */
  isResolution?: boolean;
  /**
   * All mentions of a given concept grouped by segments. For Webref, there are
   * many different kinds of segment, such as content, title and anchors; while
   * for QRef, there is only one segment called CONTENT. For QRef this field
   * contains the primary output of the annotator, and for WebRef it together
   * with topicality_score does.
   */
  segmentMentions?: RepositoryWebrefSegmentMentions[];
  /**
   * Rank of the entity when sorted by topicality score.
   */
  topicalityRank?: number;
  /**
   * The WebRef topicality score of the entity for this document. This score
   * indicates how related is the entity to the overall topic of the document.
   * See https://goto.google.com/topicality-score for details. This field is not
   * present in QRef output. Note that the topicality and the confidence score
   * are orthogonal measures. It is possible that the annotator is absolutely
   * sure that an entity is mentioned in a given range in the document, but this
   * entity may be unrelated to the overall topic of the page (e.g. the entity
   * "RSS" is mentioned in the footer of appleinsider.com). In this case the
   * mention has a very high confidence score, but very low topicality score.
   */
  topicalityScore?: number;
}

function serializeRepositoryWebrefEntityAnnotations(data: any): RepositoryWebrefEntityAnnotations {
  return {
    ...data,
    explainedRangeInfo: data["explainedRangeInfo"] !== undefined ? serializeRepositoryWebrefExplainedRangeInfo(data["explainedRangeInfo"]) : undefined,
    segmentMentions: data["segmentMentions"] !== undefined ? data["segmentMentions"].map((item: any) => (serializeRepositoryWebrefSegmentMentions(item))) : undefined,
  };
}

function deserializeRepositoryWebrefEntityAnnotations(data: any): RepositoryWebrefEntityAnnotations {
  return {
    ...data,
    explainedRangeInfo: data["explainedRangeInfo"] !== undefined ? deserializeRepositoryWebrefExplainedRangeInfo(data["explainedRangeInfo"]) : undefined,
    segmentMentions: data["segmentMentions"] !== undefined ? data["segmentMentions"].map((item: any) => (deserializeRepositoryWebrefSegmentMentions(item))) : undefined,
  };
}

/**
 * Provides some debug info for the entity. This data shown to engineers (for
 * debugging) and to raters (so it ultimately impacts eval metrics), but is also
 * used to train ML models (see below). IMPORTANT: Despite the proto naming,
 * this data has production quality impact. The data below is mostly
 * human-readable text that is useful to help engineers with debugging. However
 * the text is also used as input to machine-learned natural language processing
 * models, which are used in production Webref.
 */
export interface RepositoryWebrefEntityDebugInfo {
  /**
   * A human-readable description of the entity. This can range from brief,
   * machine-generated notes to lengthy human-written paragraphs from Wikipedia.
   */
  description?: string;
  /**
   * The language (III LanguageCode) of the `title` and `description` fields.
   */
  language?: string;
  /**
   * Internal score to merge debug info. should not set in final entityjoins.
   */
  score?: number;
  /**
   * A short human-readable name/title of the entity, similar to what is
   * displayed at the top of a Hume page. Suitable to be displayed in a list.
   */
  title?: string;
  /**
   * Link to a page with more information about the entity (internal Hume page,
   * external Wikipedia page, etc.).
   */
  url?: string;
}

/**
 * Next available tag: 35. Represents all the information that we have for a
 * given entity.
 */
export interface RepositoryWebrefEntityJoin {
  /**
   * The id of this entity, prefer accessing through webref-entities-util.h
   * functions.
   */
  annotatedEntityId?: RepositoryWebrefWebrefEntityId;
  /**
   * This field contains reference pages for this entity. A reference page is a
   * page that is highly topical for this entity, which can be used to mine
   * additional information about this entity. Example reference pages for Apple
   * Inc. would be the composite docs for
   * "http://en.wikipedia.org/wiki/Apple_Inc." and http://www.apple.com. For
   * actors or movies, you can also have the imdb page. Also see:
   * http://go/refx-pages.
   */
  cdoc?: RepositoryWebrefSimplifiedCompositeDoc[];
  /**
   * The context names (with scores) of this entity. The difference to regular
   * names (aka name_info) is that context names are not used for finding
   * mentions in a document as they consist of names somehow related to the
   * entity (e.g. name "fisherman s wharf" for the entity "Gary Danko"). Used
   * for reconciling freebase and oyster.
   */
  contextNameInfo?: RepositoryWebrefGlobalNameInfo[];
  /**
   * Debug information about the entity.
   */
  debugInfo?: RepositoryWebrefEntityDebugInfo[];
  /**
   * Optional profiling data from the enricher that enriched this entity (and
   * produced this EntityJoin as debug output).
   */
  enricherAnnotatorProfile?: RepositoryWebrefAnnotatorProfile;
  /**
   * Contains debug data produced by enricher and only used for debug purpose
   * (e.g. demo).
   */
  enricherDebugData?: RepositoryWebrefEnricherDebugData;
  /**
   * Additional metadata about the entity, that can be derived from the "raw
   * data" (composite doc, domain specific data...), or come from other sources.
   * Despite its name, this field often contains quite important information.
   */
  extraData?: RepositoryWebrefExtraMetadata;
  /**
   * Human ratings (e.g. ratings from EWOK). This is typically only populated
   * in the evaluation pipelines (e.g. P@5).
   */
  humanRatings?: RepositoryWebrefHumanRatings;
  /**
   * Contains all links (with scores) that Webref knows for this entity. Links
   * are relationships between entities. The data in this field is very
   * important for the quality of the model.
   */
  linkInfo?: RepositoryWebrefGlobalLinkInfo[];
  /**
   * Contains all names (with scores) that Webref knows for this entity. The
   * data in this field is very important for the quality of the model.
   */
  nameInfo?: RepositoryWebrefGlobalNameInfo[];
  /**
   * Contains names and names metadata used by Refcon.
   */
  refconNameInfo?: RepositoryWebrefRefconRefconNameInfo[];
  /**
   * An entity can have metadata from various data sources. Generally speaking
   * all sources will be / should be reconciled into a single KG Topic entry.
   * However, in some cases we pull in additional chunks of metadata from these
   * sources; these are stored in this field. For example a local business could
   * have a KG entry (topic proto), wikipedia entry (WikiJoin) and a MapFacts
   * entry (Feature proto).
   */
  representation?: RepositoryWebrefDomainSpecificRepresentation[];
}

function serializeRepositoryWebrefEntityJoin(data: any): RepositoryWebrefEntityJoin {
  return {
    ...data,
    annotatedEntityId: data["annotatedEntityId"] !== undefined ? serializeRepositoryWebrefWebrefEntityId(data["annotatedEntityId"]) : undefined,
    cdoc: data["cdoc"] !== undefined ? data["cdoc"].map((item: any) => (serializeRepositoryWebrefSimplifiedCompositeDoc(item))) : undefined,
    contextNameInfo: data["contextNameInfo"] !== undefined ? data["contextNameInfo"].map((item: any) => (serializeRepositoryWebrefGlobalNameInfo(item))) : undefined,
    enricherAnnotatorProfile: data["enricherAnnotatorProfile"] !== undefined ? serializeRepositoryWebrefAnnotatorProfile(data["enricherAnnotatorProfile"]) : undefined,
    enricherDebugData: data["enricherDebugData"] !== undefined ? serializeRepositoryWebrefEnricherDebugData(data["enricherDebugData"]) : undefined,
    extraData: data["extraData"] !== undefined ? serializeRepositoryWebrefExtraMetadata(data["extraData"]) : undefined,
    humanRatings: data["humanRatings"] !== undefined ? serializeRepositoryWebrefHumanRatings(data["humanRatings"]) : undefined,
    linkInfo: data["linkInfo"] !== undefined ? data["linkInfo"].map((item: any) => (serializeRepositoryWebrefGlobalLinkInfo(item))) : undefined,
    nameInfo: data["nameInfo"] !== undefined ? data["nameInfo"].map((item: any) => (serializeRepositoryWebrefGlobalNameInfo(item))) : undefined,
  };
}

function deserializeRepositoryWebrefEntityJoin(data: any): RepositoryWebrefEntityJoin {
  return {
    ...data,
    annotatedEntityId: data["annotatedEntityId"] !== undefined ? deserializeRepositoryWebrefWebrefEntityId(data["annotatedEntityId"]) : undefined,
    cdoc: data["cdoc"] !== undefined ? data["cdoc"].map((item: any) => (deserializeRepositoryWebrefSimplifiedCompositeDoc(item))) : undefined,
    contextNameInfo: data["contextNameInfo"] !== undefined ? data["contextNameInfo"].map((item: any) => (deserializeRepositoryWebrefGlobalNameInfo(item))) : undefined,
    enricherAnnotatorProfile: data["enricherAnnotatorProfile"] !== undefined ? deserializeRepositoryWebrefAnnotatorProfile(data["enricherAnnotatorProfile"]) : undefined,
    enricherDebugData: data["enricherDebugData"] !== undefined ? deserializeRepositoryWebrefEnricherDebugData(data["enricherDebugData"]) : undefined,
    extraData: data["extraData"] !== undefined ? deserializeRepositoryWebrefExtraMetadata(data["extraData"]) : undefined,
    humanRatings: data["humanRatings"] !== undefined ? deserializeRepositoryWebrefHumanRatings(data["humanRatings"]) : undefined,
    linkInfo: data["linkInfo"] !== undefined ? data["linkInfo"].map((item: any) => (deserializeRepositoryWebrefGlobalLinkInfo(item))) : undefined,
    nameInfo: data["nameInfo"] !== undefined ? data["nameInfo"].map((item: any) => (deserializeRepositoryWebrefGlobalNameInfo(item))) : undefined,
  };
}

/**
 * Metadata about the nature of the link.
 */
export interface RepositoryWebrefEntityLinkMetadata {
  /**
   * The aggregate kind flags for the link.
   */
  aggregateFlags?: RepositoryWebrefLinkKindFlags;
  /**
   * Information about all the link kinds associated with the link.
   */
  kindInfo?: RepositoryWebrefLinkKindInfo[];
}

/**
 * All link data for a given source.
 */
export interface RepositoryWebrefEntityLinkSource {
  /**
   * KG-property if the SourceType is associated with a KG-property
   * (TOPIC_PROPERTY, NEW_TOPIC_PROPERTY).
   */
  kgProperty?: string;
  /**
   * Score in [0, \infty) that represents how relatively likely it is to see
   * that entity cooccurring with the main entity (in the entity join). A value
   * of 1.0 means that the two entities are basically independent. The higher
   * the more likely (relatively to the individual entity probabilities) they
   * are to cooccur.
   */
  score?: number;
  type?:  | "UNKNOWN_LINK_SOURCE" | "REFERENCE_PAGE_MENTIONS" | "OYSTER_RELATIONS" | "TYPE_BASED_LINKS" | "TIME_LINKS" | "COMPOUND_LINKS" | "HUMAN_LANGUAGE_LINKS" | "NEW_TOPIC_PROPERTY" | "EXPERIMENTAL_LINKS" | "PERSONAL_LINKS" | "EBSE";
}

/**
 * Stores all human ratings collected for a given entity name.
 */
export interface RepositoryWebrefEntityNameRatings {
  language?: string;
  name?: string;
  /**
   * Every entity name receives one or a few ratings from human raters.
   */
  ratings?: RepositoryWebrefEntityNameRatingsEntityNameRating[];
  /**
   * Multiple tags can be assigned to a rated entity name. The tags can be used
   * when computing metrics in the Name Eval, so that different metrics are
   * computed separately for different sets of examples that have the same tag.
   */
  tags?: string[];
}

export interface RepositoryWebrefEntityNameRatingsEntityNameRating {
  /**
   * Comment left by the rater to justify the rating decision.
   */
  comment?: string;
  label?:  | "LABEL_UNSPECIFIED" | "LABEL_GOOD" | "LABEL_BAD" | "LABEL_I_DONT_KNOW";
  source?:  | "SOURCE_UNSPECIFIED" | "SOURCE_REFX" | "SOURCE_QAAS" | "SOURCE_SLS";
}

/**
 * Represents a score for an entity. Next available tag: 39.
 */
export interface RepositoryWebrefEntityNameScore {
  /**
   * If the EntityNameScore is part of a bootstrapped model, then this field
   * contains the score_ratio from the previous model ("Model 0"). If Model 0
   * does not have a corresponding entry, because it did not know about this
   * name for this entity, then bootstrapping_previous_iteration is left empty.
   */
  bootstrappingPreviousIteration?: RepositoryWebrefBootstrappingScore;
  /**
   * Confidence that this name is a trusted name of the entity. A reasonable
   * threshold for name trust is 0.6. A name can be trusted and still have very
   * low score_ratio, esp. if it is ambiguous (e.g. 'mercury') and/or not the
   * dominant interpretation (e.g. "siberian husky" -> /m/06krnsr (a book)).
   */
  confidence?: number;
  /**
   * Debug information about the entity.
   */
  debugInfo?: RepositoryWebrefEntityDebugInfo[];
  /**
   * Source and score data, this is internal to refx (e.g. for demo/debug).
   */
  debugVariantSignals?: RepositoryWebrefPreprocessingNameVariantSignals[];
  /**
   * Sparse metadata about the entity, usage should be moved back to individual
   * fields, this avoids having cyclic dependencies.
   */
  entity?: RepositoryWebrefEntityJoin;
  /**
   * Stores region specific score ratios for the entity when it is
   * significantly different from the language version above.
   */
  extendedScoreRatio?: RepositoryWebrefExtendedEntityNameScore[];
  /**
   * Include this name in the name lookup table.
   */
  includeInModel?: boolean;
  /**
   * Transient field, only used in bootstrap pipeline.
   */
  internalBootstrapIsOpenWorld?: boolean;
  internalIsClusterParent?: boolean;
  /**
   * Set to true iff the concept is cluster parent and the name can be a name
   * for any child of the cluster. (e.g. 'starbucks' is cluster_global for the
   * [Starbucks] chain cluster).
   */
  isClusterGlobal?: boolean;
  /**
   * Documened at:
   * repository/webref/universal/webref_data/enricher/entity-data.h
   */
  isDropped?: boolean;
  /**
   * Only for context names: Whether this EntityNameScore represents an entity
   * that was dominant in the search results but was not annotated by QRef
   * during learning. Matchless result contexts are useful for bootstrapping,
   * where different model iterations may have different names and thus context
   * scores from Model 0 that are inconsistent with the names from Model 1.
   */
  isMatchlessResultContext?: boolean;
  /**
   * Documened at:
   * repository/webref/universal/webref_data/enricher/entity-data.h
   */
  isPruned?: boolean;
  /**
   * The id of the entity.
   */
  mid?: bigint;
  /**
   * Metadata about this name aggregated from name signals.
   */
  nameMetadata?: RepositoryWebrefPreprocessingNameEntityMetadata;
  /**
   * Metadata of segment range, which is annotated by this entity.
   */
  rangeMetadata?: RepositoryWebrefRangeMetadata[];
  /**
   * The absolute score of that entity. score = artificial_score +
   * volume_based_score
   */
  score?: number;
  /**
   * Ratio between this entity score and the total score over all entities.
   * This is including the "open world" information if it was estimated.
   */
  scoreRatio?: number;
  /**
   * When this field is true, we consider this context name as candidate in
   * Enricher's names pipeline.
   */
  useAsNameCandidate?: boolean;
  /**
   * Absolute score that comes from quantitative sources such as navboost
   * clicks, anchors, etc. artificial_score = score - volume_based_score
   */
  volumeBasedScore?: number;
}

function serializeRepositoryWebrefEntityNameScore(data: any): RepositoryWebrefEntityNameScore {
  return {
    ...data,
    entity: data["entity"] !== undefined ? serializeRepositoryWebrefEntityJoin(data["entity"]) : undefined,
    mid: data["mid"] !== undefined ? String(data["mid"]) : undefined,
  };
}

function deserializeRepositoryWebrefEntityNameScore(data: any): RepositoryWebrefEntityNameScore {
  return {
    ...data,
    entity: data["entity"] !== undefined ? deserializeRepositoryWebrefEntityJoin(data["entity"]) : undefined,
    mid: data["mid"] !== undefined ? BigInt(data["mid"]) : undefined,
  };
}

/**
 * Represents the data for a given source of names, including all entity
 * scores. Notice that a source of name can be just a signal like a multiplier.
 * Next available tag: 8.
 */
export interface RepositoryWebrefEntityNameSource {
  /**
   * All the entity-name scores from that source. Keyed by the
   * EntityNameScore.entity_id field.
   */
  entityScore?: RepositoryWebrefEntityNameScore[];
  /**
   * Describes where the data comes from.
   */
  type?:  | "SOURCE_TITLE" | "SOURCE_QUERY" | "SOURCE_ANCHOR" | "PRODUCT_TITLE" | "PRODUCT_QUERY" | "COMMON_NGRAM_CONCEPT_BOOST" | "FREEBASE_NAME" | "TYPE_BASED_INVERSE_DEMOTION_FACTOR" | "STRONG_IDENTIFIER" | "UNTRUSTED_ANCHOR" | "PERSON_NAME" | "OYSTER_NAME" | "UNTRUSTED_QUERY" | "OYSTER_NAME_DERIVED" | "RELATED_CONTEXT" | "WIKI_DESCRIPTION" | "WIKI_INFOBOX" | "FREEBASE_PROPERTY" | "WIKI_IS_A_TYPE" | "OYSTER_TYPE" | "OYSTER_ADDRESS" | "SOURCE_MODEL" | "LEAKED_NAME_DEMOTION" | "PRODUCT_TITLE_VARIATION" | "TRUSTED_NAME" | "SUBSET_NAME" | "UNTRUSTED_COOCCURRENCE_NAME" | "RESULTS_ENTITIES_QUERY" | "RELATED_ENTITIES_NGRAM" | "CLIENT_PROVIDED_NAME" | "GENERATED_CONTAINING_CONTEXT" | "DOC_NAME_AGGREGATES" | "QUERY_NAME_AGGREGATES" | "SOURCE_LEARNED_QUERY" | "COMPANY_OR_WEBSITE_DERIVED_NAME" | "GENERATED_SPARSE_CONTEXT" | "GENERATED_ARTIFICIAL_CONTEXT" | "GENERATED_S2CELL_CONTEXT";
}

function serializeRepositoryWebrefEntityNameSource(data: any): RepositoryWebrefEntityNameSource {
  return {
    ...data,
    entityScore: data["entityScore"] !== undefined ? data["entityScore"].map((item: any) => (serializeRepositoryWebrefEntityNameScore(item))) : undefined,
  };
}

function deserializeRepositoryWebrefEntityNameSource(data: any): RepositoryWebrefEntityNameSource {
  return {
    ...data,
    entityScore: data["entityScore"] !== undefined ? data["entityScore"].map((item: any) => (deserializeRepositoryWebrefEntityNameScore(item))) : undefined,
  };
}

/**
 * Keeps a set of scores about an entity. Next available tag: 20.
 */
export interface RepositoryWebrefEntityScores {
  /**
   * Probability that any given name of this entity is fully capitalized.
   */
  allCapsProb?: number;
  /**
   * This field is only for debugging and link weight experiments. It stores
   * the entity's idf from the alpha model. Alpha idfs are used for link weight
   * computations and available during model omega building via
   * enricher_current_entity_idf_for_link_direction.
   */
  alphaEntityIdf?: number;
  /**
   * Probability that the entity is a common ngram (e.g. from dictionary).
   */
  commonNgramProb?: number;
  /**
   * The final (model omega) idf of an entity. Equals log2(1 / probability of
   * the entity to appear in a document). This probability is currently
   * estimated from its names (i.e. it is a sum of the name frequency weighted
   * by P(entity | name)).
   */
  entityIdf?: number;
  /**
   * Probability that any given name of this entity is capitalized.
   */
  nameCapitalizationProb?: number;
  /**
   * The following fields are deprecated and should eventually be removed. They
   * use data and rules that have not been refreshed for ~10y and KG has changed
   * a lot in the meantime.
   */
  personProb?: number;
}

/**
 * Information about all ranges explained by the entity or any other entity it
 * implies. For example, the Zurich entity may explain both tokens "Zurich" and
 * "Switzerland" in [FIFA Zurich Switzerland], the first directly, the other via
 * implication. Only used in the context of query annotation.
 */
export interface RepositoryWebrefExplainedRangeInfo {
  /**
   * All ranges explained by the entity.
   */
  explainedRange?: RepositoryWebrefExplainedRangeInfoExplainedRange[];
  geoQueryCoverage?:  | "NONE" | "PARTIAL" | "FULL";
}

function serializeRepositoryWebrefExplainedRangeInfo(data: any): RepositoryWebrefExplainedRangeInfo {
  return {
    ...data,
    explainedRange: data["explainedRange"] !== undefined ? data["explainedRange"].map((item: any) => (serializeRepositoryWebrefExplainedRangeInfoExplainedRange(item))) : undefined,
  };
}

function deserializeRepositoryWebrefExplainedRangeInfo(data: any): RepositoryWebrefExplainedRangeInfo {
  return {
    ...data,
    explainedRange: data["explainedRange"] !== undefined ? data["explainedRange"].map((item: any) => (deserializeRepositoryWebrefExplainedRangeInfoExplainedRange(item))) : undefined,
  };
}

/**
 * A range of the annotated document explained by an entity.
 */
export interface RepositoryWebrefExplainedRangeInfoExplainedRange {
  /**
   * SegmentMention describing the occurrence of the token in the document.
   */
  mention?: RepositoryWebrefSegmentMention;
}

function serializeRepositoryWebrefExplainedRangeInfoExplainedRange(data: any): RepositoryWebrefExplainedRangeInfoExplainedRange {
  return {
    ...data,
    mention: data["mention"] !== undefined ? serializeRepositoryWebrefSegmentMention(data["mention"]) : undefined,
  };
}

function deserializeRepositoryWebrefExplainedRangeInfoExplainedRange(data: any): RepositoryWebrefExplainedRangeInfoExplainedRange {
  return {
    ...data,
    mention: data["mention"] !== undefined ? deserializeRepositoryWebrefSegmentMention(data["mention"]) : undefined,
  };
}

/**
 * Used to store region-specific score ratio per entity. Next available tag: 4.
 */
export interface RepositoryWebrefExtendedEntityNameScore {
  /**
   * The domain name of the website, e.g. "play.google.com".
   */
  domain?: string;
  /**
   * The region in the III standard (http://go/iii). Eg. "US", "GB"
   */
  region?: string;
  /**
   * Score ratio for the entity, same as the EntityNameScore score ratio.
   */
  scoreRatio?: number;
}

/**
 * Additional metadata about the entity, that can be derived from the "raw
 * data" (composite doc, domain specific data...), or come from other sources.
 * Next available tag is 35.
 */
export interface RepositoryWebrefExtraMetadata {
  /**
   * For a book entity, store its book editions metadata. Used by Juggernaut to
   * do /book/book_edition recon, see ariane/265006. This field is used by
   * Juggernaut only.
   */
  bookEditionMetadata?: RepositoryWebrefBookEditionMetadata[];
  /**
   * Information about category types of the entity.
   */
  categoryInfo?: RepositoryWebrefCategoryInfo;
  /**
   * Metadata about clusters.
   */
  clusterMetadata?: RepositoryWebrefClusterMetadata;
  /**
   * Information for displaying the entity in applications.
   */
  displayInfo?: RepositoryWebrefDisplayInfo;
  /**
   * Additional scores for the entity.
   */
  entityScores?: RepositoryWebrefEntityScores;
  /**
   * An entity in KG that represents the same (or equivalent) entity in the
   * real world. In particular, this is used for mid-forwarding: when de-duping
   * entities in KG, the old ids represent the exact same entity as the one they
   * were merged with. So when we see one id in the query and the other in a
   * document, they are treated as the same entity.
   */
  equivalentEntityId?: RepositoryWebrefWebrefEntityId[];
  /**
   * Geo-specific entity metadata.
   */
  geoMetadata?: RepositoryWebrefGeoMetadataProto;
  /**
   * Metadata related to KC attributes and Question & Answer triggering.
   */
  kcAttributeMetadata?: RepositoryWebrefKCAttributeMetadata;
  /**
   * A list of entities that are latent given this entity. For example, "Lionel
   * Messi" can have the latent entity "FC Barcelona". The latent entity links
   * are materialized in an offline pipeline using
   * r/w/scripts/latent_entities/latent-entities.pq. For more information, see
   * go/latent-entities.
   */
  latentEntities?: RepositoryWebrefLatentEntities;
  /**
   * Metadata about MDVC.
   */
  mdvcMetadata?: RepositoryWebrefMdvcMetadata;
  /**
   * Other metadata.
   */
  otherMetadata?: Proto2BridgeMessageSet;
  /**
   * The primary recording mid of a recording cluster entity. Used by
   * Juggernaut to do /music/recording recon, see b/139901317. The primary
   * recording is unique to a recording cluster. This field is used by
   * Juggernaut only.
   */
  primaryRecording?: bigint;
  /**
   * Products-specific entity metadata.
   */
  productMetadata?: RepositoryWebrefProductMetadata;
  /**
   * # LINT.ThenChange(
   * //depot/google3/repository/webref/evaluation/query/metrics/util.cc)
   */
  specialEntityType?:  | "UNDEFINED" | "COLLECTION" | "DATETIME" | "MRF" | "SHOPPING_CATALOG_TOKEN" | "LIGHTWEIGHT_TOKEN";
  specialWord?: MapsQualitySpecialWordsProto[];
  /**
   * Metadata about support transfer rules defined for this entity.
   */
  supportTransferRules?: RepositoryWebrefSupportTransferRule[];
}

function serializeRepositoryWebrefExtraMetadata(data: any): RepositoryWebrefExtraMetadata {
  return {
    ...data,
    bookEditionMetadata: data["bookEditionMetadata"] !== undefined ? data["bookEditionMetadata"].map((item: any) => (serializeRepositoryWebrefBookEditionMetadata(item))) : undefined,
    categoryInfo: data["categoryInfo"] !== undefined ? serializeRepositoryWebrefCategoryInfo(data["categoryInfo"]) : undefined,
    clusterMetadata: data["clusterMetadata"] !== undefined ? serializeRepositoryWebrefClusterMetadata(data["clusterMetadata"]) : undefined,
    equivalentEntityId: data["equivalentEntityId"] !== undefined ? data["equivalentEntityId"].map((item: any) => (serializeRepositoryWebrefWebrefEntityId(item))) : undefined,
    geoMetadata: data["geoMetadata"] !== undefined ? serializeRepositoryWebrefGeoMetadataProto(data["geoMetadata"]) : undefined,
    mdvcMetadata: data["mdvcMetadata"] !== undefined ? serializeRepositoryWebrefMdvcMetadata(data["mdvcMetadata"]) : undefined,
    primaryRecording: data["primaryRecording"] !== undefined ? String(data["primaryRecording"]) : undefined,
    productMetadata: data["productMetadata"] !== undefined ? serializeRepositoryWebrefProductMetadata(data["productMetadata"]) : undefined,
  };
}

function deserializeRepositoryWebrefExtraMetadata(data: any): RepositoryWebrefExtraMetadata {
  return {
    ...data,
    bookEditionMetadata: data["bookEditionMetadata"] !== undefined ? data["bookEditionMetadata"].map((item: any) => (deserializeRepositoryWebrefBookEditionMetadata(item))) : undefined,
    categoryInfo: data["categoryInfo"] !== undefined ? deserializeRepositoryWebrefCategoryInfo(data["categoryInfo"]) : undefined,
    clusterMetadata: data["clusterMetadata"] !== undefined ? deserializeRepositoryWebrefClusterMetadata(data["clusterMetadata"]) : undefined,
    equivalentEntityId: data["equivalentEntityId"] !== undefined ? data["equivalentEntityId"].map((item: any) => (deserializeRepositoryWebrefWebrefEntityId(item))) : undefined,
    geoMetadata: data["geoMetadata"] !== undefined ? deserializeRepositoryWebrefGeoMetadataProto(data["geoMetadata"]) : undefined,
    mdvcMetadata: data["mdvcMetadata"] !== undefined ? deserializeRepositoryWebrefMdvcMetadata(data["mdvcMetadata"]) : undefined,
    primaryRecording: data["primaryRecording"] !== undefined ? BigInt(data["primaryRecording"]) : undefined,
    productMetadata: data["productMetadata"] !== undefined ? deserializeRepositoryWebrefProductMetadata(data["productMetadata"]) : undefined,
  };
}

export interface RepositoryWebrefFatcatCategory {
  /**
   * The category ID from verticals4. See go/verticals4 and where we read them
   * in http://google3/repository/webref/preprocessing/fatcat-categories.cc
   */
  id?: number;
  /**
   * The relative weight of the category within a distribution.
   */
  score?: number;
}

/**
 * Submessage for forwarding urls in DocumentMetadata.
 */
export interface RepositoryWebrefForwardingUrls {
  /**
   * Urls that forward to this url. Used for url -> topical entity entries.
   */
  forwardingUrl?: string[];
}

/**
 * ---------------------------------------------------------------------------
 * Enums defining the available modifier options.
 */
export interface RepositoryWebrefFprintModifierProto {
  capitalization?:  | "CAPITALIZATION_ANY" | "CAPITALIZATION_FIRST_ONLY" | "CAPITALIZATION_SOME" | "CAPITALIZATION_ALL";
  enclosing?:  | "ENCLOSING_ANY" | "ENCLOSING_QUOTES" | "ENCLOSING_PARENTHESIS" | "ENCLOSING_OTHER";
  /**
   * i18.languages.Language enum defined in
   * i18n/languages/proto/languages.proto UNKNOWN_LANGUAGE
   */
  language?: number;
  namespaceType?:  | "NAMESPACE_DEFAULT" | "NAMESPACE_WEBIT";
  punctuation?:  | "PUNCTUATION_ANY" | "PUNCTUATION_INNER";
  sentence?:  | "SENTENCE_ANY" | "SENTENCE_BEGINNING";
  sourceType?:  | "SOURCE_ANY" | "SOURCE_NEWS" | "SOURCE_YOUTUBE";
  stemming?:  | "STEMMING_ANY" | "STEMMING_YES";
  style?:  | "STYLE_ANY" | "STYLE_DISTINCT";
  tokenType?:  | "INVALID" | "CONTENT" | "URL" | "ANCHOR" | "QUERY" | "INSTANT_QUERY" | "A_HREF_TAG" | "LINK_HREF_TAG" | "IMG_ALT_TAG" | "IMG_SRC_TAG" | "META_CONTENT_TAG" | "TITLE" | "ANY" | "IMAGE_QUERY" | "CONTEXT_ENTITY" | "RESULT_ENTITY" | "CONTEXT_QUERY" | "SIMILAR_QUERIES" | "SPORE_GRAPH" | "OFFDOMAIN_ANCHOR" | "ONSITE_ANCHOR" | "NAME_CANDIDATE" | "TOPIC_LINK" | "QUERY_NAME_CANDIDATE" | "ANCHOR_NAME_CANDIDATE" | "INJECTED_NAME_CANDIDATE" | "REFERENCE_PAGE_URL" | "REFERENCE_PAGE_LINK" | "DEPRECATED_ENTITY_METADATA" | "STRONG_IDENTIFIER" | "REFERENCE_PAGE_URL_INLINK" | "REFERENCE_PAGE_LINK_INLINK" | "GEO_LINK" | "PRINCIPAL_NAME" | "NAME_BLACKLIST" | "ENTITY_CONTEXT_TOKENS" | "VIDEO_TRANSCRIPT" | "VIDEO_OCR" | "IMAGE_OCR" | "LENS" | "ONLY_LOOKUP_METADATA" | "EMBEDDED_CONTENT";
}

/**
 * The Freebase type information.
 */
export interface RepositoryWebrefFreebaseType {
  /**
   * Optional - for inferred types the principal source of information.
   */
  provenance?: string[];
  /**
   * Optional score. Not present in KG directly but e.g. in WPCat.
   */
  score?: number;
  /**
   * Mid of this type. Equivalent to type_name, but is more compact. When
   * present, overrides type_name (which can be omitted in this case to save
   * space).
   */
  typeMid?: bigint;
  /**
   * e.g.: "/business/industry", "/book/book_subject", "/people/person"...
   */
  typeName?: string;
}

function serializeRepositoryWebrefFreebaseType(data: any): RepositoryWebrefFreebaseType {
  return {
    ...data,
    typeMid: data["typeMid"] !== undefined ? String(data["typeMid"]) : undefined,
  };
}

function deserializeRepositoryWebrefFreebaseType(data: any): RepositoryWebrefFreebaseType {
  return {
    ...data,
    typeMid: data["typeMid"] !== undefined ? BigInt(data["typeMid"]) : undefined,
  };
}

/**
 * Identifies the segment index for Webref SegmentTypes not covered by other
 * *Indices messages.
 */
export interface RepositoryWebrefGenericIndices {
  /**
   * The segment index.
   */
  index?: number;
}

/**
 * Geo-specific information about the entity. Next available tag: 34.
 */
export interface RepositoryWebrefGeoMetadataProto {
  /**
   * Stores parent/container information containing city, province & country.
   */
  address?: GeostoreAddressProto;
  addressSynonyms?: RepositoryWebrefGeoMetadataProtoAddressSynonym[];
  /**
   * Area in km^2 of the feature if the feature has polygon.
   */
  areaKm2?: number;
  /**
   * The tight bounds of this feature. Note that these are different from the
   * FeatureProto.bound field.
   */
  bound?: GeostoreRectProto;
  /**
   * Country code of the country of the entity. Only available in
   * qref-metadata.
   */
  countryCode?: string;
  /**
   * The geographic location (center) and geometry of this entity. See
   * geostore.FeatureProto for more details.
   */
  location?: GeostorePointProto;
  /**
   * The best name from Oyster for this entity. Is only included for some types
   * of entities, and is a trimmed version of the proto (some fields are
   * cleared).
   */
  name?: GeostoreNameProto;
  /**
   * The oyster id of the entity
   */
  oysterId?: GeostoreFeatureIdProto;
  /**
   * Numerical country code, converted with
   * i18n/identifiers/stableinternalregionconverter.h. It is the same as
   * country_code, but it is available in the annotator model (and takes less
   * space).
   */
  stableIntegerCountryCode?: number;
  /**
   * Timezone if the feature is contained inside one.
   */
  timezone?: string;
  /**
   * Information about the geographic location (center) extracted from the
   * wikijoins.
   */
  wpLocation?: RepositoryWebrefWikipediaGeocode[];
}

function serializeRepositoryWebrefGeoMetadataProto(data: any): RepositoryWebrefGeoMetadataProto {
  return {
    ...data,
    address: data["address"] !== undefined ? serializeGeostoreAddressProto(data["address"]) : undefined,
    oysterId: data["oysterId"] !== undefined ? serializeGeostoreFeatureIdProto(data["oysterId"]) : undefined,
  };
}

function deserializeRepositoryWebrefGeoMetadataProto(data: any): RepositoryWebrefGeoMetadataProto {
  return {
    ...data,
    address: data["address"] !== undefined ? deserializeGeostoreAddressProto(data["address"]) : undefined,
    oysterId: data["oysterId"] !== undefined ? deserializeGeostoreFeatureIdProto(data["oysterId"]) : undefined,
  };
}

/**
 * Terms from AddressComponent proto that we can use as address synonyms. At
 * the time of annotation we have the entire AddressProto, however we can't use
 * it all due to size. So only store relevant pieces of components (defined in
 * superroot/impls/localweb/s2_synoyms.h).
 */
export interface RepositoryWebrefGeoMetadataProtoAddressSynonym {
  language?: string;
  name?: string;
  /**
   * The type of the geocoded address. e.g. Road, Lake, Ocean, building. This
   * comes from TypeCategory field in geostore/base/proto/feature.proto
   */
  type?: number;
}

/**
 * Groups together the LinkInfo for all locales.
 */
export interface RepositoryWebrefGlobalLinkInfo {
  /**
   * A short human-readable name/title of the entity, similar to what is
   * displayed at the top of a Hume page. Do not use for any production purpose
   * as it does not provide guarantees for stability or policy checks (access
   * requirements).
   */
  debugTitle?: string;
  /**
   * Whether this is a BoostedPrimaryWeight link. For these links in some cases
   * a higher weight is used for primary scoring.
   */
  isBoostedPrimaryWeightLink?: boolean;
  /**
   * The mid of the linked entity.
   */
  targetMid?: bigint;
  /**
   * The information about this link for each locale.
   */
  variantInfo?: RepositoryWebrefLinkInfo[];
}

function serializeRepositoryWebrefGlobalLinkInfo(data: any): RepositoryWebrefGlobalLinkInfo {
  return {
    ...data,
    targetMid: data["targetMid"] !== undefined ? String(data["targetMid"]) : undefined,
  };
}

function deserializeRepositoryWebrefGlobalLinkInfo(data: any): RepositoryWebrefGlobalLinkInfo {
  return {
    ...data,
    targetMid: data["targetMid"] !== undefined ? BigInt(data["targetMid"]) : undefined,
  };
}

/**
 * Groups together the NameInfo for all variants of a given name. The variants
 * of a name have the same normalized string, but they have a different original
 * string and/or a different language/region. Example: For the name "apple",
 * there may be variants such as "apple|en", "apple|en|US", "apple|de",
 * "Apple|en"...
 */
export interface RepositoryWebrefGlobalNameInfo {
  /**
   * The normalized name.
   */
  normalizedName?: string;
  /**
   * All the variants of this name together with associated information such as
   * score, sources, etc.
   */
  variantInfo?: RepositoryWebrefNameInfo[];
}

function serializeRepositoryWebrefGlobalNameInfo(data: any): RepositoryWebrefGlobalNameInfo {
  return {
    ...data,
    variantInfo: data["variantInfo"] !== undefined ? data["variantInfo"].map((item: any) => (serializeRepositoryWebrefNameInfo(item))) : undefined,
  };
}

function deserializeRepositoryWebrefGlobalNameInfo(data: any): RepositoryWebrefGlobalNameInfo {
  return {
    ...data,
    variantInfo: data["variantInfo"] !== undefined ? data["variantInfo"].map((item: any) => (deserializeRepositoryWebrefNameInfo(item))) : undefined,
  };
}

export interface RepositoryWebrefHumanRatings {
  annotationRatings?: RepositoryWebrefAnnotationRatings;
}

function serializeRepositoryWebrefHumanRatings(data: any): RepositoryWebrefHumanRatings {
  return {
    ...data,
    annotationRatings: data["annotationRatings"] !== undefined ? serializeRepositoryWebrefAnnotationRatings(data["annotationRatings"]) : undefined,
  };
}

function deserializeRepositoryWebrefHumanRatings(data: any): RepositoryWebrefHumanRatings {
  return {
    ...data,
    annotationRatings: data["annotationRatings"] !== undefined ? deserializeRepositoryWebrefAnnotationRatings(data["annotationRatings"]) : undefined,
  };
}

/**
 * Identifies a set of Image NavBoost queries in the CompositeDoc. Each
 * CompositeDoc can contain several images, so we store the image index from the
 * CompositeDoc::doc_images with the index of the particular query inside
 * ImageData::image_data_navboost.
 */
export interface RepositoryWebrefImageQueryIndices {
  /**
   * The (canonical) image docid of the ImageData this image query is part of.
   * Useful for identifying the ImageData even after doc_images are updated in
   * between Webref annotation runs. Use docid only when canonical_docid == 0.
   */
  canonicalDocid?: bigint;
  docid?: bigint;
  /**
   * WARNING: The doc_images in docjoins are subject to updates including
   * non-deterministic reordering of doc_images and their image_nb_data
   * extensions. This means that without re-running WebrefAnnotator one cannot
   * rely on the accuracy or even consistency of either image_index or
   * query_index when parsing a cdoc from docjoins. In those situations one
   * ought to rely on canonical_docid (or docid when canonical_docid is absent
   * viz. 0). The index of the source image in CompositeDoc::doc_images.
   */
  imageIndex?: number;
  /**
   * Queries index in ImageData::image_data_navboost.
   */
  queryIndex?: RepositoryWebrefQueryIndices;
}

function serializeRepositoryWebrefImageQueryIndices(data: any): RepositoryWebrefImageQueryIndices {
  return {
    ...data,
    canonicalDocid: data["canonicalDocid"] !== undefined ? String(data["canonicalDocid"]) : undefined,
    docid: data["docid"] !== undefined ? String(data["docid"]) : undefined,
  };
}

function deserializeRepositoryWebrefImageQueryIndices(data: any): RepositoryWebrefImageQueryIndices {
  return {
    ...data,
    canonicalDocid: data["canonicalDocid"] !== undefined ? BigInt(data["canonicalDocid"]) : undefined,
    docid: data["docid"] !== undefined ? BigInt(data["docid"]) : undefined,
  };
}

/**
 * Identifies the source of Spore segments in the CompositeDoc.
 */
export interface RepositoryWebrefJuggernautIndices {
  /**
   * Index within the proto. Several indices are necessary in case of nested
   * repeated fields. The data can be accessed as follows: TOPICS:
   * topic_annotations.kg_schema_topic(index(0)) .property_value(index(1))
   * .value(index(2)); TRIPLES: reconcile_request.triple(index(0));
   */
  index?: number[];
  type?:  | "NONE" | "TOPICS" | "TRIPLES";
}

/**
 * Metadata related to KC attributes and Question & Answer triggering. Next
 * available tag: 2.
 */
export interface RepositoryWebrefKCAttributeMetadata {
  /**
   * Equivalent kc attribute id for the given entity if applicable. E.g. for
   * Daughter (/m/029wnx) this will be 'kc:/people/person:daughter'.
   */
  equivalentAttributeId?: string;
}

/**
 * See go/kg-collections
 */
export interface RepositoryWebrefKGCollection {
  /**
   * A human friendly identifier (collection hrid). NOTE: The field name is a
   * misnomer, this is the preferred field to use in production.
   */
  debugId?: string;
  /**
   * Identifier of the collection, usually a MID (/m/xyz or /g/zyw). NOTE: In
   * most cases, this is not the id that should be used, debug_id is the
   * preferred identifier. The main reason is the this is not a stable id (mid
   * for collection sometimes shift around).
   */
  id?: string;
}

/**
 * A list of entities that are latent given this entity. For example, "Lionel
 * Messi" can have the latent entity "FC Barcelona". See go/refx-latent-entities
 * for detailed description.
 */
export interface RepositoryWebrefLatentEntities {
  /**
   * Latent entities with associated metadata including source of the
   * relationship. This is pruned ("compacted") from the concept table and will
   * never reach the annotator.
   */
  latentEntity?: RepositoryWebrefLatentEntity[];
  /**
   * List of broader MIDs from the Sports Hierarchy. Named incorrectly, it does
   * not contain all latent mids.
   */
  latentMid?: string[];
}

/**
 * Metadata about a latent entity and its relationship to a given child. See
 * go/hits.
 */
export interface RepositoryWebrefLatentEntity {
  /**
   * The relatedness score of the two entities corresponding to each source
   * above.
   */
  broaderImportance?: number[];
  /**
   * The mid of the latent entity.
   */
  mid?: string;
  /**
   * The sources this generalization relationship is coming from.
   */
  sources?:  | "INVALID" | "VERTICAL_SPECIFIC_RELATIONS" | "NN_HIERARCHY_V1"[];
}

/**
 * LexicalAnnotation is public lightweight serving structure for both WordGraph
 * features and LWT annotations to expose lexical information downstream from
 * RefX, e.g. in LooseParser.
 */
export interface RepositoryWebrefLexicalAnnotation {
  lexicalRange?: RepositoryWebrefLexicalRange[];
}

function serializeRepositoryWebrefLexicalAnnotation(data: any): RepositoryWebrefLexicalAnnotation {
  return {
    ...data,
    lexicalRange: data["lexicalRange"] !== undefined ? data["lexicalRange"].map((item: any) => (serializeRepositoryWebrefLexicalRange(item))) : undefined,
  };
}

function deserializeRepositoryWebrefLexicalAnnotation(data: any): RepositoryWebrefLexicalAnnotation {
  return {
    ...data,
    lexicalRange: data["lexicalRange"] !== undefined ? data["lexicalRange"].map((item: any) => (deserializeRepositoryWebrefLexicalRange(item))) : undefined,
  };
}

/**
 * A single understood lexicon of the |category| on byte range from
 * |begin_offset| (inclusive) to |end_offset| (exclusive). The offsets are all
 * byte offsets relative to the full original query and cover both the mentions
 * and surrounding markers.
 */
export interface RepositoryWebrefLexicalRange {
  /**
   * Begin byte offset relative to the full original query.
   */
  beginOffset?: number;
  category?:  | "UNKNOWN" | "RELATIONAL_ADJECTIVE" | "SUPERLATIVE" | "PLURAL" | "FEMALE" | "ASPECT" | "TARGET_AUDIENCE" | "TARGET_PURPOSE" | "SETTING_BY_LOCATION" | "DECORATIVE_PATTERN" | "ELECTRONIC_DEVICE_CONNECTIVITY" | "DIETARY_RESTRICTION" | "ACTOR" | "ADAPTATION_SOURCE" | "AGE" | "AUTHOR" | "AUTHOR_OF_ADAPTATION_SOURCE" | "AWARD_NOMINATED_FOR" | "AWARD_WON" | "BATTERY_LIFE" | "BATTERY_TYPE" | "BRAND" | "COLOR" | "COUNTRY_OF_ORIGIN" | "DEGREE_OF_BRIGHTNESS" | "DEGREE_OF_SEXINESS" | "DURATION" | "EXCLUDED_INGREDIENT" | "FICTIONAL_CHARACTER" | "FILM_DIRECTOR" | "GENRE" | "INTENDED_SPECIAL_OCCASION" | "LENGTH" | "MATERIAL" | "MEDIA_PROVIDER" | "MUSIC_COMPOSER" | "ORIGINAL_MEDIA_PROVIDER" | "PRIMARY_GENRE" | "PRODUCTION_COMPANY" | "PUBLICATION_DATE" | "RECENCY" | "RELATED_ARTISTIC_WORK" | "RELEASE_DATE" | "SECONDARY_GENRE" | "SETTING_BY_FICTIONAL_LOCATION" | "SETTING_BY_REAL_LOCATION" | "SETTING_BY_TIME" | "SUPPORTED_VIRTUAL_ASSISTANT" | "TEMPERATURE" | "THEME" | "TVM_ATTRIBUTE" | "WEIGHT" | "EXCLUSION";
  /**
   * Direction defines the relation between the measurable aspect and the
   * facet.
   */
  direction?:  | "MEASURABLE_ASPECT_DIRECTION_UNSPECIFIED" | "MEASURABLE_ASPECT_INCREASING" | "MEASURABLE_ASPECT_DECREASING";
  /**
   * End byte offset relative to the full original query.
   */
  endOffset?: number;
  /**
   * The mid of the facet associated with ASPECT category.
   */
  facetMid?: bigint;
}

function serializeRepositoryWebrefLexicalRange(data: any): RepositoryWebrefLexicalRange {
  return {
    ...data,
    facetMid: data["facetMid"] !== undefined ? String(data["facetMid"]) : undefined,
  };
}

function deserializeRepositoryWebrefLexicalRange(data: any): RepositoryWebrefLexicalRange {
  return {
    ...data,
    facetMid: data["facetMid"] !== undefined ? BigInt(data["facetMid"]) : undefined,
  };
}

/**
 * Necessary information of lightweight token pattern with entity retrieval to
 * pass to downstream clients. For example: FpTokenRange: normalized_text:
 * "zurichben" language: Hungarian retrieved_entity: /m/08966 (with name
 * "zurich") will get: MatchedLightweightToken: LightweightTokenType: "LOCATIVE"
 * begin_offset: 6 end_offset: 9 pattern_id: 8141703461898598811
 * source_entity_index: 0 FpTokenRange: normalized_text: "egyesult allamokott"
 * language: Hungarian retrieved_entity: /m/09c7w0 (with name "egyesult
 * allamok") will get: MatchedLightweightToken: LightweightTokenType: "LOCATIVE"
 * begin_offset: 16 end_offset: 19 pattern_id: 10449962977910715124
 * source_entity_index: 0 Note that begin_offset and end_offset marks the input
 * byte range of the matched input text. For example, if the input text is
 * [tannlegas] in Norwegian, this matches with the rewrite rule "*e:*as" to
 * transform "tannlegas" to "tannlege". The matched byte range is [7, 9) on
 * "as", therefore begin_offset = 7 and end_offset = 9. This must not be
 * confused with the rewritten range [7, 8) on "e". Also, keep in mind these are
 * byte offsets, not codepoints.
 */
export interface RepositoryWebrefLightweightTokensMatchedLightweightToken {
  /**
   * The byte offset of the beging of the additional lightweight token match.
   * e.g. the prefix pattern of the circumfix.
   */
  additionalBeginOffset?: number;
  /**
   * The byte offset of the end of the additional lightweight token match. e.g.
   * the suffix pattern of the circumfix.
   */
  additionalEndOffset?: number;
  /**
   * The byte offset of the begin of the lightweight token match within each
   * range. The default value of -1 (std::string::npos) means that there's no
   * affix or adposition detected.
   */
  beginOffset?: number;
  /**
   * The byte offset of the end of the lightweight token match within each
   * range. The default value of 0 means that there's no affix or adposition
   * detected.
   */
  endOffset?: number;
  /**
   * Matched pattern Id which will be used to retrieve back pattern features.
   * Pattern id is only populated for Enricher model.
   */
  patternId?: bigint;
  /**
   * The index of the source entity in the resulting WebrefEntities or
   * WebrefEntitiesWrapper, to which the lightweight token rule is applied. This
   * field is only populated at the end of Qref scorer when we are sure which
   * source entity should output.
   */
  sourceEntityIndex?: number;
  /**
   * The type of the lightweight token match, which provides the semantic
   * information.
   */
  type?:  | "UNKNOWN" | "DEFINITE" | "INDEFINITE" | "ABLATIVE" | "ADESSIVE" | "ALLATIVE" | "LOCATIVE" | "ACROSS_FROM" | "BEHIND" | "IN_FRONT" | "EAST" | "WEST" | "NORTH" | "SOUTH" | "LEFT" | "RIGHT" | "ADJACENT" | "GENITIVE" | "ACCUSATIVE" | "INSTRUMENTAL" | "DATIVE" | "CAUSATIVE" | "SOCIATIVE" | "INTERROGATIVE" | "PREPOSITIONAL" | "VOCATIVE" | "OBLIQUE" | "EMPHATIC" | "MESSAGE_RECIPIENT" | "MESSAGE_INITIATOR" | "MY_POSSESSION" | "OUR_POSSESSION" | "YOUR_SINGULAR_POSSESSION" | "YOUR_PLURAL_POSSESSION" | "YOUR_POLITE_POSSESSION" | "TRANSLATE_SOURCE_LANGUAGE" | "TRANSLATE_TARGET_LANGUAGE" | "NEW_MODIFIER" | "RECENT_MODIFIER" | "COURTESY_WORD" | "GENERIC_ADPOSITION" | "TARGET_CURRENCY" | "SOURCE_CURRENCY" | "PLURAL" | "CONJUNCTIVE" | "OPPOSITION_CONJUNCTIVE" | "MASCULINE_HONORIFIC" | "FEMININE_HONORIFIC" | "GENERIC_HONORIFIC" | "NEGATIVE_SUPERLATIVE" | "SUPERLATIVE" | "FACET_AUDIENCE" | "FACET_PURPOSE" | "FACET_EXCLUSION" | "FACET_SETTING_BY_LOCATION" | "FACET_DECORATIVE_PATTERN" | "FACET_ELECTRONIC_DEVICE_CONNECTIVITY" | "FACET_DIETARY_RESTRICTION" | "FACET_ACTOR" | "FACET_ADAPTATION_SOURCE" | "FACET_AGE" | "FACET_AUTHOR" | "FACET_AUTHOR_OF_ADAPTATION_SOURCE" | "FACET_AWARD_NOMINATED_FOR" | "FACET_AWARD_WON" | "FACET_BATTERY_LIFE" | "FACET_BATTERY_TYPE" | "FACET_BRAND" | "FACET_COLOR" | "FACET_COUNTRY_OF_ORIGIN" | "FACET_DEGREE_OF_BRIGHTNESS" | "FACET_DEGREE_OF_SEXINESS" | "FACET_DURATION" | "FACET_EXCLUDED_INGREDIENT" | "FACET_FICTIONAL_CHARACTER" | "FACET_FILM_DIRECTOR" | "FACET_GENRE" | "FACET_INTENDED_SPECIAL_OCCASION" | "FACET_LENGTH" | "FACET_MATERIAL" | "FACET_MEDIA_PROVIDER" | "FACET_MUSIC_COMPOSER" | "FACET_ORIGINAL_MEDIA_PROVIDER" | "FACET_PRIMARY_GENRE" | "FACET_PRODUCTION_COMPANY" | "FACET_PUBLICATION_DATE" | "FACET_RECENCY" | "FACET_RELATED_ARTISTIC_WORK" | "FACET_RELEASE_DATE" | "FACET_SECONDARY_GENRE" | "FACET_SETTING_BY_FICTIONAL_LOCATION" | "FACET_SETTING_BY_REAL_LOCATION" | "FACET_SETTING_BY_TIME" | "FACET_SUPPORTED_VIRTUAL_ASSISTANT" | "FACET_TEMPERATURE" | "FACET_THEME" | "FACET_TVM_ATTRIBUTE" | "FACET_WEIGHT";
}

function serializeRepositoryWebrefLightweightTokensMatchedLightweightToken(data: any): RepositoryWebrefLightweightTokensMatchedLightweightToken {
  return {
    ...data,
    patternId: data["patternId"] !== undefined ? String(data["patternId"]) : undefined,
  };
}

function deserializeRepositoryWebrefLightweightTokensMatchedLightweightToken(data: any): RepositoryWebrefLightweightTokensMatchedLightweightToken {
  return {
    ...data,
    patternId: data["patternId"] !== undefined ? BigInt(data["patternId"]) : undefined,
  };
}

/**
 * Collects all lightweight token patterns for each CandidateMention or
 * Mention.
 */
export interface RepositoryWebrefLightweightTokensPerMentionLightweightToken {
  matchedLightweightToken?: RepositoryWebrefLightweightTokensMatchedLightweightToken[];
}

function serializeRepositoryWebrefLightweightTokensPerMentionLightweightToken(data: any): RepositoryWebrefLightweightTokensPerMentionLightweightToken {
  return {
    ...data,
    matchedLightweightToken: data["matchedLightweightToken"] !== undefined ? data["matchedLightweightToken"].map((item: any) => (serializeRepositoryWebrefLightweightTokensMatchedLightweightToken(item))) : undefined,
  };
}

function deserializeRepositoryWebrefLightweightTokensPerMentionLightweightToken(data: any): RepositoryWebrefLightweightTokensPerMentionLightweightToken {
  return {
    ...data,
    matchedLightweightToken: data["matchedLightweightToken"] !== undefined ? data["matchedLightweightToken"].map((item: any) => (deserializeRepositoryWebrefLightweightTokensMatchedLightweightToken(item))) : undefined,
  };
}

/**
 * Collects all lightweight token patterns for each NameToConceptEntry.
 */
export interface RepositoryWebrefLightweightTokensPerNameLightweightToken {
  matchedLightweightToken?: RepositoryWebrefLightweightTokensMatchedLightweightToken[];
}

function serializeRepositoryWebrefLightweightTokensPerNameLightweightToken(data: any): RepositoryWebrefLightweightTokensPerNameLightweightToken {
  return {
    ...data,
    matchedLightweightToken: data["matchedLightweightToken"] !== undefined ? data["matchedLightweightToken"].map((item: any) => (serializeRepositoryWebrefLightweightTokensMatchedLightweightToken(item))) : undefined,
  };
}

function deserializeRepositoryWebrefLightweightTokensPerNameLightweightToken(data: any): RepositoryWebrefLightweightTokensPerNameLightweightToken {
  return {
    ...data,
    matchedLightweightToken: data["matchedLightweightToken"] !== undefined ? data["matchedLightweightToken"].map((item: any) => (deserializeRepositoryWebrefLightweightTokensMatchedLightweightToken(item))) : undefined,
  };
}

/**
 * Represents all information we have about a specific/localized link. Next
 * available tag: 11.
 */
export interface RepositoryWebrefLinkInfo {
  /**
   * The score aggregated from all sources.
   */
  aggregatedScore?: number;
  /**
   * The EntityJoin keeps bi-directional links, but for some applications we
   * only need them in one direction. This value indicates whether this is the
   * preferred direction to keep. (We usually prefer keeping the link from the
   * less common to the more common entity for performance reasons). For
   * categorical links the preferred direction is from child to parent.
   */
  isPreferredDirection?: boolean;
  /**
   * The metadata associated with the link.
   */
  metadata?: RepositoryWebrefEntityLinkMetadata;
  /**
   * The per-source scores.
   */
  source?: RepositoryWebrefEntityLinkSource[];
}

/**
 * A bitmap of bool values associated with a link kind. Next available tag: 12
 */
export interface RepositoryWebrefLinkKindFlags {
  cluster?:  | "NO_CLUSTER" | "CLUSTER_CHILD_OF" | "CLUSTER_PARENT_OF";
  geoContainment?:  | "NO_CONTAINMENT" | "CONTAINED_BY" | "CONTAINS" | "PARTIAL_OVERLAP" | "HAS_STREET_NUMBER" | "LOCATED_ON_STREET";
  implication?:  | "NO_IMPLICATION" | "IMPLIED_BY" | "IMPLIES" | "BIDIRECTIONAL_IMPLICATION" | "UNDERMERGED";
  latentEntity?:  | "NO_LATENT_ENTITY" | "LATENT_ENTITY" | "MANIFEST_ENTITY" | "LATENT_ENTITY_V2" | "MANIFEST_ENTITY_V2";
  mdvc?:  | "NO_MDVC" | "MDVC_SPECIALIZATION_OF" | "MDVC_GENERALIZATION_OF" | "MDVC_DIMENSION_VALUE" | "MDVC_DIMENSION_VALUE_OF" | "MDVC_RESOLUTION" | "MDVC_EXPANDED_OUTPUT";
  property?:  | "NO_PROPERTY" | "EQUIVALENT_TOPIC" | "EQUIVALENT_PROPERTY";
  resolution?:  | "NO_RESOLUTION" | "MAY_BE_RESOLVED_FROM" | "MAY_RESOLVE_TO" | "RESOLVED_FROM" | "RESOLVES_TO";
}

/**
 * Information about one of the types of a linked entity.
 */
export interface RepositoryWebrefLinkKindInfo {
  /**
   * The flags associated with the link kind.
   */
  flags?: RepositoryWebrefLinkKindFlags;
  /**
   * Link name extracted from Knowledge Card facts.
   */
  kcLinkName?: string;
  /**
   * If the link was extracted from a property, the name of the property. Can
   * start with an exclamation mark "!" to indicate that the inverse
   * relationship is specified. (e.g. "!/tv/tv_series_episode/series" is the
   * inverse of "tv/tv_program/episodes").
   */
  topicPropertyName?: string;
}

/**
 * Next available tag: 8.
 */
export interface RepositoryWebrefLocalizedString {
  /**
   * The domain name from which results come, e.g. "play.google.com".
   */
  domain?: string;
  /**
   * FprintModifier describing the formatting of the string. If fprint_modifier
   * is set, then original_string, language and region should not be set.
   */
  fprintModifier?: RepositoryWebrefFprintModifierProto;
  /**
   * The language in the III standard (http://go/iii)
   */
  language?: string;
  normalizedString?: string;
  originalString?: string;
  /**
   * The region in the III standard (http://go/iii)
   */
  region?: string;
  /**
   * Which querybase pipeline the data comes from.
   */
  sourceType?:  | "SOURCE_NAVBOOST" | "SOURCE_SCRAPE" | "SOURCE_INSTANT_NAVBOOST";
}

/**
 * Metadata about MDVC (go/mdvc). Next available tag: 18.
 */
export interface RepositoryWebrefMdvcMetadata {
  /**
   * Undergoing migration into the PerVertical message. Avoid using it. Concept
   * ids of MDVC dimensions of this concept.
   */
  dimension?: bigint[];
  /**
   * Undergoing migration into the PerVertical message. Avoid using it. List of
   * encoded mids to be expanded in WebRef/QRef output whenever this entity gets
   * annotated. Will be populated in the annotators once static data is
   * deprecated. b/78866814.
   */
  expandedOutputConceptId?: bigint[];
  /**
   * Undergoing migration into the PerVertical message. Avoid using it. Concept
   * ids of MDVC generalizations of this concept.
   */
  generalization?: bigint[];
  /**
   * True iff the topic is synthetically created during by MDVC extraction.
   */
  isSynthetic?: boolean;
  /**
   * Data, specific to particular verticals.
   */
  perVertical?: RepositoryWebrefMdvcMetadataPerVertical[];
  /**
   * Undergoing migration into the PerVertical message. Avoid using it.
   * Resolution priority for this entity. In case a query has many possible
   * resolutions, only the ones with the highest resolution priority are
   * annotated.
   */
  resolutionPriority?: number;
}

function serializeRepositoryWebrefMdvcMetadata(data: any): RepositoryWebrefMdvcMetadata {
  return {
    ...data,
    dimension: data["dimension"] !== undefined ? data["dimension"].map((item: any) => (String(item))) : undefined,
    expandedOutputConceptId: data["expandedOutputConceptId"] !== undefined ? data["expandedOutputConceptId"].map((item: any) => (String(item))) : undefined,
    generalization: data["generalization"] !== undefined ? data["generalization"].map((item: any) => (String(item))) : undefined,
    perVertical: data["perVertical"] !== undefined ? data["perVertical"].map((item: any) => (serializeRepositoryWebrefMdvcMetadataPerVertical(item))) : undefined,
  };
}

function deserializeRepositoryWebrefMdvcMetadata(data: any): RepositoryWebrefMdvcMetadata {
  return {
    ...data,
    dimension: data["dimension"] !== undefined ? data["dimension"].map((item: any) => (BigInt(item))) : undefined,
    expandedOutputConceptId: data["expandedOutputConceptId"] !== undefined ? data["expandedOutputConceptId"].map((item: any) => (BigInt(item))) : undefined,
    generalization: data["generalization"] !== undefined ? data["generalization"].map((item: any) => (BigInt(item))) : undefined,
    perVertical: data["perVertical"] !== undefined ? data["perVertical"].map((item: any) => (deserializeRepositoryWebrefMdvcMetadataPerVertical(item))) : undefined,
  };
}

/**
 * Per-vertical part. Next available tag: 19
 */
export interface RepositoryWebrefMdvcMetadataPerVertical {
  /**
   * Concept ids compatible with this topic: specializations and/or ones having
   * this concept as a dimension. Always includes the topic itself.
   */
  compatibleIds?: bigint[];
  /**
   * Concept ids of the dimension values of this topic.
   */
  dimensionIds?: bigint[];
  /**
   * Concept ids to annotate whenever this entity is annotated.
   */
  expandedOutputIds?: bigint[];
  /**
   * Concept ids of the generalizations of this topic.
   */
  generalizationIds?: bigint[];
  /**
   * True if the topic is considered a "core topic" for the vertical.
   */
  isCore?: boolean;
  /**
   * If true, the entity is a dimension for some entities in the vertical.
   */
  isDimension?: boolean;
  /**
   * If true, the entity is a generalization for some entities in the vertical.
   */
  isGeneralization?: boolean;
  /**
   * Resolution priority for this entity. If there are many possible
   * resolutions to a MDVC understanding, only the ones with the highest
   * priority are annotated.
   */
  resolutionPriority?: number;
  /**
   * Fingerprints that identify the topic's sub-verticals, if any.
   */
  subVerticalFp?: bigint[];
  /**
   * Name of the vertical this message is about.
   */
  verticalName?:  | "UNKNOWN" | "CARS" | "CVG" | "PRODUCTS" | "SYMPTOMS" | "CHAINS" | "MOVIES" | "SPORTS_TEAM" | "EXAMS" | "MOTORCYCLES" | "PRIMEREF" | "SONGS" | "EDUCATION" | "EVENTS";
}

function serializeRepositoryWebrefMdvcMetadataPerVertical(data: any): RepositoryWebrefMdvcMetadataPerVertical {
  return {
    ...data,
    compatibleIds: data["compatibleIds"] !== undefined ? data["compatibleIds"].map((item: any) => (String(item))) : undefined,
    dimensionIds: data["dimensionIds"] !== undefined ? data["dimensionIds"].map((item: any) => (String(item))) : undefined,
    expandedOutputIds: data["expandedOutputIds"] !== undefined ? data["expandedOutputIds"].map((item: any) => (String(item))) : undefined,
    generalizationIds: data["generalizationIds"] !== undefined ? data["generalizationIds"].map((item: any) => (String(item))) : undefined,
    subVerticalFp: data["subVerticalFp"] !== undefined ? data["subVerticalFp"].map((item: any) => (String(item))) : undefined,
  };
}

function deserializeRepositoryWebrefMdvcMetadataPerVertical(data: any): RepositoryWebrefMdvcMetadataPerVertical {
  return {
    ...data,
    compatibleIds: data["compatibleIds"] !== undefined ? data["compatibleIds"].map((item: any) => (BigInt(item))) : undefined,
    dimensionIds: data["dimensionIds"] !== undefined ? data["dimensionIds"].map((item: any) => (BigInt(item))) : undefined,
    expandedOutputIds: data["expandedOutputIds"] !== undefined ? data["expandedOutputIds"].map((item: any) => (BigInt(item))) : undefined,
    generalizationIds: data["generalizationIds"] !== undefined ? data["generalizationIds"].map((item: any) => (BigInt(item))) : undefined,
    subVerticalFp: data["subVerticalFp"] !== undefined ? data["subVerticalFp"].map((item: any) => (BigInt(item))) : undefined,
  };
}

/**
 * Multiple entities can be identified on a document or query. Each entity can
 * be mentioned several times in different positions on the document or query.
 * This message describes a single mention of the entity. Note that a mention
 * can be either explicit or implicit mentions. All explicit mentions refer to
 * exact range in the document where the entity occurred, but implicit mentions
 * may or may not have corresponding range. Next available tag number: 40
 */
export interface RepositoryWebrefMention {
  /**
   * Whether this mention was created by CloseAnswers on Postref. This bit is
   * populated into corresponding intent_query through Aqua.
   */
  addedByCloseAnswers?: boolean;
  /**
   * If the mention's range is discontinuous, additional ranges that are a part
   * of the mention but are not included in the begin/end range above.
   */
  additionalExplainedRange?: RepositoryWebrefMentionAdditionalExplainedRange[];
  /**
   * The [begin, end) byte offset, compatible with the Goldmine DocState
   * representation. - For CONTENT, TITLE, META_CONTENT_TAG and IMG_ALT_TAG
   * segments, the offsets are relative to the beginning of the document
   * content. - For ANCHOR, QUERY, URL, IMAGE_QUERY, CONTEXT_ENTITY,
   * CONTEXT_QUERY, SPORE_GRAPH, INSTANT_QUERY and VIDEO_TRANSCRIPT segments,
   * the offsets are relative to the beginning of the corresponding
   * (sub-)segment or text from doc attachment. The
   * (indexing.annotations.goldmine) options are marks for Goldmine
   * AnnotationsFinder to locate begin and end offsets in order to extract them
   */
  begin?: number;
  /**
   * The [begin end) token offsets in the Goldmine DocState. They follow
   * similar rules as "begin" and "end" above, but for tokens rather than byte
   * offsets. These fields are currently only populated by the query annotator.
   */
  beginTokenIndex?: number;
  /**
   * For a compound mention, the references to the entity and mention of the
   * components. Each compound_mention claims one or more 'mrf' fields from the
   * WebrefEntity owning this mention. Use QueryJoinToMeaningStructConverter to
   * expand compound mentions into complete MRF.
   */
  compoundMention?: RepositoryWebrefMentionCompoundMention[];
  /**
   * A probabilistic score describing how certain the annotator is that this
   * exact range in the document or query refers to the entity. Probability that
   * a mention is correct corresponds to confidence score roughly as follows:
   * 0.3 -> 75% 0.5 -> 87% 0.7 -> 89% 0.9 -> 94% 1.0 -> 98% However if you
   * consider all mentions with a score above 0.3, then most of these will have
   * scores close to 1, so the overall precision of these mentions is around
   * 95%.
   */
  confidenceScore?: number;
  /**
   * Debug information.
   */
  debugInfo?: RepositoryWebrefMentionDebugInfo;
  /**
   * Additional detailed scores about this mention.
   */
  detailedMentionScores?: RepositoryWebrefDetailedMentionScores;
  end?: number;
  endTokenIndex?: number;
  /**
   * Information used by the evaluation tools to mark mentions annotations as
   * correct/incorrect. This will never be annotated in production (would be
   * nice if was, though :-)).
   */
  evalInfo?: RepositoryWebrefMentionEvalInfo;
  /**
   * DEPRECATED and not populated anymore.
   */
  interpretationNumber?: number[];
  /**
   * True if the entity is mentioned implicitly. Note that a mention can be
   * implicit *and* have a non-empty range, for example if the entity is Sports,
   * and this is inferred from the mention of "gym".
   */
  isImplicit?: boolean;
  /**
   * Provides a Wordgraph lexical signals for the mentioned range so it can be
   * use in LooseParsing. Please don't use this field before consulting
   * wordgraph-team.
   */
  lexicalAnnotation?: RepositoryWebrefLexicalAnnotation;
  /**
   * Qref & Postref only: Set to true for candidates part of qref candidate
   * output for which there was no mention in qref. Internal to qref and
   * LooseParsing. Do not use outside of these systems.
   */
  lowConfidence?: boolean;
  /**
   * Refcon-only: Annotated span in Refcon-normalized textual format,
   * corresponding to the [begin end) offset interval in the CDoc. It will only
   * be populated for CDocs originated from Docjoin extraction.
   */
  matchingText?: string;
  /**
   * Metadata attatched to the name.
   */
  nameMetadata?: RepositoryWebrefConceptNameMetadata;
  /**
   * Whether the mention is a non-locational reference to a geographical
   * entity. Ranges from 0 (locational) to 1 (non-locational).
   */
  nonLocationalScore?: number;
  /**
   * Provides concised access to all matched MatchedLightweightToken.
   */
  perMentionLightweightToken?: RepositoryWebrefLightweightTokensPerMentionLightweightToken;
  /**
   * Additional personalization output scores about this mention.
   */
  personalizationContextOutputs?: RepositoryWebrefPersonalizationContextOutputs;
  /**
   * The prior probability of the entity for this mention.
   */
  priorProbability?: number;
  /**
   * Whether the mention is a reference (e.g. it could be resolved to an entity
   * coming from personal data) or not, currently only used for personal
   * resolutions. Scores from 0 (not a reference) to 1 (reference). Use at your
   * own risk as they are subject to change, advised to talk to refx-personal
   * first.
   */
  referenceScore?: number;
  /**
   * Whether the mention is a resolution or not, currently only used for
   * personal resolutions. Scores from 0 (not a resolution) to 1 (resolution).
   * Use at your own risk as they are subject to change, advised to talk to
   * refx-personal first.
   */
  resolutionScore?: number;
  /**
   * Assorted things that can be added to a Mention.
   */
  stuff?: Proto2BridgeMessageSet;
  /**
   * Identifies the sub-segment where the annotation occurs. See
   * SubSegmentIndex for details. Not present in QRef, also deprecated for URL
   * segment types.
   */
  subsegmentIndex?: RepositoryWebrefSubSegmentIndex;
  /**
   * Confidence for the time_offset_ms annotation, quantized to values in range
   * 0-127 (see speech::VideoASRServerUtil::ConfidenceQuantize for how the
   * quantization was done). Confidence can be empty for special characters
   * (e.g. spaces).
   */
  timeOffsetConfidence?: number;
  /**
   * Timestamp that this mention appeared in the video. The field is only
   * populated for VIDEO_TRANSCRIPT when the byte offset is the same. It is
   * extracted from
   * cdoc.doc_videos.content_based_metadata.transcript_asr.transcript.timestamp.
   */
  timeOffsetMs?: number;
  /**
   * Confidence that this name is a trusted name of the entity. This is set
   * only in case the confidence is higher than an internal threshold (see
   * ConceptProbability).
   */
  trustedNameConfidence?: number;
}

function serializeRepositoryWebrefMention(data: any): RepositoryWebrefMention {
  return {
    ...data,
    lexicalAnnotation: data["lexicalAnnotation"] !== undefined ? serializeRepositoryWebrefLexicalAnnotation(data["lexicalAnnotation"]) : undefined,
    nameMetadata: data["nameMetadata"] !== undefined ? serializeRepositoryWebrefConceptNameMetadata(data["nameMetadata"]) : undefined,
    perMentionLightweightToken: data["perMentionLightweightToken"] !== undefined ? serializeRepositoryWebrefLightweightTokensPerMentionLightweightToken(data["perMentionLightweightToken"]) : undefined,
    subsegmentIndex: data["subsegmentIndex"] !== undefined ? serializeRepositoryWebrefSubSegmentIndex(data["subsegmentIndex"]) : undefined,
  };
}

function deserializeRepositoryWebrefMention(data: any): RepositoryWebrefMention {
  return {
    ...data,
    lexicalAnnotation: data["lexicalAnnotation"] !== undefined ? deserializeRepositoryWebrefLexicalAnnotation(data["lexicalAnnotation"]) : undefined,
    nameMetadata: data["nameMetadata"] !== undefined ? deserializeRepositoryWebrefConceptNameMetadata(data["nameMetadata"]) : undefined,
    perMentionLightweightToken: data["perMentionLightweightToken"] !== undefined ? deserializeRepositoryWebrefLightweightTokensPerMentionLightweightToken(data["perMentionLightweightToken"]) : undefined,
    subsegmentIndex: data["subsegmentIndex"] !== undefined ? deserializeRepositoryWebrefSubSegmentIndex(data["subsegmentIndex"]) : undefined,
  };
}

/**
 * Additional ranges covered by the mention. Next available tag: 5
 */
export interface RepositoryWebrefMentionAdditionalExplainedRange {
  /**
   * Like begin/end, begin_token_index/end_token_index above.
   */
  begin?: number;
  beginTokenIndex?: number;
  end?: number;
  endTokenIndex?: number;
}

/**
 * Reference to a component of a compound mention. Next available tag: 5
 */
export interface RepositoryWebrefMentionComponent {
  /**
   * The indices to identify the entity within the WebrefEntities.entities, the
   * segment within its EntityAnnotations.segment_mentions, and the mention
   * within that segment. entity_index is always guaranteed to be set, but
   * segment_mentions_index and mention_index are omitted if the component
   * reference is implicit.
   */
  entityIndex?: number;
  /**
   * The source of the compound has designated this component as the head. Only
   * one of the components can be a head, but it's possible none are.
   */
  isHeadComponent?: boolean;
  mentionIndex?: number;
  segmentMentionsIndex?: number;
}

/**
 * A single compound mention. Next available tag: 3
 */
export interface RepositoryWebrefMentionCompoundMention {
  /**
   * References to the component mentions which the MRF needs to be fully
   * expanded. It is guaranteed that for a given set of components there exists
   * only a single CompoundMention, i.e. the CompoundMentions are deduped to be
   * unique so each set of components is present only once. The ArgumentValue of
   * the WebrefEntity.mrf refer to these components via ComponentReference; it
   * is guaranteed there are as many components as the MRF expression refers to.
   */
  component?: RepositoryWebrefMentionComponent[];
  /**
   * The WebrefEntity.mrf indices which this compound applies to. There can be
   * at most one CompoundMention which claims an MRF index, but it is possible
   * there are MRF expressions which are not claimed by any CompoundMention.
   */
  mrfIndex?: number[];
}

export interface RepositoryWebrefMentionDebugInfo {
  /**
   * A clean version of text. This is mostly used for compatibility with other
   * Goldmine annotators.
   */
  cleanText?: string;
  /**
   * Optional debug information.
   */
  infoString?: string[];
  /**
   * A snippet of the parsed text (html tags removed) in the page around this
   * mention. Useful for human evaluation of the quality of the annotations.
   * Outputted by WebrefAnnotator if --webref_output_mention_snippet_size is set
   * to a value greater than 0.
   */
  snippet?: string;
  /**
   * Original UTF-8 document text occurring in the range [begin, end).
   */
  text?: string;
}

export interface RepositoryWebrefMentionEvalInfo {
  /**
   * Weight of the mention used in the ATM score.
   */
  atmWeight?: number;
  /**
   * The aggregate numerical rating of this mention. 0.0 means completely
   * incorrect, and 1.0 completely correct.
   */
  rating?: number;
}

/**
 * Per document mention ratings. Next id: 10
 */
export interface RepositoryWebrefMentionRatings {
  /**
   * Byte offsets of the mention.
   */
  begin?: number;
  end?: number;
  mentionMatch?:  | "SUBPART" | "SUPER" | "EXACT"[];
  singleMentionRating?: RepositoryWebrefMentionRatingsSingleMentionRating[];
}

function serializeRepositoryWebrefMentionRatings(data: any): RepositoryWebrefMentionRatings {
  return {
    ...data,
    singleMentionRating: data["singleMentionRating"] !== undefined ? data["singleMentionRating"].map((item: any) => (serializeRepositoryWebrefMentionRatingsSingleMentionRating(item))) : undefined,
  };
}

function deserializeRepositoryWebrefMentionRatings(data: any): RepositoryWebrefMentionRatings {
  return {
    ...data,
    singleMentionRating: data["singleMentionRating"] !== undefined ? data["singleMentionRating"].map((item: any) => (deserializeRepositoryWebrefMentionRatingsSingleMentionRating(item))) : undefined,
  };
}

/**
 * Next available tag: 11
 */
export interface RepositoryWebrefMentionRatingsSingleMentionRating {
  /**
   * Set for mentions got from the new topicality template. True if the raters
   * checked this range as being a good range for the entity. If the range is
   * not correct we demote the mention score. This field is only used in
   * template version V1. From template version V2 and forward it is now set via
   * phrase_refer.
   */
  isCorrectRange?: boolean;
  mentionMatch?:  | "SUBPART" | "SUPER" | "EXACT";
  mentionRelevant?:  | "NOT_RELEVANT" | "RELEVANT" | "CORRECT" | "NOT_VALID";
  phraseRefer?:  | "PHRASE_REFER" | "PHRASE_MAYBE_REFER" | "PHRASE_NOT_REFER";
  /**
   * Whether rater can understand the topic.
   */
  raterCanUnderstandTopic?: boolean;
  /**
   * The source of the rating, possibly a golden set external to EWOK.
   */
  ratingSource?:  | "RATING_SOURCE_UNKNOWN" | "RATING_SOURCE_EWOK" | "RATING_SOURCE_SAFT_GOLDEN" | "RATING_SOURCE_CROWDCOMPUTE";
  resultCount?: number;
  taskData?: RepositoryWebrefTaskData;
  topicMentionedInResult?:  | "RESULT_MENTIONED" | "RESULT_MAYBE_MENTIONED" | "RESULT_NOT_MENTIONED"[];
}

function serializeRepositoryWebrefMentionRatingsSingleMentionRating(data: any): RepositoryWebrefMentionRatingsSingleMentionRating {
  return {
    ...data,
    taskData: data["taskData"] !== undefined ? serializeRepositoryWebrefTaskData(data["taskData"]) : undefined,
  };
}

function deserializeRepositoryWebrefMentionRatingsSingleMentionRating(data: any): RepositoryWebrefMentionRatingsSingleMentionRating {
  return {
    ...data,
    taskData: data["taskData"] !== undefined ? deserializeRepositoryWebrefTaskData(data["taskData"]) : undefined,
  };
}

/**
 * Collects signals from one query used for prior learning.
 */
export interface RepositoryWebrefNameDebugInfo {
  /**
   * List of per-candidate signals derived from annotation of this query.
   */
  candidates?: RepositoryWebrefNameDebugInfoCandidateInfo[];
  /**
   * Query with region (language is set in parent NameInfo).
   */
  query?: RepositoryWebrefLocalizedString;
  /**
   * Query weight used in learning.
   */
  weight?: number;
}

/**
 * Collects signals from one query and one candidate. Next available tag: 9
 */
export interface RepositoryWebrefNameDebugInfoCandidateInfo {
  /**
   * Whether the entity is purely from strong result entities, and is matchless
   * in query annotation.
   */
  isMatchlessResultContext?: boolean;
  /**
   * Mid of the candidate entity or empty string for the full world.
   */
  mid?: string;
  /**
   * Debug name of the entity (not usually populated).
   */
  name?: string;
  resultEntityScore?: number;
}

/**
 * Represents all information we have about a specific/localized name. Next
 * available tag: 13. NOTE: If you add a field to the NameInfo proto and wish to
 * retain it *after* the GlobalNameInfo merging steps in
 * //r/w/enricher/pipeline:topic-enricher-flume-main then the appropriate
 * combining logic for turning a flume stream of NameInfo protos into a single
 * NameInfo must be updated with the new field in mind, in either or both of
 * CombineContextNameInfosFn/CombineNameInfosFn. If not, the newly added field
 * will be ignored during the merging steps (presumably because it is a
 * transient field or a debug field that is not necessary to be retained).
 */
export interface RepositoryWebrefNameInfo {
  /**
   * The score aggregated from all sources.
   */
  aggregatedScores?: RepositoryWebrefAggregatedEntityNameScores;
  /**
   * Information on categories annotated on the range.
   */
  annotatedCategory?: RepositoryWebrefAnnotatedCategoryInfo[];
  /**
   * DEBUG ONLY: stores a list of queries with per-candidate scores about
   * signals used for prior learning.
   */
  debugDetails?: RepositoryWebrefNameDebugInfo[];
  /**
   * Field which decides if this NameInfo should be included in model creation.
   */
  includeInModel?: boolean;
  /**
   * The specific name to which this information applies.
   */
  name?: RepositoryWebrefLocalizedString;
  /**
   * N-gram data (e.g. n-gram IDF).
   */
  ngramData?: RepositoryWebrefUniversalNgramData;
  /**
   * Lightweight token semantic metadata for inflected name.
   */
  perNameLightweightToken?: RepositoryWebrefLightweightTokensPerNameLightweightToken;
  /**
   * The name-specific scores. These scores only depend on the name and are
   * independent of the entity.
   */
  scores?: RepositoryWebrefNameScores;
  /**
   * The per-source scores.
   */
  source?: RepositoryWebrefEntityNameSource[];
}

function serializeRepositoryWebrefNameInfo(data: any): RepositoryWebrefNameInfo {
  return {
    ...data,
    aggregatedScores: data["aggregatedScores"] !== undefined ? serializeRepositoryWebrefAggregatedEntityNameScores(data["aggregatedScores"]) : undefined,
    annotatedCategory: data["annotatedCategory"] !== undefined ? data["annotatedCategory"].map((item: any) => (serializeRepositoryWebrefAnnotatedCategoryInfo(item))) : undefined,
    perNameLightweightToken: data["perNameLightweightToken"] !== undefined ? serializeRepositoryWebrefLightweightTokensPerNameLightweightToken(data["perNameLightweightToken"]) : undefined,
    source: data["source"] !== undefined ? data["source"].map((item: any) => (serializeRepositoryWebrefEntityNameSource(item))) : undefined,
  };
}

function deserializeRepositoryWebrefNameInfo(data: any): RepositoryWebrefNameInfo {
  return {
    ...data,
    aggregatedScores: data["aggregatedScores"] !== undefined ? deserializeRepositoryWebrefAggregatedEntityNameScores(data["aggregatedScores"]) : undefined,
    annotatedCategory: data["annotatedCategory"] !== undefined ? data["annotatedCategory"].map((item: any) => (deserializeRepositoryWebrefAnnotatedCategoryInfo(item))) : undefined,
    perNameLightweightToken: data["perNameLightweightToken"] !== undefined ? deserializeRepositoryWebrefLightweightTokensPerNameLightweightToken(data["perNameLightweightToken"]) : undefined,
    source: data["source"] !== undefined ? data["source"].map((item: any) => (deserializeRepositoryWebrefEntityNameSource(item))) : undefined,
  };
}

/**
 * Represents some name-specific scores. (Unlike EntityNameScore, these scores
 * are independent of the entities the name is associated with). These scores
 * are available for each name as well as for each name/source. Next available
 * tag: 31.
 */
export interface RepositoryWebrefNameScores {
  /**
   * Approximates volume of this name including entities we don't have in our
   * set. This is useful to estimate the size of the "open world". For example,
   * this field can be equal to the total number of clicks for the query. Note
   * that for now, we ignore the number of clicks but just use the idf if
   * available.
   */
  completeWorldVolume?: number;
  /**
   * The fringe score in [0, 1] for this context name. This is only populated
   * for full-query context names.
   */
  contextFringeScore?: number;
  /**
   * The amount of evidence available for this context name.
   */
  contextWeight?: number;
  /**
   * The idf of this name.
   */
  idfScore?: number;
  /**
   * 'Raw' open world is computed based on ngram count data. For some names
   * however, we modify the open world based on entities associated with them.
   * This field contains the additive open world modifier. open_world_volume =
   * raw open world + open_world_volume_modifier
   */
  openWorldVolumeModifier?: number;
  /**
   * The total score of that name/source. It describes how much data we have
   * for that name/source. It can for example be the sum of all the entity
   * scores for this name.
   */
  totalScore?: number;
}

/**
 * An N-gram context encountered on the document.
 */
export interface RepositoryWebrefNgramContext {
  /**
   * The entities that were annotated on the context
   */
  mention?: RepositoryWebrefNgramMention[];
  /**
   * The context (original) text.
   */
  text?: string;
  /**
   * The weight of the context on the document; depends on how many times we
   * saw the string in the document.
   */
  weight?: number;
}

/**
 * A mention that has been matched in the context (or a substring of it).
 */
export interface RepositoryWebrefNgramMention {
  /**
   * The entity the mention was referring to.
   */
  mid?: string;
  /**
   * The average score the mention was given across all occurrences of the
   * n-gram.
   */
  score?: number;
}

/**
 * Oyster type information.
 */
export interface RepositoryWebrefOysterType {
  /**
   * The Oyster feature type, which provides a rough categorization. This is a
   * value of the enum geostore.FeatureProto.TypeCategory.
   */
  featureType?: number;
  /**
   * Geo Ontology GConcept Instances from the FeatureProto. - Design doc linked
   * off http://wiki/Main/GeoOntology - Use the accessor library to read this
   * field: geostore/base/public/gconcept_instance.h
   */
  gconcepts?: GeostoreOntologyRawGConceptInstanceContainerProto;
}

/**
 * Per document ratings relevance ratings. Next id: 21.
 */
export interface RepositoryWebrefPerDocRelevanceRating {
  contentRelevant?:  | "NONE" | "NOT_APPLICABLE" | "NOT_RELEVANT" | "BARELY_RELEVANT" | "RELEVANT" | "IMPORTANT" | "VITAL";
  /**
   * How this rating is displayed in the evals, pre-computed from the other
   * fields.
   */
  displayString?: string;
  /**
   * The url of the ewok task that resulted in this rating. Example:
   * https://furball.corp.google.com/project/view-item?itemId=1&projectId=2
   */
  furballUrl?: string;
  itemId?: bigint;
  /**
   * If the topic is about a business chain, whether the
   */
  pageIsAboutChain?:  | "PAGE_IS_ABOUT_CHAIN_NONE" | "NOT_SAME_CHAIN_AS_TOPIC" | "ALL_LOCATIONS_OF_TOPIC_CHAIN" | "SEVERAL_LOCATIONS_OF_TOPIC_CHAIN" | "EXACT_LOCATION_OF_TOPIC_CHAIN" | "DIFFERENT_LOCATION_OF_TOPIC_CHAIN";
  /**
   * Metadata for task-level ratings. Not filled for aggregated doc-level
   * ratings.
   */
  projectId?: bigint;
  /**
   * Whether rater can understand the topic.
   */
  raterCanUnderstandTopic?: boolean;
  taskDetails?: RepositoryWebrefTaskDetails;
  taskId?: bigint;
  /**
   * Whether the topic is about a business chain.
   */
  topicIsChain?:  | "TOPIC_IS_ABOUT_CHAIN_NONE" | "CHAIN_SPECIFIC_LOCATION" | "CHAIN_ENTITY" | "NOT_CHAIN" | "UNSURE";
}

function serializeRepositoryWebrefPerDocRelevanceRating(data: any): RepositoryWebrefPerDocRelevanceRating {
  return {
    ...data,
    itemId: data["itemId"] !== undefined ? String(data["itemId"]) : undefined,
    projectId: data["projectId"] !== undefined ? String(data["projectId"]) : undefined,
    taskDetails: data["taskDetails"] !== undefined ? serializeRepositoryWebrefTaskDetails(data["taskDetails"]) : undefined,
    taskId: data["taskId"] !== undefined ? String(data["taskId"]) : undefined,
  };
}

function deserializeRepositoryWebrefPerDocRelevanceRating(data: any): RepositoryWebrefPerDocRelevanceRating {
  return {
    ...data,
    itemId: data["itemId"] !== undefined ? BigInt(data["itemId"]) : undefined,
    projectId: data["projectId"] !== undefined ? BigInt(data["projectId"]) : undefined,
    taskDetails: data["taskDetails"] !== undefined ? deserializeRepositoryWebrefTaskDetails(data["taskDetails"]) : undefined,
    taskId: data["taskId"] !== undefined ? BigInt(data["taskId"]) : undefined,
  };
}

/**
 * Aggregates ratings by url/doc_fp.
 */
export interface RepositoryWebrefPerDocRelevanceRatings {
  /**
   * - In topicality ratings this is Fingerprint2011() of the normalized cdoc.
   * - In query-mention ratings this is a hash of the QueryJoin. - In
   * doc-content-mention ratings this is a hash of a QueryJoin in which the
   * mention rating task has been embedded. -
   */
  docFp?: bigint;
  entityNameRating?: RepositoryWebrefEntityNameRatings[];
  mentionRating?: RepositoryWebrefMentionRatings[];
  taskLevelRating?: RepositoryWebrefPerDocRelevanceRating[];
  /**
   * - In topicality ratings this is the url of the document. - In
   * query-mention ratings this is the query in format "en:US:query text". - In
   * doc-content-mention ratings this is %x:%s where %x is the hex doc_fp of the
   * cdoc (TODO(b/139799592) or sometimes the doc_fp below), and %s is the text
   * of the eval range. - In entity-name ratings this is the MID of the entity.
   */
  url?: string;
}

function serializeRepositoryWebrefPerDocRelevanceRatings(data: any): RepositoryWebrefPerDocRelevanceRatings {
  return {
    ...data,
    docFp: data["docFp"] !== undefined ? String(data["docFp"]) : undefined,
    mentionRating: data["mentionRating"] !== undefined ? data["mentionRating"].map((item: any) => (serializeRepositoryWebrefMentionRatings(item))) : undefined,
    taskLevelRating: data["taskLevelRating"] !== undefined ? data["taskLevelRating"].map((item: any) => (serializeRepositoryWebrefPerDocRelevanceRating(item))) : undefined,
  };
}

function deserializeRepositoryWebrefPerDocRelevanceRatings(data: any): RepositoryWebrefPerDocRelevanceRatings {
  return {
    ...data,
    docFp: data["docFp"] !== undefined ? BigInt(data["docFp"]) : undefined,
    mentionRating: data["mentionRating"] !== undefined ? data["mentionRating"].map((item: any) => (deserializeRepositoryWebrefMentionRatings(item))) : undefined,
    taskLevelRating: data["taskLevelRating"] !== undefined ? data["taskLevelRating"].map((item: any) => (deserializeRepositoryWebrefPerDocRelevanceRating(item))) : undefined,
  };
}

/**
 * Key-Value-like message to store values associated with a personalization
 * type. Next id: 3
 */
export interface RepositoryWebrefPersonalizationContextOutput {
  /**
   * Score corresponding to some kind of biasing strength which was applied.
   * The exact semantics of this score is subject to further changes. Don't make
   * assumptions about specific values or ranges. Values > 0 represents that a
   * boost was applied. Values < 0 represents that a penalty was appled.
   */
  score?: number;
  type?:  | "UNKNOWN" | "USER_CORRECTIONS" | "MEDIA_HISTORY" | "ANIMA_ENTITY_INTERESTS";
}

/**
 * Details about personalization and contextual scoring decisions from
 * Personalized Query Understanding (go/pqu). This message represents
 * information about what kind of biasing was applied, including what type of
 * data were used and how strongly. Intended to be used by client code for
 * fine-tuning necessary ranking or triggering logic if it's not possible to
 * rely on the aggregated annotation confidence alone. To minimize unwanted
 * dependencies and incorrect usage of the data this proto has restricted
 * visibility. Please reach out to refx-pqu@google.com if you want to have
 * access. Next id: 2
 */
export interface RepositoryWebrefPersonalizationContextOutputs {
  /**
   * Detailed output scores per personalization type.
   */
  outputs?: RepositoryWebrefPersonalizationContextOutput[];
}

/**
 * Metadata about a name. There are two metadata protos, whose content is meant
 * to be similar but their usage different: NameEntityMetadata for readability
 * and ConceptNameMetadata for size / decoding speed. NameEntityMetadata is
 * propagated to GlobalNameInfo and EntityJoin tables, while ConceptNameMetadata
 * is propagated from EntityJoins to the name matching tables and later to the
 * Webref's/QRef's output. To add a new metadata field in the Names pipeline,
 * and propagate it to EntityJoins and Names matching tables, it is necessary
 * to: (1) Add the field to NameEntityMetadata, and a corresponding data
 * representation in ConceptNameMetadata. (2) Populate the field in
 * NameVariantSignals.name_metadata, from any source. This can be done in a
 * corresponding NameProcessor. (3) Update the library name-metadata.h/cc to
 * make sure that the metadata field is: a) merged correctly when merging two
 * NameSignals; and b) transformed to the corresponding field in
 * ConceptNameMetadata proto. Next available tag: 22.
 */
export interface RepositoryWebrefPreprocessingNameEntityMetadata {
  /**
   * There is a limit of entities per name for which we can keep name signals
   * and score. This flag is set to true for names that by-passed
   * per-name-scoring, as there were too many entities for the name.
   */
  isBypassedName?: boolean;
  /**
   * This name is a generated compound name to pass primary pruning.
   */
  isCompoundName?: boolean;
  /**
   * Indicates special compound retrieval keys, like "Compound $mid1 $mid2"
   */
  isCompoundRetrievalKey?: boolean;
  /**
   * This is set to true if the entity corresponds to a dictionary term.
   */
  isDictionaryTerm?: boolean;
  /**
   * If true, this name is an event retrieval key.
   */
  isEventRetrievalKey?: boolean;
  /**
   * This name is generated from other names.
   */
  isGeneratedName?: boolean;
  /**
   * This name is a generated street name.
   */
  isGeneratedStreetname?: boolean;
  /**
   * This name is added by name propagation in hierarchy.
   */
  isHierarchyPropagated?: boolean;
  /**
   * This name is an ISBN.
   */
  isIsbn?: boolean;
  /**
   * This name comes from recording lyrics content.
   */
  isLyricsContent?: boolean;
  /**
   * This name is a phone number.
   */
  isPhoneNumber?: boolean;
  /**
   * This name is used for refcon.
   */
  isRefconName?: boolean;
  /**
   * This name is a reference name, only for internal usage, this name should
   * not go into matching table without support of other signals.
   */
  isReferenceName?: boolean;
  /**
   * This name is the URL of a reference page.
   */
  isRefpageUrl?: boolean;
  /**
   * This name is generated from a reverse unique property of the entity.
   */
  isReverseUniquePropertyName?: boolean;
  /**
   * This name is a strong identifier for this entity.
   */
  isStrongIdentifier?: boolean;
  /**
   * Set if the name is coming from synonyms.
   */
  isSynonymOrFuzzyMatch?: boolean;
  /**
   * If true, this name is a trusted name if it is in ALLCAPS.
   */
  isTrustedAllcapsName?: boolean;
  /**
   * If true, do not do tokenization when compute fprint hash for this name.
   */
  isUnnormalizedName?: boolean;
  /**
   * This name is clearly not generated(aka. at least one source of this name
   * is not generated). This field is added for simplifying generated name tag
   * while merging. Do not use this metadata directly.
   */
  notGeneratedName?: boolean;
  /**
   * Original versions of the name (before normalization). Used as query for
   * the entity by Explicit Entity Search.
   */
  originalNames?: RepositoryWebrefPreprocessingOriginalNames;
  /**
   * Whether or not to suppress tokenization on this name.
   */
  suppressTokenization?: boolean;
}

/**
 * Abstract, source independent scores. Next available tag: 7
 */
export interface RepositoryWebrefPreprocessingNameEntityScores {
  /**
   * An unnormalized measure of how much evidence we have that this name
   * variant refers to the key entity. Should be comparable to all scores from
   * the same source for: - other entities having the same name variant - the
   * open world score computed for this name variant
   */
  priorScore?: number;
  /**
   * Prior score come from source that is quantifiable. artificial_score =
   * prior_score - volume_based_score.
   */
  volumeBasedScore?: number;
}

/**
 * Next available tag: 33.
 */
export interface RepositoryWebrefPreprocessingNameVariantSignals {
  /**
   * Common prior_score/trust proto This field is shared by all sources
   * providing this kind of data, the information has to be considered in
   * context with the source.
   */
  scores?: RepositoryWebrefPreprocessingNameEntityScores;
  /**
   * The source of this NameVariantSignals proto
   */
  source?:  | "INVALID" | "KG" | "KG_NAME" | "KG_ALIAS" | "KG_ISBN13" | "KG_GTIN" | "KG_STOCK_TICKER" | "KG_AVIATION" | "KG_TRUSTED_ALIAS" | "KG_CHEMICAL_SYMBOL" | "KG_RADIO_STATION" | "KG_REVERSE_UNIQUE_PROPERTY" | "KG_TRANSIT_STATION_CODE" | "KG_SYMBOL" | "KG_ALLCAPS_NAME" | "KG_NICKNAME" | "KG_WORDGRAPH_NAME" | "KG_SOCIAL_PROFILE_ID" | "KG_SOCIAL_PROFILE_SITECHUNK" | "ENTITY_NAME_TRANSLATIONS_GENERATOR" | "MAPFACTS" | "MAPFACTS_PHONENUMBER" | "MAPFACTS_STREET_NAME_GENERATOR" | "MAPFACTS_FUZZY_PHONENUMBER" | "MAPFACTS_NAME_GENERATOR" | "MAPFACTS_GEOCODES_ADDRESS_LINES" | "MAPFACTS_GEOCODES_UNLINKED" | "MAPFACTS_TRIMMED_POSTAL_CODE" | "MAPFACTS_MERGED_POSTAL_CODE" | "MAPFACTS_POSTAL_CODE_WITH_COUNTRY_CODE" | "MAPFACTS_TRANSIT_LINE_NAME_GENERATOR" | "MAPFACTS_HOUSE_ID" | "CDOCS" | "CDOCS_ANCHOR" | "CDOCS_NAVBOOST" | "CDOCS_REFERENCE_PAGE_URL" | "WIKIJOINS" | "WIKIDATA_AKA" | "WIKIDATA_LABEL" | "PRODUCT" | "PRODUCT_TITLE" | "PRODUCT_MANUFACTURER_PART_NUMBER" | "PRODUCT_MODEL_VARIATION" | "PRODUCT_COMPANY_OR_BRAND_STRIPPING" | "PRODUCT_AGGRESSIVE_STRIP" | "PRODUCT_AGGRESSIVE_BRAND_STRIP" | "SCORER" | "SCORER_CATEGORICAL_NAME_SUPPRESSOR" | "SCORER_BAD_SUBNAME_DEMOTION" | "SCORER_YEAR_NAME_DEMOTION" | "SCORER_NAME_BLACKLIST" | "NAME_LEAKAGE_PREVENTION" | "INCOMPATIBLE_NUMBER_DEMOTION" | "BAD_STRIPPED_NAME" | "BAD_FRINGE_NAME" | "BAD_PERSON_NAME" | "PERSON_NAME_GENERATOR" | "PERSON_NAME_GENERATOR_WITH_INITIALS" | "INJECTED" | "AFFIXED_NAME_GENERATOR" | "BUSINESS_SUFFIX_STRIPPED_NAME" | "CHAIN_NAME_GENERATOR" | "LOCATION_STRIPPED_NAME" | "PUNCTUATION_STRIPPED_NAME" | "LEXICON_GENERATOR" | "COMPOUND_NAME" | "INDIC_NORMALIZER" | "STRIP_FIRST_STOPWORD" | "MIX_CASE_NORMALIZE" | "MOVIE_YEAR" | "STRIP_IMPLICATION" | "MIX_STRIP" | "OYSTER_NAME" | "STRIP_WIKI" | "CIVICS_NAME_GENERATOR" | "STRIPPED_THEATER_NAME" | "NUMBER_VARIANT_GENERATOR" | "PERSONAL_MEDIA_NAME_GENERATOR" | "MRF_INDEXING_NAME_TV_SHOWS" | "MATCH_WITH_MIDDLE_INITIALS" | "COMBINED";
}

export interface RepositoryWebrefPreprocessingOriginalNames {
  /**
   * The total number of original names that a normalized name has (all
   * versions from all different sources).
   */
  count?: number;
  name?: RepositoryWebrefPreprocessingOriginalNamesOriginalName[];
}

export interface RepositoryWebrefPreprocessingOriginalNamesOriginalName {
  /**
   * The total number of different sources from where this version of the
   * original name comes from.
   */
  count?: number;
  /**
   * Score estimating how good this original name is: - some sources are
   * considered more authoritative than others (e.g. KG) - a name found in more
   * sources is better.
   */
  score?: number;
  /**
   * The sources this name comes from.
   */
  source?: number[];
  /**
   * One original name version.
   */
  text?: string;
}

/**
 * Proto with metadata related to why a particular cdoc was selected for an
 * entityjoin.
 */
export interface RepositoryWebrefPreprocessingUrlMatchingMetadata {
  /**
   * The sources the url was suggested by.
   */
  source?: RepositoryWebrefPreprocessingUrlSourceInfo[];
}

/**
 * Information about where the url comes from.
 */
export interface RepositoryWebrefPreprocessingUrlSourceInfo {
  deprecatedOldSchema?: RepositoryWebrefPreprocessingUrlSourceInfoOldSchema;
  newSchema?: RepositoryWebrefPreprocessingUrlSourceInfoNewSchema;
  originalUrl?: string;
  source?:  | "DEPRECATED_OLD_SCHEMA" | "KG" | "KG_TRUSTED" | "WIKIJOIN" | "PRODUCT_OFFER" | "OYSTER_FEATURE" | "EXTRACTED_REFPAGE" | "EXPERIMENT" | "SOURCE_PROTO" | "MINED_REFERENCE_PAGE" | "WEBREF_YEAR" | "BOOK_REF_PAGES_MINING_PIPELINE" | "LYRICS_REFERENCE_PAGE" | "KG_WEAK_DATA" | "RELATED_PAGE" | "MINED_RELATED_PAGE" | "KG_SOCIAL_PROFILE";
}

/**
 * Source information for the new reference url Freebase schema.
 */
export interface RepositoryWebrefPreprocessingUrlSourceInfoNewSchema {
  sourceProperty?: string;
}

/**
 * Source information for the old reference url Freebase schema.
 */
export interface RepositoryWebrefPreprocessingUrlSourceInfoOldSchema {
  isOfficial?: boolean;
}

/**
 * A single processor counter stored as a pair of the counter name and the
 * value.
 */
export interface RepositoryWebrefProcessorCounter {
  name?: string;
  value?: number;
}

/**
 * Processor timings as produced by NestedPerfCounter, see
 * google3/repository/webref/base/nested-perf-counter.h.
 */
export interface RepositoryWebrefProcessorTiming {
  /**
   * Cpu instructions spent.
   */
  cpuInstructions?: bigint;
  /**
   * A string identifying the processor timing context.
   */
  name?: string;
  /**
   * Document counters defined by processors. A processor can add and increment
   * counters with NestedPerfCounter::IncrementCounterBy. See
   * go/webref-annotator-metrics.
   */
  processorCounters?: RepositoryWebrefProcessorCounter[];
  /**
   * Nested measurements, see NestedPerfCounter::ScopedPerfCounter.
   */
  processorTimings?: RepositoryWebrefProcessorTiming[];
  /**
   * Wall time (in nanoseconds).
   */
  wallTimeNs?: bigint;
}

function serializeRepositoryWebrefProcessorTiming(data: any): RepositoryWebrefProcessorTiming {
  return {
    ...data,
    cpuInstructions: data["cpuInstructions"] !== undefined ? String(data["cpuInstructions"]) : undefined,
    processorTimings: data["processorTimings"] !== undefined ? data["processorTimings"].map((item: any) => (serializeRepositoryWebrefProcessorTiming(item))) : undefined,
    wallTimeNs: data["wallTimeNs"] !== undefined ? String(data["wallTimeNs"]) : undefined,
  };
}

function deserializeRepositoryWebrefProcessorTiming(data: any): RepositoryWebrefProcessorTiming {
  return {
    ...data,
    cpuInstructions: data["cpuInstructions"] !== undefined ? BigInt(data["cpuInstructions"]) : undefined,
    processorTimings: data["processorTimings"] !== undefined ? data["processorTimings"].map((item: any) => (deserializeRepositoryWebrefProcessorTiming(item))) : undefined,
    wallTimeNs: data["wallTimeNs"] !== undefined ? BigInt(data["wallTimeNs"]) : undefined,
  };
}

/**
 * Products-specific information about the entity. Next available tag: 16.
 */
export interface RepositoryWebrefProductMetadata {
  /**
   * Shopping product line ids (typically moka product line tag) of this
   * entity. Represents shopping product lines, such as iPhone or Canon EOS.
   * Typically, we expect only one id. But keeping repeated, in case we want to
   * merge or aggregate product lines. Using int64, as tag_id in
   * commerce/datastore/processors/moka/proto/moka_annotations.proto.
   */
  productLineId?: bigint[];
  /**
   * All ShoppingIds for this MID that need to be copied to IntentQuery
   * (FunctionCall) if this MID is used in intent generation. See
   * go/iql-shopping-ids for details.
   */
  shoppingIds?: KnowledgeAnswersIntentQueryShoppingIds;
  type?:  | "CATALOG_ENTRY" | "VARIANT_CLUSTER" | "OTHER" | "PRODUCT_LINE" | "BRAND" | "CATEGORY" | "NOT_PRODUCT";
  /**
   * All unique variant cluster ids (shopping's GPCs) of this entity.
   */
  variantClusterId?: bigint[];
}

function serializeRepositoryWebrefProductMetadata(data: any): RepositoryWebrefProductMetadata {
  return {
    ...data,
    productLineId: data["productLineId"] !== undefined ? data["productLineId"].map((item: any) => (String(item))) : undefined,
    shoppingIds: data["shoppingIds"] !== undefined ? serializeKnowledgeAnswersIntentQueryShoppingIds(data["shoppingIds"]) : undefined,
    variantClusterId: data["variantClusterId"] !== undefined ? data["variantClusterId"].map((item: any) => (String(item))) : undefined,
  };
}

function deserializeRepositoryWebrefProductMetadata(data: any): RepositoryWebrefProductMetadata {
  return {
    ...data,
    productLineId: data["productLineId"] !== undefined ? data["productLineId"].map((item: any) => (BigInt(item))) : undefined,
    shoppingIds: data["shoppingIds"] !== undefined ? deserializeKnowledgeAnswersIntentQueryShoppingIds(data["shoppingIds"]) : undefined,
    variantClusterId: data["variantClusterId"] !== undefined ? data["variantClusterId"].map((item: any) => (BigInt(item))) : undefined,
  };
}

/**
 * Identifies a set of NavBoost queries in the CompositeDoc. Typically these
 * queries were collapsed by WebRef into a single query and they were treated by
 * the annotator as equivalent. They all contain the same mentions (at the same
 * offsets).
 */
export interface RepositoryWebrefQueryIndices {
  /**
   * The set of indices in the NavBoostQuery::features() array that belong to
   * the collapsed features.
   */
  featuresIndex?: number[];
  /**
   * The index of the query in NavBoostDocument::queries() array.
   */
  queriesIndex?: number;
}

/**
 * The fields hold "non-entity" annotations of text.
 */
export interface RepositoryWebrefRangeAnnotations {
  /**
   * The actual mentions. Note SegmentMentions contains some fields specific to
   * entity annotation, and those are typically not populated here.
   */
  segmentMentions?: RepositoryWebrefSegmentMentions[];
  /**
   * The type of ranges contained in this message.
   */
  type?:  | "STOPWORDS" | "SHOPPING_STOPWORDS";
}

function serializeRepositoryWebrefRangeAnnotations(data: any): RepositoryWebrefRangeAnnotations {
  return {
    ...data,
    segmentMentions: data["segmentMentions"] !== undefined ? data["segmentMentions"].map((item: any) => (serializeRepositoryWebrefSegmentMentions(item))) : undefined,
  };
}

function deserializeRepositoryWebrefRangeAnnotations(data: any): RepositoryWebrefRangeAnnotations {
  return {
    ...data,
    segmentMentions: data["segmentMentions"] !== undefined ? data["segmentMentions"].map((item: any) => (deserializeRepositoryWebrefSegmentMentions(item))) : undefined,
  };
}

/**
 * Metadata keeper for an annotated range of a segment. Next available tag: 3.
 */
export interface RepositoryWebrefRangeMetadata {
  /**
   * Start index of range (within the segment) being annotated.
   */
  beginOffset?: number;
  /**
   * Number of tokens in the range being annotated.
   */
  tokenCount?: number;
}

/**
 * Encapsulates the textual mention spans extracted from a document, split per
 * token.
 */
export interface RepositoryWebrefRefconDocumentMentionSpans {
  /**
   * Per token mention spans.
   */
  mentionSpan?: RepositoryWebrefRefconMentionSpans[];
}

function serializeRepositoryWebrefRefconDocumentMentionSpans(data: any): RepositoryWebrefRefconDocumentMentionSpans {
  return {
    ...data,
    mentionSpan: data["mentionSpan"] !== undefined ? data["mentionSpan"].map((item: any) => (serializeRepositoryWebrefRefconMentionSpans(item))) : undefined,
  };
}

function deserializeRepositoryWebrefRefconDocumentMentionSpans(data: any): RepositoryWebrefRefconDocumentMentionSpans {
  return {
    ...data,
    mentionSpan: data["mentionSpan"] !== undefined ? data["mentionSpan"].map((item: any) => (deserializeRepositoryWebrefRefconMentionSpans(item))) : undefined,
  };
}

/**
 * Describes a mention annotated by Webref in the given document.
 */
export interface RepositoryWebrefRefconMentionSpans {
  /**
   * Segment types in which the mention appears. Now deprecated, because we
   * only care about CONTENT segments.
   */
  segment?:  | "CONTENT" | "ANCHOR" | "QUERY" | "URL" | "TITLE" | "IMAGE_QUERY" | "CONTEXT_ENTITY" | "CONTEXT_QUERY" | "SPORE_GRAPH" | "META_CONTENT_TAG" | "IMG_ALT_TAG" | "INSTANT_QUERY" | "VIDEO_TRANSCRIPT" | "VIDEO_OCR" | "IMAGE_OCR" | "LENS"[];
  /**
   * Fingerprinted tokens which form the mention span. We are using 32-bit
   * instead of usual 64bit fingerprints - this greatly reduces the memory
   * footprint while still keeping the chance of collision reasonably low for
   * our specific use case (1 in 4 billion).
   */
  shortToken?: number[];
  /**
   * Fingerprinted tokens which form the mention span.
   */
  token?: bigint[];
}

function serializeRepositoryWebrefRefconMentionSpans(data: any): RepositoryWebrefRefconMentionSpans {
  return {
    ...data,
    token: data["token"] !== undefined ? data["token"].map((item: any) => (String(item))) : undefined,
  };
}

function deserializeRepositoryWebrefRefconMentionSpans(data: any): RepositoryWebrefRefconMentionSpans {
  return {
    ...data,
    token: data["token"] !== undefined ? data["token"].map((item: any) => (BigInt(item))) : undefined,
  };
}

/**
 * Contains high level search query statistics of the document.
 */
export interface RepositoryWebrefRefconQueryStats {
  /**
   * Total query count for the document from all the query terms. Can be used
   * to estimate the popularity of the document.
   */
  aggregatedQueryCount?: number;
}

/**
 * Encapsulates additional CDoc metadata needed by Refcon.
 */
export interface RepositoryWebrefRefconRefconDocumentMetadata {
  queryStats?: RepositoryWebrefRefconQueryStats;
}

/**
 * Refcon name representation in split concepts sstable. This is a simplified
 * version of repository_webref.GlobalNameInfo.
 */
export interface RepositoryWebrefRefconRefconNameInfo {
  confidence?: number;
  idfScore?: number;
  isGeneratedName?: boolean;
  isI18nName?: boolean;
  isStrongIdentifier?: boolean;
  isTranslatedName?: boolean;
  /**
   * Languages of the name, unknown language is not kept. TODO(b/145976266)
   * Don't use the deprecated language enum.
   */
  language?: number[];
  /**
   * Name prior to use. We read this from the prior for the "unknown" language.
   */
  namePrior?: number;
  /**
   * The normalized name.
   */
  normalizedName?: string;
  /**
   * Filled only if different than normalized_name.
   */
  originalName?: string;
  score?: number;
}

/**
 * Signals used for mining new reference pages, set by the
 * reference-page-scorer processor.
 */
export interface RepositoryWebrefReferencePageScores {
  /**
   * Stores score for later offline voting to choose reference pages. If zero,
   * it's not a good book reference page.
   */
  bookScore?: number;
  /**
   * The raw topicality score of the primary entity.
   */
  firstScore?: number;
  /**
   * Whether the primary entity has any "special" links. Currently a link is
   * considered special if it has a good implication probability and has no
   * negative disambiguation probability.
   */
  hasSpecialLinks?: boolean;
  /**
   * The median mentions core of the primary entity.
   */
  medianMentionScore?: number;
  /**
   * The navboost token coverage ratio. All queries are taken into account.
   */
  navboostCoverage?: number;
  /**
   * Reference page score used to select the reference page owner.
   */
  referencePageScore?: number;
  /**
   * True if the entity is selected as the reference page owner.
   */
  selected?: boolean;
  /**
   * A score in [0, 1] which indicates the single topicness of the entity.
   */
  singleTopicness?: number;
  /**
   * This should have the same semantic as single_topicness, and should replace
   * it in the long term.
   */
  singleTopicnessV2?: number;
  /**
   * =================================== Signals for the single topicness. Only
   * filled in for the primary (i.e., top ranked) entity. The title token
   * coverage ratio.
   */
  titleCoverage?: number;
  /**
   * The sum of raw topicality scores for all entities in this page.
   */
  totalSum?: number;
}

/**
 * A single Mention within a segment as defined by SegmentMentions.SegmentType
 */
export interface RepositoryWebrefSegmentMention {
  mention?: RepositoryWebrefMention;
  segmentType?:  | "CONTENT" | "ANCHOR" | "QUERY" | "URL" | "TITLE" | "IMAGE_QUERY" | "CONTEXT_ENTITY" | "CONTEXT_QUERY" | "SPORE_GRAPH" | "META_CONTENT_TAG" | "IMG_ALT_TAG" | "INSTANT_QUERY" | "VIDEO_TRANSCRIPT" | "VIDEO_OCR" | "IMAGE_OCR" | "LENS";
}

function serializeRepositoryWebrefSegmentMention(data: any): RepositoryWebrefSegmentMention {
  return {
    ...data,
    mention: data["mention"] !== undefined ? serializeRepositoryWebrefMention(data["mention"]) : undefined,
  };
}

function deserializeRepositoryWebrefSegmentMention(data: any): RepositoryWebrefSegmentMention {
  return {
    ...data,
    mention: data["mention"] !== undefined ? deserializeRepositoryWebrefMention(data["mention"]) : undefined,
  };
}

/**
 * Annotations of a single docjoin segment. A CDoc has several distinct data
 * types which we call "segments" (see SegmentType for complete list).
 * SegmentMentions contains all the mentions for a given (document, segment)
 * pair. For queries there is only a single CONTENT segment.
 */
export interface RepositoryWebrefSegmentMentions {
  /**
   * A list of all the places the entity in question was annotated within this
   * segment. The (indexing.annotations.goldmine) option is for Goldmine
   * AnnotationsFinder to include Mention only when segment_type="CONTENT"
   */
  mention?: RepositoryWebrefMention[];
  segmentType?:  | "CONTENT" | "ANCHOR" | "QUERY" | "URL" | "TITLE" | "IMAGE_QUERY" | "CONTEXT_ENTITY" | "CONTEXT_QUERY" | "SPORE_GRAPH" | "META_CONTENT_TAG" | "IMG_ALT_TAG" | "INSTANT_QUERY" | "VIDEO_TRANSCRIPT" | "VIDEO_OCR" | "IMAGE_OCR" | "LENS";
}

function serializeRepositoryWebrefSegmentMentions(data: any): RepositoryWebrefSegmentMentions {
  return {
    ...data,
    mention: data["mention"] !== undefined ? data["mention"].map((item: any) => (serializeRepositoryWebrefMention(item))) : undefined,
  };
}

function deserializeRepositoryWebrefSegmentMentions(data: any): RepositoryWebrefSegmentMentions {
  return {
    ...data,
    mention: data["mention"] !== undefined ? data["mention"].map((item: any) => (deserializeRepositoryWebrefMention(item))) : undefined,
  };
}

/**
 * A date range for an entity. E.g. lifespan of a person, release date of a
 * movie, ...
 */
export interface RepositoryWebrefSemanticDateRange {
  /**
   * Indicates how confident we are this extracted range is relevant to a
   * document (document to be infered from context).
   */
  confidence?: number;
  /**
   * End date extracted from the entity along end_source_property.
   */
  end?: string;
  /**
   * KG-property that links the entity to the end date.
   */
  endSourceProperty?: string;
  /**
   * Entity from which this range was extracted.
   */
  sourceEntityMid?: string;
  /**
   * Start date extracted from the entity along start_source_property.
   */
  start?: string;
  /**
   * KG-property that links the entity to the start date.
   */
  startSourceProperty?: string;
}

/**
 * Represents a subpart of the anchor data of the docjoins, but is much
 * smaller. When we build this SimplifiedAnchor from the anchor data of the
 * docjoins, by specifying the option separate_onsite_anchors to
 * SimplifiedAnchorsBuilder, we can also separate the onsite anchors from the
 * other (offdomain) anchors. So onsite anchors and offdomain anchors will have
 * their own count, score, normalized score, and total volume (.._offdomain and
 * .._onsite fields). For example, if there are 10 onsite anchors and 20
 * offdomain anchors for the anchor text "mountain view", then the
 * count_from_onsite is 10, and the count_from_offdomain is 20 when we separate
 * onsite anchors out. Otherwise (if we don't separate onsite anchors), the
 * count is 30 (10 + 20) and we don't have values in the .._offdomain and
 * .._onsite fields.
 */
export interface RepositoryWebrefSimplifiedAnchor {
  /**
   * The set of (equivalent from WebRef point of view) anchors used to produce
   * this segment.
   */
  anchorIndices?: RepositoryWebrefAnchorIndices;
  /**
   * The anchor text. Note that the normalized text is not populated.
   */
  anchorText?: RepositoryWebrefLocalizedString;
  /**
   * The number of times we see this anchor text.
   */
  count?: bigint;
  /**
   * Count, score, normalized score, and volume of offdomain anchors.
   */
  countFromOffdomain?: bigint;
  /**
   * Count, score, normalized score, and volume of onsite anchors.
   */
  countFromOnsite?: bigint;
  /**
   * The normalized score, which is computed from the score and the
   * total_volume.
   */
  normalizedScore?: number;
  normalizedScoreFromOffdomain?: number;
  normalizedScoreFromOnsite?: number;
  /**
   * The sum/aggregate of the anchor scores that have the same text.
   */
  score?: number;
  /**
   * The sum/aggregate of the anchor scores that direct to a fragment and have
   * the same text.
   */
  scoreFromFragment?: number;
  scoreFromOffdomain?: number;
  scoreFromOffdomainFragment?: number;
  scoreFromOnsite?: number;
  scoreFromOnsiteFragment?: number;
  /**
   * The sum/aggregate of the anchor scores that direct to a different wiki
   * title and have the same text. NOTE: url direct to a fragment score is not
   * included in this value.
   */
  scoreFromRedirect?: number;
  /**
   * The total score volume used for normalization.
   */
  totalVolume?: number;
  totalVolumeFromOffdomain?: number;
  totalVolumeFromOnsite?: number;
}

function serializeRepositoryWebrefSimplifiedAnchor(data: any): RepositoryWebrefSimplifiedAnchor {
  return {
    ...data,
    count: data["count"] !== undefined ? String(data["count"]) : undefined,
    countFromOffdomain: data["countFromOffdomain"] !== undefined ? String(data["countFromOffdomain"]) : undefined,
    countFromOnsite: data["countFromOnsite"] !== undefined ? String(data["countFromOnsite"]) : undefined,
  };
}

function deserializeRepositoryWebrefSimplifiedAnchor(data: any): RepositoryWebrefSimplifiedAnchor {
  return {
    ...data,
    count: data["count"] !== undefined ? BigInt(data["count"]) : undefined,
    countFromOffdomain: data["countFromOffdomain"] !== undefined ? BigInt(data["countFromOffdomain"]) : undefined,
    countFromOnsite: data["countFromOnsite"] !== undefined ? BigInt(data["countFromOnsite"]) : undefined,
  };
}

export interface RepositoryWebrefSimplifiedAnchors {
  anchor?: RepositoryWebrefSimplifiedAnchor[];
}

function serializeRepositoryWebrefSimplifiedAnchors(data: any): RepositoryWebrefSimplifiedAnchors {
  return {
    ...data,
    anchor: data["anchor"] !== undefined ? data["anchor"].map((item: any) => (serializeRepositoryWebrefSimplifiedAnchor(item))) : undefined,
  };
}

function deserializeRepositoryWebrefSimplifiedAnchors(data: any): RepositoryWebrefSimplifiedAnchors {
  return {
    ...data,
    anchor: data["anchor"] !== undefined ? data["anchor"].map((item: any) => (deserializeRepositoryWebrefSimplifiedAnchor(item))) : undefined,
  };
}

/**
 * Represents an information which is very close to composite doc, but
 * compresses how the anchors are represented to save space. Next available tag:
 * 15.
 */
export interface RepositoryWebrefSimplifiedCompositeDoc {
  /**
   * The composite doc anchors trimmed and transformed in a smaller data
   * structure and aggregated (if they have the exact same text).
   */
  anchors?: RepositoryWebrefSimplifiedAnchors;
  /**
   * IMPORTANT: do not access this field directly, use the
   * simplified-cdoc-access library functions to get the composite doc out of
   * this proto.
   */
  cdocContainer?: Proto2BridgeMessageSet;
  /**
   * The composite doc spans which were annotated with entities by Webref.
   */
  documentMentionSpans?: RepositoryWebrefRefconDocumentMentionSpans;
  /**
   * Metadata related to why this doc was matched to its owning entity.
   */
  matchingMetadata?: RepositoryWebrefPreprocessingUrlMatchingMetadata;
  /**
   * Additional document metadata needed by Refcon.
   */
  refconDocumentMetadata?: RepositoryWebrefRefconRefconDocumentMetadata;
  sourceSnapshotType?:  | "BASE" | "DAILY" | "ALEXANDRIA_BASE_SNAPSHOTS" | "UNIFIED_ZEPPELIN" | "UNIFIED_ZEPPELIN_HIGH_QUALITY" | "UNIFIED_ZEPPELIN_MEDIUM_QUALITY" | "UNIFIED_ZEPPELIN_LOW_QUALITY" | "UNIFIED_LANDFILL" | "UZLQ_AND_UL" | "QUALITY_SWAP_BASE" | "QUALITY_SWAP_UNIFIED_ZEPPELIN" | "QUALITY_SWAP_UNIFIED_ZEPPELIN_HIGH_QUALITY" | "QUALITY_SWAP_UNIFIED_ZEPPELIN_MEDIUM_QUALITY" | "QUALITY_SWAP_UNIFIED_ZEPPELIN_LOW_QUALITY" | "ADWORDS_BASE";
  /**
   * The URL, populated independently of whether we have a CompositeDoc proto.
   * If the cdoc exists, the url is the same as CompositeDoc.doc.url.
   */
  url?: string;
  webrefOutlinks?: Proto2BridgeMessageSet;
}

function serializeRepositoryWebrefSimplifiedCompositeDoc(data: any): RepositoryWebrefSimplifiedCompositeDoc {
  return {
    ...data,
    anchors: data["anchors"] !== undefined ? serializeRepositoryWebrefSimplifiedAnchors(data["anchors"]) : undefined,
    documentMentionSpans: data["documentMentionSpans"] !== undefined ? serializeRepositoryWebrefRefconDocumentMentionSpans(data["documentMentionSpans"]) : undefined,
  };
}

function deserializeRepositoryWebrefSimplifiedCompositeDoc(data: any): RepositoryWebrefSimplifiedCompositeDoc {
  return {
    ...data,
    anchors: data["anchors"] !== undefined ? deserializeRepositoryWebrefSimplifiedAnchors(data["anchors"]) : undefined,
    documentMentionSpans: data["documentMentionSpans"] !== undefined ? deserializeRepositoryWebrefRefconDocumentMentionSpans(data["documentMentionSpans"]) : undefined,
  };
}

/**
 * LINT.IfChange Some document segments may consist of multiple sub-segments
 * (e.g. a document might have multiple anchors or navboost queries).
 * SubSegmentIndex contains all information needed to identify the sub-segment
 * (e.g. specific query, query feature or or anchor) where the mention is
 * located.
 */
export interface RepositoryWebrefSubSegmentIndex {
  /**
   * Pointer to the exact set of anchors in the cdoc.
   */
  anchorIndex?: RepositoryWebrefAnchorIndices;
  /**
   * Pointer to the Webref-internal Segment indices. Can't be mapped back to
   * the CDoc.
   */
  genericIndex?: RepositoryWebrefGenericIndices;
  /**
   * Pointer to the exact set of image navboost queries in the cdoc.
   */
  imageQueryIndex?: RepositoryWebrefImageQueryIndices;
  /**
   * Pointer to the proto in the cdoc and index within the proto for Spore.
   */
  jgnIndex?: RepositoryWebrefJuggernautIndices;
  /**
   * Pointer to the exact set of queries in the cdoc.
   */
  queryIndex?: RepositoryWebrefQueryIndices;
}

function serializeRepositoryWebrefSubSegmentIndex(data: any): RepositoryWebrefSubSegmentIndex {
  return {
    ...data,
    imageQueryIndex: data["imageQueryIndex"] !== undefined ? serializeRepositoryWebrefImageQueryIndices(data["imageQueryIndex"]) : undefined,
  };
}

function deserializeRepositoryWebrefSubSegmentIndex(data: any): RepositoryWebrefSubSegmentIndex {
  return {
    ...data,
    imageQueryIndex: data["imageQueryIndex"] !== undefined ? deserializeRepositoryWebrefImageQueryIndices(data["imageQueryIndex"]) : undefined,
  };
}

/**
 * Each SupportTransferRule proto represents a single STBR (go/stbr) rule.
 * These rules are attached to entities (called STBR sources). Each rule
 * attached to an STBR source talks about a single entity (called STBR target).
 * If an STBR source gets annotated, its attached rules result in creation of
 * annotations for corresponding STBR targets. An STBR source might have more
 * than one STBR rule attached to it. STBR rules allow us to address cases where
 * otherwise annotations for what people say do not match what people mean. For
 * example, a query [france vs spain] uses names of countries while in sports
 * context the query would actually be about national sports teams of those
 * countries. In other words, STBR rules have meaning of "in this particular
 * context (see domain + target_collection fields below) a mention of this
 * particular STBR source (the entity this rule is attached to) actually should
 * be treated as that STBR target (see the target field below)". To describe the
 * meaning of STBR settings (proto fields below), we are going to use a
 * hypothetical example of an STBR rule making Search stack treat annotations
 * for /m/France as annotations for /m/Louis_XIV, since he was the one saying "I
 * am the state". In this example /m/France is going to be the STBR source.
 * NOTICE: When adding new fields also update
 * client::support_transfer::SortDeterministically to ensure deterministic
 * sorting of the SupportTransferRule objects. Next available tag: 11.
 * LINT.IfChange
 */
export interface RepositoryWebrefSupportTransferRule {
  /**
   * If set to true, allow STBR targets to trigger intents like ShowEntity that
   * do not have explicit lists of allowed collections, accepting entities with
   * any collections instead. This setting together with target_collection
   * define what intents are allowed to be triggered by the STBR target. Be
   * careful with setting this option to 'true', as in the case of our example
   * the query [france] would result in the knowledge panel for the monarch.
   * Louis XIV might've wanted such a behaviour, but you are probably not him.
   */
  allowWildcardIntents?: boolean;
  /**
   * Name of Aqua grammar domain this STBR rule is restricted to. If the domain
   * is set to anything other than "default", the STBR rule is only going to
   * result in an annotation for the STBR target inside of the Aqua domain of
   * the corresponding name. If there is no such Aqua domain, the rule is going
   * to be ignored. The default value of string "default" for domain makes it
   * possible for the STBR rule to be used inside Loose Parser.
   */
  domain?: string;
  /**
   * Whether this rule points from an STBR target to its STBR source. This
   * field is an internal implementation detail that is not configurable by
   * customers. Inside QRewrite we have to keep track of relations between
   * entities. Among other things it is useful to remember which STBR target a
   * given STBR source came from. For that purpose we attach an STBR proto to
   * the STBR target, reversing the rule, i.e, putting STBR source's mid as the
   * target etc. For this reversed rule we set is_reverse_link to true.
   */
  isReverseLink?: boolean;
  /**
   * STBR doesn't just create annotations for STBR targets. It also can modify
   * search result support (useful in PostRef) in order for web pages supporting
   * the STBR source to also support the STBR target. Otherwise in PostRef
   * annotations for STBR targets are going to be demoted, resulting in the STBR
   * rule potentially not affecting anything. Regarding treatment of this result
   * support, STBR has 3 possible modes that for historical reasons are
   * represented as 2 booleans - mentions_only and support_share. No more than
   * one of these bools is supposed to be set to 'true' for a rule. Setting both
   * to 'true' at once would lead to undefined behaviour. These 3 modes are: 1.
   * (default) All the support gets assigned to the STBR target. The STBR source
   * is left with no support. To be extra sure, interpretations that still
   * managed to get triggered by STBR source are suppressed later unless STBR
   * target has no interpretations of its own. In other words this is "we are
   * pretty sure that if France is mentioned in a query that might be talking
   * about a person, we want to treat the query as if it is about Louis XIV".
   * This mode would result in a query [age of france] being treated as [age of
   * louis xiv], while [population of france] still being about the country
   * unless [population of louis xiv] matches some intents. For this mode both
   * mentions_only and support_share should be set to 'false'. 2. Support is
   * shared between STBR source ans STBR target. That allows both STBR source
   * and STBR target to trigger some intents with KScorer later deciding which
   * intent is better. In other words, this is "when it is not clear whether a
   * query is about France of Louis XIV, provide KScorer with both options and
   * let it decide". For this mode mentions_only should be set to 'false' and
   * support_share should be set to 'true'. 3. While annotations for the STBR
   * target are created, no support is given to those annotations. This is more
   * like "we are mostly sure that a mention of France is about the country, but
   * just for a rare case it is about the monarch, we would like to have Louis
   * XIV annotated". For this mode mentions_only should be set to 'true' and
   * support_share should be set to 'false'.
   */
  mentionsOnly?: boolean;
  supportShare?: boolean;
  /**
   * Mid of the STBR target, e.g. "/m/04pwg" for Louis XIV.
   */
  target?: string;
  /**
   * Collection that is going to be assigned to the target when the annotation
   * for the target is created. This setting together with
   * allow_wildcard_intents define what intents are allowed to be triggered by
   * the STBR target. At the moment those annotations get created, we can not
   * afford to fetch information about the STBR target from Topic Server, but
   * the target mid by itself doesn't mean much for the Search stack. Setting up
   * the collection for that annotated mid allows us to provide at least some
   * information to the stack on how to treat the mid. This collection together
   * with domain and allow_wildcard_intents fields (see below) defines what
   * intents can be triggered by annotations created for this STBR target.
   * Intents that accept only entities of specific collections can only be
   * triggered if the value of this field matches one of the allowed collections
   * for that intent. In our example, KGCollection.debug_id might be
   * "/collection/people" if we care about context of the monarch as a person,
   * e.g. if we would like to understand queries like [how many children does
   * france have] as [how many childred does lous xiv have]. Or, if we would
   * like to be more restrictive and to only apply the rule to contexts that
   * only make sense for monarch, e.g. [how long did france reign], we might
   * decide to use more specific "/collection/monarchs" instead.
   */
  targetCollection?: RepositoryWebrefKGCollection;
  /**
   * The user country this rule is for. Rules only take effect if the country
   * is not set, set to an empty string or matches the country that is detected
   * for the user - like the country user issued the query from. E.g. "US" for
   * the United States.
   */
  userCountry?: string;
  /**
   * User language this rule is for. Rules only take effect if the language is
   * not set, set to an empty string or matches the language that is detected
   * for the user's query. E.g. set it to "en" if you want the STBR rule to only
   * work for users working from computers with English being set as the main
   * language. Keep it unset if you want the rule not to depend on local
   * language settings of user's computer.
   */
  userLanguage?: string;
}

export interface RepositoryWebrefTaskData {
  /**
   * Signals about quality of data that was shown to raters. If document/query
   * and concept description are readable.
   */
  isReadable?: boolean;
  itemId?: bigint;
  projectId?: bigint;
  taskDetails?: RepositoryWebrefTaskDetails;
  taskId?: bigint;
}

function serializeRepositoryWebrefTaskData(data: any): RepositoryWebrefTaskData {
  return {
    ...data,
    itemId: data["itemId"] !== undefined ? String(data["itemId"]) : undefined,
    projectId: data["projectId"] !== undefined ? String(data["projectId"]) : undefined,
    taskDetails: data["taskDetails"] !== undefined ? serializeRepositoryWebrefTaskDetails(data["taskDetails"]) : undefined,
    taskId: data["taskId"] !== undefined ? String(data["taskId"]) : undefined,
  };
}

function deserializeRepositoryWebrefTaskData(data: any): RepositoryWebrefTaskData {
  return {
    ...data,
    itemId: data["itemId"] !== undefined ? BigInt(data["itemId"]) : undefined,
    projectId: data["projectId"] !== undefined ? BigInt(data["projectId"]) : undefined,
    taskDetails: data["taskDetails"] !== undefined ? deserializeRepositoryWebrefTaskDetails(data["taskDetails"]) : undefined,
    taskId: data["taskId"] !== undefined ? BigInt(data["taskId"]) : undefined,
  };
}

/**
 * Information about what the raters saw, how the information was presented to
 * them, or how they interacted with the task. Next id: 6
 */
export interface RepositoryWebrefTaskDetails {
  /**
   * The id of the experiment in case we are dealing with a refx data
   * experiment. Should only be set in case of data experiments to gather
   * topicality ratings, in order to allow separating these ratings from regular
   * ratings.
   */
  experimentId?: string;
  lastSubmitTimestamp?: bigint;
  topicDescription?: string;
  topicName?: string;
  topicUrl?: string;
}

function serializeRepositoryWebrefTaskDetails(data: any): RepositoryWebrefTaskDetails {
  return {
    ...data,
    lastSubmitTimestamp: data["lastSubmitTimestamp"] !== undefined ? String(data["lastSubmitTimestamp"]) : undefined,
  };
}

function deserializeRepositoryWebrefTaskDetails(data: any): RepositoryWebrefTaskDetails {
  return {
    ...data,
    lastSubmitTimestamp: data["lastSubmitTimestamp"] !== undefined ? BigInt(data["lastSubmitTimestamp"]) : undefined,
  };
}

export interface RepositoryWebrefTripleAnnotation {
  /**
   * Triple annotation confidence_score (value between 0 and 1). Higher values
   * correspond to higher confidence.
   */
  confidenceScore?: number;
  /**
   * The information in this triple is implied by other triple(s) in the
   * document.
   */
  isImplied?: boolean;
  /**
   * Set to true if this triple is present in the webref model as either a link
   * or property value. This implies that the information is in the Knowledge
   * Graph. Note that it can happen that a triple is in KG but not present in
   * the webref model.
   */
  kgVerified?: boolean;
  /**
   * Occurrences of the triple on the document
   */
  mentions?: RepositoryWebrefTripleMention[];
  /**
   * The mid of the predicate kg-property(-ies). In order, in the case of
   * multihop links.
   */
  predMid?: bigint[];
  /**
   * Generic container to hold additional data such as signals, debug data etc.
   * Data that can be stored in this field and their TypeIds:
   * repository_webref::evaluation::ECMDebug (TypeId 192627933), defined in
   * repository/webref/evaluation/triple_annotations/triple-diff.proto Debugging
   * data to be used in WebIt's ECM report.
   */
  stuff?: Proto2BridgeMessageSet;
  triple?: KnowledgeGraphTriple;
}

function serializeRepositoryWebrefTripleAnnotation(data: any): RepositoryWebrefTripleAnnotation {
  return {
    ...data,
    mentions: data["mentions"] !== undefined ? data["mentions"].map((item: any) => (serializeRepositoryWebrefTripleMention(item))) : undefined,
    predMid: data["predMid"] !== undefined ? data["predMid"].map((item: any) => (String(item))) : undefined,
    triple: data["triple"] !== undefined ? serializeKnowledgeGraphTriple(data["triple"]) : undefined,
  };
}

function deserializeRepositoryWebrefTripleAnnotation(data: any): RepositoryWebrefTripleAnnotation {
  return {
    ...data,
    mentions: data["mentions"] !== undefined ? data["mentions"].map((item: any) => (deserializeRepositoryWebrefTripleMention(item))) : undefined,
    predMid: data["predMid"] !== undefined ? data["predMid"].map((item: any) => (BigInt(item))) : undefined,
    triple: data["triple"] !== undefined ? deserializeKnowledgeGraphTriple(data["triple"]) : undefined,
  };
}

/**
 * Represents a collection of triples annotated by Webref/Webit. Included in
 * WebrefEntities
 */
export interface RepositoryWebrefTripleAnnotations {
  annotations?: RepositoryWebrefTripleAnnotation[];
}

function serializeRepositoryWebrefTripleAnnotations(data: any): RepositoryWebrefTripleAnnotations {
  return {
    ...data,
    annotations: data["annotations"] !== undefined ? data["annotations"].map((item: any) => (serializeRepositoryWebrefTripleAnnotation(item))) : undefined,
  };
}

function deserializeRepositoryWebrefTripleAnnotations(data: any): RepositoryWebrefTripleAnnotations {
  return {
    ...data,
    annotations: data["annotations"] !== undefined ? data["annotations"].map((item: any) => (deserializeRepositoryWebrefTripleAnnotation(item))) : undefined,
  };
}

export interface RepositoryWebrefTripleMention {
  /**
   * Document mention of the predicate
   */
  predMention?: RepositoryWebrefSegmentMention;
  /**
   * The [begin, end) byte offset of the document scope where this triple was
   * annotated. This corresponds to a table row or a text sentence where the
   * triple was identified. The sub_mention can be outside the scope when the
   * subject is inferred from the table title.
   */
  scopeBegin?: number;
  scopeEnd?: number;
  /**
   * Fingerprint2011 of space-joined SAFT tokens in the scope.
   */
  scopeFprint?: bigint;
  /**
   * Generic container to hold additional data such as triple scoped signals.
   * Data that can be stored in this field and their TypeIds:
   * repository_webref::universal::webit::ScopeSignals (TypeId 192754198),
   * defined in repository/webref/universal/processors/understanding/webit.proto
   */
  stuff?: Proto2BridgeMessageSet;
  /**
   * Document mention of the subject
   */
  subMention?: RepositoryWebrefSegmentMention;
  /**
   * Document mention of the value
   */
  valueMention?: RepositoryWebrefSegmentMention;
}

function serializeRepositoryWebrefTripleMention(data: any): RepositoryWebrefTripleMention {
  return {
    ...data,
    predMention: data["predMention"] !== undefined ? serializeRepositoryWebrefSegmentMention(data["predMention"]) : undefined,
    scopeFprint: data["scopeFprint"] !== undefined ? String(data["scopeFprint"]) : undefined,
    subMention: data["subMention"] !== undefined ? serializeRepositoryWebrefSegmentMention(data["subMention"]) : undefined,
    valueMention: data["valueMention"] !== undefined ? serializeRepositoryWebrefSegmentMention(data["valueMention"]) : undefined,
  };
}

function deserializeRepositoryWebrefTripleMention(data: any): RepositoryWebrefTripleMention {
  return {
    ...data,
    predMention: data["predMention"] !== undefined ? deserializeRepositoryWebrefSegmentMention(data["predMention"]) : undefined,
    scopeFprint: data["scopeFprint"] !== undefined ? BigInt(data["scopeFprint"]) : undefined,
    subMention: data["subMention"] !== undefined ? deserializeRepositoryWebrefSegmentMention(data["subMention"]) : undefined,
    valueMention: data["valueMention"] !== undefined ? deserializeRepositoryWebrefSegmentMention(data["valueMention"]) : undefined,
  };
}

/**
 * This proto is filled with n-gram data during model building.
 */
export interface RepositoryWebrefUniversalNgramData {
  /**
   * IDF of the n-gram.
   */
  idf?: number;
  /**
   * Probability that the n-gram is a plural form of a word. This information
   * is extracted from SAFT annotations of queries. See HasPluralProperty().
   */
  pluralProb?: number;
}

/**
 * Detailed statistics about the annotations in the document. Contains, for
 * example, the number of ranges with name matches, the number of entities
 * matched, and the number of entities with mentions. This information can be
 * used to tune some WebRef-internal scoring functions based on existing
 * annotations (e.g., document-length normalization in global link support).
 * Next available tag: 10.
 */
export interface RepositoryWebrefWebrefAnnotationStats {
  /**
   * The relative weight of the document, used when aggregating information
   * from multiple documents.
   */
  docWeight?: number;
  /**
   * Extracted n-grams context scores (in cdoc language, weighted by
   * doc_weight) output if webref_populate_annotation_ngrams is enabled.
   */
  ngramContext?: RepositoryWebrefNgramContext[];
  /**
   * The total number of candidates.
   */
  numCandidates?: bigint;
  /**
   * The total number of concepts with at least 1 candidate.
   */
  numConceptsWithCandidates?: bigint;
  /**
   * The total number of concepts with at least 1 mention.
   */
  numConceptsWithMentions?: bigint;
  /**
   * The total number of RangeData objects with at least one candidate.
   */
  numRangesWithCandidates?: bigint;
  /**
   * Statistics for each token type.
   */
  statsPerType?: RepositoryWebrefAnnotationStatsPerType[];
}

function serializeRepositoryWebrefWebrefAnnotationStats(data: any): RepositoryWebrefWebrefAnnotationStats {
  return {
    ...data,
    numCandidates: data["numCandidates"] !== undefined ? String(data["numCandidates"]) : undefined,
    numConceptsWithCandidates: data["numConceptsWithCandidates"] !== undefined ? String(data["numConceptsWithCandidates"]) : undefined,
    numConceptsWithMentions: data["numConceptsWithMentions"] !== undefined ? String(data["numConceptsWithMentions"]) : undefined,
    numRangesWithCandidates: data["numRangesWithCandidates"] !== undefined ? String(data["numRangesWithCandidates"]) : undefined,
    statsPerType: data["statsPerType"] !== undefined ? data["statsPerType"].map((item: any) => (serializeRepositoryWebrefAnnotationStatsPerType(item))) : undefined,
  };
}

function deserializeRepositoryWebrefWebrefAnnotationStats(data: any): RepositoryWebrefWebrefAnnotationStats {
  return {
    ...data,
    numCandidates: data["numCandidates"] !== undefined ? BigInt(data["numCandidates"]) : undefined,
    numConceptsWithCandidates: data["numConceptsWithCandidates"] !== undefined ? BigInt(data["numConceptsWithCandidates"]) : undefined,
    numConceptsWithMentions: data["numConceptsWithMentions"] !== undefined ? BigInt(data["numConceptsWithMentions"]) : undefined,
    numRangesWithCandidates: data["numRangesWithCandidates"] !== undefined ? BigInt(data["numRangesWithCandidates"]) : undefined,
    statsPerType: data["statsPerType"] !== undefined ? data["statsPerType"].map((item: any) => (deserializeRepositoryWebrefAnnotationStatsPerType(item))) : undefined,
  };
}

/**
 * Annotation metadata for an individual entity.
 */
export interface RepositoryWebrefWebrefAttachmentMetadata {
  /**
   * Oyster Feature Type.
   */
  featureType?:  | "TYPE_ANY" | "TYPE_TRANSPORTATION" | "TYPE_ROUTE" | "TYPE_DEPRECATED_HIGHWAY_DO_NOT_USE" | "TYPE_HIGHWAY" | "TYPE_HIGHWAY_1" | "TYPE_HIGHWAY_2" | "TYPE_HIGHWAY_3" | "TYPE_HIGHWAY_4" | "TYPE_HIGHWAY_5" | "TYPE_HIGHWAY_6" | "TYPE_HIGHWAY_7" | "TYPE_HIGHWAY_8" | "TYPE_HIGHWAY_9" | "TYPE_BICYCLE_ROUTE" | "TYPE_TRAIL" | "TYPE_SEGMENT" | "TYPE_ROAD" | "TYPE_RAILWAY" | "TYPE_STANDARD_TRACK" | "TYPE_JR_TRACK" | "TYPE_NARROW_TRACK" | "TYPE_MONORAIL_TRACK" | "TYPE_SUBWAY_TRACK" | "TYPE_LIGHT_RAIL_TRACK" | "TYPE_BROAD_TRACK" | "TYPE_HIGH_SPEED_RAIL" | "TYPE_TROLLEY_TRACK" | "TYPE_FERRY" | "TYPE_FERRY_BOAT" | "TYPE_FERRY_TRAIN" | "TYPE_VIRTUAL_SEGMENT" | "TYPE_INTERSECTION" | "TYPE_TRANSIT" | "TYPE_TRANSIT_STATION" | "TYPE_BUS_STATION" | "TYPE_TRAMWAY_STATION" | "TYPE_TRAIN_STATION" | "TYPE_SUBWAY_STATION" | "TYPE_FERRY_TERMINAL" | "TYPE_AIRPORT" | "TYPE_AIRPORT_CIVIL" | "TYPE_AIRPORT_MILITARY" | "TYPE_AIRPORT_MIXED" | "TYPE_HELIPORT" | "TYPE_SEAPLANE_BASE" | "TYPE_AIRSTRIP" | "TYPE_CABLE_CAR_STATION" | "TYPE_GONDOLA_LIFT_STATION" | "TYPE_FUNICULAR_STATION" | "TYPE_SPECIAL_STATION" | "TYPE_HORSE_CARRIAGE_STATION" | "TYPE_MONORAIL_STATION" | "TYPE_SEAPORT" | "TYPE_TRANSIT_STOP" | "TYPE_TRANSIT_TRIP" | "TYPE_TRANSIT_DEPARTURE" | "TYPE_TRANSIT_LEG" | "TYPE_TRANSIT_LINE" | "TYPE_TRANSIT_AGENCY_DEPRECATED_VALUE" | "TYPE_TRANSIT_TRANSFER" | "TYPE_SEGMENT_PATH" | "TYPE_ROAD_SIGN" | "TYPE_INTERSECTION_GROUP" | "TYPE_PATHWAY" | "TYPE_RESTRICTION_GROUP" | "TYPE_TOLL_CLUSTER" | "TYPE_POLITICAL" | "TYPE_COUNTRY" | "TYPE_ADMINISTRATIVE_AREA" | "TYPE_ADMINISTRATIVE_AREA1" | "TYPE_US_STATE" | "TYPE_GB_COUNTRY" | "TYPE_JP_TODOUFUKEN" | "TYPE_ADMINISTRATIVE_AREA2" | "TYPE_GB_FORMER_POSTAL_COUNTY" | "TYPE_GB_TRADITIONAL_COUNTY" | "TYPE_ADMINISTRATIVE_AREA3" | "TYPE_ADMINISTRATIVE_AREA4" | "TYPE_ADMINISTRATIVE_AREA5" | "TYPE_ADMINISTRATIVE_AREA6" | "TYPE_ADMINISTRATIVE_AREA7" | "TYPE_ADMINISTRATIVE_AREA8" | "TYPE_ADMINISTRATIVE_AREA9" | "TYPE_COLLOQUIAL_AREA" | "TYPE_RESERVATION" | "TYPE_LOCALITY" | "TYPE_GB_POST_TOWN" | "TYPE_JP_GUN" | "TYPE_JP_SHIKUCHOUSON" | "TYPE_JP_SUB_SHIKUCHOUSON" | "TYPE_COLLOQUIAL_CITY" | "TYPE_SUBLOCALITY" | "TYPE_US_BOROUGH" | "TYPE_GB_DEPENDENT_LOCALITY" | "TYPE_JP_OOAZA" | "TYPE_JP_KOAZA" | "TYPE_JP_GAIKU" | "TYPE_GB_DOUBLE_DEPENDENT_LOCALITY" | "TYPE_JP_CHIBAN" | "TYPE_JP_EDABAN" | "TYPE_SUBLOCALITY1" | "TYPE_SUBLOCALITY2" | "TYPE_SUBLOCALITY3" | "TYPE_SUBLOCALITY4" | "TYPE_SUBLOCALITY5" | "TYPE_NEIGHBORHOOD" | "TYPE_CONSTITUENCY" | "TYPE_DESIGNATED_MARKET_AREA" | "TYPE_SCHOOL_DISTRICT" | "TYPE_LAND_PARCEL" | "TYPE_DISPUTED_AREA" | "TYPE_POLICE_JURISDICTION" | "TYPE_STATISTICAL_AREA" | "TYPE_CONSTITUENCY_FUTURE" | "TYPE_PARK" | "TYPE_GOLF_COURSE" | "TYPE_LOCAL_PARK" | "TYPE_NATIONAL_PARK" | "TYPE_US_NATIONAL_PARK" | "TYPE_US_NATIONAL_MONUMENT" | "TYPE_NATIONAL_FOREST" | "TYPE_PROVINCIAL_PARK" | "TYPE_PROVINCIAL_FOREST" | "TYPE_CAMPGROUNDS" | "TYPE_HIKING_AREA" | "TYPE_BUSINESS" | "TYPE_GOVERNMENT" | "TYPE_BORDER_CROSSING" | "TYPE_CITY_HALL" | "TYPE_COURTHOUSE" | "TYPE_EMBASSY" | "TYPE_LIBRARY" | "TYPE_SCHOOL" | "TYPE_UNIVERSITY" | "TYPE_EMERGENCY" | "TYPE_HOSPITAL" | "TYPE_PHARMACY" | "TYPE_POLICE" | "TYPE_FIRE" | "TYPE_DOCTOR" | "TYPE_DENTIST" | "TYPE_VETERINARIAN" | "TYPE_TRAVEL_SERVICE" | "TYPE_LODGING" | "TYPE_RESTAURANT" | "TYPE_GAS_STATION" | "TYPE_PARKING" | "TYPE_POST_OFFICE" | "TYPE_REST_AREA" | "TYPE_CASH_MACHINE" | "TYPE_CAR_RENTAL" | "TYPE_CAR_REPAIR" | "TYPE_SHOPPING" | "TYPE_GROCERY" | "TYPE_TOURIST_DESTINATION" | "TYPE_ECO_TOURIST_DESTINATION" | "TYPE_BIRD_WATCHING" | "TYPE_FISHING" | "TYPE_HUNTING" | "TYPE_NATURE_RESERVE" | "TYPE_TEMPLE" | "TYPE_CHURCH" | "TYPE_GURUDWARA" | "TYPE_HINDU_TEMPLE" | "TYPE_MOSQUE" | "TYPE_SYNAGOGUE" | "TYPE_STADIUM" | "TYPE_BAR" | "TYPE_MOVIE_RENTAL" | "TYPE_COFFEE" | "TYPE_GOLF" | "TYPE_BANK" | "TYPE_DOODLE" | "TYPE_GROUNDS" | "TYPE_AIRPORT_GROUNDS" | "TYPE_BUILDING_GROUNDS" | "TYPE_CEMETERY" | "TYPE_HOSPITAL_GROUNDS" | "TYPE_INDUSTRIAL" | "TYPE_MILITARY" | "TYPE_SHOPPING_CENTER" | "TYPE_SPORTS_COMPLEX" | "TYPE_UNIVERSITY_GROUNDS" | "TYPE_DEPRECATED_TARMAC" | "TYPE_ENCLOSED_TRAFFIC_AREA" | "TYPE_PARKING_LOT" | "TYPE_PARKING_GARAGE" | "TYPE_OFF_ROAD_AREA" | "TYPE_BORDER" | "TYPE_BUILDING" | "TYPE_GEOCODED_ADDRESS" | "TYPE_NATURAL_FEATURE" | "TYPE_TERRAIN" | "TYPE_SAND" | "TYPE_BEACH" | "TYPE_DUNE" | "TYPE_ROCKY" | "TYPE_ICE" | "TYPE_GLACIER" | "TYPE_BUILT_UP_AREA" | "TYPE_VEGETATION" | "TYPE_SHRUBBERY" | "TYPE_WOODS" | "TYPE_AGRICULTURAL" | "TYPE_GRASSLAND" | "TYPE_TUNDRA" | "TYPE_DESERT" | "TYPE_SALT_FLAT" | "TYPE_WATER" | "TYPE_OCEAN" | "TYPE_BAY" | "TYPE_BIGHT" | "TYPE_LAGOON" | "TYPE_SEA" | "TYPE_STRAIT" | "TYPE_INLET" | "TYPE_FJORD" | "TYPE_LAKE" | "TYPE_SEASONAL_LAKE" | "TYPE_RESERVOIR" | "TYPE_POND" | "TYPE_RIVER" | "TYPE_RAPIDS" | "TYPE_DISTRIBUTARY" | "TYPE_CONFLUENCE" | "TYPE_WATERFALL" | "TYPE_SPRING" | "TYPE_GEYSER" | "TYPE_HOT_SPRING" | "TYPE_SEASONAL_RIVER" | "TYPE_WADI" | "TYPE_ESTUARY" | "TYPE_WETLAND" | "TYPE_WATER_NAVIGATION" | "TYPE_FORD" | "TYPE_CANAL" | "TYPE_HARBOR" | "TYPE_CHANNEL" | "TYPE_REEF" | "TYPE_REEF_FLAT" | "TYPE_REEF_GROWTH" | "TYPE_REEF_EXTENT" | "TYPE_REEF_ROCK_SUBMERGED" | "TYPE_IRRIGATION" | "TYPE_DAM" | "TYPE_DRINKING_WATER" | "TYPE_CURRENT" | "TYPE_WATERING_HOLE" | "TYPE_TECTONIC" | "TYPE_WATERING_HOLE_DEPRECATED" | "TYPE_VOLCANO" | "TYPE_LAVA_FIELD" | "TYPE_FISSURE" | "TYPE_FAULT" | "TYPE_LAND_MASS" | "TYPE_CONTINENT" | "TYPE_ISLAND" | "TYPE_ATOLL" | "TYPE_OCEAN_ROCK_EXPOSED" | "TYPE_CAY" | "TYPE_PENINSULA" | "TYPE_ISTHMUS" | "TYPE_ELEVATED" | "TYPE_PEAK" | "TYPE_NUNATAK" | "TYPE_SPUR" | "TYPE_PASS" | "TYPE_PLATEAU" | "TYPE_RIDGE" | "TYPE_RAVINE" | "TYPE_CRATER" | "TYPE_KARST" | "TYPE_CLIFF" | "TYPE_VISTA" | "TYPE_DIGITAL_ELEVATION_MODEL" | "TYPE_UPLAND" | "TYPE_TERRACE" | "TYPE_SLOPE" | "TYPE_CONTOUR_LINE" | "TYPE_PAN" | "TYPE_UNSTABLE_HILLSIDE" | "TYPE_MOUNTAIN_RANGE" | "TYPE_UNDERSEA" | "TYPE_SUBMARINE_SEAMOUNT" | "TYPE_SUBMARINE_RIDGE" | "TYPE_SUBMARINE_GAP" | "TYPE_SUBMARINE_PLATEAU" | "TYPE_SUBMARINE_DEEP" | "TYPE_SUBMARINE_VALLEY" | "TYPE_SUBMARINE_BASIN" | "TYPE_SUBMARINE_SLOPE" | "TYPE_SUBMARINE_CLIFF" | "TYPE_SUBMARINE_PLAIN" | "TYPE_SUBMARINE_FRACTURE_ZONE" | "TYPE_CAVE" | "TYPE_ROCK" | "TYPE_ARCHIPELAGO" | "TYPE_POSTAL" | "TYPE_POSTAL_CODE" | "TYPE_POSTAL_CODE_PREFIX" | "TYPE_PREMISE" | "TYPE_SUB_PREMISE" | "TYPE_SUITE" | "TYPE_POST_TOWN" | "TYPE_POSTAL_ROUND" | "TYPE_META_FEATURE" | "TYPE_DATA_SOURCE" | "TYPE_LOCALE" | "TYPE_TIMEZONE" | "TYPE_BUSINESS_CHAIN" | "TYPE_PHONE_NUMBER_PREFIX" | "TYPE_PHONE_NUMBER_AREA_CODE" | "TYPE_BUSINESS_CORRIDOR" | "TYPE_ADDRESS_TEMPLATE" | "TYPE_TRANSIT_AGENCY" | "TYPE_FUTURE_GEOMETRY" | "TYPE_EVENT" | "TYPE_EARTHQUAKE" | "TYPE_HURRICANE" | "TYPE_WEATHER_CONDITION" | "TYPE_TRANSIENT" | "TYPE_ENTRANCE" | "TYPE_CARTOGRAPHIC" | "TYPE_HIGH_TENSION" | "TYPE_SKI_TRAIL" | "TYPE_SKI_LIFT" | "TYPE_SKI_BOUNDARY" | "TYPE_WATERSHED_BOUNDARY" | "TYPE_TARMAC" | "TYPE_WALL" | "TYPE_PICNIC_AREA" | "TYPE_PLAY_GROUND" | "TYPE_TRAIL_HEAD" | "TYPE_GOLF_TEEING_GROUND" | "TYPE_GOLF_PUTTING_GREEN" | "TYPE_GOLF_ROUGH" | "TYPE_GOLF_SAND_BUNKER" | "TYPE_GOLF_FAIRWAY" | "TYPE_GOLF_HOLE" | "TYPE_DEPRECATED_GOLF_SHOP" | "TYPE_CAMPING_SITE" | "TYPE_DESIGNATED_BARBECUE_PIT" | "TYPE_DESIGNATED_COOKING_AREA" | "TYPE_CAMPFIRE_PIT" | "TYPE_WATER_FOUNTAIN" | "TYPE_LITTER_RECEPTACLE" | "TYPE_LOCKER_AREA" | "TYPE_ANIMAL_ENCLOSURE" | "TYPE_CARTOGRAPHIC_LINE" | "TYPE_ESTABLISHMENT" | "TYPE_ESTABLISHMENT_GROUNDS" | "TYPE_ESTABLISHMENT_BUILDING" | "TYPE_ESTABLISHMENT_POI" | "TYPE_ESTABLISHMENT_SERVICE" | "TYPE_CELESTIAL" | "TYPE_ROAD_MONITOR" | "TYPE_PUBLIC_SPACES_AND_MONUMENTS" | "TYPE_STATUE" | "TYPE_TOWN_SQUARE" | "TYPE_LEVEL" | "TYPE_COMPOUND" | "TYPE_COMPOUND_GROUNDS" | "TYPE_COMPOUND_BUILDING" | "TYPE_COMPOUND_SECTION" | "TYPE_TERMINAL_POINT" | "TYPE_REGULATED_AREA" | "TYPE_LOGICAL_BORDER" | "TYPE_DO_NOT_USE_RESERVED_TO_CATCH_GENERATED_FILES" | "TYPE_UNKNOWN";
  /**
   * Indicates which entity this message belongs to: encoded_mid[index].
   */
  index?: number;
  /**
   * Latitude and longitude of the location. Same format as
   * geostore.PointProto.
   */
  latE7?: number;
  lngE7?: number;
  /**
   * Oyster Feature ID of the location.
   */
  oysterId?: GeostoreFeatureIdProto;
  /**
   * This field is populated for at most one entity. If it is populated, it
   * indicates how confident we are to claim that the page is only about this
   * entity (either it's an official web presence of the entity, or something
   * like a wikipedia page about the entity). For space reasons this is
   * represented as a fixed-point integer with two decimal points precision.
   * Convert it to the interval [0,1] using the following formula: float
   * single_topicness = single_topicness_e2 / 100.f
   */
  singleTopicnessE2?: number;
}

function serializeRepositoryWebrefWebrefAttachmentMetadata(data: any): RepositoryWebrefWebrefAttachmentMetadata {
  return {
    ...data,
    oysterId: data["oysterId"] !== undefined ? serializeGeostoreFeatureIdProto(data["oysterId"]) : undefined,
  };
}

function deserializeRepositoryWebrefWebrefAttachmentMetadata(data: any): RepositoryWebrefWebrefAttachmentMetadata {
  return {
    ...data,
    oysterId: data["oysterId"] !== undefined ? deserializeGeostoreFeatureIdProto(data["oysterId"]) : undefined,
  };
}

/**
 * All information that applies globally to the document. Next available tag:
 * 11
 */
export interface RepositoryWebrefWebrefDocumentInfo {
  /**
   * Information about the document copied from the docjoin. This will never be
   * populated when WebrefEntities appears inside a CompositeDoc, but may we
   * used when it stands alone.
   */
  documentMetadata?: RepositoryWebrefDocumentMetadata;
  /**
   * Optional extensions (e.g. taxonomic classifications).
   */
  extensions?: Proto2BridgeMessageSet;
  /**
   * Information about the outlinks of this document.
   */
  outlinkInfos?: RepositoryWebrefWebrefOutlinkInfos;
  /**
   * The content (CONTENT section 0) as parsed by WebrefParser. Only used by
   * //r/w/postprocessing/idf/idf-pipeline for document ngram idf computation.
   * Populated when the annotator is run with webref_populate_parsed_content
   * Each webref_parsed_content_sentence represents one sentence of the context
   * where saft annotations were used to determine the sentence boundaries. See
   * r/w/universal/processors/saft/saft-sentence-helper.h for details.
   */
  webrefParsedContentSentence?: string[];
}

function serializeRepositoryWebrefWebrefDocumentInfo(data: any): RepositoryWebrefWebrefDocumentInfo {
  return {
    ...data,
    documentMetadata: data["documentMetadata"] !== undefined ? serializeRepositoryWebrefDocumentMetadata(data["documentMetadata"]) : undefined,
    outlinkInfos: data["outlinkInfos"] !== undefined ? serializeRepositoryWebrefWebrefOutlinkInfos(data["outlinkInfos"]) : undefined,
  };
}

function deserializeRepositoryWebrefWebrefDocumentInfo(data: any): RepositoryWebrefWebrefDocumentInfo {
  return {
    ...data,
    documentMetadata: data["documentMetadata"] !== undefined ? deserializeRepositoryWebrefDocumentMetadata(data["documentMetadata"]) : undefined,
    outlinkInfos: data["outlinkInfos"] !== undefined ? deserializeRepositoryWebrefWebrefOutlinkInfos(data["outlinkInfos"]) : undefined,
  };
}

/**
 * Represents a collection of entities returned by the WebRef service. Next
 * available tag: 14.
 */
export interface RepositoryWebrefWebrefEntities {
  /**
   * Detailed annotation statistics that can, e.g., be used to tune the WebRef
   * scoring logic based on existing (Model-0) annotations.
   */
  annotationStats?: RepositoryWebrefWebrefAnnotationStats;
  /**
   * Fingerprints checkpointing annotator stages, can be used to track the
   * source of diffs.
   */
  annotatorCheckpointFingerprints?: RepositoryWebrefAnnotatorCheckpointFprint[];
  /**
   * Categories of the document or query. This replaces the category_score
   * found under EntityAnnotations.
   */
  category?: RepositoryWebrefCategoryAnnotation[];
  /**
   * Dates ranges that are most relevant to the document. E.g. on a document
   * about Dune the 2021 movie, this might hold the release date of that movie.
   */
  dateRange?: RepositoryWebrefSemanticDateRange[];
  /**
   * Information that applies globally to the document. The exclude_field
   * option is for Goldmine AnnotationsFinder to exclude document_info from
   * retrieving annotation entities
   */
  documentInfo?: RepositoryWebrefWebrefDocumentInfo;
  /**
   * The annotated entities, with associated confidence scores and metadata.
   * This is the primary output of WebRef/QRef. In case of Webref output,
   * entities are sorted by decreasing topicality score.
   */
  entity?: RepositoryWebrefWebrefEntity[];
  /**
   * These messages contain non-entity annotations of ranges in the document.
   * This might be used to hold part-of-speech annotations, stopword
   * annotations, and other range based information. The exclude_field option is
   * for Goldmine AnnotationsFinder to exclude ranged_annotations from
   * retrieving annotation entities
   */
  rangeAnnotations?: RepositoryWebrefRangeAnnotations[];
  /**
   * The status message returned by the annotator. Might not be populated on
   * success.
   */
  status?: RepositoryWebrefWebrefStatus;
  /**
   * A generic container to hold extra result data.
   */
  stuff?: Proto2BridgeMessageSet;
  /**
   * Triples inferred from the document When the annotator recognizes phrases,
   * lists or tables associated with a property or relationship for an entity it
   * generates triples that encode that information. This generated data is only
   * substantiated by the document vs KG data which has been verified from
   * multiple sources and/or human curators.
   */
  tripleAnnotations?: RepositoryWebrefTripleAnnotations;
}

function serializeRepositoryWebrefWebrefEntities(data: any): RepositoryWebrefWebrefEntities {
  return {
    ...data,
    annotationStats: data["annotationStats"] !== undefined ? serializeRepositoryWebrefWebrefAnnotationStats(data["annotationStats"]) : undefined,
    annotatorCheckpointFingerprints: data["annotatorCheckpointFingerprints"] !== undefined ? data["annotatorCheckpointFingerprints"].map((item: any) => (serializeRepositoryWebrefAnnotatorCheckpointFprint(item))) : undefined,
    documentInfo: data["documentInfo"] !== undefined ? serializeRepositoryWebrefWebrefDocumentInfo(data["documentInfo"]) : undefined,
    entity: data["entity"] !== undefined ? data["entity"].map((item: any) => (serializeRepositoryWebrefWebrefEntity(item))) : undefined,
    rangeAnnotations: data["rangeAnnotations"] !== undefined ? data["rangeAnnotations"].map((item: any) => (serializeRepositoryWebrefRangeAnnotations(item))) : undefined,
    tripleAnnotations: data["tripleAnnotations"] !== undefined ? serializeRepositoryWebrefTripleAnnotations(data["tripleAnnotations"]) : undefined,
  };
}

function deserializeRepositoryWebrefWebrefEntities(data: any): RepositoryWebrefWebrefEntities {
  return {
    ...data,
    annotationStats: data["annotationStats"] !== undefined ? deserializeRepositoryWebrefWebrefAnnotationStats(data["annotationStats"]) : undefined,
    annotatorCheckpointFingerprints: data["annotatorCheckpointFingerprints"] !== undefined ? data["annotatorCheckpointFingerprints"].map((item: any) => (deserializeRepositoryWebrefAnnotatorCheckpointFprint(item))) : undefined,
    documentInfo: data["documentInfo"] !== undefined ? deserializeRepositoryWebrefWebrefDocumentInfo(data["documentInfo"]) : undefined,
    entity: data["entity"] !== undefined ? data["entity"].map((item: any) => (deserializeRepositoryWebrefWebrefEntity(item))) : undefined,
    rangeAnnotations: data["rangeAnnotations"] !== undefined ? data["rangeAnnotations"].map((item: any) => (deserializeRepositoryWebrefRangeAnnotations(item))) : undefined,
    tripleAnnotations: data["tripleAnnotations"] !== undefined ? deserializeRepositoryWebrefTripleAnnotations(data["tripleAnnotations"]) : undefined,
  };
}

/**
 * All information about a single entity available to WebRef. Next available
 * tag: 7
 */
export interface RepositoryWebrefWebrefEntity {
  /**
   * Information about links (e.g. implications) between the annotated
   * entities.
   */
  annotatedRelationship?: RepositoryWebrefWebrefEntityRelationship[];
  /**
   * All annotations of this entity on the given document.
   */
  annotations?: RepositoryWebrefEntityAnnotations;
  /**
   * Information about the collections of this entity.
   */
  collections?: RepositoryWebrefWebrefEntityCollections;
  /**
   * Metadata and raw signals used by the annotator.
   */
  entityJoin?: RepositoryWebrefEntityJoin;
  /**
   * An identifier (usually a MID) for the entity. Consider using
   * GetWebrefEntityMid() in the adjacent webref-entities-util.h to read this.
   */
  id?: RepositoryWebrefWebrefEntityId;
  /**
   * MRF equivalent representations of this entity as a compound, one for each
   * unique MRF representation. Populated for compounds. Each MRF expression
   * contains a minimum FunctionCall structure wrapped in a nameless Argument
   * without signals and range data. This is not meant to be directly usable as
   * MRF, use QueryJoinToMeaningStructConverter to expand it into a usable form.
   * References to entities are made as component_reference ArgumentValue. Each
   * compound Mention of this entity (not all of its mentions need be compounds,
   * some may be plain entity mentions) have one or more compound_value fields
   * claiming these MRF expressions via their mrf_index. The compound_value has
   * nested components, one for each unique component_reference.index in the MRF
   * expression. The processing expectation is that each ArgumentValue which has
   * a component_reference has its contents discarded and replaced with the MRF
   * for the target entity and mention named by the compound_value.component. If
   * the target is not a compound, the ArgumentValue becomes a simple mid value
   * and the signals are taken from the entity and the mention. If the target is
   * a compound itself, the expansion continues recursively. If the target is a
   * compound with multiple MRFs, a cartesian product of recursive expansions
   * may need to be produced. Along with the component_reference we also emit an
   * example value, but this is purely for human consumption so it's easier to
   * understand what the full compound is like. The processing expectation
   * remains that the ArgumentValue containing a component_reference is
   * completely discarded and rebuilt with the reference target value. If the
   * target has more than one MRF expression, it's not specified which one will
   * be used as an example, except that the choice is guaranteed to be
   * deterministic from run to run.
   */
  mrf?: KnowledgeAnswersIntentQueryArgument[];
}

function serializeRepositoryWebrefWebrefEntity(data: any): RepositoryWebrefWebrefEntity {
  return {
    ...data,
    annotations: data["annotations"] !== undefined ? serializeRepositoryWebrefEntityAnnotations(data["annotations"]) : undefined,
    entityJoin: data["entityJoin"] !== undefined ? serializeRepositoryWebrefEntityJoin(data["entityJoin"]) : undefined,
    id: data["id"] !== undefined ? serializeRepositoryWebrefWebrefEntityId(data["id"]) : undefined,
    mrf: data["mrf"] !== undefined ? data["mrf"].map((item: any) => (serializeKnowledgeAnswersIntentQueryArgument(item))) : undefined,
  };
}

function deserializeRepositoryWebrefWebrefEntity(data: any): RepositoryWebrefWebrefEntity {
  return {
    ...data,
    annotations: data["annotations"] !== undefined ? deserializeRepositoryWebrefEntityAnnotations(data["annotations"]) : undefined,
    entityJoin: data["entityJoin"] !== undefined ? deserializeRepositoryWebrefEntityJoin(data["entityJoin"]) : undefined,
    id: data["id"] !== undefined ? deserializeRepositoryWebrefWebrefEntityId(data["id"]) : undefined,
    mrf: data["mrf"] !== undefined ? data["mrf"].map((item: any) => (deserializeKnowledgeAnswersIntentQueryArgument(item))) : undefined,
  };
}

export interface RepositoryWebrefWebrefEntityCollections {
  collection?: RepositoryWebrefKGCollection[];
}

/**
 * The identifier of a WebrefEntity (see webref-entities.proto). IMPORTANT:
 * Please consider reading this proto through GetWebrefEntityMid() in
 * webref-entities-util.h, because this proto may: a) contain both freebase_mid
 * and concept_id (this is frequently the case to avoid breaking downstream
 * clients), b) only contain freebase_mid or only contain concept_id (as the
 * other one is technically redundant), c) contain neither of them or be missing
 * entirely (potentially in future).
 */
export interface RepositoryWebrefWebrefEntityId {
  /**
   * The MID in integer format. Nowadays, this field contains the equivalent
   * representation of `freebase_mid`, i.e. what metaweb::ParseId() returns.
   */
  conceptId?: bigint;
  /**
   * The MID in the same format that is returned by metaweb::MidToString(),
   * e.g. "/m/02mjmr" or "/g/11b6vyscgb" or "/t/24bjj59_jbj9f".
   */
  freebaseMid?: string;
}

function serializeRepositoryWebrefWebrefEntityId(data: any): RepositoryWebrefWebrefEntityId {
  return {
    ...data,
    conceptId: data["conceptId"] !== undefined ? String(data["conceptId"]) : undefined,
  };
}

function deserializeRepositoryWebrefWebrefEntityId(data: any): RepositoryWebrefWebrefEntityId {
  return {
    ...data,
    conceptId: data["conceptId"] !== undefined ? BigInt(data["conceptId"]) : undefined,
  };
}

/**
 * Information regarding links between annotated entities. Next available tag:
 * 5
 */
export interface RepositoryWebrefWebrefEntityRelationship {
  /**
   * The index of the entry in WebrefEntities.entity that the entity carrying
   * this field is linked to. This field must be set.
   */
  entityIndex?: number;
  /**
   * Information about the link.
   */
  linkMetadata?: RepositoryWebrefEntityLinkMetadata;
  /**
   * The weight of the link.
   */
  linkWeight?: number;
}

/**
 * *** THIS ATTACHMENT IS DEPRECATED, SEE go/udr/migrate-wma. ***. We still
 * allow legacy use case to exist (no forced migration), but we will not accept
 * any new usage of WMA, incl. from existing clients. UDR has the same features
 * and can be used similarly: - To consume the topical entities (+properties,
 * incl. hitcat, browsy, ...) go/udr/migrate-wma provides a migration with
 * minimal changes. - To consume IQL, please consult go/udr/superroot#access and
 * go/pianno team. The top-level proto used to store WebRef entities and IQL
 * expressions in Mustang/TG. The proto uses packed repeated fields and
 * variable-length integers in order to be as compact as possible. See
 * http://b/5802389 and b/7473898 for details on other approaches that were
 * considered and space/readability/extensibility trade-offs made. Note: It is
 * not recommeded to read this proto directly. Clients of the attachment should
 * use the decoder instead:
 * repository/webref/tools/kc/indexing/webref-attachment-decoder.h Next
 * available tag: 25
 */
export interface RepositoryWebrefWebrefMustangAttachment {
  /**
   * The confidence of the category. In the range [0, 100].
   */
  categoryConfidenceE2?: number[];
  /**
   * See go/category-annotations-api about the story behind various types of
   * category annotations that are provided using the catmid token and
   * category_encoded_mid fields below. Some of these annotation types are
   * experimental, so please contact related-entities@ if you consider using
   * this data. For production uses, please: 1. Add your use-case to
   * go/hits-clients. 2. Subscribe to hits-users@ to receive general updates and
   * info about deprecations. To convert it to the string form use
   * metaweb::MidToString(encoded_mid) defined in metaweb/util/mid/mid.h The
   * uint64-encoded MIDs of HitCat categories. See
   * google3/repository/webref/hits/hitcat/category.textproto for the complete
   * list of HitCat categories. Should have the same number of elements as the
   * category_confidence_e2 field.
   */
  categoryEncodedMid?: bigint[];
  /**
   * The confidence scores of all entities in the encoded_mid array. For space
   * reasons this is also represented as a fixed-point integer with two decimal
   * precision. Convert it to confidence_score using the following formula:
   * float confidence_score = confidence_e2 / 100.0f Should have the same number
   * of elements as the encoded_mid field.
   */
  confidenceE2?: number[];
  /**
   * The int64-encoded MIDs of the entities in the document sorted by
   * topicality score. To convert it to the string form use
   * metaweb::MidToString(encoded_mid) defined in metaweb/util/mid/mid.h Should
   * have the same number of elements as the topicality_e2 field.
   */
  encodedMid?: bigint[];
  /**
   * Per-entity metadata. Not packed (not every entity has metadata). If you'd
   * like to add per-document metadata, see document_metadata instead.
   */
  entityMetadata?: RepositoryWebrefWebrefAttachmentMetadata[];
  /**
   * A sub-proto to encode IQL expressions. To be used by Pianno page-level
   * intents and Webref Compounds.
   */
  iqlAttachment?: KnowledgeAnswersIntentQueryIndexingIQLAttachment;
  /**
   * The indices of all the reference entities in encoded_mid that are authors
   * of the page. Not packed as in most cases when populated, it contains 1
   * element.
   */
  isAuthorIndex?: number[];
  /**
   * The indices of all the reference entities in encoded_mid that are
   * publishers of the page (e.g. /m/cnn on "http://www.cnn.com/foo/bar"). Not
   * packed as in most cases when populated, it contains 1 element.
   */
  isPublisherIndex?: number[];
  /**
   * Only populated when the document is a reference page for an entity.
   * Contains the indices of all reference entities in the encoded_mid and
   * topicality_e2 arrays. Not packed as in most cases when populated, it
   * contains 1 element.
   */
  referencePageIndex?: number[];
  /**
   * The topicality scores of all entities in the encoded_mid array. For space
   * reasons this is represented as a fixed-point integer with two decimal
   * points precision. Convert it to topicality_score using the following
   * formula: float topicality_score = topicality_e2 / 100.f Should have the
   * same number of elements as the encoded_mid field.
   */
  topicalityE2?: number[];
  /**
   * The uint64-encoded MID of the unbound intents generated by Pianno. An
   * unbound intent is the annotation of an intent without slots arguments (e.g.
   * Age) declared in Intent Catalog. See go/pianno-asteroid-belt-migration for
   * details. We only keep the top unbound intents with the highest orbit
   * scores. Should have the same number of elements as unbound_intent_score_e2.
   */
  unboundIntentMid?: bigint[];
  /**
   * The confidence of the unbound intent. represented as a fixed-point integer
   * with two decimal precision. In the range [0, 100]. Should have the same
   * number of elements as unbound_intent_mid.
   */
  unboundIntentScoreE2?: number[];
  /**
   * [Experimental code. Do not use ] Entities that webref identified as being
   * the same concept (undermerged).
   */
  undermergedMembers?: RepositoryWebrefWebrefMustangAttachmentUndermergedMembers[];
}

function serializeRepositoryWebrefWebrefMustangAttachment(data: any): RepositoryWebrefWebrefMustangAttachment {
  return {
    ...data,
    categoryEncodedMid: data["categoryEncodedMid"] !== undefined ? data["categoryEncodedMid"].map((item: any) => (String(item))) : undefined,
    encodedMid: data["encodedMid"] !== undefined ? data["encodedMid"].map((item: any) => (String(item))) : undefined,
    entityMetadata: data["entityMetadata"] !== undefined ? data["entityMetadata"].map((item: any) => (serializeRepositoryWebrefWebrefAttachmentMetadata(item))) : undefined,
    iqlAttachment: data["iqlAttachment"] !== undefined ? serializeKnowledgeAnswersIntentQueryIndexingIQLAttachment(data["iqlAttachment"]) : undefined,
    unboundIntentMid: data["unboundIntentMid"] !== undefined ? data["unboundIntentMid"].map((item: any) => (String(item))) : undefined,
    undermergedMembers: data["undermergedMembers"] !== undefined ? data["undermergedMembers"].map((item: any) => (serializeRepositoryWebrefWebrefMustangAttachmentUndermergedMembers(item))) : undefined,
  };
}

function deserializeRepositoryWebrefWebrefMustangAttachment(data: any): RepositoryWebrefWebrefMustangAttachment {
  return {
    ...data,
    categoryEncodedMid: data["categoryEncodedMid"] !== undefined ? data["categoryEncodedMid"].map((item: any) => (BigInt(item))) : undefined,
    encodedMid: data["encodedMid"] !== undefined ? data["encodedMid"].map((item: any) => (BigInt(item))) : undefined,
    entityMetadata: data["entityMetadata"] !== undefined ? data["entityMetadata"].map((item: any) => (deserializeRepositoryWebrefWebrefAttachmentMetadata(item))) : undefined,
    iqlAttachment: data["iqlAttachment"] !== undefined ? deserializeKnowledgeAnswersIntentQueryIndexingIQLAttachment(data["iqlAttachment"]) : undefined,
    unboundIntentMid: data["unboundIntentMid"] !== undefined ? data["unboundIntentMid"].map((item: any) => (BigInt(item))) : undefined,
    undermergedMembers: data["undermergedMembers"] !== undefined ? data["undermergedMembers"].map((item: any) => (deserializeRepositoryWebrefWebrefMustangAttachmentUndermergedMembers(item))) : undefined,
  };
}

export interface RepositoryWebrefWebrefMustangAttachmentUndermergedMembers {
  /**
   * Experimental code, do not use.
   */
  encodedMid?: bigint[];
}

function serializeRepositoryWebrefWebrefMustangAttachmentUndermergedMembers(data: any): RepositoryWebrefWebrefMustangAttachmentUndermergedMembers {
  return {
    ...data,
    encodedMid: data["encodedMid"] !== undefined ? data["encodedMid"].map((item: any) => (String(item))) : undefined,
  };
}

function deserializeRepositoryWebrefWebrefMustangAttachmentUndermergedMembers(data: any): RepositoryWebrefWebrefMustangAttachmentUndermergedMembers {
  return {
    ...data,
    encodedMid: data["encodedMid"] !== undefined ? data["encodedMid"].map((item: any) => (BigInt(item))) : undefined,
  };
}

/**
 * Information about the outlinks for one specific target URL, from a given
 * annotated document. Next available tag: 7
 */
export interface RepositoryWebrefWebrefOutlinkInfo {
  /**
   * The length in bytes of such a link (including internal spaces); e.g. if
   * the link text is "click here" then the length is 10.
   */
  byteLength?: bigint[];
  /**
   * The byte offset of the start of a link with this target URL, in the
   * content of the annotated document.
   */
  byteOffset?: bigint[];
  /**
   * Whether this is a nofollow link (https://en.wikipedia.org/wiki/Nofollow).
   * If the page has multiple links to the same url, all of them must be
   * nofollow to set this field.
   */
  isNofollow?: boolean;
  /**
   * The topicality_weight for each link with this target URL.
   */
  topicalityWeight?: number[];
  /**
   * The target URL of the link.
   */
  url?: string;
}

function serializeRepositoryWebrefWebrefOutlinkInfo(data: any): RepositoryWebrefWebrefOutlinkInfo {
  return {
    ...data,
    byteLength: data["byteLength"] !== undefined ? data["byteLength"].map((item: any) => (String(item))) : undefined,
    byteOffset: data["byteOffset"] !== undefined ? data["byteOffset"].map((item: any) => (String(item))) : undefined,
  };
}

function deserializeRepositoryWebrefWebrefOutlinkInfo(data: any): RepositoryWebrefWebrefOutlinkInfo {
  return {
    ...data,
    byteLength: data["byteLength"] !== undefined ? data["byteLength"].map((item: any) => (BigInt(item))) : undefined,
    byteOffset: data["byteOffset"] !== undefined ? data["byteOffset"].map((item: any) => (BigInt(item))) : undefined,
  };
}

/**
 * Information about the outlinks of an annotated document. Next available tag:
 * 3
 */
export interface RepositoryWebrefWebrefOutlinkInfos {
  /**
   * Information about each target URL referred to in the document's outlinks.
   * If a given URL has multiple links, they are grouped in a single
   * WebrefLinkInfo.
   */
  outlinkInfo?: RepositoryWebrefWebrefOutlinkInfo[];
}

function serializeRepositoryWebrefWebrefOutlinkInfos(data: any): RepositoryWebrefWebrefOutlinkInfos {
  return {
    ...data,
    outlinkInfo: data["outlinkInfo"] !== undefined ? data["outlinkInfo"].map((item: any) => (serializeRepositoryWebrefWebrefOutlinkInfo(item))) : undefined,
  };
}

function deserializeRepositoryWebrefWebrefOutlinkInfos(data: any): RepositoryWebrefWebrefOutlinkInfos {
  return {
    ...data,
    outlinkInfo: data["outlinkInfo"] !== undefined ? data["outlinkInfo"].map((item: any) => (deserializeRepositoryWebrefWebrefOutlinkInfo(item))) : undefined,
  };
}

export interface RepositoryWebrefWebrefStatus {
  /**
   * The epoch of the Webref static data (the name-filter.data file). As of Dec
   * 2020 in prod Goldmine (in webref_daily_full_model_static_data) this value
   * is over from the alpha model static data, since this is where most of the
   * parts come from. I.e. the value does not correspond to the actual model
   * being used.
   */
  dataEpoch?: string;
  /**
   * Error that occurred during the annotation. This field is only populated by
   * QRef (i.e. under QueryJoin.status) and never by WebRef (i.e. under
   * WebrefEntities.status) anymore, which instead reports errors (and soon also
   * taints) through standard Goldmine mechanisms.
   */
  utilStatus?: UtilStatusProto;
  /**
   * The version number of the annotator (the cl the binary was built from).
   * Must be enabled via a command line flag. See also the Goldmine's
   * indexing::annotations::AnnotationMeta proto.
   */
  version?: number;
}

/**
 * Information about a Wikipedia category (typically at the bottom of the
 * page).
 */
export interface RepositoryWebrefWikipediaCategory {
  categoryName?: string;
}

/**
 * Geocodes extracted from the wikijoins.
 */
export interface RepositoryWebrefWikipediaGeocode {
  /**
   * The location as extracted from the wikijoins.
   */
  location?: GeostorePointProto;
  /**
   * The source contains the url field from the wikijoins.
   */
  sourceUrl?: string;
}

/**
 * 
 * //////////////////////////////////////////////////////////////////////////////
 * Conjunction: a single AND clause that contains multiple disjunctions.
 */
export interface ResearchScamCoscamConjunction {
  /**
   * disjunction_id / is_positive *MUST* have the same length. They specify a
   * set of disjunctions that make up this conjunction. The conjunction will be
   * active iff *all* of the positive disjunctions are active and *all* of the
   * negative disjunctions are inactive.
   */
  disjunctionId?: bigint[];
  isPositive?: boolean[];
}

function serializeResearchScamCoscamConjunction(data: any): ResearchScamCoscamConjunction {
  return {
    ...data,
    disjunctionId: data["disjunctionId"] !== undefined ? data["disjunctionId"].map((item: any) => (String(item))) : undefined,
  };
}

function deserializeResearchScamCoscamConjunction(data: any): ResearchScamCoscamConjunction {
  return {
    ...data,
    disjunctionId: data["disjunctionId"] !== undefined ? data["disjunctionId"].map((item: any) => (BigInt(item))) : undefined,
  };
}

/**
 * 
 * //////////////////////////////////////////////////////////////////////////////
 * Disjunction: a single OR clause that contains multiple group:token tuples.
 */
export interface ResearchScamCoscamDisjunction {
  /**
   * key - a uint64 key that uniquely identifies this disjunction.
   */
  key?: bigint;
  /**
   * groups - the group:token tuples that make up this disjunction. The
   * disjunction will be active if *any* off the group:token tuples are present
   * in a request.
   */
  tokenGroups?: ResearchScamCoscamTokenGroup[];
}

function serializeResearchScamCoscamDisjunction(data: any): ResearchScamCoscamDisjunction {
  return {
    ...data,
    key: data["key"] !== undefined ? String(data["key"]) : undefined,
    tokenGroups: data["tokenGroups"] !== undefined ? data["tokenGroups"].map((item: any) => (serializeResearchScamCoscamTokenGroup(item))) : undefined,
  };
}

function deserializeResearchScamCoscamDisjunction(data: any): ResearchScamCoscamDisjunction {
  return {
    ...data,
    key: data["key"] !== undefined ? BigInt(data["key"]) : undefined,
    tokenGroups: data["tokenGroups"] !== undefined ? data["tokenGroups"].map((item: any) => (deserializeResearchScamCoscamTokenGroup(item))) : undefined,
  };
}

/**
 * Each EasyConjunction represents an AND-of-ORs block.
 */
export interface ResearchScamCoscamEasyConjunction {
  /**
   * disjunctions is the set of OR clauses that
   */
  disjunctions?: ResearchScamCoscamEasyDisjunction[];
}

function serializeResearchScamCoscamEasyConjunction(data: any): ResearchScamCoscamEasyConjunction {
  return {
    ...data,
    disjunctions: data["disjunctions"] !== undefined ? data["disjunctions"].map((item: any) => (serializeResearchScamCoscamEasyDisjunction(item))) : undefined,
  };
}

function deserializeResearchScamCoscamEasyConjunction(data: any): ResearchScamCoscamEasyConjunction {
  return {
    ...data,
    disjunctions: data["disjunctions"] !== undefined ? data["disjunctions"].map((item: any) => (deserializeResearchScamCoscamEasyDisjunction(item))) : undefined,
  };
}

/**
 * Each EasyDisjunction represents one OR clause.
 */
export interface ResearchScamCoscamEasyDisjunction {
  /**
   * If is_positive is set to false, then the entire disjunction is negated,
   * and will be true only if none of its members is true.
   */
  isPositive?: boolean;
  /**
   * token_groups - the group:token tuples that make up this disjunction. The
   * disjunction will be active if *any* off the group:token tuples are present
   * in a request.
   */
  tokenGroups?: ResearchScamCoscamTokenGroup[];
}

function serializeResearchScamCoscamEasyDisjunction(data: any): ResearchScamCoscamEasyDisjunction {
  return {
    ...data,
    tokenGroups: data["tokenGroups"] !== undefined ? data["tokenGroups"].map((item: any) => (serializeResearchScamCoscamTokenGroup(item))) : undefined,
  };
}

function deserializeResearchScamCoscamEasyDisjunction(data: any): ResearchScamCoscamEasyDisjunction {
  return {
    ...data,
    tokenGroups: data["tokenGroups"] !== undefined ? data["tokenGroups"].map((item: any) => (deserializeResearchScamCoscamTokenGroup(item))) : undefined,
  };
}

/**
 * Each EasyRestrictDefinition represents an OR-of-ANDs-of-ORs block.
 */
export interface ResearchScamCoscamEasyRestrictDefinition {
  /**
   * conjunctions is the set of AND-of-ORs blocks.
   */
  conjunctions?: ResearchScamCoscamEasyConjunction[];
}

function serializeResearchScamCoscamEasyRestrictDefinition(data: any): ResearchScamCoscamEasyRestrictDefinition {
  return {
    ...data,
    conjunctions: data["conjunctions"] !== undefined ? data["conjunctions"].map((item: any) => (serializeResearchScamCoscamEasyConjunction(item))) : undefined,
  };
}

function deserializeResearchScamCoscamEasyRestrictDefinition(data: any): ResearchScamCoscamEasyRestrictDefinition {
  return {
    ...data,
    conjunctions: data["conjunctions"] !== undefined ? data["conjunctions"].map((item: any) => (deserializeResearchScamCoscamEasyConjunction(item))) : undefined,
  };
}

/**
 * 
 * //////////////////////////////////////////////////////////////////////////////
 * RestrictDefinition: the set of conjunctions and disjunctions that define a
 * single OR-of-ANDs-of-ORs restrict definition.
 */
export interface ResearchScamCoscamRestrictDefinition {
  /**
   * conjunctions - each conjunction is an AND-of-ORs; if any of these
   * conjunctions match, then the entire restrict matches.
   */
  conjunctions?: ResearchScamCoscamConjunction[];
  /**
   * disjunctions - each disjunction is an OR clause.
   */
  disjunctions?: ResearchScamCoscamDisjunction[];
  /**
   * subs_key - ignore. Only used for testing.
   */
  subsKey?: bigint;
}

function serializeResearchScamCoscamRestrictDefinition(data: any): ResearchScamCoscamRestrictDefinition {
  return {
    ...data,
    conjunctions: data["conjunctions"] !== undefined ? data["conjunctions"].map((item: any) => (serializeResearchScamCoscamConjunction(item))) : undefined,
    disjunctions: data["disjunctions"] !== undefined ? data["disjunctions"].map((item: any) => (serializeResearchScamCoscamDisjunction(item))) : undefined,
    subsKey: data["subsKey"] !== undefined ? String(data["subsKey"]) : undefined,
  };
}

function deserializeResearchScamCoscamRestrictDefinition(data: any): ResearchScamCoscamRestrictDefinition {
  return {
    ...data,
    conjunctions: data["conjunctions"] !== undefined ? data["conjunctions"].map((item: any) => (deserializeResearchScamCoscamConjunction(item))) : undefined,
    disjunctions: data["disjunctions"] !== undefined ? data["disjunctions"].map((item: any) => (deserializeResearchScamCoscamDisjunction(item))) : undefined,
    subsKey: data["subsKey"] !== undefined ? BigInt(data["subsKey"]) : undefined,
  };
}

/**
 * 
 * //////////////////////////////////////////////////////////////////////////////
 * RestrictTokensV2: a set of group:token tuples, collated by group.
 */
export interface ResearchScamCoscamRestrictTokensV2 {
  /**
   * token_groups - group:token tuples, collated by group.
   */
  tokenGroups?: ResearchScamCoscamTokenGroup[];
}

function serializeResearchScamCoscamRestrictTokensV2(data: any): ResearchScamCoscamRestrictTokensV2 {
  return {
    ...data,
    tokenGroups: data["tokenGroups"] !== undefined ? data["tokenGroups"].map((item: any) => (serializeResearchScamCoscamTokenGroup(item))) : undefined,
  };
}

function deserializeResearchScamCoscamRestrictTokensV2(data: any): ResearchScamCoscamRestrictTokensV2 {
  return {
    ...data,
    tokenGroups: data["tokenGroups"] !== undefined ? data["tokenGroups"].map((item: any) => (deserializeResearchScamCoscamTokenGroup(item))) : undefined,
  };
}

export interface ResearchScamCoscamTokenGroup {
  /**
   * debug_token_strings - (optional) strings that should be used for
   * human-friendly printing. NOT used by the matching engine!
   */
  debugTokenStrings?: string[];
  /**
   * name - the name of the token group.
   */
  name?: string;
  /**
   * tokens - a list of tokens, stored by their Fingerprint2011 hash.
   */
  tokens?: bigint[];
}

function serializeResearchScamCoscamTokenGroup(data: any): ResearchScamCoscamTokenGroup {
  return {
    ...data,
    tokens: data["tokens"] !== undefined ? data["tokens"].map((item: any) => (String(item))) : undefined,
  };
}

function deserializeResearchScamCoscamTokenGroup(data: any): ResearchScamCoscamTokenGroup {
  return {
    ...data,
    tokens: data["tokens"] !== undefined ? data["tokens"].map((item: any) => (BigInt(item))) : undefined,
  };
}

/**
 * ===================================================================== #
 * GenericFeatureVector Last tag used: 23
 */
export interface ResearchScamGenericFeatureVector {
  /**
   * The class label of this datapoint. This should be populated if ScaM is
   * being used for nearest-neighbor-based classification.
   */
  classLabel?: string;
  crowding?: ResearchScamGenericFeatureVectorCrowding;
  /**
   * Optional point id that can contain an arbitrary (unrestricted in content)
   * value except when the data is provided via SSTable (sharded or not). In the
   * case of SSTable the data_id_str must be set for _all_ points in all shards
   * or the SSTable keys will be used as the values for the data_id_str of the
   * respective points. In either SSTable case--data_id_str provided explicitly
   * or via the key--the values must be unique across all shards.
   */
  dataIdStr?: Uint8Array;
  /**
   * A timestamp after which this datapoint is considered no longer valid and
   * is eligible for deletion. The exact meaning varies with
   * application/configuration.
   */
  expirationTimestamp?: Date;
  /**
   * DEPRECATED: - this field can safely be left unspecified. For dense
   * vectors, dimensionality is inferred from the number of values specified,
   * and must be identical to this, or unspecified. For sparse vectors, the
   * default value is correct for most users, and allows use of 64-bit hash
   * values for feature indices.
   */
  featureDim?: bigint;
  /**
   * - for SPARSE vectors, specifies indices of the nonzero dimensions whose
   * values are specified by the , , or field. This field is not used when
   * specifying dense vectors.
   */
  featureIndex?: bigint[];
  /**
   * Describes the type of feature values.
   */
  featureType?:  | "UNKNOWN" | "INT64" | "FLOAT" | "DOUBLE" | "STRING" | "BINARY";
  featureValueDouble?: number[];
  /**
   * Actual feature vector. Only one of the following should be populated. This
   * list has to be kept in sync with FeatureType enum. NOTES: Binary features
   * are stored as ones or zeroes in feature_value_int64. Floating point values
   * (feature_value_float, feature_value_double) may not be NaN.
   */
  featureValueFloat?: number[];
  featureValueInt64?: bigint[];
  featureValueString?: Uint8Array;
  fixedPointMetadata?: ResearchScamGenericFeatureVectorFixedPointMetadata;
  /**
   * copybara:strip_begin INTERNAL USE ONLY! The ScaM Team reserves the right
   * to remove this field and reuse its proto tag without notice. DO NOT USE
   * outside of build_shards_pipeline! This field is used inside
   * build_shards_pipeline to indicate whether this GFV is residing in its
   * secondary (vs. primary) partition. copybara:strip_end
   */
  internalOnlyIsSecondaryPartition?: boolean;
  /**
   * Describes if data has been normalized and the type.
   */
  normType?:  | "NONE" | "UNITL2NORM" | "STDGAUSSNORM" | "UNITL1NORM";
  /**
   * copybara:strip_begin A field that contains metadata information when the
   * datapoint is acting as a query.
   */
  queryMetadata?: ResearchScamQueryMetadata;
  restrictTokens?: ResearchScamGenericFeatureVectorRestrictTokens;
  tokens?: number[];
  /**
   * This field allows application-specific metadata to be stored in a GFV.
   * This information may be used by custom binaries or in pre- or
   * postprocessing outside of ScaM. Use cases include but are not limited to: *
   * Dataset IDs, if multiple datasets are multiplexed into one physical file or
   * network location. * An alternative, possibly more human-readable
   * representation of the data represented by this GFV, for e.g. debugging
   * purposes. * Outputting the contents of this field verbatim to the metadata
   * field of the NearestNeighbors.Neighbor proto.
   */
  userinfo?: Uint8Array;
  /**
   * DEPRECATED fields. Ignored by ScaM binaries. Do not use.
   */
  weight?: number;
}

function serializeResearchScamGenericFeatureVector(data: any): ResearchScamGenericFeatureVector {
  return {
    ...data,
    crowding: data["crowding"] !== undefined ? serializeResearchScamGenericFeatureVectorCrowding(data["crowding"]) : undefined,
    dataIdStr: data["dataIdStr"] !== undefined ? encodeBase64(data["dataIdStr"]) : undefined,
    expirationTimestamp: data["expirationTimestamp"] !== undefined ? data["expirationTimestamp"].toISOString() : undefined,
    featureDim: data["featureDim"] !== undefined ? String(data["featureDim"]) : undefined,
    featureIndex: data["featureIndex"] !== undefined ? data["featureIndex"].map((item: any) => (String(item))) : undefined,
    featureValueInt64: data["featureValueInt64"] !== undefined ? data["featureValueInt64"].map((item: any) => (String(item))) : undefined,
    featureValueString: data["featureValueString"] !== undefined ? encodeBase64(data["featureValueString"]) : undefined,
    restrictTokens: data["restrictTokens"] !== undefined ? serializeResearchScamGenericFeatureVectorRestrictTokens(data["restrictTokens"]) : undefined,
    userinfo: data["userinfo"] !== undefined ? encodeBase64(data["userinfo"]) : undefined,
  };
}

function deserializeResearchScamGenericFeatureVector(data: any): ResearchScamGenericFeatureVector {
  return {
    ...data,
    crowding: data["crowding"] !== undefined ? deserializeResearchScamGenericFeatureVectorCrowding(data["crowding"]) : undefined,
    dataIdStr: data["dataIdStr"] !== undefined ? decodeBase64(data["dataIdStr"] as string) : undefined,
    expirationTimestamp: data["expirationTimestamp"] !== undefined ? new Date(data["expirationTimestamp"]) : undefined,
    featureDim: data["featureDim"] !== undefined ? BigInt(data["featureDim"]) : undefined,
    featureIndex: data["featureIndex"] !== undefined ? data["featureIndex"].map((item: any) => (BigInt(item))) : undefined,
    featureValueInt64: data["featureValueInt64"] !== undefined ? data["featureValueInt64"].map((item: any) => (BigInt(item))) : undefined,
    featureValueString: data["featureValueString"] !== undefined ? decodeBase64(data["featureValueString"] as string) : undefined,
    restrictTokens: data["restrictTokens"] !== undefined ? deserializeResearchScamGenericFeatureVectorRestrictTokens(data["restrictTokens"]) : undefined,
    userinfo: data["userinfo"] !== undefined ? decodeBase64(data["userinfo"] as string) : undefined,
  };
}

/**
 * This subproto contains configuration for crowding. Crowding is a constraint
 * on a neighbor list produced by nearest neighbor search requiring that no more
 * than some value k' of the k neighbors returned have the same value of
 * crowding_attribute.
 */
export interface ResearchScamGenericFeatureVectorCrowding {
  /**
   * The value of the crowding attribute for this document. The maximum number
   * of neighbors to return per crowding attribute value
   * (per_crowding_attribute_num_neighbors) is configured per-query. This field
   * is ignored if per_crowding_attribute_num_neighbors is larger than the total
   * number of neighbors to return for a given query.
   */
  crowdingAttribute?: bigint;
}

function serializeResearchScamGenericFeatureVectorCrowding(data: any): ResearchScamGenericFeatureVectorCrowding {
  return {
    ...data,
    crowdingAttribute: data["crowdingAttribute"] !== undefined ? String(data["crowdingAttribute"]) : undefined,
  };
}

function deserializeResearchScamGenericFeatureVectorCrowding(data: any): ResearchScamGenericFeatureVectorCrowding {
  return {
    ...data,
    crowdingAttribute: data["crowdingAttribute"] !== undefined ? BigInt(data["crowdingAttribute"]) : undefined,
  };
}

/**
 * Metadata that may be populated if this GFV was transformed into fixed-point
 * from a floating-point GFV.
 */
export interface ResearchScamGenericFeatureVectorFixedPointMetadata {
  /**
   * The squared L2 norm of the original (pre-fixed-point transformation) GFV.
   * Used for computing squared L2 distance.
   */
  squaredL2Norm?: number;
}

/**
 * RestrictTokens - used to perform "restricted searches" where boolean rules
 * are used to filter the subset of the database eligible for matching. We
 * currently support V1 and V3 restrict systems. V3 restrict is a superset of V1
 * restrict. New users are encouraged to use V3 directly for its rich features
 * and cleaner semantics. See the document go/scam-v3-restricts, or read the
 * comments in //research/scam/proto/restricts.proto for details. Nevertheless,
 * V1 restrict is still supported by ScaM team. There's some minor tradeoff of
 * performance between V1 and V3. User may prefer V1 over V3 if performance is
 * the first priority. However, the CPU cost between V1 and V3 should be very
 * minor.
 * ---------------------------------------------------------------------------
 * The semantics of V1 restrict is described below: V1 "forward" restricts: The
 * dataset defines a many:many mapping between the database points and a token
 * space. Each token names a set of tokens and each database point is a member
 * of zero-to-many tokens. Queries specify zero-to-many whitelist and blacklist
 * tokens that activate database points according to the following rules: * If
 * whitelist_token is populated, the search will be restricted to points named
 * by at least one whitelist token. If whitelist_token is empty, all points are
 * whitelisted by default. * If blacklist_token is populated, it overrides the
 * whitelist. Points named by a blacklisted token are *not* searched. * Note
 * that, if neither whitelist_token nor blacklist_token is populated, the search
 * remains unrestricted.
 * ---------------------------------------------------------------------------
 * V1 "reverse" restricts: Each database point is whitelisted and/or blacklisted
 * for zero or more tokens, specified by whitelist_token and blacklist_token
 * fields. Each query specifies zero or more tokens, and the same rules apply: *
 * If a point's whitelist_token is populated, the point will only be searched if
 * the query has at least one matching whitelist token. If whitelist_token is
 * empty, the point is always whitelisted by default. * If a point's
 * blacklist_token is populated, it overrides the whitelist. The point will be
 * ignored for any query with a matching blacklist token. * Note that, if
 * neither whitelist_token nor blacklist_token is populated, the point will
 * always be searched. NEXT ID TO USE: 9
 */
export interface ResearchScamGenericFeatureVectorRestrictTokens {
  blacklistToken?: bigint[];
  /**
   * DEPRECATED
   */
  definition?: ResearchScamCoscamRestrictDefinition;
  /**
   * DEPRECATED
   */
  easyDefinition?: ResearchScamCoscamEasyRestrictDefinition;
  /**
   * B) Token Definitions (V1 Restricts) In "forward" mode: defined on database
   * points In "reverse" mode: defined on queries
   */
  tokenMembership?: bigint[];
  /**
   * DEPRECATED
   */
  tokens?: ResearchScamCoscamRestrictTokensV2;
  /**
   * Only ONE of the following sections should be used: A) V3 restricts.
   * Defined in //research/scam/proto/restricts.proto
   */
  v3?: ResearchScamV3Restrict;
  /**
   * If this field is not empty, when query is in V1 restricts while database
   * is in V3 restricts, SCaM will update V1 query to V3 automatically instead
   * of sending error messages. When updating query from V1 to V3, SCaM server
   * will use this field to fillin the 'namespace' field.
   */
  v3CompatibleNamespace?: string;
  /**
   * C) Whitelist / Blacklist Definitions (V1 Restricts) In "forward" mode:
   * defined on queries In "reverse" mode: defined on database points
   */
  whitelistToken?: bigint[];
}

function serializeResearchScamGenericFeatureVectorRestrictTokens(data: any): ResearchScamGenericFeatureVectorRestrictTokens {
  return {
    ...data,
    blacklistToken: data["blacklistToken"] !== undefined ? data["blacklistToken"].map((item: any) => (String(item))) : undefined,
    definition: data["definition"] !== undefined ? serializeResearchScamCoscamRestrictDefinition(data["definition"]) : undefined,
    easyDefinition: data["easyDefinition"] !== undefined ? serializeResearchScamCoscamEasyRestrictDefinition(data["easyDefinition"]) : undefined,
    tokenMembership: data["tokenMembership"] !== undefined ? data["tokenMembership"].map((item: any) => (String(item))) : undefined,
    tokens: data["tokens"] !== undefined ? serializeResearchScamCoscamRestrictTokensV2(data["tokens"]) : undefined,
    v3: data["v3"] !== undefined ? serializeResearchScamV3Restrict(data["v3"]) : undefined,
    whitelistToken: data["whitelistToken"] !== undefined ? data["whitelistToken"].map((item: any) => (String(item))) : undefined,
  };
}

function deserializeResearchScamGenericFeatureVectorRestrictTokens(data: any): ResearchScamGenericFeatureVectorRestrictTokens {
  return {
    ...data,
    blacklistToken: data["blacklistToken"] !== undefined ? data["blacklistToken"].map((item: any) => (BigInt(item))) : undefined,
    definition: data["definition"] !== undefined ? deserializeResearchScamCoscamRestrictDefinition(data["definition"]) : undefined,
    easyDefinition: data["easyDefinition"] !== undefined ? deserializeResearchScamCoscamEasyRestrictDefinition(data["easyDefinition"]) : undefined,
    tokenMembership: data["tokenMembership"] !== undefined ? data["tokenMembership"].map((item: any) => (BigInt(item))) : undefined,
    tokens: data["tokens"] !== undefined ? deserializeResearchScamCoscamRestrictTokensV2(data["tokens"]) : undefined,
    v3: data["v3"] !== undefined ? deserializeResearchScamV3Restrict(data["v3"]) : undefined,
    whitelistToken: data["whitelistToken"] !== undefined ? data["whitelistToken"].map((item: any) => (BigInt(item))) : undefined,
  };
}

/**
 * All nearest neighbors for one data point. Last tag used: 5
 */
export interface ResearchScamNearestNeighbors {
  /**
   * Data point for which we computed nearest neighbors. This field is set
   * based on the data_id_str field in the QueryRequest GFV (or SSTable key if
   * data_id_str is not present), and thus can be arbitrary data, e.g. docid,
   * URL, query string.
   */
  docid?: Uint8Array;
  /**
   * Metadata about the query. This field is populated if and only if: 1) ScaM
   * is running in offline query-database or online mode and; 2) The metadata is
   * directly fetched from the userinfo field inside GFV and; 3)
   * MetadataConfig.userinfo.set_user_info_for_query is set to true. The field
   * name is kept as "metadata" for consistency with neighbors.
   */
  metadata?: Uint8Array;
  /**
   * All its neighbors.
   */
  neighbor?: ResearchScamNearestNeighborsNeighbor[];
  /**
   * Propagate neighbor selection override information during offline search.
   */
  neighborSelectionOverride?: ResearchScamNeighborSelectionOverride;
  /**
   * The query vector for which we computed nearest neighbors.
   */
  query?: ResearchScamGenericFeatureVector;
  /**
   * The version ID of the server that responded to this query, if one was
   * specified. This field is not populated for offline (i.e. Flume rather than
   * RPC) search.
   */
  retrievedVersion?: string;
}

function serializeResearchScamNearestNeighbors(data: any): ResearchScamNearestNeighbors {
  return {
    ...data,
    docid: data["docid"] !== undefined ? encodeBase64(data["docid"]) : undefined,
    metadata: data["metadata"] !== undefined ? encodeBase64(data["metadata"]) : undefined,
    neighbor: data["neighbor"] !== undefined ? data["neighbor"].map((item: any) => (serializeResearchScamNearestNeighborsNeighbor(item))) : undefined,
    query: data["query"] !== undefined ? serializeResearchScamGenericFeatureVector(data["query"]) : undefined,
  };
}

function deserializeResearchScamNearestNeighbors(data: any): ResearchScamNearestNeighbors {
  return {
    ...data,
    docid: data["docid"] !== undefined ? decodeBase64(data["docid"] as string) : undefined,
    metadata: data["metadata"] !== undefined ? decodeBase64(data["metadata"] as string) : undefined,
    neighbor: data["neighbor"] !== undefined ? data["neighbor"].map((item: any) => (deserializeResearchScamNearestNeighborsNeighbor(item))) : undefined,
    query: data["query"] !== undefined ? deserializeResearchScamGenericFeatureVector(data["query"]) : undefined,
  };
}

export interface ResearchScamNearestNeighborsNeighbor {
  /**
   * If crowding is enabled, the crowding attribute of this neighbor will be
   * stored here.
   */
  crowdingAttribute?: bigint;
  /**
   * This could be exact or approximate distance.
   */
  distance?: number;
  /**
   * Neighbor data point. This field is set based on the data_id_str field in
   * the GFV of the data point in the database (or SSTable key if data_id_str is
   * not present), and thus can be arbitrary data, e.g. docid, URL, query
   * string.
   */
  docid?: Uint8Array;
  /**
   * Metadata about the neighbor. This is returned under some configurations as
   * a serialized proto. The specific proto depends on which metadata is
   * configured to be returned.
   */
  metadata?: Uint8Array;
}

function serializeResearchScamNearestNeighborsNeighbor(data: any): ResearchScamNearestNeighborsNeighbor {
  return {
    ...data,
    crowdingAttribute: data["crowdingAttribute"] !== undefined ? String(data["crowdingAttribute"]) : undefined,
    docid: data["docid"] !== undefined ? encodeBase64(data["docid"]) : undefined,
    metadata: data["metadata"] !== undefined ? encodeBase64(data["metadata"]) : undefined,
  };
}

function deserializeResearchScamNearestNeighborsNeighbor(data: any): ResearchScamNearestNeighborsNeighbor {
  return {
    ...data,
    crowdingAttribute: data["crowdingAttribute"] !== undefined ? BigInt(data["crowdingAttribute"]) : undefined,
    docid: data["docid"] !== undefined ? decodeBase64(data["docid"] as string) : undefined,
    metadata: data["metadata"] !== undefined ? decodeBase64(data["metadata"] as string) : undefined,
  };
}

/**
 * Last used tag = 8
 */
export interface ResearchScamNeighborSelectionOverride {
  /**
   * The distance threshold to use for approximate search before exact
   * reordering is performed, if exact reordering is performed. If this is not
   * set and exact reordering is enabled, a reasonable default value will be
   * chosen using a heuristic specified in
   * ScamConfig.ExactReordering.NeighborSelectionOverrideHeuristics. This field
   * is ignored if exact reordering is not enabled. This value must be non-NaN
   * if set.
   */
  approxEpsilonDistance?: number;
  /**
   * The number of neighbors to find via approximate search before exact
   * reordering is performed. If this is not set and exact reordering is
   * enabled, a reasonable default value will be chosen using the heuristic
   * specified in
   * ScamConfig.ExactReordering.NeighborSelectionOverrideHeuristics. This field
   * is ignored if exact reordering is not enabled. This value must be > 0 if
   * set.
   */
  approxNumNeighbors?: number;
  /**
   * The maximum distance at which to return a neighbor. If this proto is used,
   * at least one of this and num_neighbors must be set. The default is
   * infinity, effectively returning num_neighbors neighbors regardless of
   * distance. This value must be non-NaN if set.
   */
  epsilonDistance?: number;
  /**
   * The maximum number of neighbors to return. If this proto is used, at least
   * one of this and epsilon_distance must be set. The default is the largest
   * value representable as an int32, effectively returning all neighbors within
   * epsilon_distance. This value must be > 0 if set.
   */
  numNeighbors?: number;
  /**
   * If populated, this is the maximum number of neighbors that may be returned
   * from a single shard. If not populated, up to num_neighbors neighbors are
   * returned from each shard. Setting this to a smaller value than
   * num_neighbors will increase speed at the expense of accuray by requiring
   * cross-shard merging of fewer neighbors. If this value is set, num_neighbors
   * must also be set and this value must be <= num_neighbors and >=
   * num_neighbors / number of shards. If set, this value must always be > 0.
   */
  numSingleShardNeighbors?: number;
  /**
   * The maximum number of neighbors to return for a single value of the
   * crowding attribute. The crowding attribute is specified per-datapoint in
   * the GenericFeatureVector proto, or the Document proto for sparse logistic
   * models. Crowding is described more thoroughly in
   * research/scam/utils/crowding_top_n.h. NOTES: Crowding is effectivley
   * enabled if this value is less than num_neighbors.
   */
  perCrowdingAttributeNumNeighbors?: number;
  /**
   * The maximum number of neighbors to return from the approximate portion of
   * the nearest-neighbor search algorithm, within each shard, for a single
   * value of the crowding attribute, before performing exact reordering.
   * Ignored if exact reordering is disabled for this dataset.
   */
  perCrowdingAttributePreReorderingNumNeighbors?: number;
  /**
   * Note: currently not implemented for all database shard subclasses! Contact
   * ScaM before using. Overrides max_spill_centers for tree-X hybrid searchers
   * configured with FIXED_NUMBER_OF_CENTERS spilling. The max_spill_centers in
   * the ScaM config is used if this field isn't set. Only valid if: * Used on a
   * tree-X hybrid ScaM config with FIXED_NUMBER_OF_CENTERS. * Value is greater
   * than zero and at most equal to num_children.
   */
  treeXHybridLeavesSearchedOverride?: number;
}

/**
 * Structure to hold the response time for a node. Last used: 3
 */
export interface ResearchScamOnlineSearchLatencyStats {
  /**
   * An estimate of the CPU time used for this query on the machine associated
   * with task_id, from when the query was received to when the response was
   * ready to send, in seconds. Caveats: 1. Does not account for CPU time spent
   * serializing, deserializing, compressing or decompressing protos within
   * Stubby. 2. Does not account for cleanup time after response has been sent.
   */
  cpuTime?: number;
  /**
   * Task number associated with response time measurements.
   */
  taskId?: number;
  /**
   * Wall time taken on the machine associated with task_id from when the query
   * was received to when the response was ready to send, in seconds. This time
   * excludes the time spent sending the response and the time to perform
   * cleanup operations after the response is sent.
   */
  wallTime?: number;
}

/**
 * Metadata to encode query-specific information. This may include
 * NeighborSelectionOverride, pre-computed query tokenization, etc..
 */
export interface ResearchScamQueryMetadata {
  neighborSelectionOverride?: ResearchScamNeighborSelectionOverride;
}

/**
 * Response to a query. The main result is the nearest neighbor list, but we
 * also optionally include debugging information if the appropriate field is set
 * in the request. Last used: 8
 */
export interface ResearchScamQueryResponse {
  /**
   * Debugging fields: The wall and CPU time used by each query on each
   * machine. For successful queries, there will be one entry here for each
   * machine that the query used if QueryRequest.enable_latency_stats was
   * enabled. For unsuccessful queries, the contents of this field will be
   * undefined. NOTE: The following accounting rules apply in batched mode,
   * assuming there are
   */
  latency?: ResearchScamOnlineSearchLatencyStats[];
  /**
   * The number of non-root machines for which a DEADLINE_EXCEEDED error
   * occurred when they were contacted. This value does NOT include machines for
   * which no reply was received because their parent machine timed out.
   * Therefore, num_total_machines may be larger than num_ok_machines +
   * num_unreachable_machines + num_deadline_exceeded_machines.
   */
  numDeadlineExceededMachines?: number;
  /**
   * Number of machines that contributed to the results; this might be less
   * than the total number of machines if a machine has failed. The impact of a
   * single machine failure could be larger than just one machine, if it happens
   * to be one of the machines involved in distributing the query and collecting
   * results.
   */
  numOkMachines?: number;
  /**
   * The number of machines used in this service for the dataset that was
   * queried. If everything went right, this should be equal to num_ok_machines.
   * If num_ok_machines < num_total_machines, some neighbors may be missing from
   * results.
   */
  numTotalMachines?: number;
  /**
   * The number of non-root machines for which an UNREACHABLE error occurred
   * when they were contacted. This value does NOT include machines that were
   * implicitly unreachable because their parent machine was not reachable.
   * Therefore, num_total_machines may be larger than num_ok_machines +
   * num_unreachable_machines + num_deadline_exceeded_machines.
   */
  numUnreachableMachines?: number;
  /**
   * The number of "active" datapoints for each dataset, i.e. points that are
   * whitelisted by restricts and could be returned if they were close enough to
   * the query. For successful queries, there will be one entry here for each
   * dataset queried, if QueryRequest.enable_restrict_stats was true. For
   * partially-successful successful queries, this field will contain results
   */
  restrictStats?: ResearchScamRestrictStats[];
  /**
   * The results for each dataset searched. If per_dataset_parameters was empty
   * in QueryRequest then this will have one entry, the results for dataset 0.
   * If per_dataset_parameters was not empty in QueryRequest, this will contain
   * the results for each dataset queried, in order corresponding to the order
   * of QueryRequest.per_dataset_parameters.
   */
  results?: ResearchScamNearestNeighbors[];
  /**
   * USEFUL ONLY IN CUSTOM BINARIES. In the stock ScaM server binary, all
   * errors are relayed via the RPC's status. Thus, if RPC's status is ok, this
   * field is guaranteed to be ok and if RPC's status is an error, no
   * QueryResponse will be returned. The status of this query. This is useful
   * when using a batched postprocessing lambda, which may ignore erroneous
   * subqueries, continue postprocessing the valid ones and return OkStatus. In
   * this case, this field will inform the client of any invalid subqueries.
   */
  status?: UtilStatusProto;
}

function serializeResearchScamQueryResponse(data: any): ResearchScamQueryResponse {
  return {
    ...data,
    restrictStats: data["restrictStats"] !== undefined ? data["restrictStats"].map((item: any) => (serializeResearchScamRestrictStats(item))) : undefined,
    results: data["results"] !== undefined ? data["results"].map((item: any) => (serializeResearchScamNearestNeighbors(item))) : undefined,
  };
}

function deserializeResearchScamQueryResponse(data: any): ResearchScamQueryResponse {
  return {
    ...data,
    restrictStats: data["restrictStats"] !== undefined ? data["restrictStats"].map((item: any) => (deserializeResearchScamRestrictStats(item))) : undefined,
    results: data["results"] !== undefined ? data["results"].map((item: any) => (deserializeResearchScamNearestNeighbors(item))) : undefined,
  };
}

/**
 * Structure to hold the number of active and total datapoints for a given
 * dataset, as defined below. Last used: 2
 */
export interface ResearchScamRestrictStats {
  /**
   * The number of datapoints that are whitelisted by restricts specified for
   * this query, across all shards for which the query executed successfully. In
   * other words, this represents the number of datapoints that could
   * potentially be returned if they were close enough to the query according to
   * the selected distance measure. If restricts are disabled, this will be
   * equal to num_total_datapoints.
   */
  numActiveDatapoints?: bigint;
  /**
   * The number of total datapoints in all shards of this dataset for which the
   * query executed successfully. This is returned for convenience so that a
   * ratio can be easily computed, and so that num_active_datapoints can be put
   * in perspective for partially successful queries, i.e. queries where only
   * some shards were successful.
   */
  numTotalDatapoints?: bigint;
}

function serializeResearchScamRestrictStats(data: any): ResearchScamRestrictStats {
  return {
    ...data,
    numActiveDatapoints: data["numActiveDatapoints"] !== undefined ? String(data["numActiveDatapoints"]) : undefined,
    numTotalDatapoints: data["numTotalDatapoints"] !== undefined ? String(data["numTotalDatapoints"]) : undefined,
  };
}

function deserializeResearchScamRestrictStats(data: any): ResearchScamRestrictStats {
  return {
    ...data,
    numActiveDatapoints: data["numActiveDatapoints"] !== undefined ? BigInt(data["numActiveDatapoints"]) : undefined,
    numTotalDatapoints: data["numTotalDatapoints"] !== undefined ? BigInt(data["numTotalDatapoints"]) : undefined,
  };
}

export interface ResearchScamTokenNamespace {
  /**
   * 
   * ////////////////////////////////////////////////////////////////////////////
   * NAMESPACE - the string name of the namespace that this proto is specifying,
   * such as "color", "shape", "geo", or "tags". Recall that your overall query
   * is an AND across namespaces.
   */
  namespace?: string;
  /**
   * 
   * ////////////////////////////////////////////////////////////////////////////
   * BLACKLIST - Blacklisting can be used to implement more complex scenarios.
   * The blacklist fields have exactly the same format as the token fields, but
   * represents a negation. When a token is blacklisted, then matches will be
   * excluded whenever the other datapoint has that token. For example, if a
   * query specifies {color: red, blue, !purple}, then that query will match
   * datapoints that are red or blue, but if those points are also purple, then
   * they will be excluded even if they are red/blue. Note that, due to
   * symmetry, if one of the database points is {red, !blue}, that point will be
   * excluded from queries that specify blue. Lastly, note that namespaces with
   * *only* blacklist tokens behave similar to empty namespaces, in that {color:
   * !purple} would match blue or red datapoints, as long as those datapoints
   * don't also have the purple token.
   */
  stringBlacklistTokens?: string[];
  /**
   * 
   * ////////////////////////////////////////////////////////////////////////////
   * TOKENS - Conceptually, each token names a set datapoints. The field(s)
   * below are for declaring the tokens that name the datapoint that this
   * TokenNamespace proto is attached to. For convenience, we support either
   * string or uint64 tokens. Internally, the restricts system is based on
   * uint64s, but for many applications, strings are the more natural format,
   * and they should be preferred whenever this is the case. * When only uint64s
   * are specified, they will be used as-is. * When only strings are specified,
   * they will be converted to uint64s via Fingerprint2011. (See "Note on the
   * safety of Fingerprint2011"). * ADVANCED: When both fields are specified,
   * the uint64s are used as-is. Note that, when both fields are used, they
   * *must* have the same number of entries, and the system will assume that
   * your strings correspond 1:1 with the list of uint64 tokens. * EDGE CASE:
   * All matching is done in the uint64 space, so, I'm not sure why you'd do
   * this, but if, eg, your database uses strings, and your queries specify the
   * Fingerprint2011 hashes of those strings, matching will work, and this is a
   * specified behavior. Note on the safety of Fingerprint2011: Unless you have
   * well over 1M+ unique string tokens, you can safely assume that every string
   * will map to a unique 64-bit token. Internally, both Mustang and PSI use
   * Fingerprint2011 to hash arbitrary strings into uint64 tokens, and assume,
   * without validation, that each 64-bit token is unique. And the math backs up
   * this assumption: If we are using a "perfect" hashing function (and
   * Fingerprint2011 is close-enough for our purposes), and we then hash 1M
   * unique tokens into a 64-bit space, there's still better than 99.9999% odds
   * that all tokens are collision-free, nearly as good as the odds for the
   * datacenter's continued existence. Scenarios for having both the string and
   * uint64 token forms: * Probably none that matter to you. Just use the
   * strings directly. * You could have uint64 enum values, yet want to include
   * the string values for debugging purposes. Note that it *is* supported to
   * use a proprietary string => uint64 mapping, assuming that it is consistent,
   * and that you always specify the uint64 values. * The mixer-tier in a
   * multi-shard deployment might convert the strings into uint64s to avoid
   * redundant hashing overhead on the leaves, yet keep the string tokens to
   * preserve proto-level debugging. * When strings are present, I reserve the
   * right to use them for making logging "better", but, thusfar, there are 0
   * examples of this.
   */
  stringTokens?: string[];
  uint64BlacklistTokens?: bigint[];
  uint64Tokens?: bigint[];
}

function serializeResearchScamTokenNamespace(data: any): ResearchScamTokenNamespace {
  return {
    ...data,
    uint64BlacklistTokens: data["uint64BlacklistTokens"] !== undefined ? data["uint64BlacklistTokens"].map((item: any) => (String(item))) : undefined,
    uint64Tokens: data["uint64Tokens"] !== undefined ? data["uint64Tokens"].map((item: any) => (String(item))) : undefined,
  };
}

function deserializeResearchScamTokenNamespace(data: any): ResearchScamTokenNamespace {
  return {
    ...data,
    uint64BlacklistTokens: data["uint64BlacklistTokens"] !== undefined ? data["uint64BlacklistTokens"].map((item: any) => (BigInt(item))) : undefined,
    uint64Tokens: data["uint64Tokens"] !== undefined ? data["uint64Tokens"].map((item: any) => (BigInt(item))) : undefined,
  };
}

export interface ResearchScamV3Restrict {
  /**
   * 
   * ////////////////////////////////////////////////////////////////////////////
   * NAMESPACES - a repeating field, where each entry specifies the set of
   * tokens, within a single namespace, that apply to the query, or database
   * point, on which this V3Restrict proto is defined. Note that: * Your overall
   * query is an AND across namespaces. * Explicitly specifying a namespace with
   * 0 tokens is identical to omitting that namespace. ie, "{ns:}" == "". * It
   * is an error to specify the same namespace more than once per instance of
   * the V3Restrict proto.
   */
  namespaces?: ResearchScamTokenNamespace[];
}

function serializeResearchScamV3Restrict(data: any): ResearchScamV3Restrict {
  return {
    ...data,
    namespaces: data["namespaces"] !== undefined ? data["namespaces"].map((item: any) => (serializeResearchScamTokenNamespace(item))) : undefined,
  };
}

function deserializeResearchScamV3Restrict(data: any): ResearchScamV3Restrict {
  return {
    ...data,
    namespaces: data["namespaces"] !== undefined ? data["namespaces"].map((item: any) => (deserializeResearchScamTokenNamespace(item))) : undefined,
  };
}

/**
 * Information on the catalog that this dataset comes from. Next ID: 5
 */
export interface ResearchScienceSearchCatalog {
  /**
   * catalog description
   */
  description?: string;
  /**
   * catalog mid
   */
  mid?: string;
  /**
   * catalog name
   */
  name?: string;
  /**
   * catalog url
   */
  url?: string;
}

/**
 * Reference to the citation in Google scholar.
 */
export interface ResearchScienceSearchCitation {
  citation?: string;
  /**
   * The citation after HTML sanitation. Used only by the front-end.
   */
  safeHtmlCitation?: WebutilHtmlTypesSafeHtmlProto;
}

/**
 * The dataset in downloadable form. There can be multiple data download
 * entries for different file types. Next ID: 6
 */
export interface ResearchScienceSearchDataDownload {
  /**
   * Size of the download, as a string from the provider. May include units.
   */
  contentSize?: string;
  /**
   * URL for downloading the data
   */
  downloadUrl?: string;
  /**
   * File format at the link (ASCII, CSV, etc.)
   */
  fileFormat?: string;
  /**
   * Pragmatic classification of file formats - for filtering purposes
   */
  fileFormatClass?:  | "CLASS_UNDEFINED" | "CLASS_TABULAR" | "CLASS_DOCUMENT" | "CLASS_STRUCTURED" | "CLASS_IMAGE" | "CLASS_TEXT" | "CLASS_ARCHIVE" | "CLASS_PRESENTATION" | "CLASS_VIDEO" | "CLASS_AUDIO" | "CLASS_GEOSPATIAL" | "CLASS_MEDICAL_IMAGING" | "CLASS_COMPBIO" | "CLASS_OTHER";
  /**
   * Parsed content size
   */
  parsedContentSize?: ResearchScienceSearchDataSize;
}

/**
 * Data size information, consists of a numeric value and a unit. Next ID: 3
 */
export interface ResearchScienceSearchDataSize {
  /**
   * Data size value, in the provided size unit
   */
  size?: number;
  /**
   * The data size unit
   */
  unit?:  | "UNIT_UNSPECIFIED" | "BYTE" | "KB" | "MB" | "GB" | "TB" | "PB" | "EB" | "KIB" | "MIB" | "GIB" | "TIB" | "PIB" | "EIB";
}

/**
 * Representation of fields that contain dates. The formattes version, if
 * present, contains ISO 8601 formatted date or range. Otherwise, it is an
 * unformatted string. Next ID: 3
 */
export interface ResearchScienceSearchDate {
  formatted?: string;
  unformatted?: string;
}

/**
 * Stores the classification info of each field of study label.
 */
export interface ResearchScienceSearchFieldOfStudyInfo {
  /**
   * The classification source that determines the field of study label.
   */
  classificationSource?:  | "UNKNOWN" | "INFERENCE" | "KNOWLEDGE_GRAPH";
  /**
   * If set to true, it means that the probability is at least the threshold
   * value specified from the corresponding saved model config. Thresholds for
   * different fields may be different.
   */
  isAboveThreshold?:  | "BOOLEAN_WITH_UNDEFINED_UNDEFINED" | "BOOLEAN_WITH_UNDEFINED_TRUE" | "BOOLEAN_WITH_UNDEFINED_FALSE";
  /**
   * A label that represents the field of study.
   */
  label?:  | "UNKNOWN_FIELD_OF_STUDY_LABEL" | "HUMANITIES" | "SOCIAL_AND_BEHAVIOURAL_SCIENCE" | "BIOLOGY" | "MEDICINE" | "AGRICULTURE_FORESTRY_HORTICULTURE_AND_VETERINARY_MEDICINE" | "CHEMISTRY" | "PHYSICS" | "MATHEMATICS" | "GEOSCIENCES_AND_GEOGRAPHY" | "MECHANICAL_AND_INDUSTRIAL_ENGINEERING" | "THERMAL_ENGINEERING_AND_PROCESS_ENGINEERING" | "MATERIALS_SCIENCE_AND_ENGINEERING" | "COMPUTER_SCIENCE_ELECTRICAL_AND_SYSTEM_ENGINEERING" | "CONSTRUCTION_ENGINEERING_AND_ARCHITECTURE";
  /**
   * A score between [0, 1] outputted from the classifier indicating the
   * probability for being a YES instance.
   */
  probability?: number;
}

/**
 * Distribution license information. Next ID: 6
 */
export interface ResearchScienceSearchLicense {
  /**
   * A fingerprint id generated based on the license_class, URL or text. Since
   * the knowledge graph requires a unique string id for the license but any
   * filed of license can be empty, a fingerprint id can serve as a compact
   * identifier representing the non-empty sub-fields.
   */
  id?: string;
  /**
   * A value from a controlled vocabulary that uniquely identifies a license.
   * Unless this is set to LICENSE_CLASS_UNDEFINED_NO_MATCH or
   * LICENSE_CLASS_UNDEFINED_CONTRADICTING_MATCHES other fields in this message
   * should be empty.
   */
  licenseClass?:  | "LICENSE_CLASS_UNDEFINED_NO_MATCH" | "LICENSE_CLASS_UNDEFINED_CONTRADICTING_MATCHES" | "LICENSE_CLASS_CC0_V_1_0" | "LICENSE_CLASS_PDDL_V_1_0" | "LICENSE_CLASS_CC_BY_V_1_0" | "LICENSE_CLASS_CC_BY_V_2_0" | "LICENSE_CLASS_CC_BY_V_2_5" | "LICENSE_CLASS_CC_BY_V_3_0" | "LICENSE_CLASS_CC_BY_V_4_0" | "LICENSE_CLASS_CC_BY_SA_V_1_0" | "LICENSE_CLASS_CC_BY_SA_V_2_0" | "LICENSE_CLASS_CC_BY_SA_V_2_5" | "LICENSE_CLASS_CC_BY_SA_V_3_0" | "LICENSE_CLASS_CC_BY_SA_V_4_0" | "LICENSE_CLASS_CC_BY_NC_V_1_0" | "LICENSE_CLASS_CC_BY_NC_V_2_0" | "LICENSE_CLASS_CC_BY_NC_V_2_5" | "LICENSE_CLASS_CC_BY_NC_V_3_0" | "LICENSE_CLASS_CC_BY_NC_V_4_0" | "LICENSE_CLASS_CC_BY_NC_SA_V_1_0" | "LICENSE_CLASS_CC_BY_NC_SA_V_2_0" | "LICENSE_CLASS_CC_BY_NC_SA_V_2_5" | "LICENSE_CLASS_CC_BY_NC_SA_V_3_0" | "LICENSE_CLASS_CC_BY_NC_SA_V_4_0" | "LICENSE_CLASS_CC_BY_ND_V_1_0" | "LICENSE_CLASS_CC_BY_ND_V_2_0" | "LICENSE_CLASS_CC_BY_ND_V_2_5" | "LICENSE_CLASS_CC_BY_ND_V_3_0" | "LICENSE_CLASS_CC_BY_ND_V_4_0" | "LICENSE_CLASS_CC_BY_ND_NC_V_1_0" | "LICENSE_CLASS_CC_BY_NC_ND_V_2_0" | "LICENSE_CLASS_CC_BY_NC_ND_V_2_5" | "LICENSE_CLASS_CC_BY_NC_ND_V_3_0" | "LICENSE_CLASS_CC_BY_NC_ND_V_4_0" | "LICENSE_CLASS_CC_PDM_V_1_0" | "LICENSE_CLASS_OPEN_GOVERNMENT_LICENSE_V_1_0" | "LICENSE_CLASS_OPEN_GOVERNMENT_LICENSE_V_2_0" | "LICENSE_CLASS_OPEN_GOVERNMENT_LICENSE_V_3_0" | "LICENSE_CLASS_OPEN_GOVERNMENT_LICENSE_CANADA_V_2_0" | "LICENSE_CLASS_DL_DE_BY_V_1_0" | "LICENSE_CLASS_DL_DE_BY_V_2_0" | "LICENSE_CLASS_DL_DE_ZERO_V_2_0" | "LICENSE_CLASS_LO_OL_V_1_0" | "LICENSE_CLASS_LO_OL_V_2_0" | "LICENSE_CLASS_US_PD_V_1_0" | "LICENSE_CLASS_OCL_V_1_0" | "LICENSE_CLASS_ODC_PDDL_V_1_0" | "LICENSE_CLASS_ODC_BY_V_1_0" | "LICENSE_CLASS_ODC_ODBL_V_1_0" | "LICENSE_CLASS_MIT_V_1_0" | "LICENSE_CLASS_APACHE_V_2_0";
  /**
   * mid for the license.
   */
  licenseMid?: string;
  /**
   * The text (usually, the name) of the distribution license.
   */
  text?: string;
  /**
   * The url for the distribution license.
   */
  url?: string;
}

/**
 * Describes the spatial information about a value in spatial-coverage
 * definition of a dataset. Next ID: 9
 */
export interface ResearchScienceSearchLocation {
  /**
   * Coordinates of the corners of the polygon in the form "lat1 long1 lat2
   * long2"
   */
  boxCoordinates?: string;
  /**
   * Coordinates for the circle area defined by its center and radius: "lat
   * long, radius"
   */
  circleCoordinates?: string;
  /**
   * mids for locations that contain loctions in .
   */
  containedInMid?: string[];
  /**
   * mids for locations covering the dataset, contained in the . A region may
   * contain multiple locations that are identified by mids.
   */
  locationMid?: string[];
  /**
   * Labels (in the preferred language of the dataset) for the mids in .
   */
  locationMidLabel?: string[];
  /**
   * The original name for the area covered by the dataset.
   */
  locationName?: string;
  locationSource?:  | "UNKNOWN" | "METADATA" | "WEBREF";
  /**
   * Latitude and longitude for a single point in the form of "lat,long".
   */
  pointCoordinates?: string;
  /**
   * Unformatted coordinates describing the region.
   */
  unformattedCoordinates?: string;
}

/**
 * The information representing one navboost query for the dataset source_url.
 */
export interface ResearchScienceSearchNavboostQueryInfo {
  /**
   * imp_count stores an estimate of the number of impressions for this tuple.
   */
  impCount?: number;
  /**
   * lcc_count stores an estimate of the number of long clicks for this tuple.
   * NOTE: It is similar to query_doc_count, but calculated in different manner.
   */
  lccCount?: number;
  /**
   * The query string.
   */
  query?: string;
  /**
   * The query_count stores the counts on this query.
   */
  queryCount?: number;
  /**
   * The query_doc_count stores the number of long-clicks on this pair.
   */
  queryDocCount?: number;
}

/**
 * Organization, such as the source of a dataset or a funder NOTE:
 * source_organization_mid and source_organization_mid_label should always have
 * the same length: the mid and label correspond to each other. We don't use a
 * map for consistency with Location and if we switch to map, we should switch
 * to it in both. Next ID: 6
 */
export interface ResearchScienceSearchOrganization {
  /**
   * KG mid for the organization or person.
   */
  organizationMid?: string[];
  /**
   * Label (in the preferred language of the dataset) for the mid.
   */
  organizationMidLabel?: string[];
  /**
   * Unreconciled organization name. We store it here only if there are no
   * organization_mid values present.
   */
  organizationName?: string;
  /**
   * Original organization url
   */
  organizationUrl?: string;
  /**
   * Original name before reconciliation; empty if not reconciled.
   */
  originalOrganizationName?: string;
}

/**
 * A proto for storing inferred and reconciled metadata for Science Search.
 * Next available tag: 70
 */
export interface ResearchScienceSearchReconciledMetadata {
  /**
   * Alternate names and acronyms for the dataset.
   */
  alternateName?: string[];
  /**
   * A string representation of the authors of the dataset, collected from
   * author and creator in raw metadata. The exact format (e.g.,
   * comma-separated, etc.) is up to the extender that populates this field. The
   * assumption is that this string may appear in the UI "as is".
   */
  authorList?: string;
  /**
   * Catalog that this dataset is a part of.
   */
  catalog?: ResearchScienceSearchCatalog;
  /**
   * Compact Identifiers (for example "RRID:SCR_002088") that can be resolved
   * by Identifiers.org or N2T.net meta-resolvers.
   */
  compactIdentifier?: string[];
  /**
   * Compact Identifier(s) extracted from the citation field. Like in the case
   * of DOI(s) those identify the articles related to the dataset rather than
   * the dataset itself.
   */
  compactIdentifierFromCitation?: string[];
  coverageEndDate?: ResearchScienceSearchDate;
  /**
   * The start and end date that the dataset covers. If the dataset covers a
   * single timepoint, then start and end dates are the same. Use the ISO 8601
   * format for dates (e.g., 2006-05-23).
   */
  coverageStartDate?: ResearchScienceSearchDate;
  /**
   * The dataset in downloadable form. There can be multiple data download
   * entries for different file types.
   */
  dataDownload?: ResearchScienceSearchDataDownload[];
  /**
   * A hash of the raw metadata fields used by the QualityExtender.
   */
  datasetClassificationFieldsHash?: bigint;
  /**
   * Probability that the entity is in fact a dataset (in contrast to spam or
   * website labelled as dataset that does not describe a dataset).
   */
  datasetClassificationScore?: number;
  /**
   * The date when the dataset was created.
   */
  dateCreated?: ResearchScienceSearchDate;
  /**
   * The date when the dataset was modified.
   */
  dateModified?: ResearchScienceSearchDate;
  /**
   * The date when the dataset was published.
   */
  datePublished?: ResearchScienceSearchDate;
  /**
   * Most recent of the three dates (published, created, modified)
   */
  dateUpdated?: ResearchScienceSearchDate;
  denylistStatus?:  | "UNKNOWN_STATUS" | "FILE_NAME" | "NO_DESCRIPTION" | "DENYLIST_REGEX_MATCH" | "DENYLIST_NAME_MATCH" | "NAME_SIZE_OUT_OF_BOUNDS" | "DESCRIPTION_TOO_SHORT" | "NOT_IN_CATALOG_FOR_DOMAIN" | "MIRRORS_POPULAR_DATASET"[];
  /**
   * Description of the dataset.
   */
  description?: string[];
  /**
   * Description of the dataset converted to HTML.
   */
  descriptionInHtml?: string[];
  /**
   * The DOI for the dataset. We assume that there is only one.
   */
  doi?: string;
  /**
   * DOI(s) extracted from the citation field. In contrast to the "doi" field
   * these DOIs identify the articles related to the dataset rather than the
   * dataset itself.
   */
  doiFromCitation?: string[];
  /**
   * Field of study: a general, high-level classification of the dataset. This
   * is only populated during indexing time and it is only populated if the
   * classification_source is KNOWLEDGE_GRAPH or it's above inference threshold.
   */
  fieldOfStudy?: ResearchScienceSearchFieldOfStudyInfo[];
  /**
   * The fingerprint of basic fields from DatasetMetadata, including: - name -
   * description DEPRECATED
   */
  fingerprint?: bigint;
  /**
   * Funder of the dataset.
   */
  funder?: ResearchScienceSearchOrganization[];
  /**
   * Indicates if the dataset has table summaries. This field is only populated
   * during indexing time.
   */
  hasTableSummaries?: boolean;
  /**
   * A unique id for the dataset. For the data from Spore, this is the spore
   * id, such as, for example "http://accession.nodc.noaa.gov/8500223#__sid=js0"
   * REQUIRED
   */
  id?: string;
  /**
   * An identifier as provided by the dataset itself.
   */
  identifierFromSource?: string[];
  /**
   * The image urls provided by the dataset (e.g., for thumbnail images).
   */
  imageUrl?: string[];
  /**
   * Index of this dataset in its cluster of replicas.
   */
  indexInCluster?: number;
  /**
   * Indicates if the dataset is available for free or behind a paywal
   * http://schema.org/isAccessibleForFree
   */
  isAccessibleForFree?:  | "BOOLEAN_WITH_UNDEFINED_UNDEFINED" | "BOOLEAN_WITH_UNDEFINED_TRUE" | "BOOLEAN_WITH_UNDEFINED_FALSE";
  /**
   * A resource (most likely another dataset) from which this dataset is
   * derived or from which it is a modification or adaption.
   * http://schema.org/isBasedOn
   */
  isBasedOn?: string[];
  /**
   * Indicates whether the metadata was inferred using an ML model rather than
   * from the schema.org fields. Use optional so that explicitly setting to
   * false will ensure the value is passed along to the KG instead of being
   * indistinguisable from being unset and thus not set in the KG. This field
   * was originally non-optional; changing to optional is backwards compatible,
   * but protos created prior to being optional won't have has_is_inferred()
   * (go/proto-proposals/proto3-presence#wire-format-semantic-changes).
   */
  isInferred?: boolean;
  /**
   * Keywords describing the dataset.
   */
  keyword?: string[];
  /**
   * The 2-letter language code for the source page for the dataset. Same as
   * the language code in source_url_docjoin_info. Populated only when
   * generating output for indexing.
   */
  languageCode?: string;
  /**
   * License for the dataset.
   */
  license?: ResearchScienceSearchLicense[];
  /**
   * License for the dataset. DEPRECATED
   */
  licenseDeprecated?: string[];
  /**
   * A technique or technology used in a Dataset corresponding to the method
   * used for measuring the corresponding variable(s) (described using
   * variableMeasured). http://schema.org/measurementTechnique
   */
  measurementTechnique?: string[];
  /**
   * Mentioned URLs in the description.
   */
  mentionedUrls?: string[];
  metadataType?:  | "UNKNOWN_DATASET_TYPE" | "DATASET_TYPE" | "TABLE_TYPE" | "FIGURE_TYPE";
  /**
   * The names of the dataset.
   */
  name?: string[];
  /**
   * The number of datasets at the same source url as this dataset.
   */
  numberOfDatasetsAtSourceUrl?: number;
  /**
   * The number of articles that reference this dataset.
   */
  numberOfScholarCitations?: number;
  publication?: ResearchScienceSearchCitation[];
  /**
   * The url for the article that (likely) describes this dataset.
   */
  relatedArticleUrl?: string;
  /**
   * The info of replicas of this dataset.
   */
  replica?: ResearchScienceSearchReplica[];
  /**
   * Ids for other instances (not different versions) of this dataset.
   */
  sameAs?: string[];
  /**
   * For tables and figures, contains all of the metadata for a scholarly
   * article that was the source of this table or figure. This field is
   * populated only if metadata_type is 'TABLE' or 'FIGURE'.
   */
  scholarlyArticle?: ResearchScienceSearchScholarlyArticle;
  /**
   * Query string to send to Scholar to obtain the best approximation of
   * citations to the dataset.
   */
  scholarQuery?: string;
  /**
   * Source of the dataset: unifies provider, creator, author, publisher etc.
   */
  sourceOrganization?: ResearchScienceSearchOrganization[];
  /**
   * Source url from which we gathered the metadata
   */
  sourceUrl?: string;
  /**
   * All the information extracted from docjoin, for the source_url of this
   * dataset, aka DatasetMetadata.source_url.
   */
  sourceUrlDocjoinInfo?: ResearchScienceSearchSourceUrlDocjoinInfo;
  /**
   * Locations that describe spatial coverage of the data. If the data covers
   * multiple locations then each value corresponds to one such location,
   * describing its coordinates, mid, etc.
   */
  spatialCoverage?: ResearchScienceSearchLocation[];
  /**
   * Top salient term labels that describe the dataset document body.
   */
  topSalientTermLabel?: string[];
  /**
   * urls for the dataset, including doi.
   */
  url?: string[];
  /**
   * Variables that the data in the dataset captures (e.g., pressure, salinity,
   * temperature). For now, these are just strings.
   */
  variable?: string[];
  /**
   * Information on the version cluster that the dataset is a part of. This
   * field is populated during the indexing time; the field is populated only if
   * the dataset is part of a version cluster.
   */
  versionClusterInfo?: ResearchScienceSearchVersionClusterInfo;
  /**
   * A hash of the raw metadata fields used by the VersionEmbeddingExtender.
   */
  versionEmbeddingFieldsHash?: bigint;
  /**
   * An embedding for the dataset to be used by the VersionAggregator.
   */
  versionEmbeddingVector?: number[];
}

function serializeResearchScienceSearchReconciledMetadata(data: any): ResearchScienceSearchReconciledMetadata {
  return {
    ...data,
    datasetClassificationFieldsHash: data["datasetClassificationFieldsHash"] !== undefined ? String(data["datasetClassificationFieldsHash"]) : undefined,
    fingerprint: data["fingerprint"] !== undefined ? String(data["fingerprint"]) : undefined,
    scholarlyArticle: data["scholarlyArticle"] !== undefined ? serializeResearchScienceSearchScholarlyArticle(data["scholarlyArticle"]) : undefined,
    sourceUrlDocjoinInfo: data["sourceUrlDocjoinInfo"] !== undefined ? serializeResearchScienceSearchSourceUrlDocjoinInfo(data["sourceUrlDocjoinInfo"]) : undefined,
    versionClusterInfo: data["versionClusterInfo"] !== undefined ? serializeResearchScienceSearchVersionClusterInfo(data["versionClusterInfo"]) : undefined,
    versionEmbeddingFieldsHash: data["versionEmbeddingFieldsHash"] !== undefined ? String(data["versionEmbeddingFieldsHash"]) : undefined,
  };
}

function deserializeResearchScienceSearchReconciledMetadata(data: any): ResearchScienceSearchReconciledMetadata {
  return {
    ...data,
    datasetClassificationFieldsHash: data["datasetClassificationFieldsHash"] !== undefined ? BigInt(data["datasetClassificationFieldsHash"]) : undefined,
    fingerprint: data["fingerprint"] !== undefined ? BigInt(data["fingerprint"]) : undefined,
    scholarlyArticle: data["scholarlyArticle"] !== undefined ? deserializeResearchScienceSearchScholarlyArticle(data["scholarlyArticle"]) : undefined,
    sourceUrlDocjoinInfo: data["sourceUrlDocjoinInfo"] !== undefined ? deserializeResearchScienceSearchSourceUrlDocjoinInfo(data["sourceUrlDocjoinInfo"]) : undefined,
    versionClusterInfo: data["versionClusterInfo"] !== undefined ? deserializeResearchScienceSearchVersionClusterInfo(data["versionClusterInfo"]) : undefined,
    versionEmbeddingFieldsHash: data["versionEmbeddingFieldsHash"] !== undefined ? BigInt(data["versionEmbeddingFieldsHash"]) : undefined,
  };
}

/**
 * Stores the information about a dataset replica. Next ID: 5
 */
export interface ResearchScienceSearchReplica {
  /**
   * The name of the catalog that the replica comes from.
   */
  catalogName?: string;
  /**
   * The url of the catalog that the replica comes from.
   */
  catalogUrl?: string;
  /**
   * The index of this replica in a cluster of replicas.
   */
  indexInCluster?: number;
  /**
   * Url for the replica.
   */
  url?: string;
}

/**
 * Data and associated metadata for a scholarly pdf article.
 */
export interface ResearchScienceSearchScholarlyArticle {
  /**
   * Proto containing all of the Scholar Metadata for this article.
   */
  citation?: ScienceCitation;
  /**
   * contains the image of the figure or table cropped out of the pdf page
   * encoded as a PNG.
   */
  figureOrTableImage?: Uint8Array;
  /**
   * Contains the text (as detected by OCR) contained inside the image of the
   * figure or table.
   */
  figureOrTableOcrText?: string;
  /**
   * The url of the landing page for the scholarly article.
   */
  landingPageUrl?: string;
  /**
   * The page number where the table and figure is located in the original pdf
   * document.
   */
  pageNumber?: number;
  /**
   * The url where the pdf file is located for the scholarly article.
   */
  pdfDownloadUrl?: string;
}

function serializeResearchScienceSearchScholarlyArticle(data: any): ResearchScienceSearchScholarlyArticle {
  return {
    ...data,
    citation: data["citation"] !== undefined ? serializeScienceCitation(data["citation"]) : undefined,
    figureOrTableImage: data["figureOrTableImage"] !== undefined ? encodeBase64(data["figureOrTableImage"]) : undefined,
  };
}

function deserializeResearchScienceSearchScholarlyArticle(data: any): ResearchScienceSearchScholarlyArticle {
  return {
    ...data,
    citation: data["citation"] !== undefined ? deserializeScienceCitation(data["citation"]) : undefined,
    figureOrTableImage: data["figureOrTableImage"] !== undefined ? decodeBase64(data["figureOrTableImage"] as string) : undefined,
  };
}

/**
 * The proto containing all the information we extracted from docjoin, for the
 * source_url of the dataset. NEXT TAG: 17
 */
export interface ResearchScienceSearchSourceUrlDocjoinInfo {
  dataSource?:  | "UNKNOWN" | "RAFFIA_PROXY_SERVICE" | "SPORE_DUMP" | "INFERRED";
  /**
   * The url used to display in the google search results.
   */
  displayUrl?: string;
  /**
   * The docid of the document.
   */
  docid?: bigint;
  /**
   * Index tiers (BASE, UNIFIED_ZEPPELIN, etc) that the document belongs to.
   * NOTE: Each document may belong to multiple tiers. NOTE: The original data
   * type is an enum CompositeDoc::SubIndexType. However we don't want to depend
   * on segindexer/compositedoc.proto because the proto is too large. Instead,
   * we use CompositeDoc::SubIndexType_Name( subindexid) to convert into a
   * string representation. To convert string back to
   * CompositeDoc::SubIndexType, use CompositeDoc::SubIndexType_Parse.
   */
  indexTier?: string[];
  /**
   * The language of the document in the string representation of LanguageCode.
   * Converts from Language Enum to LanguageCode through
   * i18n/identifiers/langenclanguagecodeconverter.h Please use
   * i18n/identifiers/languagecodeconverter.h for converting between
   * LanguageCode and string representation.
   */
  languageCode?: string;
  /**
   * The syntactic date of a dataset document that reflects the publication
   * date of the content.
   */
  latestPageUpdateDate?: string;
  /**
   * A sequence of Navboost queries for the dataset source_url.
   */
  navboostQuery?: ResearchScienceSearchNavboostQueryInfo[];
  /**
   * The page rank of the document.
   */
  pagerank?: number;
  /**
   * Petacat classifications for the web document. Normally the results from
   * calling Petacat come in a PetacatResponse, which is very flexible and
   * extensible. This proto takes most of the flexibility away - only rephil
   * clusters, taxonomic classifications, and binary classifications, with
   * discretized weights.
   */
  petacatInfo?: FatcatCompactDocClassification;
  /**
   * A set of salient terms extracted fromthe document. DEPRECATEAD. Moved to
   * DatasetMetadata for performance reasons.
   */
  salientTerms?: QualitySalientTermsSalientTermSet;
  /**
   * Science per-doc data for inclusion in websearch.
   */
  scholarInfo?: ScienceIndexSignal;
  /**
   * A set of entities from WebRef annotations that are in SPORE_GRAPH.
   */
  sporeGraphMid?: string[];
  /**
   * The title of the document.
   */
  title?: string;
  /**
   * A set of top entities from WebrefAnnotation, top is defined by topicality
   * score, see go/topicality-score for detail. DEPRECATED. See
   * label_to_mids_map instead.
   */
  topEntity?: RepositoryWebrefWebrefEntity[];
  /**
   * The url of the document.
   */
  url?: string;
  /**
   * A set of entities copied from WebRefEntities on cDoc.
   */
  webrefEntity?: ResearchScienceSearchSourceUrlDocjoinInfoWebrefEntityInfo[];
}

function serializeResearchScienceSearchSourceUrlDocjoinInfo(data: any): ResearchScienceSearchSourceUrlDocjoinInfo {
  return {
    ...data,
    docid: data["docid"] !== undefined ? String(data["docid"]) : undefined,
    petacatInfo: data["petacatInfo"] !== undefined ? serializeFatcatCompactDocClassification(data["petacatInfo"]) : undefined,
    scholarInfo: data["scholarInfo"] !== undefined ? serializeScienceIndexSignal(data["scholarInfo"]) : undefined,
    topEntity: data["topEntity"] !== undefined ? data["topEntity"].map((item: any) => (serializeRepositoryWebrefWebrefEntity(item))) : undefined,
  };
}

function deserializeResearchScienceSearchSourceUrlDocjoinInfo(data: any): ResearchScienceSearchSourceUrlDocjoinInfo {
  return {
    ...data,
    docid: data["docid"] !== undefined ? BigInt(data["docid"]) : undefined,
    petacatInfo: data["petacatInfo"] !== undefined ? deserializeFatcatCompactDocClassification(data["petacatInfo"]) : undefined,
    scholarInfo: data["scholarInfo"] !== undefined ? deserializeScienceIndexSignal(data["scholarInfo"]) : undefined,
    topEntity: data["topEntity"] !== undefined ? data["topEntity"].map((item: any) => (deserializeRepositoryWebrefWebrefEntity(item))) : undefined,
  };
}

/**
 * The mid and description of a WebRefEntity.
 */
export interface ResearchScienceSearchSourceUrlDocjoinInfoWebrefEntityInfo {
  /**
   * DEPRECATED. See entity_type instead.
   */
  deprecatedEntityType?:  | "UNKNOWN" | "FIELD_OF_STUDY" | "GEO" | "ORGANIZATION";
  /**
   * The English description of the mid from the KG.
   */
  description?: string;
  entityCollectionType?:  | "UNKNOWN" | "FIELD_OF_STUDY" | "GEO" | "ORGANIZATION"[];
  /**
   * HRID of the KG collections
   */
  kgCollection?: string[];
  /**
   * The KG identifier of the WebrefEntity.
   */
  mid?: string;
}

/**
 * Stores the information about each cluster of versions. Versions are defined
 * in go/s2-versioning. Next available tag: 4
 */
export interface ResearchScienceSearchVersionClusterInfo {
  /**
   * Index of this dataset in its cluster of versions.
   */
  indexInVersionCluster?: number;
  /**
   * The number of versions in a Version Cluster. This is equivalent to cluster
   * size.
   */
  numVersions?: number;
  /**
   * A fingerprint id of the cluster of versions this dataset belongs to. This
   * is a hash of a dataset_id in the cluster.
   */
  versionClusterId?: bigint;
}

function serializeResearchScienceSearchVersionClusterInfo(data: any): ResearchScienceSearchVersionClusterInfo {
  return {
    ...data,
    versionClusterId: data["versionClusterId"] !== undefined ? String(data["versionClusterId"]) : undefined,
  };
}

function deserializeResearchScienceSearchVersionClusterInfo(data: any): ResearchScienceSearchVersionClusterInfo {
  return {
    ...data,
    versionClusterId: data["versionClusterId"] !== undefined ? BigInt(data["versionClusterId"]) : undefined,
  };
}

/**
 * Next ID: 11
 */
export interface RichsnippetsDataObject {
  AccessKey?: string;
  attribute?: RichsnippetsDataObjectAttribute[];
  source?:  | "PAGEMAP" | "MICROFORMAT" | "RDFA" | "METATAGS" | "SCRAPED" | "MICRODATA" | "AUTO_THUMBNAIL" | "JSON_LD";
  /**
   * The object type.
   */
  type?: string;
}

function serializeRichsnippetsDataObject(data: any): RichsnippetsDataObject {
  return {
    ...data,
    attribute: data["attribute"] !== undefined ? data["attribute"].map((item: any) => (serializeRichsnippetsDataObjectAttribute(item))) : undefined,
  };
}

function deserializeRichsnippetsDataObject(data: any): RichsnippetsDataObject {
  return {
    ...data,
    attribute: data["attribute"] !== undefined ? data["attribute"].map((item: any) => (deserializeRichsnippetsDataObjectAttribute(item))) : undefined,
  };
}

/**
 * Other attributes of the object.
 */
export interface RichsnippetsDataObjectAttribute {
  cdata?: Uint8Array;
  /**
   * idata holds integer data under the attribute name, and could be
   * interpreted differently according to the attribute name. Example: stores
   * the ImadeData.docid used to generate thumbnails. idata will not be
   * automatically converted into xml (the default behavior), but the behavior
   * can be overwritten if necessary.
   */
  idata?: bigint;
  name?: string;
  /**
   * A data object can have other data objects nested inside it. This is needed
   * to represent Microformats and RDFa which have nestings e.g., a review with
   * a business with an address, or a review with a rating object. See the
   * Webmaster Central 2009/05 blog on "Introducing Rich Snippets".
   */
  subobject?: Proto2BridgeMessageSet;
  /**
   * Whether we should tokenize the value and cdata when generating restricts
   * from this attribute.
   */
  tokenize?: boolean;
  /**
   * Either of cdata or value should be present.
   */
  value?: Uint8Array;
}

function serializeRichsnippetsDataObjectAttribute(data: any): RichsnippetsDataObjectAttribute {
  return {
    ...data,
    cdata: data["cdata"] !== undefined ? encodeBase64(data["cdata"]) : undefined,
    idata: data["idata"] !== undefined ? String(data["idata"]) : undefined,
    value: data["value"] !== undefined ? encodeBase64(data["value"]) : undefined,
  };
}

function deserializeRichsnippetsDataObjectAttribute(data: any): RichsnippetsDataObjectAttribute {
  return {
    ...data,
    cdata: data["cdata"] !== undefined ? decodeBase64(data["cdata"] as string) : undefined,
    idata: data["idata"] !== undefined ? BigInt(data["idata"]) : undefined,
    value: data["value"] !== undefined ? decodeBase64(data["value"] as string) : undefined,
  };
}

export interface RichsnippetsPageMap {
  DataObject?: RichsnippetsDataObject[];
  /**
   * If ignore_data_object is set to true, pagemap attachment is processed
   * regardless of whether data object is present or not.
   */
  ignoreDataObject?: boolean;
  src?:  | "REGULAR" | "KOREA_RICH";
  templatetype?: RichsnippetsPageMapTemplateType[];
}

function serializeRichsnippetsPageMap(data: any): RichsnippetsPageMap {
  return {
    ...data,
    DataObject: data["DataObject"] !== undefined ? data["DataObject"].map((item: any) => (serializeRichsnippetsDataObject(item))) : undefined,
  };
}

function deserializeRichsnippetsPageMap(data: any): RichsnippetsPageMap {
  return {
    ...data,
    DataObject: data["DataObject"] !== undefined ? data["DataObject"].map((item: any) => (deserializeRichsnippetsDataObject(item))) : undefined,
  };
}

/**
 * Unused fields
 */
export interface RichsnippetsPageMapTemplateType {
  src?: string;
}

/**
 * S3 based Audio language information about a Watch Page.
 */
export interface S3AudioLanguageS3AudioLanguage {
  /**
   * Audio language of video classified by Automatic Language Identification.
   * It corresponds to the langid_result in S3LangIdSignals.
   */
  language?:  | "ENGLISH" | "DANISH" | "DUTCH" | "FINNISH" | "FRENCH" | "GERMAN" | "HEBREW" | "ITALIAN" | "JAPANESE" | "KOREAN" | "NORWEGIAN" | "POLISH" | "PORTUGUESE" | "RUSSIAN" | "SPANISH" | "SWEDISH" | "CHINESE" | "CZECH" | "GREEK" | "ICELANDIC" | "LATVIAN" | "LITHUANIAN" | "ROMANIAN" | "HUNGARIAN" | "ESTONIAN" | "TG_UNKNOWN_LANGUAGE" | "UNKNOWN_LANGUAGE" | "BULGARIAN" | "CROATIAN" | "SERBIAN" | "IRISH" | "GALICIAN" | "TAGALOG" | "TURKISH" | "UKRAINIAN" | "HINDI" | "MACEDONIAN" | "BENGALI" | "INDONESIAN" | "LATIN" | "MALAY" | "MALAYALAM" | "WELSH" | "NEPALI" | "TELUGU" | "ALBANIAN" | "TAMIL" | "BELARUSIAN" | "JAVANESE" | "OCCITAN" | "URDU" | "BIHARI" | "GUJARATI" | "THAI" | "ARABIC" | "CATALAN" | "ESPERANTO" | "BASQUE" | "INTERLINGUA" | "KANNADA" | "PUNJABI" | "SCOTS_GAELIC" | "SWAHILI" | "SLOVENIAN" | "MARATHI" | "MALTESE" | "VIETNAMESE" | "FRISIAN" | "SLOVAK" | "CHINESE_T" | "FAROESE" | "SUNDANESE" | "UZBEK" | "AMHARIC" | "AZERBAIJANI" | "GEORGIAN" | "TIGRINYA" | "PERSIAN" | "BOSNIAN" | "SINHALESE" | "NORWEGIAN_N" | "PORTUGUESE_P" | "PORTUGUESE_B" | "XHOSA" | "ZULU" | "GUARANI" | "SESOTHO" | "TURKMEN" | "KYRGYZ" | "BRETON" | "TWI" | "YIDDISH" | "SERBO_CROATIAN" | "SOMALI" | "UIGHUR" | "KURDISH" | "MONGOLIAN" | "ARMENIAN" | "LAOTHIAN" | "SINDHI" | "RHAETO_ROMANCE" | "AFRIKAANS" | "LUXEMBOURGISH" | "BURMESE" | "KHMER" | "TIBETAN" | "DHIVEHI" | "CHEROKEE" | "SYRIAC" | "LIMBU" | "ORIYA" | "ASSAMESE" | "CORSICAN" | "INTERLINGUE" | "KAZAKH" | "LINGALA" | "MOLDAVIAN" | "PASHTO" | "QUECHUA" | "SHONA" | "TAJIK" | "TATAR" | "TONGA" | "YORUBA" | "CREOLES_AND_PIDGINS_ENGLISH_BASED" | "CREOLES_AND_PIDGINS_FRENCH_BASED" | "CREOLES_AND_PIDGINS_PORTUGUESE_BASED" | "CREOLES_AND_PIDGINS_OTHER" | "MAORI" | "WOLOF" | "ABKHAZIAN" | "AFAR" | "AYMARA" | "BASHKIR" | "BISLAMA" | "DZONGKHA" | "FIJIAN" | "GREENLANDIC" | "HAUSA" | "HAITIAN_CREOLE" | "INUPIAK" | "INUKTITUT" | "KASHMIRI" | "KINYARWANDA" | "MALAGASY" | "NAURU" | "OROMO" | "RUNDI" | "SAMOAN" | "SANGO" | "SANSKRIT" | "SISWANT" | "TSONGA" | "TSWANA" | "VOLAPUK" | "ZHUANG" | "KHASI" | "SCOTS" | "GANDA" | "MANX" | "MONTENEGRIN" | "AKAN" | "IGBO" | "MAURITIAN_CREOLE" | "HAWAIIAN" | "CEBUANO" | "EWE" | "GA" | "HMONG" | "KRIO" | "LOZI" | "LUBA_LULUA" | "LUO_KENYA_AND_TANZANIA" | "NEWARI" | "NYANJA" | "OSSETIAN" | "PAMPANGA" | "PEDI" | "RAJASTHANI" | "SESELWA_CREOLE_FRENCH" | "TUMBUKA" | "VENDA" | "WARAY_PHILIPPINES" | "NUM_LANGUAGES";
  /**
   * Confidence interval of the recognized language.
   */
  languageConfidence?:  | "UNKNOWN_CONFIDENCE" | "NOT_CONFIDENT" | "CONFIDENT" | "HIGHLY_CONFIDENT";
  /**
   * Type of detected speech.
   */
  speechClass?:  | "UNKNOWN" | "NO_SPEECH" | "HAS_SPEECH_FOR_ASR";
}

/**
 * A proto that stores SafeSearch internal signals that are not exported to
 * clients.
 */
export interface SafesearchInternalImageSignals {
  imageEntitiesViolenceScore?: number;
  /**
   * Additional SafeSearch signals that are used to compute final scores.
   */
  starburstPornScore?: number;
  starburstViolenceScore?: number;
}

/**
 * Flexible multi-vertical classification output. The output for each vertical
 * should be defined as a proto extension to this proto. When defining an
 * extension for a new vertical please follow the format: message NewVertical {
 * extend safesearch.VideoClassifierOutput { optional NewVertical
 * classifier_output_extension = ; } optional safesearch.VideoVerticalOutput
 * vertical_output = 1; } SafeSearch verticals only: Please also update this
 * message with a new extension declaration. For more details on extension
 * declaration please refer to http://go/proto-proposals/extension-declarations.
 * Please refer to http://go/proto2-extensions for details on message
 * extensions. LINT.IfChange next extension id: 5
 */
export interface SafesearchVideoClassifierOutput {
}

/**
 * SafeSearch video content classification scores are computed based on
 * go/golden7 video features. To access these scores see the library at:
 * google3/quality/safesearch/video/api/video_score_info.h
 */
export interface SafesearchVideoContentSignals {
  /**
   * This is used by Amarna to determine whether it should notify Raffia for
   * immediate reprocessing. This field will be generated in Amarna's
   * image_metadata corpus and exported to references_video_search corpus and
   * written to ExportState.module_state.critical_metadata_checksum for
   * determining whether Amarna should immediately notify Raffia whenever
   * is_abuse_with_high_confidence's value changes.
   */
  isAbuseWithHighConfidence?: boolean;
  scores?: {
    [key: string]: number
  };
  versionTag?:  | "UNKNOWN" | "V20220330" | "V20220620";
  /**
   * Output of all SafeSearch video classifiers in Amarna.
   */
  videoClassifierOutput?: SafesearchVideoClassifierOutput;
}

export interface ScienceCitation {
  /**
   * The source of abstract text that is chosen by science docid assigner.
   */
  AbstractCitationSource?: number;
  AbstractDisplay?:  | "UNKNOWN_ABSTRACT_DISPLAY" | "MAIN_ABSTRACT_DISPLAY" | "GRAPHICAL_ABSTRACT_DISPLAY" | "SUMMARY_ABSTRACT_DISPLAY";
  /**
   * Version of abstract field for display. Contains unsanitized XML/HTML.
   */
  AbstractHtml?: string;
  /**
   * Leftovers from AbstractHtml. These are usually unrecognized xml/html
   * entities or xml/html tags
   */
  AbstractHtmlLeftOver?: string;
  AbstractLanguage?: string;
  AbstractSource?:  | "NO_ABSTRACT" | "METADATA_ABSTRACT" | "LABELED_HTML_ABSTRACT" | "LABELED_PDF_ABSTRACT" | "UNLABELED_HTML_ABSTRACT" | "UNLABELED_PDF_ABSTRACT" | "HTML_TEXT_BLOCK" | "PDF_TEXT_BLOCK";
  AbstractText?: string;
  accessurl?: ScienceCitationAccessURL[];
  alternateabstract?: ScienceCitationAlternateAbstract[];
  alternatetitle?: ScienceCitationAlternateTitle[];
  /**
   * Fingerprint of the URL after applying crawl and aggregate rewrites.
   * Different citations with the same AlternateVersionID must have the same
   * VersionID, but not necessarily vice versa. Omitted when identical to the
   * VersionID.
   */
  AlternateVersionID?: bigint;
  /**
   * All the anchor text (before, after, formal, etc) for this citation in the
   * referring page.
   */
  Anchors?: ScienceCitationAnchor[];
  /**
   * e.g. hep-ph
   */
  ArxivSection?: string;
  author?: ScienceCitationAuthor[];
  /**
   * whether this citation had an "et al" in the author list
   */
  AuthorListHasEtAl?: boolean;
  AuthorMetatagLeftOver?: string;
  /**
   * Global document identifier - only available when building increments over
   * a known base index. This id is from the base index.
   */
  BaseGlobalID?: bigint;
  /**
   * Set when building an incremental index. Whereas BaseGlobalID is the ID of
   * the corresponding base cluster, the local ID is the ID of an individual
   * citation within that base cluster that corresponds to this reparse.
   */
  BaseLocalID?: bigint;
  /**
   * one bit per author
   */
  BorrowedAuthors?: number;
  /**
   * OR of FieldType
   */
  BorrowedFields?: number;
  category?: ScienceCitationCategory[];
  Chapter?: string;
  /**
   * citation src: dblp/crossref/paper etc
   */
  CitationSource?: number;
  /**
   * url where record came from
   */
  CitationSourceUrl?: string;
  /**
   * DEPRECATED: use CitationSource
   */
  CitationSrc?: string;
  ClearedReason?:  | "CLEARED_REASON_NONE" | "CLEARED_REASON_TOC";
  /**
   * Used for logging, recommendations, and sort-by-date. Contains the earliest
   * discovery date of the cluster, adjusted for earlier publication dates.
   * Stored in Universal time scale (100 ns ticks since 0001 AD) because Unix
   * timestamp would lead to negative dates for pre-1970 docs.
   */
  ClusterDiscoveryDate?: bigint;
  /**
   * Identifier for conference series - issn-lite
   */
  ConferenceId?: string;
  /**
   * 27 in the "27th conference on magical realism"
   */
  ConferenceNumber?: number;
  /**
   * If a citation is merged from a crawled version and a metadata version,
   * keep the normal docid fp of the crawled version for clustering FP of normal
   * docid of crawl version
   */
  CrawledDocid?: bigint;
  DblpId?: string;
  DEPRECATEDMetadataSourceFile?: string;
  /**
   * these fields moved to DownloadURL where they belong
   */
  DEPRECATEDPublisherDisplayName?: string;
  /**
   * Local document identifier - url fingerprint if we know the url, or
   * fingerprint of all fields if we don't. Different urls have different local
   * docids.
   */
  DocumentID?: bigint;
  /**
   * Digital Object Identifier
   */
  DOI?: string;
  downloadurl?: ScienceCitationDownloadURL[];
  /**
   * Dspace uses handle.net handles
   */
  DspaceID?: string;
  Edition?: string;
  Editor?: string[];
  FileCreationDay?: number;
  /**
   * zero-indexed field
   */
  FileCreationMonth?: number;
  /**
   * date of creation of the pdf/doc
   */
  FileCreationYear?: number;
  funding?: ScienceCitationFunding[];
  /**
   * Is this article expected to have been indexed in the incremental?
   */
  IncrementalExpected?: boolean;
  ISBN?: string;
  ISBNVariant?: string[];
  ISSN?: string;
  ISSNVariant?: string[];
  JOI?: string;
  Keywords?: string[];
  Language?: string;
  /**
   * library of congress call number
   */
  LCCN?: string;
  /**
   * The ScienceCitation is how metadata passes through the scholar system. For
   * legal, we use the normal ScienceCitation for the metadata/citation of legal
   * journals. For court/government documents (like opinions or statues), we
   * wrap it in the following embedded message
   */
  LegalCitation?: LegalCitation;
  /**
   * If this is a target reference, the level of discussion of this reference.
   */
  LevelOfDiscussion?: number;
  /**
   * random string data - unparsed
   */
  Note?: string;
  /**
   * for display in gws
   */
  NumBackwardLinks?: number;
  /**
   * hack for legal rollout
   */
  NumBackwardLinksFromLegal?: number;
  /**
   * numcited in WoS
   */
  NumBackwardLinksInWoS?: number;
  /**
   * can be 1-3
   */
  Number?: string;
  /**
   * for display in gws
   */
  NumForwardLinks?: number;
  /**
   * good embedded refs
   */
  NumGoodEmbeddedRefs?: number;
  /**
   * If set, then we host this many pages of this citation's content. Note that
   * this field may be set to 0, in which case we should be hosting this content
   * but have failed. DEPRECATED, moved to DownloadURL
   */
  NumHostedPages?: number;
  /**
   * for display in gws
   */
  NumKeyQuotes?: number;
  /**
   * for display in gws
   */
  NumRelated?: number;
  /**
   * for experiments
   */
  NumRelated2?: number;
  /**
   * for experiments
   */
  NumRelated3?: number;
  /**
   * refs in marked section
   */
  NumSectionRefs?: number;
  /**
   * for display in gws
   */
  NumVersions?: number;
  OnlineDay?: number;
  /**
   * OnlineMonth is a zero-indexed field (0 is January).
   */
  OnlineMonth?: number;
  OnlineYear?: number;
  /**
   * eg ERIC doc number or TR number
   */
  OtherID?: string;
  /**
   * Using string to handle all kinds of page specifications. Internal
   * structure is not really needed.
   */
  Pages?: string;
  ParseSource?: number;
  /**
   * Note that an issued patent has a PatentNumber and can also have a
   * PatentApplicationNumber, whereas a patent application has a
   * PatentApplicationNumber and can also have a PatentPublicationNumber.
   */
  PatentApplicationNumber?: string;
  /**
   * patent classification e.g., "B24B 3100"
   */
  PatentClassification?: string[];
  /**
   * 2-letter country code where patent was issued, see
   * ocean/metadata/patent_record.proto::Patent_Record::country_code for EPO one
   * patent pertains to a list of countries.
   */
  PatentCountry?: string[];
  /**
   * number according to USPTO/EPO/JPO scheme.
   */
  PatentNumber?: string;
  /**
   * one of the above
   */
  PatentOffice?: number;
  PatentPublicationNumber?: string;
  PMCID?: string;
  /**
   * Pubmed ID
   */
  PMID?: string;
  /**
   * for patents, publicationD/M/Y is the date of issue, not application
   */
  PublicationDay?: number;
  /**
   * month from bibtex PublicationMonth is a zero-indexed field (0 is January).
   */
  PublicationMonth?: number;
  /**
   * where published - subsumes booktitle, howpublished and journal from bibtex
   */
  PublicationVenue?: string;
  PublicationVenueVariant?: string[];
  /**
   * year from bibtext full year
   */
  PublicationYear?: number;
  /**
   * address from bibtex
   */
  PublisherAddress?: string;
  PublisherId?: string;
  /**
   * subsumes organization, school and institution from bibtex
   */
  PublisherOrg?: string;
  /**
   * local journal number
   */
  PubvenueID?: string;
  referencediscussion?: ScienceCitationReferenceDiscussion[];
  /**
   * bitmap of ReviewArticleTypeReasons
   */
  ReviewTypeReason?: number;
  Series?: string;
  SICI?: string;
  subject?: ScienceCitationSubject[];
  Title?: string;
  /**
   * Version of title for display. Contains unsanitized HTML/XML.
   */
  TitleHtml?: string;
  /**
   * Leftovers from TitleHtml. These are usually unrecognized xml/html entities
   * or xml/html tags
   */
  TitleHtmlLeftOver?: string;
  translatedauthor?: ScienceCitationTranslatedAuthor[];
  /**
   * etal marker for the translated author list - just in case
   */
  TranslatedAuthorListHasEtAl?: boolean;
  /**
   * ArticleType
   */
  Type?: number;
  unioncatalog?: ScienceCitationUnionCatalog[];
  /**
   * Email addresses found in the document that we weren't able to match
   */
  UnmatchedEmailAddr?: string[];
  /**
   * Author affiliations found in the document that we weren't able to match up
   * to specific authors.
   */
  UnmatchedInstitution?: string[];
  /**
   * Document version identifier - fingerprint of an id computed from the url,
   * or of bibliographic data from a publisher. Different urls for the same
   * article from the same source have the same version id (e.g., abstract, pdf
   * version, and html version).
   */
  VersionID?: bigint;
  Volume?: number;
  /**
   * Is this version of the article world viewable?
   */
  WorldViewable?: boolean;
  /**
   * Web of Science ID
   */
  WOSID?: string;
}

function serializeScienceCitation(data: any): ScienceCitation {
  return {
    ...data,
    AlternateVersionID: data["AlternateVersionID"] !== undefined ? String(data["AlternateVersionID"]) : undefined,
    Anchors: data["Anchors"] !== undefined ? data["Anchors"].map((item: any) => (serializeScienceCitationAnchor(item))) : undefined,
    BaseGlobalID: data["BaseGlobalID"] !== undefined ? String(data["BaseGlobalID"]) : undefined,
    BaseLocalID: data["BaseLocalID"] !== undefined ? String(data["BaseLocalID"]) : undefined,
    ClusterDiscoveryDate: data["ClusterDiscoveryDate"] !== undefined ? String(data["ClusterDiscoveryDate"]) : undefined,
    CrawledDocid: data["CrawledDocid"] !== undefined ? String(data["CrawledDocid"]) : undefined,
    DocumentID: data["DocumentID"] !== undefined ? String(data["DocumentID"]) : undefined,
    downloadurl: data["downloadurl"] !== undefined ? data["downloadurl"].map((item: any) => (serializeScienceCitationDownloadURL(item))) : undefined,
    referencediscussion: data["referencediscussion"] !== undefined ? data["referencediscussion"].map((item: any) => (serializeScienceCitationReferenceDiscussion(item))) : undefined,
    unioncatalog: data["unioncatalog"] !== undefined ? data["unioncatalog"].map((item: any) => (serializeScienceCitationUnionCatalog(item))) : undefined,
    VersionID: data["VersionID"] !== undefined ? String(data["VersionID"]) : undefined,
  };
}

function deserializeScienceCitation(data: any): ScienceCitation {
  return {
    ...data,
    AlternateVersionID: data["AlternateVersionID"] !== undefined ? BigInt(data["AlternateVersionID"]) : undefined,
    Anchors: data["Anchors"] !== undefined ? data["Anchors"].map((item: any) => (deserializeScienceCitationAnchor(item))) : undefined,
    BaseGlobalID: data["BaseGlobalID"] !== undefined ? BigInt(data["BaseGlobalID"]) : undefined,
    BaseLocalID: data["BaseLocalID"] !== undefined ? BigInt(data["BaseLocalID"]) : undefined,
    ClusterDiscoveryDate: data["ClusterDiscoveryDate"] !== undefined ? BigInt(data["ClusterDiscoveryDate"]) : undefined,
    CrawledDocid: data["CrawledDocid"] !== undefined ? BigInt(data["CrawledDocid"]) : undefined,
    DocumentID: data["DocumentID"] !== undefined ? BigInt(data["DocumentID"]) : undefined,
    downloadurl: data["downloadurl"] !== undefined ? data["downloadurl"].map((item: any) => (deserializeScienceCitationDownloadURL(item))) : undefined,
    referencediscussion: data["referencediscussion"] !== undefined ? data["referencediscussion"].map((item: any) => (deserializeScienceCitationReferenceDiscussion(item))) : undefined,
    unioncatalog: data["unioncatalog"] !== undefined ? data["unioncatalog"].map((item: any) => (deserializeScienceCitationUnionCatalog(item))) : undefined,
    VersionID: data["VersionID"] !== undefined ? BigInt(data["VersionID"]) : undefined,
  };
}

/**
 * User-defined URL and its last access data for citation manager.
 */
export interface ScienceCitationAccessURL {
  AccessDay?: number;
  /**
   * AccessMonth is a zero-indexed field (0 is January).
   */
  AccessMonth?: number;
  AccessYear?: number;
  UrlStr?: string;
}

/**
 * There are templated functions that fill the abstract fields designed to take
 * either ScienceCitation or ScienceCitation::AlternateAbstract, so these field
 * names must match those used for the primary abstract.
 */
export interface ScienceCitationAlternateAbstract {
  AbstractDisplay?:  | "UNKNOWN_ABSTRACT_DISPLAY" | "MAIN_ABSTRACT_DISPLAY" | "GRAPHICAL_ABSTRACT_DISPLAY" | "SUMMARY_ABSTRACT_DISPLAY";
  /**
   * Version of abstract field for display. This may contain XML/HTML tags.
   */
  AbstractHtml?: string;
  /**
   * Leftovers from AbstractHtml. These are usually unrecognized xml/html
   * entities or xml/html tags
   */
  AbstractHtmlLeftOver?: string;
  AbstractLanguage?: string;
  AbstractText?: string;
}

/**
 * alternate titles (including language where available)
 */
export interface ScienceCitationAlternateTitle {
  Language?: string;
  Title?: string;
  /**
   * Version of title for display. Contains unsanitized HTML/XML.
   */
  TitleHtml?: string;
  /**
   * Leftovers from TitleHtml. These are usually unrecognized xml/html entities
   * or xml/html tags
   */
  TitleHtmlLeftOver?: string;
}

/**
 * The anchor class holds content relevant to a citation, for example, the text
 * before or after the citation that explains what the citation is about.
 */
export interface ScienceCitationAnchor {
  /**
   * Number of times this anchor text appears, only consider the text itself
   */
  count?: number;
  /**
   * Fingerprint of the referral document. The fingerprint should resist to
   * small variance in the document content. DO NOT USE IT!
   */
  DEPRECATEDSrcFP?: bigint;
  /**
   * font face bitmask: kBold, kItalic, etc.
   */
  face?: number;
  /**
   * font size, in px
   */
  size?: number;
  /**
   * Space-delimited anchor words. Text that needs segmentation (like CJK or
   * Thai) is unsegmented. Generated by
   * ScienceParseUtils::AppendTokenSeqToString()
   */
  text?: string;
  /**
   * one of the "Type" value defined below.
   */
  type?: number;
  /**
   * weight of the anchor by looking where we get this anchor text. It can be
   * PR, court level, year, or the combination of differerent aspects. weights
   * are 1 - 128 defined as "Weights"
   */
  weight?: number;
}

function serializeScienceCitationAnchor(data: any): ScienceCitationAnchor {
  return {
    ...data,
    DEPRECATEDSrcFP: data["DEPRECATEDSrcFP"] !== undefined ? String(data["DEPRECATEDSrcFP"]) : undefined,
  };
}

function deserializeScienceCitationAnchor(data: any): ScienceCitationAnchor {
  return {
    ...data,
    DEPRECATEDSrcFP: data["DEPRECATEDSrcFP"] !== undefined ? BigInt(data["DEPRECATEDSrcFP"]) : undefined,
  };
}

/**
 * author names should be in the order specified in the paper
 */
export interface ScienceCitationAuthor {
  Comment?: string;
  /**
   * not in bibtex - from paper
   */
  Department?: string;
  Email?: string;
  /**
   * Tracks the GuessNameOrder case used to parse this author name, defaults to
   * 0 simply means that GuessNameOrder wasn't used.
   */
  GuessOrderType?: number;
  /**
   * Author ID. Formatted as idtype:id
   */
  ID?: string[];
  /**
   * not in bibtex - from paper
   */
  Institution?: string;
  IsCJKForeignName?: boolean;
  IsCorrespondingAuthor?: boolean;
  LastName?: string;
  OtherNames?: string;
  SourceText?: string;
  /**
   * Type is one of the contributors types. Writers are the default.
   */
  Type?: number;
}

export interface ScienceCitationCategory {
  Name?: string;
  /**
   * ontology/set of categories for the category
   */
  Type?: string;
}

/**
 * Download URL mentioned in citation; we keep up to K of them LINT.IfChange
 */
export interface ScienceCitationDownloadURL {
  /**
   * set if we know the landing page is broken
   */
  BrokenLandingPage?: boolean;
  CanonicalUrlfp?: bigint;
  /**
   * checksum of the page
   */
  ContentChecksum?: bigint;
  /**
   * makes gws display nicer :)
   */
  ContentType?: number;
  /**
   * seconds since the epoch
   */
  CrawlTimestamp?: bigint;
  /**
   * publisher display name
   */
  DisplayOrg?: string;
  /**
   * display preference score
   */
  DisplayPriority?: number;
  /**
   * metatag: URL; result was taken down
   */
  DMCANotice?: string;
  DownloadDay?: number;
  /**
   * DownloadMonth is a zero-indexed field (0 is January).
   */
  DownloadMonth?: number;
  /**
   * no abbrv
   */
  DownloadYear?: number;
  /**
   * first few lines of abstract'ish excerpt
   */
  ExcerptContent?: string;
  /**
   * label for excerpt (abstract, summary, ..)
   */
  ExcerptDebugLabel?: string;
  /**
   * seconds since the epoch
   */
  FirstDiscovered?: bigint;
  /**
   * explicit zero means hosting failed
   */
  HostedNumPages?: number;
  HostedStartPage?: number;
  /**
   * html title of the page
   */
  HtmlTitle?: string;
  /**
   * indexing preference score
   */
  IndexPriority?: number;
  /**
   * is url included in a previous index
   */
  InPrevIndex?: boolean;
  /**
   * e.g., in law_articles.pat
   */
  LegalMustInclude?: boolean;
  /**
   * Whether this is likely the URL for an ahead print, at indexing time.
   */
  LikelyAheadPrint?: boolean;
  /**
   * In the context of a given venue in Scholar Metrics, whether this URL
   * likely does not link to the current venue.
   */
  LikelyDifferentMetricsVenue?: boolean;
  /**
   * e.g., in legal_journals.pat
   */
  LikelyLegalJournal?: boolean;
  /**
   * badurls_nocache at indexing time
   */
  LikelyNoCache?: boolean;
  /**
   * badurls_noreturngws at indexing time
   */
  LikelyNoIndex?: boolean;
  /**
   * Likely to be free-to-read for everyone, after accounting for library links
   * etc.
   */
  LikelyWorldViewable?: boolean;
  /**
   * number of long paragraphs
   */
  LongChunkCount?: number;
  /**
   * Incremental only: mark as NoIndexed if this is a reparse and the base
   * version is NoIndexed.
   */
  MaybeNoIndexReparse?: boolean;
  /**
   * url of publisher metadata file
   */
  MetadataUrl?: string;
  /**
   * e.g., in science_articles.pat
   */
  MustInclude?: boolean;
  /**
   * metatag: don't show cached version
   */
  NoArchive?: boolean;
  /**
   * metatag: don't display this url
   */
  NoIndex?: boolean;
  /**
   * metatag: don't show snippet
   */
  NoSnippet?: boolean;
  /**
   * describes whether url is viewable in ocean
   */
  OceanView?: ScienceOceanView;
  /**
   * number of external URLs (in PDF).
   */
  OutLinkCount?: number;
  /**
   * Number of pages in the pdf2html conversion output. Only set for PDFs. For
   * a partitioned PDF, this is the page count of the entire volume.
   */
  PageCount?: number;
  /**
   * were references parsed in a previous index
   */
  ReferencesInPrevIndex?: boolean;
  /**
   * ArticleType for this particular url
   */
  Type?: number;
  UrlAfterRedirects?: string;
  UrlStr?: string;
  /**
   * number of words in content/body
   */
  WordCount?: number;
  /**
   * metatag: is viewable by world
   */
  WorldViewable?: boolean;
}

function serializeScienceCitationDownloadURL(data: any): ScienceCitationDownloadURL {
  return {
    ...data,
    CanonicalUrlfp: data["CanonicalUrlfp"] !== undefined ? String(data["CanonicalUrlfp"]) : undefined,
    ContentChecksum: data["ContentChecksum"] !== undefined ? String(data["ContentChecksum"]) : undefined,
    CrawlTimestamp: data["CrawlTimestamp"] !== undefined ? String(data["CrawlTimestamp"]) : undefined,
    FirstDiscovered: data["FirstDiscovered"] !== undefined ? String(data["FirstDiscovered"]) : undefined,
  };
}

function deserializeScienceCitationDownloadURL(data: any): ScienceCitationDownloadURL {
  return {
    ...data,
    CanonicalUrlfp: data["CanonicalUrlfp"] !== undefined ? BigInt(data["CanonicalUrlfp"]) : undefined,
    ContentChecksum: data["ContentChecksum"] !== undefined ? BigInt(data["ContentChecksum"]) : undefined,
    CrawlTimestamp: data["CrawlTimestamp"] !== undefined ? BigInt(data["CrawlTimestamp"]) : undefined,
    FirstDiscovered: data["FirstDiscovered"] !== undefined ? BigInt(data["FirstDiscovered"]) : undefined,
  };
}

export interface ScienceCitationFunding {
  /**
   * values are from FundingAgency enum
   */
  Agency?: number;
  /**
   * Text name of the agency. For analysis. Plus for agencies that don't have
   * an enum.
   */
  AgencyName?: string;
  /**
   * Funding entries for the same agency and grant number can be merged during
   * our extraction process so we maintain a record of all the deduped
   * ExtractionInfo messages within the remaining entry.
   */
  DebugExtractionInfo?: ScienceCitationFundingExtractionInfo[];
  /**
   * Text block from which the funding entry was extracted. Intended to be used
   * for offline analysis. DEPRECATED
   */
  DebugFundingTextBlock?: string;
  GrantNumber?: string;
  /**
   * funding recipient
   */
  Recipient?: string;
  /**
   * Original text for the funding acknowledgement
   */
  SourceText?: string;
  /**
   * Whether this funding info was added because this article was at the
   * exclusive repository for this agency.
   */
  UrlBasedFundingSource?: boolean;
}

/**
 * Holds information about the source of the funding entry.
 */
export interface ScienceCitationFundingExtractionInfo {
  /**
   * Text block context from which the funding entry was extracted. Optionally
   * filled and intended to be used for offline analysis.
   */
  DebugFundingTextBlock?: string;
  DocPart?:  | "UNSPECIFIED_DOC_PART" | "DOC_PREFIX" | "BEFORE_REFS" | "AFTER_REFS" | "DOC_SUFFIX";
  ParseSection?:  | "UNKNOWN" | "ACKNOWLEDGEMENT" | "FOOTNOTE" | "NEAR_REFS" | "BODY";
  Source?:  | "UNSPECIFIED" | "HTML" | "HTML_METADATA" | "PDF" | "XML_METADATA" | "XML_TEXT" | "URL_BASED_FUNDING";
}

/**
 * If this is a source document, the levels of discussion of the references
 * this document cites.
 */
export interface ScienceCitationReferenceDiscussion {
  Level?: number;
  TargetID?: bigint;
}

function serializeScienceCitationReferenceDiscussion(data: any): ScienceCitationReferenceDiscussion {
  return {
    ...data,
    TargetID: data["TargetID"] !== undefined ? String(data["TargetID"]) : undefined,
  };
}

function deserializeScienceCitationReferenceDiscussion(data: any): ScienceCitationReferenceDiscussion {
  return {
    ...data,
    TargetID: data["TargetID"] !== undefined ? BigInt(data["TargetID"]) : undefined,
  };
}

/**
 * subject classification
 */
export interface ScienceCitationSubject {
  /**
   * e.g., "eng"
   */
  Name?: string;
  /**
   * [0,1]
   */
  Probability?: number;
}

/**
 * translated author names. we usually get these for non-english papers which
 * provide english title/author/abstract info
 */
export interface ScienceCitationTranslatedAuthor {
  Department?: string;
  Email?: string;
  GuessOrderType?: number;
  Institution?: string;
  Language?: string;
  LastName?: string;
  OtherNames?: string;
  SourceText?: string;
  Type?: number;
}

/**
 * Create UnionCatalog as a group if we want to later add book level
 * informations.
 */
export interface ScienceCitationUnionCatalog {
  CanonicalUrlfp?: bigint;
  /**
   * url of catalog metadata file
   */
  MetadataUrl?: string;
  /**
   * Information about the number of libraries the citation appears. It should
   * be useful for ranking.
   */
  NumLibraries?: number;
  /**
   * Categories classification of the citation
   */
  Subject?: string[];
  /**
   * UnionCatalog url to display to users
   */
  Url?: string;
}

function serializeScienceCitationUnionCatalog(data: any): ScienceCitationUnionCatalog {
  return {
    ...data,
    CanonicalUrlfp: data["CanonicalUrlfp"] !== undefined ? String(data["CanonicalUrlfp"]) : undefined,
  };
}

function deserializeScienceCitationUnionCatalog(data: any): ScienceCitationUnionCatalog {
  return {
    ...data,
    CanonicalUrlfp: data["CanonicalUrlfp"] !== undefined ? BigInt(data["CanonicalUrlfp"]) : undefined,
  };
}

export interface ScienceIndexSignal {
  author?: ScienceIndexSignalAuthor[];
  /**
   * Fingerprint of the html title of the page. This is useful for checking if
   * we have the same version of the page as websearch.
   */
  HtmlTitleFp?: bigint;
  /**
   * Index selection score for websearch, bigger is better: (0.5,1.0] - prefer
   * selection into the base index, (0.0,0.5] - prefer selection into the
   * supplemental index.
   */
  IndexSelectionScore?: number;
  /**
   * Summary statistics.
   */
  NumBackwardLinks?: number;
  NumRelated?: number;
  NumVersions?: number;
  PublicationDay?: number;
  PublicationMonth?: number;
  /**
   * Publication date.
   */
  PublicationYear?: number;
  /**
   * Remove this URL from the index - error page, broken landing page, etc.
   * DEPRECATED, was never used or even filled correctly.
   */
  RemoveLink?: boolean;
  /**
   * For links from websearch to scholar.
   */
  ScholarId?: bigint;
  /**
   * Title of the article. Its only filled in when the html title of the page
   * isn't good.
   */
  Title?: string;
  /**
   * Length of document prefix that most users are likely to see. Only filled
   * in when we index subscription fulltext but most users see abstracts. This
   * is a conservative guesstimate - e.g., ACM shows fulltext to
   * university/company subscribers (including Google employees) based on user's
   * IP address, but we don't know subscriber IPs, so ACM's PDF pages would have
   * ~500 in this field (estimated length of abstract).
   */
  VisiblePrefixTerms?: number;
}

function serializeScienceIndexSignal(data: any): ScienceIndexSignal {
  return {
    ...data,
    HtmlTitleFp: data["HtmlTitleFp"] !== undefined ? String(data["HtmlTitleFp"]) : undefined,
    ScholarId: data["ScholarId"] !== undefined ? String(data["ScholarId"]) : undefined,
  };
}

function deserializeScienceIndexSignal(data: any): ScienceIndexSignal {
  return {
    ...data,
    HtmlTitleFp: data["HtmlTitleFp"] !== undefined ? BigInt(data["HtmlTitleFp"]) : undefined,
    ScholarId: data["ScholarId"] !== undefined ? BigInt(data["ScholarId"]) : undefined,
  };
}

export interface ScienceIndexSignalAuthor {
  LastName?: string;
  OtherNames?: string;
}

/**
 * Describes the viewability of ocean content.
 */
export interface ScienceOceanView {
  countryview?: ScienceOceanViewCountryView[];
}

export interface ScienceOceanViewCountryView {
  /**
   * No CountryCode means default viewability. two letter code
   */
  CountryCode?: string;
  /**
   * enum in ocean::LocaleViewability::ViewType
   */
  ViewType?: number;
}

export interface SdrEmbedding {
  compressedEmbeddings?: QualityRankembedMustangMustangRankEmbedInfo;
  values?: number[];
  version?: number;
}

function serializeSdrEmbedding(data: any): SdrEmbedding {
  return {
    ...data,
    compressedEmbeddings: data["compressedEmbeddings"] !== undefined ? serializeQualityRankembedMustangMustangRankEmbedInfo(data["compressedEmbeddings"]) : undefined,
  };
}

function deserializeSdrEmbedding(data: any): SdrEmbedding {
  return {
    ...data,
    compressedEmbeddings: data["compressedEmbeddings"] !== undefined ? deserializeQualityRankembedMustangMustangRankEmbedInfo(data["compressedEmbeddings"]) : undefined,
  };
}

export interface SdrPageAnchorsDocInfo {
  articleness?: number;
  pageAnchors?: SdrPageAnchorsSitelink[];
  qscore?: number;
  sitelinkWrapper?: SdrPageAnchorsSitelinkWrapper[];
  textRichness?: number;
}

function serializeSdrPageAnchorsDocInfo(data: any): SdrPageAnchorsDocInfo {
  return {
    ...data,
    pageAnchors: data["pageAnchors"] !== undefined ? data["pageAnchors"].map((item: any) => (serializeSdrPageAnchorsSitelink(item))) : undefined,
    sitelinkWrapper: data["sitelinkWrapper"] !== undefined ? data["sitelinkWrapper"].map((item: any) => (serializeSdrPageAnchorsSitelinkWrapper(item))) : undefined,
  };
}

function deserializeSdrPageAnchorsDocInfo(data: any): SdrPageAnchorsDocInfo {
  return {
    ...data,
    pageAnchors: data["pageAnchors"] !== undefined ? data["pageAnchors"].map((item: any) => (deserializeSdrPageAnchorsSitelink(item))) : undefined,
    sitelinkWrapper: data["sitelinkWrapper"] !== undefined ? data["sitelinkWrapper"].map((item: any) => (deserializeSdrPageAnchorsSitelinkWrapper(item))) : undefined,
  };
}

export interface SdrPageAnchorsSitelink {
  /**
   * Needed for relevance scoring.
   */
  embedding?: SdrEmbedding;
  /**
   * aggregate score from Section Geometry.
   */
  geometryScore?: number;
  /**
   * Heading Abbreviation score.
   */
  headingAbbrvScore?: number;
  /**
   * Needed for heading/passage filtering.
   */
  hpScore?: number;
  level?: number;
  scrollTo?: SdrScrollTo;
  /**
   * Needed for Geometry Scoring and backoffs. from Section Geometry.
   */
  sectionHeight?: number;
  /**
   * Heading/Reformulated text is needed to display.
   */
  text?: string;
}

function serializeSdrPageAnchorsSitelink(data: any): SdrPageAnchorsSitelink {
  return {
    ...data,
    embedding: data["embedding"] !== undefined ? serializeSdrEmbedding(data["embedding"]) : undefined,
  };
}

function deserializeSdrPageAnchorsSitelink(data: any): SdrPageAnchorsSitelink {
  return {
    ...data,
    embedding: data["embedding"] !== undefined ? deserializeSdrEmbedding(data["embedding"]) : undefined,
  };
}

/**
 * This wrapper is used for passing in additional information to generate
 * embeddings in Goldmine.
 */
export interface SdrPageAnchorsSitelinkWrapper {
  abbreviatedHeadingText?: string;
  abbrvEmbedding?: SdrEmbedding;
  headingEmbedding?: SdrEmbedding;
  normalizedHeadingText?: string;
  passageEmbedding?: SdrEmbedding;
  passageText?: string;
}

function serializeSdrPageAnchorsSitelinkWrapper(data: any): SdrPageAnchorsSitelinkWrapper {
  return {
    ...data,
    abbrvEmbedding: data["abbrvEmbedding"] !== undefined ? serializeSdrEmbedding(data["abbrvEmbedding"]) : undefined,
    headingEmbedding: data["headingEmbedding"] !== undefined ? serializeSdrEmbedding(data["headingEmbedding"]) : undefined,
    passageEmbedding: data["passageEmbedding"] !== undefined ? serializeSdrEmbedding(data["passageEmbedding"]) : undefined,
  };
}

function deserializeSdrPageAnchorsSitelinkWrapper(data: any): SdrPageAnchorsSitelinkWrapper {
  return {
    ...data,
    abbrvEmbedding: data["abbrvEmbedding"] !== undefined ? deserializeSdrEmbedding(data["abbrvEmbedding"]) : undefined,
    headingEmbedding: data["headingEmbedding"] !== undefined ? deserializeSdrEmbedding(data["headingEmbedding"]) : undefined,
    passageEmbedding: data["passageEmbedding"] !== undefined ? deserializeSdrEmbedding(data["passageEmbedding"]) : undefined,
  };
}

/**
 * Data needed to construct a go/scroll-to text fragment. The url fragment is:
 * #:~:text=[prefix-,]text_start,text_end
 */
export interface SdrScrollTo {
  onpageMatches?: SdrScrollToOnPageMatches;
  /**
   * Prefix to help with disambiguating between multiple text matches on page.
   * Optional.
   */
  prefix?: string;
  /**
   * Suffix to help with disambiguating between multiple text matches on page.
   * Optional.
   */
  suffix?: string;
  /**
   * End of the text span to be highlighted. Optional.
   */
  textEnd?: string;
  /**
   * Start of the text span to be highlighted.
   */
  textStart?: string;
}

/**
 * Number of matches in the page when using text alone, prefix + text, text +
 * suffix, and prefix + text + suffix. The match is case-insensitive to align
 * with go/scroll-to behavior.
 */
export interface SdrScrollToOnPageMatches {
  text?: number;
  textWithPrefix?: number;
  textWithPrefixSuffix?: number;
  textWithSuffix?: number;
}

/**
 * Encapsulates sensitivity mode, source, and other metadata, used for ranking
 * when there are multiple sensitivies set by default sources (eg, followon,
 * query understanding, attentional entity).
 */
export interface SearchPolicyRankableSensitivity {
  /**
   * Propagated from knowledge.answers.sensitivity.Sensitivity
   * account_provenance. Any ambiguity between the data here and dasher_user
   * should be resolved by the conversion to pToken in
   * http://source/search?q=symbol:CreatePTokenFromSensitivity
   */
  accountProvenance?: QualityQrewriteAccountProvenance[];
  attentionalEntity?: SearchPolicyRankableSensitivityAttentionalEntity;
  /**
   * True iff the query is from a Dasher user.
   */
  dasherUser?: boolean;
  followon?: SearchPolicyRankableSensitivityFollowOn;
  groundingProvider?: SearchPolicyRankableSensitivityGroundingProvider;
  prefilter?: SearchPolicyRankableSensitivityPrefilter;
  qu?: SearchPolicyRankableSensitivityQueryUnderstanding;
  /**
   * Key of a sensitivity.
   */
  sensitivityMode?:  | "UNKNOWN" | "INIT" | "NONE" | "SEND_EMAIL" | "SEARCH_EMAIL" | "SENSITIVE_AOG_CONVERSATION" | "SMART_HOME_PROVIDE_PIN" | "SEARCH_DRIVE" | "READ_MESSAGE" | "SEND_MESSAGE" | "BROADCAST" | "CALL" | "NOTES_AND_LISTS" | "DEVICE_ACTIONS_AUTH" | "INTERPRETER_MODE" | "VOICE_MATCH_ENROLLMENT" | "REMINDERS" | "DESIGNED_FOR_FAMILY" | "CALENDAR" | "HEALTH_AND_FITNESS" | "MEDIA_PROVIDER_SPOTIFY" | "APP_ACTION_HEALTH" | "DG_HOME_FEED" | "SEARCH_GSUITE" | "ASSISTANT_SURVEY" | "ASSISTANT_MEMORY" | "DEPRECATED_SENSITIVE_HEALTH_CONVERSATION" | "DEPRECATED_READ_CALENDAR" | "DEPRECATED_WRITE_CALENDAR";
  syntheticIntent?: SearchPolicyRankableSensitivitySyntheticIntent;
  winningFulfillment?: SearchPolicyRankableSensitivityFulfillment;
}

function serializeSearchPolicyRankableSensitivity(data: any): SearchPolicyRankableSensitivity {
  return {
    ...data,
    accountProvenance: data["accountProvenance"] !== undefined ? data["accountProvenance"].map((item: any) => (serializeQualityQrewriteAccountProvenance(item))) : undefined,
  };
}

function deserializeSearchPolicyRankableSensitivity(data: any): SearchPolicyRankableSensitivity {
  return {
    ...data,
    accountProvenance: data["accountProvenance"] !== undefined ? data["accountProvenance"].map((item: any) => (deserializeQualityQrewriteAccountProvenance(item))) : undefined,
  };
}

/**
 * Attentional entities (AE) can be pulled from arguments of interpretations,
 * entities annotated by Aqua or QRef annotators, and entities mentioned in
 * Assistant's response and annotated by the fulfillment logic (see
 * https://g3doc.corp.google.com/quality/dialog_manager/attentional_entities/g3doc/overview.md#overview).
 * Sensitivity of AEs can be marked by (1) feature developers in a Monastery
 * frame, (2) code to infer the sensitivity from Argument provenance, and (3)
 * entity annotators, such as Aqua annotator and QRef annotator. See
 * go/sensitive-ae.
 */
export interface SearchPolicyRankableSensitivityAttentionalEntity {
  aeOrigin?:  | "UNKNOWN_ORIGIN" | "MONASTERY_VERTICAL_DEVELOPER" | "ARGUMENT_PROVENANCE";
}

/**
 * Sensitivity is marked at end of the last turn. See go/followon-sensitivity
 * for more details.
 */
export interface SearchPolicyRankableSensitivityFollowOn {
  /**
   * Should e2e search candidates running in parallel with QU (eg. GBot) be
   * blocked.
   */
  blockNonV2SearchBackends?: boolean;
  /**
   * Iff true this follow-on sensitivity will rank above the ones determined by
   * query understanding (QU).
   */
  ignoreQueryUnderstanding?: boolean;
}

/**
 * Marks that this sensitivity is from fulfillment.
 */
export interface SearchPolicyRankableSensitivityFulfillment {
}

/**
 * Marks that sensitivity is from a Grounding Provider.
 */
export interface SearchPolicyRankableSensitivityGroundingProvider {
}

/**
 * Deprecated, do not use.
 */
export interface SearchPolicyRankableSensitivityPrefilter {
  propagateOnly?: boolean;
}

/**
 * Sensitivity is produced by QU.
 */
export interface SearchPolicyRankableSensitivityQueryUnderstanding {
  /**
   * QU dectects a sensitive intent with no sensitive content (eg., [Send
   * email]). This flag is only used to trigger a sensitive feature because as a
   * precaution all sensitive features should check current sensitivity mode
   * before triggering; but will NOT block any backends, which means all other
   * features can compete fairly.
   */
  intentOnlyNoPii?: boolean;
  /**
   * The rewritten query this sensitivity is for. Note different query rewrites
   * could produce different sensitivities.
   */
  rewrittenQuery?: string;
}

/**
 * Marks that this sensitivity is from a synthetic intent.
 */
export interface SearchPolicyRankableSensitivitySyntheticIntent {
}

/**
 * Represents a principal who has authenticated as any kind of user which the
 * application understands. This is typically used for "wiki-like" security,
 * where anyone is allowed access so long as they can be held accountable for
 * that access. Since the purpose is knowing whom to blame, it is up to the
 * application to decide what kinds of users it knows how to blame. For example,
 * an application might choose to include GAIA users in "all authenticated
 * users", but not include MDB users. Nothing here.
 */
export interface SecurityCredentialsAllAuthenticatedUsersProto {
}

/**
 * Represents a principal which possesses a particular secret string whose
 * cryptographic hash is specified here. CapTokens ("Capability Tokens") are
 * used in ACLProto. It's expected that ACLs with CapTokenHolders will strongly
 * enforce them by Keystore-wrapping crypto keys for the corresponding
 * CapTokens.
 */
export interface SecurityCredentialsCapTokenHolderProto {
  /**
   * The hash of the corresponding capability token. The value is defined to be
   * identical to the one in acl.proto's CapTokenMetadata: 10-byte prefix of
   * HMAC-SHA1 of the token. The HMAC key is the following fixed (non-secret)
   * 512-bit value: 79b1c8f4 82baf523 b8a9ab4a e960f438 c45be041 11f1f222
   * e8a3f64d aeb05e3d c3576acc ec649194 aede422c 4e48e0d1 ff21234a a6ed6b49
   * a7fa592e efd7bba3
   */
  tokenHmacSha1Prefix?: Uint8Array;
}

function serializeSecurityCredentialsCapTokenHolderProto(data: any): SecurityCredentialsCapTokenHolderProto {
  return {
    ...data,
    tokenHmacSha1Prefix: data["tokenHmacSha1Prefix"] !== undefined ? encodeBase64(data["tokenHmacSha1Prefix"]) : undefined,
  };
}

function deserializeSecurityCredentialsCapTokenHolderProto(data: any): SecurityCredentialsCapTokenHolderProto {
  return {
    ...data,
    tokenHmacSha1Prefix: data["tokenHmacSha1Prefix"] !== undefined ? decodeBase64(data["tokenHmacSha1Prefix"] as string) : undefined,
  };
}

/**
 * Represents the invitees or other users associated with a Babel Chat (see
 * http://goto/babel). Corresponds to GroupType CHAT in
 * //social/graph/storage/proto/data.proto.
 */
export interface SecurityCredentialsChatProto {
  /**
   * Chat IDs consist of alphanumeric characters and colons. Currently
   * required.
   */
  chatId?: string;
  /**
   * The type of Chat members to consider, e.g. "all members" vs. "invitee"
   * These are defined by legacy_relation_id values in
   * social.graph.storage.EdgeTypeEnum.EdgeType enum options in
   * social/graph/storage/proto/id.proto. See chat.pb (defined in
   * production/config/cdd/socialgraph/mixer_config/prod/node_type_config) for
   * all valid edge types associated with chat. Currently required.
   */
  memberType?: number;
}

/**
 * Represents a Google+ Circle. Currently (12/2011), a Circle is identical to
 * the ContactGroup with matching parameters, but Circle must only be used for
 * true Circles and not other Focus groups, and should be preferred over
 * ContactGroup where applicable. Soon it may become more efficient to check
 * membership in a Circle than in a ContactGroup (see http://go/superglue).
 * Support for this principal type is currently (12/2011) incomplete -- e.g.,
 * Keystore does not support it yet (see b/5703421).
 */
export interface SecurityCredentialsCircleProto {
  /**
   * Circle ID is unique only relative to the owner's Gaia ID. Currently
   * required.
   */
  circleId?: bigint;
  /**
   * The owner of the circle. Currently required.
   */
  ownerGaiaId?: bigint;
  /**
   * If present, then tests for membership in this circle must use data known
   * to be at least as fresh as the given (FBS-assigned) timestamp. See
   * http://go/fbs-consistent-read-after-important-write Before using this, be
   * sure that any service checking authorization against this circle supports
   * checking consistency timestamps. For example, as of 12/2011, Keystore only
   * supports this for the Moonshine configuration, and in others authorization
   * checks will fail if the timestamp is present.
   */
  requiredConsistencyTimestampUsec?: bigint;
}

function serializeSecurityCredentialsCircleProto(data: any): SecurityCredentialsCircleProto {
  return {
    ...data,
    circleId: data["circleId"] !== undefined ? String(data["circleId"]) : undefined,
    ownerGaiaId: data["ownerGaiaId"] !== undefined ? String(data["ownerGaiaId"]) : undefined,
    requiredConsistencyTimestampUsec: data["requiredConsistencyTimestampUsec"] !== undefined ? String(data["requiredConsistencyTimestampUsec"]) : undefined,
  };
}

function deserializeSecurityCredentialsCircleProto(data: any): SecurityCredentialsCircleProto {
  return {
    ...data,
    circleId: data["circleId"] !== undefined ? BigInt(data["circleId"]) : undefined,
    ownerGaiaId: data["ownerGaiaId"] !== undefined ? BigInt(data["ownerGaiaId"]) : undefined,
    requiredConsistencyTimestampUsec: data["requiredConsistencyTimestampUsec"] !== undefined ? BigInt(data["requiredConsistencyTimestampUsec"]) : undefined,
  };
}

/**
 * Principal associated with a Cloud Principal representing third party user.
 */
export interface SecurityCredentialsCloudPrincipalProto {
  /**
   * Format: "{identity-pool}:{subject}#" Details:
   * go/cloud-principal-identifiers
   */
  id?: string;
}

/**
 * A group of contacts for a given user, as described in
 * http://cs/p#google3/focus/backend/proto/backend.proto Historically (and in
 * still-existing ACLs), this was used to represent Google+ circles as well as
 * contact groups, but this use is now deprecated. New code should use the
 * CIRCLE principal type to represent Google+ circles.
 */
export interface SecurityCredentialsContactGroupProto {
  /**
   * Group ID is unique only relative to the owner's Gaia ID.
   */
  groupId?: bigint;
  ownerGaiaId?: bigint;
  /**
   * If present, then tests for membership in this ContactGroup must use data
   * known to be at least as fresh as the given (FBS-assigned) timestamp. See
   * http://go/fbs-consistent-read-after-important-write Before using this, be
   * sure that any service checking authorization against this group supports
   * checking consistency timestamps. For example, as of 12/2011, Keystore only
   * supports this for the Moonshine configuration, and in others authorization
   * checks will fail if the timestamp is present.
   */
  requiredConsistencyTimestampUsec?: bigint;
}

function serializeSecurityCredentialsContactGroupProto(data: any): SecurityCredentialsContactGroupProto {
  return {
    ...data,
    groupId: data["groupId"] !== undefined ? String(data["groupId"]) : undefined,
    ownerGaiaId: data["ownerGaiaId"] !== undefined ? String(data["ownerGaiaId"]) : undefined,
    requiredConsistencyTimestampUsec: data["requiredConsistencyTimestampUsec"] !== undefined ? String(data["requiredConsistencyTimestampUsec"]) : undefined,
  };
}

function deserializeSecurityCredentialsContactGroupProto(data: any): SecurityCredentialsContactGroupProto {
  return {
    ...data,
    groupId: data["groupId"] !== undefined ? BigInt(data["groupId"]) : undefined,
    ownerGaiaId: data["ownerGaiaId"] !== undefined ? BigInt(data["ownerGaiaId"]) : undefined,
    requiredConsistencyTimestampUsec: data["requiredConsistencyTimestampUsec"] !== undefined ? BigInt(data["requiredConsistencyTimestampUsec"]) : undefined,
  };
}

/**
 * Represents a verified owner of the given email address. Note that a single
 * address may have many owners, and a single user may own many addresses. (All
 * lower-case, in display form -- see com.google.gaia.client.GaiaEmail)
 */
export interface SecurityCredentialsEmailOwnerProto {
  email?: string;
}

/**
 * Represents the invitees or other users associated with a Google+ Event (see
 * http://goto/events-backend-design).
 */
export interface SecurityCredentialsEventProto {
  /**
   * Event IDs consist of alphanumeric characters and colons. Currently
   * required.
   */
  eventId?: string;
  /**
   * The type of Event members to consider, e.g. "all members" vs. "owners" vs.
   * "admins". These are defined by legacy_relation_id values in
   * social.graph.storage.EdgeTypeEnum.EdgeType enum options in
   * social/graph/storage/proto/id.proto. See event.pb (defined in
   * production/config/cdd/socialgraph/mixer_config/prod/node_type_config) for
   * all valid edge types associated with event. Currently required.
   */
  memberType?: number;
}

export interface SecurityCredentialsGaiaGroupProto {
  groupId?: bigint;
}

function serializeSecurityCredentialsGaiaGroupProto(data: any): SecurityCredentialsGaiaGroupProto {
  return {
    ...data,
    groupId: data["groupId"] !== undefined ? String(data["groupId"]) : undefined,
  };
}

function deserializeSecurityCredentialsGaiaGroupProto(data: any): SecurityCredentialsGaiaGroupProto {
  return {
    ...data,
    groupId: data["groupId"] !== undefined ? BigInt(data["groupId"]) : undefined,
  };
}

/**
 * A Gaia account, which may represent a user, device, service account, etc.
 * For prod (@prod.google.com) accounts, use MdbUserProto instead.
 */
export interface SecurityCredentialsGaiaUserProto {
  userId?: bigint;
}

function serializeSecurityCredentialsGaiaUserProto(data: any): SecurityCredentialsGaiaUserProto {
  return {
    ...data,
    userId: data["userId"] !== undefined ? String(data["userId"]) : undefined,
  };
}

function deserializeSecurityCredentialsGaiaUserProto(data: any): SecurityCredentialsGaiaUserProto {
  return {
    ...data,
    userId: data["userId"] !== undefined ? BigInt(data["userId"]) : undefined,
  };
}

/**
 * Represents a single host. Optionally, the MDB owner of the host can be
 * specified.
 */
export interface SecurityCredentialsHostProto {
  /**
   * Lower-case, fully qualified hostname.
   */
  hostName?: string;
  /**
   * If present, then any checks that compare this Principal to LOAS peer info
   * must confirm the peer's machine owner is equal to 'host_owner'. If absent,
   * then any peer machine owner is acceptable.
   */
  hostOwner?: string;
}

export interface SecurityCredentialsLdapGroupProto {
  groupName?: string;
}

export interface SecurityCredentialsLdapUserProto {
  userName?: string;
}

/**
 * An entity from the MDB namespace that is to be interpreted as a group. If
 * using this for authorization, you should do an exact match of the peer role
 * against group_name or any of the names in the Chubby expansion of the MDB
 * group named group_name.
 */
export interface SecurityCredentialsMdbGroupProto {
  groupName?: string;
}

/**
 * An entity from the MDB namespace that is to be interpreted as a user. If
 * using this for authorization, you should only do an exact match on the peer
 * role against user_name.
 */
export interface SecurityCredentialsMdbUserProto {
  /**
   * Do not set this field. Contact credentials-eng@ if you believe you
   * absolutely need to use it. This is the @prod.google.com Gaia ID that
   * corresponds to the MDB user, see go/authn-merge for details. This field may
   * always be safely ignored when performing an authorization check.
   */
  gaiaId?: bigint;
  userName?: string;
}

function serializeSecurityCredentialsMdbUserProto(data: any): SecurityCredentialsMdbUserProto {
  return {
    ...data,
    gaiaId: data["gaiaId"] !== undefined ? String(data["gaiaId"]) : undefined,
  };
}

function deserializeSecurityCredentialsMdbUserProto(data: any): SecurityCredentialsMdbUserProto {
  return {
    ...data,
    gaiaId: data["gaiaId"] !== undefined ? BigInt(data["gaiaId"]) : undefined,
  };
}

/**
 * Represents an OAuth consumer, a/k/a AuthSub target. These principals are
 * identified by domain name (e.g., example.com). Historically, Dasher domain
 * GAIA group IDs have been used instead, but that doesn't work:
 * http://go/tricky-gaia-ids
 */
export interface SecurityCredentialsOAuthConsumerProto {
  domain?: string;
}

/**
 * See
 * http://s/?fileprint=//depot/google3/security/authentication/postini/auth_token.proto
 */
export interface SecurityCredentialsPostiniUserProto {
  postiniUserId?: bigint;
}

function serializeSecurityCredentialsPostiniUserProto(data: any): SecurityCredentialsPostiniUserProto {
  return {
    ...data,
    postiniUserId: data["postiniUserId"] !== undefined ? String(data["postiniUserId"]) : undefined,
  };
}

function deserializeSecurityCredentialsPostiniUserProto(data: any): SecurityCredentialsPostiniUserProto {
  return {
    ...data,
    postiniUserId: data["postiniUserId"] !== undefined ? BigInt(data["postiniUserId"]) : undefined,
  };
}

/**
 * A Principal represents something to which permissions are assigned, often
 * but not always a user or group of some kind. It is most appropriate for use
 * in ACLs and authorization checks. Callers should prefer to use the wrapper
 * classes in google3/security/credentials/public/principal.h
 * google3/java/com/google/security/credentials/Principal.java
 * google3/security/credentials/go/principal.go unless direct proto access is
 * essential. If you update this protocol buffer, please update the wrapper
 * classes as well. LINT.IfChange
 */
export interface SecurityCredentialsPrincipalProto {
  /**
   * scope = ALL_AUTHENTICATED_USERS
   */
  allAuthenticatedUsers?: SecurityCredentialsAllAuthenticatedUsersProto;
  /**
   * scope = CAP_TOKEN_HOLDER
   */
  capTokenHolder?: SecurityCredentialsCapTokenHolderProto;
  /**
   * scope = CHAT
   */
  chat?: SecurityCredentialsChatProto;
  /**
   * scope = CIRCLE
   */
  circle?: SecurityCredentialsCircleProto;
  /**
   * scope = CLOUD_PRINCIPAL
   */
  cloudPrincipal?: SecurityCredentialsCloudPrincipalProto;
  /**
   * scope = CONTACT_GROUP
   */
  contactGroup?: SecurityCredentialsContactGroupProto;
  /**
   * scope = EMAIL_OWNER
   */
  emailOwner?: SecurityCredentialsEmailOwnerProto;
  /**
   * scope = EVENT
   */
  event?: SecurityCredentialsEventProto;
  /**
   * scope = GAIA_GROUP
   */
  gaiaGroup?: SecurityCredentialsGaiaGroupProto;
  /**
   * scope = GAIA_USER
   */
  gaiaUser?: SecurityCredentialsGaiaUserProto;
  /**
   * scope = HOST
   */
  host?: SecurityCredentialsHostProto;
  /**
   * scope = LDAP_GROUP
   */
  ldapGroup?: SecurityCredentialsLdapGroupProto;
  /**
   * scope = LDAP_USER
   */
  ldapUser?: SecurityCredentialsLdapUserProto;
  /**
   * scope = MDB_GROUP
   */
  mdbGroup?: SecurityCredentialsMdbGroupProto;
  /**
   * scope = MDB_USER
   */
  mdbUser?: SecurityCredentialsMdbUserProto;
  /**
   * scope = OAUTH_CONSUMER;
   */
  oauthConsumer?: SecurityCredentialsOAuthConsumerProto;
  /**
   * scope = POSTINI_USER
   */
  postiniUser?: SecurityCredentialsPostiniUserProto;
  /**
   * scope = RBAC_ROLE
   */
  rbacRole?: SecurityCredentialsRbacRoleProto;
  /**
   * scope = RBAC_SUBJECT
   */
  rbacSubject?: SecurityCredentialsRbacSubjectProto;
  /**
   * scope = RESOURCE_ROLE
   */
  resourceRole?: SecurityCredentialsResourceRoleProto;
  /**
   * This is only optional because required enums cannot be extended. Currently
   * required.
   */
  scope?:  | "INVALID" | "GAIA_USER" | "GAIA_GROUP" | "LDAP_USER" | "LDAP_GROUP" | "MDB_USER" | "MDB_GROUP" | "POSTINI_USER" | "CONTACT_GROUP" | "SIMPLE_SECRET_HOLDER" | "SIGNING_KEY_POSSESSOR" | "ALL_AUTHENTICATED_USERS" | "OAUTH_CONSUMER" | "HOST" | "SOCIAL_GRAPH_NODE" | "EMAIL_OWNER" | "CAP_TOKEN_HOLDER" | "CIRCLE" | "SQUARE" | "EVENT" | "RESOURCE_ROLE" | "CHAT" | "YOUTUBE_USER" | "UNUSED_ZWIEBACK_SESSION" | "ZWIEBACK_SESSION" | "RBAC_ROLE" | "RBAC_SUBJECT" | "CLOUD_PRINCIPAL";
  /**
   * scope = SIGNING_KEY_POSSESSOR
   */
  signingKeyPossessor?: SecurityCredentialsSigningKeyPossessorProto;
  /**
   * scope = SIMPLE_SECRET_HOLDER
   */
  simpleSecretHolder?: SecurityCredentialsSimpleSecretHolderProto;
  /**
   * scope = SOCIAL_GRAPH_NODE
   */
  socialGraphNode?: SecurityCredentialsSocialGraphNodeProto;
  /**
   * scope = SQUARE
   */
  square?: SecurityCredentialsSquareProto;
  /**
   * scope = YOUTUBE_USER
   */
  youtubeUser?: SecurityCredentialsYoutubeUserProto;
  /**
   * scope = ZWIEBACK_SESSION
   */
  zwiebackSession?: SecurityCredentialsZwiebackSessionProto;
}

function serializeSecurityCredentialsPrincipalProto(data: any): SecurityCredentialsPrincipalProto {
  return {
    ...data,
    capTokenHolder: data["capTokenHolder"] !== undefined ? serializeSecurityCredentialsCapTokenHolderProto(data["capTokenHolder"]) : undefined,
    circle: data["circle"] !== undefined ? serializeSecurityCredentialsCircleProto(data["circle"]) : undefined,
    contactGroup: data["contactGroup"] !== undefined ? serializeSecurityCredentialsContactGroupProto(data["contactGroup"]) : undefined,
    gaiaGroup: data["gaiaGroup"] !== undefined ? serializeSecurityCredentialsGaiaGroupProto(data["gaiaGroup"]) : undefined,
    gaiaUser: data["gaiaUser"] !== undefined ? serializeSecurityCredentialsGaiaUserProto(data["gaiaUser"]) : undefined,
    mdbUser: data["mdbUser"] !== undefined ? serializeSecurityCredentialsMdbUserProto(data["mdbUser"]) : undefined,
    postiniUser: data["postiniUser"] !== undefined ? serializeSecurityCredentialsPostiniUserProto(data["postiniUser"]) : undefined,
    signingKeyPossessor: data["signingKeyPossessor"] !== undefined ? serializeSecurityCredentialsSigningKeyPossessorProto(data["signingKeyPossessor"]) : undefined,
    simpleSecretHolder: data["simpleSecretHolder"] !== undefined ? serializeSecurityCredentialsSimpleSecretHolderProto(data["simpleSecretHolder"]) : undefined,
    square: data["square"] !== undefined ? serializeSecurityCredentialsSquareProto(data["square"]) : undefined,
    youtubeUser: data["youtubeUser"] !== undefined ? serializeSecurityCredentialsYoutubeUserProto(data["youtubeUser"]) : undefined,
    zwiebackSession: data["zwiebackSession"] !== undefined ? serializeSecurityCredentialsZwiebackSessionProto(data["zwiebackSession"]) : undefined,
  };
}

function deserializeSecurityCredentialsPrincipalProto(data: any): SecurityCredentialsPrincipalProto {
  return {
    ...data,
    capTokenHolder: data["capTokenHolder"] !== undefined ? deserializeSecurityCredentialsCapTokenHolderProto(data["capTokenHolder"]) : undefined,
    circle: data["circle"] !== undefined ? deserializeSecurityCredentialsCircleProto(data["circle"]) : undefined,
    contactGroup: data["contactGroup"] !== undefined ? deserializeSecurityCredentialsContactGroupProto(data["contactGroup"]) : undefined,
    gaiaGroup: data["gaiaGroup"] !== undefined ? deserializeSecurityCredentialsGaiaGroupProto(data["gaiaGroup"]) : undefined,
    gaiaUser: data["gaiaUser"] !== undefined ? deserializeSecurityCredentialsGaiaUserProto(data["gaiaUser"]) : undefined,
    mdbUser: data["mdbUser"] !== undefined ? deserializeSecurityCredentialsMdbUserProto(data["mdbUser"]) : undefined,
    postiniUser: data["postiniUser"] !== undefined ? deserializeSecurityCredentialsPostiniUserProto(data["postiniUser"]) : undefined,
    signingKeyPossessor: data["signingKeyPossessor"] !== undefined ? deserializeSecurityCredentialsSigningKeyPossessorProto(data["signingKeyPossessor"]) : undefined,
    simpleSecretHolder: data["simpleSecretHolder"] !== undefined ? deserializeSecurityCredentialsSimpleSecretHolderProto(data["simpleSecretHolder"]) : undefined,
    square: data["square"] !== undefined ? deserializeSecurityCredentialsSquareProto(data["square"]) : undefined,
    youtubeUser: data["youtubeUser"] !== undefined ? deserializeSecurityCredentialsYoutubeUserProto(data["youtubeUser"]) : undefined,
    zwiebackSession: data["zwiebackSession"] !== undefined ? deserializeSecurityCredentialsZwiebackSessionProto(data["zwiebackSession"]) : undefined,
  };
}

/**
 * Principal associated with a given RBAC role. This principal is used by
 * Sphinx Provisioning Service for RBAC provisionable (go/sphinx-rbacz).
 */
export interface SecurityCredentialsRbacRoleProto {
  name?: string;
  objectId?: string;
  /**
   * DEPRECATED as of 01.11.2019
   */
  rbacNamespace?: string;
  /**
   * Format: "role/z?" - "role" is the Sphinx globally unique name of the
   * Sphinx role that provisions the RBAC role. - "/z?" suffix indicates which
   * Zanzibar environment stores the role membership data ("/zd": dev, "/zs":
   * staging, "/zp": prod, "/zt": local test instance). Example:
   * "mysystem_myrole/zp"
   */
  rbacRoleName?: string;
}

/**
 * Principal associated with a given RBAC subject. This principal is used by
 * Sphinx Provisioning Service for RBAC provisionable (go/sphinx-rbacz).
 */
export interface SecurityCredentialsRbacSubjectProto {
  /**
   * Format "username" without "@domain", e.g., "bogdand".
   */
  username?: string;
}

/**
 * A type of sharing target that points to some resource's ACL. Used to refer
 * to the set of Principals that have the given privilege ('role_id') for the
 * given resource ('application_id', 'object_id', 'object_part'). The meaning of
 * 'role_id' is interpreted only by implementations of AclRpcService and is
 * usually dependent on 'application_id' All fields except object_part are
 * required. If present, object_part must be non-empty.
 */
export interface SecurityCredentialsResourceRoleProto {
  applicationId?: string;
  objectId?: string;
  objectPart?: string;
  roleId?: number;
}

/**
 * Represents a principal who possesses a signing key corresponding to the
 * verification key or keyset described here.
 */
export interface SecurityCredentialsSigningKeyPossessorProto {
  /**
   * This value must be from the KeyMetadata.Type enum in keymaster.proto.
   */
  keymasterKeyType?: number;
  /**
   * The actual verification key bytes corresponding to the above type.
   */
  serializedVerificationKey?: Uint8Array;
  /**
   * The binary serialized Keymaster SerializedReader of a public keyset. The
   * keyset must contain exactly one key. N.B.: If this field is populated,
   * serialized_verification_key should be set to the empty string and
   * keymaster_key_type should be set to zero.
   */
  serializedVerificationKeyset?: Uint8Array;
}

function serializeSecurityCredentialsSigningKeyPossessorProto(data: any): SecurityCredentialsSigningKeyPossessorProto {
  return {
    ...data,
    serializedVerificationKey: data["serializedVerificationKey"] !== undefined ? encodeBase64(data["serializedVerificationKey"]) : undefined,
    serializedVerificationKeyset: data["serializedVerificationKeyset"] !== undefined ? encodeBase64(data["serializedVerificationKeyset"]) : undefined,
  };
}

function deserializeSecurityCredentialsSigningKeyPossessorProto(data: any): SecurityCredentialsSigningKeyPossessorProto {
  return {
    ...data,
    serializedVerificationKey: data["serializedVerificationKey"] !== undefined ? decodeBase64(data["serializedVerificationKey"] as string) : undefined,
    serializedVerificationKeyset: data["serializedVerificationKeyset"] !== undefined ? decodeBase64(data["serializedVerificationKeyset"] as string) : undefined,
  };
}

/**
 * Represents a principal which possesses a particular, presumably secret,
 * string. Useful for things like "auth keys," used for anonymous sharing. Since
 * representing this principal with the actual secret included reveals the
 * secret, it's best if the requisite condition is enforced in some other way,
 * for example via Keystore wrapping attributes (Keystore will unwrap only if
 * the specified secret, aka "attribute", is presented). All that's stored here
 * is an identifying label.
 */
export interface SecurityCredentialsSimpleSecretHolderProto {
  /**
   * A descriptive label to help identify a relevant ACL entry or otherwise
   * disambiguate this instance.
   */
  label?: SecurityCredentialsSimpleSecretLabelProto;
}

function serializeSecurityCredentialsSimpleSecretHolderProto(data: any): SecurityCredentialsSimpleSecretHolderProto {
  return {
    ...data,
    label: data["label"] !== undefined ? serializeSecurityCredentialsSimpleSecretLabelProto(data["label"]) : undefined,
  };
}

function deserializeSecurityCredentialsSimpleSecretHolderProto(data: any): SecurityCredentialsSimpleSecretHolderProto {
  return {
    ...data,
    label: data["label"] !== undefined ? deserializeSecurityCredentialsSimpleSecretLabelProto(data["label"]) : undefined,
  };
}

/**
 * SimpleSecretProto (in authenticator.proto) and SimpleSecretHolderProto
 * (below) share the notion of a "label", which identifies a particular secret
 * without (hopefully) revealing the secret. Note that a SimpleSecretLabel only
 * disambiguates between secrets used to get access to some particular object.
 * Two different secrets that apply to two different objects could have the same
 * label. For example, in the common sharing model, each object has no more than
 * one "auth key". Therefore, the label for an auth key simply has type =
 * AUTH_KEY with no additional information. In theory, we could add some sort of
 * resource ID to SimpleSecretLabel to make it more explicit. However, in
 * practice, this is never really needed. A SimpleSecret for one object is never
 * used to authorize a request on some other object, so there is no ambiguity.
 * Also, since SimpleSecrets must obviously be unguessable, there is no risk
 * that a SimpleSecret intended for one object will accidentally grant access to
 * another.
 */
export interface SecurityCredentialsSimpleSecretLabelProto {
  /**
   * ***DEPRECATED (3-Oct-2011) *** This field should be deleted when code
   * stops using CAP_TOKEN labels. Used when type = CAP_TOKEN. When a CAP_TOKEN
   * label appears in a SimpleSecretHolder Principal, |capability_id| must be
   * filled in to identify one of the capabilities on the ACL. When a CAP_TOKEN
   * label appears in a SimpleSecret Authenticator, it is NOT necessary to fill
   * in |capability_id| -- ACL Service will find the ID by searching all
   * capabilities on the ACL for one associated with the token given by the
   * SimpleSecret's secret data. If |capability_id| is specified, though, then
   * the Authenticator will only be accepted if it actually matches that
   * particular token ID.
   */
  capabilityId?: number;
  /**
   * Used when type = GENERIC_SECRET
   */
  genericLabel?: Uint8Array;
  /**
   * Used when type == INVITE.
   */
  inviteId?: bigint;
  /**
   * This is optional because required enums cannot be extended.
   */
  type?:  | "INVALID" | "AUTH_KEY" | "INVITE" | "GENERIC_SECRET" | "CAP_TOKEN" | "REKE";
}

function serializeSecurityCredentialsSimpleSecretLabelProto(data: any): SecurityCredentialsSimpleSecretLabelProto {
  return {
    ...data,
    genericLabel: data["genericLabel"] !== undefined ? encodeBase64(data["genericLabel"]) : undefined,
    inviteId: data["inviteId"] !== undefined ? String(data["inviteId"]) : undefined,
  };
}

function deserializeSecurityCredentialsSimpleSecretLabelProto(data: any): SecurityCredentialsSimpleSecretLabelProto {
  return {
    ...data,
    genericLabel: data["genericLabel"] !== undefined ? decodeBase64(data["genericLabel"] as string) : undefined,
    inviteId: data["inviteId"] !== undefined ? BigInt(data["inviteId"]) : undefined,
  };
}

/**
 * Represents a user pseudonym. Pseudonyms are linked accounts on Google and
 * third-party services (e.g. YouTube or Twitter) and are described by a Social
 * Graph Node.
 */
export interface SecurityCredentialsSocialGraphNodeProto {
  /**
   * The fields from ccc/socialgraph/socialgraphnode.proto:SgnNode that
   * uniquely identify a social graph node. The 'ident' field is not included
   * here because its value can be changed.
   */
  sgnDomain?: string;
  sgnPk?: string;
}

/**
 * Represents the set of members (of a given type) in a Google+ Square (see
 * http://go/squares). A Square with default member_type is currently (1/2012)
 * identical to the GaiaGroup with the same ID, but that is expected to change
 * soon (see http://go/superglue). Support for this principal type is currently
 * (1/2012) incomplete -- e.g., Keystore does not support it yet (see
 * b/5703421).
 */
export interface SecurityCredentialsSquareProto {
  /**
   * The type of Square members to consider, e.g. "all members" vs. "owners"
   * vs. "admins". These are defined by legacy_relation_id values in
   * social.graph.storage.EdgeTypeEnum.EdgeType enum options in
   * social/graph/storage/proto/id.proto. See square.pb (defined in
   * production/config/cdd/socialgraph/mixer_config/prod/node_type_config) for
   * all valid edge types associated with square. Currently required.
   */
  memberType?: number;
  /**
   * Currently required.
   */
  squareId?: bigint;
}

function serializeSecurityCredentialsSquareProto(data: any): SecurityCredentialsSquareProto {
  return {
    ...data,
    squareId: data["squareId"] !== undefined ? String(data["squareId"]) : undefined,
  };
}

function deserializeSecurityCredentialsSquareProto(data: any): SecurityCredentialsSquareProto {
  return {
    ...data,
    squareId: data["squareId"] !== undefined ? BigInt(data["squareId"]) : undefined,
  };
}

export interface SecurityCredentialsYoutubeUserProto {
  youtubeUserId?: bigint;
}

function serializeSecurityCredentialsYoutubeUserProto(data: any): SecurityCredentialsYoutubeUserProto {
  return {
    ...data,
    youtubeUserId: data["youtubeUserId"] !== undefined ? String(data["youtubeUserId"]) : undefined,
  };
}

function deserializeSecurityCredentialsYoutubeUserProto(data: any): SecurityCredentialsYoutubeUserProto {
  return {
    ...data,
    youtubeUserId: data["youtubeUserId"] !== undefined ? BigInt(data["youtubeUserId"]) : undefined,
  };
}

/**
 * See go/zwieback. New uses of Zwieback sessions must be approved via
 * go/zwieback-request.
 */
export interface SecurityCredentialsZwiebackSessionProto {
  zwiebackSessionId?: bigint;
}

function serializeSecurityCredentialsZwiebackSessionProto(data: any): SecurityCredentialsZwiebackSessionProto {
  return {
    ...data,
    zwiebackSessionId: data["zwiebackSessionId"] !== undefined ? String(data["zwiebackSessionId"]) : undefined,
  };
}

function deserializeSecurityCredentialsZwiebackSessionProto(data: any): SecurityCredentialsZwiebackSessionProto {
  return {
    ...data,
    zwiebackSessionId: data["zwiebackSessionId"] !== undefined ? BigInt(data["zwiebackSessionId"]) : undefined,
  };
}

/**
 * Sentence boundaries.
 */
export interface SentenceBoundaryAnnotations {
  /**
   * Used for application-specific information about the whole set of
   * SentenceBoundaryAnnotations. Example: SAFT Team uses this to store an
   * nlp_saft.Document proto giving any processing errors encountered.
   */
  info?: Proto2BridgeMessageSet;
  instance?: SentenceBoundaryAnnotationsInstance[];
}

export interface SentenceBoundaryAnnotationsInstance {
  begin?: number;
  /**
   * A clean version of .text() generated by using CleanText() and stripping
   * unnecessary whitespace.
   */
  cleanText?: string;
  /**
   * Plain text context from the page within which the annotation occurred.
   */
  context?: string;
  /**
   * Byte offsets for the clean text context above.
   */
  contextBegin?: number;
  contextEnd?: number;
  end?: number;
  /**
   * Used for application-specific information about this annotation.
   */
  info?: Proto2BridgeMessageSet;
  /**
   * Original UTF-8 document text occurring in the range [begin, end).
   */
  text?: string;
  /**
   * Used to mark the annotations selected to be indexed.
   */
  toIndex?: boolean;
}

/**
 * This proto contains the sentiment and emotions that the user is exhibiting
 * at the time of the query. NEXT ID: 4
 */
export interface SentimentSentiment {
  /**
   * Polarity represents the sentiment towards the subject.
   */
  polarity?:  | "UNKNOWN" | "VERY_POSITIVE" | "POSITIVE" | "NEUTRAL" | "NEGATIVE" | "VERY_NEGATIVE";
  userBehaviors?: SentimentSentimentBehaviors;
  /**
   * The emotions that the user is feeling.
   */
  userEmotions?: SentimentSentimentEmotions;
}

/**
 * The set of behavior signals that the user is expressing/demonstrating that
 * is detected by the sentiment analysis. These signals are used to help
 * assistant determine the proper response behavior. NEXT ID = 2
 */
export interface SentimentSentimentBehaviors {
  /**
   * The degree to which the user is showing politeness.
   */
  politeness?: number;
}

/**
 * Basic emotions. NEXT ID: 7
 */
export interface SentimentSentimentEmotions {
  anger?: number;
  disgust?: number;
  fear?: number;
  happiness?: number;
  sadness?: number;
  surprise?: number;
}

/**
 * This message represents shingle-related information obtained from a
 * document.
 */
export interface ShingleInfoPerDocData {
  /**
   * Total number of shingles in the document.
   */
  numShingles?: number;
  /**
   * A list of all sources.
   */
  source?: ShingleSource[];
}

/**
 * This message represents a source of shingles. Used by ShingleInfoPerDocData.
 */
export interface ShingleSource {
  /**
   * Hash-value of the URL.
   */
  id?: number;
  /**
   * Number of shingles originating from this source.
   */
  numShingles?: number;
  /**
   * First-seen timestamp of the source.
   */
  timestamp?: number;
}

/**
 * Images inferred from context instead of propagated from Shopping backends.
 * The same image might be inferred via different means; then it may appear
 * multiple times in Offer.inferred_images list with different values of
 * inferred_image_type field.
 */
export interface ShoppingWebentityShoppingAnnotationInferredImage {
  inferredImageId?: bigint;
  inferredImageSource?:  | "INFERRED_IMAGE_SOURCE_UNKNOWN" | "INFERRED_IMAGE_SOURCE_WEB_INDEX" | "INFERRED_IMAGE_SOURCE_OVERLAY" | "INFERRED_IMAGE_SOURCE_SCARAB";
  inferredImageType?:  | "INFERRED_IMAGE_TYPE_UNKNOWN" | "INFERRED_IMAGE_TYPE_NEARDUP_STARBURST_V3" | "INFERRED_IMAGE_TYPE_STRIDE_EXTRACTION" | "INFERRED_IMAGE_TYPE_CRAWLED_OFFER_DUPLICATE" | "INFERRED_IMAGE_TYPE_NEARDUP_FOR_INFERRED_IMAGES" | "INFERRED_IMAGE_TYPE_OTHER_ML_MATCHED_IMAGES" | "INFERRED_IMAGE_TYPE_PRODUCT_BLOCKS" | "INFERRED_IMAGE_TYPE_SCHEMA_DOT_ORG" | "INFERRED_IMAGE_TYPE_CRAWZALL" | "INFERRED_IMAGE_TYPE_OPEN_GRAPH";
  /**
   * This field will only be populated if the inferred image is a neardup of an
   * inferred image. It stores the type and source of the images it is a neardup
   * of.
   */
  neardupInfo?: ShoppingWebentityShoppingAnnotationInferredImageNeardupInfo[];
}

function serializeShoppingWebentityShoppingAnnotationInferredImage(data: any): ShoppingWebentityShoppingAnnotationInferredImage {
  return {
    ...data,
    inferredImageId: data["inferredImageId"] !== undefined ? String(data["inferredImageId"]) : undefined,
  };
}

function deserializeShoppingWebentityShoppingAnnotationInferredImage(data: any): ShoppingWebentityShoppingAnnotationInferredImage {
  return {
    ...data,
    inferredImageId: data["inferredImageId"] !== undefined ? BigInt(data["inferredImageId"]) : undefined,
  };
}

export interface ShoppingWebentityShoppingAnnotationInferredImageNeardupInfo {
  inferredImageSource?:  | "INFERRED_IMAGE_SOURCE_UNKNOWN" | "INFERRED_IMAGE_SOURCE_WEB_INDEX" | "INFERRED_IMAGE_SOURCE_OVERLAY" | "INFERRED_IMAGE_SOURCE_SCARAB";
  inferredImageType?:  | "INFERRED_IMAGE_TYPE_UNKNOWN" | "INFERRED_IMAGE_TYPE_NEARDUP_STARBURST_V3" | "INFERRED_IMAGE_TYPE_STRIDE_EXTRACTION" | "INFERRED_IMAGE_TYPE_CRAWLED_OFFER_DUPLICATE" | "INFERRED_IMAGE_TYPE_NEARDUP_FOR_INFERRED_IMAGES" | "INFERRED_IMAGE_TYPE_OTHER_ML_MATCHED_IMAGES" | "INFERRED_IMAGE_TYPE_PRODUCT_BLOCKS" | "INFERRED_IMAGE_TYPE_SCHEMA_DOT_ORG" | "INFERRED_IMAGE_TYPE_CRAWZALL" | "INFERRED_IMAGE_TYPE_OPEN_GRAPH";
}

/**
 * Information about a rating provided for a product. This can represent an
 * aggregated rating if count is set. Next Id: 7
 */
export interface ShoppingWebentityShoppingAnnotationProductRating {
  /**
   * Number of ratings/reviews aggregated to create this product rating. If
   * there are no ratings yet, this field will be explicitly set to zero, so
   * whether this field is set should be checked using has_count.
   */
  count?: bigint;
  maxValueMillis?: bigint;
  /**
   * The lower and upper bounds of the rating values that could be submitted
   * for the product. (Note that it is not the min/max ratings submitted for the
   * product, it is the min/max that can hypothetically be submitted.)
   */
  minValueMillis?: bigint;
  source?:  | "PRODUCT_RATING_SOURCE_UNKNOWN" | "PRODUCT_RATING_SOURCE_CRAWLED_DATA";
  /**
   * The value of this rating normalized between 0 and 5. This will not be set
   * if count is set to 0.
   */
  value?: number;
  /**
   * The non-normalized aggregated value of the ratings for this product.
   */
  valueMillis?: bigint;
}

function serializeShoppingWebentityShoppingAnnotationProductRating(data: any): ShoppingWebentityShoppingAnnotationProductRating {
  return {
    ...data,
    count: data["count"] !== undefined ? String(data["count"]) : undefined,
    maxValueMillis: data["maxValueMillis"] !== undefined ? String(data["maxValueMillis"]) : undefined,
    minValueMillis: data["minValueMillis"] !== undefined ? String(data["minValueMillis"]) : undefined,
    valueMillis: data["valueMillis"] !== undefined ? String(data["valueMillis"]) : undefined,
  };
}

function deserializeShoppingWebentityShoppingAnnotationProductRating(data: any): ShoppingWebentityShoppingAnnotationProductRating {
  return {
    ...data,
    count: data["count"] !== undefined ? BigInt(data["count"]) : undefined,
    maxValueMillis: data["maxValueMillis"] !== undefined ? BigInt(data["maxValueMillis"]) : undefined,
    minValueMillis: data["minValueMillis"] !== undefined ? BigInt(data["minValueMillis"]) : undefined,
    valueMillis: data["valueMillis"] !== undefined ? BigInt(data["valueMillis"]) : undefined,
  };
}

/**
 * Versioning Information used for Logging Purposes. See go/sori-logjoining.
 */
export interface ShoppingWebentityShoppingAnnotationSoriVersionId {
  f1CommitTimestampMicros?: bigint;
  opaqueSoriId?: AdsShoppingReportingOffersSerializedSoriId;
}

function serializeShoppingWebentityShoppingAnnotationSoriVersionId(data: any): ShoppingWebentityShoppingAnnotationSoriVersionId {
  return {
    ...data,
    f1CommitTimestampMicros: data["f1CommitTimestampMicros"] !== undefined ? String(data["f1CommitTimestampMicros"]) : undefined,
    opaqueSoriId: data["opaqueSoriId"] !== undefined ? serializeAdsShoppingReportingOffersSerializedSoriId(data["opaqueSoriId"]) : undefined,
  };
}

function deserializeShoppingWebentityShoppingAnnotationSoriVersionId(data: any): ShoppingWebentityShoppingAnnotationSoriVersionId {
  return {
    ...data,
    f1CommitTimestampMicros: data["f1CommitTimestampMicros"] !== undefined ? BigInt(data["f1CommitTimestampMicros"]) : undefined,
    opaqueSoriId: data["opaqueSoriId"] !== undefined ? deserializeAdsShoppingReportingOffersSerializedSoriId(data["opaqueSoriId"]) : undefined,
  };
}

/**
 * Note: If you are going to populate any new field in this proto, you probably
 * need to go through the go/dj-new-field and go/index-changes process.
 */
export interface Sitemap {
  /**
   * DEPRECATED DEPRECATED DEPRECATED In case you didn't realize, these fields
   * are (and have been for some time) deprecated. We'll stop pushing their data
   * to production soon (probably Feb/09) and after a few weeks we'll probably
   * remove them.
   */
  DEPRECATEDSourceTitle?: string;
  deprecatedTarget?: SitemapDEPRECATED_Target[];
  /**
   * This field is populated in the Sitemap MDU subpopulator from cdoc data.
   * This is used to store page anchors information for TopicTagsScrolltoFlow.
   */
  pageAnchorsDocInfo?: SdrPageAnchorsDocInfo;
  /**
   * Enable site search.
   */
  searchInSite?: boolean;
  sitemapType?:  | "ORIGINAL" | "EXPANDED" | "TABLE_OF_CONTENTS" | "WEBANSWER";
  /**
   * prevents cross-domain forwarding
   */
  sourceOrgfp?: bigint;
  sourceUrl?: string;
  /**
   * This field is populated in the Sitemap MDU subpopulator from cdoc data.
   * It's not set in the cdoc Sitemap.
   */
  subresultList?: QualitySitemapSubresultList;
  /**
   * One Sitemap can contain multiple TargetGroups, but only one of them will
   * be displayed to the user - this decision will be made at displaying time
   * and can take into account various factors, such as the users' language and
   * country, currently running experiments, etc.
   */
  TargetGroups?: QualitySitemapTargetGroup[];
}

function serializeSitemap(data: any): Sitemap {
  return {
    ...data,
    pageAnchorsDocInfo: data["pageAnchorsDocInfo"] !== undefined ? serializeSdrPageAnchorsDocInfo(data["pageAnchorsDocInfo"]) : undefined,
    sourceOrgfp: data["sourceOrgfp"] !== undefined ? String(data["sourceOrgfp"]) : undefined,
    subresultList: data["subresultList"] !== undefined ? serializeQualitySitemapSubresultList(data["subresultList"]) : undefined,
    TargetGroups: data["TargetGroups"] !== undefined ? data["TargetGroups"].map((item: any) => (serializeQualitySitemapTargetGroup(item))) : undefined,
  };
}

function deserializeSitemap(data: any): Sitemap {
  return {
    ...data,
    pageAnchorsDocInfo: data["pageAnchorsDocInfo"] !== undefined ? deserializeSdrPageAnchorsDocInfo(data["pageAnchorsDocInfo"]) : undefined,
    sourceOrgfp: data["sourceOrgfp"] !== undefined ? BigInt(data["sourceOrgfp"]) : undefined,
    subresultList: data["subresultList"] !== undefined ? deserializeQualitySitemapSubresultList(data["subresultList"]) : undefined,
    TargetGroups: data["TargetGroups"] !== undefined ? data["TargetGroups"].map((item: any) => (deserializeQualitySitemapTargetGroup(item))) : undefined,
  };
}

export interface SitemapDEPRECATED_Target {
  DEPRECATEDAnchor?: string;
  DEPRECATEDRunningAnchor?: boolean;
  DEPRECATEDTitle?: string;
  displaytitle?: string;
  /**
   * optional, exclude to save space
   */
  score?: number;
  url?: string;
}

/**
 * This message is used for storing smartphone related information. Note:
 * MobilePerDocData is a similar message, but it's for lowend mobile.
 */
export interface SmartphonePerDocData {
  /**
   * Indicates if the page is violating mobile ads density interstitial policy
   * and the violation strength. See go/interstitials-for-ads and
   * http://ariane/268642 for details. To save indexing space, we convert the
   * double values in [0.0, 1.0] to intergers in range [0, 1000] by using
   * floor(value * 1000).
   */
  adsDensityInterstitialViolationStrength?: number;
  /**
   * If set, this page is a smartphone dup, a page serving equivalent contents
   * as another URL (desktop canonical), but in smartphone-optimized style. This
   * field holds the docid of the desktop canonical.
   */
  DEPRECATEDDesktopCanonicalDocid?: bigint;
  /**
   * Mobile URL for homepages, predicted by the URL rewrite rules. See
   * go/mobile-homepage-prediction.
   */
  DEPRECATEDMobileHomepageDocid?: bigint;
  /**
   * Indicates if the page serves error to smartphone crawler.
   * go/ramsey-sp404demotion
   */
  isErrorPage?: boolean;
  /**
   * Indicates if the page has mobile N-1 redirection. go/ramsey-n1demotion
   */
  isN1Redirect?: boolean;
  /**
   * Indicates if the page is rendered in a friendly manner on smartphones. We
   * use this field as tri-state: "unset" means the rendering result
   * classification is not available, and "set as false" means that the page is
   * rendered in unfriendly manner on smartphones. See also go/modena-ranking.
   */
  isSmartphoneOptimized?: boolean;
  /**
   * Indicates if the current URL serves error page to desktop crawler and non
   * error page to smartphone crawler.
   */
  isWebErrorMobileContent?: boolean;
  /**
   * The ratio of the area of the largest Flash to the render area.
   */
  maximumFlashRatio?: number;
  /**
   * Mobile friendliness score in the range of [0, 100]. See go/modena-ranking.
   */
  mobileFriendlyScore?: number;
  /**
   * Indicates if the page is violating mobile interstitial policy and should
   * be demoted. See go/interstitials-ranking-dd for details.
   */
  violatesMobileInterstitialPolicy?: boolean;
}

function serializeSmartphonePerDocData(data: any): SmartphonePerDocData {
  return {
    ...data,
    DEPRECATEDDesktopCanonicalDocid: data["DEPRECATEDDesktopCanonicalDocid"] !== undefined ? String(data["DEPRECATEDDesktopCanonicalDocid"]) : undefined,
    DEPRECATEDMobileHomepageDocid: data["DEPRECATEDMobileHomepageDocid"] !== undefined ? String(data["DEPRECATEDMobileHomepageDocid"]) : undefined,
  };
}

function deserializeSmartphonePerDocData(data: any): SmartphonePerDocData {
  return {
    ...data,
    DEPRECATEDDesktopCanonicalDocid: data["DEPRECATEDDesktopCanonicalDocid"] !== undefined ? BigInt(data["DEPRECATEDDesktopCanonicalDocid"]) : undefined,
    DEPRECATEDMobileHomepageDocid: data["DEPRECATEDMobileHomepageDocid"] !== undefined ? BigInt(data["DEPRECATEDMobileHomepageDocid"]) : undefined,
  };
}

/**
 * For legacy purposes, cdocs contain a repeated list of *Entry, whereas it's
 * more convenient elsewhere to contain this information within its own protocol
 * buffer.
 */
export interface SmearedWebLandingPageEntry {
  /**
   * Source imagesearch docid
   */
  imagesearchDocid?: bigint;
  /**
   * Docid of web landing page
   */
  webDocid?: bigint;
}

function serializeSmearedWebLandingPageEntry(data: any): SmearedWebLandingPageEntry {
  return {
    ...data,
    imagesearchDocid: data["imagesearchDocid"] !== undefined ? String(data["imagesearchDocid"]) : undefined,
    webDocid: data["webDocid"] !== undefined ? String(data["webDocid"]) : undefined,
  };
}

function deserializeSmearedWebLandingPageEntry(data: any): SmearedWebLandingPageEntry {
  return {
    ...data,
    imagesearchDocid: data["imagesearchDocid"] !== undefined ? BigInt(data["imagesearchDocid"]) : undefined,
    webDocid: data["webDocid"] !== undefined ? BigInt(data["webDocid"]) : undefined,
  };
}

/**
 * A simple 2D box represented by an (x, y) co-ordinate, width and height.
 * Copied from htmlrender_webkit_headless_proto.Document to avoid additional
 * dependency.
 */
export interface SnapshotBox {
  height?: number;
  width?: number;
  x?: number;
  y?: number;
}

export interface SnapshotImageNode {
  boundingBox?: SnapshotBox;
  /**
   * An image is considered external iff both: 1. The image appears in a link
   * that is not in the same org as the document, or the target URL is in a
   * different org. 2. The image src is not in the same org as the document.
   */
  isExternal?: boolean;
  /**
   * The absolute url of the image as present in the page.
   */
  url?: string;
}

export interface SnapshotSnapshotDocument {
  imageNode?: SnapshotImageNode[];
  metaNoPreview?: boolean;
  /**
   * These are set from tags in the web page:
   */
  metaNoSnippet?: boolean;
  /**
   * If this is present it supercedes all the above data.
   */
  teradoc?: TeragoogleDocumentInfo;
  textNode?: SnapshotTextNode[];
  title?: string;
}

function serializeSnapshotSnapshotDocument(data: any): SnapshotSnapshotDocument {
  return {
    ...data,
    teradoc: data["teradoc"] !== undefined ? serializeTeragoogleDocumentInfo(data["teradoc"]) : undefined,
  };
}

function deserializeSnapshotSnapshotDocument(data: any): SnapshotSnapshotDocument {
  return {
    ...data,
    teradoc: data["teradoc"] !== undefined ? deserializeTeragoogleDocumentInfo(data["teradoc"]) : undefined,
  };
}

export interface SnapshotSnapshotMetadata {
  /**
   * The number of distinct resources fetched to render the content. This may
   * aid the calculation of total page load time for user experience. For
   * example, if total_content_length is only a few dozen kilobytes, but that is
   * from fetching 100 distinct resources, total page load time might be much
   * higher than the total_content_length would otherwise infer.
   */
  countDistinctResources?: number;
  /**
   * The time at which the main resource of the Snapshot was fetched, in
   * seconds since epoch. Note that the various page dependencies may have been
   * fetched at much earlier points in time (hours, maybe days) and that this
   * could be off from the actual rendering time.
   */
  crawlTimestamp?: bigint;
  snapshotDocument?: SnapshotSnapshotDocument;
  /**
   * The score here corresponds to the score in Snapshot, a number between 0.0
   * and 1.0 (higher the better).
   */
  snapshotQualityScore?: number;
  /**
   * Number of bytes fetched to render the content. For example, to render a
   * web page, this value would include the HTML, stylesheets, images, and all
   * other dependencies. This can be used to calculate a coarse estimate of the
   * total page load time a user might experience.
   */
  totalContentSize?: bigint;
}

function serializeSnapshotSnapshotMetadata(data: any): SnapshotSnapshotMetadata {
  return {
    ...data,
    crawlTimestamp: data["crawlTimestamp"] !== undefined ? String(data["crawlTimestamp"]) : undefined,
    snapshotDocument: data["snapshotDocument"] !== undefined ? serializeSnapshotSnapshotDocument(data["snapshotDocument"]) : undefined,
    totalContentSize: data["totalContentSize"] !== undefined ? String(data["totalContentSize"]) : undefined,
  };
}

function deserializeSnapshotSnapshotMetadata(data: any): SnapshotSnapshotMetadata {
  return {
    ...data,
    crawlTimestamp: data["crawlTimestamp"] !== undefined ? BigInt(data["crawlTimestamp"]) : undefined,
    snapshotDocument: data["snapshotDocument"] !== undefined ? deserializeSnapshotSnapshotDocument(data["snapshotDocument"]) : undefined,
    totalContentSize: data["totalContentSize"] !== undefined ? BigInt(data["totalContentSize"]) : undefined,
  };
}

/**
 * The SnapshotDocument contains a list of TextNode's. Each node contains a
 * string of text of the webpage, its bounding box in the agove snapshot image,
 * and its font size (in number of pixels in the snapshot, which could be a
 * fraction number since the snapshot image is typically shrinked). This list of
 * text nodes are extracted from the output from the rendering service:
 * htmlrender_webkit_headless_proto.Document The extraction is done by
 * TrimDocument defined in ./shared/doctrimmer.cc
 */
export interface SnapshotTextNode {
  boundingBox?: SnapshotBox;
  fontSize?: number;
  /**
   * One if the current text node is within a link; otherwise zero/not present.
   */
  inLink?: number;
  /**
   * A value in the range [0,7] (zero if not present) indicating the most
   * "powerful" splitting tag since the last text node. See "enum Category" in
   * mustang/snippets/taginfo.h.
   */
  maxSplit?: number;
  text?: string;
}

export interface SnippetExtraInfo {
  /**
   * Candidates are ordered by their id.
   */
  candidateInfo?: SnippetExtraInfoSnippetCandidateInfo[];
  /**
   * Indicates that the snippet candidates all contain uesr quotes.
   */
  containUserQuotes?: boolean;
  /**
   * Indicates if there are any vulgar snippet candidates.
   */
  containVulgarCandidates?: boolean;
  /**
   * Indicates whether the query relevance features is disabled or not in
   * Muppet scoring.
   */
  disableQueryFeatures?: boolean;
  /**
   * Snippet candidate index selected by snippet brain model. This field will
   * get populated in SnippetFlow in superroot. go/snippets-brain
   */
  snippetBrainSelectedCandidateIndex?: number;
  /**
   * SnippetsBrain model information for snippets popup debug.
   */
  snippetsbrainModelInfo?: SnippetExtraInfoSnippetsBrainModelInfo;
}

function serializeSnippetExtraInfo(data: any): SnippetExtraInfo {
  return {
    ...data,
    candidateInfo: data["candidateInfo"] !== undefined ? data["candidateInfo"].map((item: any) => (serializeSnippetExtraInfoSnippetCandidateInfo(item))) : undefined,
  };
}

function deserializeSnippetExtraInfo(data: any): SnippetExtraInfo {
  return {
    ...data,
    candidateInfo: data["candidateInfo"] !== undefined ? data["candidateInfo"].map((item: any) => (deserializeSnippetExtraInfoSnippetCandidateInfo(item))) : undefined,
  };
}

/**
 * Next ID: 14
 */
export interface SnippetExtraInfoSnippetCandidateInfo {
  /**
   * Bolded ranges in the printed snippet lines.
   */
  boldedRanges?: QualitySnippetsTruncationSnippetBoldedRange[];
  /**
   * Candidate identifier number, unique among all snippet candidates under
   * each document in each request. What does this number mean: - Muppet
   * candidates: This equals to the candidate's rank by Muppet snippets scorer.
   * - Superroot candidates: No specific meaning, this number should be larger
   * than that of Muppet candidates. This field is used to: - Verify whether
   * snippet brain chooses a different snippet from Muppet (the one chosen by
   * Muppet is always in id 0). - Print debugging information and sort
   * candidates in debug output.
   */
  id?: number;
  /**
   * If this snippet is chosen by Muppet.
   */
  isMuppetSelectedSnippet?: boolean;
  /**
   * If SnippetsBrain bolding model triggered and a bolding span is generated.
   */
  isSnippetBrainBoldingTriggered?: boolean;
  /**
   * List information for this candidate, only populated for RADISH_LIST
   * snippets.
   */
  listInfo?: MustangReposWwwSnippetsOrganicListSnippetResponse;
  scoringInfo?: SnippetExtraInfoSnippetScoringInfo;
  /**
   * Sentence starting positions in the printed snippet lines.
   */
  sentenceStarts?: QualitySnippetsTruncationSnippetBoldedRangePosition[];
  /**
   * Muppet fills snippet lines in `snippet` field.
   */
  snippet?: string[];
  /**
   * `snippet_text` will be filled by snippet brain flow in SR for model
   * scoring and debugging purpose.
   */
  snippetText?: string;
  snippetType?:  | "SNIPPET_TYPE_UNSPECIFIED" | "SEQUENCE" | "SEQUENCE_V2" | "FULL" | "FULL_V2" | "META" | "LEADING_TEXT" | "SAFT_SENTENCE" | "RADISH_SENTENCE" | "RADISH_LIST" | "RADISH_TABLE" | "ANNOTATED_FULL" | "PEREGRINE";
}

function serializeSnippetExtraInfoSnippetCandidateInfo(data: any): SnippetExtraInfoSnippetCandidateInfo {
  return {
    ...data,
    scoringInfo: data["scoringInfo"] !== undefined ? serializeSnippetExtraInfoSnippetScoringInfo(data["scoringInfo"]) : undefined,
  };
}

function deserializeSnippetExtraInfoSnippetCandidateInfo(data: any): SnippetExtraInfoSnippetCandidateInfo {
  return {
    ...data,
    scoringInfo: data["scoringInfo"] !== undefined ? deserializeSnippetExtraInfoSnippetScoringInfo(data["scoringInfo"]) : undefined,
  };
}

/**
 * Log model name, partition and input processor used to generate SnippetsBrain
 * scores, if SnippetsBrain debugging is enabled.
 */
export interface SnippetExtraInfoSnippetsBrainModelInfo {
  ng3ModelName?: string;
  /**
   * The below fields are populated by SnippetFlow in superroot.
   */
  snippetsbrainModelName?: string;
  snippetsbrainModelPartition?: string;
  snippetsbrainTokenizerType?: string;
}

/**
 * Next ID: 9
 */
export interface SnippetExtraInfoSnippetScoringInfo {
  brainNg3Score?: number;
  /**
   * The below fields are populated by SnippetFlow in superroot. Score
   * generated from snippet brain model. go/snippets-brain
   */
  brainScore?: number;
  /**
   * Snippets ranklab features generated by scorer V2.
   */
  features?: QualityPreviewRanklabSnippet;
  /**
   * Final snippet score by chooser.
   */
  finalScore?: number;
  /**
   * Final rank given by SnippetFlow.
   */
  rankBySnippetFlow?: number;
}

function serializeSnippetExtraInfoSnippetScoringInfo(data: any): SnippetExtraInfoSnippetScoringInfo {
  return {
    ...data,
    features: data["features"] !== undefined ? serializeQualityPreviewRanklabSnippet(data["features"]) : undefined,
  };
}

function deserializeSnippetExtraInfoSnippetScoringInfo(data: any): SnippetExtraInfoSnippetScoringInfo {
  return {
    ...data,
    features: data["features"] !== undefined ? deserializeQualityPreviewRanklabSnippet(data["features"]) : undefined,
  };
}

/**
 * Leading text which may consist of multiple pieces.
 */
export interface SnippetsLeadingtextLeadingTextAnnotation {
  piece?: SnippetsLeadingtextLeadingTextAnnotationPiece[];
  pieceType?:  | "SEPARATED" | "JOINED";
  /**
   * Type of this leading text. Should be an enum of
   * LeadingTextInfo.LeadingTextType
   */
  type?: number;
}

export interface SnippetsLeadingtextLeadingTextAnnotationPiece {
  /**
   * A piece of leading text is text within [begin, end). For example, a
   * document is "ABCDEF". If we want to set leading text as 'CD', the value of
   * begin is byte offset of 'C', the value of end is byte offset of 'E'. end ==
   * -1 means to the end of document.
   */
  begin?: number;
  /**
   * UTF8 text, for alignment when using reusableinfo. Those text are not
   * available in docjoins.
   */
  beginText?: string;
  end?: number;
  endText?: string;
  /**
   * Matched dom path string for debugging.
   */
  matchedPattern?: string;
}

export interface SnippetsLeadingtextLeadingTextInfo {
  /**
   * Leading text start position, byte offset of page content. The offset is
   * got in ParseMaster. So it is the offset after the content is converted to
   * UTF8.
   */
  beginPos?: number;
  /**
   * Note: You can also use it to save multiple leading text candidates.
   */
  leadingtext?: SnippetsLeadingtextLeadingTextAnnotation[];
  /**
   * UTF8 text, for alignment when using reusableinfo. The text is not
   * available in docjoins.
   */
  text?: string;
  /**
   * Type of leading text which is optimized for this type of document.
   */
  type?:  | "INVALID" | "NORMAL" | "HOMEPAGE" | "DICTIONARY" | "WIKI" | "SECTION_BOOST" | "IN_LIST" | "LOW" | "SALIENT_NUGGET" | "SCHEMA_ORG_DESC" | "SCHEMA_ORG_ANSWER" | "PDF";
}

/**
 * An Attachment represents a linked entity associated with a piece of social
 * content. This may be a 1st-party or 3rd-party entity. In the Papyrus context,
 * an Attachment is part of a Cent, and sits alongside the main content of the
 * cent, which is represented as a sequence of Segments. Right now an Attachment
 * is just a wrapper around an Embed, but we provide the extra layer of
 * abstraction since, as Embeds move to separate storage in Briefcase, we may
 * want to add additional fields that are not part of the Embed proper, but that
 * (for example) relate to the usage of the linked content within the particular
 * post/cent.
 */
export interface SocialCommonAttachmentAttachment {
  /**
   * An embed represents an external entity. See go/es-embeds.
   */
  embedItem?: EmbedsEmbedClientItem;
  /**
   * An id to uniquely identify an attachment when several attachments are in a
   * collection.
   */
  id?: string;
}

function serializeSocialCommonAttachmentAttachment(data: any): SocialCommonAttachmentAttachment {
  return {
    ...data,
    embedItem: data["embedItem"] !== undefined ? serializeEmbedsEmbedClientItem(data["embedItem"]) : undefined,
  };
}

function deserializeSocialCommonAttachmentAttachment(data: any): SocialCommonAttachmentAttachment {
  return {
    ...data,
    embedItem: data["embedItem"] !== undefined ? deserializeEmbedsEmbedClientItem(data["embedItem"]) : undefined,
  };
}

/**
 * Formatting information for a segment.
 */
export interface SocialCommonFormatting {
  bold?: boolean;
  /**
   * This indicates that the segment should be rendered as highlighted or
   * visually emphasized.
   */
  highlight?: boolean;
  italics?: boolean;
  strikethrough?: boolean;
  /**
   * If set, this indicates that the segment should be rendered with the
   * specified style. The absence of an explicit style represents "no style",
   * i.e. the segment can be rendered with the default style chosen by the
   * application.
   */
  style?:  | "UNKNOWN_STYLE" | "HEADING_1" | "HEADING_2" | "HEADING_3" | "HEADING_4";
  underline?: boolean;
}

/**
 * Hashtag metadata, for HASHTAG segments. For a hashtag, the "text" field
 * should contain the display text, and the search_text field should represent
 * the topic being referenced, without the hash symbol; for example, we might
 * have: text = "#Google" hashtag_data.search_text = "Google" Another example:
 * text = "#pikachu" hashtag_data.search_text = "Pokemon" Both strings should be
 * considered part of the searchable text. In go/sbe, both are indexed and
 * searchable.
 */
export interface SocialCommonHashtagData {
  searchText?: string;
}

/**
 * Link metadata, for LINK segments. Anchor text should be stored in the "text"
 * field of the Segment, which can also serve as a fallback.
 */
export interface SocialCommonLinkData {
  /**
   * An Attachment represents the structured entity to which we are linking. It
   * contains an Embed (apps/tacotown/proto/embeds/embed_client.proto) with
   * fields specific to the appropriate type of linked entity. For example, if
   * we are linking to a photo album, the Embed may include the album ID and
   * gaia ID of the creator. Clients that understand the Embed type within the
   * Attachment may construct and/or decorate their link appropriately e.g. to
   * make use of type-specific functionality or first-party integrations. The
   * link_target and (if appropriate) display_url fields must still be set even
   * when an Attachment is present, so that clients who do not know how to
   * interpret the Attachment can fall back to those fields, and render the
   * Segment as an ordinary web link. N.B. Even when an Attachment is present,
   * the intention of a "LINK" Segment is for the Segment to be presented inline
   * with the rest of the text of a post or comment, with a clickable link or
   * other UI suitable for inlining (though the client may modify the UI based
   * on Attachment data, e.g. to add appropriate hovers, icons, etc.). When an
   * entity is intended to be rendered separately from the main body of the
   * post/comment, a separate Attachment proto can be added outside the set of
   * Segments. N.B. Within the Attachment, fields of EmbedClientItem have their
   * own visibility annotations, which should be enforced separately from
   * Segment visibility annotations. See:
   * apps/tacotown/proto/embeds/embed_annotations.proto
   */
  attachment?: SocialCommonAttachmentAttachment;
  /**
   * The hint to use when rendering the associated attachment. Ignored if there
   * is no associated attachment.
   */
  attachmentRenderHint?:  | "ATTACHMENT_RENDER_HINT_UNKNOWN" | "ATTACHMENT_RENDER_HINT_AFTER" | "ATTACHMENT_RENDER_HINT_INTERLEAVED";
  /**
   * If we wish to show the user a different (e.g. shortened) version of the
   * URL for display purposes, then that version should be set here. If this
   * field isn't set, link_target will be used for both purposes.
   */
  displayUrl?: string;
  /**
   * link_target is the URL to navigate to when clicked. This could be the
   * original URL, or a URL signed by the GWS URL signing service.
   */
  linkTarget?: string;
  /**
   * LinkType is an optional field that provides additional information
   * regarding link target. For example, link type can be identified as the
   * SELF_LINK when the request was executed from the same link as the link
   * target.
   */
  linkType?:  | "UNKNOWN_LINK_TYPE" | "SELF_LINK";
  /**
   * Title is an optional field that provides a short string that describes the
   * link or its destination. User interfaces often use title as a tooltip or
   * for accessibility purposes. However, they are of course free to present
   * this data in any form. This field is plain text.
   */
  title?: string;
}

function serializeSocialCommonLinkData(data: any): SocialCommonLinkData {
  return {
    ...data,
    attachment: data["attachment"] !== undefined ? serializeSocialCommonAttachmentAttachment(data["attachment"]) : undefined,
  };
}

function deserializeSocialCommonLinkData(data: any): SocialCommonLinkData {
  return {
    ...data,
    attachment: data["attachment"] !== undefined ? deserializeSocialCommonAttachmentAttachment(data["attachment"]) : undefined,
  };
}

export interface SocialCommonSegment {
  /**
   * Formatting to be applied when rendering the Segment. For all segment
   * types, this is the standard way of representing that the Segment should be
   * rendered in bold, italics, etc.
   */
  formatting?: SocialCommonFormatting;
  /**
   * For HASHTAG type:
   */
  hashtagData?: SocialCommonHashtagData;
  /**
   * Type-specific metadata. At most one of these should be populated, and the
   * one that is populated should correspond to the type of the Segment. For
   * LINK type:
   */
  linkData?: SocialCommonLinkData;
  /**
   * Text content of the Segment. As a general rule, this field should contain
   * the actual text that should be rendered in the UI. Thus, for a hashtag, it
   * should be "#Foo", and for a link, it should be the display text. Clients
   * that do not understand a particular segment type may use this text, along
   * with the Formatting info below, as a fallback for display. The field is not
   * required -- if all relevant information is carried in other metadata fields
   * and there is no need for a fallback, or it is not practical for a fallback
   * to be provided for any other reason, the field may be left blank. A
   * standard example would be a user reference being transmitted between server
   * layers, where a gaia-ID representation may be sufficient and there is no
   * need for a textual fallback. In such a case, it would be valid and useful -
   * though not required - for servers to compute and populate a fallback on the
   * serving path.
   */
  text?: string;
  /**
   * Type of Segment.
   */
  type?:  | "TEXT" | "LINE_BREAK" | "LINK" | "USER_MENTION" | "ALL_USER_MENTION" | "HASHTAG";
  /**
   * For USER_MENTION type:
   */
  userMentionData?: SocialCommonUserMentionData;
}

function serializeSocialCommonSegment(data: any): SocialCommonSegment {
  return {
    ...data,
    linkData: data["linkData"] !== undefined ? serializeSocialCommonLinkData(data["linkData"]) : undefined,
    userMentionData: data["userMentionData"] !== undefined ? serializeSocialCommonUserMentionData(data["userMentionData"]) : undefined,
  };
}

function deserializeSocialCommonSegment(data: any): SocialCommonSegment {
  return {
    ...data,
    linkData: data["linkData"] !== undefined ? deserializeSocialCommonLinkData(data["linkData"]) : undefined,
    userMentionData: data["userMentionData"] !== undefined ? deserializeSocialCommonUserMentionData(data["userMentionData"]) : undefined,
  };
}

/**
 * Segments (go/social-segments) represent structured social content, e.g. the
 * contents of a G+ stream post or chat message. A single post or message may
 * consist of a sequence of segments, each representing a type of content, e.g.
 * plain text, hash tag, mention, etc. Segments correspond approximately to
 * units of content delimited by HTML tags, so that a piece of bolded text would
 * be a distinct Segment, a link would be a distinct Segment, and so forth. A
 * single Segment may have multiple such qualifiers; e.g. it may be a bold link;
 * in this case, information about all such qualifiers will be encoded in the
 * Segment proto.
 */
export interface SocialCommonSegments {
  segments?: SocialCommonSegment[];
}

function serializeSocialCommonSegments(data: any): SocialCommonSegments {
  return {
    ...data,
    segments: data["segments"] !== undefined ? data["segments"].map((item: any) => (serializeSocialCommonSegment(item))) : undefined,
  };
}

function deserializeSocialCommonSegments(data: any): SocialCommonSegments {
  return {
    ...data,
    segments: data["segments"] !== undefined ? data["segments"].map((item: any) => (deserializeSocialCommonSegment(item))) : undefined,
  };
}

/**
 * Person metadata, for USER_MENTION segments. Should always contain at least
 * one of user_gaia_id, user_id, email or user. The exact set of populated
 * fields may differ depending on the context and the level in the serving
 * stack; for example, emails will be elided on the viewing path. But as a
 * general rule, a proto having any one of the four is valid, subject to the
 * standard constraints of the applied annotations -- that is, communication
 * between servers and clients will ignore jspb.ignore fields, and communication
 * between servers and other servers (or between servers and storage) will
 * ignore client_only fields. For more on the annotations, see the comments in
 * social/common/segment_annotations.proto
 */
export interface SocialCommonUserMentionData {
  email?: string;
  /**
   * If the principal is backed by a gaia id, DO NOT use this field. Use
   * user_gaia_id/user_id fields instead.
   */
  user?: SecurityCredentialsPrincipalProto;
  /**
   * An unobfuscated gaia ID:
   */
  userGaiaId?: bigint;
  /**
   * An obfuscated gaia ID:
   */
  userId?: string;
}

function serializeSocialCommonUserMentionData(data: any): SocialCommonUserMentionData {
  return {
    ...data,
    user: data["user"] !== undefined ? serializeSecurityCredentialsPrincipalProto(data["user"]) : undefined,
    userGaiaId: data["userGaiaId"] !== undefined ? String(data["userGaiaId"]) : undefined,
  };
}

function deserializeSocialCommonUserMentionData(data: any): SocialCommonUserMentionData {
  return {
    ...data,
    user: data["user"] !== undefined ? deserializeSecurityCredentialsPrincipalProto(data["user"]) : undefined,
    userGaiaId: data["userGaiaId"] !== undefined ? BigInt(data["userGaiaId"]) : undefined,
  };
}

/**
 * An entity key with an obfuscated gaia id that can be used externally.
 */
export interface SocialDiscoveryExternalEntityKey {
  email?: string;
  phone?: string;
  /**
   * Obfuscated GAIA id.
   */
  profileId?: string;
}

/**
 * Contains a mimetype supported by a third-party app together with additional
 * ids and other data that the apps use to complete the action for the given
 * mimetype. For example, an app_specific_endpoint_id that corresponds to a
 * WhatsApp Profile. Full Design: go/3p-contact-upload LINT.IfChange
 */
export interface SocialGraphApiAppContactData {
  /**
   * Set of column-name and value for the given mimetype. The semantic meaning
   * of the column values is mime-type specific. For example they may contain
   * app_specific_endpoint_ids for WhatsApp. This is uploaded from CP2
   * http://go/cp2-data1 through http://go/cp2-data14.
   */
  data?: SocialGraphApiDataColumn[];
  /**
   * The mimetype of the action defined by the third-party app.
   */
  mimetype?:  | "UNKNOWN_MIMETYPE" | "WHATSAPP_PROFILE" | "WHATSAPP_VOIP_CALL" | "WHATSAPP_VIDEO_CALL" | "LINE_PROFILE" | "LINE_VOICE" | "LINE_VIDEO" | "HIKE_MESSAGE" | "HIKE_MESSAGE_ASSISTANT" | "HIKE_VOICE_CALL" | "HIKE_VIDEO_CALL" | "TELEGRAM_ANDROID_PROFILE" | "THREEMA_PROFILE" | "VIBER_OUT_CALL_NONE" | "VIBER_NUMBER_CALL" | "VIBER_NUMBER_MESSAGE" | "VIBER_OUT_CALL" | "VIBER_GOOGLE_VOICE_MESSAGE" | "WECHAT_VOICEACTION" | "LINKEDIN_ANDROID_MESSAGING" | "VK_SENDMSG" | "TACHYON_PHONE_AUDIO" | "TACHYON_PHONE";
}

/**
 * LINT.IfChange
 */
export interface SocialGraphApiDataColumn {
  /**
   * The name of the column in CP2 for raw_contact_data.
   */
  columnName?:  | "UNKNOWN_COLUMN" | "DATA1" | "DATA2" | "DATA3" | "DATA4" | "DATA5" | "DATA6" | "DATA7" | "DATA8" | "DATA9" | "DATA10" | "DATA11" | "DATA12" | "DATA13" | "DATA14";
  /**
   * The value of the data inside column.
   */
  value?: string;
}

export interface SocialGraphApiProtoAndroidDeviceInfo {
  /**
   * This string will represent either the device make and model in the case of
   * FSA2, or the device model in the case of FSA1.
   */
  id?: string;
}

export interface SocialGraphApiProtoBirthdayDecoration {
  birthdayDecorationVisibility?:  | "BIRTHDAY_DECORATION_VISIBILITY_UNSPECIFIED" | "BIRTHDAY_DECORATION_VISIBILITY_NONE" | "BIRTHDAY_DECORATION_VISIBILITY_SAME_AS_BIRTHDAY_VISIBILITY";
}

/**
 * The ContactEditContext message is a wrapper around the generic
 * ContactMutationContext data to represent when and where a contact create was
 * performed.
 */
export interface SocialGraphApiProtoContactCreateContext {
  mutationContext?: SocialGraphApiProtoContactMutationContext;
}

function serializeSocialGraphApiProtoContactCreateContext(data: any): SocialGraphApiProtoContactCreateContext {
  return {
    ...data,
    mutationContext: data["mutationContext"] !== undefined ? serializeSocialGraphApiProtoContactMutationContext(data["mutationContext"]) : undefined,
  };
}

function deserializeSocialGraphApiProtoContactCreateContext(data: any): SocialGraphApiProtoContactCreateContext {
  return {
    ...data,
    mutationContext: data["mutationContext"] !== undefined ? deserializeSocialGraphApiProtoContactMutationContext(data["mutationContext"]) : undefined,
  };
}

/**
 * The ContactDeletionContext message is a wrapper around the generic
 * ContactMutationContext data, and will include any needed delete specific
 * data. NOTE: Before using this message please review
 * go/people-api-contact-deletion-context
 */
export interface SocialGraphApiProtoContactDeletionContext {
  /**
   * The general mutation context data
   */
  mutationContext?: SocialGraphApiProtoContactMutationContext;
}

function serializeSocialGraphApiProtoContactDeletionContext(data: any): SocialGraphApiProtoContactDeletionContext {
  return {
    ...data,
    mutationContext: data["mutationContext"] !== undefined ? serializeSocialGraphApiProtoContactMutationContext(data["mutationContext"]) : undefined,
  };
}

function deserializeSocialGraphApiProtoContactDeletionContext(data: any): SocialGraphApiProtoContactDeletionContext {
  return {
    ...data,
    mutationContext: data["mutationContext"] !== undefined ? deserializeSocialGraphApiProtoContactMutationContext(data["mutationContext"]) : undefined,
  };
}

/**
 * The ContactEditContext message is a wrapper around the generic
 * ContactMutationContext data to represent when and where a contact edit was
 * performed.
 */
export interface SocialGraphApiProtoContactEditContext {
  mutationContext?: SocialGraphApiProtoContactMutationContext;
}

function serializeSocialGraphApiProtoContactEditContext(data: any): SocialGraphApiProtoContactEditContext {
  return {
    ...data,
    mutationContext: data["mutationContext"] !== undefined ? serializeSocialGraphApiProtoContactMutationContext(data["mutationContext"]) : undefined,
  };
}

function deserializeSocialGraphApiProtoContactEditContext(data: any): SocialGraphApiProtoContactEditContext {
  return {
    ...data,
    mutationContext: data["mutationContext"] !== undefined ? deserializeSocialGraphApiProtoContactMutationContext(data["mutationContext"]) : undefined,
  };
}

/**
 * This message is the generic mutation message which will encapsulate the
 * fields which are shared between the create, update, and delete actions,
 * including source of change, timestamp, and metadata messages passed in from
 * the source for any source specific data (such as phone name/model from FSA).
 */
export interface SocialGraphApiProtoContactMutationContext {
  /**
   * Android device info should always be set when using either ANDROID_FSA1 or
   * ANDROID_FSA2 as the source of the delete.
   */
  androidDeviceInfo?: SocialGraphApiProtoAndroidDeviceInfo;
  /**
   * Host app info should always be set when using CONTACTS_COMPANION as the
   * source.
   */
  hostAppInfo?: SocialGraphApiProtoHostAppInfo;
  /**
   * The source of a mutate should provide all needed information a user should
   * know, and should be enough information for the front end to generate a
   * proper human readable string to describe the mutate to the user.
   */
  source?:  | "UNKNOWN_SOURCE" | "CONTACT_MERGE" | "WEB_CONTACTS" | "CONTACTS_COMPANION" | "HEALER_DUPLICATES" | "HEALER_OTHER_CONTACT" | "HEALER_CONTACT_LIMIT" | "THIRD_PARTY" | "ANDROID_FSA1" | "ANDROID_FSA2" | "GMAIL_WEB_CONTACTS" | "CARBON_IMPORT_CONTACTS" | "IOS" | "MAC_OS_X" | "WINDOWS_PC" | "WINDOWS_PHONE" | "JUNK_EMAIL_CLEANUP" | "INTERNAL_TESTING" | "ONE_PICK" | "ASSISTANT_SMART_DEVICE_MANAGEMENT_API";
  /**
   * Third party info should always be set when using THIRD_PARTY as the
   * source.
   */
  thirdPartyInfo?: SocialGraphApiProtoThirdPartyInfo;
  /**
   * Timestamp representing when the contact was mutated. This should not be
   * set on write, as it is the job of focus backend to determine this
   * timestamp. This field will be populated on read with the data written by
   * FBS.
   */
  timestamp?: Date;
}

function serializeSocialGraphApiProtoContactMutationContext(data: any): SocialGraphApiProtoContactMutationContext {
  return {
    ...data,
    thirdPartyInfo: data["thirdPartyInfo"] !== undefined ? serializeSocialGraphApiProtoThirdPartyInfo(data["thirdPartyInfo"]) : undefined,
    timestamp: data["timestamp"] !== undefined ? data["timestamp"].toISOString() : undefined,
  };
}

function deserializeSocialGraphApiProtoContactMutationContext(data: any): SocialGraphApiProtoContactMutationContext {
  return {
    ...data,
    thirdPartyInfo: data["thirdPartyInfo"] !== undefined ? deserializeSocialGraphApiProtoThirdPartyInfo(data["thirdPartyInfo"]) : undefined,
    timestamp: data["timestamp"] !== undefined ? new Date(data["timestamp"]) : undefined,
  };
}

export interface SocialGraphApiProtoContactPromptSettings {
  /**
   * Indicates if any reminders are active for entire contact. This will affect
   * both connection reminders and date reminders such as birthday reminders.
   * This is required.
   */
  contactActiveState?:  | "UNKNOWN_ACTIVE_STATE" | "ACTIVE" | "DISABLED";
}

/**
 * Contact state and related metadata. See go/fbs-contacts-trash.
 */
export interface SocialGraphApiProtoContactState {
  /**
   * A trashed contact may have deletion context set, which indicates where and
   * when the contact was trashed. Deletion context is cleared when the contact
   * is untrashed.
   */
  deletionContext?: SocialGraphApiProtoContactDeletionContext;
  deletionState?:  | "DEFAULT" | "TRASHED";
}

function serializeSocialGraphApiProtoContactState(data: any): SocialGraphApiProtoContactState {
  return {
    ...data,
    deletionContext: data["deletionContext"] !== undefined ? serializeSocialGraphApiProtoContactDeletionContext(data["deletionContext"]) : undefined,
  };
}

function deserializeSocialGraphApiProtoContactState(data: any): SocialGraphApiProtoContactState {
  return {
    ...data,
    deletionContext: data["deletionContext"] !== undefined ? deserializeSocialGraphApiProtoContactDeletionContext(data["deletionContext"]) : undefined,
  };
}

/**
 * Pattern for a DAILY (or every N day) recurrence. Time of the day that the
 * notification will occur is taken from the Prompt that owns this recurrence.
 * Used in PeopleAPI layers + FBS/ContactsService (not in ProfileService)
 */
export interface SocialGraphApiProtoDailyRecurrence {
}

/**
 * Settings that control how a SIBS decoration overlay is displayed.
 */
export interface SocialGraphApiProtoDecorationOverlay {
  /**
   * Settings that describe how the decoration should be overlaid on the photo.
   */
  overlay?: SocialGraphApiProtoPhotoOverlay;
  /**
   * SIBS ID of the decoration that is overlaid on the photo.
   */
  sibsId?: string;
}

/**
 * Represents a delegated group id, delegated groups refer to groups that are
 * owned by another gaiaId, but this user has access to.
 */
export interface SocialGraphApiProtoDelegatedGroupId {
  /**
   * Required. The id for a delegated group.
   */
  id?: string;
}

export interface SocialGraphApiProtoDisplayNameSource {
  source?:  | "DISPLAY_NAME_SOURCE_UNSPECIFIED" | "LIMITED_PROFILE" | "LIMITED_PROFILE_FULL_NAME" | "LIMITED_PROFILE_SHORTENED_NAME";
}

export interface SocialGraphApiProtoHostAppInfo {
  /**
   * This string will represent the info for the host app to the Companion
   * sidebar
   */
  hostAppName?: string;
}

/**
 * A reference to a photo in either Photos Backend or SGI storage. This message
 * should be treated as an opaque blob to avoid a dependency on a specific
 * storage backend. This version of ImageReference is visible outside of SGBE.
 * Do not add fields that should not be exposed outside of Profile Service and
 * Image Service.
 */
export interface SocialGraphApiProtoImageReference {
  /**
   * Identifies the most recent version of this photo. Use this as a FIFE param
   * (ie -iv12) to prevent reads of a stale version.
   */
  contentVersion?: bigint;
  /**
   * Unique identifier for the photo. For now, this will always be a Photos
   * Backend media key.
   */
  mediaId?: string;
}

function serializeSocialGraphApiProtoImageReference(data: any): SocialGraphApiProtoImageReference {
  return {
    ...data,
    contentVersion: data["contentVersion"] !== undefined ? String(data["contentVersion"]) : undefined,
  };
}

function deserializeSocialGraphApiProtoImageReference(data: any): SocialGraphApiProtoImageReference {
  return {
    ...data,
    contentVersion: data["contentVersion"] !== undefined ? BigInt(data["contentVersion"]) : undefined,
  };
}

export interface SocialGraphApiProtoLimitedProfileNameSettings {
  /**
   * Required. Describes which shortening option the user implicitly chose for
   * their limited profile. E.g., if 'John Doe' chose 'John D.', they implicitly
   * chose: partial_name_options { given_name_spec { show_all: true }
   * family_name_spec: { show_initial: true truncation_indicator: PERIOD } }
   * While we'll in all cases serve the actual name chosen by the user for
   * limited profiles (stored below), we'll use this information to recompute
   * the default limited profile to be rendered to users when they change their
   * core name.
   */
  partialNameOptions?: SocialGraphApiProtoPartialNameOptions;
  /**
   * The actual textual name that was chosen by the user in the UI. E.g., if
   * 'John Doe' chose 'John D.', this holds 'John D.'. While
   * `partial_name_options` allows the limited profile name to be computed from
   * the core name, the resulting shortened name might change across different
   * versions of the name shortening logic, and we want to preserve the user's
   * choice verbatim whenever possible. This field will be cleared when the two
   * conditions below are met: (1) A successful core name change is not
   * accompanied by a limited profile settings update and (2) The shortened name
   * computed from `partial_name_options` yields a different result than what is
   * originally stored in `verbatim_full_name`. When this happens, the limited
   * profile is effectively *disabled*. E.g., if 'John Doe' from the example
   * above changes their name to 'Jane Doe' and no LimitedProfileSettings are
   * provided, `Jane D.` is the resulting shortened name. Therefore
   * `verbatim_full_name` will be cleared and the limited profile settings will
   * be disabled. On the other hand, if they change their name to `John De`,
   * the resulting shortened name remains `John D.`, and `verbatim_full_name` is
   * kept as is.
   */
  verbatimFullName?: string;
}

export interface SocialGraphApiProtoLimitedProfilePictureSettings {
  profilePictureOption?:  | "PROFILE_PICTURE_OPTION_UNSPECIFIED" | "STANDARD_PROFILE_PICTURE" | "MONOGRAM";
}

/**
 * Next ID: 9
 */
export interface SocialGraphApiProtoLimitedProfileSettings {
  /**
   * Indicates why the limited profile has been disabled. Will be set iff the
   * limited profile is disabled. Note: When mutating limited profiles, in order
   * to disable them, MutateDataRequest.DisableLimitedProfile must be true.
   * Currently, disables are only performed server-side, so this is read-only
   * for clients.
   */
  disableReason?:  | "DISABLE_REASON_UNSPECIFIED" | "INCOMPATIBLE_NAME_ONLY_MUTATION" | "NAME_ABUSE_VIOLATION";
  /**
   * Created with user input in GPay OOBE.
   */
  gpayOobe?: boolean;
  /**
   * Timestamp indicating when the settings were last stored. Read-only field.
   */
  lastUpdateTime?: Date;
  /**
   * A user who had legacy discoverability had a Limited Profile autogenerated
   * for them, either through a healer or in the live path in FBS.
   */
  legacyDiscoverability?:  | "AUTOGEN_STATUS_UNSPECIFIED" | "AUTOGEN_UNCONFIRMED" | "AUTOGEN_CONFIRMED";
  /**
   * Created with user input in MyAccount UI.
   */
  myAccount?: boolean;
  /**
   * Required. Defines how the name should be formatted in the limited profile.
   */
  nameSettings?: SocialGraphApiProtoLimitedProfileNameSettings;
  /**
   * DEPRECATED. Profile picture choices are controlled through the ACL of the
   * Photo field.
   */
  profilePictureSettings?: SocialGraphApiProtoLimitedProfilePictureSettings;
}

function serializeSocialGraphApiProtoLimitedProfileSettings(data: any): SocialGraphApiProtoLimitedProfileSettings {
  return {
    ...data,
    lastUpdateTime: data["lastUpdateTime"] !== undefined ? data["lastUpdateTime"].toISOString() : undefined,
  };
}

function deserializeSocialGraphApiProtoLimitedProfileSettings(data: any): SocialGraphApiProtoLimitedProfileSettings {
  return {
    ...data,
    lastUpdateTime: data["lastUpdateTime"] !== undefined ? new Date(data["lastUpdateTime"]) : undefined,
  };
}

/**
 * Pattern for a MONTHLY recurrence. This Monthly reccurence supports: 1.
 * Absolute days of the month (i.e. the 1st and 15th) 2. Relative day from the
 * end of the month (i.e. -1 for last day, -2 for second-to-last day). Used in
 * PeopleAPI layers + FBS/ContactsService (not in ProfileService)
 */
export interface SocialGraphApiProtoMonthlyDayRecurrence {
  /**
   * Absolute day of the month (if positive) or relative day from the end of
   * the month (if negative). Example: 2nd and 20th of the month [2, 20].
   * Example: Last day of the month [-1]. Positive values should correspond to
   * actual calendar day number (indexing starts at 1).
   */
  monthDay?: number[];
  /**
   * If true, month_day beyond the end of month (i.e. month_day=31 in February)
   * will default to the last day of the month.
   */
  useLastDayIfMonthDayPastEnd?: boolean;
}

/**
 * A MONTHLY recurrence can be one of a MonthlyDayRecurrence or
 * MonthlyWeekdayRecurrence but not both. Used in PeopleAPI layers +
 * FBS/ContactsService (not in ProfileService)
 */
export interface SocialGraphApiProtoMonthlyRecurrence {
  monthlyDayRecurrence?: SocialGraphApiProtoMonthlyDayRecurrence;
  monthlyWeekdayRecurrence?: SocialGraphApiProtoMonthlyWeekdayRecurrence;
}

/**
 * Pattern for a MONTHLY recurrence. This Monthly reccurence supports: 1. The
 * nth specific weekday of the month. For example, the 3rd Wednesday of the
 * month. This represents the 3rd instance of a Wednesday of the month,
 * regardless of what weekday the month started on. It does not necessarily mean
 * the Wednesday on the 3rd week of the month. Used in PeopleAPI layers +
 * FBS/ContactsService (not in ProfileService)
 */
export interface SocialGraphApiProtoMonthlyWeekdayRecurrence {
  /**
   * The nth occurrence of week_day to match. I.e. For 3rd Wednesday of the
   * month, week_day = WEDNESDAY and week_day_number = 3. Values beyond the end
   * of the month are skipped.
   */
  weekDay?:  | "DAY_OF_WEEK_UNSPECIFIED" | "MONDAY" | "TUESDAY" | "WEDNESDAY" | "THURSDAY" | "FRIDAY" | "SATURDAY" | "SUNDAY";
  weekDayNumber?: number;
}

/**
 * Metadata for a user's name pronunciation audio. Proto message is shared
 * between merged_person and FBS.
 */
export interface SocialGraphApiProtoNamePronunciationAudioMetadata {
  /**
   * Stored. Updated on pronunciation creates and updates.
   */
  audioSource?:  | "SOURCE_UNSPECIFIED" | "USER_GENERATED";
  /**
   * Stored.
   */
  audioState?:  | "STATE_UNSPECIFIED" | "ENABLED" | "DISABLED_FOR_NAME_CHANGE";
}

/**
 * Used in PeopleAPI layers + FBS/ContactsService (not in ProfileService)
 */
export interface SocialGraphApiProtoNotificationTrigger {
  /**
   * Positive number of days before active date. The value 0 will denote a
   * notification on the same day.
   */
  daysBeforeActiveDate?: number;
  /**
   * Time of day that notification is sent to user. This is local to the user's
   * device.
   */
  notificationTimeOfDay?: GoogleTypeTimeOfDay;
}

export interface SocialGraphApiProtoPartialNameOptions {
  /**
   * IETF BCP-47 language code that should be used for localizing the name
   * computation (go/bcp-47). If not provided, we'll use the name origin
   * detector to infer it. If unable to detect, "en" will be assumed.
   */
  language?: string;
  parsedDisplayNameSpec?: SocialGraphApiProtoPartialNameOptionsParsedDisplayNameSpec;
  twoPartNameSpec?: SocialGraphApiProtoPartialNameOptionsTwoPartNameSpec;
}

/**
 * Specifies how each piece of the name should be handled. Names are structured
 * into given name and family name and this allows an independent specification
 * for each of these pieces. Very limited preprocessing is done for this option
 * (leading whitespace trimming mostly). Composed names are treated as a single
 * unit and are not broken down.
 */
export interface SocialGraphApiProtoPartialNameOptionsNamePartSpec {
  /**
   * Completely omit that part of the name.
   */
  hideAll?: boolean;
  /**
   * Show the complete name. Note that this does not express the same semantics
   * as show_first_n_chars=length_of_name, because when regenerating a shortened
   * name the new name could have more characters, thus yielding a different
   * result.
   */
  showAll?: boolean;
  /**
   * Show first `n` characters. Same note about characters referring to
   * "grapheme_clusters" applies.
   */
  showFirstNChars?: number;
  /**
   * Show only the initial, i.e., a single character. Note that "character"
   * refers to "user-perceived" characters, aka a "grapheme cluster". See
   * go/morphology for more details.
   */
  showInitial?: boolean;
  /**
   * Which truncation indicator to use after the shortened piece of the name.
   * Will be ignored for the `hide_all` or `show_all` options.
   */
  truncationIndicator?:  | "TRUNCATION_INDICATOR_UNSPECIFIED" | "ELLIPSIS" | "PERIOD";
}

/**
 * These options use more sophisticated logic from a location-aware name
 * detector to parse the full name of a user into structured parts and operate
 * on those parts. For more information on how names are parsed, see the
 * NameOccurrence proto definition:
 * http://google3/quality/peoplesearch/namedetector/detector/proto/name_occurrence.proto?l=50&rcl=334484707
 * In general, when parsing display names the following rules will apply to
 * *all* specs: - Hyphenated names are broken down: "Angelina Jollie-Pit" is
 * pre-processed as "Angelina Jollie Pitt"; - Prefixes are ignored: "Prof. Albus
 * Dumbledore" is pre-processed as "Albus Dumbledore"; - Auxiliaries are
 * ignored: "Lus de Cames" is pre-processed as "Lus Cames". Next ID: 8
 */
export interface SocialGraphApiProtoPartialNameOptionsParsedDisplayNameSpec {
  /**
   * Extract an initial from each parsed name. For example, "Niels Henrik David
   * Bohr" yields "N. H. D. B.". Other special cases are treated as follows:
   */
  allInitialsFromParsedName?: boolean;
  /**
   * Show the initial of the very first name and the first last name, e.g.
   * "Hugo Daniel Hernandez Garcia" yields "H. Hernandez".
   */
  firstInitialAndFirstLastName?: boolean;
  /**
   * Show the initial of the very first name and the very last name, e.g. "Ana
   * Maria Silva" yields "A. Silva".
   */
  firstInitialAndVeryLastName?: boolean;
  /**
   * Shorten the display name using the Knowledge Graph name shortener
   * (go/short-names).
   */
  knowledgeGraphNameShortening?: boolean;
  /**
   * Which truncation indicator to use after each shortened part of the name.
   * Will be ignored for the `knowledge_graph_name_shortening` option.
   */
  truncationIndicator?:  | "TRUNCATION_INDICATOR_UNSPECIFIED" | "ELLIPSIS" | "PERIOD";
  /**
   * Show the full very first name and all the other initials, e.g. "Ana Maria
   * Silva" yields "Ana M. S.".
   */
  veryFirstNameAndAllInitials?: boolean;
  /**
   * Show the very first name only, e.g. "Ana Maria Silva" yields "Ana".
   */
  veryFirstNameOnly?: boolean;
}

/**
 * Holds the name specs for the two parts of a name, as they are structured in
 * storage (given and family).
 */
export interface SocialGraphApiProtoPartialNameOptionsTwoPartNameSpec {
  familyNameSpec?: SocialGraphApiProtoPartialNameOptionsNamePartSpec;
  givenNameSpec?: SocialGraphApiProtoPartialNameOptionsNamePartSpec;
}

/**
 * Settings that control how a photo overlay is displayed.
 */
export interface SocialGraphApiProtoPhotoOverlay {
  /**
   * Top left position of the overlay relative to the user's avatar.
   */
  relativePosition?: SocialGraphApiProtoRelativePosition;
  /**
   * Scale of the overlay relative to the user's avatar.
   */
  relativeScale?: SocialGraphApiProtoRelativeScale;
}

/**
 * Used in PeopleAPI layers + FBS/ContactsService (not in ProfileService)
 */
export interface SocialGraphApiProtoPrompt {
  /**
   * Indicates if this prompt is active regardless of its reccurrence date,
   * dismiss date or notification triggers. This is required.
   */
  activeState?:  | "UNKNOWN_ACTIVE_STATE" | "ACTIVE" | "DISABLED";
  content?: SocialGraphApiProtoPromptContent;
  /**
   * The most recent day the user dismissed this prompt. Empty means the user
   * has never dismissed the prompt.
   */
  lastDismissDate?: GoogleTypeDate;
  /**
   * If this is empty, only the "Prompt Spark" will be displayed (in the
   * time-range read from per type config), no push notifications will be shown.
   * If push notification are configured with this field, the "Prompt Spark"
   * time-range will be determined by earliest notification value here.
   */
  notificationTriggers?: SocialGraphApiProtoNotificationTrigger[];
  /**
   * Read-only. This is derived from the containing field value.
   */
  purpose?:  | "UNKNOWN_PURPOSE" | "BIRTHDAY" | "ANNIVERSARY" | "SIGNIFICANT_DATE" | "CONNECTION_FREQUENCY";
  /**
   * How frequently will this prompt occur and how many times.
   */
  recurrence?: SocialGraphApiProtoRecurrence;
  /**
   * Prompt ID is generated by server on initial mutate.
   */
  uniquePromptId?: string;
}

function serializeSocialGraphApiProtoPrompt(data: any): SocialGraphApiProtoPrompt {
  return {
    ...data,
    recurrence: data["recurrence"] !== undefined ? serializeSocialGraphApiProtoRecurrence(data["recurrence"]) : undefined,
  };
}

function deserializeSocialGraphApiProtoPrompt(data: any): SocialGraphApiProtoPrompt {
  return {
    ...data,
    recurrence: data["recurrence"] !== undefined ? deserializeSocialGraphApiProtoRecurrence(data["recurrence"]) : undefined,
  };
}

/**
 * Used in PeopleAPI layers + FBS/ContactsService (not in ProfileService) and
 * in Custard response to client apps that read Prompts.
 */
export interface SocialGraphApiProtoPromptContent {
  /**
   * Title of prompt/spark being sent.
   */
  title?: string;
}

/**
 * Design doc: go/pronouns-backend Represents a user's preferred pronouns.
 */
export interface SocialGraphApiProtoPronounData {
  pronounEntry?: SocialGraphApiProtoPronounEntry[];
}

export interface SocialGraphApiProtoPronounEntry {
  /**
   * Locale option in which the pronouns were set, in the BCP-47 format. Set by
   * the client at write time.
   */
  languageCode?: string;
  /**
   * The pronoun entry type that the user has selected. This indicates which
   * locale-independent classification of pronoun was selected (or optionally,
   * if it is a custom field).
   */
  pronounType?:  | "UNKNOWN" | "CUSTOM" | "FEMININE" | "MASCULINE" | "NEUTRAL";
  /**
   * The user's preferred pronouns. Eg. "they / them". This is a human-readable
   * string to be displayed as the user's pronoun. Set at write-time, regardless
   * of pronoun-type. Value is returned as it was set (no localization).
   */
  value?: string;
}

/**
 * Stores the pronunciation as phoneme for the given word/text. Next ID: 8
 */
export interface SocialGraphApiProtoPronunciation {
  /**
   * All pronunciations with the same learning_session_id were learnt in the
   * same learning flow, e.g. multiple name segments learnt simultaneously from
   * a recording in the Your People UI.
   */
  learningSessionId?: string;
  learningSource?:  | "LEARNING_SOURCE_UNKNOWN" | "EXPLICIT_YOUR_PEOPLE_UI" | "INFERRED_COMMS_DIALOG";
  /**
   * The locale used when learning the pronunciation. BCP-47 language code,
   * e.g. "en-US".
   */
  locale?: string;
  /**
   * Phoneme sequence representing how the user pronounces |token|. Format is
   * specified by the phonology_type type field, e.g. go/psampa is the preferred
   * phonology type used by the TTS team.
   */
  phonemes?: string;
  phonologyType?:  | "PHONOLOGY_TYPE_UNKNOWN" | "PSAMPA";
  /**
   * An optional user-specified spelling of this token, to improve
   * pronunciation learning success rate. E.g. the token may be "Jana" and the
   * spelling hint "jah-nah".
   */
  spellingHint?: string;
  /**
   * Corresponds to a word segment of the contact name. E.g. for a contact with
   * given name "John Doe", last name "Smith" and nickname "Best Dad", |token|
   * can be any of {John, Doe, Smith, Best, Dad}.
   */
  token?: string;
}

/**
 * Container proto for repeated pronunciation objects. For example, a set of
 * pronunciations that can be added to a single name field.
 */
export interface SocialGraphApiProtoPronunciations {
  pronunciation?: SocialGraphApiProtoPronunciation[];
}

/**
 * Flexible Recurrence proto to be used with People Prompts. Examples: Single
 * recurrence that occurs on a specific date: single_recurrence { date { year:
 * 2022 month: 11 day: 17 } } Yearly recurrence such as a birthday or
 * anniversary: yearly_recurrence { monthly_pattern { monthly_day_recurrence {
 * month_day: 17 } } months: JULY } Weekly reccurrence such as: every two weeks
 * on Monday: every: 2 weekly_recurrence { week_day: MONDAY } Monthly recurrence
 * such as: third Thursday of every month: monthly_recurrence {
 * monthly_weekday_recurrence { week_day: THURSDAY week_day_number: 3 } } Used
 * in PeopleAPI layers + FBS/ContactsService (not in ProfileService) The
 * canonical recurrence validation function is located here:
 * http://google3/java/com/google/social/people/prompts/util/PromptValidators.java?q=func:%5CbvalidateRecurrence%5Cb
 */
export interface SocialGraphApiProtoRecurrence {
  dailyRecurrence?: SocialGraphApiProtoDailyRecurrence;
  /**
   * Multiplier on the frequency of the recurrence. Use this to specify
   * patterns that recur every X days, months, years, etc. Must be a positive
   * int. Example: [remind me to call mom every 2nd week]. If this field isn't
   * set, it will default to 1 (every day,every week, etc). This field is
   * ignored when recurrence_data is a SingleRecurrence. Optional.
   */
  every?: number;
  monthlyRecurrence?: SocialGraphApiProtoMonthlyRecurrence;
  /**
   * Ends at abstract DateTime. (inclusive)
   */
  recurrenceEndDate?: GoogleTypeDateTime;
  /**
   * The start of the recurrence can be represented as a DateTime. This field
   * is ignored when recurrence_data is a SingleRecurrence.
   */
  recurrenceStart?: GoogleTypeDateTime;
  /**
   * Will repeat only a finite number of times. This is the original number of
   * times the recurrence will repeat and not how many times are left for it to
   * repeat. This end type is not currently supported.
   */
  repeatCount?: number;
  /**
   * Will continue to repeat until prompt is deleted.
   */
  repeatForever?: SocialGraphApiProtoRecurrenceRepeatForever;
  singleRecurrence?: SocialGraphApiProtoSingleRecurrence;
  weeklyRecurrence?: SocialGraphApiProtoWeeklyRecurrence;
  yearlyRecurrence?: SocialGraphApiProtoYearlyRecurrence;
}

function serializeSocialGraphApiProtoRecurrence(data: any): SocialGraphApiProtoRecurrence {
  return {
    ...data,
    recurrenceEndDate: data["recurrenceEndDate"] !== undefined ? serializeGoogleTypeDateTime(data["recurrenceEndDate"]) : undefined,
    recurrenceStart: data["recurrenceStart"] !== undefined ? serializeGoogleTypeDateTime(data["recurrenceStart"]) : undefined,
  };
}

function deserializeSocialGraphApiProtoRecurrence(data: any): SocialGraphApiProtoRecurrence {
  return {
    ...data,
    recurrenceEndDate: data["recurrenceEndDate"] !== undefined ? deserializeGoogleTypeDateTime(data["recurrenceEndDate"]) : undefined,
    recurrenceStart: data["recurrenceStart"] !== undefined ? deserializeGoogleTypeDateTime(data["recurrenceStart"]) : undefined,
  };
}

/**
 * An internal message to signal that this recurrence has no end date.
 */
export interface SocialGraphApiProtoRecurrenceRepeatForever {
}

/**
 * Position relative to the user's avatar. 0 = top/left, 1 = bottom/right.
 */
export interface SocialGraphApiProtoRelativePosition {
  x?: number;
  y?: number;
}

/**
 * Scale relative to the user's avatar. x and y range from 0 (exclusive) to 1
 * (inclusive).
 */
export interface SocialGraphApiProtoRelativeScale {
  x?: number;
  y?: number;
}

/**
 * Data contained in every search profile. go/janata-profile-in-sgbe.
 */
export interface SocialGraphApiProtoSearchProfileData {
  /**
   * A free-text summary that the user inputs. E.g. "Coder by day, jazz
   * guitarist by night."
   */
  description?: string;
  education?: SocialGraphApiProtoSearchProfileEducation[];
  interest?: SocialGraphApiProtoSearchProfileEntity[];
  /**
   * Indicates the language of this search profile. Use ISO-639 2-letter
   * language code to specifying the language that this profile is created in.
   */
  language?: string;
  location?: SocialGraphApiProtoSearchProfileLocation[];
  metadata?: SocialGraphApiProtoSearchProfileMetadata;
  occupation?: SocialGraphApiProtoSearchProfileEntity[];
  /**
   * This is the email that the user has chosen to display on their
   * "SearchCard" publicly.
   */
  publicEmail?: string[];
  /**
   * This is the phone number that the user has chosen to display on their
   * "SearchCard" publicly.
   */
  publicPhoneNumber?: string[];
  socialLink?: SocialGraphApiProtoSearchProfileSocialLink[];
  website?: string[];
  workplace?: SocialGraphApiProtoSearchProfileWorkplace[];
}

function serializeSocialGraphApiProtoSearchProfileData(data: any): SocialGraphApiProtoSearchProfileData {
  return {
    ...data,
    location: data["location"] !== undefined ? data["location"].map((item: any) => (serializeSocialGraphApiProtoSearchProfileLocation(item))) : undefined,
    metadata: data["metadata"] !== undefined ? serializeSocialGraphApiProtoSearchProfileMetadata(data["metadata"]) : undefined,
  };
}

function deserializeSocialGraphApiProtoSearchProfileData(data: any): SocialGraphApiProtoSearchProfileData {
  return {
    ...data,
    location: data["location"] !== undefined ? data["location"].map((item: any) => (deserializeSocialGraphApiProtoSearchProfileLocation(item))) : undefined,
    metadata: data["metadata"] !== undefined ? deserializeSocialGraphApiProtoSearchProfileMetadata(data["metadata"]) : undefined,
  };
}

/**
 * Wraps information about a user's eductational background.
 */
export interface SocialGraphApiProtoSearchProfileEducation {
  endTime?: GoogleTypeDate;
  fieldOfStudy?: SocialGraphApiProtoSearchProfileEntity[];
  institution?: SocialGraphApiProtoSearchProfileEntity;
  startTime?: GoogleTypeDate;
}

/**
 * This proto represents either a KG-entity, as represented by it's MID, or
 * free-string text.
 */
export interface SocialGraphApiProtoSearchProfileEntity {
  /**
   * Corresponding country code. Refer to go/people-search-dashboard for code
   * list.
   */
  countryCode?: string;
  /**
   * Corresponding mid in KG.
   */
  entity?: string;
  /**
   * Custom name of entity if there is no corresponding place/entity in KG
   * (mid)
   */
  name?: string[];
}

/**
 * Wraps information about a user's location, if they have chosen to share it
 * on their SearchCard.
 */
export interface SocialGraphApiProtoSearchProfileLocation {
  endTime?: GoogleTypeDate;
  lengthOfStay?: number /* Duration */;
  place?: SocialGraphApiProtoSearchProfileEntity;
  point?: SocialGraphApiProtoSearchProfileLocationInfo;
  startTime?: GoogleTypeDate;
  type?:  | "LOCATION_TYPE_UNKNOWN" | "HOMETOWN" | "CURRENT" | "PAST";
}

function serializeSocialGraphApiProtoSearchProfileLocation(data: any): SocialGraphApiProtoSearchProfileLocation {
  return {
    ...data,
    lengthOfStay: data["lengthOfStay"] !== undefined ? data["lengthOfStay"] : undefined,
  };
}

function deserializeSocialGraphApiProtoSearchProfileLocation(data: any): SocialGraphApiProtoSearchProfileLocation {
  return {
    ...data,
    lengthOfStay: data["lengthOfStay"] !== undefined ? data["lengthOfStay"] : undefined,
  };
}

export interface SocialGraphApiProtoSearchProfileLocationInfo {
  /**
   * Degrees [-90 .. 90]
   */
  lat?: number;
  /**
   * Degrees [-180 .. 180]
   */
  lon?: number;
  /**
   * Meters
   */
  radius?: number;
}

/**
 * This proto represents metadata of the users SearchProfile like profile
 * state, GOG account id etc.,
 */
export interface SocialGraphApiProtoSearchProfileMetadata {
  /**
   * Unique contributor account id allocated by presence/janata infrastructure.
   * This will be used in the frontend for various actions like reporting
   * errors, photo uploads etc., go/boba-janata, go/cleanup-contributor-creation
   */
  accountId?: string;
  /**
   * Account KG entity mid assigned to this user required by old janata serving
   * stack. This is not required anymore for serving. But might need it for
   * historical purposes. See https://hume.google.com/edit/g/11gg6cyvch for more
   * details.
   */
  accountMid?: string;
  /**
   * Ares id used for tracking the auto moderation.
   */
  aresId?: string;
  /**
   * Current state of the Search Profile.
   */
  state?: SocialGraphApiProtoSearchProfileState[];
}

function serializeSocialGraphApiProtoSearchProfileMetadata(data: any): SocialGraphApiProtoSearchProfileMetadata {
  return {
    ...data,
    state: data["state"] !== undefined ? data["state"].map((item: any) => (serializeSocialGraphApiProtoSearchProfileState(item))) : undefined,
  };
}

function deserializeSocialGraphApiProtoSearchProfileMetadata(data: any): SocialGraphApiProtoSearchProfileMetadata {
  return {
    ...data,
    state: data["state"] !== undefined ? data["state"].map((item: any) => (deserializeSocialGraphApiProtoSearchProfileState(item))) : undefined,
  };
}

/**
 * Wraps social profile information about the user.
 */
export interface SocialGraphApiProtoSearchProfileSocialLink {
  link?: string;
  type?:  | "SOCIAL_LINK_TYPE_UNKNOWN" | "FACEBOOK" | "INSTAGRAM" | "LINKEDIN" | "PINTERIST" | "SOUNDCLOUD" | "TWITTER" | "YOUTUBE" | "PINTEREST" | "JUMPROPE" | "TIKTOK" | "WORDPRESS" | "FIREWORK" | "SNAPCHAT";
}

export interface SocialGraphApiProtoSearchProfileState {
  /**
   * Timestamp of when the state was changed.
   */
  changeTimestamp?: Date;
  /**
   * This will be used to display status to the user at a set time. If set to a
   * value after `change_timestamp`, the change will not be 'reflected' until
   * this time.
   */
  displayTimestamp?: Date;
  /**
   * State that the UserProfile was changed to.
   */
  type?:  | "UNKNOWN_PROFILE_STATE" | "STATE_DRAFT" | "STATE_FAILED_PHONE_VERIFICATION" | "STATE_FAILED_ID_VERIFICATION" | "STATE_FAILED_CONTENT_VERIFICATION" | "STATE_NEEDS_MANUAL_REVIEW" | "STATE_PUBLIC" | "STATE_DELETED" | "STATE_CONTENT_VERIFICATION_REQUIRED" | "STATE_REJECTED_FOR_IMPERSONATION" | "STATE_REQUIRES_ID_VERIFICATION";
}

function serializeSocialGraphApiProtoSearchProfileState(data: any): SocialGraphApiProtoSearchProfileState {
  return {
    ...data,
    changeTimestamp: data["changeTimestamp"] !== undefined ? data["changeTimestamp"].toISOString() : undefined,
    displayTimestamp: data["displayTimestamp"] !== undefined ? data["displayTimestamp"].toISOString() : undefined,
  };
}

function deserializeSocialGraphApiProtoSearchProfileState(data: any): SocialGraphApiProtoSearchProfileState {
  return {
    ...data,
    changeTimestamp: data["changeTimestamp"] !== undefined ? new Date(data["changeTimestamp"]) : undefined,
    displayTimestamp: data["displayTimestamp"] !== undefined ? new Date(data["displayTimestamp"]) : undefined,
  };
}

/**
 * Wraps information about a user working at a specific place.
 */
export interface SocialGraphApiProtoSearchProfileWorkplace {
  company?: SocialGraphApiProtoSearchProfileEntity;
  endTime?: GoogleTypeDate;
  startTime?: GoogleTypeDate;
}

/**
 * This prompt will occur one time only. Could be a single event such as a
 * graduation or a single connection reminder e.g. remind me to call X on
 * 2022/03/19. Used in PeopleAPI layers + FBS/ContactsService (not in
 * ProfileService)
 */
export interface SocialGraphApiProtoSingleRecurrence {
  date?: GoogleTypeDate;
}

/**
 * LINT.IfChange
 */
export interface SocialGraphApiProtoSyncInfo {
  /**
   * CP2 sourceid column.
   */
  sourceId?: string;
  /**
   * CP2 sync1 column.
   */
  sync1?: string;
  /**
   * CP2 sync2 column.
   */
  sync2?: string;
  /**
   * CP2 sync3 column.
   */
  sync3?: string;
  /**
   * CP2 sync4 column.
   */
  sync4?: string;
}

export interface SocialGraphApiProtoThirdPartyInfo {
  /**
   * Not to be used. We have since moved to a lookup string at read time
   * approach as opposed to storing data at write time. b/146072927
   */
  clientName?: string;
  /**
   * Project number of the third party application performing the delete to be
   * looked up via ClientAuthConfig during display time for users to know the
   * current name of an application which has deleted contact data.
   */
  projectNumber?: bigint;
}

function serializeSocialGraphApiProtoThirdPartyInfo(data: any): SocialGraphApiProtoThirdPartyInfo {
  return {
    ...data,
    projectNumber: data["projectNumber"] !== undefined ? String(data["projectNumber"]) : undefined,
  };
}

function deserializeSocialGraphApiProtoThirdPartyInfo(data: any): SocialGraphApiProtoThirdPartyInfo {
  return {
    ...data,
    projectNumber: data["projectNumber"] !== undefined ? BigInt(data["projectNumber"]) : undefined,
  };
}

/**
 * Usage information. This is currently used for device contacts. Next ID: 3
 */
export interface SocialGraphApiProtoUsageInfo {
  /**
   * Last time a contact was contacted.
   */
  lastTimeContacted?: Date;
  /**
   * Number of times a contact was contacted.
   */
  timesContacted?: bigint;
}

function serializeSocialGraphApiProtoUsageInfo(data: any): SocialGraphApiProtoUsageInfo {
  return {
    ...data,
    lastTimeContacted: data["lastTimeContacted"] !== undefined ? data["lastTimeContacted"].toISOString() : undefined,
    timesContacted: data["timesContacted"] !== undefined ? String(data["timesContacted"]) : undefined,
  };
}

function deserializeSocialGraphApiProtoUsageInfo(data: any): SocialGraphApiProtoUsageInfo {
  return {
    ...data,
    lastTimeContacted: data["lastTimeContacted"] !== undefined ? new Date(data["lastTimeContacted"]) : undefined,
    timesContacted: data["timesContacted"] !== undefined ? BigInt(data["timesContacted"]) : undefined,
  };
}

/**
 * Pattern for a WEEKLY recurrence. You must specify at least one week_day.
 * Used in PeopleAPI layers + FBS/ContactsService (not in ProfileService)
 */
export interface SocialGraphApiProtoWeeklyRecurrence {
  /**
   * Set of weekdays the recurrence applies to.
   */
  weekDay?:  | "DAY_OF_WEEK_UNSPECIFIED" | "MONDAY" | "TUESDAY" | "WEDNESDAY" | "THURSDAY" | "FRIDAY" | "SATURDAY" | "SUNDAY"[];
}

/**
 * Pattern for a YEARLY recurrence. A YEARLY recurrence is specified using a
 * monthly pattern and a set of months the pattern applies to. Some examples:
 * "Every January 16" : monthly_pattern { monthly_day_recurrence { month_day: 16
 * } } months: JANUARY "Fourth Thursday of November and December" :
 * monthly_pattern { monthly_weekday_recurrence { week_day: THURSDAY
 * week_day_number: 4 } } months: NOVEMBER months: DECEMBER Used in PeopleAPI
 * layers + FBS/ContactsService (not in ProfileService)
 */
export interface SocialGraphApiProtoYearlyRecurrence {
  /**
   * The monthly pattern to recur.
   */
  monthlyPattern?: SocialGraphApiProtoMonthlyRecurrence;
  /**
   * The months of the year to apply the pattern.
   */
  months?:  | "MONTH_UNSPECIFIED" | "JANUARY" | "FEBRUARY" | "MARCH" | "APRIL" | "MAY" | "JUNE" | "JULY" | "AUGUST" | "SEPTEMBER" | "OCTOBER" | "NOVEMBER" | "DECEMBER"[];
}

/**
 * Extra ranking info returned with affinity data. This info is returned by DAS
 * and passed to PAPI clients (Yenta), where it is used for ranking and
 * filtering device and server suggestions together.
 */
export interface SocialGraphWireProtoPeopleapiAffinityMetadata {
  /**
   * Information regarding client interactions.
   */
  clientInteractionInfo?: SocialGraphWireProtoPeopleapiAffinityMetadataClientInteractionInfo;
  /**
   * Device information about the candidate available in the cloud.
   */
  cloudDeviceDataInfo?: SocialGraphWireProtoPeopleapiAffinityMetadataCloudDeviceDataInfo;
  /**
   * Affinity score for the cloud contact.
   */
  cloudScore?: number;
}

export interface SocialGraphWireProtoPeopleapiAffinityMetadataClientInteractionInfo {
  /**
   * Whether this suggestion is an edge directly from the client. E.g., a
   * suggestion with which the user shared a photo on photos app.
   */
  isDirectClientInteraction?: boolean;
}

export interface SocialGraphWireProtoPeopleapiAffinityMetadataCloudDeviceDataInfo {
  /**
   * The partial affinity score only counting device features.
   */
  deviceScore?: number;
  /**
   * Whether device data about this candidate were available in the cloud.
   */
  isDeviceDataKnown?: boolean;
}

/**
 * Waldo-related extension data.
 */
export interface SocialGraphWireProtoPeopleapiExtensionAppsWaldoExtendedData {
  availabilities?: GoogleInternalAppsWaldoV1alphaUserAvailabilities;
}

function serializeSocialGraphWireProtoPeopleapiExtensionAppsWaldoExtendedData(data: any): SocialGraphWireProtoPeopleapiExtensionAppsWaldoExtendedData {
  return {
    ...data,
    availabilities: data["availabilities"] !== undefined ? serializeGoogleInternalAppsWaldoV1alphaUserAvailabilities(data["availabilities"]) : undefined,
  };
}

function deserializeSocialGraphWireProtoPeopleapiExtensionAppsWaldoExtendedData(data: any): SocialGraphWireProtoPeopleapiExtensionAppsWaldoExtendedData {
  return {
    ...data,
    availabilities: data["availabilities"] !== undefined ? deserializeGoogleInternalAppsWaldoV1alphaUserAvailabilities(data["availabilities"]) : undefined,
  };
}

/**
 * Dynamite-related extension data.
 */
export interface SocialGraphWireProtoPeopleapiExtensionDynamiteExtendedData {
  /**
   * Avatar image URL for a Google Group, based on the member count.
   */
  avatarUrl?: string;
  /**
   * Short description of this bot. Only set if EntityType == BOT.
   */
  description?: string;
  /**
   * Display name of bot developer. Only set if EntityType == BOT.
   */
  developerName?: string;
  dndState?:  | "UNKNOWN_DND_STATE" | "AVAILABLE" | "DND";
  entityType?:  | "UNKNOWN_ENTITY_TYPE" | "PERSON" | "GOOGLE_GROUP" | "BOT";
  /**
   * Number of members (direct or indirect) in a Google Group. Only an estimate
   * for large groups (currently > 1K direct / indirect members).
   */
  memberCount?: bigint;
  /**
   * NEXT TAG: 9
   */
  organizationInfo?: AppsDynamiteSharedOrganizationInfo;
  presence?:  | "UNDEFINED_PRESENCE" | "ACTIVE" | "INACTIVE" | "UNKNOWN" | "SHARING_DISABLED";
}

function serializeSocialGraphWireProtoPeopleapiExtensionDynamiteExtendedData(data: any): SocialGraphWireProtoPeopleapiExtensionDynamiteExtendedData {
  return {
    ...data,
    memberCount: data["memberCount"] !== undefined ? String(data["memberCount"]) : undefined,
  };
}

function deserializeSocialGraphWireProtoPeopleapiExtensionDynamiteExtendedData(data: any): SocialGraphWireProtoPeopleapiExtensionDynamiteExtendedData {
  return {
    ...data,
    memberCount: data["memberCount"] !== undefined ? BigInt(data["memberCount"]) : undefined,
  };
}

/**
 * Next tag number: 3
 */
export interface SocialGraphWireProtoPeopleapiExtensionPaisaExtendedData {
  /**
   * Actor ID of the person, if available (if the person has used the Paisa
   * app).
   */
  actorId?: string;
  /**
   * Display subtitle, which may be used in suggestion/autocompletion results.
   * Generally, this will be the Actor's registered Paisa phone number, in
   * unmasked or masked form (e.g. +1 ***-***-1234) depending on visibility
   * rules.
   */
  subtitle?: string;
}

export interface SocialGraphWireProtoPeopleapiExtensionPeopleStackExtendedData {
  /**
   * Whether the person is in the same family as the requesting user. Family
   * here refers to https://families.google.com/families. This information is
   * read from SuperGlue, and can be consumed by clients, e.g. Assistant and
   * Photos. If this field is not set, the person is not in the user's family.
   */
  familyStatus?:  | "FAMILY_STATUS_UNSPECIFIED" | "FAMILY_MEMBER";
  /**
   * The full list of hidden keys associated with this person. These are the
   * external equivalent to the keys stored by the ConnectionLabelService, and
   * they can be passed to the MutateConnectionLabel endpoint to unhide this
   * person. This field will only be set if hide_type is HIDDEN.
   */
  hiddenKeys?: SocialDiscoveryExternalEntityKey[];
  /**
   * If this field is not set, the person is visible (implicit).
   */
  hideType?:  | "HIDE_TYPE_UNSPECIFIED" | "HIDDEN";
}

/**
 * NEXT_ID: 5
 */
export interface SocialGraphWireProtoPeopleapiExtensionPeopleStackPersonExtendedData {
  /**
   * Whether the person has birthday field populated.
   */
  birthdayStatus?:  | "BIRTHDAY_STATUS_UNSPECIFIED" | "HAS_BIRTHDAY";
  /**
   * Whether the person is in the same family as the requesting user. Family
   * here refers to https://families.google.com/families. This information is
   * read from SuperGlue, and can be consumed by clients, e.g. Assistant and
   * Photos. If this field is not set, the person is not in the user's family.
   */
  familyStatus?:  | "FAMILY_STATUS_UNSPECIFIED" | "FAMILY_MEMBER";
  /**
   * The full list of hidden keys associated with this person. These are the
   * external equivalent to the keys stored by the ConnectionLabelService, and
   * they can be passed to the MutateConnectionLabel endpoint to unhide this
   * person. This field will only be set if hide_type is HIDDEN.
   */
  hiddenKeys?: SocialDiscoveryExternalEntityKey[];
  /**
   * If this field is not set, the person is visible (implicit).
   */
  hideType?:  | "HIDE_TYPE_UNSPECIFIED" | "HIDDEN";
}

export interface SocialPersonalizationKnexAnnotation {
  item?: SocialPersonalizationKnexAnnotationItem[];
}

function serializeSocialPersonalizationKnexAnnotation(data: any): SocialPersonalizationKnexAnnotation {
  return {
    ...data,
    item: data["item"] !== undefined ? data["item"].map((item: any) => (serializeSocialPersonalizationKnexAnnotationItem(item))) : undefined,
  };
}

function deserializeSocialPersonalizationKnexAnnotation(data: any): SocialPersonalizationKnexAnnotation {
  return {
    ...data,
    item: data["item"] !== undefined ? data["item"].map((item: any) => (deserializeSocialPersonalizationKnexAnnotationItem(item))) : undefined,
  };
}

/**
 * Next Tag: 8
 */
export interface SocialPersonalizationKnexAnnotationItem {
  confidence?: number;
  /**
   * Description of the item for debugging. Note that this field is populated
   * only in a few select places.
   */
  description?: string;
  /**
   * If this field exists, then there exists a commonly used MID (typically a
   * public MID, i.e., one in /m/) that approximates the meaning for this
   * particular k'nex topic. For example, the value of this field for k'nex
   * topic Tennis (/t/236) is /m/07bs0. The difference between k'nex /m/07bs0
   * and webref /m/07bs0 is as follows. If a content is annotated with webref
   * /m/07bs0, then the content has to explicitly mention "Tennis" in some way,
   * whereas if a content is annotated with k'nex /m/07bs0, then the content
   * simply needs to talk about stuff related to tennis. Note that this field is
   * not populated for all queries. For example, the compound concept "Tennis in
   * California" does not have an associated mid. This field is intended to help
   * external clients transit to k'nex.
   */
  equivalentMid?: bigint;
  /**
   * A score that measures how broad / narrow a topic is, independent of the
   * document and/or user profile. This is an experimental score and is not
   * populated by default. Currently, it is in the range of [0, 1], where the
   * higher the score is, the more general a topic is. Please talk to
   * sherlock-dev@ before using this score. Populated when debug_level > 0.
   */
  generality?: number;
  /**
   * This is an MID in the /t/ namespace. We will migrate them to /g/ in Q3'15.
   */
  mid?: bigint;
  relatedEntity?: SocialPersonalizationKnexAnnotationItemTopic[];
  topicality?: number;
}

function serializeSocialPersonalizationKnexAnnotationItem(data: any): SocialPersonalizationKnexAnnotationItem {
  return {
    ...data,
    equivalentMid: data["equivalentMid"] !== undefined ? String(data["equivalentMid"]) : undefined,
    mid: data["mid"] !== undefined ? String(data["mid"]) : undefined,
    relatedEntity: data["relatedEntity"] !== undefined ? data["relatedEntity"].map((item: any) => (serializeSocialPersonalizationKnexAnnotationItemTopic(item))) : undefined,
  };
}

function deserializeSocialPersonalizationKnexAnnotationItem(data: any): SocialPersonalizationKnexAnnotationItem {
  return {
    ...data,
    equivalentMid: data["equivalentMid"] !== undefined ? BigInt(data["equivalentMid"]) : undefined,
    mid: data["mid"] !== undefined ? BigInt(data["mid"]) : undefined,
    relatedEntity: data["relatedEntity"] !== undefined ? data["relatedEntity"].map((item: any) => (deserializeSocialPersonalizationKnexAnnotationItemTopic(item))) : undefined,
  };
}

export interface SocialPersonalizationKnexAnnotationItemTopic {
  mid?: bigint;
  score?: number;
}

function serializeSocialPersonalizationKnexAnnotationItemTopic(data: any): SocialPersonalizationKnexAnnotationItemTopic {
  return {
    ...data,
    mid: data["mid"] !== undefined ? String(data["mid"]) : undefined,
  };
}

function deserializeSocialPersonalizationKnexAnnotationItemTopic(data: any): SocialPersonalizationKnexAnnotationItemTopic {
  return {
    ...data,
    mid: data["mid"] !== undefined ? BigInt(data["mid"]) : undefined,
  };
}

/**
 * Restrictions that affect the delivery of the stanza. By default, Stanzas are
 * publishable, which means that they are eligible for indexing, aggregation,
 * and other delivery options (Goops, Moonshine, notifications). A stanza can be
 * created in a "do not publish" state; the stanza will not be published
 * anywhere. The restriction can subsequently be removed with an UpdateStanza
 * call, at which point the post will be treated as if it were newly created. A
 * few notes/limitations about this option: 1. Client should keep a stanza
 * unpublishable for a small period of time (if possible to) so that our ranking
 * system does not consider this as a stale post (thus downranking the post). 2.
 * Client should keep the number of unpublishable stanzas to a minimum, to
 * reduce under-serving. 3. Updating a stanza from publishable to unpublishable
 * after creation is not supported 4. At this time, publishing options are only
 * supported on root stanzas; let us know if you require this for child stanzas.
 * 5. Similarly, this is only supported as a global restriction. It may not be
 * set as a per-destination-stream restriction.
 */
export interface SocialStanzaDeliveryRestriction {
  doNotPublish?: boolean;
}

/**
 * ModerationInfo stores the information of moderation for a stanza in a
 * specific destination stream. Including who moderated and why.
 */
export interface SocialStanzaModerationInfo {
  /**
   * The reason why this stanza was moderated provided by client.
   */
  moderationReason?: string;
  moderator?: SecurityCredentialsPrincipalProto;
  /**
   * Type of moderation. Semantically REQUIRED, http://go/required At write
   * time, only ModeratorType.AUTO_MODERATOR is allowed. For all other cases,
   * this information is inferred from the request at write time.
   */
  moderatorType?:  | "MODERATOR_TYPE_UNKNOWN" | "SYSTEM" | "MODERATOR" | "SYSTEM_BADWORD_BLACKLIST" | "AUTO_MODERATOR";
}

function serializeSocialStanzaModerationInfo(data: any): SocialStanzaModerationInfo {
  return {
    ...data,
    moderator: data["moderator"] !== undefined ? serializeSecurityCredentialsPrincipalProto(data["moderator"]) : undefined,
  };
}

function deserializeSocialStanzaModerationInfo(data: any): SocialStanzaModerationInfo {
  return {
    ...data,
    moderator: data["moderator"] !== undefined ? deserializeSecurityCredentialsPrincipalProto(data["moderator"]) : undefined,
  };
}

/**
 * Contains various restriction information about a stanza, derived from
 * properties of the stanza, the viewer and the creator. Restrictions stored in
 * this message are not related to direct/indirect relationship between the
 * viewer and the creator of stanza. Some examples are: - Abusive - Legal - Racy
 * - Content not suitable for age - Porn - Blocked by country/geo of viewer. -
 * Restricted by stanza creator (not the user specific block). - etc... Please
 * see go/stanza-abuse-flow for more details.
 */
export interface SocialStanzaStanzaRestriction {
  /**
   * The abuses.
   */
  abuseTypes?: AbuseiamAbuseType[];
  /**
   * The appeal state.
   */
  appealState?:  | "UNKNOWN_APPEAL_STATE" | "APPEALED" | "APPEAL_REJECTED" | "APPEAL_APPROVED";
  /**
   * Field to explain various restrictions of the Stanza. Some examples of
   * restrictions are: - Not permitted because of legal restrictions of
   * geography/country of viewer or creator. - Content not suitable for current
   * viewer i.e. porn, abusive, racy. - Creator restricted the content to an age
   * group. - etc...
   */
  contentRestriction?: AbuseiamContentRestriction;
  /**
   * Delete reasons. This is a repeated field because an stanza can be deleted
   * multiple times due to different reasons such as user_delete, admin_delete.
   */
  deleteReason?:  | "UNKNOWN_DELETE_REASON" | "USER_ACCOUNT_DELETE" | "OWNER_DELETE" | "SPAM_ADMIN_DELETE" | "SPAM_ADMIN_DELETE_CHILD_PORN" | "SYSTEM_DELETE" | "USER_ACCOUNT_DISABLE" | "DESTINATION_STREAM_OWNER_DELETE" | "SBE_ADMIN_TAKEDOWN" | "CLIENT_ADMIN_TAKEDOWN" | "SPAM_ADMIN_SUSPEND" | "ANCESTOR_DELETE" | "USER_PRODUCT_DOWNGRADE" | "USER_PRODUCT_SUSPENDED" | "ENTITY_STATE_CHANGE" | "ENTITY_ADMIN_DELETED" | "ENTITY_DELETED_DUE_TO_CLASSIFICATION" | "ENTITY_PURGED" | "USER_UNDERAGE" | "YOUTUBE_CHANNEL_HIDDEN" | "YOUTUBE_SERVICE_REMOVED" | "YOUTUBE_LIGHTWEIGHT_DELETED" | "YOUTUBE_LIGHTWEIGHT_HIDDEN"[];
  /**
   * Delivery restrictions, if present.
   */
  deliveryRestriction?: SocialStanzaDeliveryRestriction;
  destinationStream?: AppsPeopleActivityBackendDestinationStream;
  /**
   * The moderation info. At write time, this field is only allowed to be set
   * when moderator_type is AUTO_MODERATOR. For other moderator types,
   * moderation_reason is the only field that can be set by clients.
   */
  moderationInfo?: SocialStanzaModerationInfo;
  /**
   * The moderation state.
   */
  moderationState?:  | "UNKNOWN_MODERATION_STATE" | "NEW" | "APPROVED" | "REJECTED" | "HOLD";
}

function serializeSocialStanzaStanzaRestriction(data: any): SocialStanzaStanzaRestriction {
  return {
    ...data,
    contentRestriction: data["contentRestriction"] !== undefined ? serializeAbuseiamContentRestriction(data["contentRestriction"]) : undefined,
    moderationInfo: data["moderationInfo"] !== undefined ? serializeSocialStanzaModerationInfo(data["moderationInfo"]) : undefined,
  };
}

function deserializeSocialStanzaStanzaRestriction(data: any): SocialStanzaStanzaRestriction {
  return {
    ...data,
    contentRestriction: data["contentRestriction"] !== undefined ? deserializeAbuseiamContentRestriction(data["contentRestriction"]) : undefined,
    moderationInfo: data["moderationInfo"] !== undefined ? deserializeSocialStanzaModerationInfo(data["moderationInfo"]) : undefined,
  };
}

/**
 * This holds SpamBrain values which will be populated to docjoins & muppet.
 * Proto is copied from spam_brain::SpamBrainData and populated at sitechunked
 * site level (as opposed to the spambrain page classifier score).
 */
export interface SpamBrainData {
  /**
   * Sitechunker site granularity for this result
   */
  site?: string;
  /**
   * Versioned scores of SB classifiers
   */
  versionedData?: SpamBrainScore[];
}

/**
 * Message representing versioned scores
 */
export interface SpamBrainScore {
  /**
   * The value corresponding to this version.
   */
  sbScore?: number;
  /**
   * The version id.
   */
  versionId?: number;
}

/**
 * This protocol buffer indicates actions that we take based on Cookbook
 * recipes (see http://cookbook/) matching a particular document.
 */
export interface SpamCookbookAction {
  dropInServing?: boolean;
}

export interface SpamMuppetjoinsMuppetSignals {
  hackedDateNautilus?: number;
  hackedDateRaiden?: number;
  raidenScore?: number;
  site?: string;
}

/**
 * Response proto for the LangId service running on a Greco server in prod.
 * Next Tag: 6
 */
export interface SpeechS3LanguageIdentificationResult {
  /**
   * The end time of the input audio that this result refers to. This value
   * should increase across LanguageIdentificationResult emitted by the Greco
   * server running LangId, and reflects the server having processed more of the
   * input audio.
   */
  endTimeUsec?: bigint;
  /**
   * Ranked list of top-N language codes. Ranking is based on
   * ConfidenceIntervals of supported languages, and N is defined in the
   * LanguageIdentificationConfig.
   */
  rankedTopSupportedLanguages?: SpeechS3Locale[];
  /**
   * Global start time. This value should be fixed across all
   * LanguageIdentificationResults for a given utterance.
   */
  startTimeUsec?: bigint;
  /**
   * Confidence interval of the top recognized language.
   */
  topLanguageConfidence?:  | "UNKNOWN_CONFIDENCE" | "NOT_CONFIDENT" | "CONFIDENT" | "HIGHLY_CONFIDENT";
  /**
   * Identifies when the provided audio sample does or doesn't contain voiced
   * samples. E.g. an unvoice utterance happens when the EOS signal is received
   * before any frame because all frames were filtered by the endpointer. For
   * events where voiced_utterance is false, ranked_top_supported_languages is
   * defined but scores are not to be trusted. All LanguageIdentificationResults
   * contains a valid value of voiced_utterance.
   */
  voicedUtterance?: boolean;
}

function serializeSpeechS3LanguageIdentificationResult(data: any): SpeechS3LanguageIdentificationResult {
  return {
    ...data,
    endTimeUsec: data["endTimeUsec"] !== undefined ? String(data["endTimeUsec"]) : undefined,
    startTimeUsec: data["startTimeUsec"] !== undefined ? String(data["startTimeUsec"]) : undefined,
  };
}

function deserializeSpeechS3LanguageIdentificationResult(data: any): SpeechS3LanguageIdentificationResult {
  return {
    ...data,
    endTimeUsec: data["endTimeUsec"] !== undefined ? BigInt(data["endTimeUsec"]) : undefined,
    startTimeUsec: data["startTimeUsec"] !== undefined ? BigInt(data["startTimeUsec"]) : undefined,
  };
}

export interface SpeechS3Locale {
  /**
   * The format of the string in "locale". Should be one of LocaleFormat.
   */
  format?: number;
  locale?: string;
}

/**
 * go/entity-authority NB: currently all facts associated with Authority
 * Feedback are externally traceable to the requests from which they originate.
 */
export interface StorageGraphBfgAuthorityFeedbackMetadata {
}

export interface StorageGraphBfgLegalRequestMetadata {
  /**
   * The buganizer ID associated with this legal request. This is required.
   */
  bugId?: bigint;
}

function serializeStorageGraphBfgLegalRequestMetadata(data: any): StorageGraphBfgLegalRequestMetadata {
  return {
    ...data,
    bugId: data["bugId"] !== undefined ? String(data["bugId"]) : undefined,
  };
}

function deserializeStorageGraphBfgLegalRequestMetadata(data: any): StorageGraphBfgLegalRequestMetadata {
  return {
    ...data,
    bugId: data["bugId"] !== undefined ? BigInt(data["bugId"]) : undefined,
  };
}

/**
 * Metadata on source assertions that isn't part of the user-visible Triple
 * payload, and that doesn't really represent data provenance, but that's used
 * to affect the way Livegraph and possibly other horizontal KG infra systems
 * *process* the triple. Read: fields below really shouldn't be part of the
 * cross-system Triple proto at all. But because Triple is used both as an
 * internal and an external KG API, we at least want to "hide" those fields that
 * ought to be purely part of the internal source <-> LG contract. Next id: 6
 */
export interface StorageGraphBfgLivegraphProvenanceMetadata {
  /**
   * If one triple is directly-written after recon by LG without going through
   * Composer, we add the record id it's from. Otherwise, it's empty. Note: 1)
   * LG will dedup record ids before updating it. So this field shouldn't see
   * duplicated record ids. 2) This is used internally by LG only. So if set by
   * clients, they will be dropped by LG.
   */
  directWriteRecordIds?: string[];
  /**
   * Identifies the LG internal writers that asserted the triple. This is the
   * same as 'origin_id' in LG. This will only be populated by the LG writers to
   * FactStore
   */
  lgInternalWriterId?: bigint;
  /**
   * Whether this provenance is a provenance only addition or not. A provenance
   * is considered an "addition" if it belongs to a triple that we expect
   * FactStore to contain on its own (i.e through some inference), and thus we
   * will *not* attempt to write it explicitly. This is a composer only
   * populated field. Clients are not expected to populate this field.
   */
  provenanceOnlyAddition?: boolean;
  /**
   * Triples typically have a single triangulation key. This field supports > 1
   * keys to allow staged transition to a different key scheme. To successfully
   * triangulate in the Livegraph Composer, the triple must have >=3 instances
   * and each triple instance having a pairwise disjoint set of triangulation
   * keys. The triangulation keys supplied for a single input triple are treated
   * part of the same set, so a single triple cannot self-triangulate,
   * regardless of how many triangulation keys it has. Note2: If a triple has
   * multiple provenances, each one is expected to set the same
   * triangulation_keys.
   */
  triangulationKey?: string[];
  /**
   * WARNING! The feature is still under active development and the exact
   * semantics may be subject to change pending KE Design Review. Data marked as
   * weak will be less preferred to regular data which does not have the marker.
   * This allows ingesting data with a lower chance of negatively affecting
   * existing features and products, at the cost of potentially not showing the
   * data when competing data is available. Specifically, weak data is less
   * preferred by conflict resolution inside of Livegraph composition.
   * Additionally, RefX triggering will prefer to trigger based on signals
   * computed from regular data. Aside from data providers choosing to mark
   * their data as weak, Livegraph and RefX are the only horizontal systems
   * expected to use this information. Please contact livegraph-team@ if you see
   * a need for this to change. See go/weak-data for more information.
   */
  weakData?: boolean;
}

function serializeStorageGraphBfgLivegraphProvenanceMetadata(data: any): StorageGraphBfgLivegraphProvenanceMetadata {
  return {
    ...data,
    lgInternalWriterId: data["lgInternalWriterId"] !== undefined ? String(data["lgInternalWriterId"]) : undefined,
  };
}

function deserializeStorageGraphBfgLivegraphProvenanceMetadata(data: any): StorageGraphBfgLivegraphProvenanceMetadata {
  return {
    ...data,
    lgInternalWriterId: data["lgInternalWriterId"] !== undefined ? BigInt(data["lgInternalWriterId"]) : undefined,
  };
}

/**
 * Metadata fields for LMS. See go/lms-online-restrictions for details.
 */
export interface StorageGraphBfgLmsPolicyMetadata {
  clientIdsAllowed?: string[];
  isEditorial?: boolean;
  /**
   * Int values corresponds to the values of
   * image_repository.licensed.api.restrictions.Modification enum.
   */
  modificationsAllowed?: bigint[];
  regionsAllowed?: KeGovernanceTypedRegions;
  regionsDisallowed?: KeGovernanceTypedRegions;
  requiresAttribution?: boolean;
  requiresFirstPartyOnly?: boolean;
  requiresLinkback?: boolean;
  requiresShareAlike?: boolean;
}

function serializeStorageGraphBfgLmsPolicyMetadata(data: any): StorageGraphBfgLmsPolicyMetadata {
  return {
    ...data,
    modificationsAllowed: data["modificationsAllowed"] !== undefined ? data["modificationsAllowed"].map((item: any) => (String(item))) : undefined,
  };
}

function deserializeStorageGraphBfgLmsPolicyMetadata(data: any): StorageGraphBfgLmsPolicyMetadata {
  return {
    ...data,
    modificationsAllowed: data["modificationsAllowed"] !== undefined ? data["modificationsAllowed"].map((item: any) => (BigInt(item))) : undefined,
  };
}

/**
 * Metadata about data governance policies. For more context, see
 * go/ke-triple-dg-policy-and-metadata. If any attribute is not set, then
 * there's no specific restrictions associated with the missing attribute. For
 * example, if `availability_start_timestamp` is not set, the data won't be
 * embargoed automatically; if `availability_end_timestamp` is not set, they
 * won't expire automatically. LINT.IfChange
 */
export interface StorageGraphBfgPolicyMetadata {
  /**
   * Timestamp after which data with this policy cannot be used. This value
   * must be strictly larger/later than availability_start_time, if both are
   * set.
   */
  availabilityEndTimestamp?: Date;
  /**
   * Timestamp before which data with this policy cannot be used. This value
   * must be strictly smaller/earlier than availability_end_time, if both are
   * set.
   */
  availabilityStartTimestamp?: Date;
  /**
   * List of regions in which the data with this policy is allowed to be used,
   * while the data need to be removed in all regions outside this list
   * according to legal request. This field should be used when the data is only
   * allowed in a few regions and it is inconvenient to enumerate all of the
   * regions in `legal_removal_regions` field. `legal_allowed_regions` and
   * `legal_removal_region` together should include all possible regions,
   * setting one field implies the other. Please set only one of them so the
   * other field's values are implied. See details:
   * http://go/ke-allowed-countries-policy-1p WARNING: This field is for legal
   * purposes only. Please do not populate it without consulting
   * ke-data-governance@.
   */
  legalAllowedRegions?: KeGovernanceTypedRegions[];
  /**
   * List of regions in which the data with this policy need to be removed
   * according to legal request. WARNING: This field is for legal purposes only.
   * Please do not populate it without consulting ke-data-governance@.
   */
  legalRemovalRegions?: KeGovernanceTypedRegions[];
  /**
   * Policy metadata fields for LMS data. Only expected to be used by LMS
   * providers -- please consult ke-data-governance@ before populating this
   * field.
   */
  lmsPolicyMetadata?: StorageGraphBfgLmsPolicyMetadata;
  /**
   * This triple is protected by the policies with PolicyDataScope identified
   * by these global unique ids.
   */
  policyDataScopeKeys?: number[];
  /**
   * Policy metadata are VERTICAL by default. Vertical policy makers /
   * providers does not need to set this field explicitly.
   */
  policySourceType?:  | "UNKNOWN" | "VERTICAL" | "HORIZONTAL";
  /**
   * Policy metadata fields for UMP data. Only expected to be used by UMP
   * providers -- please consult ke-data-governance@ before populating this
   * field.
   */
  umpPolicyMetadata?: StorageGraphBfgUmpPolicyMetadata;
}

function serializeStorageGraphBfgPolicyMetadata(data: any): StorageGraphBfgPolicyMetadata {
  return {
    ...data,
    availabilityEndTimestamp: data["availabilityEndTimestamp"] !== undefined ? data["availabilityEndTimestamp"].toISOString() : undefined,
    availabilityStartTimestamp: data["availabilityStartTimestamp"] !== undefined ? data["availabilityStartTimestamp"].toISOString() : undefined,
    lmsPolicyMetadata: data["lmsPolicyMetadata"] !== undefined ? serializeStorageGraphBfgLmsPolicyMetadata(data["lmsPolicyMetadata"]) : undefined,
    umpPolicyMetadata: data["umpPolicyMetadata"] !== undefined ? serializeStorageGraphBfgUmpPolicyMetadata(data["umpPolicyMetadata"]) : undefined,
  };
}

function deserializeStorageGraphBfgPolicyMetadata(data: any): StorageGraphBfgPolicyMetadata {
  return {
    ...data,
    availabilityEndTimestamp: data["availabilityEndTimestamp"] !== undefined ? new Date(data["availabilityEndTimestamp"]) : undefined,
    availabilityStartTimestamp: data["availabilityStartTimestamp"] !== undefined ? new Date(data["availabilityStartTimestamp"]) : undefined,
    lmsPolicyMetadata: data["lmsPolicyMetadata"] !== undefined ? deserializeStorageGraphBfgLmsPolicyMetadata(data["lmsPolicyMetadata"]) : undefined,
    umpPolicyMetadata: data["umpPolicyMetadata"] !== undefined ? deserializeStorageGraphBfgUmpPolicyMetadata(data["umpPolicyMetadata"]) : undefined,
  };
}

export interface StorageGraphBfgPublicInformationMetadata {
  /**
   * Publicly-visible URLs claiming this fact. Can not be empty -- at least one
   * URL must be provided.
   */
  attributionUrl?: string[];
  /**
   * Most recent date at which 'attribution_url's were verified, as UNIX epoch
   * time in milliseconds. This is required.
   */
  lastVerifiedDate?: bigint;
}

function serializeStorageGraphBfgPublicInformationMetadata(data: any): StorageGraphBfgPublicInformationMetadata {
  return {
    ...data,
    lastVerifiedDate: data["lastVerifiedDate"] !== undefined ? String(data["lastVerifiedDate"]) : undefined,
  };
}

function deserializeStorageGraphBfgPublicInformationMetadata(data: any): StorageGraphBfgPublicInformationMetadata {
  return {
    ...data,
    lastVerifiedDate: data["lastVerifiedDate"] !== undefined ? BigInt(data["lastVerifiedDate"]) : undefined,
  };
}

/**
 * A fact about potentially sensitive personal info (http://what/SPII) can be
 * "certified" iff it meets specific requirements. See go/kg-spii-certification
 * for details.
 */
export interface StorageGraphBfgSpiiCertification {
  /**
   * This fact was provided via KGO / Entity Authority.
   */
  authorityFeedback?: StorageGraphBfgAuthorityFeedbackMetadata;
  /**
   * This fact was provided via a legal request.
   */
  legalRequest?: StorageGraphBfgLegalRequestMetadata;
  /**
   * This fact is public information. (See go/kg-spii-certification for a
   * description of what qualifies as public information -- simply finding a
   * fact online is not sufficient to certify a fact as public.)
   */
  publicInformation?: StorageGraphBfgPublicInformationMetadata;
}

function serializeStorageGraphBfgSpiiCertification(data: any): StorageGraphBfgSpiiCertification {
  return {
    ...data,
    legalRequest: data["legalRequest"] !== undefined ? serializeStorageGraphBfgLegalRequestMetadata(data["legalRequest"]) : undefined,
    publicInformation: data["publicInformation"] !== undefined ? serializeStorageGraphBfgPublicInformationMetadata(data["publicInformation"]) : undefined,
  };
}

function deserializeStorageGraphBfgSpiiCertification(data: any): StorageGraphBfgSpiiCertification {
  return {
    ...data,
    legalRequest: data["legalRequest"] !== undefined ? deserializeStorageGraphBfgLegalRequestMetadata(data["legalRequest"]) : undefined,
    publicInformation: data["publicInformation"] !== undefined ? deserializeStorageGraphBfgPublicInformationMetadata(data["publicInformation"]) : undefined,
  };
}

/**
 * a message containing information about the source of this triple. Note for
 * freebase data: that this is an unpacking of the creator/attribution chain.
 * The creator below is the actual creator of the attribution node, and the rest
 * of the attribution data sits along side. Next id: 22
 */
export interface StorageGraphBfgTripleProvenance {
  /**
   * Data providers shall use this to specify access requirement.
   */
  accessRequired?:  | "ACCESS_REQUIREMENT_UNSPECIFIED" | "LEGACY_RESTRICTION" | "LEGAL_UNSERVABLE_UNTIL_FURTHER_REVIEW" | "CONTRACTUAL_PRERELEASE_MUSIC_DATA" | "CONTRACTUAL_PRERELEASE_MUSIC_DATA_GPM" | "CONTRACTUAL_STATS_LLC_DATA" | "LEGAL_PUBLIC_DOMAIN_US" | "LEGAL_GEO_NOT_SERVABLE_IN_CHINA" | "ACCESS_REQUIREMENT_OUT_OF_RANGE" | "SPII_SEARCH_PUBLIC_INTEREST" | "SPII_KGO" | "SPII_WALDREF" | "CONTRACTUAL_OPTA_DATA_MIGRATION" | "CONTRACTUAL_STATS_DATA_MIGRATION" | "TECHNICAL_DEBT_SIRIUS_MIGRATION" | "TECHNICAL_IN_DEVELOPMENT_GEO_KG_UGC" | "MOMA_RESTRICTED_TVC" | "MOMA_UNRESTRICTED_TVC" | "MOMA_FTE" | "AOG_TEST_DATA" | "CONTRACTUAL_NETFLIX_DATA" | "CONTRACTUAL_NETFLIX_GRACENOTE" | "CONTRACTUAL_SPOTIFY_PODCAST_DATA" | "CONTRACTUAL_IPG_DATA" | "CONTRACTUAL_YOUVIEW_DATA" | "CONTRACTUAL_YOUTUBE_ALC_DATA" | "CREATOR_PRESENCE_DATA" | "TECHNICAL_UNRECONCILED_MEDIA_ACTION" | "CONTRACTUAL_AUDIBLE_DATA" | "CONTRACTUAL_SEARCH_NETFLIX_DATA" | "CONTRACTUAL_ASSISTANT_MEDIA_ACTIONS" | "CONTRACTUAL_ANDROID_TV_NETFLIX_DATA" | "CONTRACTUAL_GOOGLE_PLAY_MOVIES_DATA" | "CONTRACTUAL_RANKING_PROVIDER_POPULARITY_DATA" | "CONTRACTUAL_CARBON_INDEX_DATA" | "CONTRACTUAL_CARBON_INDEX_APP" | "TRAVEL_ACTIVITY_DATA" | "CONTRACTUAL_AOG_FOOD_ORDERING_DATA" | "CONTRACTUAL_YETI_DATA" | "CONTRACTUAL_BBC_PROVIDER_METADATA" | "JANATA_USER_GENERATED_DATA" | "TRIANGULATION_LOSERS_FOR_REFX" | "CONTRACTUAL_PRERELEASE_YT_SHOWS" | "SPII_LOSERS_FOR_REFX" | "SHOPPING_PRODUCT_IMAGE" | "SHOPPING_PRODUCT_DESCRIPTION" | "SHOPPING_PRODUCT_ATTRIBUTE" | "SHOPPING_ON_DOT_COM_ONLY" | "SHOPPING_ORGANIC_ONLY" | "SHOPPING_ORGANIC_ON_DOT_COM_ONLY" | "SHOPPING_PRE_RELEASE_PRODUCT" | "SHOPPING_DO_NOT_PUBLISH_TO_TOPIC_SERVER" | "LMS_POLICY_ACKED_ONLY" | "MINED_PEOPLE" | "LIMITED_FOR_SEMANTIC_UNDERSTANDING" | "ISOLATION_S3_MEDIA_ACTION" | "ISOLATION_S3_REAL_ESTATE" | "ISOLATION_S3_AUTOS" | "ISOLATION_S3_NLWEB" | "ISOLATION_S3_RECOMEDIA" | "ISOLATION_S3_GEO_CARS" | "ISOLATION_YOUTUBE_OTT" | "ISOLATION_YOUTUBE_MUSIC_BASS_ENTITIES" | "ISOLATION_FINANCIAL_DATA" | "ISOLATION_MEDICAL" | "ISOLATION_G4C" | "ISOLATION_EXPERIMENT_ONLY" | "ISOLATION_KE_INTERNAL" | "ISOLATION_WEB_CHANNELS" | "ISOLATION_ONRAMP_DICTIONARY_EXPERIMENT" | "ISOLATION_S3_TRAVEL_HOTEL_ROOMS" | "ISOLATION_PKG_ANDROID_AUTO_EMBEDDED_SIGNED_IN" | "ISOLATION_PKG_ANDROID_AUTO_EMBEDDED_SIGNED_OUT" | "ISOLATION_PKG_APP_NAMES" | "ISOLATION_PKG_ASSISTANT_CONTACT_AFFINITY_WITH_METADATA" | "ISOLATION_PKG_ASSISTANT_DEVICE_SETTINGS" | "ISOLATION_PKG_ASSISTANT_LIST_NAMES_FOR_SPEECH_BIASING" | "ISOLATION_PKG_ASSISTANT_SETTINGS_FOOTPRINTS" | "ISOLATION_PKG_ASSISTANT_SETTINGS_NICKNAME" | "ISOLATION_PKG_CALENDAR_EVENTS_FOR_QUERY_ANNOTATION" | "ISOLATION_PKG_CALENDAR_EVENTS_FOR_SPEECH_BIASING" | "ISOLATION_PKG_CALENDARS_FOR_QUERY_ANNOTATION" | "ISOLATION_PKG_CALENDARS_FOR_SPEECH_BIASING" | "PKG_ASSISTANT_CONTACT_AFFINITY_FOOTPRINTS" | "ISOLATION_PKG_CONTACT_AGGREGATED_SIGNALS" | "ISOLATION_PKG_CONTENT_INTERESTS" | "ISOLATION_PKG_DEVICE_INSTALLED_APPS" | "ISOLATION_PKG_DISCOVER_SMART_HOME_DEVICES" | "ISOLATION_PKG_DYNAMIC_ENTITIES" | "ISOLATION_PKG_FLIGHT_LEG_RESERVATIONS" | "ISOLATION_PKG_FOCUS_OWNER_PROFILE" | "ISOLATION_PKG_FORMATTED_ADDRESS" | "ISOLATION_PKG_GAIA" | "ISOLATION_PKG_GELLER_ANSWERS" | "ISOLATION_PKG_GMAIL_BILLS" | "ISOLATION_PKG_GMAIL_ORDERS" | "ISOLATION_PKG_HABITS" | "ISOLATION_PKG_HANDBAG_ENTITIES" | "ISOLATION_PKG_HERON_INTENTS_AND_TYPES" | "ISOLATION_PKG_HOTEL_RESERVATIONS" | "ISOLATION_PKG_HOUSEHOLD" | "ISOLATION_PKG_LAMS_PREFERENCES" | "ISOLATION_PKG_LOCATION_SHARING_CONTACTS" | "ISOLATION_PKG_MAPS_ALIAS_FOOTPRINTS" | "ISOLATION_PKG_MAPS_SEARCH_LOCATIONS" | "ISOLATION_PKG_LOCAL_LEAF_PAGE_VIEW_LOCATIONS" | "ISOLATION_PKG_MEDIA_HABITUAL_CACHE" | "ISOLATION_PKG_MEDIA_LIBRARY" | "ISOLATION_PKG_MEDIA_USER_CONTEXT_INFO" | "ISOLATION_PKG_MEDIA_USER_ENTITIES" | "ISOLATION_PKG_PARKING_LOCATIONS" | "ISOLATION_PKG_PEOPLE_API" | "ISOLATION_PKG_PEOPLE_API_CONTACT_ANNOTATIONS" | "ISOLATION_PKG_PEOPLE_API_GET_PEOPLE_BY_IDS" | "ISOLATION_PKG_PERSONAL_CONTACT_ANNOTATIONS" | "ISOLATION_PKG_PERSONAL_PLACES" | "ISOLATION_PKG_PERSONAL_SHARED_CONTACT_ANNOTATIONS" | "ISOLATION_PKG_PERSONALIZED_PRONUNCIATIONS" | "ISOLATION_PKG_PLAY_AUDIO_BOOKS" | "ISOLATION_PKG_PWS_ASSISTANT_CONTACTS_FOOTPRINTS" | "ISOLATION_PKG_ASSISTANT_UPP_PERSONAL_TOP_ENTITIES" | "PKG_RESERVATION_DATA" | "ISOLATION_PKG_GI_HOTEL_RESERVATION_DATA" | "ISOLATION_PKG_GI_FLIGHT_RESERVATION_DATA" | "ISOLATION_PKG_GI_CAR_RENTAL_RESERVATION_DATA" | "ISOLATION_PKG_GI_TRANSPORTATION_RESERVATION_DATA" | "ISOLATION_PKG_GI_RESTAURANT_RESERVATION_DATA" | "ISOLATION_PKG_RESTAURANT_RESERVATIONS" | "ISOLATION_PKG_SELF_ENTITIES" | "ISOLATION_PKG_SOCIAL_EVENT_RESERVATIONS" | "ISOLATION_PKG_SOCIAL_GRAPH_PEOPLE_API" | "ISOLATION_PKG_STADIA_CONTACTS" | "ISOLATION_PKG_STARLIGHT_BULK_LOOKUP" | "ISOLATION_PKG_STARLIGHT_BULK_LOOKUP_CONSISTENT" | "ISOLATION_PKG_STARLIGHT_BULK_LOOKUP_CONSISTENT_CONTACTS" | "ISOLATION_PKG_STARLIGHT_COMPOSITE" | "ISOLATION_PKG_STARLIGHT_COMPOSITE_FACE_LABELS" | "ISOLATION_PKG_STARLIGHT_FACE_LABELS" | "ISOLATION_PKG_STARLIGHT_QUERY" | "ISOLATION_PKG_STARLIGHT_TOP_CONTACTS" | "ISOLATION_PKG_STARLIGHT_VISIBLE_TO_GUESTS" | "ISOLATION_PKG_STRUCTURED_MEMORY_FOOTPRINTS" | "ISOLATION_PKG_TEACH_AND_LEARN_ENTITIES" | "ISOLATION_PKG_ASSISTANT_ROUTINES" | "ISOLATION_PKG_VANITY_COLLECTIONS" | "ISOLATION_PKG_WEBSEARCH" | "ISOLATION_PKG_WHITEPAGES_PHONE_NUMBER" | "ISOLATION_PKG_VOICE_PROFILE" | "ISOLATION_PKG_YOUTUBE_ASSISTANT_CONTEXT" | "ISOLATION_PKG_YOUTUBE_ASSISTANT_XWALKSAFE_CONTEXT" | "ISOLATION_PKG_YOUTUBE_MUSIC_LOCKER" | "ISOLATION_PKG_YOUTUBE_PLAYLISTS" | "ISOLATION_PKG_YOUTUBE_PLAYLIST_SEARCH" | "ISOLATION_PKG_YOUTUBE_PRIVATE_PLAYLISTS" | "ISOLATION_PKG_YOUTUBE_PUBLIC_AND_PRIVATE_PLAYLISTS" | "ISOLATION_S3_CREATOR_PRESENCE" | "ISOLATION_S12Y_RECIPE_INGREDIENT_INSIGHTS" | "UMP_TESTING_ONLY" | "INTENTJOINS_NB_SIGNALS" | "ADS_INTEGRITY_ANNOTATION" | "COVID_MAPS_SENSITIVE" | "KE_TRUST" | "SENSITIVE_ENTITIES_CLASSIFICATION" | "ISOLATION_S3_DATASEARCH" | "VIRTUALCARE_US" | "NETFLIX_AVAILABILITY_MEDIA_ACTION" | "ACCC_RISKY_DATA" | "AU_ACCC_RISKY_FOR_DISPLAY" | "GEO_FEATURE_RESTRICTION" | "RIGHTS_MANAGEMENT_100" | "RIGHTS_MANAGEMENT_101" | "RIGHTS_MANAGEMENT_102" | "DICTIONARY_DATA_OXFORD" | "DICTIONARY_DATA_LE_ROBERT" | "ENTITY_TEXT_FEATURES" | "AR_ONBOARDING_TEST" | "AR_ONBOARDING_TEST_2" | "MATERIALIZED_ENRICHER_INTERNAL" | "MATERIALIZED_SCUBED_INTERNAL";
  /**
   * For KE internal use only. Data providers shall *not* set this. At ingress,
   * LG Record service will read access_required and properly translate it to
   * access_required_int. KE horizontal systems shall use this field instead of
   * access_required; so that binaries would not depend on the release of a
   * newly introduced AccessRequirement enum. (go/easy-ar-onboarding)
   */
  accessRequiredInt?: number;
  authoringTimestamp?: bigint;
  /**
   * Freebase: the freebase user id in the form '/user/userid' KG: the Google
   * LDAP of the developer or MDB group that set up the triplification and
   * import pipeline for this data source.
   */
  creator?: string;
  /**
   * Freebase & KG: the dataset the assertion was loaded from
   */
  dataset?: string;
  extractionPattern?: Uint8Array;
  extractionTimestamp?: bigint;
  /**
   * Below are deprecated Provenance fields. They are not indexed or served in
   * KE infrastructure (they are stripped at ingress in Livegraph).
   */
  freebaseAttribution?: string;
  /**
   * Indicates that the corresponding data is supporting evidence for
   * reconciliation only, and is *not* an assertion that should be visible to
   * other systems or to external users. Note that this also means that no
   * provenances indicating supporting data will be visible in the composed
   * graph. Please see go/supporting-kg-triples-design-doc for additional
   * details and background. If a triple is sent to Livegraph with multiple
   * provenances each of them must have is_supporting_data bit set for it to be
   * considered valid supporting evidence triple.
   */
  isSupportingData?: boolean;
  /**
   * Internal metadata used by Livegraph and possibly other horizontal KG infra
   * systems. This is not part of the logical triple or its provenance, and
   * contents may not be visible downstream of LG.
   */
  lgMetadata?: StorageGraphBfgLivegraphProvenanceMetadata;
  /**
   * Metadata specifying data governance policies. This information will be
   * processed and enforced in KE systems. For more context, see
   * go/ke-triple-dg-policy-and-metadata. WARNING: This field is WIP and please
   * do not populate it without consulting ke-data-governance@.
   */
  policyMetadata?: StorageGraphBfgPolicyMetadata;
  /**
   * Used to uniquely identify data sources. Freebase: the OAuth application
   * KG: the name of the source directory the triple was loaded from (eg, "amg",
   * "tms ", "collections"). KV: identifier of an extraction system, e.g., SAFT
   * or Tractzor.
   */
  process?: string;
  provenanceExtension?: Proto2BridgeMessageSet;
  /**
   * 'ranking_token' (which must be accompanied by the 'process' field above or
   * will be ignored) is used to distinguish subsets of data within a single
   * process, solely for the purposes of composition in Livegraph. This field is
   * useful when partitioning of data is needed, but using a separate process is
   * intractable due to organizational or infrastructure limitations. For
   * example, if a process such as "geo" wishes to distinguish some of their
   * /type/object/name triples as higher priority in Composer's conflict
   * resolution rules, then they can add a config entry with a dedicated
   * ranking_token and tag the relevant triples with that ranking_token. This
   * field should only be used in conjunction with a Composer-side configuration
   * to use it for value selection. It is not appropriate to use this field as
   * free-form metadata. This value must match [[:alnum:]][[:alnum:]_-]{0,127}
   * (i.e., [a-zA-Z0-9]+[a-zA-Z0-9_-]* and must be less than 128 characters in
   * length) , or else its containing triple will be considered malformed and
   * will be rejected by Livegraph at ingress. As of 2018-02-14, this field is
   * used within Livegraph's Composer and is exposed in Livegraph's Lookup APIs
   * to aid debugging, but it is not indexed or served by TopicServer.
   */
  rankingToken?: string;
  /**
   * When specified as part of triples input to Livegraph (go/livegraph), this
   * indicates that the triple needs to be triangulated by 3 different sources
   * before it can be served in production. A triple's source is identified by
   * its URL(provenance.source).host(). Please see go/baike-triangulation for
   * more background on this. WARNING: If you're a new client trying to enable
   * triangulation for your feed, please contact lg-composition@/kashk@ before
   * using this feature.
   */
  requiresTriangulation?: boolean;
  restrictions?:  | "REQUIRES_CITATION" | "REQUIRES_PCOUNSEL_REVIEW" | "REQUIRES_ACCESS_CONTROL" | "UNRESTRICTED_WITHIN_GOOGLE_NO_3P_USE"[];
  /**
   * Freebase & KG: if the triples were extracted from the web, the source URL
   * where the assertion was found. (generally empty in freebase-sourced
   * triples) TopicServer will serve/populate/retain if REQUIRES_CITATION is
   * also set, or if the process is explicitly allowed.
   * http://g/topic-server/vn9PBWtVKqI/arQEDqKTAgAJ
   */
  source?: string;
  sourceCategory?:  | "THIRD_PARTY" | "CURATION" | "PARTNER_FEED" | "EXTRACTION"[];
  sourceDocId?: bigint[];
  spiiCertification?: StorageGraphBfgSpiiCertification;
}

function serializeStorageGraphBfgTripleProvenance(data: any): StorageGraphBfgTripleProvenance {
  return {
    ...data,
    authoringTimestamp: data["authoringTimestamp"] !== undefined ? String(data["authoringTimestamp"]) : undefined,
    extractionPattern: data["extractionPattern"] !== undefined ? encodeBase64(data["extractionPattern"]) : undefined,
    extractionTimestamp: data["extractionTimestamp"] !== undefined ? String(data["extractionTimestamp"]) : undefined,
    lgMetadata: data["lgMetadata"] !== undefined ? serializeStorageGraphBfgLivegraphProvenanceMetadata(data["lgMetadata"]) : undefined,
    policyMetadata: data["policyMetadata"] !== undefined ? serializeStorageGraphBfgPolicyMetadata(data["policyMetadata"]) : undefined,
    sourceDocId: data["sourceDocId"] !== undefined ? data["sourceDocId"].map((item: any) => (String(item))) : undefined,
    spiiCertification: data["spiiCertification"] !== undefined ? serializeStorageGraphBfgSpiiCertification(data["spiiCertification"]) : undefined,
  };
}

function deserializeStorageGraphBfgTripleProvenance(data: any): StorageGraphBfgTripleProvenance {
  return {
    ...data,
    authoringTimestamp: data["authoringTimestamp"] !== undefined ? BigInt(data["authoringTimestamp"]) : undefined,
    extractionPattern: data["extractionPattern"] !== undefined ? decodeBase64(data["extractionPattern"] as string) : undefined,
    extractionTimestamp: data["extractionTimestamp"] !== undefined ? BigInt(data["extractionTimestamp"]) : undefined,
    lgMetadata: data["lgMetadata"] !== undefined ? deserializeStorageGraphBfgLivegraphProvenanceMetadata(data["lgMetadata"]) : undefined,
    policyMetadata: data["policyMetadata"] !== undefined ? deserializeStorageGraphBfgPolicyMetadata(data["policyMetadata"]) : undefined,
    sourceDocId: data["sourceDocId"] !== undefined ? data["sourceDocId"].map((item: any) => (BigInt(item))) : undefined,
    spiiCertification: data["spiiCertification"] !== undefined ? deserializeStorageGraphBfgSpiiCertification(data["spiiCertification"]) : undefined,
  };
}

/**
 * Metadata fields for UMP. A piece of data satisfies UMP policy if: (data
 * access region is in the `regions_allowed` list) AND (data access time >=
 * availability_start_timestamp) AND (data access time <
 * availability_end_timestamp)
 */
export interface StorageGraphBfgUmpPolicyMetadata {
  /**
   * Timestamp after which data with this policy cannot be used.
   */
  availabilityEnds?: Date;
  /**
   * Timestamp before which data with this policy cannot be used.
   */
  availabilityStarts?: Date;
  regionsAllowed?: KeGovernanceTypedRegions;
}

function serializeStorageGraphBfgUmpPolicyMetadata(data: any): StorageGraphBfgUmpPolicyMetadata {
  return {
    ...data,
    availabilityEnds: data["availabilityEnds"] !== undefined ? data["availabilityEnds"].toISOString() : undefined,
    availabilityStarts: data["availabilityStarts"] !== undefined ? data["availabilityStarts"].toISOString() : undefined,
  };
}

function deserializeStorageGraphBfgUmpPolicyMetadata(data: any): StorageGraphBfgUmpPolicyMetadata {
  return {
    ...data,
    availabilityEnds: data["availabilityEnds"] !== undefined ? new Date(data["availabilityEnds"]) : undefined,
    availabilityStarts: data["availabilityStarts"] !== undefined ? new Date(data["availabilityStarts"]) : undefined,
  };
}

/**
 * LINT.IfChange Next ID: 101
 */
export interface SuperrootPodcastsRecommendationsPodcastRecsFeatures {
  /**
   * Average duration listened per episode. Ignores duration < 10s. Computed
   * offline
   */
  averageDurationSecondsEpisode?: bigint;
  /**
   * Average duration listened per show. Ignores duration < 10s. Computed
   * offline
   */
  averageDurationSecondsShow?: bigint;
  /**
   * Average fraction of podcast listened per episode. Ignores duration < 10s.
   * Computed offline
   */
  averageFractionEpisode?: number;
  /**
   * Average fraction of podcast listened per show. Ignores duration < 10s.
   * Computed offline
   */
  averageFractionShow?: number;
  /**
   * Per cluster lift where the lift_squashing_factor is set to 0.4
   */
  balancedLift?: number;
  /**
   * category_match is a 0 to 1 score depicting how much of the user's
   * listening history matches the categories of this podcast recommendation.
   */
  categoryMatch?: number;
  /**
   * The total minutes listened to this podcast show by users in this cluster
   */
  clusterFeedMinutes?: bigint;
  /**
   * This captures the probability that this show could have been listened by
   * the user in lieu of what they have subscribed or listened to.
   */
  colistenedShowColistenAffinity?: number;
  /**
   * This captures the rank of the podcast show in the colisten candidate
   * generator.
   */
  colistenedShowLevelRank?: bigint;
  convAiToxicitySevereScore?: number;
  /**
   * Score of csai safe search score go/safesearch
   */
  csaiScore?: number;
  /**
   * Ordinal rank features like this have been found to be useful in Hermione
   * Recipes, where the top ranked items from a candidate generator is always
   * retained. Ranks are integral values starting with 1 for the highest
   * affinity show.
   */
  dnnShowLevelRank?: bigint;
  /**
   * Dot product of user embedding and podcast show embedding from the two
   * tower model v2a
   */
  dnnV2aScore?: number;
  /**
   * Sigmoid of the score obtained by dot product of user embedding and show
   * embedding. See https://b.corp.google.com/issues/158602034#comment2 for
   * intuition.
   */
  dnnV2aScoreSigmoid?: number;
  /**
   * Total duration listened for this episode by all users. Ignores duration <
   * 10s. Computed offline
   */
  durationTotalSecondsEpisode?: bigint;
  /**
   * Total duration listened for this show by all users. Ignores duration <
   * 10s. Computed offline
   */
  durationTotalSecondsShow?: bigint;
  /**
   * The duration of a single episode, in seconds. - For show documents, this
   * is a duration of a typical recent episode, or an approximation thereof. -
   * For episode documents, this is the duration of the episode itself.
   */
  episodeDurationSec?: bigint;
  /**
   * Number of all episode impressions.
   */
  episodeImpressions?: bigint;
  /**
   * Number of episode impressions during the past week.
   */
  episodeImpressionsPastWeek?: bigint;
  /**
   * How frequently are podcasts published by this show. To see publishing
   * frequency calculation go here: http://shortn/_6zzfyEpBRq
   */
  episodesPublishedPerMonth?: bigint;
  /**
   * Whether the show is marked as explicit by the authors
   */
  explicitShow?:  | "EXPLICIT_NO" | "EXPLICIT_YES" | "EXPLICIT_CLEAN";
  /**
   * Scaled pagerank score for the feed url in [0..1]. Not to be confused with
   * pagerank above, which measures the pagerank for the feed's homepage.
   */
  feedPagerank?: number;
  /**
   * final reaction boost score computed from positive_reaction_boost_score and
   * negative_reaction_boost_score. The score will be applied as a multiplier on
   * the ranking score to adjust the ranking.
   */
  finalReactionBoostScore?: number;
  /**
   * Some of all fraction of this listened by users. Ignores duration < 10s.
   * Computed offline
   */
  fractionTotalEpisode?: number;
  /**
   * Some of all fraction of this show listened by users. Ignores duration <
   * 10s. Computed offline
   */
  fractionTotalShow?: number;
  /**
   * Score of fringe safe search score go/safesearch
   */
  fringeScore?: number;
  /**
   * Probability of a random user listening to this podcast randomly
   */
  globalProb?: number;
  /**
   * Probability of a random user from this cluster listening to this podcast
   * randomly (K-means specific feature)
   */
  inClusterProb?: number;
  /**
   * A binary value based on whether this is a canonical source for a cluster.
   */
  isCanonical?: boolean;
  /**
   * Ranks are integral values starting with 1 for the highest affinity show.
   */
  kmeansShowLevelRank?: bigint;
  /**
   * How much of user listening history match the language of this episode
   */
  languageMatch?: number;
  /**
   * Ownership verification status for the episode page URL.
   */
  linkOwnershipVerified?: boolean;
  /**
   * The rank of the show in the top listened shows candidate generator. Ranks
   * are integral values starting with 1 for the highest affinity show.
   */
  listenedShowLevelRank?: bigint;
  /**
   * This captures the fraction of total listening time accounted for by this
   * show.
   */
  listenedShowListeningAffinity?: number;
  /**
   * Number of minutes of podcasts listened by the user
   */
  listenTimeMin?: number;
  /**
   * Feature ID of a location. For more info, see go/feature-id.
   */
  locationFeatureId?: string;
  /**
   * Match score between user listening mids and episode webref entities, where
   * the listening can have happened at any time in the past. Values are in a
   * 0.0 to 1.0 range.
   */
  longUserListeningWebrefSimilarity?: number;
  /**
   * Score of medical safe search score go/safesearch
   */
  medicalScore?: number;
  /**
   * Match score between user listening mids and episode webref entities, where
   * the listening is limited to last two mohths activity. Values are in a 0.0
   * to 1.0 range.
   */
  mediumUserListeningWebrefSimilarity?: number;
  /**
   * boost score from the similarity between the candidate and the shows with
   * user negative feedback, currently the score will be applied directly to the
   * final ranking score: go/podcast-reaction-reranking-v1, but can be used as
   * reranker model feature in the future.
   */
  negativeReactionBoostScore?: number;
  /**
   * Per cluster lift where the lift_squashing_factor is set to +2
   */
  nicheLift?: number;
  /**
   * The number of users in this k-means cluster.
   */
  numListenersInKmeansCluster?: bigint;
  /**
   * The number of users in the k-means cluster who have listened to this feed.
   */
  numListenersToShowInKmeansCluster?: bigint;
  /**
   * Number of podcasts listened by the user
   */
  numListens?: number;
  /**
   * From: indexing/speech/proto/colisten-matrix.proto The number of
   * subscribers for this podcast series.
   */
  numSubscribersShow?: bigint;
  /**
   * From: indexing/speech/proto/colisten-matrix.proto Absolute number of
   * unique listeners during the past month.
   */
  numUniqueListenersShow?: bigint;
  /**
   * Score of offensive safe search score go/safesearch
   */
  offensiveScore?: number;
  peDurationScoreEpisode?: number;
  peDurationScoreShow?: number;
  peDurationTotalScoreEpisode?: number;
  peDurationTotalScoreShow?: number;
  peFractionScoreEpisode?: number;
  peFractionScoreShow?: number;
  peFractionTotalScoreEpisode?: number;
  peFractionTotalScoreShow?: number;
  peListenScoreEpisode?: number;
  /**
   * Anima User Embedding based features. Dot product of Anima User Embedding
   * and podcast embeddings from UserEmbeddingBasedSignals
   * (podcasts/quality/proto/ranking_signals.proto)
   */
  peListenScoreShow?: number;
  peListenTotalScoreEpisode?: number;
  peListenTotalScoreShow?: number;
  /**
   * Per cluster lift where the lift_squashing_factor is set to -3
   */
  popularLift?: number;
  /**
   * Score of porn safe search score go/safesearch
   */
  pornScore?: number;
  /**
   * boost score from the similarity between the candidate and the shows with
   * user positive feedback, currently the score will be applied directly to the
   * final ranking score: go/podcast-reaction-reranking-v1, but can be used as
   * reranker model feature in the future.
   */
  positiveReactionBoostScore?: number;
  /**
   * This is the language extracted from the query_language.
   */
  queryLanguage?: string;
  /**
   * The index in the list of most popular podcasts.
   */
  rank?: bigint;
  /**
   * rank_percent_contrib = 100 / ( 1 + rank_percent ) Here rank_percent was
   * derived from show level data in Wernicke corpus So if rank_percent of a
   * feed was 3, then the feature value would be: 100 / (1 + 3) = 25. This
   * indicator falls off quickly from 100 to almost 1 as we go from rank_percent
   * 0 to 100.
   */
  rankPercentContrib?: number;
  /**
   * Match score between user listening mids and episode webref entities, where
   * the listening is limited to recent activity. Values are in a 0.0 to 1.0
   * range.
   */
  recentUserListeningWebrefSimilarity?: number;
  /**
   * A reranking feature showing the age of the episode that is being
   * recommended. This is computed as (current time - publication_time)
   * publication_time of the episode is defined: (http://shortn/_S46Ouk5ZWW)
   * publication_time is specified as seconds since Unix Epoch.
   */
  secondsSincePublication?: bigint;
  /**
   * Base quality of the document, used as a multiplier for the query-specific
   * score. Should be in [0, 1] range. See:
   * http://g3doc/indexing/moonshine/generic/g3doc/doc/scoring
   */
  showBaseQuality?: number;
  /**
   * Number of show episode impressions.
   */
  showImpressions?: bigint;
  /**
   * Number of show impressions during the past week.
   */
  showImpressionsPastWeek?: bigint;
  /**
   * Language of the show from show data.
   */
  showLanguage?: string;
  /**
   * Show only impressions. Doesn't include shows of episode impressions.
   */
  showOnlyImpressions?: bigint;
  showOnlyImpressionsPastWeek?: bigint;
  /**
   * Expresses the absolute popularity rank within all documents.
   */
  showPopularRank?: bigint;
  /**
   * Score of spoof safe search score go/safesearch
   */
  spoofScore?: number;
  /**
   * This captures the fraction of total listening time accounted for by this
   * subscribed show.
   */
  subscribedShowListeningAffinity?: number;
  /**
   * The rank of the show in the subscription candidate generator. Ranks are
   * integral values starting with 1 for the highest subscribed affinity show.
   */
  subscriptionShowLevelRank?: bigint;
  surface?: string;
  /**
   * Show level trending score percent from Wernicke corpus.
   */
  trendingScorePercent?: bigint;
  /**
   * Inferred language preferences of the user with their probabilities.
   */
  ulpLanguage?: SuperrootPodcastsRecommendationsPodcastRecsFeaturesUserLanguage[];
  /**
   * How much of ulp match the language of this episode
   */
  ulpLanguageMatch?: number;
  /**
   * The distance between user's Anima embedding and the centroid of the
   * cluster in k-means.
   */
  userClusterDistance?: number;
  /**
   * Match score between user interest mids and episode salient entities. in a
   * 0.0 to 1.0 range.
   */
  userInterestsSalientSimilarity?: number;
  /**
   * Match score between user interest mids and episode webref entities. in a
   * 0.0 to 1.0 range.
   */
  userInterestsWebrefSimilarity?: number;
  /**
   * Language of shows in user history and how much they listened to each.
   */
  userLanguage?: SuperrootPodcastsRecommendationsPodcastRecsFeaturesUserLanguage[];
  /**
   * Score of violence safe search score go/safesearch
   */
  violenceScore?: number;
  /**
   * Score of vulgar safe search score go/safesearch
   */
  vulgarScore?: number;
}

function serializeSuperrootPodcastsRecommendationsPodcastRecsFeatures(data: any): SuperrootPodcastsRecommendationsPodcastRecsFeatures {
  return {
    ...data,
    averageDurationSecondsEpisode: data["averageDurationSecondsEpisode"] !== undefined ? String(data["averageDurationSecondsEpisode"]) : undefined,
    averageDurationSecondsShow: data["averageDurationSecondsShow"] !== undefined ? String(data["averageDurationSecondsShow"]) : undefined,
    clusterFeedMinutes: data["clusterFeedMinutes"] !== undefined ? String(data["clusterFeedMinutes"]) : undefined,
    colistenedShowLevelRank: data["colistenedShowLevelRank"] !== undefined ? String(data["colistenedShowLevelRank"]) : undefined,
    dnnShowLevelRank: data["dnnShowLevelRank"] !== undefined ? String(data["dnnShowLevelRank"]) : undefined,
    durationTotalSecondsEpisode: data["durationTotalSecondsEpisode"] !== undefined ? String(data["durationTotalSecondsEpisode"]) : undefined,
    durationTotalSecondsShow: data["durationTotalSecondsShow"] !== undefined ? String(data["durationTotalSecondsShow"]) : undefined,
    episodeDurationSec: data["episodeDurationSec"] !== undefined ? String(data["episodeDurationSec"]) : undefined,
    episodeImpressions: data["episodeImpressions"] !== undefined ? String(data["episodeImpressions"]) : undefined,
    episodeImpressionsPastWeek: data["episodeImpressionsPastWeek"] !== undefined ? String(data["episodeImpressionsPastWeek"]) : undefined,
    episodesPublishedPerMonth: data["episodesPublishedPerMonth"] !== undefined ? String(data["episodesPublishedPerMonth"]) : undefined,
    kmeansShowLevelRank: data["kmeansShowLevelRank"] !== undefined ? String(data["kmeansShowLevelRank"]) : undefined,
    listenedShowLevelRank: data["listenedShowLevelRank"] !== undefined ? String(data["listenedShowLevelRank"]) : undefined,
    numListenersInKmeansCluster: data["numListenersInKmeansCluster"] !== undefined ? String(data["numListenersInKmeansCluster"]) : undefined,
    numListenersToShowInKmeansCluster: data["numListenersToShowInKmeansCluster"] !== undefined ? String(data["numListenersToShowInKmeansCluster"]) : undefined,
    numSubscribersShow: data["numSubscribersShow"] !== undefined ? String(data["numSubscribersShow"]) : undefined,
    numUniqueListenersShow: data["numUniqueListenersShow"] !== undefined ? String(data["numUniqueListenersShow"]) : undefined,
    rank: data["rank"] !== undefined ? String(data["rank"]) : undefined,
    secondsSincePublication: data["secondsSincePublication"] !== undefined ? String(data["secondsSincePublication"]) : undefined,
    showImpressions: data["showImpressions"] !== undefined ? String(data["showImpressions"]) : undefined,
    showImpressionsPastWeek: data["showImpressionsPastWeek"] !== undefined ? String(data["showImpressionsPastWeek"]) : undefined,
    showOnlyImpressions: data["showOnlyImpressions"] !== undefined ? String(data["showOnlyImpressions"]) : undefined,
    showOnlyImpressionsPastWeek: data["showOnlyImpressionsPastWeek"] !== undefined ? String(data["showOnlyImpressionsPastWeek"]) : undefined,
    showPopularRank: data["showPopularRank"] !== undefined ? String(data["showPopularRank"]) : undefined,
    subscriptionShowLevelRank: data["subscriptionShowLevelRank"] !== undefined ? String(data["subscriptionShowLevelRank"]) : undefined,
    trendingScorePercent: data["trendingScorePercent"] !== undefined ? String(data["trendingScorePercent"]) : undefined,
  };
}

function deserializeSuperrootPodcastsRecommendationsPodcastRecsFeatures(data: any): SuperrootPodcastsRecommendationsPodcastRecsFeatures {
  return {
    ...data,
    averageDurationSecondsEpisode: data["averageDurationSecondsEpisode"] !== undefined ? BigInt(data["averageDurationSecondsEpisode"]) : undefined,
    averageDurationSecondsShow: data["averageDurationSecondsShow"] !== undefined ? BigInt(data["averageDurationSecondsShow"]) : undefined,
    clusterFeedMinutes: data["clusterFeedMinutes"] !== undefined ? BigInt(data["clusterFeedMinutes"]) : undefined,
    colistenedShowLevelRank: data["colistenedShowLevelRank"] !== undefined ? BigInt(data["colistenedShowLevelRank"]) : undefined,
    dnnShowLevelRank: data["dnnShowLevelRank"] !== undefined ? BigInt(data["dnnShowLevelRank"]) : undefined,
    durationTotalSecondsEpisode: data["durationTotalSecondsEpisode"] !== undefined ? BigInt(data["durationTotalSecondsEpisode"]) : undefined,
    durationTotalSecondsShow: data["durationTotalSecondsShow"] !== undefined ? BigInt(data["durationTotalSecondsShow"]) : undefined,
    episodeDurationSec: data["episodeDurationSec"] !== undefined ? BigInt(data["episodeDurationSec"]) : undefined,
    episodeImpressions: data["episodeImpressions"] !== undefined ? BigInt(data["episodeImpressions"]) : undefined,
    episodeImpressionsPastWeek: data["episodeImpressionsPastWeek"] !== undefined ? BigInt(data["episodeImpressionsPastWeek"]) : undefined,
    episodesPublishedPerMonth: data["episodesPublishedPerMonth"] !== undefined ? BigInt(data["episodesPublishedPerMonth"]) : undefined,
    kmeansShowLevelRank: data["kmeansShowLevelRank"] !== undefined ? BigInt(data["kmeansShowLevelRank"]) : undefined,
    listenedShowLevelRank: data["listenedShowLevelRank"] !== undefined ? BigInt(data["listenedShowLevelRank"]) : undefined,
    numListenersInKmeansCluster: data["numListenersInKmeansCluster"] !== undefined ? BigInt(data["numListenersInKmeansCluster"]) : undefined,
    numListenersToShowInKmeansCluster: data["numListenersToShowInKmeansCluster"] !== undefined ? BigInt(data["numListenersToShowInKmeansCluster"]) : undefined,
    numSubscribersShow: data["numSubscribersShow"] !== undefined ? BigInt(data["numSubscribersShow"]) : undefined,
    numUniqueListenersShow: data["numUniqueListenersShow"] !== undefined ? BigInt(data["numUniqueListenersShow"]) : undefined,
    rank: data["rank"] !== undefined ? BigInt(data["rank"]) : undefined,
    secondsSincePublication: data["secondsSincePublication"] !== undefined ? BigInt(data["secondsSincePublication"]) : undefined,
    showImpressions: data["showImpressions"] !== undefined ? BigInt(data["showImpressions"]) : undefined,
    showImpressionsPastWeek: data["showImpressionsPastWeek"] !== undefined ? BigInt(data["showImpressionsPastWeek"]) : undefined,
    showOnlyImpressions: data["showOnlyImpressions"] !== undefined ? BigInt(data["showOnlyImpressions"]) : undefined,
    showOnlyImpressionsPastWeek: data["showOnlyImpressionsPastWeek"] !== undefined ? BigInt(data["showOnlyImpressionsPastWeek"]) : undefined,
    showPopularRank: data["showPopularRank"] !== undefined ? BigInt(data["showPopularRank"]) : undefined,
    subscriptionShowLevelRank: data["subscriptionShowLevelRank"] !== undefined ? BigInt(data["subscriptionShowLevelRank"]) : undefined,
    trendingScorePercent: data["trendingScorePercent"] !== undefined ? BigInt(data["trendingScorePercent"]) : undefined,
  };
}

export interface SuperrootPodcastsRecommendationsPodcastRecsFeaturesUserLanguage {
  lang?: string;
  score?: number;
}

export interface TelephoneNumber {
  /**
   * The local "area code", if there is such a concept.
   */
  areaCode?: string;
  /**
   * The international direct dialing code for the country, as per ITU E.164:
   * http://www.itu.int/itudoc/itu-t/ob-lists/icc/e164_763.html
   */
  countryCode?: number;
  /**
   * Extension (to be dialed after connection).
   */
  extension?: string;
  /**
   * To call this number from within the same country, the national call prefix
   * may be necessary. This is 1 in the US, 0 in the UK, etc. In the US, it's
   * reasonable to omit the leading 1 when writing the number, but in other
   * countries it is less optional.
   */
  nationalPrefix?: string;
  /**
   * The actual number, broken down into sections as per local convention. Note
   * that the actual formatting of these sections (hyphen vs space, usage of
   * parentheses) will vary according to local custom.
   */
  number?: string[];
}

/**
 * The docshards are a FlatSSTable from (64-bit) urlfp to data containing the
 * information found in this protocol buffer. (It's not actually one of these
 * PBs for various performance reasons; instead, the DocumentFormat class
 * handles serialization and deserialization in our own way) Next available ID:
 * 37
 */
export interface TeragoogleDocumentInfo {
  attachment?: TeragoogleDocumentInfoAttachment[];
  /**
   * The average weight of terms in the document. If not available, there will
   * be no term weight averaging: font sizes will be taken literally from the
   * document HTML.
   */
  averageTermWeight?: number;
  /**
   * The document itself. If present, the docservers parse the contents to
   * create a mustang repository.
   */
  doc?: GDocumentBase;
  /**
   * The serialized ExtendedDocId, needed to construct a proper docinfo
   * response if the docinfo request is missing it and it's present.
   */
  extendedDocid?: Uint8Array;
  /**
   * the global docid, we need it in the docservers (Continuum mode) to
   * construct proper docinfo response when the docinfo request does not contain
   * a valid global docid
   */
  globalDocid?: bigint;
  /**
   * If the original encoding isn't UTF8
   */
  originalEncoding?: number;
  section?: TeragoogleDocumentInfoSection[];
  /**
   * Indicates format of 'tokens' field in all Section entries.
   */
  sectionType?:  | "MDU" | "TOKENSPACE" | "TERADOC";
}

function serializeTeragoogleDocumentInfo(data: any): TeragoogleDocumentInfo {
  return {
    ...data,
    attachment: data["attachment"] !== undefined ? data["attachment"].map((item: any) => (serializeTeragoogleDocumentInfoAttachment(item))) : undefined,
    doc: data["doc"] !== undefined ? serializeGDocumentBase(data["doc"]) : undefined,
    extendedDocid: data["extendedDocid"] !== undefined ? encodeBase64(data["extendedDocid"]) : undefined,
    globalDocid: data["globalDocid"] !== undefined ? String(data["globalDocid"]) : undefined,
    section: data["section"] !== undefined ? data["section"].map((item: any) => (serializeTeragoogleDocumentInfoSection(item))) : undefined,
  };
}

function deserializeTeragoogleDocumentInfo(data: any): TeragoogleDocumentInfo {
  return {
    ...data,
    attachment: data["attachment"] !== undefined ? data["attachment"].map((item: any) => (deserializeTeragoogleDocumentInfoAttachment(item))) : undefined,
    doc: data["doc"] !== undefined ? deserializeGDocumentBase(data["doc"]) : undefined,
    extendedDocid: data["extendedDocid"] !== undefined ? decodeBase64(data["extendedDocid"] as string) : undefined,
    globalDocid: data["globalDocid"] !== undefined ? BigInt(data["globalDocid"]) : undefined,
    section: data["section"] !== undefined ? data["section"].map((item: any) => (deserializeTeragoogleDocumentInfoSection(item))) : undefined,
  };
}

/**
 * Misc. attachments to be added to the dynamic repository the docservers
 * build. These override any attachments created by parsing the GDocumentBase.
 */
export interface TeragoogleDocumentInfoAttachment {
  name?: string;
  options?: TeragoogleRepositoryAttachmentOptions;
  value?: Uint8Array;
}

function serializeTeragoogleDocumentInfoAttachment(data: any): TeragoogleDocumentInfoAttachment {
  return {
    ...data,
    value: data["value"] !== undefined ? encodeBase64(data["value"]) : undefined,
  };
}

function deserializeTeragoogleDocumentInfoAttachment(data: any): TeragoogleDocumentInfoAttachment {
  return {
    ...data,
    value: data["value"] !== undefined ? decodeBase64(data["value"] as string) : undefined,
  };
}

/**
 * Sections to be added to the dynamic repository the docservers build.
 * 'tokens' is either a sequence of tokens encoded using the
 * TokenSequenceEncoder (MDU), or a TokenspaceRepository (depends on what's set
 * in section_type. If 'doc' is present, then the contents of these sections
 * override what was created by parsing 'doc'.
 */
export interface TeragoogleDocumentInfoSection {
  /**
   * List of field repository (subsection) names within the section.
   */
  fieldName?: string[];
  name?: string;
  tokens?: Uint8Array;
}

function serializeTeragoogleDocumentInfoSection(data: any): TeragoogleDocumentInfoSection {
  return {
    ...data,
    tokens: data["tokens"] !== undefined ? encodeBase64(data["tokens"]) : undefined,
  };
}

function deserializeTeragoogleDocumentInfoSection(data: any): TeragoogleDocumentInfoSection {
  return {
    ...data,
    tokens: data["tokens"] !== undefined ? decodeBase64(data["tokens"] as string) : undefined,
  };
}

/**
 * Compression type to be applied to section/attachment.
 */
export interface TeragoogleRepositoryAttachmentOptions {
  compression?:  | "COMPRESSION_NONE" | "COMPRESSION_ZIPPY";
}

/**
 * Data related to title sizing calculations in Muppet.
 */
export interface TitleSizeParams {
  /**
   * Total max length of title in deciems
   */
  muppetTitleLengthInDeciems?: number;
  /**
   * Number of lines for title
   */
  muppetTitleNumLines?: number;
}

/**
 * DO NOT USE THIS FOR ANYTHING LIVE WITHOUT PERMISSION! If you want to use
 * this for anything user-facing file a logs-access ticket describing what you
 * want to do. This data is currently only available in the freshdocs pipeline,
 * so it will only be present in instant mustang and certain librarian shards.
 * Email freshdocs-indexing with questions.
 */
export interface ToolBarPerDocData {
  /**
   * Indicates how many distinct toolbar visitors this page had in the past
   * day. Will only be present if the number is reasonably large.
   */
  VisitorsPastDay?: number;
}

/**
 * Next ID: 27
 */
export interface TravelFlightsAirlineConfig {
  /**
   * Populated using airlines_company_ids.csv for AdWords company map
   */
  adwordsCid?: number;
  /**
   * STAR_ALLIANCE
   */
  alliance?:  | "UNKNOWN" | "AIRUNION" | "ARAB_AIR_CARRIERS_ORGANIZATION" | "ARABESK_AIRLINE_ALLIANCE" | "CENTRAL_MOUNTAIN_AIR" | "CONTINENTAL_AIRLINES" | "EAGLE_AIR" | "FEDEX_EXPRESS" | "GRUPO_TACA" | "JAT_AIRWAYS" | "LUFTHANSA_REGIONAL" | "ONEWORLD" | "QUALIFLYER" | "SIX" | "SKYTEAM" | "SKYTEAM_CARGO" | "STAR_ALLIANCE" | "TUI_AIRLINES" | "WOW_ALLIANCE";
  /**
   * Default url for baggage fee information.
   */
  baggageCarryonLimitationsUrls?: TravelFlightsNameCatalogProto;
  /**
   * Default url for baggage fee information.
   */
  baggageFeeUrls?: TravelFlightsNameCatalogProto;
  /**
   * ISO 3166-1 alpha-2 country code in which this airline is domestic.
   */
  countryCode?: string;
  /**
   * LocalizedContactInfo allows localization by country and language. Once the
   * data is ready, we will start filling both fields. After that the old field
   * will be deprecated and deleted at some point.
   */
  countryContactInfo?: TravelFlightsAirlineConfigCountryContactInfo[];
  /**
   * true, if this carrier's IATA code is a "controlled duplicate"
   * (goto/controlled-duplicate).
   */
  dupFlag?: boolean;
  fareFamilyUrls?: TravelFlightsNameCatalogProto;
  /**
   * IATA codes of airlines who this airline's travel can be credited to for
   * mileage accrual.
   */
  fqtvPartnerCode?: string[];
  /**
   * Note that some iata_codes are reused (`dup_flag` field). For details,
   * including how to resolve collisions for airlines shown in Google Flights,
   * see: go/controlled-duplicate
   * go/flights-data/airlines#resolving-iata-code-collisions
   * cs/go/controlled-duplicate U2 - some have no IATA code
   */
  iataCode?: string;
  /**
   * EZY - some have no ICAO code
   */
  icaoCode?: string;
  /**
   * U2! - with optional dedup sign ('!')
   */
  innovataCode?: string;
  localizedContactInfo?: TravelFlightsAirlineConfigLocalizedContactInfo[];
  /**
   * Note: fields #16 and #17 are ununused. The identifier of the airline, e.g.
   * /m/07y2s for United Populated using airlines_mids.csv.
   */
  mid?: string;
  /**
   * EasyJet/
   */
  names?: TravelFlightsNameCatalogProto;
  /**
   * Default url for passenger assistance information.
   */
  passengerAssistanceUrls?: TravelFlightsNameCatalogProto;
  /**
   * Number of flights with this airline over the next 180 days.
   */
  popularity?: number;
  /**
   * KLM - instead of 'KLM Royal Dutch Airlines'
   */
  shortNames?: TravelFlightsNameCatalogProto;
  type?:  | "SCHEDULED_PASSENGER" | "NON_SCHEDULED_PASSENGER" | "SCHEDULED_CARGO" | "NON_SCHEDULED_CARGO" | "NON_AIRLINE_LOAD_DEVICE" | "CRS" | "SCHEDULED_PASSENGER_CARGO" | "NON_SCHEDULED_PASSENGER_CARGO" | "RAILWAY" | "AIRLINE_PREFIX" | "UNRECOGNIZED";
  /**
   * http://www.airfrance.us/
   */
  urls?: TravelFlightsNameCatalogProto;
  /**
   * Default url for waiver information.
   */
  waiverSummaryUrls?: TravelFlightsNameCatalogProto;
}

export interface TravelFlightsAirlineConfigContactInfo {
  /**
   * Typically, formatted phone number.
   */
  data?: string;
  type?:  | "PHONE_PRIMARY" | "PHONE_TTY";
}

/**
 * Airline contact info grouped by country.
 */
export interface TravelFlightsAirlineConfigCountryContactInfo {
  contactInfo?: TravelFlightsAirlineConfigContactInfo[];
  /**
   * Two char country code, e.g. "US"
   */
  countryCode?: string;
}

/**
 * Airline contact info grouped by language. The language locale subcode will
 * determine the country.
 */
export interface TravelFlightsAirlineConfigLocalizedContactInfo {
  contactInfo?: TravelFlightsAirlineConfigContactInfo[];
  /**
   * IETF BCP-47, e.g. "en" or "zh-HK-Hant"
   */
  language?: string;
}

export interface TravelFlightsNameCatalogEntry {
  language?: string;
  text?: string;
}

export interface TravelFlightsNameCatalogProto {
  name?: TravelFlightsNameCatalogEntry[];
}

/**
 * ClientServiceInfo is meant for trawler/harpoon clients which are in turn
 * services to store some data specific to their clients. E.g., Kodachrome may
 * serve multiple other clients. In this case they can store their client name
 * here. Webmirror may also store the feed name here even though a feed is
 * technically not a service client. ClientServiceInfo is in nature similar to
 * ClientInfo, except it's stored in FetchReplyData (i.e., trawler logs),
 * whereas ClientInfo is copied to FetchReply (outside FetchReplyData), thus
 * it's not stored in trawler logs.
 */
export interface TrawlerClientServiceInfo {
  clientLabels?: TrawlerClientServiceInfoClientLabels[];
  /**
   * Project delegation name to support bandwidth enforcement. Harpoon will
   * call SetDelegatedUser() with the specified DelegatedProjectName and a
   * domain associated with the RequestorID provided in the client capatibility
   * file.
   */
  DelegatedProjectName?: string;
  ServiceClientID?: string;
}

/**
 * ClientLabels contains client-specified key/value pairs, used to annotate
 * individual FetchRequests and FetchReplies. This is primarily useful when the
 * Multiverse Nexus performs postprocessing of fetchreplies. ClientLabels
 * essentially allow clients to use the Nexus UI to slice statistics computed on
 * fetchreplies by the specified key/value pairs. Note: we don't use "map" type
 * here delibrately in order to avoid the non-deterministric serialization of
 * the "map" field. See b/69064361 for more details.
 */
export interface TrawlerClientServiceInfoClientLabels {
  /**
   * ======================== End of Deprecated Part ========================
   */
  labelsDeprecated?: {
    [key: string]: TrawlerClientServiceInfoClientLabelsClientLabelValues
  };
  name?: string;
  values?: string[];
}

/**
 * ===================== Beginning of Deprecated Part ======================
 */
export interface TrawlerClientServiceInfoClientLabelsClientLabelValues {
  value?: string[];
}

/**
 * Parsed version of a Content-Range field, which in http might look like:
 * Content-Range: bytes 500-999/3156
 */
export interface TrawlerContentRangeInfo {
  EndPos?: bigint;
  /**
   * In ContentRange, the first byte is 0 (rather than 1), and the positions
   * are inclusive. Thus, length is EndPos+1-StartPos
   */
  StartPos?: bigint;
  TotalLength?: bigint;
}

function serializeTrawlerContentRangeInfo(data: any): TrawlerContentRangeInfo {
  return {
    ...data,
    EndPos: data["EndPos"] !== undefined ? String(data["EndPos"]) : undefined,
    StartPos: data["StartPos"] !== undefined ? String(data["StartPos"]) : undefined,
    TotalLength: data["TotalLength"] !== undefined ? String(data["TotalLength"]) : undefined,
  };
}

function deserializeTrawlerContentRangeInfo(data: any): TrawlerContentRangeInfo {
  return {
    ...data,
    EndPos: data["EndPos"] !== undefined ? BigInt(data["EndPos"]) : undefined,
    StartPos: data["StartPos"] !== undefined ? BigInt(data["StartPos"]) : undefined,
    TotalLength: data["TotalLength"] !== undefined ? BigInt(data["TotalLength"]) : undefined,
  };
}

/**
 * This is similar to CrawlDates group in FetchReplyData, except that 1) it's a
 * message; 2) it's filled in each Redirects hop; and 3) the timestamps are in
 * ms rather than seconds since Unix Epoch.
 */
export interface TrawlerCrawlTimes {
  /**
   * fetched from the web. Time when the page was last
   */
  NotChangedTimeMs?: bigint;
  /**
   * Time when the page was
   */
  OriginalCrawlTimeMs?: bigint;
  /**
   * checked but found to be the same as before. If set, timestamp to indicate
   */
  ReuseTimeMs?: bigint;
}

function serializeTrawlerCrawlTimes(data: any): TrawlerCrawlTimes {
  return {
    ...data,
    NotChangedTimeMs: data["NotChangedTimeMs"] !== undefined ? String(data["NotChangedTimeMs"]) : undefined,
    OriginalCrawlTimeMs: data["OriginalCrawlTimeMs"] !== undefined ? String(data["OriginalCrawlTimeMs"]) : undefined,
    ReuseTimeMs: data["ReuseTimeMs"] !== undefined ? String(data["ReuseTimeMs"]) : undefined,
  };
}

function deserializeTrawlerCrawlTimes(data: any): TrawlerCrawlTimes {
  return {
    ...data,
    NotChangedTimeMs: data["NotChangedTimeMs"] !== undefined ? BigInt(data["NotChangedTimeMs"]) : undefined,
    OriginalCrawlTimeMs: data["OriginalCrawlTimeMs"] !== undefined ? BigInt(data["OriginalCrawlTimeMs"]) : undefined,
    ReuseTimeMs: data["ReuseTimeMs"] !== undefined ? BigInt(data["ReuseTimeMs"]) : undefined,
  };
}

/**
 * Event is for logging interesting events that happen during a url fetch.
 * Interesting events include "fetch start", "url rejected", etc. The events are
 * written to binary logs together with the request and reply messages. If the
 * same event occurs multiple times consecutively, We record the time of the
 * first three instances in EarliestTimeStamp but omit the rest. We keep track
 * the total number of occurrences in NumOccurrences and the timestamp of the
 * last occurrence is kept in TimeStamp field.
 */
export interface TrawlerEvent {
  ID?: bigint;
  Msg?: string;
  NumOccurrences?: number;
  /**
   * Limited to 3.
   */
  OldestTimeStampInUS?: bigint[];
  TimeStampInUS?: bigint;
}

function serializeTrawlerEvent(data: any): TrawlerEvent {
  return {
    ...data,
    ID: data["ID"] !== undefined ? String(data["ID"]) : undefined,
    OldestTimeStampInUS: data["OldestTimeStampInUS"] !== undefined ? data["OldestTimeStampInUS"].map((item: any) => (String(item))) : undefined,
    TimeStampInUS: data["TimeStampInUS"] !== undefined ? String(data["TimeStampInUS"]) : undefined,
  };
}

function deserializeTrawlerEvent(data: any): TrawlerEvent {
  return {
    ...data,
    ID: data["ID"] !== undefined ? BigInt(data["ID"]) : undefined,
    OldestTimeStampInUS: data["OldestTimeStampInUS"] !== undefined ? data["OldestTimeStampInUS"].map((item: any) => (BigInt(item))) : undefined,
    TimeStampInUS: data["TimeStampInUS"] !== undefined ? BigInt(data["TimeStampInUS"]) : undefined,
  };
}

export interface TrawlerFetchBodyData {
  compression?:  | "NO_COMPRESSION" | "ZLIB_COMPRESSION" | "HTML_DICTIONARY_COMPRESSION";
  content?: Uint8Array;
  /**
   * Size hint. Set if compression != NO_COMPRESSION
   */
  uncompressedSize?: bigint;
}

function serializeTrawlerFetchBodyData(data: any): TrawlerFetchBodyData {
  return {
    ...data,
    content: data["content"] !== undefined ? encodeBase64(data["content"]) : undefined,
    uncompressedSize: data["uncompressedSize"] !== undefined ? String(data["uncompressedSize"]) : undefined,
  };
}

function deserializeTrawlerFetchBodyData(data: any): TrawlerFetchBodyData {
  return {
    ...data,
    content: data["content"] !== undefined ? decodeBase64(data["content"] as string) : undefined,
    uncompressedSize: data["uncompressedSize"] !== undefined ? BigInt(data["uncompressedSize"]) : undefined,
  };
}

/**
 * Fetcher -> FetchClient FetchReplyData is the metadata for a reply from a
 * FetchRequest. For metadata + document body, FetchReply is further below.
 * NOTE: FetchReplyData (and FetchReply) is the output interface from
 * Multiverse. Teams outside Multiverse/Trawler should not create fake
 * FetchReplies. Trawler: When adding new fields here, it is recommended that at
 * least the following be rebuilt and pushed: - cron_fetcher_index mapreduces:
 * so that UrlReplyIndex, etc. retain the new fields - tlookup, tlookup_server:
 * want to be able to return the new fields - logviewer, fetchutil: annoying to
 * get back 'tag88:' in results -------------------------- Next Tag: 124
 * -----------------------
 */
export interface TrawlerFetchReplyData {
  /**
   * This field, if non-empty, contains the SSL certificate chain from the
   * server. The filed should be serialized SSLCertificateInfo protobuf,
   * although it used to be text format. Hence, one should ideally use
   * trawler::CertificateUtil to check this field and understand in more detail.
   * This field is populated in two cases: (1) something is wrong with the
   * server certificate and we cannot verify the server's identity. In this case
   * the URL most likely won't display in a browser; (2) if you turned on
   * WantSSLCertificateChain in the FetchRequest. In this case the server
   * certificate may be perfectly fine (despite the field name). This is for the
   * initial hop; additional hops are in Redirects group.
   */
  BadSSLCertificate?: Uint8Array;
  /**
   * Some client specific data that's set by client in the FetchRequest, and we
   * just copy it here verbatim. This is similar to ClientInfo that we copy from
   * FetchRequest to FetchReply, but this is copied to FetchReplyData, thus
   * stored in trawler logs so can be useful for debugging cases.
   */
  ClientServiceInfo?: TrawlerClientServiceInfo;
  /**
   * Is the associated body compressed ?
   */
  CompressedBody?: boolean;
  crawldates?: TrawlerFetchReplyDataCrawlDates;
  CrawlTimes?: TrawlerCrawlTimes;
  /**
   * Transfer operation detailed report.
   */
  deliveryReport?: TrawlerFetchReplyDataDeliveryReport;
  /**
   * Sometimes the hostid and destination IP in the FetchReplyData are not for
   * the hostname in the url. If that's the case DNSHost will be the host that
   * we have used when resolving hostid and DNS. Right now there are two cases:
   * (1) malware team provides a proxy IP:Port to us, so DNSHost will be the
   * proxy IP; and (2) PSS team provides a reference DNS host; so DNSHost will
   * be the reference DNS host.
   */
  DNSHost?: string;
  /**
   * The download time for this fetch (ms). This is the RTT time between
   * fetcher and HOPE, note it does not include time from redirects, just
   * initial hop. If you want the sum of the DownloadTime values for all fetches
   * in the redirect chain, then use the DownLoadTime value in the FetchStats.
   */
  DownloadTime?: number;
  /**
   * If present, the edge region that we have used.
   */
  EgressRegion?: string;
  /**
   * If present, it means this host might be eligible for geo crawl. However,
   * this does not mean we enable geo-crawl for this request. Check
   * "GeoCrawlEgressRegion" instead to see if this fetch is conducted via geo
   * crawl.
   */
  EligibleGeoCrawlEgressRegion?: string;
  /**
   * ------- If fetched, the IP from which we fetched, as well as source IP and
   * ports. It is recommended to use trawler::DestinationIP()/HasDestinationIP()
   * accessors, which return a proper IPAddress.
   */
  Endpoints?: TrawlerTCPIPInfo;
  Events?: TrawlerEvent[];
  /**
   * With the introduction of fetch pattern based hostload exceptions, one
   * hostid may have multiple hostload buckets, each with its own hostload. In
   * this case, FetchPatternFp will be set to identify the hostload bucket
   * within the hostid. Note this field is only meaningful for the
   * HostBucketData which is recorded only when the client requests to have as
   * part of reply. However, this field is useful for certain stats gathering,
   * so we choose to always record it if its value is available during the
   * fetch.
   */
  FetchPatternFp?: bigint;
  fetchstats?: TrawlerFetchReplyDataFetchStats;
  /**
   * If present, fetch was conducted using floonet and this is the location of
   * floonet egress point we used.
   */
  FlooEgressRegion?: string;
  /**
   * If present, the last hop of the fetch was conducted using floonet and this
   * is the location of floonet egress point. It is different from EgressRegion
   * and FlooEgressREgion because it is a Trawler transparent routing configured
   * in the geo crawl rules(go/da-geo-crawl).
   */
  GeoCrawlEgressRegion?: string;
  /**
   * Whether we fallback from geo crawl to local crawl during fetch. The
   * fallback could happen in any hops and there can be at most one fallback
   * because once fallback happens, we will not try geo-crawl anymore.
   */
  GeoCrawlFallback?: boolean;
  /**
   * Set only when GeoCrawlFallback is true. Logs the geo crawl location we
   * attempted but failed for this request.
   */
  GeoCrawlLocationAttempted?: string;
  /**
   * Returns the cache key used when doing cache lookup/update, on a per-hop
   * basis (initial hop) Note this field will not be set if cache lookup/update
   * is disabled/skipped.
   */
  HopCacheKeyForLookup?: bigint;
  HopCacheKeyForUpdate?: bigint;
  /**
   * Returns trawler::ReuseInfo with status of IMS/IMF/cache query, on a
   * per-hop basis (initial hop) For example, if the URL redirect chain is [URL
   * A] --> [URL B] --> [URL C], this field stores the reuse info of [URL A].
   */
  HopReuseInfo?:  | "RUI_NONE" | "RUI_IMS_CACHE_CURRENT" | "RUI_IMS_NOT_MODIFIED" | "RUI_IMS_CHANGED" | "RUI_IMF_NOCACHE" | "RUI_IMF_CACHE_CURRENT" | "RUI_IMF_HIT" | "RUI_IMF_CHANGED" | "RUI_IMF_POST_HIT_ERROR" | "RUI_CACHE_CURRENT" | "RUI_CACHE_EXPIRED" | "RUI_CACHE_NOCACHE" | "RUI_CACHE_UNUSABLE" | "RUI_IMF_UNUSABLE" | "NUM_REUSE_INFO_VALS";
  /**
   * Extra information in robots.txt for this page (integer: or'ed together of
   * type trawler::RobotsInfo) on a per-hop basis (initial hop)
   */
  HopRobotsInfo?: number;
  /**
   * Data about the host bucket this request is in (if desired) Please talk
   * with Trawler team before considering using this, since what we fill in here
   * is subject to change.
   */
  HostBucketData?: TrawlerHostBucketData;
  /**
   * If known, the trawler::HostId that identifies the host (initial hop).
   */
  HostId?: bigint;
  /**
   * Set to: o HSTS_STATUS_NONE if there was no HSTS policy match for the URL's
   * host. o HSTS_STATUS_AVAILABLE if there was an HSTS policy, but the URL was
   * not rewritten from HTTP to HTTPS because enable_hsts was not set in client
   * capability config. o HSTS_STATUS_REWRITTEN if the HSTS policy was followed
   * and url was rewritten from HTTP to HTTPS. This field only pertains to the
   * current URL fetch and does not explain a redirect's HSTS status. However,
   * FetchReplyData.Redirects have their own HSTSInfo.
   */
  HSTSInfo?:  | "HSTS_STATUS_NONE" | "HSTS_STATUS_AVAILABLE" | "HSTS_STATUS_REWRITTEN";
  /**
   * The http protocol we send to fetch this URL. This will only be set if the
   * request is using http
   */
  HttpProtocol?:  | "PROTO_GET" | "PROTO_POST" | "PROTO_HEAD" | "PROTO_PUT" | "PROTO_DELETE" | "PROTO_PATCH" | "PROTO_OPTIONS" | "FIRST_PROTO" | "NUM_PROTOS";
  /**
   * The HTTP headers we sent to fetch this URL (initial hop). Not normally
   * filled in, unless FetchParams.WantSentHeaders is set.
   */
  HttpRequestHeaders?: string;
  /**
   * HTTP headers from the response (initial hop). Trawler does not fill this
   * in; this is intended as a placeholder for crawls like webmirror that fill
   * in and want to track this across redirect hops.
   */
  HttpResponseHeaders?: string;
  /**
   * The received HTTP trailers if available.
   */
  HTTPTrailers?: TrawlerFetchReplyDataHTTPHeader[];
  /**
   * Stores the HTTP version we used in the final hop.
   */
  HttpVersion?:  | "HTTP_11" | "HTTP_10" | "HTTP_09" | "HTTP_2" | "HTTP_AUTO" | "FIRST_VERSION" | "NUM_VERSIONS";
  /**
   * Same as the ID of the matching request (used for matching internal
   * fetchclient data in request/reply)
   */
  ID?: bigint;
  /**
   * Crawl status of the last url on chain
   */
  LastUrlStatus?: TrawlerFetchStatus;
  /**
   * If the input url in FetchRequest is Amazon S3 protocol or Apple Itunes
   * protocol, we will translate it into https url and log it as https url. In
   * the meantime we will store the original s3/itunes url in this field. Before
   * sending back to client, the Url will be translated back to s3 and this
   * field will be cleard.
   */
  originalProtocolUrl?: string;
  partialresponse?: TrawlerFetchReplyDataPartialResponse;
  /**
   * Trawler can optionally add a policy label to a FetchReply. Some uses: -
   * "spam" label via trawler_site_info - "roboted:googlebot" label as a signal
   * to crawls supporting multiple useragents that it's not safe to share the
   * fetch replies with googlebot crawls.
   */
  PolicyData?: TrawlerPolicyData[];
  /**
   * If the fetch uses HTTP POST, PUT, or PATCH protocol, and WantPostData is
   * true, the POST data will be copied here. This is only for initial hop. If
   * there are redirects, HTTP POST will be changed to GET on subsequent hops,
   * and the PostData will be cleared. There is only one exception, if the HTTP
   * response code to the POST request is 307 (a new code introduced in RFC7321,
   * sec. 6.4.7), we will preserve the request method and the PostData for the
   * next hop.
   */
  PostData?: Uint8Array;
  /**
   * This is available only if a fetch results in TIMEOUT_WEB, and we were able
   * to predict, based on content length and bandwidth we were using, how much
   * time (in ms) would be needed to download the entire content.
   */
  PredictedDownloadTimeMs?: number;
  protocolresponse?: TrawlerFetchReplyDataProtocolResponse;
  /**
   * Whether we fallback from HTTP/2 to HTTP/1.1 during fetch. The fallback
   * could happen in any hops and there can be at most one fallback because once
   * fallback happens, we will not try HTTP/2 anymore.
   */
  ProtocolVersionFallback?: boolean;
  redirects?: TrawlerFetchReplyDataRedirects[];
  /**
   * If this fetch was a result of a redirect, we populate the parent ID here.
   */
  RedirectSourceFetchId?: bigint;
  /**
   * RequestorId is the same on as in the request that triggers this reply --
   * mainly for diagnostics purpose
   */
  RequestorID?: string;
  /**
   * Machine that sent Trawler this request, for logging. An IPAddress object,
   * packed as a string.
   */
  RequestorIPAddressPacked?: Uint8Array;
  /**
   * -------- Returns trawler::ReuseInfo with status of IMS/IMF/cache query.
   * Consider using HopReuseInfo instead, which has per-redirect hop detail. If
   * there's URL redirection, this field stores the reuse info of the last hop.
   * For example, if the and URL redirect chain is [URL A] --> [URL B] --> [URL
   * C], this field stores the reuse info of [URL C].
   */
  ReuseInfo?:  | "RUI_NONE" | "RUI_IMS_CACHE_CURRENT" | "RUI_IMS_NOT_MODIFIED" | "RUI_IMS_CHANGED" | "RUI_IMF_NOCACHE" | "RUI_IMF_CACHE_CURRENT" | "RUI_IMF_HIT" | "RUI_IMF_CHANGED" | "RUI_IMF_POST_HIT_ERROR" | "RUI_CACHE_CURRENT" | "RUI_CACHE_EXPIRED" | "RUI_CACHE_NOCACHE" | "RUI_CACHE_UNUSABLE" | "RUI_IMF_UNUSABLE" | "NUM_REUSE_INFO_VALS";
  /**
   * Extra information in robots.txt for this page (ORed together bits from
   * trawler::RobotsInfo). e.g. nosnippet vs. noarchive vs nofollow vs noindex
   * vs disallow Consider using HopRobotsInfo instead, which has per-redirect
   * hop detail.
   */
  RobotsInfo?: number;
  /**
   * Status of the robots.txt fetch. Currently, this is present if: - Certain
   * robots error cases, such as URL_TIMEOUT-TIMEOUT_ROBOTS or
   * URL_UNREACHABLE-UNREACHABLE_ROBOTS_ERROR. - If WantRobotsBody is set in the
   * FetchParams.
   */
  RobotsStatus?: TrawlerFetchStatus;
  /**
   * The robots.txt we used for this URL (initial hop). Not normally filled in
   * unless WantRobotsBody is set. This is mostly for debugging purposes and
   * should not be used for large volumes of traffic.
   */
  RobotsTxt?: Uint8Array;
  /**
   * Status of the fetch - refers to the final status at the end of the
   * redirect chain.
   */
  Status?: TrawlerFetchStatus;
  /**
   * If present, Client API will enforce the contained constraints
   */
  ThrottleClient?: TrawlerThrottleClientData;
  /**
   * Sometimes we throw away content because we cannot store it in the internal
   * buffers. These is how many bytes we have thrown away for this factor.
   */
  ThrownAwayBytes?: bigint;
  /**
   * When this reply came back from fetcher NOTE: TimestampInMS is used for
   * internal debugging. To see when a document was crawled, check CrawlDates.
   */
  TimestampInMS?: bigint;
  /**
   * How many raw bytes we read from the connection to the server when we
   * fetched the page. Includes everything: HTTP headers, overhead for HTTP
   * chunked encoding, whatever compressed/uncompressed form (i.e. gzip/deflate
   * accept-encoding) the content was sent in, etc. This is NOT the same as the
   * size of the uncompressed FetchReply::Body - if the webserver used gzip
   * encoding, this value might be much smaller, since it only counts the
   * compressed wire size. To illustrate, think of 3 sizes: 1) TotalFetchedSize
   * - amount Trawler read over the wire from the server. If they used
   * gzip/deflate, this might be 4-5x smaller than the body. 2)
   * UnTruncatedSize/CutoffSize - how big is the full document, after
   * uncompressing any gzip/deflate encoding? If truncated, this is reflected in
   * CutoffSize. 3) FetchReply::Body size - most crawls enable Trawler
   * compression to save storage space (gzip + a google html dictionary). The
   * body size that the end Trawler client sees is post-compression.
   */
  TotalFetchedSize?: bigint;
  /**
   * Traffic type of this fetch.
   */
  trafficType?:  | "TRAFFIC_TYPE_UNSPECIFIED" | "TRAFFIC_TYPE_NO_FETCH" | "TRAFFIC_TYPE_ONEOFF_CRAWL" | "TRAFFIC_TYPE_DISCOVERY" | "TRAFFIC_TYPE_REFRESH";
  /**
   * If the url got rewriten by transparent rewrites, here it is the series of
   * rewrites it got through. The fetched one is the last
   */
  TransparentRewrites?: string[];
  /**
   * For logging only; not present in the actual fetcher response
   */
  TrawlerPrivate?: TrawlerTrawlerPrivateFetchReplyData;
  /**
   * The original url in the request we are answering. Even though "optional,"
   * url must be filled in on all well-formed replies. Trawler guarantees that
   * it is filled in, and basically every client expects it (CHECKs in some
   * cases). -> Not filling this field in is a bug, if you share this data with
   * other crawls/pipelines. You should expect everybody else to require a url.
   */
  Url?: string;
  /**
   * Encoding info for the original url itself. Bitfield encoding; see
   * UrlEncoding::{Set,Get}Value in webutil/urlencoding.
   */
  UrlEncoding?: number;
  /**
   * Use the special compression dictionary for uncompressing this.
   * (trawler::kHtmlCompressionDict. Use trawler::FetchReplyUncompressor to
   * uncompress; crawler/trawler/public/fetchreply-util.h)
   */
  UseHtmlCompressDictionary?: boolean;
}

function serializeTrawlerFetchReplyData(data: any): TrawlerFetchReplyData {
  return {
    ...data,
    BadSSLCertificate: data["BadSSLCertificate"] !== undefined ? encodeBase64(data["BadSSLCertificate"]) : undefined,
    CrawlTimes: data["CrawlTimes"] !== undefined ? serializeTrawlerCrawlTimes(data["CrawlTimes"]) : undefined,
    deliveryReport: data["deliveryReport"] !== undefined ? serializeTrawlerFetchReplyDataDeliveryReport(data["deliveryReport"]) : undefined,
    Endpoints: data["Endpoints"] !== undefined ? serializeTrawlerTCPIPInfo(data["Endpoints"]) : undefined,
    Events: data["Events"] !== undefined ? data["Events"].map((item: any) => (serializeTrawlerEvent(item))) : undefined,
    FetchPatternFp: data["FetchPatternFp"] !== undefined ? String(data["FetchPatternFp"]) : undefined,
    fetchstats: data["fetchstats"] !== undefined ? serializeTrawlerFetchReplyDataFetchStats(data["fetchstats"]) : undefined,
    HopCacheKeyForLookup: data["HopCacheKeyForLookup"] !== undefined ? String(data["HopCacheKeyForLookup"]) : undefined,
    HopCacheKeyForUpdate: data["HopCacheKeyForUpdate"] !== undefined ? String(data["HopCacheKeyForUpdate"]) : undefined,
    HostBucketData: data["HostBucketData"] !== undefined ? serializeTrawlerHostBucketData(data["HostBucketData"]) : undefined,
    HostId: data["HostId"] !== undefined ? String(data["HostId"]) : undefined,
    ID: data["ID"] !== undefined ? String(data["ID"]) : undefined,
    partialresponse: data["partialresponse"] !== undefined ? serializeTrawlerFetchReplyDataPartialResponse(data["partialresponse"]) : undefined,
    PostData: data["PostData"] !== undefined ? encodeBase64(data["PostData"]) : undefined,
    protocolresponse: data["protocolresponse"] !== undefined ? serializeTrawlerFetchReplyDataProtocolResponse(data["protocolresponse"]) : undefined,
    redirects: data["redirects"] !== undefined ? data["redirects"].map((item: any) => (serializeTrawlerFetchReplyDataRedirects(item))) : undefined,
    RedirectSourceFetchId: data["RedirectSourceFetchId"] !== undefined ? String(data["RedirectSourceFetchId"]) : undefined,
    RequestorIPAddressPacked: data["RequestorIPAddressPacked"] !== undefined ? encodeBase64(data["RequestorIPAddressPacked"]) : undefined,
    RobotsTxt: data["RobotsTxt"] !== undefined ? encodeBase64(data["RobotsTxt"]) : undefined,
    ThrownAwayBytes: data["ThrownAwayBytes"] !== undefined ? String(data["ThrownAwayBytes"]) : undefined,
    TimestampInMS: data["TimestampInMS"] !== undefined ? String(data["TimestampInMS"]) : undefined,
    TotalFetchedSize: data["TotalFetchedSize"] !== undefined ? String(data["TotalFetchedSize"]) : undefined,
    TrawlerPrivate: data["TrawlerPrivate"] !== undefined ? serializeTrawlerTrawlerPrivateFetchReplyData(data["TrawlerPrivate"]) : undefined,
  };
}

function deserializeTrawlerFetchReplyData(data: any): TrawlerFetchReplyData {
  return {
    ...data,
    BadSSLCertificate: data["BadSSLCertificate"] !== undefined ? decodeBase64(data["BadSSLCertificate"] as string) : undefined,
    CrawlTimes: data["CrawlTimes"] !== undefined ? deserializeTrawlerCrawlTimes(data["CrawlTimes"]) : undefined,
    deliveryReport: data["deliveryReport"] !== undefined ? deserializeTrawlerFetchReplyDataDeliveryReport(data["deliveryReport"]) : undefined,
    Endpoints: data["Endpoints"] !== undefined ? deserializeTrawlerTCPIPInfo(data["Endpoints"]) : undefined,
    Events: data["Events"] !== undefined ? data["Events"].map((item: any) => (deserializeTrawlerEvent(item))) : undefined,
    FetchPatternFp: data["FetchPatternFp"] !== undefined ? BigInt(data["FetchPatternFp"]) : undefined,
    fetchstats: data["fetchstats"] !== undefined ? deserializeTrawlerFetchReplyDataFetchStats(data["fetchstats"]) : undefined,
    HopCacheKeyForLookup: data["HopCacheKeyForLookup"] !== undefined ? BigInt(data["HopCacheKeyForLookup"]) : undefined,
    HopCacheKeyForUpdate: data["HopCacheKeyForUpdate"] !== undefined ? BigInt(data["HopCacheKeyForUpdate"]) : undefined,
    HostBucketData: data["HostBucketData"] !== undefined ? deserializeTrawlerHostBucketData(data["HostBucketData"]) : undefined,
    HostId: data["HostId"] !== undefined ? BigInt(data["HostId"]) : undefined,
    ID: data["ID"] !== undefined ? BigInt(data["ID"]) : undefined,
    partialresponse: data["partialresponse"] !== undefined ? deserializeTrawlerFetchReplyDataPartialResponse(data["partialresponse"]) : undefined,
    PostData: data["PostData"] !== undefined ? decodeBase64(data["PostData"] as string) : undefined,
    protocolresponse: data["protocolresponse"] !== undefined ? deserializeTrawlerFetchReplyDataProtocolResponse(data["protocolresponse"]) : undefined,
    redirects: data["redirects"] !== undefined ? data["redirects"].map((item: any) => (deserializeTrawlerFetchReplyDataRedirects(item))) : undefined,
    RedirectSourceFetchId: data["RedirectSourceFetchId"] !== undefined ? BigInt(data["RedirectSourceFetchId"]) : undefined,
    RequestorIPAddressPacked: data["RequestorIPAddressPacked"] !== undefined ? decodeBase64(data["RequestorIPAddressPacked"] as string) : undefined,
    RobotsTxt: data["RobotsTxt"] !== undefined ? decodeBase64(data["RobotsTxt"] as string) : undefined,
    ThrownAwayBytes: data["ThrownAwayBytes"] !== undefined ? BigInt(data["ThrownAwayBytes"]) : undefined,
    TimestampInMS: data["TimestampInMS"] !== undefined ? BigInt(data["TimestampInMS"]) : undefined,
    TotalFetchedSize: data["TotalFetchedSize"] !== undefined ? BigInt(data["TotalFetchedSize"]) : undefined,
    TrawlerPrivate: data["TrawlerPrivate"] !== undefined ? deserializeTrawlerTrawlerPrivateFetchReplyData(data["TrawlerPrivate"]) : undefined,
  };
}

/**
 * Reuse information returned if UrlState == CRAWLED, specifying when we may
 * have reused from cache. See also ReuseInfo below. NOTE: Please use the
 * CrawlTimes below. CrawlDates is deprecated. use CrawlTimes instead!
 */
export interface TrawlerFetchReplyDataCrawlDates {
  /**
   * fetched from the web. Timestamp indicates when
   */
  NotChangedDate?: number;
  /**
   * Timestamp when the page was
   */
  OriginalCrawlDate?: number;
  /**
   * the page was last checked but found to be the same as before. If set,
   * timestamp to indicate
   */
  ReuseDate?: number;
}

/**
 * Depending on which Data Acquisition API the client uses, the fetched content
 * can be delivered to the client in the RPC, via Goops, or copied to the
 * client's storage system (possibly after transformation). In the latter case,
 * DeliveryReport will contain info about the delivery status, such as whether
 * we have permission error, whether the destination storage is out of quota,
 * etc).
 */
export interface TrawlerFetchReplyDataDeliveryReport {
  /**
   * The events store the detail of messages (usually error).
   */
  events?: TrawlerEvent[];
  /**
   * The complete path (include the file name) of the file downloaded. For
   * requests that require delivery, this path will be the user specified
   * location. For requests that use Multiverse default storage, this path will
   * be the managed by Multiverse.
   */
  filePath?: string;
  /**
   * Status of the transfer action.
   */
  status?:  | "TRANSFER_UNSPECIFIED" | "TRANSFER_OK" | "TRANSFER_UNAVAILABLE" | "TRANSFER_INTERNAL" | "TRANSFER_INVALID_DESTINATION" | "TRANSFER_PERMISSION_DENIED" | "TRANSFER_RESOURCE_EXHAUSTED" | "TRANSFER_NOT_ATTEMPTED";
}

function serializeTrawlerFetchReplyDataDeliveryReport(data: any): TrawlerFetchReplyDataDeliveryReport {
  return {
    ...data,
    events: data["events"] !== undefined ? data["events"].map((item: any) => (serializeTrawlerEvent(item))) : undefined,
  };
}

function deserializeTrawlerFetchReplyDataDeliveryReport(data: any): TrawlerFetchReplyDataDeliveryReport {
  return {
    ...data,
    events: data["events"] !== undefined ? data["events"].map((item: any) => (deserializeTrawlerEvent(item))) : undefined,
  };
}

/**
 * The fetcher keeps track of various time intervals spent in the states of the
 * fetcher url control flow. Sometimes flows branch out into more than one flow
 * (next flow), and we aggregate all the time intervals spent in a specific
 * state for all the flows to get the time interval for the state. The time
 * interval for a state is therefore not the time interval of an individual
 * flow, if the WaitNextFlow time is non zero. The WaitNextFlow interval
 * included here is the time spent by one flow waiting for another flow.
 * Although the WaitNextFlow time is the time spent by a flow in the
 * WaitNextFlow state, its also equivalent to the entire timeline of another
 * flow. It is the time spent in the various states of another flow. In
 * computing the total time spent in the primary flow, one must omit the
 * WaitNextFlow time, since it is already included in the form of slices of
 * individual state time intervals in the aggregated time intervals for other
 * states, and will result in double counting.
 */
export interface TrawlerFetchReplyDataFetchStats {
  /**
   * Overhead spent RPCing with the Bot/proxy.
   */
  BotOverheadMS?: number;
  ClientControlflowStats?: TrawlerFetchReplyDataFetchStatsClientStateStats;
  /**
   * Report only with first request on connection, so that we keep track of the
   * connect time with a host. Sometimes a connection is initiated by a prior
   * request that times out before the connection is established. Another
   * request can get scheduled on a connection that is already in the process of
   * being established but has no request scheduled onto it. We want to keep
   * track of the entire connect time even if a request didn't need to wait for
   * the entire connection establishment time. Sometimes a connection may get
   * established before the first request uses it. We tag along the connect time
   * with the first request using the connection. ConnectTimeMs also includes
   * SSL negotiation time.
   */
  ConnectTimeMs?: number;
  ControlflowStats?: TrawlerFetchReplyDataFetchStatsStateStats;
  /**
   * DownLoadTime = Share of connect time + ServerResponseTimeMs +
   * TransferTimeMs (see below) in ms
   */
  DownLoadTime?: number;
  /**
   * Overhead spent routing the request from HOPE to edge egress nodes, which
   * open connection to webservers. This is only set for edge fetches (e.g.,
   * through Floonet egress nodes).
   */
  EdgeEgressOverheadMs?: number;
  /**
   * Time between the request send and the receipt of the first fragment of the
   * response. For HTTP responses the first fragment is the first fragment of
   * the response payload (the headers are ignored).
   */
  ServerResponseTimeMs?: number;
  /**
   * ConnectTimeMs includes TCP connect time + SSL time, whereas
   * SSLConnectTimeMs includes only the latter.
   */
  SSLConnectTimeMs?: number;
  /**
   * Time to receive the entire response payload starting the clock on
   * receiving the first fragment.
   */
  TransferTimeMs?: number;
}

function serializeTrawlerFetchReplyDataFetchStats(data: any): TrawlerFetchReplyDataFetchStats {
  return {
    ...data,
    ControlflowStats: data["ControlflowStats"] !== undefined ? serializeTrawlerFetchReplyDataFetchStatsStateStats(data["ControlflowStats"]) : undefined,
  };
}

function deserializeTrawlerFetchReplyDataFetchStats(data: any): TrawlerFetchReplyDataFetchStats {
  return {
    ...data,
    ControlflowStats: data["ControlflowStats"] !== undefined ? deserializeTrawlerFetchReplyDataFetchStatsStateStats(data["ControlflowStats"]) : undefined,
  };
}

/**
 * Records stats about state changes on the client side if there're any. For
 * example, there's a state of cache lookup when using private-cache client
 * library.
 */
export interface TrawlerFetchReplyDataFetchStatsClientStateStats {
  WaitContentCacheUsec?: number;
}

/**
 * The following are only populated if Params.WantStateStats is true.
 */
export interface TrawlerFetchReplyDataFetchStatsStateStats {
  EndTrackingTimeUsec?: bigint;
  /**
   * Start and end timestamp tracking the delays for this request.
   */
  StartTrackingTimeUsec?: bigint;
  WaitCompressTimeUsec?: number;
  WaitContentCacheUsec?: number;
  WaitCredentialTimeUsec?: number;
  WaitDNSTimeUsec?: number;
  WaitFetchClientUsec?: number;
  WaitForCachedContentStreamingUsec?: number;
  WaitForFetchUsec?: number;
  WaitHostIdTimeUsec?: number;
  WaitNextFlowUsec?: number;
  /**
   * obsolete. Not set.
   */
  WaitRobotsCacheTimeUsec?: number;
  /**
   * obsolete. Not set.
   */
  WaitRobotsFetchTimeUsec?: number;
  WaitRobotsTimeUsec?: number;
  WaitScheduleTimeUsec?: number;
}

function serializeTrawlerFetchReplyDataFetchStatsStateStats(data: any): TrawlerFetchReplyDataFetchStatsStateStats {
  return {
    ...data,
    EndTrackingTimeUsec: data["EndTrackingTimeUsec"] !== undefined ? String(data["EndTrackingTimeUsec"]) : undefined,
    StartTrackingTimeUsec: data["StartTrackingTimeUsec"] !== undefined ? String(data["StartTrackingTimeUsec"]) : undefined,
  };
}

function deserializeTrawlerFetchReplyDataFetchStatsStateStats(data: any): TrawlerFetchReplyDataFetchStatsStateStats {
  return {
    ...data,
    EndTrackingTimeUsec: data["EndTrackingTimeUsec"] !== undefined ? BigInt(data["EndTrackingTimeUsec"]) : undefined,
    StartTrackingTimeUsec: data["StartTrackingTimeUsec"] !== undefined ? BigInt(data["StartTrackingTimeUsec"]) : undefined,
  };
}

/**
 * header : value
 */
export interface TrawlerFetchReplyDataHTTPHeader {
  key?: string;
  value?: string;
}

/**
 * ----------------------------------------------------------------------
 * PartialResponse is used with streaming responses in LargeFileFetchAdapter.
 * Rather than fitting entirely in a single FetchReply, there is a series of
 * FetchReplies until IsFinalResponse. Each group of responses will have a
 * unique FetchID to link them.
 */
export interface TrawlerFetchReplyDataPartialResponse {
  /**
   * If set, indicates where the fetched body is, e.g. a CNS file path.
   * FetchReply.Body should be empty in this case. In the case where client does
   * not support streaming but the content is too large to be accumulated in
   * memory, we keep writing the streaming chunks to some storage unit and
   * notify client when it is done.
   */
  BodyLocation?: string;
  /**
   * Fetch number in this series of fetches
   */
  ChunkNumber?: number;
  /**
   * If there is a Content-Range header, the ranges in it
   */
  ContentRange?: TrawlerContentRangeInfo;
  /**
   * Any ETag seen in the headers
   */
  ETag?: string;
  /**
   * ID which links all partial fetches for this url
   */
  FetchID?: bigint;
  /**
   * Is this the final response for this fetch?
   */
  IsFinalResponse?: boolean;
}

function serializeTrawlerFetchReplyDataPartialResponse(data: any): TrawlerFetchReplyDataPartialResponse {
  return {
    ...data,
    ContentRange: data["ContentRange"] !== undefined ? serializeTrawlerContentRangeInfo(data["ContentRange"]) : undefined,
    FetchID: data["FetchID"] !== undefined ? String(data["FetchID"]) : undefined,
  };
}

function deserializeTrawlerFetchReplyDataPartialResponse(data: any): TrawlerFetchReplyDataPartialResponse {
  return {
    ...data,
    ContentRange: data["ContentRange"] !== undefined ? deserializeTrawlerContentRangeInfo(data["ContentRange"]) : undefined,
    FetchID: data["FetchID"] !== undefined ? BigInt(data["FetchID"]) : undefined,
  };
}

/**
 * Group with protocol specific response (determined by the protocol of the url
 * that generated the content we return).
 */
export interface TrawlerFetchReplyDataProtocolResponse {
  /**
   * Response code. We emulate the HTTP response codes for all protocols that
   * we know. -- HTTP: response code for the downloaded page. -- FTP: similar
   * with HTTP: 200 - OK, 40X - errors (not found, etc), 500 - server
   * unavailable
   */
  Code?: number;
  /**
   * Content type as inferred by the fetcher (webutil/http/content-type.proto)
   */
  ContentType?:  | "CONTENT_FIRST_TYPE" | "CONTENT_GOOGLE_ERROR" | "CONTENT_GOOGLE_EMPTY" | "CONTENT_GOOGLE_OTHER" | "CONTENT_TEXT_HTML" | "CONTENT_TEXT_PLAIN" | "CONTENT_APPLICATION_POSTSCRIPT" | "CONTENT_APPLICATION_PDF" | "CONTENT_TEXT_WML" | "CONTENT_GOOGLE_WHITEPAGE" | "CONTENT_TEXT_HDML" | "CONTENT_TEXT_PDF" | "CONTENT_GOOGLE_USENET" | "CONTENT_IMAGE" | "CONTENT_IMAGE_THUMBNAIL" | "CONTENT_AUDIO_MP3" | "CONTENT_TEXT_POSTSCRIPT" | "CONTENT_APPLICATION_MSWORD" | "CONTENT_TEXT_MSWORD" | "CONTENT_APPLICATION_MS_POWERPOINT" | "CONTENT_TEXT_MS_POWERPOINT" | "CONTENT_APPLICATION_RTF" | "CONTENT_TEXT_RTF" | "CONTENT_APPLICATION_MS_EXCEL" | "CONTENT_TEXT_MS_EXCEL" | "CONTENT_TEXT_OTHER" | "CONTENT_APPLICATION_XSHOCKWAVEFLASH" | "CONTENT_TEXT_XSHOCKWAVEFLASH" | "CONTENT_APPLICATION_XGZIP" | "CONTENT_IMAGE_JPEG" | "CONTENT_IMAGE_XDJVU" | "CONTENT_SCAN_ATTR" | "CONTENT_SCAN_FAKE_HTML" | "CONTENT_GOOGLE_QECONOMY" | "CONTENT_GOOGLE_FROOGLE_OFFER" | "CONTENT_GOOGLE_DPL" | "CONTENT_GOOGLE_YP" | "CONTENT_APPLICATION_XML" | "CONTENT_GOOGLE_OCEAN_METADATA" | "CONTENT_GOOGLE_LOCALSEARCH" | "CONTENT_BINARY_OTHER" | "CONTENT_APPLICATION_ATOM_XML" | "CONTENT_APPLICATION_RDF_XML" | "CONTENT_APPLICATION_RSS_XML" | "CONTENT_APPLICATION_XHTML_XML" | "CONTENT_APPLICATION_OCTET_STREAM" | "CONTENT_TEXT_XML" | "CONTENT_GOOGLE_OCEAN_DOC" | "CONTENT_IMAGE_PNG" | "CONTENT_IMAGE_GIF" | "CONTENT_IMAGE_TIFF" | "CONTENT_APPLICATION_ZIP_ARCHIVE" | "CONTENT_TEXT_ZIP_ARCHIVE" | "CONTENT_APPLICATION_XGZIP_ARCHIVE" | "CONTENT_TEXT_XGZIP_ARCHIVE" | "CONTENT_APPLICATION_XTAR_ARCHIVE" | "CONTENT_TEXT_XTAR_ARCHIVE" | "CONTENT_APPLICATION_XCOMPRESS_ARCHIVE" | "CONTENT_TEXT_XCOMPRESS_ARCHIVE" | "CONTENT_APPLICATION_WAP_XHTML" | "CONTENT_APPLICATION_XJAVASCRIPT" | "CONTENT_APPLICATION_JAVASCRIPT" | "CONTENT_APPLICATION_ECMASCRIPT" | "CONTENT_TEXT_JAVASCRIPT" | "CONTENT_TEXT_ECMASCRIPT" | "CONTENT_APPLICATION_KML" | "CONTENT_APPLICATION_KMZ_ARCHIVE" | "CONTENT_TEXT_KML" | "CONTENT_APPLICATION_DWF" | "CONTENT_DRAWING_DWF" | "CONTENT_TEXT_DWF" | "CONTENT_APPLICATION_ODF" | "CONTENT_TEXT_ODF" | "CONTENT_GOOGLE_NEW" | "CONTENT_APPLICATION_OPENXML_WORD" | "CONTENT_TEXT_OPENXML_WORD" | "CONTENT_APPLICATION_OPENXML_EXCEL" | "CONTENT_TEXT_OPENXML_EXCEL" | "CONTENT_APPLICATION_OPENXML_POWERPOINT" | "CONTENT_TEXT_OPENXML_POWERPOINT" | "CONTENT_APPLICATION_OPENXML" | "CONTENT_TEXT_CSS" | "CONTENT_APPLICATION_JSON" | "CONTENT_TEXT_CROSS_DOMAIN_POLICY" | "CONTENT_APPLICATION_GPX_XML" | "CONTENT_APPLICATION_ENDNOTE_STYLE" | "CONTENT_TEXT_ENDNOTE_STYLE" | "CONTENT_APPLICATION_XPROTOBUFFER" | "CONTENT_APPLICATION_OPENSEARCHDESCRIPTION_XML" | "CONTENT_TEXT_CACHE_MANIFEST" | "CONTENT_VIDEO_3GPP" | "CONTENT_APPLICATION_ADOBE_ACSM" | "CONTENT_MODEL_DWFX" | "CONTENT_IMAGE_SVG_XML" | "CONTENT_APPLICATION_XHWP" | "CONTENT_TEXT_XHWP" | "CONTENT_APPLICATION_EPUB_ZIP" | "CONTENT_APPLICATION_X_WINDOWS_EXECUTABLE" | "CONTENT_APPLICATION_TEX_LATEX" | "CONTENT_TEXT_TEX_LATEX" | "CONTENT_APPLICATION_SAFEBROWSING_UPDATE" | "CONTENT_APPLICATION_SAFEBROWSING_CHUNK" | "CONTENT_APPLICATION_SAFEBROWSING_KEY" | "CONTENT_VIDEO_X_MS_ASF" | "CONTENT_APPLICATION_XBZIP" | "CONTENT_APPLICATION_OCTET_STREAM_COMPRESSIBLE" | "CONTENT_IMAGE_X_ICON" | "CONTENT_APPLICATION_ICS" | "CONTENT_IMAGE_WEBP" | "CONTENT_IMAGE_BMP" | "CONTENT_FONT_TTF" | "CONTENT_FONT_OTF" | "CONTENT_FONT_WOFF" | "CONTENT_FONT_WOFF2" | "CONTENT_APPLICATION_CSP_REPORT" | "CONTENT_VIDEO_MP2T" | "CONTENT_TEXT_X_VCALENDAR" | "CONTENT_FONT_EOT" | "CONTENT_APPLICATION_XMPEG_URL" | "CONTENT_APPLICATION_X_BROTLI_DICT_COMPRESSED" | "CONTENT_VIDEO_MP4" | "CONTENT_AUDIO_MP4" | "CONTENT_APPLICATION_MANIFEST_JSON" | "CONTENT_APPLICATION_MS_TNEF" | "CONTENT_TEXT_EPUB_ZIP" | "CONTENT_APPLICATION_FB2_XML" | "CONTENT_TEXT_FB2_XML" | "CONTENT_APPLICATION_WASM" | "CONTENT_APPLICATION_GEO_JSON" | "CONTENT_TEXT_CSV" | "CONTENT_APPLICATION_XPROTOBUF" | "CONTENT_VIDEO_WEBM" | "CONTENT_AUDIO_WEBM" | "CONTENT_TEXT_CONVERTED_XML" | "CONTENT_NUM_TYPES";
  /**
   * Where did we cut off? Includes headers plus truncated but uncompressed
   * content. Present if and only if we truncated the document.
   */
  CutoffSize?: bigint;
  /**
   * DEPRECATED, see field 113. Stores the HTTP version we used in the final
   * hop.
   */
  HttpVersion?:  | "HTTP_11" | "HTTP_10" | "HTTP_09" | "HTTP_2" | "HTTP_AUTO" | "FIRST_VERSION" | "NUM_VERSIONS";
  /**
   * DEPRECATED, see field 114. Whether we fallback from HTTP/2 to HTTP/1.1
   * during fetch. The fallback could happen in any hops and there can be at
   * most one fallback because once fallback happens, we will not try HTTP/2
   * anymore.
   */
  ProtocolVersionFallback?: boolean;
  /**
   * The amount of data we got from the webserver before any truncation, but
   * after undoing any HTTP gzip/deflate encoding. For HTTP, this includes
   * headers and uncompressed content. Content size is excluded if content was
   * not successfully fetched. See description above TotalFetchedSize for
   * comparison.
   */
  UnTruncatedSize?: bigint;
}

function serializeTrawlerFetchReplyDataProtocolResponse(data: any): TrawlerFetchReplyDataProtocolResponse {
  return {
    ...data,
    CutoffSize: data["CutoffSize"] !== undefined ? String(data["CutoffSize"]) : undefined,
    UnTruncatedSize: data["UnTruncatedSize"] !== undefined ? String(data["UnTruncatedSize"]) : undefined,
  };
}

function deserializeTrawlerFetchReplyDataProtocolResponse(data: any): TrawlerFetchReplyDataProtocolResponse {
  return {
    ...data,
    CutoffSize: data["CutoffSize"] !== undefined ? BigInt(data["CutoffSize"]) : undefined,
    UnTruncatedSize: data["UnTruncatedSize"] !== undefined ? BigInt(data["UnTruncatedSize"]) : undefined,
  };
}

/**
 * The sequence of redirects fetched, if applicable. This includes url plus
 * stats for each hop after the first hop. NOTE: This can be one redirect longer
 * than the chain of redirects *followed*, in the case where there was a
 * redirect at the end of the chain that the fetcher detected but did not
 * follow.
 */
export interface TrawlerFetchReplyDataRedirects {
  /**
   * The server SSL certificate chain in SSLCertificateInfo protobuf format.
   * See this field in FetchReplyData (i.e., the initial hop) for more
   * description on when it will be populated.
   */
  BadSSLCertificate?: Uint8Array;
  /**
   * Per redirect hop timestamps. This
   */
  CrawlTimes?: TrawlerCrawlTimes;
  /**
   * Download time of this fetch (ms)
   */
  DownloadTime?: number;
  /**
   * ## stats If fetched, ip info.
   */
  Endpoints?: TrawlerTCPIPInfo;
  /**
   * Extra trawler::PageNoIndexInfo for this hop. Integer: ORed together bits
   * from trawler::PageNoIndexInfo. The information specified by this field
   * comes from the http header or content of the source url, not the
   * "TargetUrl" in this Redirects group.
   */
  HopPageNoIndexInfo?: number;
  /**
   * trawler::ReuseInfo with status of IMS/IMF/cache query, for this hop.
   */
  HopReuseInfo?:  | "RUI_NONE" | "RUI_IMS_CACHE_CURRENT" | "RUI_IMS_NOT_MODIFIED" | "RUI_IMS_CHANGED" | "RUI_IMF_NOCACHE" | "RUI_IMF_CACHE_CURRENT" | "RUI_IMF_HIT" | "RUI_IMF_CHANGED" | "RUI_IMF_POST_HIT_ERROR" | "RUI_CACHE_CURRENT" | "RUI_CACHE_EXPIRED" | "RUI_CACHE_NOCACHE" | "RUI_CACHE_UNUSABLE" | "RUI_IMF_UNUSABLE" | "NUM_REUSE_INFO_VALS";
  /**
   * Extra trawler::RobotsInfo for this hop. Integer: ORed together bits from
   * trawler::RobotsInfo
   */
  HopRobotsInfo?: number;
  /**
   * If known, the hostid for this hop
   */
  HostId?: bigint;
  /**
   * This specifies if the url in a redirect was rewritten to HTTPS because of
   * an HSTS policy for the domain. See comments on FetchReplyData.HSTSInfo for
   * how this field's values. A redirect that was rewritten with HSTS will have
   * HSTS_STATUS_REWRITTEN ## here.
   */
  HSTSInfo?:  | "HSTS_STATUS_NONE" | "HSTS_STATUS_AVAILABLE" | "HSTS_STATUS_REWRITTEN";
  /**
   * The http headers we sent for fetching this redirect hop. Not normally
   * filled in, unless FetchParams.WantSentHeaders is set.
   */
  HttpRequestHeaders?: string;
  /**
   * The HTTP response code for this hop. We need this since multiple response
   * codes may have the same redirect type (e.g., 302 and 307 are both
   * REDIRECT_TEMPORARILY), but clients may want to know which one was received.
   * Note this is set only for the hops that are followed (i.e., TargetUrl is
   * present). If the last redirect hop was not followed the fetch status will
   * be URL_NOT_FOLLOWED, and the response code will be in the top level
   * ProtocolResponse field.
   */
  HTTPResponseCode?: number;
  /**
   * The http headers we received from this redirect hop. Trawler does not fill
   * this in; this is intended as a placeholder for crawls like webmirror that
   * fill in and want to track this across redirect hops.
   */
  HttpResponseHeaders?: string;
  /**
   * bytes: can contain bad encoding.
   */
  RawTargetUrl?: Uint8Array;
  /**
   * Refresh time in meta redirect tag
   */
  RefreshTime?: number;
  /**
   * The robots.txt we used for this fetch. Not normally filled in unless
   * WantRobotsBody is set.
   */
  RobotsTxt?: Uint8Array;
  /**
   * For meta-redirects, this field may contain the body of the source
   * document. Currently only filled client side and not implemented (yet) for
   * server-side redirects.
   */
  SourceBody?: TrawlerFetchBodyData;
  /**
   * Difference between the following two fields: TargetUrl is set when we have
   * followed the redirect target, and the url is canonicalized. RawTargetUrl is
   * set in either of the following two cases: (1) The url has not be been
   * followed. For example, the redirect is intended to be handled by the
   * client. In the fetch reply response, you will see the url's status as
   * URL_NOT_FOLLOWED-NOT_FOLLOWED*. (2) The extracted redirect url is different
   * from its *canonicalized* form. For example, if the target url contains
   * fragments, then this RawTargetUrl will have the fragments. Redirect target
   */
  TargetUrl?: string;
  /**
   * URL and redirect type
   */
  Type?:  | "REDIRECT_NONE" | "REDIRECT_EMPTY" | "REDIRECT_TOO_LONG" | "REDIRECT_PERMANENT" | "REDIRECT_TEMPORARILY" | "REDIRECT_META" | "REDIRECT_BAD_URL" | "REDIRECT_HTTP_REFRESH" | "REDIRECT_SCRIPT" | "REDIRECT_CUSTOM" | "REDIRECT_META_FRAGMENT" | "NUM_REDIRECT_TYPES";
}

function serializeTrawlerFetchReplyDataRedirects(data: any): TrawlerFetchReplyDataRedirects {
  return {
    ...data,
    BadSSLCertificate: data["BadSSLCertificate"] !== undefined ? encodeBase64(data["BadSSLCertificate"]) : undefined,
    CrawlTimes: data["CrawlTimes"] !== undefined ? serializeTrawlerCrawlTimes(data["CrawlTimes"]) : undefined,
    Endpoints: data["Endpoints"] !== undefined ? serializeTrawlerTCPIPInfo(data["Endpoints"]) : undefined,
    HostId: data["HostId"] !== undefined ? String(data["HostId"]) : undefined,
    RawTargetUrl: data["RawTargetUrl"] !== undefined ? encodeBase64(data["RawTargetUrl"]) : undefined,
    RobotsTxt: data["RobotsTxt"] !== undefined ? encodeBase64(data["RobotsTxt"]) : undefined,
    SourceBody: data["SourceBody"] !== undefined ? serializeTrawlerFetchBodyData(data["SourceBody"]) : undefined,
  };
}

function deserializeTrawlerFetchReplyDataRedirects(data: any): TrawlerFetchReplyDataRedirects {
  return {
    ...data,
    BadSSLCertificate: data["BadSSLCertificate"] !== undefined ? decodeBase64(data["BadSSLCertificate"] as string) : undefined,
    CrawlTimes: data["CrawlTimes"] !== undefined ? deserializeTrawlerCrawlTimes(data["CrawlTimes"]) : undefined,
    Endpoints: data["Endpoints"] !== undefined ? deserializeTrawlerTCPIPInfo(data["Endpoints"]) : undefined,
    HostId: data["HostId"] !== undefined ? BigInt(data["HostId"]) : undefined,
    RawTargetUrl: data["RawTargetUrl"] !== undefined ? decodeBase64(data["RawTargetUrl"] as string) : undefined,
    RobotsTxt: data["RobotsTxt"] !== undefined ? decodeBase64(data["RobotsTxt"] as string) : undefined,
    SourceBody: data["SourceBody"] !== undefined ? deserializeTrawlerFetchBodyData(data["SourceBody"]) : undefined,
  };
}

export interface TrawlerFetchStatus {
  /**
   * The Reason field gives further clarifying details about why or how the
   * fetch had the given outcome. For instance, if State is URL_ERROR - was it a
   * 404/NotFound or a DNS error? The Reason field is present iff State !=
   * URL_CRAWLED. For a given crawl status of URL_FOO, the Reason value will be
   * one of the various FetchFooReason enum values from
   * crawler/trawler/trawler_enums.proto
   */
  Reason?: number;
  /**
   * The State field describes the basic outcome of a fetch (URL_CRAWLED,
   * URL_ROBOTED, URL_ERROR, etc). The value is one of the UrlStatusType enum
   * values from crawler/trawler/trawler_enums.proto Note, there are several
   * combinations of this Status/Reason tuple that could mean that your content
   * is crawled or can be bucketed in a particular type of error. So instead of
   * comparing the enumeration values manually, we suggest to use the predicate
   * functions such as IsContentCrawled() provided in
   * crawler/trawler/public/basictypes.h (see details there).
   */
  State?:  | "URL_CRAWLED" | "URL_ERROR" | "URL_ROBOTED" | "URL_UNREACHABLE" | "URL_TIMEOUT" | "URL_REJECTED" | "URL_NOT_FOLLOWED" | "NUM_STATE_TYPES";
}

/**
 * ============================ Next Tag: 21 ============================ Data
 * about the scheduling host bucket a URL was in (if the client wants to use
 * this, e.g. for more intelligent scheduling, etc).
 */
export interface TrawlerHostBucketData {
  /**
   * How much existing traffic
   */
  ClientTrafficFraction?: number;
  /**
   * belong to the client How much weight the client
   */
  ClientWeightFraction?: number;
  /**
   * How many connections are actively used for downloading ?
   */
  CurrentActiveConnections?: number;
  /**
   * Is this bucket currently full ?
   */
  IsFull?: boolean;
  /**
   * How many ms ago we last scheduled a url
   */
  LastScheduleIntervalMs?: bigint;
  /**
   * The current hostload value (# of connections) - if negative does not apply
   */
  MaxActiveConnections?: number;
  /**
   * The load the recent times (the actual hostload that we apply is
   * MaxActiveConnections / MediumTermLoad) - a hostload of 1.00 is normal,
   * while over 1.0 is higher than normal load
   */
  MediumTermLoad?: number;
  /**
   * The min delay between requests (in secs) - if negative does not apply
   */
  MinInterRequestSecs?: number;
  /**
   * If is full, when is becoming non-full (in ms)
   */
  NonFullIntervalMs?: bigint;
  /**
   * The following four fields attempt to make things simpler for clients to
   * estimate available capacity. They are not populated yet as of 2013/08/21.
   * Even after they are populated, they may change. So talk to trawler-dev@
   * before you use the fields. Total qps for this hostid
   */
  TotalCapacityQps?: number;
  /**
   * Currently used qps
   */
  TotalUsedQps?: number;
  urllist?: TrawlerHostBucketDataUrlList[];
}

function serializeTrawlerHostBucketData(data: any): TrawlerHostBucketData {
  return {
    ...data,
    LastScheduleIntervalMs: data["LastScheduleIntervalMs"] !== undefined ? String(data["LastScheduleIntervalMs"]) : undefined,
    NonFullIntervalMs: data["NonFullIntervalMs"] !== undefined ? String(data["NonFullIntervalMs"]) : undefined,
    urllist: data["urllist"] !== undefined ? data["urllist"].map((item: any) => (serializeTrawlerHostBucketDataUrlList(item))) : undefined,
  };
}

function deserializeTrawlerHostBucketData(data: any): TrawlerHostBucketData {
  return {
    ...data,
    LastScheduleIntervalMs: data["LastScheduleIntervalMs"] !== undefined ? BigInt(data["LastScheduleIntervalMs"]) : undefined,
    NonFullIntervalMs: data["NonFullIntervalMs"] !== undefined ? BigInt(data["NonFullIntervalMs"]) : undefined,
    urllist: data["urllist"] !== undefined ? data["urllist"].map((item: any) => (deserializeTrawlerHostBucketDataUrlList(item))) : undefined,
  };
}

/**
 * Per each list that wishes to schedule url we return one of these:
 */
export interface TrawlerHostBucketDataUrlList {
  /**
   * Is this client/requestorid allowed to crawl now? (based on resource use)
   */
  ClientCanCrawl?: boolean;
  /**
   * Is this the 'default' user's list
   */
  IsDefaultNode?: boolean;
  /**
   * Was this the list that a given request landed in?
   */
  IsListForUrl?: boolean;
  /**
   * # of current active fetches
   */
  NumCurrentFetches?: number;
  /**
   * # of urls currently in the queue
   */
  NumUrls?: number;
  /**
   * The fp64 of the requestor string
   */
  RequestorFp?: bigint;
  /**
   * The type of the request (low latency vs. high throughput)
   */
  RequestType?:  | "HIGH_THROUGHPUT" | "LOW_LATENCY" | "NUM_REQUEST_TYPES";
}

function serializeTrawlerHostBucketDataUrlList(data: any): TrawlerHostBucketDataUrlList {
  return {
    ...data,
    RequestorFp: data["RequestorFp"] !== undefined ? String(data["RequestorFp"]) : undefined,
  };
}

function deserializeTrawlerHostBucketDataUrlList(data: any): TrawlerHostBucketDataUrlList {
  return {
    ...data,
    RequestorFp: data["RequestorFp"] !== undefined ? BigInt(data["RequestorFp"]) : undefined,
  };
}

/**
 * Information about VPC fetches tracked for logging purposes.
 */
export interface TrawlerLoggedVPCDestination {
  cloudRegion?: string;
  vnid?: NetFabricRpcVirtualNetworkId;
}

/**
 * Contain Multiverse client information, such as topic name. Can include other
 * information such as crawl policy id in the future.
 */
export interface TrawlerMultiverseClientIdentifier {
  topicName?: string;
  trafficType?:  | "TRAFFIC_TYPE_UNSPECIFIED" | "TRAFFIC_TYPE_NO_FETCH" | "TRAFFIC_TYPE_ONEOFF_CRAWL" | "TRAFFIC_TYPE_DISCOVERY" | "TRAFFIC_TYPE_REFRESH";
}

/**
 * The information about the original client who starts the request.
 */
export interface TrawlerOriginalClientParams {
  clientCell?: string;
  clientIp?: string;
  /**
   * through which RPC request
   */
  clientRpcType?:  | "UNKNOWN_RPC" | "PUSH_URL_TO_CRAWL" | "PUSH_BATCH_TO_CRAWL" | "CRAWL_URL" | "STREAM_FETCH_URL" | "LEGACY_STREAM_FETCH_URL" | "SUBSCRIBE_URL_ONCE" | "FEEDS_TRANSFER";
  clientUsername?: string;
}

/**
 * Trawler can add a policy label to a FetchReply. The two main cases are: -
 * "spam" label added for specific spammer IPs listed in trawler_site_info,
 * which most crawls auto-reject. - "roboted:useragent" (e.g.
 * "roboted:googlebot") if InfoOnlyUserAgents field is set in FetchParams
 */
export interface TrawlerPolicyData {
  /**
   * in roboted case, the RobotsInfo
   */
  ExtraData?: number;
  /**
   * "spam" or "roboted:googlebot"
   */
  Label?: string;
}

/**
 * This protobuf specifies the results of https certificate validation,
 * typically used for the BadSSLCertificate field in FetchReplyData.
 * -------------------------- Next Tag: 13 -------------------------------
 */
export interface TrawlerSSLCertificateInfo {
  /**
   * ALPN negotiated protocol, see https://tools.ietf.org/html/rfc7301 The
   * value will either be empty, or one of the protocol names sent by the client
   * that the server accepted. Examples include "h2" and "acme-tls/1".
   */
  ALPNNegotiatedProtocol?: string;
  /**
   * If present, this consists of the remote webserver's X.509 certificate
   * chain in DER format. The chain stored here is the *reversed* result of
   * SSL_get_peer_cert_chain(). That is to say, it is the chain presented by the
   * peer (which may differ from the chain that was built and verified), but in
   * leaf-last order. Typically the root cert will not be included. But do not
   * assume anything, because servers do all manner of weird things. (For
   * example on the beginning of the chain, there might be also some irrelevant
   * certificates besides the root certificate.) Certificates may be the empty
   * string, indicating an encoding failure. See also |IsTruncated|. Certs can
   * be loaded with util/sig/cert.h Cert::LoadBinaryCert(), converted to ASCII
   * PEM format (CertificateUtil::CertificateToPEM()) or shown as text at the
   * commandline by piping them into 'openssl x509 -text -inform DER'.
   */
  CertificateChain?: Uint8Array[];
  /**
   * ErrorMessages contains errors from HTTPS validation. Examples of such
   * errors include invalid certificates, failure to build a certificate chain,
   * certificates that do not match the expected hostname, and internal errors.
   * If ErrorMessages is empty, HTTPS validation succeeded. Otherwise, it
   * failed. This is the only guarantee about the contents of this field, though
   * legacy code exists that embeds invalid assumptions, b/70904498. New code
   * should not do anything with this field other than test whether it is empty
   * and display its value to humans. If you need to know more about the details
   * of a particular HTTPS validation, you can revalidate |CertificateChain|
   * independently.
   */
  ErrorMessages?: string[];
  /**
   * This SSLCertificateInfo had its fields truncated because it was too large.
   * It is no longer set (cl/205356251) but may be true in old records.
   */
  IsTruncated?: boolean;
  /**
   * Stapled OCSP response obtained during the TLS handshake, if any. An OCSP
   * (Online Certificate Status Protocol) response is an indication, signed by
   * the issuing CA, that the certificate has not been revoked. A TLS handshake
   * extension allows servers to "staple" a response to the certificate served
   * in the handshake, saving the need for the client to fetch it itself from
   * the CA. This field contain the stapled OCSP response if the server served
   * one. See RFC6066, Section 8 for the data format:
   * https://tools.ietf.org/html/rfc6066#section-8
   */
  OCSPResponse?: Uint8Array;
  /**
   * SCTList obtained during the TLS handshake, if any. See RFC6962, Section
   * 3.3 for the data format: https://tools.ietf.org/html/rfc6962#section-3.3
   */
  SCTList?: Uint8Array;
  SSLCipherSuite?: number;
  SSLCipherSuiteName?: string;
  /**
   * Details about the SSL/TLS protocol and cipher. See RFC5246 and
   * google3/crawler/trawler/hope/proto/ssl.proto for more details.
   */
  SSLProtocolVersion?: number;
  /**
   * The names of the SSL protocol version and cipher suite. These strings are
   * implementation defined and may be subject to change.
   */
  SSLProtocolVersionName?: string;
}

function serializeTrawlerSSLCertificateInfo(data: any): TrawlerSSLCertificateInfo {
  return {
    ...data,
    CertificateChain: data["CertificateChain"] !== undefined ? data["CertificateChain"].map((item: any) => (encodeBase64(item))) : undefined,
    OCSPResponse: data["OCSPResponse"] !== undefined ? encodeBase64(data["OCSPResponse"]) : undefined,
    SCTList: data["SCTList"] !== undefined ? encodeBase64(data["SCTList"]) : undefined,
  };
}

function deserializeTrawlerSSLCertificateInfo(data: any): TrawlerSSLCertificateInfo {
  return {
    ...data,
    CertificateChain: data["CertificateChain"] !== undefined ? data["CertificateChain"].map((item: any) => (decodeBase64(item as string))) : undefined,
    OCSPResponse: data["OCSPResponse"] !== undefined ? decodeBase64(data["OCSPResponse"] as string) : undefined,
    SCTList: data["SCTList"] !== undefined ? decodeBase64(data["SCTList"] as string) : undefined,
  };
}

/**
 * To keep track of fetch connection endpoints. Note: You can use
 * trawler::SourceIP(info) or trawler::DestinationIP(info) (as well as
 * HasSourceIP/HasDestinationIP) in basictypes.h instead of accessing the packed
 * strings directly. This will return a proper IPAddress. Never use the fixed32
 * based Source/Destination-IP in new code as they will go away (only IPv4).
 */
export interface TrawlerTCPIPInfo {
  /**
   * Address of the destination host. Extract with trawler::DestinationIP() or
   * decode with PackedStringToIPAddress().
   */
  DestinationIPAddressPacked?: Uint8Array;
  DestinationPort?: number;
  /**
   * Source address of the crawl machine we originated the fetch from. Extract
   * with trawler::SourceIP() or decode with PackedStringToIPAddress().
   */
  SourceIPAddressPacked?: Uint8Array;
  SourcePort?: number;
}

function serializeTrawlerTCPIPInfo(data: any): TrawlerTCPIPInfo {
  return {
    ...data,
    DestinationIPAddressPacked: data["DestinationIPAddressPacked"] !== undefined ? encodeBase64(data["DestinationIPAddressPacked"]) : undefined,
    SourceIPAddressPacked: data["SourceIPAddressPacked"] !== undefined ? encodeBase64(data["SourceIPAddressPacked"]) : undefined,
  };
}

function deserializeTrawlerTCPIPInfo(data: any): TrawlerTCPIPInfo {
  return {
    ...data,
    DestinationIPAddressPacked: data["DestinationIPAddressPacked"] !== undefined ? decodeBase64(data["DestinationIPAddressPacked"] as string) : undefined,
    SourceIPAddressPacked: data["SourceIPAddressPacked"] !== undefined ? decodeBase64(data["SourceIPAddressPacked"] as string) : undefined,
  };
}

export interface TrawlerThrottleClientData {
  IsBandwidthThrottle?: boolean;
  /**
   * Max doc_requestor urls/second allowed from this client to this fetcher.
   */
  MaxAllowedRate?: number;
}

/**
 * This is an optional container of arbitrary data that can be added to a
 * FetchReplyData. This data is meant to be logged, but not sent back in a fetch
 * reply (it should be added *after* the reply is prepared). Use
 * FetchResponsePreparatorImpl::AddTrawlerPrivateDataToFetchReplyData to add.
 * See also the comment in fetch_response_preparator_impl.cc. Next Tag: 44
 */
export interface TrawlerTrawlerPrivateFetchReplyData {
  /**
   * Stores the OAuth authentication method.
   */
  authenticationInfo?:  | "AUTHORIZATION_UNKNOWN" | "AUTHORIZATION_REQUEST_HEADER" | "AUTHORIZATION_POST_BODY" | "AUTHORIZATION_QUERY_PARAMETER";
  /**
   * If we fetched using BotFetchAgent, what is the BotGroupName?
   */
  BotGroupName?: string;
  /**
   * This is the HOPE server that we sent the url to. We log the HOPE backend
   * cell and hope server shard number (e.g., 'qf:6'). This allows us to
   * understand how we are balancing our load to the HOPE servers.
   */
  BotHostname?: string;
  /**
   * Cache hit for this url, bypassed host_overfull error.
   */
  bypassedHostOverfull?: boolean;
  /**
   * Corresponds to AcceptableAfterDate field in FetchParams.
   */
  cacheAcceptableAfterDate?: number;
  /**
   * Corresponds to AcceptableAge field in FetchParams.
   */
  cacheAcceptableAge?: number;
  /**
   * Only set if the fetch uses cache content (is_cache_fetch is true).
   */
  cacheHitType?:  | "CACHE_HIT_NONE" | "FETCHER_IN_MEMORY_HIT" | "CACHE_PROXY_CACHE_SERVER_HIT" | "CACHE_PROXY_LARGE_STORE_HIT" | "CACHE_SERVER_HIT";
  /**
   * Present if the reply is from the trawler cache. This is the requestorid of
   * the trawler client that populated the cache with the data we are reusing.
   */
  CacheRequestorID?: string;
  cdnProvider?:  | "NON_CDN" | "CLOUDFLARE";
  /**
   * How many concurrent streams are on the connection when the request
   * finishes (including this request). Export this value to monitor the stream
   * multiplexing for HTTP/2.
   */
  concurrentStreamNum?: bigint;
  /**
   * Dependent fetch type
   */
  dependentFetchType?:  | "DEPENDENT_UNSPECIFIED" | "DEPENDENT_COMPOSITE_FETCH";
  /**
   * If the response header contains Content-Disposition header "attachment;
   * filename="google.zip": the download_file_name would be "google.zip"
   */
  downloadFileName?: string;
  /**
   * Which Trawler fetcher task fetched this URL.
   */
  FetcherTaskNumber?: number;
  HadInMemCacheHit?: boolean;
  /**
   * If we do not have Endpoints in FetchReplyData (e.g., url rejected due to
   * hostload limit), do we have a guess of the server IPAddress (e.g., from
   * robots fetch)? This helps us classify URLs based on country code, etc. The
   * field is filled with IPAddress::ToPackedString().
   */
  HintIPAddress?: Uint8Array;
  /**
   * HTTP Strict-Transport-Security (RFC6797) header value. We log this so we
   * can generate a list of hosts that prefer HTTPS over HTTP.
   */
  HSTSHeaderValue?: string;
  /**
   * Stores the HTTP version we used in the last hop.
   */
  httpVersion?:  | "HTTP_11" | "HTTP_10" | "HTTP_09" | "HTTP_2" | "HTTP_AUTO" | "FIRST_VERSION" | "NUM_VERSIONS";
  /**
   * Represents if the HostId belongs to HostId set in 5xx url patterns, it can
   * work as a tag when emitting requestor minute summary, this helps us to
   * aggregate traffic affected by 5xx patterns, and test if there are any
   * fetching changes.
   */
  Is5xxHostId?: boolean;
  /**
   * Whether this is a bidirectional streaming fetch.
   */
  isBidiStreamingFetch?: boolean;
  /**
   * Whether or not this is a Floonet fetch request. Floonet requests have
   * inherent lower availability (due to HOPE rejections when HOPE is in
   * degraded mode, and other Floonet specific reasons). Therefore, it is
   * important for debugging and for our availability SLO to know whether of not
   * it is a floonet fetch. IMPORTANT NOTE: This field is only currently set for
   * traffic that explicitly requires Floonet and can not failover to use
   * Googlebot (i.e. "transparent" or "implicit" Floonet fetches).
   */
  isFloonetFetch?: boolean;
  /**
   * Whether or not this response is sent from gRPC proxy service.
   */
  isFromGrpcProxy?: boolean;
  /**
   * Was this an internally-initiated robots.txt fetch?
   */
  IsRobotsFetch?: boolean;
  /**
   * Set if the fetch goes through the virtual private cloud path so we can
   * track the VPC traffic.
   */
  isVpcTraffic?: boolean;
  /**
   * Set to the hit location (CNS filename) if cache comes from large store.
   */
  largeStoreHitLocation?: string;
  /**
   * Multiverse client information
   */
  multiverseClientIdentifier?: TrawlerMultiverseClientIdentifier;
  /**
   * Number of times we drop the content of a stream reply or the final reply,
   * which can only be caused by REJECTED_NO_RPC_BUFFERS now.
   */
  numDroppedReplies?: bigint;
  /**
   * Store the original client information.
   */
  originalClientParams?: TrawlerOriginalClientParams;
  /**
   * What's the post data size (in bytes) if it's a post request.
   */
  PostDataSize?: bigint;
  /**
   * Note TrawlerPrivateFetchReplyData is never sent back to clients. The
   * following field is just for Trawler and Multiverse internal tracking, and
   * clients should not look at this field at all.
   */
  Producer?:  | "UNKNOWN_SUBSYSTEM_NAME" | "TRAWLER_HARPOON_FETCHER" | "WEBMIRROR_DISPATCHER" | "WEBMIRROR_CRAWL_ENGINE" | "MULTIVERSE_TRAWLER_FETCHPROXY" | "MULTIVERSE_FRONTEND_SERVER";
  /**
   * If set, this fetch was done through a proxy (e.g., fetchproxy).
   */
  ProxyInstance?: string;
  /**
   * Log the loas username in trawler private to help with debugging. Store the
   * username in trawler private so clients won't see it from FetchReply. To
   * reduce disk usage, we only log the loas username if the requestorid being
   * used does not have ClientUsernameRestrictions.
   */
  RequestUserName?: string;
  /**
   * If the requestor shares resource bucket with other requestorids, we will
   * store the resource bucket name in these fields.
   */
  resourceBucket?: string;
  /**
   * The number of bytes we sent back to the client.
   */
  ResponseBytes?: bigint;
  /**
   * If this was a robots.txt fetch (IsRobotsFetch above), this may contain the
   * robots.txt body. (It may not, for instance, 404s are omitted; current
   * policy is URL_CRAWLED + partially crawled) This includes http headers +
   * body.
   */
  RobotsBody?: string;
  /**
   * RPC deadline left at the end of url control flow. Can be useful for
   * debugging rpc deadline exceeded error received by clients, this field is
   * only recorded if it's small enough.
   */
  RpcEndDeadlineLeftMs?: number;
  /**
   * RPC deadline left at the start of url control flow. Can be useful for
   * debugging rpc deadline exceeded error received by clients, this field is
   * only recorded if RpcEndDeadlineLeftMs is small enough.
   */
  RpcStartDeadlineLeftMs?: number;
  /**
   * An arbitrary string signature identifying the remote server type/version.
   * In the case of HTTP, this would be the contents of the "Server:" header.
   */
  ServerSignature?: string;
  subResourceBucket?: string;
  /**
   * Service tier info will be used in traffic grapher for ploting per tier
   * graph.
   */
  tier?:  | "SERVICE_TIER_UNKNOWN" | "SERVICE_TIER_TRAWLER" | "SERVICE_TIER_HARPOON" | "SERVICE_TIER_PARTNER";
  /**
   * Which Trawler cell was this response fetched in? (e.g. "HR" or "YQ")
   */
  TrawlerInstance?: string;
  /**
   * The useragent string sent to the remote webserver. It corresponds to
   * UserAgentToSend field in FetchParams.
   */
  UserAgentSent?: string;
  /**
   * The fp2011 of useragent sent to the remote webserver, note it corresponds
   * to UserAgentToSend field in FetchParams
   */
  UserAgentSentFp?: bigint;
  /**
   * The following are vpc information that's only set if is_vpc_traffic is
   * true.
   */
  vpcDestination?: TrawlerLoggedVPCDestination;
}

function serializeTrawlerTrawlerPrivateFetchReplyData(data: any): TrawlerTrawlerPrivateFetchReplyData {
  return {
    ...data,
    concurrentStreamNum: data["concurrentStreamNum"] !== undefined ? String(data["concurrentStreamNum"]) : undefined,
    HintIPAddress: data["HintIPAddress"] !== undefined ? encodeBase64(data["HintIPAddress"]) : undefined,
    numDroppedReplies: data["numDroppedReplies"] !== undefined ? String(data["numDroppedReplies"]) : undefined,
    PostDataSize: data["PostDataSize"] !== undefined ? String(data["PostDataSize"]) : undefined,
    ResponseBytes: data["ResponseBytes"] !== undefined ? String(data["ResponseBytes"]) : undefined,
    UserAgentSentFp: data["UserAgentSentFp"] !== undefined ? String(data["UserAgentSentFp"]) : undefined,
  };
}

function deserializeTrawlerTrawlerPrivateFetchReplyData(data: any): TrawlerTrawlerPrivateFetchReplyData {
  return {
    ...data,
    concurrentStreamNum: data["concurrentStreamNum"] !== undefined ? BigInt(data["concurrentStreamNum"]) : undefined,
    HintIPAddress: data["HintIPAddress"] !== undefined ? decodeBase64(data["HintIPAddress"] as string) : undefined,
    numDroppedReplies: data["numDroppedReplies"] !== undefined ? BigInt(data["numDroppedReplies"]) : undefined,
    PostDataSize: data["PostDataSize"] !== undefined ? BigInt(data["PostDataSize"]) : undefined,
    ResponseBytes: data["ResponseBytes"] !== undefined ? BigInt(data["ResponseBytes"]) : undefined,
    UserAgentSentFp: data["UserAgentSentFp"] !== undefined ? BigInt(data["UserAgentSentFp"]) : undefined,
  };
}

/**
 * Information about the result support for a given interpretation.
 */
export interface UniversalsearchNewPackerKnowledgeResultSupport {
  /**
   * A debug message that summarizes how the score was computed. Populated if
   * result was matched and in debug mode.
   */
  debug?: string;
  /**
   * The docid of the result, if available.
   */
  docid?: bigint;
  /**
   * The naviness for this result. Each matcher can determine the naviness to
   * use for the result. This can be copied directly from the result, or
   * estimated based on clicks or some other heuristic. The value should be
   * between 0 and 1 and should indicate the probability that the user will
   * click on that result. The estimated_naviness is used to break ties when
   * between results with the same rank.
   */
  estimatedNaviness?: number;
  /**
   * All provenances of this result support.
   */
  provenance?: UniversalsearchNewPackerKnowledgeResultSupportProvenance[];
  /**
   * The 0 based rank for this result. When the source is MAIN_GSR this
   * corresponds to the index of the result in the generic search response
   * specific in AddKnowledgePackerPreprocessors. Otherwise, the rank should be
   * estimated so the result is closest in importance to the web result at the
   * same rank.
   */
  rank?: number;
  /**
   * A score from 0 to 1 inclusive that represents the strength of the result
   * support. A score of one indicates this result is entirely about this
   * interpretation.
   */
  score?: number;
  /**
   * The source of the result support.
   */
  source?:  | "MAIN_GSR" | "LIVE_RESULT" | "NEWS" | "CLIR_GSR" | "CONTEXTBOOST_RESULT" | "SUPPORT_FROM_KSCORER" | "PERSONALIZED_RESULT";
  /**
   * The result url when available.
   */
  url?: string;
}

function serializeUniversalsearchNewPackerKnowledgeResultSupport(data: any): UniversalsearchNewPackerKnowledgeResultSupport {
  return {
    ...data,
    docid: data["docid"] !== undefined ? String(data["docid"]) : undefined,
  };
}

function deserializeUniversalsearchNewPackerKnowledgeResultSupport(data: any): UniversalsearchNewPackerKnowledgeResultSupport {
  return {
    ...data,
    docid: data["docid"] !== undefined ? BigInt(data["docid"]) : undefined,
  };
}

/**
 * Information about provenance of a result support.
 */
export interface UniversalsearchNewPackerKnowledgeResultSupportProvenance {
  /**
   * Entity group type of the supported entity. This field should only be set
   * for support on entities.
   */
  entityGroupType?:  | "QUESTION" | "ANSWER" | "INTENT";
  /**
   * ===== Deprecated Fields ===== The bool flag indicating whether the
   * ResultSupport comes from answer entities.
   */
  fromAnswer?: boolean;
  /**
   * The provenance provider name.
   */
  name?: string;
}

/**
 * Url poisoning information. This information is sparse: if num_spam_siblings
 * is not populated, none of the following fields will be populated. Next tag: 6
 */
export interface UrlPoisoningData {
  /**
   * fetched from the web. Time when the page was last
   */
  NotChangedTimeMs?: bigint;
  numSpamSiblings?: number;
  /**
   * Time when the page was
   */
  OriginalCrawlTimeMs?: bigint;
  /**
   * checked but found to be the same as before. If set, timestamp to indicate
   */
  ReuseTimeMs?: bigint;
  /**
   * when it is fetched from the repository. URL of the document for debugging
   */
  url?: string;
}

function serializeUrlPoisoningData(data: any): UrlPoisoningData {
  return {
    ...data,
    NotChangedTimeMs: data["NotChangedTimeMs"] !== undefined ? String(data["NotChangedTimeMs"]) : undefined,
    OriginalCrawlTimeMs: data["OriginalCrawlTimeMs"] !== undefined ? String(data["OriginalCrawlTimeMs"]) : undefined,
    ReuseTimeMs: data["ReuseTimeMs"] !== undefined ? String(data["ReuseTimeMs"]) : undefined,
  };
}

function deserializeUrlPoisoningData(data: any): UrlPoisoningData {
  return {
    ...data,
    NotChangedTimeMs: data["NotChangedTimeMs"] !== undefined ? BigInt(data["NotChangedTimeMs"]) : undefined,
    OriginalCrawlTimeMs: data["OriginalCrawlTimeMs"] !== undefined ? BigInt(data["OriginalCrawlTimeMs"]) : undefined,
    ReuseTimeMs: data["ReuseTimeMs"] !== undefined ? BigInt(data["ReuseTimeMs"]) : undefined,
  };
}

/**
 * Wire-format for a Status object
 */
export interface UtilStatusProto {
  /**
   * The canonical error code (see codes.proto) that most closely corresponds
   * to this status. May be missing.
   */
  canonicalCode?: number;
  /**
   * Numeric code drawn from the space specified below. Often, this is the
   * canonical error space, and code is drawn from google3/util/task/codes.proto
   */
  code?: number;
  /**
   * Detail message
   */
  message?: string;
  /**
   * message_set associates an arbitrary proto message with the status.
   */
  messageSet?: Proto2BridgeMessageSet;
  /**
   * The following are usually only present when code != 0 Space to which this
   * status belongs
   */
  space?: string;
}

/**
 * 
 * ------------------------------------------------------------------------------
 * Proto message containing the trusted genome entities that belong to an app.
 * Document type: ANDROID_APP See go/gd-server-design for more info. ## Next
 * tag: 4
 */
export interface VendingConsumerProtoTrustedGenomeAnnotation {
  /**
   * The list of trusted genome policy.
   */
  policy?: VendingConsumerProtoTrustedGenomePolicy;
  /**
   * The list of test code, used to log when serving. The test code is set in
   * both control and experiment annotations when they are different.
   */
  testCode?:  | "UNKNOWN" | "RESERVED" | "RESERVED_2" | "RESERVED_3" | "CRSCORE_EQ_0" | "CRSCORE_GT_0" | "STORIES_IN_MOVIES_HOME" | "RELATED_X_DC_CLUSTERS_IN_MOVIE_DETAILS_PAGES" | "TC_IN_PSS_CHECK_A" | "TC_IN_PSS_CHECK_B" | "QUERY_IS_BOOTS_ELIGIBLE" | "QUERY_HAS_SELECTED_BOOTS_CHIP" | "QUERY_HAS_ONLY_UNSELECTED_BOOTS_CHIPS" | "SPONSORED_ADS_CLUSTER" | "IRON_THRONE_QUERY" | "GUIDED_DISCOVERY" | "BOOKS_AUTHOR_QUERY" | "BOOTS_PROD_V1_QUERY" | "SHOULD_SEE_LIVE_OP_CLUSTER_CANDIDATES" | "ENTERTAINMENT_CLUSTER_TRIGGERING" | "BOOTS_EN_IN" | "BOOTS_EN_GB" | "BOOTS_EN_PH" | "BOOTS_EN_CA" | "ENTERTAINMENT_CLUSTER_CONTAINER_SEARCH_ENABLED" | "SEARCH_NAV_SPONSORED_ADS_CLUSTER" | "TOP_CHART_RANKING_INFO" | "APPS_PUB_QUERY" | "ABUSIVE_QUERY_SQUASHING_EVENT" | "APP_SUPPORTS_INSTANT_LAUNCH" | "LOW_RESULT_CLUSTER" | "PERSONALIZED_CLUSTER" | "GAME_SEEKING_PERSONALIZED_CLUSTER_AT_EVENT_LEVEL" | "VX_CLUSTER" | "MOVIES_GROOT_20" | "MOVIES_GROOT_10" | "MOVIES_GROOT_5" | "MOVIES_GROOT_3" | "MOVIES_GROOT_1" | "MOVIES_DORA_SEARCH" | "MOVIES_MDP_SEARCH" | "MOVIES_ORGANIC_SEARCH" | "FULL_PAGE_REPLACEMENT" | "AUDIOBOOKS_KIDS_CATEGORICAL_SEARCH" | "ZERO_RESULT" | "BOOTS_I18N_100_THRESH" | "DISPLAY_ADS_RESPONSE_RECEIVED_EVENT_LEVEL" | "BEST_SELLER_CART_TAG_FOR_MENDEL_AT_EVENT_LEVEL" | "ABUSIVE_QUERY" | "HOME_SPONSORED_ADS_CLUSTER_NO_ADS" | "BOOKS_XSELL_ELIGIBLE_APP" | "NAV_EXT_EVENT" | "ADS_CUSTOM_DETAILS_PAGE_ASSETS_SERVED_EVENT_LEVEL" | "BOOKS_DETAILS_PAGE_SIMILAR_CLUSTER" | "BOOKS_DETAILS_PAGE_POST_ACQUIRE_SIMILAR_CLUSTER" | "APPS_PERSONALIZED_TOPIC_QUERY_EVENT_LEVEL" | "APPS_PERSONALIZED_TG_QUERY_EVENT_LEVEL" | "APPS_PERSONALIZED_ALL_GAME_QUERIES_EVENT_LEVEL" | "APPS_PERSONALIZED_CATEGORICAL_GAME_SEEKING_QUERIES_EVENT_LEVEL" | "APPS_PERSONALIZED_CATEGORICAL_NON_TG_QUERIES_EVENT_LEVEL" | "BOOKS_ELIGIBLE_FOR_BUNDLE_EVENT_LEVEL" | "GAMES_PROFILE_CREATION_EVENT" | "MOVIES_QUERY_ELIGIBLE_FOR_APPS_CLUSTER" | "MOVIES_WALLE_SEARCH" | "TRUSTED_ENTITY_SEARCH_QUERY_EVENT" | "BUNDLE_FBT_DISCOUNT" | "BUNDLE_SERIES_DISCOUNT" | "APPS_SEARCH_TOPIC_RFY_CLUSTER_AT_EVENT_LEVEL" | "APPS_SEARCH_MINI_TOP_CHARTS_CLUSTER_AT_EVENT_LEVEL" | "APPS_SEARCH_TOPIC_RFY_CLUSTER_COUNTERFACTUAL" | "APPS_SEARCH_MINI_TOP_CHARTS_CLUSTER_COUNTERFACTUAL" | "GEARHEAD_TOOLTIP_ASSISTANT_FIRST_RUN" | "GEARHEAD_TOOLTIP_ASSISTANT_NTH_RUN" | "GEARHEAD_TOOLTIP_ASSISTANT_NTH_RUN_BUTTON" | "GEARHEAD_TOOLTIP_LAUNCHER_FIRST_RUN" | "GEARHEAD_TOOLTIP_LAUNCHER_NTH_RUN" | "GEARHEAD_TOOLTIP_NOTIFICATION_FIRST_RUN" | "GEARHEAD_TOOLTIP_NOTIFICATION_NEW" | "GEARHEAD_TOOLTIP_NOTIFICATION_NTH_NEW" | "KIDS_AGE_SCORE_BONUS_AT_EVENT_LEVEL" | "KIDS_QUALITY_TAG_SCORE_BONUS_AT_EVENT_LEVEL" | "LB_TARGETED_AT_EVENT_LEVEL" | "LB_IMPRESSED_AT_EVENT_LEVEL" | "GEARHEAD_INPUT_TOUCH_PRESENT" | "GEARHEAD_INPUT_ROTARY_PRESENT" | "GEARHEAD_INPUT_TOUCHPAD_PRESENT" | "GEARHEAD_INPUT_TOUCH_ABSENT" | "GEARHEAD_INPUT_ROTARY_ABSENT" | "GEARHEAD_INPUT_TOUCHPAD_ABSENT" | "CANCEL_SUBSCRIPTION_CONFIRMATION_DIALOG_SHOWN_WHEN_ELIGIBLE_FOR_ENTITLEMENT_BENEFITS_EVENT_LEVEL_AT_EVENT_LEVEL" | "SMART_FOP_AT_EVENT_LEVEL" | "VX_CLUSTER_IN_APPS_SERP_IMPRESSION" | "KIDS_CONTENT_SEEKING_QUERY" | "KIDS_CONTENT_SEEKING_QUERY_TREATMENT_APPLIED" | "PREFERRED_FOP" | "REDEEM_NOT_ENROLLED_TO_LOYALTY" | "GEARHEAD_TOOLTIP_SETTINGS" | "SEARCH_MDP_TRIGGERED_EVENT_LEVEL" | "DEVELOPER_PAGE_AT_EVENT_LEVEL" | "BOOKS_FREE_FIXED_DURATION_RENTAL_EVENT_LEVEL" | "BOOKS_FREE_FIXED_DATE_RENTAL_EVENT_LEVEL" | "BOOKS_PRICE_DROP_EVENT_LEVEL" | "TG_VALIDATED_CRISPR_TAG_AT_EVENT_LEVEL" | "GEARHEAD_TOOLTIP_ASSISTANT_DIALER_FIRST_OPEN" | "GEARHEAD_TOOLTIP_ASSISTANT_MEDIA_OPEN" | "GEARHEAD_WIDESCREEN_DISPLAY" | "GEARHEAD_TOOLTIP_ASSISTANT_PHONE_CALL_ENDED" | "SERIES_BUNDLE_MULTI_TIER_DISCOUNT_EVENT_LEVEL" | "GEARHEAD_TOOLTIP_FEEDBACK" | "GEARHEAD_TOOLTIP_ASSISTANT_MEDIA_REC_FIRST_RUN" | "GEARHEAD_WORK_PROFILE_DETECTED" | "GEARHEAD_WORK_PROFILE_DETECTED_AND_COMPATIBLE" | "GEARHEAD_WORK_PROFILE_QUERYING_ALLOWED" | "PLAY_ADS_REENGAGEMENT_COUNTERFACTUAL" | "GEARHEAD_TOOLTIP_ASSISTANT_LAUNCHER_OPEN" | "GEARHEAD_MULTIPLE_CALLABLE_PHONE_ACCOUNTS_DETECTED" | "GEARHEAD_USER_HAS_SELECTED_OUTGOING_PHONE_ACCOUNT" | "GEARHEAD_TOOLTIP_ASSISTANT_LONG_DRIVE_START" | "GEARHEAD_TOOLTIP_DIALER_MULTI_SIM" | "GEARHEAD_AUDIO_SERVICE_MIGRATION" | "GEARHEAD_TOOLTIP_ASSISTANT_MEDIA_REC_MEDIA_IDLE" | "GEARHEAD_DO_NOT_DISTURB_CALLS_ENABLED" | "REGIONAL_NAV_EXT_EVENT_LEVEL" | "GEARHEAD_TOOLTIP_BUGREPORT" | "GENERAL_QUERY_PAGINATION_EVENT_LEVEL" | "GEARHEAD_SESSION_ELIGIBLE_FOR_MEDIA_AUTOPLAY" | "GEARHEAD_AUDIO_FLOW_CONTROL_PERMIT_UNAVAILABLE" | "SHOULD_SEE_SEARCH_MEDIA_RESULT_CLUSTER" | "FRESH_RESULTS_SEEKING_SEARCH_QUERY_EVENT_LEVEL" | "GOOGLE_FUNDED_BUNDLE_DISCOUNT_BUCKET_1_EVENT_LEVEL" | "GOOGLE_FUNDED_BUNDLE_DISCOUNT_BUCKET_2_EVENT_LEVEL" | "GOOGLE_FUNDED_BUNDLE_DISCOUNT_BUCKET_3_EVENT_LEVEL" | "GOOGLE_FUNDED_BUNDLE_DISCOUNT_BUCKET_4_EVENT_LEVEL" | "GOOGLE_FUNDED_BUNDLE_DISCOUNT_BUCKET_5_EVENT_LEVEL" | "GOOGLE_FUNDED_BUNDLE_DISCOUNT_BUCKET_6_EVENT_LEVEL" | "TRUSTED_GENOME_RELATED_QUERY_CLUSTER_EVENT" | "NAV_TG_RELATED_QUERY_EVENT" | "PROMOTABLE_APPS_EVENT" | "PROMOTABLE_APPS_STRONG_CAT_EVENT" | "INLINE_DETAILS_TQUALITY_CHECK_PASS" | "INLINE_DETAILS_TQUALITY_CHECK_FAIL" | "INLINE_DETAILS_IS_INLINE_URL" | "EDITORS_CHOICE_CLUSTER_SERP_EVENT_LEVEL" | "BESTK_CLUSTER_SERP_EVENT_LEVEL" | "LIVEOPS_CLUSTER_SERP_EVENT_LEVEL" | "QUICKPICKS_CLUSTER_SERP_EVENT_LEVEL" | "INLINE_DETAILS_AQUALITY_CHECK_PASS" | "INLINE_DETAILS_AQUALITY_CHECK_FAIL" | "FRESH_RESULTS_SEEKING_CURRENT_YEAR_EVENT_LEVEL" | "FILTER_TQ_FAILURE_APP" | "EDITORIAL_CONTENT_CLUSTER_FHR_SERP_EVENT_LEVEL" | "PGSS_DETAILS_PAGE_TQUALITY_UNKNOWN_EVENT_LEVEL" | "PGSS_DETAILS_PAGE_TQUALITY_FAILED_EVENT_LEVEL" | "PGSS_DETAILS_PAGE_TQUALITY_PASSED_EVENT_LEVEL" | "PGSS_DETAILS_PAGE_AQUALITY_UNKNOWN_EVENT_LEVEL" | "PGSS_DETAILS_PAGE_AQUALITY_FAILED_EVENT_LEVEL" | "PGSS_DETAILS_PAGE_AQUALITY_PASSED_EVENT_LEVEL" | "PRE_INSTALL_LOW_QUALITY_DETAILS_PAGE_SIMILAR_APPS_ABSENT_EVENT_LEVEL" | "PRE_INSTALL_LOW_QUALITY_DETAILS_PAGE_SIMILAR_APPS_PRESENT_EVENT_LEVEL" | "INLINE_DETAILS_CALLER_AQUALITY_CHECK_PASS" | "INLINE_DETAILS_CALLER_AQUALITY_CHECK_FAIL" | "HSDP_AD_NETWORK_CALLER_TABLET_AQUALITY_CHECK_PASS" | "HSDP_AD_NETWORK_CALLER_TABLET_AQUALITY_CHECK_FAIL" | "HSDP_INDEPENDENT_APP_TABLET_AQUALITY_CHECK_UNKNOWN" | "HSDP_INDEPENDENT_APP_TABLET_AQUALITY_CHECK_PASS" | "HSDP_INDEPENDENT_APP_TABLET_AQUALITY_CHECK_FAIL" | "PTP_CLUSTER_SERP_P13N_RANKING_EVENT_LEVEL" | "BROAD_INTENT_REWEIGHTING_EVENT_LEVEL" | "QUERY_DEPENDENT_SNIPPET_EVENT_LEVEL" | "EXPANDED_DEV_SUCCESS_CLUSTER_EVENT_LEVEL" | "COLLAPSED_DEV_SUCCESS_CLUSTER_EVENT_LEVEL" | "TRIGGERED_DEV_SUCCESS_CLUSTER_EVENT_LEVEL" | "BROAD_INTENT_GAMES_TIMESPENT_EVENT_LEVEL" | "GEARHEAD_ATTEMPT_USB_RECOVERY" | "MDP_P13N_ALL_EVENT_LEVEL" | "MDP_P13N_GAME_QUERY_L5_EVENT_LEVEL" | "MDP_P13N_GAME_QUERY_L6_EVENT_LEVEL" | "MDP_P13N_GAME_QUERY_L7_EVENT_LEVEL" | "MDP_P13N_GAME_QUERY_L8_EVENT_LEVEL" | "MDP_P13N_GAME_QUERY_L9_EVENT_LEVEL" | "MDP_P13N_RERANKING_UNKNOWN_EVENT_LEVEL" | "MDP_P13N_RERANKING_CATEGORICAL_EVENT_LEVEL" | "MDP_P13N_RERANKING_NAVIGATIONAL_EVENT_LEVEL" | "MDP_P13N_RERANKING_MULTI_NAVIGATIONAL_EVENT_LEVEL" | "MDP_P13N_RERANKING_NAVIGATIONAL_EXT_EVENT_LEVEL" | "SECOND_PASS_POLARIS_RERANKING_EVENT_LEVEL" | "SECOND_PASS_POLARIS_WITH_RANKING_CHANGE_EVENT_LEVEL" | "GEARHEAD_TOOLTIP_COOLWALK_DASHBOARD_UNAVAILABLE" | "SECOND_PASS_BROAD_INTENT_QUERY_EVENT_LEVEL" | "SECOND_PASS_REWEIGHTING_TRIGGERED_EVENT_LEVEL" | "GEARHEAD_TOOLTIP_COOLWALK_RAIL_WIDGET" | "INLINE_DETAILS_TQUALITY_CHECK_UNKNOWN" | "SUPERROOT_PDS_SHORT_DESCRIPTION_EVENT_LEVEL" | "PGSS_SHORT_DESCRIPTION_DIFF_EVENT_LEVEL" | "EVENT_LEVEL_TEST_CODE_LIMIT" | "ENTERTAINMENT_CLUSTER_TRIGGERING_AT_SESSION_LEVEL" | "BEST_SELLER_CART_TAG_AT_SESSION_LEVEL" | "SHOULD_SEE_BOOKS_WISHLIST_CLUSTER" | "PRIMETIME_CONTENT_IN_DETAILS_PAGES" | "SEARCH_NON_NAV_SPONSORED_ADS_CLUSTER" | "BOOTS_NO_DIFF_AT_SESSION_LEVEL" | "ABUSIVE_QUERY_SQUASHING_AT_SESSION_LEVEL" | "CART_ABANDONMENT_TEST_CODE" | "APP_SUPPORTS_INSTANT_LAUNCH_AT_SESSION_LEVEL" | "LOW_RESULT_CLUSTER_AT_SESSION_LEVEL" | "PERSONALIZED_CLUSTER_AT_SESSION_LEVEL" | "GAME_SEEKING_PERSONALIZED_CLUSTER_AT_SESSION_LEVEL" | "VX_CLUSTER_AT_SESSION_LEVEL" | "MOVIES_GROOT_20_AT_SESSION_LEVEL" | "MOVIES_GROOT_10_AT_SESSION_LEVEL" | "MOVIES_GROOT_5_AT_SESSION_LEVEL" | "MOVIES_GROOT_3_AT_SESSION_LEVEL" | "MOVIES_GROOT_1_AT_SESSION_LEVEL" | "GEARHEAD_MESSAGING_AUTO_REPLY_CANDIDATE" | "MOVIES_DORA_SEARCH_AT_SESSION_LEVEL" | "MOVIES_MDP_SEARCH_AT_SESSION_LEVEL" | "MOVIES_ORGANIC_SEARCH_AT_SESSION_LEVEL" | "BUY_NOW_BUTTON" | "AUDIOBOOKS_KIDS_CATEGORICAL_SEARCH_AT_SESSION_LEVEL" | "ZERO_RESULT_AT_SESSION_LEVEL" | "ABUSIVE_QUERY_AT_SESSION_LEVEL" | "HOME_SPONSORED_ADS_CLUSTER_NO_ADS_AT_SESSION_LEVEL" | "BOOKS_XSELL_ELIGIBLE_APP_AT_SESSION_LEVEL" | "PURCHASABLE_SUBSCRIPTIONS_IN_DETAILS_PAGE_SESSION_LEVEL" | "NAV_EXT_SESSION" | "FAST_REINSTALL_TEST_CODE" | "APPS_DETAILS_PAGE_PROMOTION_SESSION_LEVEL" | "BOOKS_DETAILS_PAGE_PROMOTION_SESSION_LEVEL" | "DETAILS_PAGE_PROMOTION_SESSION_LEVEL" | "SHOULD_SEE_LIVE_OPS_V2_CLUSTER" | "BOOKS_DETAILS_PAGE_SIMILAR_CLUSTER_AT_SESSION_LEVEL" | "BOOKS_DETAILS_PAGE_POST_ACQUIRE_SIMILAR_CLUSTER_AT_SESSION_LEVEL" | "FLOATING_HIGHLIGHTS_ROW_TRIGGERING_AT_SESSION_LEVEL" | "APPS_DETAILS_PAGE_EXISTING_PROMOTION_SESSION_LEVEL" | "BOOKS_DETAILS_PAGE_EXISTING_PROMOTION_SESSION_LEVEL" | "BOOKS_ELIGIBLE_FOR_BUNDLE" | "FALLBACK_FOP_OPTIONS_RECOMMENDED" | "SHOULD_SEE_PREREG_LIVE_OPS_EH" | "SHOULD_SEE_PREREG_LIVE_OPS_DP" | "HERO_CARD_CLUSTER_AT_SESSION_LEVEL" | "FALLBACK_FOP_OPTIONS_AVAILABLE" | "SWOOP_10P_OFF_SESSION_LEVEL" | "SWOOP_25P_OFF_SESSION_LEVEL" | "SWOOP_50P_OFF_SESSION_LEVEL" | "SWOOP_75P_OFF_SESSION_LEVEL" | "CANCEL_SUBSCRIPTION_CONFIRMATION_DIALOG_SHOWN_WHEN_ELIGIBLE_FOR_ENTITLEMENT_BENEFITS" | "PREREGISTRATION_AT_SESSION_LEVEL" | "GAMES_PROFILE_CREATION" | "IN_APP_SALE_IN_CART" | "MOVIES_MAX_NUMBER_MEESEEKS_CLUSTERS_SHOWN" | "MOVIES_MAX_NUMBER_BYW_CLUSTERS_SHOWN" | "RANDOM_FOP_OPTIONS_RECOMMENDED" | "MOVIES_QUERY_ELIGIBLE_FOR_APPS_CLUSTER_AT_SESSION_LEVEL" | "INSTANT_BANNER_ELIGIBLE" | "SUGGEST_NAV_SUGGEST_TRIGGERED" | "TRUSTED_ENTITY_SEARCH_QUERY" | "BURNSIE_ADD_FOP_PROMOTION_SESSION_LEVEL" | "MOVIES_WALLE_SEARCH_AT_SESSION_LEVEL" | "BUNDLE_FBT_DISCOUNT_AT_SESSION_LEVEL" | "BUNDLE_SERIES_DISCOUNT_AT_SESSION_LEVEL" | "MOVIES_REPEATED_BUYER" | "SUBSCRIPTION_CANCELLATION_PROMOTION_SESSION_LEVEL" | "SUBSCRIPTION_RETRY_FOP_FOR_DCB_AS_PRIMARY_SESSION_LEVEL" | "SUBSCRIPTION_DCB_AS_ADD_FOP_OPTION_SESSION_LEVEL" | "APPS_SEARCH_TOPIC_RFY_CLUSTER_AT_SESSION_LEVEL" | "APPS_SEARCH_MINI_TOP_CHARTS_CLUSTER_AT_SESSION_LEVEL" | "APPS_PERSONALIZED_TOPIC_QUERY_SESSION_LEVEL" | "APPS_PERSONALIZED_TG_QUERY_SESSION_LEVEL" | "APPS_PERSONALIZED_ALL_GAME_QUERIES_SESSION_LEVEL" | "APPS_PERSONALIZED_CATEGORICAL_GAME_SEEKING_QUERIES_SESSION_LEVEL" | "APPS_PERSONALIZED_CATEGORICAL_NON_TG_QUERIES_SESSION_LEVEL" | "PLAY_STORE_SHOW_CART" | "MOVIES_RENTER" | "APPS_SEARCH_TOPIC_RFY_CLUSTER_COUNTERFACTUAL_AT_SESSION_LEVEL" | "APPS_SEARCH_MINI_TOP_CHARTS_CLUSTER_COUNTERFACTUAL_AT_SESSION_LEVEL" | "FREE_TRIAL_SUBSCRIPTION_CANCELATION_APP_INSTALLED" | "FREE_TRIAL_SUBSCRIPTION_CANCELATION_APP_NOT_INSTALLED" | "NON_FREE_TRIAL_SUBSCRIPTION_CANCELATION_APP_INSTALLED" | "NON_FREE_TRIAL_SUBSCRIPTION_CANCELATION_APP_NOT_INSTALLED" | "CLIENT_NOTIFICATION_APP_UNINSTALLED_WITH_SUBSCRIPTION" | "PURCHASABLE_SUBSCRIPTIONS_IN_DETAILS_PAGE_APP_1_AT_SESSION_LEVEL" | "PURCHASABLE_SUBSCRIPTIONS_IN_DETAILS_PAGE_APP_3_AT_SESSION_LEVEL" | "KIDS_AGE_SCORE_BONUS" | "UPDATE_SUBSCRIPTION_INSTRUMENT_PAYMENT_DECLINED_FOP_IMPRESSION" | "UPDATE_SUBSCRIPTION_INSTRUMENT_PAYMENT_DECLINED_FOP_MESSAGE_IMPRESSION" | "KIDS_QUALITY_TAG_SCORE_BONUS_AT_SESSION_LEVEL" | "SHOULD_SEE_REVIEW_MORE_LINK" | "INCENTIVIZED_OPTIN_INTERSTITIAL_AT_SESSION_LEVEL" | "PREMIUM_GAME_HOME" | "LB_TARGETED_AT_SESSION_LEVEL" | "PCD_APP_DETAILS" | "MIXED_AUDIENCE_APP_DETAILS" | "LB_IMPRESSED_AT_SESSION_LEVEL" | "HERO_CARD_CLUSTER_INSTANT_ELIGIBLE" | "LOYALTY_SHOULD_NOT_SEE_FREE_TRIAL_SUBSCRIPTION_POINTS_EARN_MESSAGE" | "MOVIES_USER_INTERESTS_NONE_AT_SESSION_LEVEL" | "MOVIES_USER_INTERESTS_LOW_AT_SESSION_LEVEL" | "MOVIES_USER_INTERESTS_MEDIUM_AT_SESSION_LEVEL" | "MOVIES_USER_INTERESTS_HIGH_AT_SESSION_LEVEL" | "MOVIES_BOY_SEEDS_NONE_AT_SESSION_LEVEL" | "MOVIES_BOY_SEEDS_LOW_AT_SESSION_LEVEL" | "MOVIES_BOY_SEEDS_MEDIUM_AT_SESSION_LEVEL" | "MOVIES_BOY_SEEDS_HIGH_AT_SESSION_LEVEL" | "RENEWAL_REMINDER_SET_IN_CANCEL_FLOW" | "RENEWAL_REMINDER_CAN_BE_SET_IN_CANCEL_FLOW" | "PLAY_PASS_SIGNUP_INTERSTITIAL_ELIGIBLE_SESSION_LEVEL" | "PLAY_PASS_SIGNUP_INTERSTITIAL_TARGETED_SESSION_LEVEL" | "PLAY_PASS_IPD_ELIGIBLE_SESSION_LEVEL" | "PLAY_PASS_FHR_ELIGIBLE_SESSION_LEVEL" | "DOUBLE_WIDE_SCREENSHOT_CLUSTER_TRIGGERING_AT_SESSION_LEVEL" | "TRIPLE_WIDE_VIDEO_CLUSTER_TRIGGERING_AT_SESSION_LEVEL" | "WIDE_MEDIA_CLUSTER_TRIGGERING_AT_SESSION_LEVEL" | "SMART_FOP_AT_SESSION_LEVEL" | "BILLING_PROFILE_DCB_ELIGIBLE" | "LOYALTY_UPSELL_AFTER_IN_APP_PURCHASE_AT_SESSION_LEVEL" | "SHOULD_SEE_APPS_COMPARISON_CLUSTER" | "RESIGNUP_FROM_SUBS_CENTER" | "VX_CLUSTER_IN_APPS_SERP_IMPRESSION_SESSIONS" | "PARTNER_REWARD_ON_LOYALTY_SIGNUP_PAGE" | "UGC_CLUSTER_AT_SESSION_LEVEL" | "REGIONAL_TRENDING_CLUSTER" | "USABLE_ANON_ML_FOP_OPTIONS_FOUND" | "ANON_ML_FOP_OPTIONS_RECOMMENDED" | "BUY_BUTTON_CLICK" | "TV_BUTTON_CLICK" | "LOYALTY_SEES_POINTS_EARN_PROMOTIONS_AT_SESSION_LEVEL" | "KIDS_CONTENT_SEEKING_QUERY_SESSION" | "KIDS_CONTENT_SEEKING_QUERY_TREATMENT_APPLIED_SESSION" | "UGC_CLUSTER_NON_FIRST_PAGE_AT_SESSION_LEVEL" | "UGC_CLUSTER_ELIGIBLE_AT_SESSION_LEVEL" | "LOYALTY_SEES_FREE_TRIAL_SUBSCRIPTION_AT_SESSION_LEVEL" | "APPS_SEARCH_FILTERS_TRIGGERED" | "APPS_SEARCH_FILTERS_ACTIVATED" | "PLAY_SUBMANAGEMENT_LOG_HOOK_SESSION_EXAMPLE" | "LOYALTY_SIGNUP_INTERSTITIAL_AT_SESSION_LEVEL" | "BOOTS_CHIPS_NOT_TRIGGERED_COUNTERFACTUAL" | "BOOTS_CHIPS_TRIGGERED_COUNTERFACTUAL" | "APPS_SEARCH_FILTERS_NOT_TRIGGERED" | "PREFERRED_FOP_AT_SESSION_LEVEL" | "REDEEM_NOT_ENROLLED_TO_LOYALTY_AT_SESSION_LEVEL" | "VIDEO_CLUSTER_EXPANDED" | "LOYALTY_UPSELL_SEEN_AT_SESSION_LEVEL" | "TRIPLE_WIDE_SCREENSHOT_CLUSTER_TRIGGERING_AT_SESSION_LEVEL" | "LOYALTY_LIVE_OPS_RETURNED_AT_SESSION_LEVEL" | "SEARCH_MDP_TRIGGERED_SESSION_LEVEL" | "PROMOLINK_CDP_SESSION_LEVEL" | "PROMOLINK_CDP_TITLE_PAGE_SESSION_LEVEL" | "PROMOLINK_CDP_TOPIC_PAGE_SESSION_LEVEL" | "PROMOLINK_CDP_GENERIC_PAGE_SESSION_LEVEL" | "WMC_INSTANT_PREVIEW_CLUSTER_AT_SESSION_LEVEL" | "POINTS_PROMOTION_CONTENT_PAGE_AT_SESSION_LEVEL" | "SEARCH_SYN_APPS_SESSION_LEVEL" | "IN_APP_OFFER_AT_SESSION_LEVEL" | "IN_APP_OFFER_APP_1_AT_SESSION_LEVEL" | "IN_APP_OFFER_APP_2_AT_SESSION_LEVEL" | "IN_APP_OFFER_APP_3_AT_SESSION_LEVEL" | "IN_APP_OFFER_APP_4_AT_SESSION_LEVEL" | "IN_APP_OFFER_ELIGIBLE_AT_SESSION_LEVEL" | "IN_APP_OFFER_ELIGIBLE_APP_1_AT_SESSION_LEVEL" | "IN_APP_OFFER_ELIGIBLE_APP_2_AT_SESSION_LEVEL" | "IN_APP_OFFER_ELIGIBLE_APP_3_AT_SESSION_LEVEL" | "IN_APP_OFFER_ELIGIBLE_APP_4_AT_SESSION_LEVEL" | "IN_APP_OFFER_SAVED_AT_SESSION_LEVEL" | "IN_APP_OFFER_SAVED_APP_1_AT_SESSION_LEVEL" | "IN_APP_OFFER_SAVED_APP_2_AT_SESSION_LEVEL" | "IN_APP_OFFER_SAVED_APP_3_AT_SESSION_LEVEL" | "IN_APP_OFFER_SAVED_APP_4_AT_SESSION_LEVEL" | "QUICK_BUY_AT_SESSION_LEVEL" | "DEVELOPER_PAGE_AT_SESSION_LEVEL" | "GAMES_SUBNAV_SHUFFLE_APPLIED" | "APPS_SUBNAV_SHUFFLE_APPLIED" | "BOOKS_FREE_FIXED_DURATION_RENTAL_SESSION_LEVEL" | "BOOKS_FREE_FIXED_DATE_RENTAL_SESSION_LEVEL" | "PAYMENTS_DELAYED_CHARGING_AT_SESSION_LEVEL" | "BOOKS_PRICE_DROP_SESSION_LEVEL" | "NON_EMPTY_HOME_STREAM_LIVE_OPS_CLUSTER_SERVED" | "SHOULD_SEE_LIVE_OPS_CARD_IN_SEARCH_MDP" | "CART_ABANDONMENT_SUBSCRIPTION_ONE_TIME_PASS_SESSION_LEVEL" | "MY_REVIEWS_PAGE_VISIT_USER_LEVEL" | "SERIES_BUNDLE_MULTI_TIER_DISCOUNT_SESSION_LEVEL" | "GOOGLE_PROMOTIONS_ELIGIBLE_SESSION_LEVEL" | "USER_TRIGGERED_IAP_PROMOTION_RETRIEVAL_SESSION_LEVEL" | "IAP_HAS_UNREDEEMED_PROMOTIONS_CLIENT_SESSION_LEVEL" | "SUBSCRIPTION_UPDATE_FOP_FOR_DCB_AS_PRIMARY_SIGNUP_SESSION_LEVEL" | "SUBSCRIPTION_UPDATE_FOP_FOR_DCB_AS_PRIMARY_SUB_CENTER_SESSION_LEVEL" | "RENEW_TASK_DELAYED_SUBSCRIPTION_TARGETED" | "RENEW_TASK_DELAYED_SUBSCRIPTION_NOT_TARGETED" | "PRE_AUTH_TASK_DELAYED_SUBSCRIPTION_TARGETED" | "PRE_AUTH_TASK_DELAYED_SUBSCRIPTION_NOT_TARGETED" | "REDEEM_REDIRECT_CHALLENGE_AT_SESSION_LEVEL" | "PLAY_STORE_IAP_SALES" | "PLAY_STORE_IAP_SALES_APP_1" | "PLAY_STORE_IAP_SALES_MINI_DETAILS_PAGE" | "CROSS_DEVICE_INSTALL_OPTIONS_FETCHED_IN_SESSION" | "CROSS_DEVICE_INSTALL_OPTIONS_ITEM_FIELDS_TRIGGERED" | "OTHER_DEVICES_SUBNAV_RETURNED_IN_SESSION" | "GEARHEAD_FRX_SENSITIVE_PERMISSION_SCREEN_SEEN" | "POST_PURCHASE_ITEM_UPSELL_SESSION_LEVEL" | "PLAY_PASS_SIGNUP_INTERSTITIAL_SHOWN_SESSION_LEVEL" | "FETCH_PROMOTION_BANNER_FROM_P3_SESSION_LEVEL" | "AVP_SWOOP_10P_OFF_SESSION_LEVEL" | "AVP_SWOOP_25P_OFF_SESSION_LEVEL" | "AVP_SWOOP_50P_OFF_SESSION_LEVEL" | "AVP_SWOOP_75P_OFF_SESSION_LEVEL" | "CLUSTER_TRIGGER_CONDITION_IS_PARENT" | "CDP_ENABLE_PREFETCH_SESSION_LEVEL" | "P13N_INTERSTITIAL_SESSION_LEVEL" | "GEARHEAD_SKIP_LEGACY_FRX_FOR_CAKEWALK" | "FEATURED_SUBSCRIPTIONS_PRESENT" | "SHOULD_NOT_SEE_HOME_LIVE_OPS_CLUSTER" | "SHOULD_SEE_HOME_LIVE_OPS_CLUSTER_K1_2" | "SHOULD_SEE_HOME_LIVE_OPS_CLUSTER_K1" | "SHOULD_SEE_HOME_LIVE_OPS_CLUSTER_K2" | "SHOULD_SEE_HOME_LIVE_OPS_CLUSTER_K3_4" | "SHOULD_SEE_HOME_LIVE_OPS_CLUSTER_GTE_K5" | "SHOULD_NOT_SEE_HOME_OFFER_CLUSTER" | "SHOULD_SEE_HOME_OFFER_CLUSTER_K1" | "SHOULD_SEE_HOME_OFFER_CLUSTER_K2" | "SHOULD_SEE_HOME_OFFER_CLUSTER_K3_4" | "SHOULD_SEE_HOME_OFFER_CLUSTER_GTE_K5" | "SHOULD_NOT_SEE_DEALS_HOME_OFFER" | "SHOULD_SEE_DEALS_HOME_OFFER_K1" | "SHOULD_SEE_DEALS_HOME_OFFER_K2" | "SHOULD_SEE_DEALS_HOME_OFFER_K3_4" | "SHOULD_SEE_DEALS_HOME_OFFER_GTE_K5" | "SHOULD_SEE_DEALS_HOME_GAME_K1" | "SHOULD_SEE_DEALS_HOME_GAME_K2" | "SHOULD_SEE_DEALS_HOME_GAME_K3" | "SHOULD_SEE_DEALS_HOME_GAME_K4" | "SHOULD_SEE_DEALS_HOME_GAME_GTE_K5" | "SHOULD_SEE_DEALS_HOME_APP_K1" | "SHOULD_SEE_DEALS_HOME_APP_K2" | "SHOULD_SEE_DEALS_HOME_APP_K3" | "SHOULD_SEE_DEALS_HOME_APP_K4" | "SHOULD_SEE_DEALS_HOME_APP_GTE_K5" | "SHOULD_SEE_DEALS_HOME_EVER_INSTALL_K1" | "SHOULD_SEE_DEALS_HOME_EVER_INSTALL_K2" | "SHOULD_SEE_DEALS_HOME_EVER_INSTALL_K3" | "SHOULD_SEE_DEALS_HOME_EVER_INSTALL_K4" | "SHOULD_SEE_DEALS_HOME_EVER_INSTALL_GTE_K5" | "SHOULD_SEE_DEALS_HOME_NEVER_INSTALL_K1" | "SHOULD_SEE_DEALS_HOME_NEVER_INSTALL_K2" | "SHOULD_SEE_DEALS_HOME_NEVER_INSTALL_K3" | "SHOULD_SEE_DEALS_HOME_NEVER_INSTALL_K4" | "SHOULD_SEE_DEALS_HOME_NEVER_INSTALL_GTE_K5" | "USE_SUBSCRIPTION_NEW_DOCUMENT_FORMAT_SESSION_LEVEL" | "USE_SUBSCRIPTION_NEW_DOCUMENT_FORMAT_PREVIEW_BATCH_SESSION_LEVEL" | "USE_SUBSCRIPTION_NEW_DOCUMENT_FORMAT_SKU_DETAILS_SESSION_LEVEL" | "USE_SUBSCRIPTION_NEW_DOCUMENT_FORMAT_PREVIEW_BATCH_SKU_DETAILS_SESSION_LEVEL" | "USE_SUBSCRIPTION_NEW_DOCUMENT_FORMAT_FOR_ALL_SUBS_SESSION_LEVEL" | "LEON_LIVEOPS_DEAL_STATE_SYNC_SESSION_LEVEL" | "SURVEY_AHC_AT_SESSION_LEVEL" | "PLAY_PASS_CART_MAREKTING_BANNER_ELIGIBLE_AND_SHOWN_CART_SESSION_LEVEL" | "PLAY_PASS_PERKS_VOUCHER_IN_CART_SESSION_LEVEL" | "PLAY_SEARCH_MDP_TRIGGERING" | "PLAY_SEARCH_NON_MDP_TRIGGERING" | "PRICE_TRANSPARENCY_IS_OFFER_PERSONALIZED_SESSION_LEVEL" | "GEARHEAD_SKIP_LEGACY_FRX_FOR_CAKEWALK_USB_CANDIDATE" | "PLAY_PASS_PARENT_FOCUSED_SPLASH_PAGE_SESSION_LEVEL" | "PLAY_PASS_SPLASH_PAGE_FOR_UNICORN_SESSION_LEVEL" | "REVIEW_SUBMITTED_SESSION_LEVEL" | "REVIEW_TOPIC_FILTER_SELECTED_SESSION_LEVEL" | "PLAY_SEARCH_GENERAL_QUERY_PAGINATION_SESSION_LEVEL" | "IN_CART_EXCHANGE_OPTIONS_ELIGIBLE_SESSION_LEVEL" | "PLAY_SEARCH_MULTINAV_PAGINATION_SESSION_LEVEL" | "REGIONAL_NAV_EXT_SESSION_LEVEL" | "IAP_SKU_DEALS_LIVE_OP_DEALS_HOME_SESSION_LEVEL" | "IAP_SKU_DEALS_LIVE_OP_GAMES_HOME_SESSION_LEVEL" | "FEATURING_AHC_OR_FHR_TRIGGERED_SESSION_LEVEL" | "ALLOWLIST_EXPANSION_FOR_P13N_INTERSTITIAL_SESSION_LEVEL" | "SURVEY_RECS_LIST_AT_SESSION_LEVEL" | "GEARHEAD_FRX_RUNNING_CW175_IN_GH" | "RANDOM_SHUFFLE_CLUSTERS_ON_TARGET_USERS_SESSION_LEVEL" | "RANDOM_SHUFFLE_CLUSTERS_AND_APPS_ON_TARGET_USERS_SESSION_LEVEL" | "ALLOWLIST_EXPANSION_FOR_P13N_NOTIFICATIONS_SESSION_LEVEL" | "FRESH_RESULTS_SEEKING_SEARCH_QUERY_SESSION_LEVEL" | "GOOGLE_FUNDED_BUNDLE_DISCOUNT_BUCKET_1_SESSION_LEVEL" | "GOOGLE_FUNDED_BUNDLE_DISCOUNT_BUCKET_2_SESSION_LEVEL" | "GOOGLE_FUNDED_BUNDLE_DISCOUNT_BUCKET_3_SESSION_LEVEL" | "GOOGLE_FUNDED_BUNDLE_DISCOUNT_BUCKET_4_SESSION_LEVEL" | "GOOGLE_FUNDED_BUNDLE_DISCOUNT_BUCKET_5_SESSION_LEVEL" | "GOOGLE_FUNDED_BUNDLE_DISCOUNT_BUCKET_6_SESSION_LEVEL" | "TRUSTED_GENOME_RELATED_QUERY_CLUSTER_SESSION" | "NAV_TG_RELATED_QUERY_SESSION" | "PROMOTABLE_APPS_SESSION" | "PROMOTABLE_APPS_STRONG_CAT_SESSION" | "GROWTH_COFFEE_CARD_IN_PURCHASE_FLOW_SESSION_LEVEL" | "GROWTH_COFFEE_CARD_IN_PURCHASE_FLOW_SERVER_SESSION_LEVEL" | "LIVE_OPS_ROI_HOLDBACK" | "EDITORS_CHOICE_CLUSTER_SERP_SESSION_LEVEL" | "BESTK_CLUSTER_SERP_SESSION_LEVEL" | "LIVEOPS_CLUSTER_SERP_SESSION_LEVEL" | "QUICKPICKS_CLUSTER_SERP_SESSION_LEVEL" | "WIDE_MEDIA_CLUSTER_INVALID_VIDEO_ASSET_SESSION_LEVEL" | "ALTERNATE_DEVICE_PRESENT_SESSION_LEVEL" | "MULTIPLE_ALTERNATE_DEVICES_PER_FORM_FACTOR_SESSION_LEVEL" | "APPS_SEARCH_DISCOVERY_CLUSTER_TRIGGERED_SESSION_LEVEL" | "SUGGEST_CROSS_FORM_FACTOR_APPS_WEAR_SUGGESTIONS_ENABLED" | "SUGGEST_CROSS_FORM_FACTOR_APPS_WEAR_SUGGESTIONS_AVAILABLE" | "SUGGEST_CROSS_FORM_FACTOR_APPS_TV_SUGGESTIONS_ENABLED" | "SUGGEST_CROSS_FORM_FACTOR_APPS_TV_SUGGESTIONS_AVAILABLE" | "SUGGEST_APPS_SUBTEXT_SUGGESTIONS_SESSION_LEVEL" | "SUGGEST_ZERO_PREFIX_LIVE_OPS_AVAILABLE" | "INLINE_DETAILS_TQUALITY_CHECK_PASS_SESSION_LEVEL" | "INLINE_DETAILS_TQUALITY_CHECK_FAIL_SESSION_LEVEL" | "INLINE_DETAILS_AQUALITY_CHECK_PASS_SESSION_LEVEL" | "INLINE_DETAILS_AQUALITY_CHECK_FAIL_SESSION_LEVEL" | "INLINE_DETAILS_CALLER_AQUALITY_CHECK_PASS_SESSION_LEVEL" | "INLINE_DETAILS_CALLER_AQUALITY_CHECK_FAIL_SESSION_LEVEL" | "HSDP_AD_NETWORK_CALLER_TABLET_AQUALITY_CHECK_PASS_SESSION_LEVEL" | "HSDP_AD_NETWORK_CALLER_TABLET_AQUALITY_CHECK_FAIL_SESSION_LEVEL" | "HSDP_INDEPENDENT_APP_TABLET_AQUALITY_CHECK_UNKNOWN_SESSION_LEVEL" | "HSDP_INDEPENDENT_APP_TABLET_AQUALITY_CHECK_PASS_SESSION_LEVEL" | "HSDP_INDEPENDENT_APP_TABLET_AQUALITY_CHECK_FAIL_SESSION_LEVEL" | "INLINE_DETAILS_IS_INLINE_URL_SESSION_LEVEL" | "SENT_EMAIL_ENTER_GRACE_PERIOD_SESSION_LEVEL" | "SENT_EMAIL_ENTER_SUSPENDED_PERIOD_SESSION_LEVEL" | "ANALYTICS_AD_LINKING_RECOMMENDATION_ELIGIBLE_SESSION_LEVEL" | "EDITORIAL_FCC_AT_SESSION_LEVEL" | "FRESH_RESULTS_SEEKING_CURRENT_YEAR_SESSION_LEVEL" | "FILTER_TQ_FAILURE_APP_SESSION_LEVEL" | "EDITORIAL_CONTENT_CLUSTER_FHR_SERP_SESSION_LEVEL" | "HAS_DECLINE_REASON_IN_PAYMENT_DECLINE_EMAIL_SESSION_LEVEL" | "QUEST_CONTENT_CARD_IN_DEALS_HOME_SESSION_LEVEL" | "PGSS_DETAILS_PAGE_TQUALITY_UNKNOWN_SESSION_LEVEL" | "PGSS_DETAILS_PAGE_TQUALITY_FAILED_SESSION_LEVEL" | "PGSS_DETAILS_PAGE_TQUALITY_PASSED_SESSION_LEVEL" | "PGSS_DETAILS_PAGE_AQUALITY_UNKNOWN_SESSION_LEVEL" | "PGSS_DETAILS_PAGE_AQUALITY_FAILED_SESSION_LEVEL" | "PGSS_DETAILS_PAGE_AQUALITY_PASSED_SESSION_LEVEL" | "PRE_INSTALL_LOW_QUALITY_DETAILS_PAGE_SIMILAR_APPS_ABSENT_SESSION_LEVEL" | "PRE_INSTALL_LOW_QUALITY_DETAILS_PAGE_SIMILAR_APPS_PRESENT_SESSION_LEVEL" | "PRE_INSTALL_LOW_QUALITY_DETAILS_PAGE_WITH_GAME_SESSION_LEVEL" | "PRE_INSTALL_LOW_QUALITY_DETAILS_PAGE_WITH_NON_GAME_SESSION_LEVEL" | "QUERY_DEPENDENT_SNIPPET_SESSION_LEVEL" | "FOP_STEERING_PROMOTION_INITIAL_BILLING_PROFILE_SESSION_LEVEL" | "FOP_STEERING_PROMOTION_CART_ADD_FOP_SESSION_LEVEL" | "FOP_STEERING_PROMOTION_CART_CHANGE_FOP_SESSION_LEVEL" | "FOP_STEERING_PROMOTION_CART_APPLY_PROMOTION_SESSION_LEVEL" | "PTP_CLUSTER_SERP_P13N_RANKING_SESSION_LEVEL" | "QUERY_DEPENDENT_SNIPPET_FRONT_END_SESSION_LEVEL" | "SUBS_HIGH_CHURN_FOP_OPTIONS_AVAILABLE_SESSION_LEVEL" | "SUBS_HIGH_CHURN_FOP_OPTIONS_AVAILABLE_SESSION_LEVEL_V2" | "SUBS_HIGH_CHURN_FOP_OPTIONS_AVAILABLE_WITH_EXISTING_FOP_SESSION_LEVEL" | "SUBS_HIGH_CHURN_FOP_OPTIONS_AVAILABLE_WITHOUT_EXISTING_FOP_SESSION_LEVEL" | "MDP_WITHOUT_QUALITY_SESSION_LEVEL" | "MDP_WITH_HIGH_QUALITY_SESSION_LEVEL" | "MDP_WITH_MEDIUM_QUALITY_SESSION_LEVEL" | "MDP_WITH_LOW_QUALITY_SESSION_LEVEL" | "MDP_TRIGGERED_AND_GAME_SEEKING_SESSION_LEVEL" | "PLAY_SEARCH_GENERAL_QUERY_MDP_PAGINATION_WITH_GAME_SEEKING_RYF_CLUSTER_SESSION_LEVEL" | "PLAY_SEARCH_GENERAL_QUERY_NON_MDP_PAGINATION_WITH_GAME_SEEKING_RYF_CLUSTER_SESSION_LEVEL" | "BUY_BUTTON_WITH_AUTHENTICATION_DISABLED" | "PSS_GENERAL_PAGINATION_SESSION_LEVEL" | "PSS_GENERAL_PAGINATION_GAME_SEEKING_SESSION_LEVEL" | "INLINE_ADD_PAYMENT_CREDIT_CARD_ELIGIBLE" | "INLINE_ADD_PAYMENT_CARRIER_BILLING_ELIGIBLE" | "INLINE_ADD_PAYMENT_EWALLET_ELIGIBLE" | "INLINE_ADD_PAYMENT_NO_ELIGIBLE_TYPE" | "SHOULD_NOT_SEE_NOW_CONTENT_AH" | "SHOULD_SEE_NOW_CONTENT_AH_K1" | "SHOULD_SEE_NOW_CONTENT_AH_K2" | "SHOULD_SEE_NOW_CONTENT_AH_K3_4" | "SHOULD_SEE_NOW_CONTENT_AH_GTE_K5" | "SHOULD_NOT_SEE_NOW_CONTENT_GH" | "SHOULD_SEE_NOW_CONTENT_GH_K1" | "SHOULD_SEE_NOW_CONTENT_GH_K2" | "SHOULD_SEE_NOW_CONTENT_GH_K3_4" | "SHOULD_SEE_NOW_CONTENT_GH_GTE_K5" | "SHOULD_SEE_NOW_CONTENT_NEW_RELEASE_AH_K1" | "SHOULD_SEE_NOW_CONTENT_NEW_RELEASE_AH_K2" | "SHOULD_SEE_NOW_CONTENT_NEW_RELEASE_AH_K3_4" | "SHOULD_SEE_NOW_CONTENT_NEW_RELEASE_AH_GTE_K5" | "SHOULD_SEE_NOW_CONTENT_NEW_RELEASE_GH_K1" | "SHOULD_SEE_NOW_CONTENT_NEW_RELEASE_GH_K2" | "SHOULD_SEE_NOW_CONTENT_NEW_RELEASE_GH_K3_4" | "SHOULD_SEE_NOW_CONTENT_NEW_RELEASE_GH_GTE_K5" | "SHOULD_SEE_NOW_CONTENT_EDITORIAL_AH_K1" | "SHOULD_SEE_NOW_CONTENT_EDITORIAL_AH_K2" | "SHOULD_SEE_NOW_CONTENT_EDITORIAL_AH_K3_4" | "SHOULD_SEE_NOW_CONTENT_EDITORIAL_AH_GTE_K5" | "SHOULD_SEE_NOW_CONTENT_EDITORIAL_GH_K1" | "SHOULD_SEE_NOW_CONTENT_EDITORIAL_GH_K2" | "SHOULD_SEE_NOW_CONTENT_EDITORIAL_GH_K3_4" | "SHOULD_SEE_NOW_CONTENT_EDITORIAL_GH_GTE_K5" | "SHOULD_SEE_NOW_CONTENT_LIVE_OPS_AH_K1" | "SHOULD_SEE_NOW_CONTENT_LIVE_OPS_AH_K2" | "SHOULD_SEE_NOW_CONTENT_LIVE_OPS_AH_K3_4" | "SHOULD_SEE_NOW_CONTENT_LIVE_OPS_AH_GTE_K5" | "SHOULD_SEE_NOW_CONTENT_LIVE_OPS_GH_K1" | "SHOULD_SEE_NOW_CONTENT_LIVE_OPS_GH_K2" | "SHOULD_SEE_NOW_CONTENT_LIVE_OPS_GH_K3_4" | "SHOULD_SEE_NOW_CONTENT_LIVE_OPS_GH_GTE_K5" | "SHOULD_SEE_NOW_CONTENT_PRE_REGISTRATION_AH_K1" | "SHOULD_SEE_NOW_CONTENT_PRE_REGISTRATION_AH_K2" | "SHOULD_SEE_NOW_CONTENT_PRE_REGISTRATION_AH_K3_4" | "SHOULD_SEE_NOW_CONTENT_PRE_REGISTRATION_AH_GTE_K5" | "SHOULD_SEE_NOW_CONTENT_PRE_REGISTRATION_GH_K1" | "SHOULD_SEE_NOW_CONTENT_PRE_REGISTRATION_GH_K2" | "SHOULD_SEE_NOW_CONTENT_PRE_REGISTRATION_GH_K3_4" | "SHOULD_SEE_NOW_CONTENT_PRE_REGISTRATION_GH_GTE_K5" | "SHOULD_NOT_SEE_TOP_NOW_CONTENT_AH" | "SHOULD_SEE_TOP_NOW_CONTENT_AH_K1" | "SHOULD_SEE_TOP_NOW_CONTENT_AH_K2" | "SHOULD_SEE_TOP_NOW_CONTENT_AH_K3_4" | "SHOULD_SEE_TOP_NOW_CONTENT_AH_GTE_K5" | "SHOULD_NOT_SEE_TOP_NOW_CONTENT_GH" | "SHOULD_SEE_TOP_NOW_CONTENT_GH_K1" | "SHOULD_SEE_TOP_NOW_CONTENT_GH_K2" | "SHOULD_SEE_TOP_NOW_CONTENT_GH_K3_4" | "SHOULD_SEE_TOP_NOW_CONTENT_GH_GTE_K5" | "SHOULD_SEE_TOP_NOW_CONTENT_NEW_RELEASE_AH_K1" | "SHOULD_SEE_TOP_NOW_CONTENT_NEW_RELEASE_AH_K2" | "SHOULD_SEE_TOP_NOW_CONTENT_NEW_RELEASE_AH_K3_4" | "SHOULD_SEE_TOP_NOW_CONTENT_NEW_RELEASE_AH_GTE_K5" | "SHOULD_SEE_TOP_NOW_CONTENT_NEW_RELEASE_GH_K1" | "SHOULD_SEE_TOP_NOW_CONTENT_NEW_RELEASE_GH_K2" | "SHOULD_SEE_TOP_NOW_CONTENT_NEW_RELEASE_GH_K3_4" | "SHOULD_SEE_TOP_NOW_CONTENT_NEW_RELEASE_GH_GTE_K5" | "SHOULD_SEE_TOP_NOW_CONTENT_EDITORIAL_AH_K1" | "SHOULD_SEE_TOP_NOW_CONTENT_EDITORIAL_AH_K2" | "SHOULD_SEE_TOP_NOW_CONTENT_EDITORIAL_AH_K3_4" | "SHOULD_SEE_TOP_NOW_CONTENT_EDITORIAL_AH_GTE_K5" | "SHOULD_SEE_TOP_NOW_CONTENT_EDITORIAL_GH_K1" | "SHOULD_SEE_TOP_NOW_CONTENT_EDITORIAL_GH_K2" | "SHOULD_SEE_TOP_NOW_CONTENT_EDITORIAL_GH_K3_4" | "SHOULD_SEE_TOP_NOW_CONTENT_EDITORIAL_GH_GTE_K5" | "SHOULD_SEE_TOP_NOW_CONTENT_LIVE_OPS_AH_K1" | "SHOULD_SEE_TOP_NOW_CONTENT_LIVE_OPS_AH_K2" | "SHOULD_SEE_TOP_NOW_CONTENT_LIVE_OPS_AH_K3_4" | "SHOULD_SEE_TOP_NOW_CONTENT_LIVE_OPS_AH_GTE_K5" | "SHOULD_SEE_TOP_NOW_CONTENT_LIVE_OPS_GH_K1" | "SHOULD_SEE_TOP_NOW_CONTENT_LIVE_OPS_GH_K2" | "SHOULD_SEE_TOP_NOW_CONTENT_LIVE_OPS_GH_K3_4" | "SHOULD_SEE_TOP_NOW_CONTENT_LIVE_OPS_GH_GTE_K5" | "SHOULD_SEE_TOP_NOW_CONTENT_PRE_REGISTRATION_AH_K1" | "SHOULD_SEE_TOP_NOW_CONTENT_PRE_REGISTRATION_AH_K2" | "SHOULD_SEE_TOP_NOW_CONTENT_PRE_REGISTRATION_AH_K3_4" | "SHOULD_SEE_TOP_NOW_CONTENT_PRE_REGISTRATION_AH_GTE_K5" | "SHOULD_SEE_TOP_NOW_CONTENT_PRE_REGISTRATION_GH_K1" | "SHOULD_SEE_TOP_NOW_CONTENT_PRE_REGISTRATION_GH_K2" | "SHOULD_SEE_TOP_NOW_CONTENT_PRE_REGISTRATION_GH_K3_4" | "SHOULD_SEE_TOP_NOW_CONTENT_PRE_REGISTRATION_GH_GTE_K5" | "SHOULD_SEE_TOP_NOW_CONTENT_MERCH_NEW_RELEASE_AH" | "SHOULD_SEE_TOP_NOW_CONTENT_MERCH_PRE_REGISTRATION_AH" | "SHOULD_SEE_TOP_NOW_CONTENT_MERCH_LIVE_OPS_AH" | "SHOULD_SEE_TOP_NOW_CONTENT_MERCH_NEW_RELEASE_GH" | "SHOULD_SEE_TOP_NOW_CONTENT_MERCH_PRE_REGISTRATION_GH" | "SHOULD_SEE_TOP_NOW_CONTENT_MERCH_LIVE_OPS_GH" | "WALLET_WELLBEING_ALERT_SESSION_LEVEL" | "BROAD_INTENT_REWEIGHTING_SESSION_LEVEL" | "DYNASTY_DEVICE_HANDOFF_SESSION_LEVEL" | "EXPANDED_DEV_SUCCESS_CLUSTER_SESSION_LEVEL" | "COLLAPSED_DEV_SUCCESS_CLUSTER_SESSION_LEVEL" | "TRIGGERED_DEV_SUCCESS_CLUSTER_SESSION_LEVEL" | "PLANOGRAM_MERCH_AMERICAS_GAMES_PAYPAL_SESSION_LEVEL" | "BROAD_INTENT_GAMES_TIMESPENT_SESSION_LEVEL" | "ELIGIBLE_FOR_MANAGE_IN_APP_DETAILS_SESSION_LEVEL" | "ELIGIBLE_FOR_ACC_SESSION_LEVEL" | "ELIGIBLE_FOR_ACQUISITION_ACC_SESSION_LEVEL" | "ELIGIBLE_FOR_REENGAGEMENT_ACC_SESSION_LEVEL" | "MDP_P13N_ALL_SESSION_LEVEL" | "MDP_P13N_GAME_QUERY_L5_SESSION_LEVEL" | "MDP_P13N_GAME_QUERY_L6_SESSION_LEVEL" | "MDP_P13N_GAME_QUERY_L7_SESSION_LEVEL" | "MDP_P13N_GAME_QUERY_L8_SESSION_LEVEL" | "MDP_P13N_GAME_QUERY_L9_SESSION_LEVEL" | "MDP_P13N_RERANKING_UNKNOWN_SESSION_LEVEL" | "MDP_P13N_RERANKING_CATEGORICAL_SESSION_LEVEL" | "MDP_P13N_RERANKING_NAVIGATIONAL_SESSION_LEVEL" | "MDP_P13N_RERANKING_MULTI_NAVIGATIONAL_SESSION_LEVEL" | "MDP_P13N_RERANKING_NAVIGATIONAL_EXT_SESSION_LEVEL" | "YOUTUBE_FROM_LANDING_PAGE_SESSION_LEVEL" | "SECOND_PASS_POLARIS_RERANKING_SESSION_LEVEL" | "SECOND_PASS_POLARIS_WITH_RANKING_CHANGE_SESSION_LEVEL" | "PLAY_BOOKS_READING_PROGRESS_TOOLTIP_SESSION_LEVEL" | "NAV_SEARCH_D2D_EMBEDDING_BOOST_SESSION_LEVEL" | "HAS_NO_BACKUP_FOP_FOR_ORDER_SESSION_LEVEL" | "SECOND_PASS_BROAD_INTENT_QUERY_SESSION_LEVEL" | "SECOND_PASS_REWEIGHTING_TRIGGERED_SESSION_LEVEL" | "BOOKS_SEARCH_PAGE_DORA_QUERY_SESSION_LEVEL" | "INLINE_DETAILS_TQUALITY_CHECK_UNKNOWN_SESSION_LEVEL" | "APPS_LAUNCHER_CLUSTER_AT_SESSION_LEVEL" | "SUPERROOT_PDS_SHORT_DESCRIPTION_SESSION_LEVEL" | "PGSS_SHORT_DESCRIPTION_DIFF_SESSION_LEVEL" | "NAV_ADS_DUPLICATE_SERVED_SESSION_LEVEL" | "NAV_ADS_NON_DUPLICATE_SERVED_SESSION_LEVEL" | "NAV_ADS_NO_AD_SERVED_SESSION_LEVEL" | "PAYMENTS_TOS_ACCEPTANCE_CHALLENGE_SHOWN" | "PAYMENTS_TOS_ACCEPTANCE_CHALLENGE_RESOLVED" | "WEBSKY_SEARCH_THIRD_PARTY_CONTENT_ELIGIBLE_QUERY_SESSION_LEVEL" | "SESSION_LEVEL_TEST_CODE_LIMIT" | "CART_ABANDONMENT_USER_LEVEL" | "IN_APP_PRODUCTS_IN_DETAILS_PAGE_USER_LEVEL" | "BOOKS_DETAILS_PAGE_PROMOTION_USER_LEVEL" | "BURNSIE_ADD_FOP_PROMOTION_USER_LEVEL" | "BOOKS_DETAILS_PAGE_EXISTING_PROMOTION_USER_LEVEL" | "SWOOP_CAMPAIGN_10P_OFF_USER_LEVEL" | "SWOOP_CAMPAIGN_25P_OFF_USER_LEVEL" | "SWOOP_CAMPAIGN_50P_OFF_USER_LEVEL" | "SWOOP_CAMPAIGN_75P_OFF_USER_LEVEL" | "PURCHASABLE_SUBSCRIPTIONS_IN_DETAILS_PAGE_WAVE_2_USER_LEVEL" | "CART_ABANDONMENT_ELIGIBLE_USER_LEVEL" | "APPS_DETAILS_PAGE_PROMOTION_EXP_2_USER_LEVEL" | "APPS_DETAILS_PAGE_EXISTING_PROMOTION_EXP_2_USER_LEVEL" | "APPS_DETAILS_PAGE_PROMOTION_EXP_2_IN_APP_ITEM_NEVERS_USER_LEVEL" | "APPS_PERSONALIZED_TOPIC_QUERY_USER_LEVEL" | "APPS_PERSONALIZED_TG_QUERY_USER_LEVEL" | "APPS_PERSONALIZED_ALL_GAME_QUERIES_USER_LEVEL" | "APPS_PERSONALIZED_CATEGORICAL_GAME_SEEKING_QUERIES_USER_LEVEL" | "APPS_PERSONALIZED_CATEGORICAL_NON_TG_QUERIES_USER_LEVEL" | "SUBSCRIPTION_CANCELLATION_PROMOTION_USER_LEVEL" | "SUBSCRIPTION_UPDATE_FOP_FOR_DCB_AS_PRIMARY_SIGNUP_USER_LEVEL" | "SUBSCRIPTION_UPDATE_FOP_FOR_DCB_AS_PRIMARY_USER_LEVEL" | "SUBSCRIPTION_RETRY_FOP_FOR_DCB_AS_PRIMARY_USER_LEVEL" | "SUBSCRIPTION_DCB_AS_ADD_FOP_OPTION_USER_LEVEL" | "PURCHASABLE_SUBSCRIPTIONS_IN_DETAILS_PAGE_APP_1_AT_USER_LEVEL" | "PURCHASABLE_SUBSCRIPTIONS_IN_DETAILS_PAGE_APP_3_AT_USER_LEVEL" | "DETAILS_PAGE_PROMOTION_HOLDBACK_USER_LEVEL" | "LB_TARGETED_AT_USER_LEVEL" | "LB_IMPRESSED_AT_USER_LEVEL" | "MOVIES_USER_INTERESTS_NONE_AT_USER_LEVEL" | "MOVIES_USER_INTERESTS_LOW_AT_USER_LEVEL" | "MOVIES_USER_INTERESTS_MEDIUM_AT_USER_LEVEL" | "MOVIES_USER_INTERESTS_HIGH_AT_USER_LEVEL" | "MOVIES_BOY_SEEDS_NONE_AT_USER_LEVEL" | "MOVIES_BOY_SEEDS_LOW_AT_USER_LEVEL" | "MOVIES_BOY_SEEDS_MEDIUM_AT_USER_LEVEL" | "MOVIES_BOY_SEEDS_HIGH_AT_USER_LEVEL" | "PLAY_PASS_SIGNUP_INTERSTITIAL_ELIGIBLE_USER_LEVEL" | "PLAY_PASS_SIGNUP_INTERSTITIAL_TARGETED_USER_LEVEL" | "PLAY_PASS_IPD_ELIGIBLE_USER_LEVEL" | "PLAY_PASS_FHR_ELIGIBLE_USER_LEVEL" | "LOYALTY_UPSELL_AFTER_IN_APP_PURCHASE_AT_USER_LEVEL" | "PROMOTION_BANNER_ELIGIBLE_USER_LEVEL" | "LOYALTY_SEES_POINTS_EARN_PROMOTIONS_AT_USER_LEVEL" | "LOYALTY_SEES_FREE_TRIAL_SUBSCRIPTION_AT_USER_LEVEL" | "LOYALTY_SIGNUP_INTERSTITIAL_AT_USER_LEVEL" | "PLAY_SUBMANAGEMENT_LOG_HOOK_USER_EXAMPLE" | "NEW_USER_FOP_PROMOTION_SEEN" | "LOYALTY_UPSELL_SEEN_AT_USER_LEVEL" | "LOYALTY_ELIGIBLE_TO_SEE_UPSELL_AT_USER_LEVEL" | "LOYALTY_LIVE_OPS_RETURNED_AT_USER_LEVEL" | "PROMOLINK_CDP_USER_LEVEL" | "PROMOLINK_CDP_TITLE_PAGE_USER_LEVEL" | "PROMOLINK_CDP_TOPIC_PAGE_USER_LEVEL" | "PROMOLINK_CDP_GENERIC_PAGE_USER_LEVEL" | "POINTS_PROMOTION_CONTENT_PAGE_AT_USER_LEVEL" | "IN_APP_OFFER_AT_USER_LEVEL" | "IN_APP_OFFER_APP_1_AT_USER_LEVEL" | "IN_APP_OFFER_APP_2_AT_USER_LEVEL" | "IN_APP_OFFER_APP_3_AT_USER_LEVEL" | "IN_APP_OFFER_APP_4_AT_USER_LEVEL" | "IN_APP_OFFER_ELIGIBLE_AT_USER_LEVEL" | "IN_APP_OFFER_ELIGIBLE_APP_1_AT_USER_LEVEL" | "IN_APP_OFFER_ELIGIBLE_APP_2_AT_USER_LEVEL" | "IN_APP_OFFER_ELIGIBLE_APP_3_AT_USER_LEVEL" | "IN_APP_OFFER_ELIGIBLE_APP_4_AT_USER_LEVEL" | "IN_APP_OFFER_SAVED_AT_USER_LEVEL" | "IN_APP_OFFER_SAVED_APP_1_AT_USER_LEVEL" | "IN_APP_OFFER_SAVED_APP_2_AT_USER_LEVEL" | "IN_APP_OFFER_SAVED_APP_3_AT_USER_LEVEL" | "IN_APP_OFFER_SAVED_APP_4_AT_USER_LEVEL" | "SHOULD_SEE_FIRST_PARTY_PROMO_LIVE_OP_ON_SERP_MDP_USER_LEVEL" | "SHOULD_SEE_FIRST_PARTY_PROMO_LIVE_OP_ON_APP_DP_USER_LEVEL" | "CART_ABANDONMENT_SUBSCRIPTION_ONE_TIME_PASS_USER_LEVEL" | "GOOGLE_PROMOTIONS_ELIGIBLE_USER_LEVEL" | "USER_TRIGGERED_IAP_PROMOTION_RETRIEVAL_USER_LEVEL" | "LOYALTY_IAP_UPSELL_USER_LEVEL" | "IAP_HAS_UNREDEEMED_PROMOTIONS_CLIENT_USER_LEVEL" | "PLAY_STORE_IAP_SALES_USER_LEVEL" | "PLAY_STORE_IAP_SALES_APP_1_USER_LEVEL" | "PLAY_STORE_IAP_SALES_MINI_DETAILS_PAGE_USER_LEVEL" | "PLAY_GROWTH_IS_SCHEDULED" | "GEARHEAD_VISUAL_PREVIEW_UNCHAINED_ELIGIBLE" | "POST_PURCHASE_ITEM_UPSELL_USER_LEVEL" | "PLAY_PASS_SIGNUP_INTERSTITIAL_SHOWN_USER_LEVEL" | "DISABLE_TOPUP_EXPERIMENT_CONTROL_GROUP_USER_LEVEL" | "DISABLE_TOPUP_EXPERIMENT_TREATMENT_GROUP_USER_LEVEL" | "AVP_SWOOP_CAMPAIGN_10P_OFF_USER_LEVEL" | "AVP_SWOOP_CAMPAIGN_25P_OFF_USER_LEVEL" | "AVP_SWOOP_CAMPAIGN_50P_OFF_USER_LEVEL" | "AVP_SWOOP_CAMPAIGN_75P_OFF_USER_LEVEL" | "CDP_ENABLE_PREFETCH_USER_LEVEL" | "P13N_INTERSTITIAL_USER_LEVEL" | "PLAY_EVENT_SERVICE_LOG_HOOK_USER_EXAMPLE" | "FEATURED_SUBSCRIPTIONS_PRESENT_USER_LEVEL" | "USE_SUBSCRIPTION_NEW_DOCUMENT_FORMAT_USER_LEVEL" | "USE_SUBSCRIPTION_NEW_DOCUMENT_FORMAT_PREVIEW_BATCH_USER_LEVEL" | "USE_SUBSCRIPTION_NEW_DOCUMENT_FORMAT_SKU_DETAILS_USER_LEVEL" | "USE_SUBSCRIPTION_NEW_DOCUMENT_FORMAT_PREVIEW_BATCH_SKU_DETAILS_USER_LEVEL" | "USE_SUBSCRIPTION_NEW_DOCUMENT_FORMAT_FOR_ALL_SUBS_USER_LEVEL" | "LEON_LIVEOPS_DEAL_STATE_SYNC_USER_LEVEL" | "SURVEY_AHC_AT_USER_LEVEL" | "PLAY_PASS_CART_MAREKTING_BANNER_ELIGIBLE_AND_SHOWN_CART_USER_LEVEL" | "PLAY_PASS_PERKS_VOUCHER_IN_CART_USER_LEVEL" | "PLAY_PASS_PARENT_FOCUSED_SPLASH_PAGE_USER_LEVEL" | "PLAY_PASS_SPLASH_PAGE_FOR_UNICORN_USER_LEVEL" | "IN_CART_EXCHANGE_OPTIONS_ELIGIBLE_USER_LEVEL" | "GE_USER_BUYER_STATE_UNKNOWN" | "GE_USER_BUYER_STATE_NEVER" | "GE_USER_BUYER_STATE_NEW" | "GE_USER_BUYER_STATE_CHURN" | "GE_USER_BUYER_STATE_REPEAT" | "GE_USER_VALUE_SEGMENT_UNKNOWN" | "GE_USER_VALUE_SEGMENT_LOW" | "GE_USER_VALUE_SEGMENT_MEDIUM" | "GE_USER_VALUE_SEGMENT_HIGH" | "GE_USER_VALUE_SEGMENT_NEVER" | "GE_IS_SCHEDULED_UNKNOWN_SURFACE" | "GE_IS_SCHEDULED_LEON" | "GE_IS_SCHEDULED_NOTIFICATION" | "GE_IS_SCHEDULED_CART_ABANDONMENT" | "GE_IS_SCHEDULED_SWOOP" | "GE_IS_SCHEDULED_LIVE_OP" | "GE_IS_SCHEDULED_REDEEM_SAVE" | "GE_IS_SCHEDULED_APP_HERO_CARD" | "GE_IS_SCHEDULED_POINTS_BOOSTER" | "GE_IS_SCHEDULED_INTERSTITIAL" | "GE_IS_SCHEDULED_COFFEE_CARD" | "GE_IS_SCHEDULED_QUEST" | "GE_IS_SCHEDULED_LOYALTY_MULTIPLIER" | "IAP_SKU_DEALS_LIVE_OP_DEALS_HOME_USER_LEVEL" | "IAP_SKU_DEALS_LIVE_OP_GAMES_HOME_USER_LEVEL" | "FEATURING_AHC_OR_FHR_TRIGGERED_USER_LEVEL" | "ALLOWLIST_EXPANSION_FOR_P13N_INTERSTITIAL_USER_LEVEL" | "SURVEY_RECS_LIST_AT_USER_LEVEL" | "DEV_OFFER_SWGOH_USER_LEVEL" | "ALLOWLIST_EXPANSION_FOR_P13N_NOTIFICATIONS_USER_LEVEL" | "GROWTH_COFFEE_CARD_IN_PURCHASE_FLOW_USER_LEVEL" | "GROWTH_COFFEE_CARD_IN_PURCHASE_FLOW_SERVER_USER_LEVEL" | "GROWTH_CORPUS_WIDE_STAMP_CARD_PURCHASE_FLOW_CLIENT_USER_LEVEL" | "GROWTH_CORPUS_WIDE_STAMP_CARD_PURCHASE_FLOW_SERVER_USER_LEVEL" | "GROWTH_CORPUS_WIDE_STAMP_CARD_GAMES_HOME_USER_LEVEL" | "LOYALTY_PURCHASE_QUEST_GAMES_HOME_USER_LEVEL" | "GROWTH_CORPUS_WIDE_STAMP_CARD_GAMES_HOME_SERVER_USER_LEVEL" | "LOYALTY_PURCHASE_QUEST_GAMES_HOME_SERVER_USER_LEVEL" | "SUBS_HIGH_CHURN_FOP_OPTIONS_AVAILABLE_USER_LEVEL" | "SUBS_HIGH_CHURN_FOP_OPTIONS_AVAILABLE_USER_LEVEL_V2" | "SUBS_HIGH_CHURN_FOP_OPTIONS_AVAILABLE_WITH_EXISTING_FOP_USER_LEVEL" | "SUBS_HIGH_CHURN_FOP_OPTIONS_AVAILABLE_WITHOUT_EXISTING_FOP_USER_LEVEL" | "WIDE_MEDIA_CLUSTER_INVALID_VIDEO_ASSET_USER_LEVEL" | "WEBSKY_SEARCH_THIRD_PARTY_CONTENT_ELIGIBLE_QUERY_USER_LEVEL" | "EDITORIAL_FCC_AT_USER_LEVEL" | "QUEST_CONTENT_CARD_IN_DEALS_HOME_USER_LEVEL" | "FOP_STEERING_PROMOTION_INITIAL_BILLING_PROFILE_USER_LEVEL_V2" | "FOP_STEERING_PROMOTION_CART_ADD_FOP_USER_LEVEL_V2" | "FOP_STEERING_PROMOTION_CART_CHANGE_FOP_USER_LEVEL_V2" | "FOP_STEERING_PROMOTION_CART_APPLY_PROMOTION_USER_LEVEL_V2" | "FOP_STEERING_PROMOTION_USER_LEVEL" | "LOYALTY_STAMP_CARD_IN_PURCHASE_FLOW_USER_LEVEL" | "HAS_MONETIZATION_BEHAVIOR_USER_LEVEL" | "HAS_MONETIZATION_BEHAVIOR_LAST_180D_USER_LEVEL" | "HAS_LAST_28D_CART_ABANDONMENT_USER_LEVEL" | "HAS_LAST_7D_CART_ABANDONMENT_USER_LEVEL" | "POST_SUCCESS_ADD_BACKUP_FLOW_USER_LEVEL" | "SKIP_CHECK_MARK_SCREEN_WITH_BACKUP_FLOW_USER_LEVEL" | "IS_ELIGIBLE_FOR_ONE_CLICK_BACKUP_FOP_USER_LEVEL" | "LOYALTY_STAMP_CARD_IN_PURCHASE_FLOW_SERVER_USER_LEVEL" | "ELIGIBLE_FOR_MANAGE_IN_APP_DETAILS_USER_LEVEL" | "PLAY_ONBOARDING_QUEST_GAMES_HOME_USER_LEVEL" | "SERVED_GPP_ONBOARDING_QUEST_USER_LEVEL" | "PLAY_ONBOARDING_QUEST_GAMES_HOME_SERVER_USER_LEVEL" | "PCH_O2_WITH_CRE_USER_LEVEL" | "MERCH_USER_JOURNEY_SPEND_USER_LEVEL" | "MERCH_USER_JOURNEY_PUBG_NPU" | "MERCH_USER_JOURNEY_PUBG_REPEAT_SPEND" | "PLAY_GAMES_ACHIEVEMENT_LOYALTY_QUEST_USER_LEVEL" | "PLAY_BOOKS_READING_PROGRESS_TOOLTIP_USER_LEVEL" | "IAP_SKU_DEALS_LIVE_OP_GAMES_HOME_USER_LEVEL1" | "POST_PURCHASE_OFFER_POST_PURCHASE_CONFIRMATION_DIALOG_SERVER_USER_LEVEL" | "POST_PURCHASE_OFFER_POST_PURCHASE_OFFER_SAVED_DIALOG_SERVER_USER_LEVEL" | "POST_PURCHASE_OFFER_VALUE_PROMOTION_DIALOG_SHOWN_SERVER_USER_LEVEL" | "MDP_P13N_RERANKING_UNKNOWN_USER_LEVEL" | "MDP_P13N_RERANKING_CATEGORICAL_USER_LEVEL" | "MDP_P13N_RERANKING_NAVIGATIONAL_USER_LEVEL" | "MDP_P13N_RERANKING_MULTI_NAVIGATIONAL_USER_LEVEL" | "MDP_P13N_RERANKING_NAVIGATIONAL_EXT_USER_LEVEL" | "PLAY_ONBOARDING_QUEST_PLATFORM_SERVING_USER_LEVEL" | "APPS_LAUNCHER_CLUSTER_AT_USER_LEVEL" | "TRIGGERED_DEV_SUCCESS_CLUSTER_USER_LEVEL" | "PREPERIOD_PAGE_VISIT_28D_FREQUENCY_INVALID_USER_LEVEL_V2" | "PREPERIOD_PAGE_VISIT_28D_FREQUENCY_0_USER_LEVEL_V2" | "PREPERIOD_PAGE_VISIT_28D_FREQUENCY_1_USER_LEVEL_V2" | "PREPERIOD_PAGE_VISIT_28D_FREQUENCY_2_USER_LEVEL_V2" | "PREPERIOD_PAGE_VISIT_28D_FREQUENCY_3_USER_LEVEL_V2" | "PREPERIOD_PAGE_VISIT_28D_FREQUENCY_4_USER_LEVEL_V2" | "PREPERIOD_PAGE_VISIT_28D_FREQUENCY_5_USER_LEVEL_V2" | "PREPERIOD_PAGE_VISIT_28D_FREQUENCY_6_USER_LEVEL_V2" | "PREPERIOD_PAGE_VISIT_28D_FREQUENCY_7_USER_LEVEL_V2" | "PREPERIOD_PAGE_VISIT_28D_FREQUENCY_8_USER_LEVEL_V2" | "PREPERIOD_PAGE_VISIT_28D_FREQUENCY_9_USER_LEVEL_V2" | "PREPERIOD_PAGE_VISIT_28D_FREQUENCY_10_USER_LEVEL_V2" | "PREPERIOD_PAGE_VISIT_28D_FREQUENCY_11_USER_LEVEL_V2" | "PREPERIOD_PAGE_VISIT_28D_FREQUENCY_12_USER_LEVEL_V2" | "PREPERIOD_PAGE_VISIT_28D_FREQUENCY_13_USER_LEVEL_V2" | "PREPERIOD_PAGE_VISIT_28D_FREQUENCY_14_USER_LEVEL_V2" | "PREPERIOD_PAGE_VISIT_28D_FREQUENCY_15_USER_LEVEL_V2" | "PREPERIOD_PAGE_VISIT_28D_FREQUENCY_16_USER_LEVEL_V2" | "PREPERIOD_PAGE_VISIT_28D_FREQUENCY_17_USER_LEVEL_V2" | "PREPERIOD_PAGE_VISIT_28D_FREQUENCY_18_USER_LEVEL_V2" | "PREPERIOD_PAGE_VISIT_28D_FREQUENCY_19_USER_LEVEL_V2" | "PREPERIOD_PAGE_VISIT_28D_FREQUENCY_20_USER_LEVEL_V2" | "PREPERIOD_PAGE_VISIT_28D_FREQUENCY_21_USER_LEVEL_V2" | "PREPERIOD_PAGE_VISIT_28D_FREQUENCY_22_USER_LEVEL_V2" | "PREPERIOD_PAGE_VISIT_28D_FREQUENCY_23_USER_LEVEL_V2" | "PREPERIOD_PAGE_VISIT_28D_FREQUENCY_24_USER_LEVEL_V2" | "PREPERIOD_PAGE_VISIT_28D_FREQUENCY_25_USER_LEVEL_V2" | "PREPERIOD_PAGE_VISIT_28D_FREQUENCY_26_USER_LEVEL_V2" | "PREPERIOD_PAGE_VISIT_28D_FREQUENCY_27_USER_LEVEL_V2" | "PREPERIOD_PAGE_VISIT_28D_FREQUENCY_28_USER_LEVEL_V2" | "HAS_REINSTALL_APP_PASSING_FILTERING_USER_LEVEL" | "USER_LEVEL_TEST_CODE_LIMIT"[];
  /**
   * The list of trusted genome hierarchy. One trusted_genome_hierarchy may
   * contain one or multiple entities. This is required for TG 2.0 tags.
   */
  trustedGenomeHierarchy?: VendingConsumerProtoTrustedGenomeHierarchy[];
}

/**
 * Proto message containing the id, localized title, score, and hierarchy level
 * of a trusted genome entity. Next ID: 10
 */
export interface VendingConsumerProtoTrustedGenomeEntity {
  /**
   * The category id matching this trusted genome entity. e.g. Action tag with
   * id /m/025zzc matches category of id GAME_ACTION
   */
  categoryId?: string;
  /**
   * The identifier of a play trusted genome entity. Required.
   */
  id?: string;
  /**
   * The level of the entity. E.g. in hierarchy like Action -> Platformer >
   * Endless Runner. Action is level 1, Platformer is level 2 and Endless Runner
   * is level 3. Currently, only APP_TAXONOMY and GAME_TAXONOMY type may have
   * the levels. For entity that does not have hierarchy, its level is 1.
   * Required.
   */
  level?: number;
  /**
   * The name of the relation between the app and the entity. Required.
   */
  predicateName?: string;
  /**
   * The localized query string for this trusted genome entity. This query will
   * be used when we want to bring users to SERP on click.
   */
  queryText?: string;
  /**
   * The confidence score of the entity to the app.
   */
  score?: number;
  /**
   * The localized title. Required.
   */
  title?: string;
  /**
   * This boolean is used to decide whether this entity will be shown on
   * user-facing features in the Store or not.
   */
  userVisible?: boolean;
}

/**
 * Proto message containing one or multiple trusted genome entity. This is used
 * to capture entities that belong to the same type and have parent-children
 * relationship in the taxonomy. e.g. One hierarchy may include 3 entities with
 * Game_Taxonomy Type: (1) Action (Level 1) (2) Platformer (Level 2 under
 * Action) (3) Endless Runner (Level 3 under Platformer) e.g. One hierarchy may
 * also include only 1 entity with Game_Graphic_Style: (1) Anime (No level
 * information) Next ID: 5
 */
export interface VendingConsumerProtoTrustedGenomeHierarchy {
  /**
   * List of entities (one or multiple) that belong in the same hierarchy. The
   * entries will be ordered such that the first entry will be of level 1, and
   * the second entry will be of level 2, and so on. Required
   */
  entity?: VendingConsumerProtoTrustedGenomeEntity[];
  /**
   * The (hierarchy-level) type of this Trusted Genome hierarchy. Will only be
   * populated when meeting certain criteria, e.g. 'GD2_Game_Main' means this
   * hierarchy of entities can serve as the main game genre for Game Discovery
   * 2.0.
   */
  hierarchyType?:  | "UNKNOWN_HIERARCHY_TYPE" | "GD2_GAME_MAIN" | "GD2_GAME_SUB";
  /**
   * The source of this Trusted Genome hierarchy.
   */
  source?:  | "UNKNOWN_TRUSTED_GENOME_SOURCE" | "TRUSTED_GENOME_2" | "VALIDATED_DEVELOPER" | "DEVELOPER_PROVIDED";
  /**
   * The (entity-level) type of trusted genome entities in this hierarchy.
   * Required.
   */
  trustedGenomeType?:  | "UNKNOWN_ENTITY_TYPE" | "APP_TAXONOMY" | "APP_ATTRIBUTE" | "GAME_TAXONOMY" | "GAMEPLAY_ELEMENT" | "GAMEPLAY_MODE" | "GAME_GRAPHIC_STYLE" | "GAME_THEME_SETTING" | "GAME_CONNECTIVITY" | "GAME_DIMENSIONAL_PLANES" | "GAME_MONETIZATION" | "ACCESSIBLITY" | "ASSISTANT" | "CHROMEBOOK_COMPATIBILITY";
}

/**
 * Proto message containing policy related information.
 */
export interface VendingConsumerProtoTrustedGenomePolicy {
  /**
   * Override text for region for special treatment. Override will be used in
   * special cases for example regions are too long to show in UI, the override
   * will be "CA/NV/..." to cut it short. By keeping a region override string
   * we'll have more flexibility to adjust what we show on UI. Optional.
   */
  localizedRegionOverride?: string;
  /**
   * Policy type. e.g. Government Endorsed, Apollo Required.
   */
  policyType?:  | "UNKNOWN_POLICY_TYPE" | "GOVERNMENT_COMMISSIONED" | "APOLLO_APPROVED" | "APOLLO_EXPRESS"[];
  /**
   * Contains target region for the current policy. Optional
   */
  targetRegion?: VendingConsumerProtoTrustedGenomePolicyTargetRegion[];
}

export interface VendingConsumerProtoTrustedGenomePolicyTargetRegion {
  /**
   * Localized name for targeted regions. e.g. San Francisco Bay Area Required.
   */
  localizedRegion?: string;
  /**
   * Associated KG entity mid for region. e.g. /m/06pvr
   */
  mid?: string;
}

export interface VideoAmbisonicsAmbisonicsMetadata {
  /**
   * Maps channel indexes of an audio stream to indexes corresponding to the
   * specified ambisonics channel ordering scheme. For example: A 1st order
   * pheriphonic ambisonics format is configured with 4 audio channels
   * corresponding to ambisonic components W, X, Y, Z respectively. The
   * channel_ordering scheme is specified as CHANNEL_ORDERING_ACN (which implies
   * a W, Y, Z, X ordering). Therefore the channel_map is [0, 3, 1, 2].
   */
  channelMap?: number[];
  channelOrdering?:  | "CHANNEL_ORDERING_UNKNOWN" | "CHANNEL_ORDERING_ACN";
  nonDiegeticStereo?: boolean;
  normalization?:  | "NORMALIZATION_UNKNOWN" | "NORMALIZATION_SN3D";
  numChannels?: number;
  order?: number;
  type?:  | "TYPE_UNKNOWN" | "TYPE_PERIPHONIC" | "TYPE_HORIZONTAL";
  version?: number;
}

/**
 * Valid fields in ACL are "mdb/groupname", or "user/username", e.g.,
 * "mdb/youtube-prod", or "user/alice".
 */
export interface VideoAssetsVenomACL {
  /**
   * REQUIRED: the current owner of this video. Please note that owner does not
   * get implicit reader/writer access. You must set them explicitly.
   */
  owner?: string;
  /**
   * Allowed readers of this video.
   */
  reader?: string[];
  /**
   * Allowed writers of this video.
   */
  writer?: string[];
}

/**
 * Describes ingredient level settings. Clients are authoritative in defining
 * Settings. See go/venom-trustme for how Settings and ProcessingCharacteristics
 * work together. If your Settings extension contains PII fields, please 1)
 * Annotate them appropriately with DataPol, and 2) Add your BUILD target to
 * google3/video/assets/venom/proto/settings/BUILD:pii See
 * google3/video/assets/venom/proto/settings/ for extension messages.
 */
export interface VideoAssetsVenomSettings {
}

/**
 * As video mutations are reconciled by Venom, we can tell if the ingredient
 * did or did not reach certain objectives. When processing has completed, all
 * objectives will have a corresponding transition. All transitions are reset
 * for every mutation, but will take into account assets outside of that
 * mutation. For example, if Asset X fails, and was part of
 * "OBJECTIVE_PRIMARY_ASSETS_DONE", a rerun of Asset Y is destined to result in
 * OUTCOME_FAILED, regardless of the fate of Asset Y. Some phenonema have
 * effects on most or all Objectives. For example, a bad input file will result
 * on OUTCOME_INFEASIBLE across the board (eventually, for now it's just GO_LIVE
 * and DO_ALL, work in progress), and a failure to produce Format 18 will cause
 * OUTCOME_FAILED across most Objectives.
 */
export interface VideoAssetsVenomTransition {
  /**
   * The objective this transition is about. REQUIRED.
   */
  objective?:  | "OBJECTIVE_UNKNOWN" | "OBJECTIVE_INGREDIENT_DO_ALL" | "OBJECTIVE_INGREDIENT_GO_LIVE" | "OBJECTIVE_INGREDIENT_VALIDATED" | "OBJECTIVE_PRIMARY_ASSETS_DONE" | "OBJECTIVE_PREVIEW_DONE" | "OBJECTIVE_TRANSMUXED_DONE" | "OBJECTIVE_MEDIA_INFO_DONE" | "OBJECTIVE_PRIMARY_720P_TRANSCODES_DONE" | "OBJECTIVE_PRIMARY_1080P_TRANSCODES_DONE" | "OBJECTIVE_PRIMARY_2K_TRANSCODES_DONE" | "OBJECTIVE_PRIMARY_4K_TRANSCODES_DONE" | "OBJECTIVE_PRIMARY_8K_TRANSCODES_DONE" | "OBJECTIVE_FINGERPRINTS_DONE" | "OBJECTIVE_CHECKSUMS_DONE" | "OBJECTIVE_CLAIM_DONE" | "OBJECTIVE_THUMBNAILS_DONE" | "OBJECTIVE_LIVE_STITCHABLE_ASSETS_DONE" | "OBJECTIVE_CRAWL_ASSETS_DONE" | "OBJECTIVE_VITAL_ASSETS_DONE" | "OBJECTIVE_SAM_FEATURES_DONE" | "OBJECTIVE_SPEECH_RECOGNITION_DONE" | "OBJECTIVE_MULTI_TRACK_AUDIO_DONE";
  /**
   * Whether the objective is reached or not. REQUIRED.
   */
  outcome?:  | "OUTCOME_UNKNOWN" | "OUTCOME_SUCCESS" | "OUTCOME_FAILED" | "OUTCOME_INFEASIBLE" | "OUTCOME_NOT_REQUESTED" | "OUTCOME_PENDING";
  /**
   * An optional debug string indicating the reason for this transition. This
   * is typically omitted for OUTCOME_SUCCESS. e.g. "The video's content is
   * invalid due to failed blobstore cloning."
   */
  reason?: string;
}

/**
 * A VideoId is the unique identifier of a video. Privacy: VideoIds are visible
 * in logs, notifications, etc and must not contain PII.
 */
export interface VideoAssetsVenomVideoId {
  /**
   * REQUIRED. IDs have some constraints: - 32 bytes max: this is enforced by
   * the server - for the time being, must be parseable as a youtube ID
   * (basically a base64-encoded string which maps to a 64-bit integer). This
   * restriction will eventually be lifted.
   */
  id?: Uint8Array;
  /**
   * LINT.ThenChange(
   * //depot/google3/googledata/production/playbooks/video-assets/clients.md,
   * //depot/google3/video/assets/venom/proto/namespace.proto ) REQUIRED.
   */
  ns?:  | "NS_UNKNOWN" | "NS_YOUTUBE" | "NS_YOUTUBE_MEDIA" | "NS_KIDS_HUB" | "NS_GMAIL" | "NS_YOUTUBE_DIRECTOR" | "NS_DCLK_VIDEO_ADS" | "NS_TESTING" | "NS_HVC_INGESTION" | "NS_DRIVE" | "NS_ASK_QNA" | "NS_LOCAL_VIDEO" | "NS_PLAY_AUDIOBOOKS" | "NS_HANGOUTS_CHAT" | "NS_VIDEO_INTEREST_FEED" | "NS_RECORDER" | "NS_STAMP" | "NS_CRAWL" | "NS_PHOTOS" | "NS_MATERIAL_GALLERY" | "NS_YT_REFERENCE" | "NS_LENSLETS_VIDEOS" | "NS_BLOGGER" | "NS_OCEAN" | "NS_OCEAN_DEV" | "NS_ADORA" | "NS_WEB_VIDEO_ADS" | "NS_STUDIO" | "NS_YT_TDSD_REFERENCE" | "NS_WEB_STORY" | "NS_NEST_CAMERA_CLOUD" | "NS_AREA120_BLUEBIRD" | "NS_ARTS_AND_CULTURE" | "NS_DAI_PODCAST" | "NS_DEMO" | "NS_KARTO" | "NS_CONTRIB_SERVICE_SHARED" | "NS_CONTRIB_SERVICE_GEO_UGC" | "NS_SEARCH_SPORTS" | "NS_BUSINESSMESSAGING";
}

function serializeVideoAssetsVenomVideoId(data: any): VideoAssetsVenomVideoId {
  return {
    ...data,
    id: data["id"] !== undefined ? encodeBase64(data["id"]) : undefined,
  };
}

function deserializeVideoAssetsVenomVideoId(data: any): VideoAssetsVenomVideoId {
  return {
    ...data,
    id: data["id"] !== undefined ? decodeBase64(data["id"] as string) : undefined,
  };
}

/**
 * Next tag: 10
 */
export interface VideoAudioStream {
  /**
   * Audio bitrate in bits/s.
   */
  bitrate?: bigint;
  /**
   * Number of audio channels.
   */
  channels?: number;
  /**
   * Audio codec ID. Uses the numeric value corresponding to the CodecId enum
   * object, in order to avoid the dependency on vsi/videostreaminfo.proto.
   * http://cs/symbol:CodecId%20f:google3/video/vidproc/vsi/videostreaminfo.proto
   */
  codecId?: number;
  /**
   * Content type of the stream. Only populated with valid "acont" xtag values
   * at the moment. Supported acont xtag values can be found in
   * google3/video/storage/common/xtag_validation.cc. Examples: "original",
   * "dubbed", "descriptive", "commentary", etc.
   */
  contentType?: string;
  /**
   * Language, examples: "eng", "en", "enG", etc.
   */
  language?: string;
  /**
   * Audio length, in seconds. This value is derived from metadata in the
   * source video, and often differs from the actual duration of any given
   * transcode. In videos without valid timestamps, this value is not
   * calculable, and is reported as zero.
   */
  lengthSec?: number;
  loudness1770Lkfs?: number;
  /**
   * Audio sample rate.
   */
  sampleRate?: bigint;
  /**
   * Index of the stream in the file, 0-based.
   */
  streamIndex?: bigint;
}

function serializeVideoAudioStream(data: any): VideoAudioStream {
  return {
    ...data,
    bitrate: data["bitrate"] !== undefined ? String(data["bitrate"]) : undefined,
    sampleRate: data["sampleRate"] !== undefined ? String(data["sampleRate"]) : undefined,
    streamIndex: data["streamIndex"] !== undefined ? String(data["streamIndex"]) : undefined,
  };
}

function deserializeVideoAudioStream(data: any): VideoAudioStream {
  return {
    ...data,
    bitrate: data["bitrate"] !== undefined ? BigInt(data["bitrate"]) : undefined,
    sampleRate: data["sampleRate"] !== undefined ? BigInt(data["sampleRate"]) : undefined,
    streamIndex: data["streamIndex"] !== undefined ? BigInt(data["streamIndex"]) : undefined,
  };
}

/**
 * Generic clip information contains a key string and a value string.
 */
export interface VideoClipInfo {
  key?: Uint8Array;
  value?: Uint8Array;
}

function serializeVideoClipInfo(data: any): VideoClipInfo {
  return {
    ...data,
    key: data["key"] !== undefined ? encodeBase64(data["key"]) : undefined,
    value: data["value"] !== undefined ? encodeBase64(data["value"]) : undefined,
  };
}

function deserializeVideoClipInfo(data: any): VideoClipInfo {
  return {
    ...data,
    key: data["key"] !== undefined ? decodeBase64(data["key"] as string) : undefined,
    value: data["value"] !== undefined ? decodeBase64(data["value"] as string) : undefined,
  };
}

export interface VideoClosedCaptions {
  videoHasClosedCaptions?: boolean;
}

/**
 * Contains anchor level features that apply to all anchor types. Next id: 18.
 */
export interface VideoContentSearchAnchorCommonFeatureSet {
  /**
   * QBST distance between the anchor and the top navboost query of the video
   * if exists, or the video title otherwise.
   */
  anchorQbstDistance?: number;
  /**
   * Features needed for Bleurt inference.
   */
  bleurtFeatures?: VideoContentSearchBleurtFeatures;
  /**
   * The Bleurt inference score generated using the bleurt_features.
   */
  bleurtScore?: number;
  /**
   * Descartes similarity score between video title and anchor label.
   */
  descartesScoreWithTitle?: number;
  /**
   * The predicted descriptiveness and usefulness rating scores generated by
   * the Unified Dolphin model. Rating template:
   * experimental/video/video_anchors_oneside_without_thumbnail/template.jhtml
   */
  dolphinDescriptivenessScore?: number;
  /**
   * If the dolphin model is an ensemble model, this contains the scores
   * associated to each individual ensemble model.
   */
  dolphinEnsembleScore?: VideoContentSearchDolphinEnsembleScore[];
  /**
   * The features used to generate the Dolphin score.
   */
  dolphinFeatures?: VideoContentSearchDolphinFeatures;
  /**
   * The score generated by the Dolphin callout model.
   */
  dolphinScore?: number;
  dolphinUsefulnessScore?: number;
  /**
   * A phrase embedding for the anchor label. The model used to generate the
   * embedding can be found in VideoAnchorSets:
   * video_score_info.common_features.label_phrase_embedding_model
   */
  labelPhraseEmbedding?: number[];
  /**
   * The predicted descriptiveness of the anchor using the MUM unified scoring
   * model.
   */
  mumDescriptivenessScore?: number;
  /**
   * The predicted usefulness of the anchor using the MUM unified scoring
   * model.
   */
  mumUsefulnessScore?: number;
  /**
   * A score that is correlated with retention probability of the interval
   * associated with this anchor (start time to end time). Retention probability
   * of an interval is 1 - (probability the user does not watch the interval all
   * the way through, given they started watching it). This score may be
   * predicted by a model, or calculated from actual retention data.
   */
  retentionScore?: number;
  /**
   * A saft document generated from the anchor label.
   */
  saftDocument?: NlpSaftDocument;
  /**
   * For annotating labels and their timing and context info. For example, this
   * is used for anchor labels within a passage.
   */
  timedLabelFeatures?: VideoContentSearchCaptionLabelFeatures[];
  timestamp?: VideoContentSearchAnchorCommonFeatureSetLabelSpanTimestamp[];
  /**
   * Babel similarity between the anchor and the video title.
   */
  titleAnchorBabelMatchScore?: number;
}

function serializeVideoContentSearchAnchorCommonFeatureSet(data: any): VideoContentSearchAnchorCommonFeatureSet {
  return {
    ...data,
    dolphinFeatures: data["dolphinFeatures"] !== undefined ? serializeVideoContentSearchDolphinFeatures(data["dolphinFeatures"]) : undefined,
    saftDocument: data["saftDocument"] !== undefined ? serializeNlpSaftDocument(data["saftDocument"]) : undefined,
    timedLabelFeatures: data["timedLabelFeatures"] !== undefined ? data["timedLabelFeatures"].map((item: any) => (serializeVideoContentSearchCaptionLabelFeatures(item))) : undefined,
    timestamp: data["timestamp"] !== undefined ? data["timestamp"].map((item: any) => (serializeVideoContentSearchAnchorCommonFeatureSetLabelSpanTimestamp(item))) : undefined,
  };
}

function deserializeVideoContentSearchAnchorCommonFeatureSet(data: any): VideoContentSearchAnchorCommonFeatureSet {
  return {
    ...data,
    dolphinFeatures: data["dolphinFeatures"] !== undefined ? deserializeVideoContentSearchDolphinFeatures(data["dolphinFeatures"]) : undefined,
    saftDocument: data["saftDocument"] !== undefined ? deserializeNlpSaftDocument(data["saftDocument"]) : undefined,
    timedLabelFeatures: data["timedLabelFeatures"] !== undefined ? data["timedLabelFeatures"].map((item: any) => (deserializeVideoContentSearchCaptionLabelFeatures(item))) : undefined,
    timestamp: data["timestamp"] !== undefined ? data["timestamp"].map((item: any) => (deserializeVideoContentSearchAnchorCommonFeatureSetLabelSpanTimestamp(item))) : undefined,
  };
}

/**
 * When an anchor label has a long duration (for example, labels that contain
 * multiple sentences), this field stores the mapping between label segments and
 * the start time.
 */
export interface VideoContentSearchAnchorCommonFeatureSetLabelSpanTimestamp {
  /**
   * The ASR confidence for the label span, if available.
   */
  asrConfidence?: number;
  /**
   * Whether or not this token is the first token in a sentence.
   */
  isSentenceStart?: boolean;
  /**
   * The character index range for the span. The end index is exclusive.
   */
  labelBeginCharIndex?: bigint;
  labelEndCharIndex?: bigint;
  /**
   * The time of the span.
   */
  timeMs?: bigint;
}

function serializeVideoContentSearchAnchorCommonFeatureSetLabelSpanTimestamp(data: any): VideoContentSearchAnchorCommonFeatureSetLabelSpanTimestamp {
  return {
    ...data,
    labelBeginCharIndex: data["labelBeginCharIndex"] !== undefined ? String(data["labelBeginCharIndex"]) : undefined,
    labelEndCharIndex: data["labelEndCharIndex"] !== undefined ? String(data["labelEndCharIndex"]) : undefined,
    timeMs: data["timeMs"] !== undefined ? String(data["timeMs"]) : undefined,
  };
}

function deserializeVideoContentSearchAnchorCommonFeatureSetLabelSpanTimestamp(data: any): VideoContentSearchAnchorCommonFeatureSetLabelSpanTimestamp {
  return {
    ...data,
    labelBeginCharIndex: data["labelBeginCharIndex"] !== undefined ? BigInt(data["labelBeginCharIndex"]) : undefined,
    labelEndCharIndex: data["labelEndCharIndex"] !== undefined ? BigInt(data["labelEndCharIndex"]) : undefined,
    timeMs: data["timeMs"] !== undefined ? BigInt(data["timeMs"]) : undefined,
  };
}

/**
 * Contains anchor set level features that apply to all anchor types.
 */
export interface VideoContentSearchAnchorsCommonFeatureSet {
  /**
   * A summary of the Dolphin descriptiveness scores of the anchors in the set.
   */
  dolphinDescriptivenessStats?: VideoContentSearchMetricStats;
  /**
   * A summary of the Dolphin usefulness scores of the anchors in the set.
   */
  dolphinUsefulnessStats?: VideoContentSearchMetricStats;
  /**
   * A summary of the MUM descriptiveness scores of the anchors in the set.
   */
  mumDescriptivenessStats?: VideoContentSearchMetricStats;
  /**
   * A summary of the MUM usefulness scores of the anchors in the set.
   */
  mumUsefulnessStats?: VideoContentSearchMetricStats;
}

export interface VideoContentSearchAnchorsThumbnailInfo {
  /**
   * Whether or not any of the anchor thumbnails have missing Starburst
   * embeddings.
   */
  hasMissingStarburst?: boolean;
  /**
   * Whether or not any of the anchors have missing thumbnails.
   */
  hasMissingThumbnails?: boolean;
  /**
   * A score representing how diverse a set of thumbnails is. This is currently
   * defined as one minus the median pairwise cosine similarity between
   * thumbnail Starburst embeddings.
   */
  thumbnailDiversity?: number;
}

/**
 * Properties of the thumbnail image to show for an anchor.
 */
export interface VideoContentSearchAnchorThumbnail {
  /**
   * Serving docid for the thumbnail in the images-tbn tables.
   */
  imagesearchDocid?: bigint;
  /**
   * Set to true when no thumbnail could be generated for this anchor.
   */
  isThumbnailMissing?: boolean;
  /**
   * Metadata about the anchor thumbnail computed by Amarna, including
   * dimensions and the size in bytes.
   */
  servingMetadata?: ImageBaseThumbnailMetadata;
  /**
   * Information about the thumbnail anchor.
   */
  thumbnailInfo?: VideoContentSearchAnchorThumbnailInfo;
  /**
   * Millisecond timestamp of the frame used for the thumbnail.
   */
  timestampMs?: number;
}

function serializeVideoContentSearchAnchorThumbnail(data: any): VideoContentSearchAnchorThumbnail {
  return {
    ...data,
    imagesearchDocid: data["imagesearchDocid"] !== undefined ? String(data["imagesearchDocid"]) : undefined,
    servingMetadata: data["servingMetadata"] !== undefined ? serializeImageBaseThumbnailMetadata(data["servingMetadata"]) : undefined,
    thumbnailInfo: data["thumbnailInfo"] !== undefined ? serializeVideoContentSearchAnchorThumbnailInfo(data["thumbnailInfo"]) : undefined,
  };
}

function deserializeVideoContentSearchAnchorThumbnail(data: any): VideoContentSearchAnchorThumbnail {
  return {
    ...data,
    imagesearchDocid: data["imagesearchDocid"] !== undefined ? BigInt(data["imagesearchDocid"]) : undefined,
    servingMetadata: data["servingMetadata"] !== undefined ? deserializeImageBaseThumbnailMetadata(data["servingMetadata"]) : undefined,
    thumbnailInfo: data["thumbnailInfo"] !== undefined ? deserializeVideoContentSearchAnchorThumbnailInfo(data["thumbnailInfo"]) : undefined,
  };
}

export interface VideoContentSearchAnchorThumbnailInfo {
  /**
   * Entropy of the clustered color distribution.
   */
  colorEntropy?: number;
  /**
   * Thumbnail image data for SafeSearch classification.
   */
  imageData?: ImageData;
  /**
   * Convenience field that consolidates signals for whether this thumbnail is
   * safe.
   */
  isUnsafe?: boolean;
  /**
   * 64d float vector of starburst v4 embedings.
   */
  starburstV4Embedding?: DrishtiDenseFeatureData;
  /**
   * The raw data for a thumbnail.
   */
  thumbnailBytes?: Uint8Array;
}

function serializeVideoContentSearchAnchorThumbnailInfo(data: any): VideoContentSearchAnchorThumbnailInfo {
  return {
    ...data,
    imageData: data["imageData"] !== undefined ? serializeImageData(data["imageData"]) : undefined,
    thumbnailBytes: data["thumbnailBytes"] !== undefined ? encodeBase64(data["thumbnailBytes"]) : undefined,
  };
}

function deserializeVideoContentSearchAnchorThumbnailInfo(data: any): VideoContentSearchAnchorThumbnailInfo {
  return {
    ...data,
    imageData: data["imageData"] !== undefined ? deserializeImageData(data["imageData"]) : undefined,
    thumbnailBytes: data["thumbnailBytes"] !== undefined ? decodeBase64(data["thumbnailBytes"] as string) : undefined,
  };
}

/**
 * Product aspect.
 */
export interface VideoContentSearchAspect {
  /**
   * Product aspect to be used if non of the other aspects exist.
   */
  fallbackAspect?: string;
  /**
   * Product aspect produced by running SAFT annotation.
   */
  saftAspect?: string;
}

/**
 * Contains token-level information about ASR captions.
 */
export interface VideoContentSearchAsrCaption {
  /**
   * The confidence score of the token: between 0 and 1.
   */
  confidence?: number;
  /**
   * The duration that the token is spoken for.
   */
  durationMs?: number;
  /**
   * The time in the video at which the token starts being spoken.
   */
  startTimeMs?: number;
  /**
   * The speech token.
   */
  text?: string;
}

/**
 * Contains features needed for Bleurt inference.
 */
export interface VideoContentSearchBleurtFeatures {
  candidate?: string;
  reference?: string;
}

/**
 * Features and debug info for individual caption entity video anchors.
 */
export interface VideoContentSearchCaptionEntityAnchorFeatures {
  /**
   * If the description anchor has been recognized as an entity and that entity
   * has also been mention in the ASR, this is the mention text from the ASR.
   */
  asrMentionText?: string;
  /**
   * The start index of the ASR entity mention from the beginning of the ASR
   * transcript. The index is included so that individual mentions that share
   * the same mid and time can be distinguished which happens when an entity is
   * mentioned multiple times in an ASR sentence. Each
   * mid/asr_mention_transcript_offset will be unique.
   */
  asrMentionTranscriptOffset?: number;
  /**
   * The nearest ASR sentence.
   */
  asrSentence?: string;
  /**
   * The begin time in ms of the ASR sentence.
   */
  asrStartTime?: number;
  /**
   * The result of the BERT inference using the title, ASR sentence and entity
   * mention text.
   */
  bertScores?: number[];
  /**
   * A score to help determine how specific this entity is.
   */
  broadness?: number;
  /**
   * The percentage of the video covered by the span of the first mention to
   * the last mention.
   */
  durationCoverage?: number;
  /**
   * The webref connectedness score of the entity.
   */
  entityConnectedness?: number;
  /**
   * A short text describing the entity.
   */
  entityDescription?: string;
  /**
   * Information about how many documents the entity occurred in and how many
   * total mentions the entity has across the entire video corpus.
   */
  entityInfo?: VideoContentSearchCaptionEntityDocInfo;
  /**
   * Whether or not the entity mention text appears in the description of the
   * video.
   */
  entityMentionInDescription?: boolean;
  /**
   * The estimated begin time in ms of the entity mention using the text offset
   * divided by the ASR duration.
   */
  estimatedMentionTime?: number;
  /**
   * Average similarity between this anchor and other anchors in the set.
   */
  groupCohesion?: number;
  /**
   * The confidence of the hypernym used as the set label.
   */
  hypernymConfidence?: number;
  /**
   * Number of hypernyms used for calculating similarity.
   */
  hypernymCount?: number;
  /**
   * The cosine similarity between the document salient terms and the
   * hyperpedia hypernyms for a given entity.
   */
  hyperpediaSalientTermsSimilarity?: number;
  /**
   * Whether or not this entity is in the webref entities.
   */
  inWebrefEntities?: boolean;
  /**
   * True if the given entity appears as an Oracle followup query.
   */
  isOracleEntity?: boolean;
  /**
   * Whether this entity counts as a 'product' for the purpose of dividing
   * entities between the 'related topics' and 'products in this video'
   * features.
   */
  isProduct?: boolean;
  /**
   * The maximum confidence of all of the entity mentions in the transcript.
   */
  maxMentionConfidence?: number;
  /**
   * The confidence that the ASR mention matches the given mid.
   */
  mentionConfidence?: number;
  /**
   * Number of times an entity is mentioned in the ASR transcript.
   */
  mentions?: number;
  /**
   * The duration in ms between this anchor and the previous anchor or the
   * beginning of the video if this is the first anchor.
   */
  msFromLastAnchor?: number;
  /**
   * The ASR sentence after asr_sentence or "" if it is the last sentence.
   */
  nextAsrSentence?: string;
  /**
   * The ASR text of each mention of the entity.
   */
  otherAsrMentionText?: string[];
  /**
   * Each time the entity was mentioned.
   */
  otherEstimatedMentionTimes?: number[];
  /**
   * The ASR sentence before asr_sentence or "" if it is the first sentence.
   */
  previousAsrSentence?: string;
  /**
   * The confidence that the ASR mention is a trusted name.
   */
  trustedNameConfidence?: number;
  /**
   * The webref entity topicality score if the entity is a webref entity and 0
   * if not.
   */
  webrefEntityTopicality?: number;
}

function serializeVideoContentSearchCaptionEntityAnchorFeatures(data: any): VideoContentSearchCaptionEntityAnchorFeatures {
  return {
    ...data,
    entityInfo: data["entityInfo"] !== undefined ? serializeVideoContentSearchCaptionEntityDocInfo(data["entityInfo"]) : undefined,
  };
}

function deserializeVideoContentSearchCaptionEntityAnchorFeatures(data: any): VideoContentSearchCaptionEntityAnchorFeatures {
  return {
    ...data,
    entityInfo: data["entityInfo"] !== undefined ? deserializeVideoContentSearchCaptionEntityDocInfo(data["entityInfo"]) : undefined,
  };
}

/**
 * Features and debug info for clusters of caption entity video anchors.
 */
export interface VideoContentSearchCaptionEntityAnchorSetFeatures {
  /**
   * The total score used for filtering and selecting entity sets.
   */
  aggregateScore?: number;
  /**
   * The prefiltered size of the entity set.
   */
  clusterSize?: number;
  /**
   * The number of entities in the anchor set that are in the webref entities.
   */
  entitiesInWebrefEntities?: number;
  /**
   * The number of anchors where the entity mention text appears in the
   * description of the video.
   */
  entityMentionInDescriptionCount?: boolean;
  /**
   * The average cosine similarity between hypernyms of members of the set.
   */
  groupCohesion?: number;
  /**
   * The most prominent hypernym across the entities in the set.
   */
  hypernym?: string;
  /**
   * The salience of the best hypernym for the set.
   */
  hypernymSalience?: number;
  /**
   * Median number of times any member of the set was mentioned in the ASR
   * transcript.
   */
  medianMentions?: number;
  /**
   * Mentions divided by the total number of entity mentions in the video.
   */
  mentionSalience?: number;
  /**
   * Salience of the set computed by aggregating the hypernyms from each member
   * and calculating the cosine similarity with the salient terms.
   */
  salience?: number;
  /**
   * The top N hypernyms for the entities in the set.
   */
  topHypernym?: string[];
  /**
   * Number of times any member of the group was mentioned in the ASR
   * transcript.
   */
  totalMentions?: number;
}

/**
 * Contains information about document appearances of an entity.
 */
export interface VideoContentSearchCaptionEntityDocInfo {
  /**
   * The number of documents where this entity was mentioned at least once.
   */
  entityDocCount?: bigint;
  /**
   * The number of times the entity was mentioned across the entire corpus.
   */
  entityMentionCount?: bigint;
  /**
   * The entity id.
   */
  mid?: string;
  /**
   * The number of documents in the corpus.
   */
  totalDocCount?: bigint;
  /**
   * The number of mentions of any entity across the entire corpus.
   */
  totalMentionCount?: bigint;
}

function serializeVideoContentSearchCaptionEntityDocInfo(data: any): VideoContentSearchCaptionEntityDocInfo {
  return {
    ...data,
    entityDocCount: data["entityDocCount"] !== undefined ? String(data["entityDocCount"]) : undefined,
    entityMentionCount: data["entityMentionCount"] !== undefined ? String(data["entityMentionCount"]) : undefined,
    totalDocCount: data["totalDocCount"] !== undefined ? String(data["totalDocCount"]) : undefined,
    totalMentionCount: data["totalMentionCount"] !== undefined ? String(data["totalMentionCount"]) : undefined,
  };
}

function deserializeVideoContentSearchCaptionEntityDocInfo(data: any): VideoContentSearchCaptionEntityDocInfo {
  return {
    ...data,
    entityDocCount: data["entityDocCount"] !== undefined ? BigInt(data["entityDocCount"]) : undefined,
    entityMentionCount: data["entityMentionCount"] !== undefined ? BigInt(data["entityMentionCount"]) : undefined,
    totalDocCount: data["totalDocCount"] !== undefined ? BigInt(data["totalDocCount"]) : undefined,
    totalMentionCount: data["totalMentionCount"] !== undefined ? BigInt(data["totalMentionCount"]) : undefined,
  };
}

/**
 * Contains transcript-level data about a video whether it comes from ASR or
 * closed captions.
 */
export interface VideoContentSearchCaptionInfo {
  asrCaption?: VideoContentSearchAsrCaption[];
  saftDocument?: NlpSaftDocument;
}

function serializeVideoContentSearchCaptionInfo(data: any): VideoContentSearchCaptionInfo {
  return {
    ...data,
    saftDocument: data["saftDocument"] !== undefined ? serializeNlpSaftDocument(data["saftDocument"]) : undefined,
  };
}

function deserializeVideoContentSearchCaptionInfo(data: any): VideoContentSearchCaptionInfo {
  return {
    ...data,
    saftDocument: data["saftDocument"] !== undefined ? deserializeNlpSaftDocument(data["saftDocument"]) : undefined,
  };
}

/**
 * Contains timing and text for a given label.
 */
export interface VideoContentSearchCaptionLabelFeatures {
  /**
   * OCR anchors with overlapping time-window with this anchor
   */
  alignedOcrTexts?: VideoContentSearchOCRText[];
  /**
   * The time stamp in milliseconds for the reference text (e.g. description
   * anchor time).
   */
  alignedTime?: bigint;
  /**
   * Text around the aligned_time of a long duration, say [-15 minutes, +15
   * minutes]
   */
  contextText?: string;
  /**
   * The main label text for the feature.
   */
  labelText?: string;
  /**
   * Identified matching text by similarity.
   */
  textSimilarityFeatures?: VideoContentSearchTextSimilarityFeatures;
  /**
   * The text span in the passage starting from the aligned time.
   */
  textSpanAtAlignedTime?: string;
}

function serializeVideoContentSearchCaptionLabelFeatures(data: any): VideoContentSearchCaptionLabelFeatures {
  return {
    ...data,
    alignedOcrTexts: data["alignedOcrTexts"] !== undefined ? data["alignedOcrTexts"].map((item: any) => (serializeVideoContentSearchOCRText(item))) : undefined,
    alignedTime: data["alignedTime"] !== undefined ? String(data["alignedTime"]) : undefined,
    textSimilarityFeatures: data["textSimilarityFeatures"] !== undefined ? serializeVideoContentSearchTextSimilarityFeatures(data["textSimilarityFeatures"]) : undefined,
  };
}

function deserializeVideoContentSearchCaptionLabelFeatures(data: any): VideoContentSearchCaptionLabelFeatures {
  return {
    ...data,
    alignedOcrTexts: data["alignedOcrTexts"] !== undefined ? data["alignedOcrTexts"].map((item: any) => (deserializeVideoContentSearchOCRText(item))) : undefined,
    alignedTime: data["alignedTime"] !== undefined ? BigInt(data["alignedTime"]) : undefined,
    textSimilarityFeatures: data["textSimilarityFeatures"] !== undefined ? deserializeVideoContentSearchTextSimilarityFeatures(data["textSimilarityFeatures"]) : undefined,
  };
}

export interface VideoContentSearchCaptionSpanAnchorFeatures {
  /**
   * The features used to construct the inference example.
   */
  dolphinFeatures?: VideoContentSearchSpanDolphinFeatures;
  /**
   * The inference result from the Dolphin span model.
   */
  dolphinScores?: VideoContentSearchSpanDolphinScores;
  /**
   * Embedding distances (e.g. cosine distance) to the other anchors of the
   * same video.
   */
  embeddingDistance?: number[];
  /**
   * Time gap in ms to the next anchor. Always positive number.
   */
  postGapInMs?: number;
  /**
   * Time gap in ms to the previous anchor. Always a positive number.
   */
  preGapInMs?: number;
  /**
   * The range of tokens in video_info.saft_doc for the anchor label.
   */
  saftBeginTokenIndex?: number;
  saftEndTokenIndex?: number;
  saftTranscriptEndCharOffset?: number;
  /**
   * The range of characters in video_info.saft_transcript for the anchor
   * label.
   */
  saftTranscriptStartCharOffset?: number;
  /**
   * A summary of the ASR confidence for the selected candidate.
   */
  spanAsrConfidenceStats?: VideoContentSearchMetricStats;
  /**
   * A summary of the Dolphin span token scores for the selected candidate.
   */
  spanDolphinScore?: VideoContentSearchMetricStats;
  /**
   * Word count of the span text, tokenized with SAFT.
   */
  wordCount?: number;
}

function serializeVideoContentSearchCaptionSpanAnchorFeatures(data: any): VideoContentSearchCaptionSpanAnchorFeatures {
  return {
    ...data,
    dolphinScores: data["dolphinScores"] !== undefined ? serializeVideoContentSearchSpanDolphinScores(data["dolphinScores"]) : undefined,
  };
}

function deserializeVideoContentSearchCaptionSpanAnchorFeatures(data: any): VideoContentSearchCaptionSpanAnchorFeatures {
  return {
    ...data,
    dolphinScores: data["dolphinScores"] !== undefined ? deserializeVideoContentSearchSpanDolphinScores(data["dolphinScores"]) : undefined,
  };
}

export interface VideoContentSearchCaptionSpanAnchorSetFeatures {
  /**
   * A summary of the dolphin scores over the anchor set.
   */
  anchorSetDolphinScoreStats?: VideoContentSearchMetricStats;
}

/**
 * A message containing set-level comment anchor features. Next ID: 3
 */
export interface VideoContentSearchCommentAnchorSetFeatures {
  replies?: VideoContentSearchCommentAnchorSetFeaturesComment[];
  rootComment?: VideoContentSearchCommentAnchorSetFeaturesComment;
}

function serializeVideoContentSearchCommentAnchorSetFeatures(data: any): VideoContentSearchCommentAnchorSetFeatures {
  return {
    ...data,
    replies: data["replies"] !== undefined ? data["replies"].map((item: any) => (serializeVideoContentSearchCommentAnchorSetFeaturesComment(item))) : undefined,
    rootComment: data["rootComment"] !== undefined ? serializeVideoContentSearchCommentAnchorSetFeaturesComment(data["rootComment"]) : undefined,
  };
}

function deserializeVideoContentSearchCommentAnchorSetFeatures(data: any): VideoContentSearchCommentAnchorSetFeatures {
  return {
    ...data,
    replies: data["replies"] !== undefined ? data["replies"].map((item: any) => (deserializeVideoContentSearchCommentAnchorSetFeaturesComment(item))) : undefined,
    rootComment: data["rootComment"] !== undefined ? deserializeVideoContentSearchCommentAnchorSetFeaturesComment(data["rootComment"]) : undefined,
  };
}

/**
 * A structure that represents a comment. Fields 1 through 6 are designed to
 * store responses from the 3P YouTube Data API (see
 * https://developers.google.com/youtube/v3/docs/comments). Field 7 is used to
 * store the Google-internal representation of the comment; if it is populated,
 * then all other fields may be empty. Next ID: 8
 */
export interface VideoContentSearchCommentAnchorSetFeaturesComment {
  /**
   * The ID that YouTube uses to uniquely identify the comment.
   */
  commentId?: string;
  /**
   * The total number of likes (positive ratings) the comment has received.
   */
  likeCount?: number;
  /**
   * The MiniStanza object that represents the comment. If populated, all other
   * fields in this message may be empty.
   */
  miniStanza?: YoutubeCommentsClusteringMiniStanza;
  /**
   * The date and time when the comment was orignally published, specified in
   * ISO 8601 format.
   */
  publishedAt?: string;
  /**
   * The comment's text, in HTML.
   */
  textDisplay?: string;
  /**
   * The original, raw text of the comment.
   */
  textOriginal?: string;
  /**
   * The date and time when the comment was last updated, specified in ISO 8601
   * format.
   */
  updatedAt?: string;
}

function serializeVideoContentSearchCommentAnchorSetFeaturesComment(data: any): VideoContentSearchCommentAnchorSetFeaturesComment {
  return {
    ...data,
    miniStanza: data["miniStanza"] !== undefined ? serializeYoutubeCommentsClusteringMiniStanza(data["miniStanza"]) : undefined,
  };
}

function deserializeVideoContentSearchCommentAnchorSetFeaturesComment(data: any): VideoContentSearchCommentAnchorSetFeaturesComment {
  return {
    ...data,
    miniStanza: data["miniStanza"] !== undefined ? deserializeYoutubeCommentsClusteringMiniStanza(data["miniStanza"]) : undefined,
  };
}

export interface VideoContentSearchDescriptionAnchorFeatures {
  /**
   * When the description anchor text has been recognized as an entity, how
   * much of the description anchor text is covered by the entity mention.
   */
  entityTextCoverage?: number;
  /**
   * Whether or not a mention of the description anchor exists in the ASR.
   */
  inAsr?: boolean;
  /**
   * Whether or not the anchor was created from the description for use in
   * training data. This will be set to true for positive examples and false for
   * negative examples.
   */
  isDescriptionAnchor?: boolean;
  /**
   * The distance from the ASR sentence to the description anchor time in ms.
   */
  spanToAsrTime?: number;
}

export interface VideoContentSearchDescriptionAnchorSetFeatures {
  /**
   * The number of description anchors that were matched to captions in the
   * ASR.
   */
  asrAnchorCount?: number;
  /**
   * The fraction of anchors that were matched to captions in the ASR.
   */
  asrAnchorFraction?: number;
  /**
   * The number of unique mids which where matched to description anchors.
   */
  uniqueAsrMidCount?: number;
}

/**
 * Metadata about the span when the anchor source is description span.
 */
export interface VideoContentSearchDescriptionSpanInfo {
  /**
   * The number of tokens in the context (sentence) where the description span
   * is extracted from.
   */
  contextTokenCount?: number;
  /**
   * The inference result from the Dolphin span model if the anchor's source is
   * description span.
   */
  dolphinScores?: VideoContentSearchSpanDolphinScores;
  /**
   * A summary of the Dolphin span token scores for the selected candidate.
   * Currently, dolphin_scores in DescriptionSpanInfo would only contain a
   * single span candidate so this field is essentially the copy of the
   * score_stats for that span candidate.
   */
  spanDolphinScoreStats?: VideoContentSearchMetricStats;
  /**
   * The number of tokens in the description span. The description span is
   * formed from non-contiguous segment spans of a sentence (context), where
   * each segment span's score satifsies the min span thresholds.
   */
  spanTokenCount?: number;
  /**
   * The ratio of span_token_count / context_token_count.
   */
  spanTokenCountRatio?: number;
}

function serializeVideoContentSearchDescriptionSpanInfo(data: any): VideoContentSearchDescriptionSpanInfo {
  return {
    ...data,
    dolphinScores: data["dolphinScores"] !== undefined ? serializeVideoContentSearchSpanDolphinScores(data["dolphinScores"]) : undefined,
  };
}

function deserializeVideoContentSearchDescriptionSpanInfo(data: any): VideoContentSearchDescriptionSpanInfo {
  return {
    ...data,
    dolphinScores: data["dolphinScores"] !== undefined ? deserializeVideoContentSearchSpanDolphinScores(data["dolphinScores"]) : undefined,
  };
}

/**
 * Contains information about the scores from each individual dolphin ensemble
 * model.
 */
export interface VideoContentSearchDolphinEnsembleScore {
  /**
   * The score generated by the Dolphin callout model.
   */
  dolphinScore?: number;
  modelName?: string;
}

export interface VideoContentSearchDolphinFeatures {
  /**
   * The alt query used for building the Dolphin example.
   */
  altQuery?: string;
  /**
   * The answer used for building the Dolphin example.
   */
  answer?: string;
  /**
   * The query used for building the Dolphin example.
   */
  query?: string;
  /**
   * The time stamp of the video anchor in milliseconds.
   */
  timeMs?: bigint;
  /**
   * The title used for building the Dolphin example.
   */
  title?: string;
  /**
   * The url of the video.
   */
  url?: string;
}

function serializeVideoContentSearchDolphinFeatures(data: any): VideoContentSearchDolphinFeatures {
  return {
    ...data,
    timeMs: data["timeMs"] !== undefined ? String(data["timeMs"]) : undefined,
  };
}

function deserializeVideoContentSearchDolphinFeatures(data: any): VideoContentSearchDolphinFeatures {
  return {
    ...data,
    timeMs: data["timeMs"] !== undefined ? BigInt(data["timeMs"]) : undefined,
  };
}

export interface VideoContentSearchDolphinScoringConfig {
  /**
   * The output put keys for Dolphin PredictResponse
   */
  descriptivenessOutputKey?: string;
  /**
   * If the dolphin model is an ensemble model (e.g. Video QnA model which
   * consists of 4 teacher models), stores each individual model name.
   */
  ensembleModelNames?: string[];
  /**
   * The inference batch size to use for inference methods that handle
   * batching.
   */
  inferenceBatchSize?: number;
  /**
   * The method to use for inference. This must be set or inference will fail.
   */
  inferenceMethod?:  | "NONE" | "RPC" | "IN_PROCESS";
  /**
   * Holds value of flag --max_rpc_retries.
   */
  maxRpcRetries?: number;
  /**
   * Model name used for ModelSpec in PredictRequest used in the
   * PredictionService API.
   */
  modelName?: string;
  /**
   * Only used when using the bulk_inference API. See go/dolphin-models to
   * learn about the different dolphin models.
   */
  modelPath?: string;
  /**
   * TODO(alexiaxu) To deprecate this field in the future Output key for
   * Dolphin PredictResponse.
   */
  outputKey?: string;
  /**
   * Holds value of flag --rpc_deadline (converted to seconds).
   */
  rpcDeadlineSeconds?: number;
  /**
   * Tensorflow inference BNS address when using PredictionService API.
   */
  serviceBns?: string;
  usefulnessOutputKey?: string;
}

/**
 * Entity annotations for one of the mids representing an anchor label or a
 * query text.
 */
export interface VideoContentSearchEntityAnnotations {
  /**
   * The Webref category that this entity belongs to e.g. "/moka/software".
   */
  category?: string;
  /**
   * The overall confidence that this entity is annotated somewhere in the
   * label.
   */
  confidence?: number;
  /**
   * Whether or not this entity belongs to a set of blocklisted categories.
   */
  isRestricted?: boolean;
  /**
   * The Webref entity mid.
   */
  mid?: string;
}

export interface VideoContentSearchEntityGroupInfo {
  /**
   * Collection id.
   */
  collectionId?: string;
  /**
   * Label for this anchor group.
   */
  label?: string;
}

/**
 * Frame-level similarities info for each topic for an interval of frames.
 */
export interface VideoContentSearchFrameSimilarityInterval {
  /**
   * Timestamp in milliseconds for the last frame in this frame interval.
   */
  framesEndTimestampMs?: bigint;
  /**
   * The similarity between this topic and starburst features for frames in
   * [frames[frame_level_starburst_start_index],
   * frames[frame_level_starburst_start_index + len(frame_similarity)].
   */
  frameSimilarity?: number[];
  /**
   * The index of the first frame within this interval of similar frames.
   * VideoMultimodalTopicFeatures.frame_starburst_data.
   */
  framesStarburstStartIndex?: number;
  /**
   * Timestamp in milliseconds for the first frame in this frame interval.
   */
  framesStartTimestampMs?: bigint;
}

function serializeVideoContentSearchFrameSimilarityInterval(data: any): VideoContentSearchFrameSimilarityInterval {
  return {
    ...data,
    framesEndTimestampMs: data["framesEndTimestampMs"] !== undefined ? String(data["framesEndTimestampMs"]) : undefined,
    framesStartTimestampMs: data["framesStartTimestampMs"] !== undefined ? String(data["framesStartTimestampMs"]) : undefined,
  };
}

function deserializeVideoContentSearchFrameSimilarityInterval(data: any): VideoContentSearchFrameSimilarityInterval {
  return {
    ...data,
    framesEndTimestampMs: data["framesEndTimestampMs"] !== undefined ? BigInt(data["framesEndTimestampMs"]) : undefined,
    framesStartTimestampMs: data["framesStartTimestampMs"] !== undefined ? BigInt(data["framesStartTimestampMs"]) : undefined,
  };
}

/**
 * Starburst frame-level dense data.
 */
export interface VideoContentSearchFrameStarburstData {
  /**
   * Raw float feature vector of the starburst representation.
   */
  denseVector?: number[];
  /**
   * Starburst version. Possible values are: STARBURST_TEXT_V4
   * STARBURST_TEXT_V4_5 STARBURST_TEXT_V4_PLC STARBURST_TEXT_V5
   */
  sbVersion?:  | "SIGNAL_VERSION_UNSPECIFIED" | "RAID_V1" | "RAID_V2" | "RAID_V2_2" | "RAID_V2_NEST" | "RAID_V3" | "RAID_FOREGROUND_SEGMENTER_V1" | "RAID_FOREGROUND_SEGMENTER_V2" | "RAID_PRODUCT_SEGMENTER_V1" | "RAID_PRODUCT_SEGMENTER_V2" | "BARCODE_V1" | "BARCODE_V2" | "BARCODE_V3" | "LOGO_DEEPLOGO" | "LOGO_V1" | "LOGO_V2" | "LOGO_V2_PLUS" | "LOGO_MNET_V2" | "LOGO_MNET_V2_HATE_SYMBOLS" | "ICA_HNET" | "ICA_INET" | "ICA_KNET" | "ICA_LNET" | "ICA_OIDV6_GNET" | "ICA_ONET" | "ICA_PNET" | "ICA_PNET_SENSITIVE" | "ICA_RNET" | "NIMA_VQ_V1" | "NIMA_AVA_V1" | "NIMA_VQ_V2" | "NIMA_AVA_V2" | "ATT_GMAIL" | "ATT_MS" | "IM2SHOP_LOCAL_V1" | "IM2SHOP_LOCAL_V2" | "NIMBY_RAW_V0" | "NIMBY_RAW_V1" | "NIMBY_TOKENIZER_V0" | "NIMBY_TOKENIZER_V1" | "IM2QUERY_LABELED_PRODUCTS_V1" | "IM2QUERY_LABELED_PRODUCTS_V2" | "PLACE_EMB_V1" | "PLACE_EMB_V2" | "STARBURST_V3" | "STARBURST_V4" | "STARBURST_V4_01" | "STARBURST_VISUAL_V4" | "STARBURST_V5" | "STARBURST_V5_5" | "ATTRIBUTE_EMBEDDING_V1" | "PHOTOCAT_V1" | "PHOTOCAT_V3" | "PHOTOCAT_V4" | "PHOTOCAT_V5" | "STARBURST_TEXT_V4" | "STARBURST_TEXT_V4_5" | "STARBURST_TEXT_V4_PLC" | "STARBURST_TEXT_V5" | "STARBURST_TEXT_V5_PLC" | "COLLAGE_V1" | "SHOPPING_COLOR_INFO_V1_V2" | "SHOPPING_COLOR_INFO_V3" | "SHOPPING_COLOR_INFO_V3_WITHOUT_PER_DOMAIN_OUTPUTS" | "SHOPPING_COLOR_SAMPLING_V1" | "FOODNET_WIC_V1" | "FOODNET_WIC_V2" | "SINGLE_IMAGE_HOLISTIC_STABLE" | "SINGLE_IMAGE_HOLISTIC_EXP" | "MOKA_ATTRIBUTES_V1" | "MOKA_ATTRIBUTES_V1_1" | "MOKA_ATTRIBUTES_V1_2" | "MOKA_ATTRIBUTES_V2" | "GNN_OCR_EMB_V1" | "AKSARA_RPN_LAYOUT" | "GCN_LAYOUT" | "FACE_DETECTION_V1" | "FACE_DETECTION_LANDMARKLESS_V2" | "FACE_DETECTION_V2" | "PRODUCT_POSE_SHOE_V1" | "GOCR_LATEST" | "GOCR_STABLE" | "PAGEBURST_V1" | "PAGEBURST_V2" | "ADSBURST_V09" | "ADSBURST_COMP_V09" | "ADSBURST_V1_COMP" | "ADSBURST_V1_CONCAT" | "ADSBURST_BASIC_COAT4_V0" | "ADSBURST_HUBBLE_V1_COMP" | "ADSBURST_HUBBLE_V1_CONCAT" | "ADSBURST_DISCOVERY_UNCOMFORTABLE_V1" | "ADSBURST_DISCOVERY_NERV_SUBS_V1" | "ADSBURST_BASIC_TEXT_TOWER_V0" | "SHOPPING_IMAGE_TRANSFORMATION_UNCROP" | "SHOPPING_IMAGE_TRANSFORMATION_V2" | "SCREENAI_V1" | "SCREENAI_V2" | "SCREENAI_V2_MOBILE" | "SCREENAI_CLASSIFIER_V1" | "PERSONNET_V4" | "PERSONNET_V5" | "DEEP_IMAGE_ENGAGINGNESS_V1";
  /**
   * Timestamp in milliseconds for this frame.
   */
  timestampMs?: bigint;
}

function serializeVideoContentSearchFrameStarburstData(data: any): VideoContentSearchFrameStarburstData {
  return {
    ...data,
    timestampMs: data["timestampMs"] !== undefined ? String(data["timestampMs"]) : undefined,
  };
}

function deserializeVideoContentSearchFrameStarburstData(data: any): VideoContentSearchFrameStarburstData {
  return {
    ...data,
    timestampMs: data["timestampMs"] !== undefined ? BigInt(data["timestampMs"]) : undefined,
  };
}

export interface VideoContentSearchGenerativePredictionFeatures {
  /**
   * Features for inferences from generative models.
   */
  passage?: string;
  /**
   * Inference results.
   */
  predictions?: string[];
  target?: string;
}

/**
 * The inference result features coming from the prediction service that
 * generates the topics.
 */
export interface VideoContentSearchGenerativeTopicPredictionFeatures {
  /**
   * This field is present if we already have a ground truth topic from the
   * training data.
   */
  groundTruthTopic?: string;
  /**
   * The name of the model where the predictions come from.
   */
  modelName?: string;
  /**
   * Inference results from the prediction service. Since we generally use beam
   * search with beam_size > 1, this field is repeated to capture all the
   * generated topic beams.
   */
  predictions?: string[];
}

/**
 * Anchor-level Metadata about Instruction anchors. TODO(keyvana) Update this
 * proto.
 */
export interface VideoContentSearchInstructionAnchorFeatures {
}

/**
 * Anchor-level metadata about the instruction anchors. Each instruction
 * passage anchor can contain multiple instruction steps and multiple
 * description anchors and thus the following fields are defined as repeated.
 */
export interface VideoContentSearchInstructionTrainingDataAnchorFeatures {
  /**
   * The match info about the description anchor matches with the ASR n-grams
   * in the instruction passage. Each element represents the best match between
   * a given description anchor and all qualified n-grams within the passage.
   */
  bestAsrAndDescriptionAnchorsMatchInfo?: VideoContentSearchSimilarityMatchInfo[];
  /**
   * The match info about the description anchor matches with the instruction
   * anchors in a instruction passage. Each element represents the best match
   * between a given description anchor and all the instruction anchors in the
   * passage.
   */
  bestDescriptionAndInstructionAnchorsMatchInfo?: VideoContentSearchSimilarityMatchInfo[];
  /**
   * The match info about the instruction steps matches with the ASR. Each
   * instruction step corresponds to a step extracted from a web doc. Each
   * instruction passage can contain multiple instruction step matches thus the
   * repeated field.
   */
  instructionAnchorsMatchInfo?: VideoContentSearchSimilarityMatchInfo[];
}

/**
 * Anchor-level Metadata about list description anchors.
 */
export interface VideoContentSearchListAnchorFeatures {
  /**
   * The babel match info of the list anchor with its matched ASR text.
   */
  babelMatch?: VideoContentSearchTextMatchInfo;
  /**
   * The description span metadata about list anchor when the anchor source is
   * DESCRIPTION_SPANS.
   */
  descriptionSpanInfo?: VideoContentSearchDescriptionSpanInfo;
  /**
   * The list item index of this anchor in the video description.
   */
  listItemIndex?: number;
  /**
   * The metadata about this list item's matches with different ASR snippets.
   * This is currently used in the base model (DTW) to generate candidate
   * anchors.
   */
  matchScores?: VideoContentSearchMatchScores[];
  /**
   * The score from the pretrigger model.
   */
  pretriggerScore?: number;
  /**
   * Babel similarity between the anchor and the video title.
   */
  titleAnchorBabelMatchScore?: number;
}

function serializeVideoContentSearchListAnchorFeatures(data: any): VideoContentSearchListAnchorFeatures {
  return {
    ...data,
    babelMatch: data["babelMatch"] !== undefined ? serializeVideoContentSearchTextMatchInfo(data["babelMatch"]) : undefined,
    descriptionSpanInfo: data["descriptionSpanInfo"] !== undefined ? serializeVideoContentSearchDescriptionSpanInfo(data["descriptionSpanInfo"]) : undefined,
    matchScores: data["matchScores"] !== undefined ? data["matchScores"].map((item: any) => (serializeVideoContentSearchMatchScores(item))) : undefined,
  };
}

function deserializeVideoContentSearchListAnchorFeatures(data: any): VideoContentSearchListAnchorFeatures {
  return {
    ...data,
    babelMatch: data["babelMatch"] !== undefined ? deserializeVideoContentSearchTextMatchInfo(data["babelMatch"]) : undefined,
    descriptionSpanInfo: data["descriptionSpanInfo"] !== undefined ? deserializeVideoContentSearchDescriptionSpanInfo(data["descriptionSpanInfo"]) : undefined,
    matchScores: data["matchScores"] !== undefined ? data["matchScores"].map((item: any) => (deserializeVideoContentSearchMatchScores(item))) : undefined,
  };
}

/**
 * Cluster-level Metadata about list anchors. Next id: 15.
 */
export interface VideoContentSearchListAnchorSetFeatures {
  /**
   * The following fields are used for description span anchors, The aggregated
   * span token texts over all the span candidates of the anchor set.
   */
  aggregatedSpanText?: string;
  /**
   * A summary of the span scores over the anchor set. This summary is
   * calculated over the aggregation of the individual token spans belonging to
   * the span candidates of anchors.
   */
  anchorSetSpanScoreStats?: VideoContentSearchMetricStats;
  /**
   * Median, average and standard deviation of babel_match_score among anchors
   * in the same VideoAnchors cluster.
   */
  babelMatchScoreStats?: VideoContentSearchMetricStats;
  /**
   * A summary of the context token counts over the anchor set.
   */
  contextTokenCountStats?: VideoContentSearchMetricStats;
  /**
   * The ratio of anchors timespan duration over the total duration of the
   * video. Anchors timespan duration is defined as the time span from the first
   * anchor to the last anchor in VideoAnchors.
   */
  durationSpanRatio?: number;
  /**
   * Median, average and standard deviation of duration_to_predicted_time_ms
   * among anchors in the same VideoAnchors cluster.
   */
  durationToPredictedTimeMsStats?: VideoContentSearchMetricStats;
  /**
   * The source of anchors extracted from the video descriptions.
   */
  listAnchorSource?:  | "UNKNOWN_SOURCE" | "ORDERED_LIST_PARSER" | "DESCRIPTION_SPANS" | "STEPS_PARSER" | "DESCRIPTION_LIST_EXTRACTION";
  /**
   * The total number of list items mentioned in the video description. Not all
   * these list items are necessarily found as list anchors.
   */
  listDescriptionItemsSize?: number;
  /**
   * The number of matched anchors in the list anchors over the total number of
   * post-filtering list items in the video description, i.e.
   * matched_list_description_anchors_ratio =
   * matched_list_description_anchors_size /
   * post_filtering_list_description_items_size.
   */
  matchedListDescriptionAnchorsRatio?: number;
  /**
   * The number of matched list anchors found in the ASR. The matched list
   * anchors are a subset of the post-filtering list items in the video
   * description, and as such matched_list_description_anchors_size <=
   * post_filtering_list_description_items_size.
   */
  matchedListDescriptionAnchorsSize?: number;
  /**
   * The total number of list items in the video description that are actually
   * considered for matching. This is a subset of list items in the video
   * description that passed filterings such as language filtering, i.e.
   * post_filtering_list_description_items_size <= list_description_items_size
   */
  postFilteringListDescriptionItemsSize?: number;
  /**
   * Median, average and standard deviation of pretrigger_score among anchors
   * in the same cluster.
   */
  pretriggerScoreStats?: VideoContentSearchMetricStats;
  /**
   * A summary of the span token count ratios over the anchor set.
   */
  spanTokenCountRatioStats?: VideoContentSearchMetricStats;
  /**
   * A summary of the span token counts over the anchor set.
   */
  spanTokenCountStats?: VideoContentSearchMetricStats;
}

/**
 * Anchor-level metadata about the description anchors used as list items to
 * build training data for list anchors.
 */
export interface VideoContentSearchListTrainingDataAnchorFeatures {
  /**
   * The timestamp of when the description anchor is annotated to appear in the
   * video in ms.
   */
  descriptionAnchorTimeMs?: number;
  /**
   * The time gap of when the description anchor is annotated to appear in the
   * video (description_anchor_time_ms) from when it's matched in the ASR as the
   * list anchor.
   */
  descriptionAnchorTimeToMatchedTimeMs?: bigint;
  /**
   * Closest edit distance between the anchor generated by description span and
   * the description anchor where the span anchor must be within small threshold
   * time difference of the description anchor timestamp.
   */
  editDistance?: number;
  /**
   * edit_distance over the description anchor's label length.
   */
  editDistanceRatio?: number;
  /**
   * The description anchor text used for matching to Span anchor text.
   */
  matchedDescriptionText?: string;
  /**
   * The description span anchor text that was the best match for the nearby
   * description anchor.
   */
  matchedSpanText?: string;
}

function serializeVideoContentSearchListTrainingDataAnchorFeatures(data: any): VideoContentSearchListTrainingDataAnchorFeatures {
  return {
    ...data,
    descriptionAnchorTimeToMatchedTimeMs: data["descriptionAnchorTimeToMatchedTimeMs"] !== undefined ? String(data["descriptionAnchorTimeToMatchedTimeMs"]) : undefined,
  };
}

function deserializeVideoContentSearchListTrainingDataAnchorFeatures(data: any): VideoContentSearchListTrainingDataAnchorFeatures {
  return {
    ...data,
    descriptionAnchorTimeToMatchedTimeMs: data["descriptionAnchorTimeToMatchedTimeMs"] !== undefined ? BigInt(data["descriptionAnchorTimeToMatchedTimeMs"]) : undefined,
  };
}

/**
 * Cluster-level metadata about the description anchors used as list items to
 * build training data for list anchors.
 */
export interface VideoContentSearchListTrainingDataSetFeatures {
  /**
   * Summary of the edit_distance_ratios of the description spans from their
   * best matched description anchor texts.
   */
  editDistanceRatioStats?: VideoContentSearchMetricStats;
  /**
   * Summary of the edit_distances of the description spans from their best
   * matched description anchor texts.
   */
  editDistanceStats?: VideoContentSearchMetricStats;
  /**
   * Median, average and standard deviation of time gaps of when the
   * description anchors is annotated to appear in the video
   * (description_anchor_time_ms) from when they are matched in the ASR as the
   * list description anchors.
   */
  matchedDescriptionAnchorsTimegapStats?: VideoContentSearchMetricStats;
  /**
   * Number of description anchors in the description of this video.
   */
  numDescriptionAnchors?: number;
}

export interface VideoContentSearchMatchScores {
  matchInfo?: VideoContentSearchTextMatchInfo[];
  /**
   * The method used for matching, e.g. 'babel', 'nlp', 'neon', 'phonetic'.
   */
  method?: string;
}

function serializeVideoContentSearchMatchScores(data: any): VideoContentSearchMatchScores {
  return {
    ...data,
    matchInfo: data["matchInfo"] !== undefined ? data["matchInfo"].map((item: any) => (serializeVideoContentSearchTextMatchInfo(item))) : undefined,
  };
}

function deserializeVideoContentSearchMatchScores(data: any): VideoContentSearchMatchScores {
  return {
    ...data,
    matchInfo: data["matchInfo"] !== undefined ? data["matchInfo"].map((item: any) => (deserializeVideoContentSearchTextMatchInfo(item))) : undefined,
  };
}

/**
 * Median, mean and standard deviation of a feature value.
 */
export interface VideoContentSearchMetricStats {
  max?: number;
  mean?: number;
  median?: number;
  min?: number;
  stddev?: number;
  sum?: number;
}

/**
 * Multimodal features for a single generated topic. Next ID: 8
 */
export interface VideoContentSearchMultimodalTopicFeatures {
  /**
   * The list of frame sequence similarities to this topic. The list of frames
   * are picked to be around the topic timestamp. The set of frames selected are
   * thresholded at a value to ensure the selected frame intervals are similar
   * to the query.
   */
  frameSimilarityInterval?: VideoContentSearchFrameSimilarityInterval[];
  /**
   * The inference results from the prediction services that generate the
   * topics.
   */
  generativeTopicPredictionFeatures?: VideoContentSearchGenerativeTopicPredictionFeatures[];
  /**
   * Features related to queries generated using document navboost data with
   * timed anchors. Only populated if the query was generated using this
   * approach.
   */
  navboostAnchorFeatures?: VideoContentSearchNavboostAnchorFeatures;
  /**
   * The text of the generated topic.
   */
  topic?: string;
  /**
   * End time of the topic.
   */
  topicEndMs?: bigint;
  /**
   * Start time of the topic.
   */
  topicStartMs?: bigint;
  /**
   * How the query was generated.
   */
  videoQuerySource?:  | "UNKNOWN_QUERY_SOURCE" | "NAVBOOST_ANCHOR" | "ORACLE" | "GENERATED_NAVBOOST_ANCHOR" | "GENERATED_AQUARIUM_RETRIEVAL" | "ORACLE_PER_RESULT" | "ENTITY_ANCHOR" | "PRODUCT_ANCHOR" | "ANCHOR" | "RANKEMBED_GENERATED_NAVBOOST_ANCHOR";
}

function serializeVideoContentSearchMultimodalTopicFeatures(data: any): VideoContentSearchMultimodalTopicFeatures {
  return {
    ...data,
    frameSimilarityInterval: data["frameSimilarityInterval"] !== undefined ? data["frameSimilarityInterval"].map((item: any) => (serializeVideoContentSearchFrameSimilarityInterval(item))) : undefined,
    topicEndMs: data["topicEndMs"] !== undefined ? String(data["topicEndMs"]) : undefined,
    topicStartMs: data["topicStartMs"] !== undefined ? String(data["topicStartMs"]) : undefined,
  };
}

function deserializeVideoContentSearchMultimodalTopicFeatures(data: any): VideoContentSearchMultimodalTopicFeatures {
  return {
    ...data,
    frameSimilarityInterval: data["frameSimilarityInterval"] !== undefined ? data["frameSimilarityInterval"].map((item: any) => (deserializeVideoContentSearchFrameSimilarityInterval(item))) : undefined,
    topicEndMs: data["topicEndMs"] !== undefined ? BigInt(data["topicEndMs"]) : undefined,
    topicStartMs: data["topicStartMs"] !== undefined ? BigInt(data["topicStartMs"]) : undefined,
  };
}

/**
 * Multimodal features for a single generated topic used to build training
 * data.
 */
export interface VideoContentSearchMultimodalTopicTrainingFeatures {
  /**
   * The similarity info for the frame with maximum similarity to the topic in
   * its visual interval. The repeated similarity field in this proto has a
   * single value corresponding to the maximum similarity. This similarity score
   * is used to filter and pick the training data examples.
   */
  maxFrameSimilarityInterval?: VideoContentSearchFrameSimilarityInterval;
  /**
   * The topic/query normalized for Navboost and QBST lookups as well as
   * fetching of the Rankembed nearest neighbors.
   */
  normalizedTopic?: string;
  /**
   * QBST terms overlap features for a candidate query.
   */
  qbstTermsOverlapFeatures?: VideoContentSearchQbstTermsOverlapFeatures;
  /**
   * Rankembed similarity features for a candidate nearest neighbor rankembed
   * query.
   */
  rankembedNearestNeighborsFeatures?: VideoContentSearchRankEmbedNearestNeighborsFeatures;
  /**
   * The information about the saft entity annotation for this topic.
   */
  saftEntityInfo?: VideoContentSearchSaftEntityInfo;
  /**
   * Raw float feature vector of the topic's co-text embedding representation
   * in the Starburst space.
   */
  topicDenseVector?: number[];
}

function serializeVideoContentSearchMultimodalTopicTrainingFeatures(data: any): VideoContentSearchMultimodalTopicTrainingFeatures {
  return {
    ...data,
    maxFrameSimilarityInterval: data["maxFrameSimilarityInterval"] !== undefined ? serializeVideoContentSearchFrameSimilarityInterval(data["maxFrameSimilarityInterval"]) : undefined,
  };
}

function deserializeVideoContentSearchMultimodalTopicTrainingFeatures(data: any): VideoContentSearchMultimodalTopicTrainingFeatures {
  return {
    ...data,
    maxFrameSimilarityInterval: data["maxFrameSimilarityInterval"] !== undefined ? deserializeVideoContentSearchFrameSimilarityInterval(data["maxFrameSimilarityInterval"]) : undefined,
  };
}

/**
 * Message for SAFT named entities.
 */
export interface VideoContentSearchNamedEntity {
  /**
   * Type name: e.g. /saft/person for a person's name.
   */
  entityType?: string;
  /**
   * Text referring to an entity of type entity_type;
   */
  text?: string;
}

/**
 * Features for queries generated using document navboost data with timed
 * anchors.
 */
export interface VideoContentSearchNavboostAnchorFeatures {
  /**
   * The anchor text used in the generated query.
   */
  anchorText?: string;
  /**
   * The navboost query used in the generated query.
   */
  navboostText?: string;
  /**
   * How the navboost-anchor query was constructed.
   */
  source?:  | "UNKNOWN_NAVBOOST_ANCHOR_SOURCE" | "ANCHOR_TEXT" | "NAVBOOST_AND_ANCHOR_TEXT" | "ANCHOR_SIMILAR_QUERY" | "NAVBOOST_AND_ANCHOR_SIMILAR_QUERY";
}

export interface VideoContentSearchOcrAsrFeature {
  /**
   * The minimum char edit distance between the normalized OCR text and
   * candidate word strings taken from a time window around the OCR appearance.
   */
  minCharEditDistance?: number;
  /**
   * The matched ASR candidate for minimum char edit distance.
   */
  minCharEditDistanceAsrText?: string;
  /**
   * The min_char_edit_distance divided by the length of the OCR string.
   */
  minCharEditDistancePercent?: number;
  /**
   * The normalized OCR text which was used to match the candidate.
   */
  ocrTextNormalizedForCharMatch?: string;
  /**
   * The length of the normalized OCR text.
   */
  ocrTextNormalizedForCharMatchLength?: number;
  /**
   * The score from the pretrigger model.
   */
  pretriggerScore?: number;
  /**
   * The ASR text that was used for the word overlap calculation.
   */
  wordOverlapAsrText?: string;
  /**
   * The number of words found both in the OCR text and the ASR in a time
   * window around OCR appearance.
   */
  wordOverlapCount?: number;
  /**
   * The word_overlap_count divided by the number of words in the OCR text.
   */
  wordOverlapPercent?: number;
}

export interface VideoContentSearchOcrAsrSetFeature {
  /**
   * The word_overlap_score divided by the greatest word_overlap_score for any
   * cluster in the VideoAnchorSets.
   */
  normalizedWordOverlapScore?: number;
  /**
   * A score based on the number of overlapped words between the OCR and ASR
   * for anchors in the cluster.
   */
  wordOverlapScore?: number;
}

/**
 * Metadata about the join of description anchors and OCR data which is used to
 * build training data.
 */
export interface VideoContentSearchOcrDescriptionTrainingDataAnchorFeatures {
  /**
   * The string edit distance from the anchor label to the nearest OCR text.
   */
  editDistance?: number;
  /**
   * edit_distance over the description anchor's label length.
   */
  editDistanceRatio?: number;
  /**
   * The description anchor text used for matching to OCR text.
   */
  matchedDescriptionText?: string;
  /**
   * The time of the selected OCR frame in ms. The best frame in a window
   * around the target description anchor will be selected.
   */
  matchedFrameTimeMs?: number;
  /**
   * The OCR text that was the best match for the nearby description anchor.
   */
  matchedOcrText?: string;
}

/**
 * Metadata about the join of description anchors and OCR data for a set of
 * description anchors.
 */
export interface VideoContentSearchOcrDescriptionTrainingDataSetFeatures {
  /**
   * The max edit distance of any description anchor to its closest OCR text.
   */
  maxEditDistance?: number;
  /**
   * The maximum of (edit distance of any description anchor to its closest OCR
   * text over description anchor label length).
   */
  maxEditDistanceRatio?: number;
  /**
   * The median edit distance of any description anchor to its closest OCR
   * text.
   */
  medianEditDistance?: number;
}

/**
 * Contains OCR text, its start time and additional details about
 * position/fonts
 */
export interface VideoContentSearchOCRText {
  /**
   * Additional details about position/font/color etc. for the OCR text
   */
  ocrFeature?: VideoContentSearchOnScreenTextFeature;
  /**
   * The OCR recognized text label
   */
  ocrText?: string;
  /**
   * The time in ms at which the OCR text appears on the frame
   */
  timeMs?: bigint;
}

function serializeVideoContentSearchOCRText(data: any): VideoContentSearchOCRText {
  return {
    ...data,
    timeMs: data["timeMs"] !== undefined ? String(data["timeMs"]) : undefined,
  };
}

function deserializeVideoContentSearchOCRText(data: any): VideoContentSearchOCRText {
  return {
    ...data,
    timeMs: data["timeMs"] !== undefined ? BigInt(data["timeMs"]) : undefined,
  };
}

/**
 * Features for video level info.
 */
export interface VideoContentSearchOcrVideoFeature {
  /**
   * Average text area ratio throughout video frames. Text area ratio for a
   * frame is defined by sum(text area) / image area.
   */
  averageTextAreaRatio?: number;
  /**
   * Cluster id to the num of frames in each cluster.
   */
  clusterIdToFrameSize?: {
    [key: string]: number
  };
  /**
   * Total time of this video in milliseconds.
   */
  durationInMs?: number;
  /**
   * Video level detected language by lang id, aggregated from each frame.
   */
  langIdDetectedLanguage?: string;
  /**
   * The number of ShotInfo clusters.
   */
  numClusters?: number;
  /**
   * The number of video frames contained in ShotInfo cluster.
   */
  numFrames?: number;
  /**
   * Video level detected language, aggregated from each frame.
   */
  ocrDetectedLanguage?: string;
}

/**
 * Features for the set of OnScreenText.
 */
export interface VideoContentSearchOnScreenTextClusterFeature {
  /**
   * Average confidence.
   */
  averageConfidence?: number;
  averageDurationRatio?: number;
  averageHorizontalPosition?: number;
  /**
   * Deprecated. Please use ocr_text_length_stats.median instead. The average
   * length of anchor labels. average_ocr_text_length is deprecated, because now
   * ocr_text_length_stats has a field for holding the same value.
   */
  averageOcrTextLength?: number;
  /**
   * Deprecated. Please use text_height_ratio_stats.mean instead. Average value
   * of text height ratio (over image height), which is taken average over the
   * same text. average_of_average_text_height_ratio is deprecated, because now
   * text_height_ratio_stats has a field for keeping the same value.
   */
  averageOfAverageTextHeightRatio?: number;
  /**
   * Average of label center position.
   */
  averageVerticalPosition?: number;
  /**
   * The number of anchors in the cluster over the number of anchors in the
   * video.
   */
  clusterRatio?: number;
  /**
   * The number of anchors in the cluster.
   */
  clusterSize?: number;
  /**
   * The number of anchors that had a counting number over the number of
   * anchors in total.
   */
  countingNumberRatio?: number;
  /**
   * Median, average and standard deviation of duration_ms among anchors in the
   * same cluster.
   */
  durationMsStats?: VideoContentSearchMetricStats;
  /**
   * Frame size ratio over total frames in video.
   */
  frameSizeRatio?: number;
  /**
   * Average and standard deviation of logarithm of the length of labels among
   * anchors in the same cluster.
   */
  logOcrTextLengthStats?: VideoContentSearchMetricStats;
  /**
   * Average and standard deviation of log(1000 + duration_ms) among anchors in
   * the same cluster. Since duration_ms can be zero, 1000 is added before
   * applying logarithm.
   */
  logp1000DurationMsStats?: VideoContentSearchMetricStats;
  /**
   * Average and standard deviation of log(average_text_height_ratio) among
   * anchors in the same cluster.
   */
  logTextHeightRatioStats?: VideoContentSearchMetricStats;
  /**
   * Stats for ratio of frame time intervals, over total video time.
   */
  maximumDurationRatio?: number;
  /**
   * The maximum ratio of duration between two consecutive anchors to video
   * duration. This is calculated after all anchor filtering has been completed.
   */
  maxVideoDurationRatioBetweenAnchors?: number;
  /**
   * The median cluster distance for the anchors in the cluster. The way the
   * distance is calculated will vary depending on the clustering method.
   */
  medianClusteringDistance?: number;
  medianDurationRatio?: number;
  /**
   * Deprecated. Please use text_height_ratio_stats.median instead. Median
   * value of text height ratio (over image height), which is taken average over
   * the same text. median_of_average_text_height_ratio is deprecated, because
   * now text_height_ratio_stats has a field for keeping the same value.
   */
  medianOfAverageTextHeightRatio?: number;
  /**
   * Features for the overlap between OCR and ASR.
   */
  ocrAsrFeature?: VideoContentSearchOcrAsrSetFeature;
  /**
   * Median, average and standard deviation of the length of labels among
   * anchors in the same cluster.
   */
  ocrTextLengthStats?: VideoContentSearchMetricStats;
  stddevDurationRatio?: number;
  /**
   * Median, average and standard deviation of average_text_height_ratio among
   * anchors in the same cluster.
   */
  textHeightRatioStats?: VideoContentSearchMetricStats;
}

/**
 * Keep feature values which are useful to filter titles, labels.
 */
export interface VideoContentSearchOnScreenTextFeature {
  /**
   * The average of rotation angles (degree) of texts.
   */
  averageAngle?: number;
  /**
   * Average value of confidence.
   */
  averageConfidence?: number;
  /**
   * Font size or weight information. This is extracted from internal message,
   * so may not be available in future.
   */
  averageFontsize?: number;
  averageFontweight?: number;
  averageHeightRatio?: number;
  backgroundBlue?: number;
  backgroundGray?: number;
  backgroundGreen?: number;
  backgroundRed?: number;
  boxHeightRatio?: number;
  /**
   * Box width and height ratio, against to the frame size, so the value range
   * is [0, 1]. If this text feature consists of multiple text boxes, the box
   * width / height is a union of each text box.
   */
  boxWidthRatio?: number;
  /**
   * Horizontal position of the center of this text, by ratio [0.0, 1.0].
   */
  centerHorizontalPositionRatio?: number;
  /**
   * Vertical position of the center of this text, by ratio [0.0, 1.0].
   */
  centerVerticalPositionRatio?: number;
  /**
   * Counting number in this anchor's original label.
   */
  countingNumber?: number;
  /**
   * # of numbered anchors that are not out-of-order / # of all the numbered
   * anchors. If no counting number is detected, this will be empty.
   */
  countingNumberOooRatio?: number;
  /**
   * Prefix for counting number in this anchor's label. If no counting number
   * is detected, this will be empty.
   */
  countingNumberPrefix?: string;
  /**
   * Suffix for counting number in this anchor's label. If no counting number
   * is detected, this will be empty.
   */
  countingNumberSuffix?: string;
  /**
   * Duration time in millisec.
   */
  durationMs?: number;
  foregroundBlue?: number;
  /**
   * Color information, normalized to [0-1]. This color information is
   * extracted from the largest word in the line entities of PageLayout message.
   * See goodoc::PageLayoutEntity::Colors for details.
   */
  foregroundGray?: number;
  foregroundGreen?: number;
  foregroundRed?: number;
  /**
   * Whether or not this anchor had URL in its label before the label fixing
   * step.
   */
  hadUrlInLabel?: boolean;
  /**
   * # of LINE entities that are recognized as handwritten texts over # of
   * merged LINE entities.
   */
  handwrittenTextRatio?: number;
  /**
   * Whether or not the counting number in this anchor's label is out-of-order.
   * If no counting number is detected, this will be empty.
   */
  isCountingNumberOoo?: boolean;
  /**
   * Languages predicted by OCR. "repeated" is employed for this field because
   * LINE entities of PageLayout message are sometimes annotated with multiple
   * languages, and also two VideoAnchor that are annotated with different
   * languages can be merged into one VideoAnchor. When two VideoAnchor are
   * merged into one, the weight field values of the new VideoAnchor will be the
   * average of weight field values weighted by merged_line_count.
   */
  languages?: GoodocLanguageCombinationLanguage[];
  /**
   * Left position of this text, by ratio [0, 1].
   */
  leftPositionRatio?: number;
  /**
   * The median distance between this anchor and other anchors in the cluster.
   * The way the distance is calculated will vary depending on the clustering
   * method.
   */
  medianClusteringDistance?: number;
  /**
   * The number of LINE entities used for this text.
   */
  mergedLineCount?: number;
  /**
   * # of OCR texts that appear in the same frame. If duration of this OCR text
   * is not zero, the maximum number among multiple frames where this OCR text
   * appears is set to this field.
   */
  nTextsInSameFrame?: number;
  /**
   * The number of OCR texts that have the same text among temporally-merged
   * OCR texts.
   */
  occurrenceCount?: number;
  /**
   * occurrence_count over the number of anchors merged to this anchor.
   */
  occurrenceRatio?: number;
  /**
   * Features for the overlap between OCR and ASR.
   */
  ocrAsrFeature?: VideoContentSearchOcrAsrFeature;
  /**
   * The label this VideoAnchor originally had before label clearning steps.
   */
  originalLabel?: string;
  relativeShotTimeMsPosteriorToEndTime?: number;
  relativeShotTimeMsPosteriorToStartTime?: number;
  relativeShotTimeMsPriorToEndTime?: number;
  /**
   * Shot boundary time nearest to OnScreenText's start and end time. The time
   * is relative to each OnScreenText's start / end time (ex. -1 means shot time
   * exists prior to the start / end time). If shot time and start/end time is
   * the same, 0 is set in 'prior' field. If no shot info is available, the
   * below fields are not set.
   */
  relativeShotTimeMsPriorToStartTime?: number;
  shotInfoCountDuringText?: number;
  /**
   * OCR language that has the highest weight.
   */
  topOcrLanguage?: string;
  /**
   * Note that top-left position is (0, 0) for position values. Top position of
   * this text, by ratio [0, 1].
   */
  topPositionRatio?: number;
}

/**
 * QBST terms overlap features for the candidate query.
 */
export interface VideoContentSearchQbstTermsOverlapFeatures {
  /**
   * Fraction of salient terms of original query covered by anchor text.
   */
  qbstAnchorOverlap?: number;
  /**
   * Fraction of salient terms of original query covered by top navboost query
   * of the video.
   */
  qbstNavboostOverlap?: number;
}

/**
 * Features for individual Q&A anchors. Next ID: 23
 */
export interface VideoContentSearchQnaAnchorFeatures {
  /**
   * Segment of text from the ASR.
   */
  answer?: string;
  descartesDotScore?: number;
  descartesRankingScore?: number;
  dolphinModelType?:  | "DOLPHIN_MODEL_TYPE_UNKNOWN" | "VIDEO_QA_TEACHER_V2" | "VIDEO_QA_V11";
  /**
   * Dolphin score calculated using the question as the query, the ASR passage
   * as the answer. See go/dolphin-models to learn more.
   */
  dolphinScore?: number;
  /**
   * Edit distance of the question and the title from 0 to 1 where 1 is most
   * similar.
   */
  editDistance?: number;
  /**
   * End time in milliseconds relative to the beginning of the video.
   */
  endMs?: bigint;
  ensembleScore?: number;
  /**
   * True if question_title_similarity is less than 0.2.
   */
  isDuplicateOfTitle?: boolean;
  /**
   * Neon similarity of question and title.
   */
  neonScore?: number;
  /**
   * Pointwise GAP normalized score. Score ranges from 0 to 1 and corresponds
   * to GAP precision. See go/wa-cgap-to-pgap-migration to learn more.
   */
  pointwiseNormalizedGapScore?: number;
  /**
   * QBST similarity of question and title.
   */
  qbstScore?: number;
  /**
   * NavBoostFeature f_query_count for questions that are NavBoost queries.
   */
  queryCount?: number;
  /**
   * NavBoostFeature f_query_doc_count for questions that are NavBoost queries.
   */
  queryDocCount?: number;
  /**
   * Question from Related Questions SSTable or NavBoost.
   */
  question?: string;
  questionTitleSimilarity?: number;
  questionType?:  | "UNKNOWN" | "ENTITY" | "NAVBOOST" | "GLUE_WEBANS" | "INSTANT_NAVBOOST";
  /**
   * Start time in milliseconds relative to the beginning of the video.
   */
  startMs?: bigint;
  /**
   * Duration of the video.
   */
  videoDurationMs?: bigint;
  /**
   * Video title.
   */
  videoTitle?: string;
  /**
   * Mid corresponding to the WebRef entity from the CDoc that was used to
   * source the question.
   */
  webrefMid?: string;
  /**
   * The WebRef entity topicality score. Learn more about this score at:
   * http://go/topicality-score
   */
  webrefTopicalityScore?: number;
}

function serializeVideoContentSearchQnaAnchorFeatures(data: any): VideoContentSearchQnaAnchorFeatures {
  return {
    ...data,
    endMs: data["endMs"] !== undefined ? String(data["endMs"]) : undefined,
    startMs: data["startMs"] !== undefined ? String(data["startMs"]) : undefined,
    videoDurationMs: data["videoDurationMs"] !== undefined ? String(data["videoDurationMs"]) : undefined,
  };
}

function deserializeVideoContentSearchQnaAnchorFeatures(data: any): VideoContentSearchQnaAnchorFeatures {
  return {
    ...data,
    endMs: data["endMs"] !== undefined ? BigInt(data["endMs"]) : undefined,
    startMs: data["startMs"] !== undefined ? BigInt(data["startMs"]) : undefined,
    videoDurationMs: data["videoDurationMs"] !== undefined ? BigInt(data["videoDurationMs"]) : undefined,
  };
}

/**
 * Debug info for Q&A anchors. Next ID: 15
 */
export interface VideoContentSearchQnaAnchorSetFeatures {
  /**
   * Path to Descartes background encoding in the form of a serialized
   * drishti.DenseFeatureData proto. This is generated by the
   * flume_generate_background_encoding binary.
   */
  backgroundEncodingPath?: string;
  /**
   * This field is used for debugging which model the decartes_model_score is
   * generated from. You can learn more about the Descartes model at
   * go/descartes-qa.
   */
  descartesModelVersion?: string;
  /**
   * Descartes score threshold for determining whether to output a QA pair as
   * an anchor. This currently effects only the Descartes ranking score.
   */
  descartesScoreThreshold?: number;
  /**
   * The configuration used for fetching Dolphin scores.
   */
  dolphinConfig?: VideoContentSearchDolphinScoringConfig;
  /**
   * Path to Ranklab ensemble model used in post-trigger step.
   */
  ensembleModelPath?: string;
  /**
   * Minimum score for video anchor to pass the post-trigger step. Calculated
   * by training a logisitic regression model with 95% precision. Training colab
   * can be found at go/video-qa-ensemble.
   */
  ensembleModelScoreThreshold?: number;
  /**
   * Threshold for determining whether to consider an entity from a CDoc for
   * sourcing questions on that topic. Learn more about this score at:
   * http://go/topicality-score
   */
  minEntityTopicalityScore?: number;
  /**
   * Threshold for determining whether questions belong in the same cluster.
   */
  minQuestionDistance?: number;
  /**
   * Path to the Related Questions SSTable that maps entities to questions.
   */
  relatedQuestionsSstablePath?: string;
  /**
   * The duration threshold for merging captions.
   */
  spanDurationSecs?: bigint;
}

function serializeVideoContentSearchQnaAnchorSetFeatures(data: any): VideoContentSearchQnaAnchorSetFeatures {
  return {
    ...data,
    spanDurationSecs: data["spanDurationSecs"] !== undefined ? String(data["spanDurationSecs"]) : undefined,
  };
}

function deserializeVideoContentSearchQnaAnchorSetFeatures(data: any): VideoContentSearchQnaAnchorSetFeatures {
  return {
    ...data,
    spanDurationSecs: data["spanDurationSecs"] !== undefined ? BigInt(data["spanDurationSecs"]) : undefined,
  };
}

/**
 * Rankembed neighbor neighbor features for the candidate query.
 */
export interface VideoContentSearchRankEmbedNearestNeighborsFeatures {
  /**
   * Rankembed similarity between the rankembed neighbor and the video anchor.
   */
  anchorReSimilarity?: number;
  /**
   * Rankembed similarity between the rankembed neighbor and the top navboost
   * query of the video.
   */
  navQueryReSimilarity?: number;
  /**
   * Rankembed similarity between the rankembed neighbor and the original query
   * candidate.
   */
  reSimilarity?: number;
}

/**
 * Saft named-entities info for a given topic.
 */
export interface VideoContentSearchSaftEntityInfo {
  /**
   * Representative canonical name for the entity.
   */
  canonicalEntityName?: string;
  /**
   * Score indicating the saliency (centrality) of this entity to the
   * original_text.
   */
  entitySalience?: number;
  /**
   * The type name, like "/saft/person", "/saft/art". See README.entity-types
   * for the inventory of SAFT type tags.
   */
  entityTypeName?: string;
  /**
   * Representative entity name mention extracted from original_text.
   */
  mentionText?: string;
  /**
   * SAFT Mention type.
   */
  mentionType?:  | "NAM" | "NOM" | "PRE" | "PRO" | "CMC" | "NRP" | "VRB" | "IMP";
  /**
   * Freebase MID for entity if this the saft entity corresponds to a Webref KG
   * mid. This field is not always populated and is taken from FREEBASE_MID mid
   * in EntityProfile in the saft entity annotation.
   */
  mid?: string;
  /**
   * The original input text (e.g. the anchor text) where the saft entity
   * annotation was run on.
   */
  originalText?: string;
}

/**
 * Features for an individual Shopping Opinions Anchor. This file is used for
 * video anchor use case. Next Id: 34
 */
export interface VideoContentSearchShoppingOpinionsAnchorFeatures {
  /**
   * The anchor label.
   */
  anchorLabel?: string;
  /**
   * The first anchor_label mention position (word index, 0-based). It is
   * computed from the snippet_sub_segment if exists. Otherwise it is computed
   * from the snippet. It is not populated if there is no such mention.
   */
  anchorLabelFirstMentionPos?: number;
  /**
   * The sentiment score of the anchor label, with range: [-1, 1]. If using
   * Lumin Pro/Con tags as the anchor labels, the "Pro" Lumin tag will have a
   * score of 1 and Con Lumin tag will have a score of -1.
   */
  anchorLabelSentiment?: number;
  /**
   * The number of times words in anchor label (that is not a stopword) being
   * mentioned in the snippet.
   */
  anchorLabelWordsMentions?: number;
  /**
   * The smaller number of anchor_label_first_mention_pos and
   * lumin_aspect_first_mention_pos.
   */
  anchorOrAspectFirstMentionPos?: number;
  /**
   * The number of times words in anchor label or Lumin aspect (that is not a
   * stopword) being mentioned in the snippet. If a word exists in both anchor
   * label and Lumin aspect, it shall be only counted once for a mention in the
   * snippet.
   */
  anchorOrAspectWordsMentions?: number;
  /**
   * Product aspect being discussed by this Shopping Opinions.
   */
  aspect?: VideoContentSearchAspect;
  /**
   * The asr with sentence break that was used for pro/con extraction.
   */
  asrForProConExtraction?: string;
  /**
   * The Babel similarity score between the snippet and the anchor label.
   */
  babelSimilarityScore?: number;
  /**
   * The classification score of the anchor being a con opinion.
   */
  conScore?: number;
  /**
   * The score from the Grampus model if the pro/con is extracted by Grampus.
   */
  grampusScore?: number;
  /**
   * Whether the anchor is classified as a con opinion.
   */
  isCon?: boolean;
  /**
   * Whether the anchor is classified as a pro opinion.
   */
  isPro?: boolean;
  /**
   * True if the anchor is considered as pro or con when extracted from MUM.
   */
  isProConWhenExtractedFromMum?: boolean;
  /**
   * The lumin aspect of the Pro/Con Lumin tag. e.g. "weight".
   */
  luminAspect?: string;
  /**
   * The first Lumin aspect mention position (word index, 0-based). It is
   * computed from the snippet_sub_segment if exists. Otherwise it is computed
   * from the snippet. It is not populated if there is no such mention.
   */
  luminAspectFirstMentionPos?: number;
  /**
   * The number of times words in Lumin aspect (that is not a stopword) being
   * mentioned in the snippet.
   */
  luminAspectWordsMentions?: number;
  /**
   * The Lumin model score for the anchor label against the segment.
   */
  luminScore?: number;
  /**
   * The product aspect of the pro/con generated using the MUM model.
   */
  mumProductAspect?: string;
  /**
   * The score from the MUM model if the pro/con anchor is extracted by MUM.
   */
  mumScore?: number;
  /**
   * Scores from Opinions Dolphin scorer. Opinions Dolphin scorer is built by
   * finetuning the Dolphin-based Video Anchor Unified Scorer V2 on the Opinions
   * anchors ratings. It outputs two scores, which are optimized for
   * descriptiveness and usefulness ratings respectively.
   * 'descriptiveness_score' measures how well the anchor label describes the
   * video section. 'usefulness_score' measures how useful the anchor label is
   * for jumping to an important section in the video.
   * go/vs-opinions-migration-report
   */
  opinionsDolphinDescriptivenessScore?: number;
  opinionsDolphinUsefulnessScore?: number;
  /**
   * The product name from title extracted by the grampus model.
   */
  productNameFromTitle?: string;
  /**
   * The classification score of the anchor being a pro opinion.
   */
  proScore?: number;
  /**
   * The question used to score this video segment.
   */
  question?: string;
  /**
   * The ASR for the selected segment window.
   */
  snippet?: string;
  /**
   * The QA model score for the selected segment window against the question.
   */
  snippetQaScore?: number;
  /**
   * The go/scarlett sentiment score of the selected segment window. Positive
   * score represents positive sentiment. Negative score represents negative
   * sentiment.
   */
  snippetSentimentScore?: number;
  /**
   * The ASR for the best matched sub segment inside the selected segment.
   */
  snippetSubSegment?: string;
  /**
   * The QA model score for the best sub segment against the question.
   */
  snippetSubSegmentQaScore?: number;
  /**
   * The go/scarlett sentiment score of the best matched sub segment. Positive
   * score represents positive sentiment. Negative score represents negative
   * sentiment.
   */
  snippetSubSegmentSentimentScore?: number;
  /**
   * The number of words in the ASR for the best matched sub segment.
   */
  snippetSubSegmentWordCount?: number;
  /**
   * The number of words in the ASR for the selected segment window.
   */
  snippetWordCount?: number;
}

export interface VideoContentSearchSimilarityMatchInfo {
  /**
   * The timestamp of when the first token in the token sequence is spoken in
   * the video.
   */
  instructionStartMs?: number;
  /**
   * The instruction step text coming from the web document. Currently only
   * populated for best_description_and_instruction_anchors_match_info.
   */
  instructionText?: string;
  /**
   * The reference text used for matching against token_sequence (e.g.
   * description anchor text or instruction step text).
   */
  referenceText?: string;
  /**
   * The timestamp of when the reference text is pointing in the video (e.g.
   * this is the description anchor timestamp when reference_text is description
   * anchor. For instruction step used as the reference, no timestamps exists
   * and thus this field is not populated).
   */
  referenceTextTimeMs?: number;
  /**
   * Similarity scorer name.
   */
  scoringMethodName?: string;
  /**
   * The similarity score given by the scoring method specified by the message
   * scoring_method_name.
   */
  similarityScore?: number;
  /**
   * The index of the step in HowToInstructions that this token_sequence
   * corresponds to.
   */
  stepIndex?: number;
  /**
   * The matched token sequence text in ASR.
   */
  tokenSequence?: string;
  /**
   * The length of the tokens in the token sequence.
   */
  tokenSequenceLength?: number;
  /**
   * The token offset of the matched token sequence from the beginning of the
   * document.
   */
  tokenStartPos?: number;
}

export interface VideoContentSearchSpanDolphinFeatures {
  /**
   * The text passage from ASR.
   */
  passage?: string;
  /**
   * The title of the video.
   */
  title?: string;
}

export interface VideoContentSearchSpanDolphinScores {
  /**
   * The span candidates extracted from the list of span tokens. Each token is
   * added to a span if its score is above a certain threshold.
   */
  spanCandidate?: VideoContentSearchSpanDolphinScoresSpanCandidate[];
  /**
   * The token-score pairs for the passage.
   */
  spanToken?: VideoContentSearchSpanDolphinScoresSpanToken[];
}

function serializeVideoContentSearchSpanDolphinScores(data: any): VideoContentSearchSpanDolphinScores {
  return {
    ...data,
    spanCandidate: data["spanCandidate"] !== undefined ? data["spanCandidate"].map((item: any) => (serializeVideoContentSearchSpanDolphinScoresSpanCandidate(item))) : undefined,
    spanToken: data["spanToken"] !== undefined ? data["spanToken"].map((item: any) => (serializeVideoContentSearchSpanDolphinScoresSpanToken(item))) : undefined,
  };
}

function deserializeVideoContentSearchSpanDolphinScores(data: any): VideoContentSearchSpanDolphinScores {
  return {
    ...data,
    spanCandidate: data["spanCandidate"] !== undefined ? data["spanCandidate"].map((item: any) => (deserializeVideoContentSearchSpanDolphinScoresSpanCandidate(item))) : undefined,
    spanToken: data["spanToken"] !== undefined ? data["spanToken"].map((item: any) => (deserializeVideoContentSearchSpanDolphinScoresSpanToken(item))) : undefined,
  };
}

export interface VideoContentSearchSpanDolphinScoresSpanCandidate {
  /**
   * A summary of the token asr_confidence scores that make up the candidate.
   */
  asrConfidenceStats?: VideoContentSearchMetricStats;
  /**
   * A summary of the token scores that make up the candidate.
   */
  scoreStats?: VideoContentSearchMetricStats;
  /**
   * The passage text from which this span candidate belongs to. In case of
   * description spans, this field stores the sentence containing the span
   * candidate where the sentence is a subset of the passage used for generating
   * the span candidate.
   */
  sourcePassage?: string;
  /**
   * The span candidate text.
   */
  text?: string;
  /**
   * The start time for the span candidate.
   */
  timeMs?: bigint;
}

function serializeVideoContentSearchSpanDolphinScoresSpanCandidate(data: any): VideoContentSearchSpanDolphinScoresSpanCandidate {
  return {
    ...data,
    timeMs: data["timeMs"] !== undefined ? String(data["timeMs"]) : undefined,
  };
}

function deserializeVideoContentSearchSpanDolphinScoresSpanCandidate(data: any): VideoContentSearchSpanDolphinScoresSpanCandidate {
  return {
    ...data,
    timeMs: data["timeMs"] !== undefined ? BigInt(data["timeMs"]) : undefined,
  };
}

export interface VideoContentSearchSpanDolphinScoresSpanToken {
  /**
   * The ASR confidence for the token, if available.
   */
  asrConfidence?: number;
  /**
   * Whether or not this token is the first token in a sentence.
   */
  isSentenceStart?: boolean;
  /**
   * A score correlated with the probability that the token is part of a span
   * candidate.
   */
  score?: number;
  /**
   * The token text.
   */
  text?: string;
  /**
   * The start time of the passage with this token.
   */
  timeMs?: bigint;
}

function serializeVideoContentSearchSpanDolphinScoresSpanToken(data: any): VideoContentSearchSpanDolphinScoresSpanToken {
  return {
    ...data,
    timeMs: data["timeMs"] !== undefined ? String(data["timeMs"]) : undefined,
  };
}

function deserializeVideoContentSearchSpanDolphinScoresSpanToken(data: any): VideoContentSearchSpanDolphinScoresSpanToken {
  return {
    ...data,
    timeMs: data["timeMs"] !== undefined ? BigInt(data["timeMs"]) : undefined,
  };
}

/**
 * Features for a set of Sports Key Moments (SKM) Anchors. Each instance of
 * this object should be associated with a VideoAnchorSets object. Next ID: 3
 */
export interface VideoContentSearchSportsKeyMomentsAnchorSetFeatures {
  /**
   * The Prefilter classification label associated with the video that contains
   * the VideoAnchorSets this object is asociated with. E.g. "basketball".
   */
  prefilterClassificationLabel?: string;
  /**
   * Version of the underlying TensorFlow model.
   */
  tensorflowModelVersion?: string;
}

export interface VideoContentSearchTextMatchInfo {
  /**
   * The time gap of the matched_time_ms from the predicted timestamp of when
   * this anchor should appear in the video.
   */
  durationToPredictedTimeMs?: bigint;
  /**
   * The start token offset from the beginning of ASR where matched_asr_text
   * starts.
   */
  matchedAsrStartPos?: number;
  /**
   * The ASR text that was a candidate match for the list anchor.
   */
  matchedAsrText?: string;
  /**
   * The timestamp of the matched ASR in the video in milliseconds.
   */
  matchedAsrTimeMs?: bigint;
  /**
   * The ratio of the matched_asr_time_ms over the total duration of the video.
   */
  matchedAsrTimeRatio?: number;
  /**
   * The number of tokens in matched_asr_text
   */
  matchedAsrTokenCount?: number;
  /**
   * The ratio of the video description item index this match corresponds to
   * over the total number of list description items for the video.
   */
  matchedDescriptionItemIndexRatio?: number;
  /**
   * The video description text matched with the ASR that's used as the anchor
   * label.
   */
  matchedDescriptionText?: string;
  /**
   * The number of tokens in matched_description_text.
   */
  matchedDescriptionTokenCount?: number;
  /**
   * The float similarty score from the anchor label to matched_asr_text.
   */
  matchScore?: number;
}

function serializeVideoContentSearchTextMatchInfo(data: any): VideoContentSearchTextMatchInfo {
  return {
    ...data,
    durationToPredictedTimeMs: data["durationToPredictedTimeMs"] !== undefined ? String(data["durationToPredictedTimeMs"]) : undefined,
    matchedAsrTimeMs: data["matchedAsrTimeMs"] !== undefined ? String(data["matchedAsrTimeMs"]) : undefined,
  };
}

function deserializeVideoContentSearchTextMatchInfo(data: any): VideoContentSearchTextMatchInfo {
  return {
    ...data,
    durationToPredictedTimeMs: data["durationToPredictedTimeMs"] !== undefined ? BigInt(data["durationToPredictedTimeMs"]) : undefined,
    matchedAsrTimeMs: data["matchedAsrTimeMs"] !== undefined ? BigInt(data["matchedAsrTimeMs"]) : undefined,
  };
}

export interface VideoContentSearchTextSimilarityFeatures {
  /**
   * The hypothesis text that was used for the token overlap calculation.
   */
  hypothesisText?: string;
  /**
   * The time in ms for the hypothesis_text.
   */
  hypothesisTextTime?: bigint;
  referenceText?: string;
  /**
   * Similarity scorer name.
   */
  scoringMethodName?: string;
  /**
   * The similarity score given by the scoring method specified by the message
   * scoring_method_name.
   */
  similarityScore?: number;
  /**
   * Token by token matching stats. Exact matched token count.
   */
  tokenMatchCount?: number;
  /**
   * The token_overlap_count divided by the number of tokens in the hypothesis
   * text.
   */
  tokenMatchPercent?: number;
  /**
   * Word by word alignment.
   */
  wordAlignment?: VideoContentSearchTokenAlignment[];
}

function serializeVideoContentSearchTextSimilarityFeatures(data: any): VideoContentSearchTextSimilarityFeatures {
  return {
    ...data,
    hypothesisTextTime: data["hypothesisTextTime"] !== undefined ? String(data["hypothesisTextTime"]) : undefined,
  };
}

function deserializeVideoContentSearchTextSimilarityFeatures(data: any): VideoContentSearchTextSimilarityFeatures {
  return {
    ...data,
    hypothesisTextTime: data["hypothesisTextTime"] !== undefined ? BigInt(data["hypothesisTextTime"]) : undefined,
  };
}

/**
 * Token by token mapping between hypothesis text and reference text.
 */
export interface VideoContentSearchTokenAlignment {
  /**
   * Index of the token in hypothesis text.
   */
  hypothesisIndex?: number;
  /**
   * Token in hypothesis.
   */
  hypothesisToken?: string;
  /**
   * Index of the word in reference.
   */
  referenceIndex?: number;
  /**
   * Token in label.
   */
  referenceToken?: string;
  /**
   * Whether it's a perfect match.
   */
  tokenIsMatched?: boolean;
}

/**
 * Token level timing information for ASR spans. This is expected to be
 * extracted from PseudoVideoData in the CDoc. Next ID: 5
 */
export interface VideoContentSearchTokenTimingInfo {
  /**
   * Generated from th PseudoVideoData Timestamp Confidence field, which is
   * quantized values in range 0-127. To convert to range 0-1 this field divides
   * the PseudoVideoData Timestamp Confidence field by 127.
   */
  confidence?: number;
  durationMs?: bigint;
  startMs?: bigint;
  /**
   * Should be a single token.
   */
  text?: string;
}

function serializeVideoContentSearchTokenTimingInfo(data: any): VideoContentSearchTokenTimingInfo {
  return {
    ...data,
    durationMs: data["durationMs"] !== undefined ? String(data["durationMs"]) : undefined,
    startMs: data["startMs"] !== undefined ? String(data["startMs"]) : undefined,
  };
}

function deserializeVideoContentSearchTokenTimingInfo(data: any): VideoContentSearchTokenTimingInfo {
  return {
    ...data,
    durationMs: data["durationMs"] !== undefined ? BigInt(data["durationMs"]) : undefined,
    startMs: data["startMs"] !== undefined ? BigInt(data["startMs"]) : undefined,
  };
}

/**
 * Video level info for online pipeline usage. For example: skip pattern as
 * defined in https://schema.org/SeekToAction.
 */
export interface VideoContentSearchVideoActions {
  /**
   * startOffset_input name as defined in https://schema.org/SeekToAction
   */
  skipPatternStartOffsetInput?: string;
  /**
   * Skip to time pattern as defined in https://schema.org/SeekToAction
   */
  skipToTimePattern?: string;
}

/**
 * Next ID: 23
 */
export interface VideoContentSearchVideoAnchor {
  /**
   * The score indicating anchor confidence.
   */
  anchorScore?: number;
  /**
   * Specifies the type of the anchor.
   */
  anchorType?:  | "UNKNOWN" | "DESCRIPTION_ANCHOR" | "LIST" | "OCR" | "LIST_ENTITY" | "CAPTION_ENTITY" | "KEY_MOMENT" | "QUESTION_AND_ANSWER" | "MARKUP" | "OCR_ASR" | "ASR_SPAN" | "INSTRUCTION" | "DESCRIPTION_SPAN" | "EXPERIMENTAL_MORE_VIDEO_ANSWERS" | "SHOPPING_OPINIONS" | "GENERATED_QUERY" | "HIGHLIGHTED_SNIPPET" | "SHORT_TOPIC_HEADING_GROUP" | "SHOPPING_ASR_SPAN" | "RADISH_QA" | "GENERATIVE_ASR" | "ASR_TRANSCRIPT" | "COMMENT" | "GENERATIVE_ASR_V2" | "SUMMARY_SEGMENT" | "OCR_EDU" | "ASR_SPAN_EDU" | "GENERATIVE_ASR_I18N";
  /**
   * Context text from ASR of long duration, used for longT5 models.
   */
  contextText?: string;
  /**
   * When set, this is the link that should be used when clicking on a video
   * anchor. This should jump to the given time in the video.
   */
  destinationUrl?: string;
  /**
   * The duration of the video anchor in milliseconds.
   */
  duration?: bigint;
  /**
   * The score indicating the usefulness of the entity identified by 'mid'.
   */
  entityScore?: number;
  /**
   * If is_filtered is true, this field illustrates the reasons.
   */
  filterReason?:  | "UNKNOWN_REASON" | "DISPLAY_SIZE_LIMIT" | "THUMBNAIL_MISSING" | "THUMBNAIL_UNSAFE" | "LABEL_UNSAFE" | "TITLE_DUPLICATE_AND_CLOSE_TO_START" | "POLICY" | "INVALID_TIMESTAMP" | "NO_ANCHOR_DESTINATION_URL" | "LABEL_WITH_RESTRICTED_ENTITIES" | "LABEL_WITH_PERSON_NAMES" | "LABEL_IN_VIDEO_WITH_RESTRICTED_PETACATS" | "LABEL_REMOVED_BY_GENERAL_SAFE_SEARCH" | "LABEL_REMOVED_BY_FRINGE_SAFE_SEARCH" | "LABEL_REMOVED_BY_OFFENSIVE_SAFE_SEARCH" | "LABEL_IN_VIDEO_GENERAL_SAFE_SEARCH"[];
  /**
   * If true, the anchor is filtered and not served online.
   */
  isFiltered?: boolean;
  /**
   * Convenience field that consolidates signals for whether this label is
   * safe.
   */
  isSafe?: boolean;
  /**
   * whether this label is bad by go/scuti
   */
  isScutiBad?: boolean;
  /**
   * The text label of the video anchor.
   */
  label?: string;
  /**
   * The score indicating label confidence.
   */
  labelScore?: number;
  /**
   * The mid of the video anchor.
   */
  mid?: string;
  /**
   * Specifies named enitities the label has.
   */
  namedEntity?: VideoContentSearchNamedEntity[];
  /**
   * The precision for which the anchor should trigger. For example, if the
   * desired precision is 95%, anchors with precision_score < 0.95 should be
   * removed.
   */
  precisionScore?: number;
  /**
   * Additional scoring info used for debugging.
   */
  scoreInfo?: VideoContentSearchVideoAnchorScoreInfo;
  /**
   * Visual tokens for the anchor. Eg. starbust feature vectors for several
   * frames concatenated together.
   */
  starburstFeatures?: VideoContentSearchVisualFeatures;
  /**
   * Data about the thumbnail to display for this anchor.
   */
  thumbnail?: VideoContentSearchAnchorThumbnail;
  /**
   * The url for a frame to display for this anchor.
   */
  thumbnailUrl?: string;
  /**
   * The time stamp of the video anchor in milliseconds.
   */
  time?: bigint;
  /**
   * Timing info for each token in the anchor label.
   */
  tokenTimingInfo?: VideoContentSearchTokenTimingInfo[];
}

function serializeVideoContentSearchVideoAnchor(data: any): VideoContentSearchVideoAnchor {
  return {
    ...data,
    duration: data["duration"] !== undefined ? String(data["duration"]) : undefined,
    scoreInfo: data["scoreInfo"] !== undefined ? serializeVideoContentSearchVideoAnchorScoreInfo(data["scoreInfo"]) : undefined,
    thumbnail: data["thumbnail"] !== undefined ? serializeVideoContentSearchAnchorThumbnail(data["thumbnail"]) : undefined,
    time: data["time"] !== undefined ? String(data["time"]) : undefined,
    tokenTimingInfo: data["tokenTimingInfo"] !== undefined ? data["tokenTimingInfo"].map((item: any) => (serializeVideoContentSearchTokenTimingInfo(item))) : undefined,
  };
}

function deserializeVideoContentSearchVideoAnchor(data: any): VideoContentSearchVideoAnchor {
  return {
    ...data,
    duration: data["duration"] !== undefined ? BigInt(data["duration"]) : undefined,
    scoreInfo: data["scoreInfo"] !== undefined ? deserializeVideoContentSearchVideoAnchorScoreInfo(data["scoreInfo"]) : undefined,
    thumbnail: data["thumbnail"] !== undefined ? deserializeVideoContentSearchAnchorThumbnail(data["thumbnail"]) : undefined,
    time: data["time"] !== undefined ? BigInt(data["time"]) : undefined,
    tokenTimingInfo: data["tokenTimingInfo"] !== undefined ? data["tokenTimingInfo"].map((item: any) => (deserializeVideoContentSearchTokenTimingInfo(item))) : undefined,
  };
}

/**
 * Aggregated rating score, used in training pipeline, etc.
 */
export interface VideoContentSearchVideoAnchorRatingScore {
  /**
   * Average score of bookmark usefulness.
   */
  averageBookmarkUsefulness?: number;
  /**
   * Average score of description quality.
   */
  averageDescriptionQuality?: number;
  /**
   * Furball URL(s) of the rating score (may have been rated more than once)
   */
  furballUrl?: string[];
}

/**
 * A video can have a list of text anchors, which have different anchor types.
 * Next ID: 15
 */
export interface VideoContentSearchVideoAnchors {
  anchorType?:  | "UNKNOWN" | "DESCRIPTION_ANCHOR" | "LIST" | "OCR" | "LIST_ENTITY" | "CAPTION_ENTITY" | "KEY_MOMENT" | "QUESTION_AND_ANSWER" | "MARKUP" | "OCR_ASR" | "ASR_SPAN" | "INSTRUCTION" | "DESCRIPTION_SPAN" | "EXPERIMENTAL_MORE_VIDEO_ANSWERS" | "SHOPPING_OPINIONS" | "GENERATED_QUERY" | "HIGHLIGHTED_SNIPPET" | "SHORT_TOPIC_HEADING_GROUP" | "SHOPPING_ASR_SPAN" | "RADISH_QA" | "GENERATIVE_ASR" | "ASR_TRANSCRIPT" | "COMMENT" | "GENERATIVE_ASR_V2" | "SUMMARY_SEGMENT" | "OCR_EDU" | "ASR_SPAN_EDU" | "GENERATIVE_ASR_I18N";
  /**
   * The list of entity groups derived from the caption entities.
   */
  entityGroupInfo?: VideoContentSearchEntityGroupInfo;
  /**
   * Same as above, but used for experimenting with new models.
   */
  experimentalPredictedQuerylessTocUsefulness?: number;
  /**
   * If is_filtered is true, this field illustrates the reasons.
   */
  filterReason?:  | "UNKNOWN_REASON" | "DISPLAY_SIZE_LIMIT" | "THUMBNAIL_MISSING" | "THUMBNAIL_UNSAFE" | "LABEL_UNSAFE" | "TITLE_DUPLICATE_AND_CLOSE_TO_START" | "POLICY" | "INVALID_TIMESTAMP" | "NO_ANCHOR_DESTINATION_URL" | "LABEL_WITH_RESTRICTED_ENTITIES" | "LABEL_WITH_PERSON_NAMES" | "LABEL_IN_VIDEO_WITH_RESTRICTED_PETACATS" | "LABEL_REMOVED_BY_GENERAL_SAFE_SEARCH" | "LABEL_REMOVED_BY_FRINGE_SAFE_SEARCH" | "LABEL_REMOVED_BY_OFFENSIVE_SAFE_SEARCH" | "LABEL_IN_VIDEO_GENERAL_SAFE_SEARCH"[];
  /**
   * If true, the anchor set is filtered and not served online.
   */
  isFiltered?: boolean;
  /**
   * The anchor sources being used to generate this merged anchors. This field
   * is filled only when this is a merged anchor.
   */
  mergedAnchorsSources?:  | "UNKNOWN" | "DESCRIPTION_ANCHOR" | "LIST" | "OCR" | "LIST_ENTITY" | "CAPTION_ENTITY" | "KEY_MOMENT" | "QUESTION_AND_ANSWER" | "MARKUP" | "OCR_ASR" | "ASR_SPAN" | "INSTRUCTION" | "DESCRIPTION_SPAN" | "EXPERIMENTAL_MORE_VIDEO_ANSWERS" | "SHOPPING_OPINIONS" | "GENERATED_QUERY" | "HIGHLIGHTED_SNIPPET" | "SHORT_TOPIC_HEADING_GROUP" | "SHOPPING_ASR_SPAN" | "RADISH_QA" | "GENERATIVE_ASR" | "ASR_TRANSCRIPT" | "COMMENT" | "GENERATIVE_ASR_V2" | "SUMMARY_SEGMENT" | "OCR_EDU" | "ASR_SPAN_EDU" | "GENERATIVE_ASR_I18N"[];
  /**
   * The score that predicts the usefulness of this anchor set on the Huh table
   * of contents eval without considering the query.
   */
  predictedQuerylessTocUsefulness?: number;
  /**
   * The quality of the anchor set.
   */
  score?: number;
  /**
   * Additional scoring info used for debugging.
   */
  scoreInfo?: VideoContentSearchVideoAnchorsScoreInfo;
  /**
   * Whether or not thumbnails should be displayed when serving anchors.
   */
  shouldServeThumbnails?: boolean;
  /**
   * This field indicates that the thumbnail should be hidden but is forced to
   * show.
   */
  thumbnailForced?: boolean;
  /**
   * Information about the set of thumbnails.
   */
  thumbnailSetInfo?: VideoContentSearchAnchorsThumbnailInfo;
  videoAnchor?: VideoContentSearchVideoAnchor[];
  /**
   * Information about the video's introduction segment.
   */
  videoIntroduction?: VideoContentSearchVideoIntroduction;
}

function serializeVideoContentSearchVideoAnchors(data: any): VideoContentSearchVideoAnchors {
  return {
    ...data,
    scoreInfo: data["scoreInfo"] !== undefined ? serializeVideoContentSearchVideoAnchorsScoreInfo(data["scoreInfo"]) : undefined,
    videoAnchor: data["videoAnchor"] !== undefined ? data["videoAnchor"].map((item: any) => (serializeVideoContentSearchVideoAnchor(item))) : undefined,
    videoIntroduction: data["videoIntroduction"] !== undefined ? serializeVideoContentSearchVideoIntroduction(data["videoIntroduction"]) : undefined,
  };
}

function deserializeVideoContentSearchVideoAnchors(data: any): VideoContentSearchVideoAnchors {
  return {
    ...data,
    scoreInfo: data["scoreInfo"] !== undefined ? deserializeVideoContentSearchVideoAnchorsScoreInfo(data["scoreInfo"]) : undefined,
    videoAnchor: data["videoAnchor"] !== undefined ? data["videoAnchor"].map((item: any) => (deserializeVideoContentSearchVideoAnchor(item))) : undefined,
    videoIntroduction: data["videoIntroduction"] !== undefined ? deserializeVideoContentSearchVideoIntroduction(data["videoIntroduction"]) : undefined,
  };
}

/**
 * Message to contain scoring / debugging information. If you want to add
 * information which is not directly used in the final VideoAnchor data, it
 * should be put here. Next ID: 27
 */
export interface VideoContentSearchVideoAnchorScoreInfo {
  /**
   * Common features for any anchor types.
   */
  anchorCommonFeatureSet?: VideoContentSearchAnchorCommonFeatureSet;
  /**
   * Additional attachments which extend MessageSet.
   */
  attachments?: Proto2BridgeMessageSet;
  /**
   * The path to the particular babel checkpoint
   */
  babelCheckpointPath?: string;
  /**
   * Training features and debug info for caption entity anchors.
   */
  captionEntityAnchorFeatures?: VideoContentSearchCaptionEntityAnchorFeatures;
  /**
   * Features for caption span anchors for use in training.
   */
  captionSpanAnchorFeatures?: VideoContentSearchCaptionSpanAnchorFeatures;
  /**
   * Description anchor features for use in training.
   */
  descriptionAnchorFeatures?: VideoContentSearchDescriptionAnchorFeatures;
  /**
   * Whether or not the anchor will be removed in the final proto.
   */
  filtered?: boolean;
  /**
   * A description of why the anchor was removed. This is intended for
   * debugging anchor sets which use multiple heuristics to filter anchors.
   */
  filterReason?: string[];
  /**
   * Generated predictions from generative models
   */
  generativeFeatures?: VideoContentSearchGenerativePredictionFeatures[];
  /**
   * Anchor level features for Instruction anchors.
   */
  instructionAnchorFeatures?: VideoContentSearchInstructionAnchorFeatures;
  /**
   * Training data features for Instruction anchors.
   */
  instructionTrainingDataAnchorFeatures?: VideoContentSearchInstructionTrainingDataAnchorFeatures;
  /**
   * Detected language of label
   */
  labelLanguage?: string;
  labelTransformation?: VideoContentSearchVideoAnchorScoreInfoLabelTransformation[];
  /**
   * List anchor features.
   */
  listAnchorFeatures?: VideoContentSearchListAnchorFeatures;
  /**
   * Anchor level metadata about the description anchors used to build training
   * data for list anchors.
   */
  listTrainingDataAnchorFeatures?: VideoContentSearchListTrainingDataAnchorFeatures;
  /**
   * Multimodal features for a generated topic.
   */
  multimodalTopicFeatures?: VideoContentSearchMultimodalTopicFeatures;
  /**
   * Features for a generated topic used to build training data for multimodal
   * topics.
   */
  multimodalTopicTrainingFeatures?: VideoContentSearchMultimodalTopicTrainingFeatures;
  /**
   * Normalized babel embedding of anchor.label(). If the label has more than
   * one sentences, the embedding will be the averaged normalized embedding of
   * each sentence.
   */
  normalizedBabelEmbedding?: number[];
  /**
   * OCR anchor features.
   */
  ocrAnchorFeature?: VideoContentSearchOnScreenTextFeature;
  /**
   * Anchor level metadata about the join of description anchors and OCR data
   * which is used to build training data.
   */
  ocrDescriptionTrainingDataAnchorFeatures?: VideoContentSearchOcrDescriptionTrainingDataAnchorFeatures;
  /**
   * Shopping Opinions anchor features.
   */
  opinionsAnchorFeatures?: VideoContentSearchShoppingOpinionsAnchorFeatures;
  /**
   * Q&A anchor features for use in training.
   */
  qnaAnchorFeatures?: VideoContentSearchQnaAnchorFeatures;
  /**
   * Human rating score, used for training.
   */
  ratingScore?: VideoContentSearchVideoAnchorRatingScore;
  /**
   * The output of Safe Search's MultiLabelClassifier.
   */
  safeSearchClassifierOutput?: ClassifierPornQueryMultiLabelClassifierOutput;
  /**
   * ASR matching feature for any anchor types.
   */
  textSimilarityFeatures?: VideoContentSearchTextSimilarityFeatures[];
  /**
   * Information about the thumbnail anchor.
   */
  thumbnailInfo?: VideoContentSearchAnchorThumbnailInfo;
}

function serializeVideoContentSearchVideoAnchorScoreInfo(data: any): VideoContentSearchVideoAnchorScoreInfo {
  return {
    ...data,
    anchorCommonFeatureSet: data["anchorCommonFeatureSet"] !== undefined ? serializeVideoContentSearchAnchorCommonFeatureSet(data["anchorCommonFeatureSet"]) : undefined,
    captionEntityAnchorFeatures: data["captionEntityAnchorFeatures"] !== undefined ? serializeVideoContentSearchCaptionEntityAnchorFeatures(data["captionEntityAnchorFeatures"]) : undefined,
    captionSpanAnchorFeatures: data["captionSpanAnchorFeatures"] !== undefined ? serializeVideoContentSearchCaptionSpanAnchorFeatures(data["captionSpanAnchorFeatures"]) : undefined,
    listAnchorFeatures: data["listAnchorFeatures"] !== undefined ? serializeVideoContentSearchListAnchorFeatures(data["listAnchorFeatures"]) : undefined,
    listTrainingDataAnchorFeatures: data["listTrainingDataAnchorFeatures"] !== undefined ? serializeVideoContentSearchListTrainingDataAnchorFeatures(data["listTrainingDataAnchorFeatures"]) : undefined,
    multimodalTopicFeatures: data["multimodalTopicFeatures"] !== undefined ? serializeVideoContentSearchMultimodalTopicFeatures(data["multimodalTopicFeatures"]) : undefined,
    multimodalTopicTrainingFeatures: data["multimodalTopicTrainingFeatures"] !== undefined ? serializeVideoContentSearchMultimodalTopicTrainingFeatures(data["multimodalTopicTrainingFeatures"]) : undefined,
    qnaAnchorFeatures: data["qnaAnchorFeatures"] !== undefined ? serializeVideoContentSearchQnaAnchorFeatures(data["qnaAnchorFeatures"]) : undefined,
    textSimilarityFeatures: data["textSimilarityFeatures"] !== undefined ? data["textSimilarityFeatures"].map((item: any) => (serializeVideoContentSearchTextSimilarityFeatures(item))) : undefined,
    thumbnailInfo: data["thumbnailInfo"] !== undefined ? serializeVideoContentSearchAnchorThumbnailInfo(data["thumbnailInfo"]) : undefined,
  };
}

function deserializeVideoContentSearchVideoAnchorScoreInfo(data: any): VideoContentSearchVideoAnchorScoreInfo {
  return {
    ...data,
    anchorCommonFeatureSet: data["anchorCommonFeatureSet"] !== undefined ? deserializeVideoContentSearchAnchorCommonFeatureSet(data["anchorCommonFeatureSet"]) : undefined,
    captionEntityAnchorFeatures: data["captionEntityAnchorFeatures"] !== undefined ? deserializeVideoContentSearchCaptionEntityAnchorFeatures(data["captionEntityAnchorFeatures"]) : undefined,
    captionSpanAnchorFeatures: data["captionSpanAnchorFeatures"] !== undefined ? deserializeVideoContentSearchCaptionSpanAnchorFeatures(data["captionSpanAnchorFeatures"]) : undefined,
    listAnchorFeatures: data["listAnchorFeatures"] !== undefined ? deserializeVideoContentSearchListAnchorFeatures(data["listAnchorFeatures"]) : undefined,
    listTrainingDataAnchorFeatures: data["listTrainingDataAnchorFeatures"] !== undefined ? deserializeVideoContentSearchListTrainingDataAnchorFeatures(data["listTrainingDataAnchorFeatures"]) : undefined,
    multimodalTopicFeatures: data["multimodalTopicFeatures"] !== undefined ? deserializeVideoContentSearchMultimodalTopicFeatures(data["multimodalTopicFeatures"]) : undefined,
    multimodalTopicTrainingFeatures: data["multimodalTopicTrainingFeatures"] !== undefined ? deserializeVideoContentSearchMultimodalTopicTrainingFeatures(data["multimodalTopicTrainingFeatures"]) : undefined,
    qnaAnchorFeatures: data["qnaAnchorFeatures"] !== undefined ? deserializeVideoContentSearchQnaAnchorFeatures(data["qnaAnchorFeatures"]) : undefined,
    textSimilarityFeatures: data["textSimilarityFeatures"] !== undefined ? data["textSimilarityFeatures"].map((item: any) => (deserializeVideoContentSearchTextSimilarityFeatures(item))) : undefined,
    thumbnailInfo: data["thumbnailInfo"] !== undefined ? deserializeVideoContentSearchAnchorThumbnailInfo(data["thumbnailInfo"]) : undefined,
  };
}

/**
 * Used to store the label before label cleaning or other transformations. If
 * the label goes through multiple transformations, the original_label vector
 * will include the transformations in chronological order.
 */
export interface VideoContentSearchVideoAnchorScoreInfoLabelTransformation {
  /**
   * A label for the transformation.
   */
  description?: string;
  /**
   * The label that was transformated from.
   */
  sourceLabel?: string;
}

/**
 * Aggregated set level rating score, used in training pipeline, etc.
 */
export interface VideoContentSearchVideoAnchorSetRatingScore {
  /**
   * Average score of set level description quality.
   */
  averageSetDescriptionQuality?: number;
  /**
   * Average score of how useful the set is for navigation.
   */
  averageSetNavigationUsefulness?: number;
}

/**
 * One video can have multiple types of text anchors. For example,
 * https://www.youtube.com/watch?v=Rtk0I5PVOIc has both list anchors and OCR
 * anchors.
 */
export interface VideoContentSearchVideoAnchorSets {
  videoActions?: VideoContentSearchVideoActions;
  videoAnchors?: VideoContentSearchVideoAnchors[];
  videoInfo?: VideoContentSearchVideoInfo;
  videoScoreInfo?: VideoContentSearchVideoScoreInfo;
}

function serializeVideoContentSearchVideoAnchorSets(data: any): VideoContentSearchVideoAnchorSets {
  return {
    ...data,
    videoAnchors: data["videoAnchors"] !== undefined ? data["videoAnchors"].map((item: any) => (serializeVideoContentSearchVideoAnchors(item))) : undefined,
    videoInfo: data["videoInfo"] !== undefined ? serializeVideoContentSearchVideoInfo(data["videoInfo"]) : undefined,
    videoScoreInfo: data["videoScoreInfo"] !== undefined ? serializeVideoContentSearchVideoScoreInfo(data["videoScoreInfo"]) : undefined,
  };
}

function deserializeVideoContentSearchVideoAnchorSets(data: any): VideoContentSearchVideoAnchorSets {
  return {
    ...data,
    videoAnchors: data["videoAnchors"] !== undefined ? data["videoAnchors"].map((item: any) => (deserializeVideoContentSearchVideoAnchors(item))) : undefined,
    videoInfo: data["videoInfo"] !== undefined ? deserializeVideoContentSearchVideoInfo(data["videoInfo"]) : undefined,
    videoScoreInfo: data["videoScoreInfo"] !== undefined ? deserializeVideoContentSearchVideoScoreInfo(data["videoScoreInfo"]) : undefined,
  };
}

/**
 * Message to contain scoring / debugging information. If you want to add
 * information which is not directly used in the final VideoAnchors data, it
 * should be put here. Next ID: 14
 */
export interface VideoContentSearchVideoAnchorsScoreInfo {
  /**
   * Common set-level features for any anchor types.
   */
  anchorsCommonFeatureSet?: VideoContentSearchAnchorsCommonFeatureSet;
  /**
   * Training features and debug info for caption entity anchors.
   */
  captionEntityAnchorSetFeatures?: VideoContentSearchCaptionEntityAnchorSetFeatures;
  captionSpanAnchorSetFeatures?: VideoContentSearchCaptionSpanAnchorSetFeatures;
  /**
   * Set-level features for comment anchors.
   */
  commentAnchorSetFeatures?: VideoContentSearchCommentAnchorSetFeatures;
  /**
   * Description anchor features for use in training.
   */
  descriptionAnchorSetFeatures?: VideoContentSearchDescriptionAnchorSetFeatures;
  /**
   * Whether or not the anchors will be removed in the final proto.
   */
  filtered?: boolean;
  /**
   * Set-level features for list anchors.
   */
  listAnchorSetFeatures?: VideoContentSearchListAnchorSetFeatures;
  /**
   * Set level metadata about the description anchors used to build training
   * data for List Description anchors.
   */
  listTrainingDataSetFeatures?: VideoContentSearchListTrainingDataSetFeatures;
  /**
   * OCR anchor cluster features.
   */
  ocrAnchorClusterFeature?: VideoContentSearchOnScreenTextClusterFeature;
  /**
   * Set level metadata about the join of description anchors and OCR data
   * which is used to build training data.
   */
  ocrDescriptionTrainingDataSetFeatures?: VideoContentSearchOcrDescriptionTrainingDataSetFeatures;
  /**
   * Metadata such as model versions for Q&A anchors.
   */
  qnaAnchorSetFeatures?: VideoContentSearchQnaAnchorSetFeatures;
  /**
   * Human rating score, used for training.
   */
  ratingScore?: VideoContentSearchVideoAnchorSetRatingScore;
  sportsKeyMomentsAnchorSetFeatures?: VideoContentSearchSportsKeyMomentsAnchorSetFeatures;
}

function serializeVideoContentSearchVideoAnchorsScoreInfo(data: any): VideoContentSearchVideoAnchorsScoreInfo {
  return {
    ...data,
    commentAnchorSetFeatures: data["commentAnchorSetFeatures"] !== undefined ? serializeVideoContentSearchCommentAnchorSetFeatures(data["commentAnchorSetFeatures"]) : undefined,
    qnaAnchorSetFeatures: data["qnaAnchorSetFeatures"] !== undefined ? serializeVideoContentSearchQnaAnchorSetFeatures(data["qnaAnchorSetFeatures"]) : undefined,
  };
}

function deserializeVideoContentSearchVideoAnchorsScoreInfo(data: any): VideoContentSearchVideoAnchorsScoreInfo {
  return {
    ...data,
    commentAnchorSetFeatures: data["commentAnchorSetFeatures"] !== undefined ? deserializeVideoContentSearchCommentAnchorSetFeatures(data["commentAnchorSetFeatures"]) : undefined,
    qnaAnchorSetFeatures: data["qnaAnchorSetFeatures"] !== undefined ? deserializeVideoContentSearchQnaAnchorSetFeatures(data["qnaAnchorSetFeatures"]) : undefined,
  };
}

/**
 * Contains video level features that apply to all anchor types.
 */
export interface VideoContentSearchVideoCommonFeatures {
  /**
   * The total number of anchors in all video anchor sets.
   */
  anchorCount?: number;
  /**
   * The caption data for the video transcript. The models used for unified
   * scorer. Should be a filepath that contains saved_model.pb and a variables/
   * folder
   */
  captionInfo?: VideoContentSearchCaptionInfo;
  /**
   * The model used for generating label_phrase_embedding.
   */
  labelPhraseEmbeddingModel?: string;
  unifiedScoringBertModels?: string[];
}

function serializeVideoContentSearchVideoCommonFeatures(data: any): VideoContentSearchVideoCommonFeatures {
  return {
    ...data,
    captionInfo: data["captionInfo"] !== undefined ? serializeVideoContentSearchCaptionInfo(data["captionInfo"]) : undefined,
  };
}

function deserializeVideoContentSearchVideoCommonFeatures(data: any): VideoContentSearchVideoCommonFeatures {
  return {
    ...data,
    captionInfo: data["captionInfo"] !== undefined ? deserializeVideoContentSearchCaptionInfo(data["captionInfo"]) : undefined,
  };
}

/**
 * Contains video level features for generated queries that are applied at the
 * video level.
 */
export interface VideoContentSearchVideoGeneratedQueryFeatures {
  /**
   * A description of why the video was removed. This is intended for debugging
   * generated queries that are filtered at the video level.
   */
  filterReason?: string[];
  /**
   * The total number of passages that were input to generating queries for
   * this video. This count might be bigger than the total number of anchors in
   * the video as some of the anchors might have been filtered by the pipeline.
   */
  prefilteredPassageCount?: number;
  /**
   * Entity annotations for one of the mids representing the video title. This
   * entity is either one of the blocklisted entities if at least of the
   * mentioned entities in the title belongs to the blocklisted categories, or
   * is the highest confidence entity for the title.
   */
  titleEntityAnnotations?: VideoContentSearchEntityAnnotations;
  /**
   * The total number of queries that belong to the blocklisted categories for
   * this video.
   */
  totalRestrictedQueries?: number;
}

/**
 * This message holds metadata and signals of one video. It is typically used
 * for holding debug data in tables produced by offline pipelines related to
 * video anchors. Please never populate this message into the search serving
 * stack. Next ID: 31
 */
export interface VideoContentSearchVideoInfo {
  /**
   * A hash of the video bytes used as a key to Amarna's video_metadata table.
   */
  amarnaDocid?: string;
  /**
   * Language information, extracted from
   * content_based_metadata.speech_properties.
   */
  asrLanguage?: string;
  /**
   * Craps data from the video cdoc.
   */
  crapsData?: QualityNavboostCrapsCrapsData;
  /**
   * Video description.
   */
  description?: string;
  /**
   * Language information, extracted from DocProperties.
   */
  docLanguage?: string;
  /**
   * Video duration in ms.
   */
  durationMs?: number;
  /**
   * Whether or not automatic speech recognition has been generated for this
   * video.
   */
  hasAsr?: boolean;
  /**
   * Whether or not the video has description anchors.
   */
  hasDescriptionAnchors?: boolean;
  /**
   * Convenience field that is false if any of the video's anchors have their
   * is_safe field set to false.
   */
  isSafe?: boolean;
  /**
   * Whether or not this is watchpage.
   */
  isWatchpage?: boolean;
  /**
   * Navqueries for the video.
   */
  navqueries?: string[];
  /**
   * NSR for the video page document.
   */
  nsr?: number;
  /**
   * Number of views.
   */
  numViews?: bigint;
  /**
   * ASR with timing info for each token copied from
   * doc_videos.content_based_metadata.transcript_asr.
   */
  pseudoVideoData?: PseudoVideoData;
  /**
   * The Saft document generated from the anchor labels.
   */
  saftDoc?: NlpSaftDocument;
  /**
   * The transcript used to generate the Saft doc.
   */
  saftTranscript?: string;
  /**
   * Salient term set from the document. This message contains a lot of data
   * and dependencies, so sub-messages are disabled in model evaluation in
   * scorer.
   */
  salientTermSet?: QualitySalientTermsSalientTermSet;
  /**
   * The subindexid from the cdoc. Stored as an int to avoid a cyclical
   * dependency. Should be convertible to CompositeDoc.SubIndexType.
   */
  subindexid?: number[];
  /**
   * Video title.
   */
  title?: string;
  /**
   * Video title language Language information, set automatically by the SAFT
   * LangID.
   */
  titleLanguage?: string;
  /**
   * Transcript annotations that include information about the ASR including
   * timing and entity mentions.
   */
  transcriptAnnotations?: QualityWebanswersTranscriptAnnotations;
  /**
   * Number of unique visits in Chrome.
   */
  uniqueChromeViews?: number;
  /**
   * Document url.
   */
  url?: string;
  /**
   * Top petacat verticals of the video produced by indexing/ml/vertical,
   * sorted in descending order by vertical confidence.
   */
  verticalItem?: IndexingMlVerticalVerticalItem[];
  /**
   * Genre of the video from the page metadata. Concatenate all with a comma
   * separator if there are multiple genres.
   */
  videoGenre?: string;
  videoType?:  | "UNKNOWN" | "LISTICLE" | "INSTRUCTION" | "SPORTS" | "SINGLE_PRODUCT_RESEARCH" | "EDU";
  /**
   * Video url. Note that VideoInfo::url is a page url that has this video,
   * while this is a video file url.
   */
  videoUrl?: string;
  /**
   * Represents a collection of entities returned by the WebRef service. This
   * message contains a lot of data and dependencies, so sub-messages are
   * disabled in model evaluation in scorer.
   */
  webrefEntities?: RepositoryWebrefWebrefEntities;
}

function serializeVideoContentSearchVideoInfo(data: any): VideoContentSearchVideoInfo {
  return {
    ...data,
    crapsData: data["crapsData"] !== undefined ? serializeQualityNavboostCrapsCrapsData(data["crapsData"]) : undefined,
    numViews: data["numViews"] !== undefined ? String(data["numViews"]) : undefined,
    pseudoVideoData: data["pseudoVideoData"] !== undefined ? serializePseudoVideoData(data["pseudoVideoData"]) : undefined,
    saftDoc: data["saftDoc"] !== undefined ? serializeNlpSaftDocument(data["saftDoc"]) : undefined,
    transcriptAnnotations: data["transcriptAnnotations"] !== undefined ? serializeQualityWebanswersTranscriptAnnotations(data["transcriptAnnotations"]) : undefined,
    webrefEntities: data["webrefEntities"] !== undefined ? serializeRepositoryWebrefWebrefEntities(data["webrefEntities"]) : undefined,
  };
}

function deserializeVideoContentSearchVideoInfo(data: any): VideoContentSearchVideoInfo {
  return {
    ...data,
    crapsData: data["crapsData"] !== undefined ? deserializeQualityNavboostCrapsCrapsData(data["crapsData"]) : undefined,
    numViews: data["numViews"] !== undefined ? BigInt(data["numViews"]) : undefined,
    pseudoVideoData: data["pseudoVideoData"] !== undefined ? deserializePseudoVideoData(data["pseudoVideoData"]) : undefined,
    saftDoc: data["saftDoc"] !== undefined ? deserializeNlpSaftDocument(data["saftDoc"]) : undefined,
    transcriptAnnotations: data["transcriptAnnotations"] !== undefined ? deserializeQualityWebanswersTranscriptAnnotations(data["transcriptAnnotations"]) : undefined,
    webrefEntities: data["webrefEntities"] !== undefined ? deserializeRepositoryWebrefWebrefEntities(data["webrefEntities"]) : undefined,
  };
}

/**
 * Specifies whether a video has an introduction part that can be skipped. An
 * introduction is the beginning part of a video that can be safely skipped
 * without impacting user's understanding of the overall video content.
 */
export interface VideoContentSearchVideoIntroduction {
  /**
   * If set to true, it means the video has an introduction spanning from
   * intro_start_ms to intro_end_ms.
   */
  hasIntro?: boolean;
  /**
   * Timestamp of the end of an introduction. Will only be set if has_intro is
   * true. Indicates video may be skipped to this timestamp with minimal impact
   * on understanding the overall video contents.
   */
  introEndMs?: bigint;
  /**
   * Timestamp of the beginning of an introduction. Will only be set if
   * has_intro is true. This value may be nonzero.
   */
  introStartMs?: bigint;
}

function serializeVideoContentSearchVideoIntroduction(data: any): VideoContentSearchVideoIntroduction {
  return {
    ...data,
    introEndMs: data["introEndMs"] !== undefined ? String(data["introEndMs"]) : undefined,
    introStartMs: data["introStartMs"] !== undefined ? String(data["introStartMs"]) : undefined,
  };
}

function deserializeVideoContentSearchVideoIntroduction(data: any): VideoContentSearchVideoIntroduction {
  return {
    ...data,
    introEndMs: data["introEndMs"] !== undefined ? BigInt(data["introEndMs"]) : undefined,
    introStartMs: data["introStartMs"] !== undefined ? BigInt(data["introStartMs"]) : undefined,
  };
}

/**
 * Video-level Multimodal features for generated topics. Next ID: 2
 */
export interface VideoContentSearchVideoMultimodalTopicFeatures {
  /**
   * Starburst vectors. Sorted by timestamp.
   */
  frameStarburstData?: VideoContentSearchFrameStarburstData[];
}

function serializeVideoContentSearchVideoMultimodalTopicFeatures(data: any): VideoContentSearchVideoMultimodalTopicFeatures {
  return {
    ...data,
    frameStarburstData: data["frameStarburstData"] !== undefined ? data["frameStarburstData"].map((item: any) => (serializeVideoContentSearchFrameStarburstData(item))) : undefined,
  };
}

function deserializeVideoContentSearchVideoMultimodalTopicFeatures(data: any): VideoContentSearchVideoMultimodalTopicFeatures {
  return {
    ...data,
    frameStarburstData: data["frameStarburstData"] !== undefined ? data["frameStarburstData"].map((item: any) => (deserializeVideoContentSearchFrameStarburstData(item))) : undefined,
  };
}

/**
 * Video level scoring info.
 */
export interface VideoContentSearchVideoScoreInfo {
  /**
   * Anchor scoring features that apply to all anchor types.
   */
  commonFeatures?: VideoContentSearchVideoCommonFeatures;
  /**
   * OCR specific video level feature.
   */
  ocrVideoFeature?: VideoContentSearchOcrVideoFeature;
  /**
   * The output of Safe Search's MultiLabelClassifier for video title.
   */
  safeSearchClassifierOutput?: ClassifierPornQueryMultiLabelClassifierOutput;
  /**
   * The version of this VideoAnchorSets in spanner.
   */
  version?: string;
  /**
   * Video-level features that apply to all the generated queries within this
   * VideoAnchorSets.
   */
  videoGeneratedQueryFeatures?: VideoContentSearchVideoGeneratedQueryFeatures;
  /**
   * Video-level features for Multimodal topics.
   */
  videoMultimodalTopicFeatures?: VideoContentSearchVideoMultimodalTopicFeatures;
}

function serializeVideoContentSearchVideoScoreInfo(data: any): VideoContentSearchVideoScoreInfo {
  return {
    ...data,
    commonFeatures: data["commonFeatures"] !== undefined ? serializeVideoContentSearchVideoCommonFeatures(data["commonFeatures"]) : undefined,
    videoMultimodalTopicFeatures: data["videoMultimodalTopicFeatures"] !== undefined ? serializeVideoContentSearchVideoMultimodalTopicFeatures(data["videoMultimodalTopicFeatures"]) : undefined,
  };
}

function deserializeVideoContentSearchVideoScoreInfo(data: any): VideoContentSearchVideoScoreInfo {
  return {
    ...data,
    commonFeatures: data["commonFeatures"] !== undefined ? deserializeVideoContentSearchVideoCommonFeatures(data["commonFeatures"]) : undefined,
    videoMultimodalTopicFeatures: data["videoMultimodalTopicFeatures"] !== undefined ? deserializeVideoContentSearchVideoMultimodalTopicFeatures(data["videoMultimodalTopicFeatures"]) : undefined,
  };
}

/**
 * Startburst visual tokens or features, more details in
 * go/starburst-mum-user-guide
 */
export interface VideoContentSearchVisualFeatures {
  /**
   * Starburst features semantic or visual/
   */
  features?: number[];
  starbustVersion?:  | "UNKNOWN_VERSION" | "STARBURST_V1" | "STARBURST_V2" | "STARBURST_V3" | "STARBURST_V4" | "STARBURST_VISUAL_V4" | "STARBURST_V5" | "STARBURST_V5_5";
  /**
   * Starburst visual tokens
   */
  tokens?: number[];
}

/**
 * This message is used to store information about Inline Playback in the
 * VideoWebAttachment portion of the websearch index. LINT.IfChange
 */
export interface VideoCrawlVideoInlinePlaybackMetadata {
  /**
   * Timestamp (measured in seconds since epoch) when a video may not be used
   * for inline playback in the interest feed.
   */
  expirationTimestampSec?: bigint;
  /**
   * Publisher's Google Analytics Id to which we can report view metrics.
   */
  googleAnalyticsId?: string;
  /**
   * All two-letter codes for countries where this video may NOT be played.
   */
  playbackCountryBlacklist?: string[];
  /**
   * All two-letter codes for countries where this video may be played. If
   * empty, then all countries not on the blacklist are allowed for playback.
   */
  playbackCountryWhitelist?: string[];
  /**
   * Set of transcodes which are available for the video.
   */
  transcodeItags?: number[];
  /**
   * VAST tag for ads to be played along with this video. Currently, we only
   * support VAST tags from Doubleclick and FreeWheel.
   */
  vastTag?: string;
  /**
   * Identifier video is known by in the video infrastructure. The format given
   * here is the YoutubeId format (base-64) used in Venom; for Viper/Bandaid/
   * StreamingURLService, convert to ContentIdHex.
   */
  videoId?: string;
  /**
   * Set if the video is hosted on an external CDN, in which case it is not to
   * be transcoded and hosted at Google for the Interest Feed.
   */
  videoUrlOnExternalCdn?: string;
}

function serializeVideoCrawlVideoInlinePlaybackMetadata(data: any): VideoCrawlVideoInlinePlaybackMetadata {
  return {
    ...data,
    expirationTimestampSec: data["expirationTimestampSec"] !== undefined ? String(data["expirationTimestampSec"]) : undefined,
  };
}

function deserializeVideoCrawlVideoInlinePlaybackMetadata(data: any): VideoCrawlVideoInlinePlaybackMetadata {
  return {
    ...data,
    expirationTimestampSec: data["expirationTimestampSec"] !== undefined ? BigInt(data["expirationTimestampSec"]) : undefined,
  };
}

/**
 * Decoder configuration for Dolby Vision encoded by any codec. Dolby Vision
 * defines a separate profile & level hierarchy regardless of the base codec.
 * See Dolby Vision profiles, levels and compatibility:
 * https://dolby.my.salesforce.com/sfc/p/#700000009YuG/a/4u000000l6G4/4R18riPaaW3gxpVx7XwyQLdEITLFjB.w.Si0LoQR5j8
 * Dolby Vision DASH streaming:
 * https://professional.dolby.com/siteassets/content-creation/dolby-vision-for-content-creators/dolbyvisioninmpegdashspecification_v2_0_public_20190107.pdf
 * HTTP Live Streaming:
 * https://professional.dolby.com/siteassets/content-creation/dolby-vision-for-content-creators/dolby-vision-streams-within-the-http-live-streaming-format-v2.0-13-november-2018.pdf
 * Dolby Vision bitstreams:
 * https://professional.dolby.com/siteassets/pdfs/dolbyvisionstreamsinisobmffspecification-v2.1.2.pdf
 */
export interface VideoDoViDecoderConfiguration {
  /**
   * If a track contains the base layer substream.
   */
  blPresentFlag?: boolean;
  /**
   * Whether the stream is compatible with other sets of standard.
   */
  dvBlSignalCompatibilityId?: number;
  dvLevel?: number;
  dvProfile?: number;
  /**
   * Specifies the major version number of the Dolby Vision specification that
   * the stream complies with.
   */
  dvVersionMajor?: number;
  /**
   * Specifies the minor version number of the Dolby Vision specification that
   * the stream complies with.
   */
  dvVersionMinor?: number;
  /**
   * If a track contains the enhancement layer substream.
   */
  elPresentFlag?: boolean;
  /**
   * dvhe, dvh1, dvav, dva1: https://screenshot.googleplex.com/ipMGXFqLX9E
   */
  fourccTag?: string;
  /**
   * If a track contains the reference picture unit substream.
   */
  rpuPresentFlag?: boolean;
}

/**
 * A message holding all of the color information about a signal: -Color
 * primaries identify the meaning of red, green, and blue ( and the white
 * point). -The transfer characteristic identifies the mapping used to go
 * between linear and coded values of light. -The matrix coefficients
 * identifies, e.g., the conversion between Ycbcr to RGB (in the space of the
 * primaries) -And the color range defines the min/max of the levels used.
 */
export interface VideoFileColorInfo {
  matrixCoefficients?:  | "COLOR_MATRIX_COEFFICIENTS_RGB" | "COLOR_MATRIX_COEFFICIENTS_BT709" | "COLOR_MATRIX_COEFFICIENTS_UNSPECIFIED" | "COLOR_MATRIX_COEFFICIENTS_FCC" | "COLOR_MATRIX_COEFFICIENTS_BT470BG" | "COLOR_MATRIX_COEFFICIENTS_SMPTE170M" | "COLOR_MATRIX_COEFFICIENTS_SMPTE240M" | "COLOR_MATRIX_COEFFICIENTS_YCOCG" | "COLOR_MATRIX_COEFFICIENTS_BT2020_NCL" | "COLOR_MATRIX_COEFFICIENTS_BT2020_CL" | "COLOR_MATRIX_COEFFICIENTS_SMPTE2085" | "COLOR_MATRIX_COEFFICIENTS_CHROMA_DERIVED_NCL" | "COLOR_MATRIX_COEFFICIENTS_CHROMA_DERIVED_CL" | "COLOR_MATRIX_COEFFICIENTS_ICTCP";
  primaries?:  | "COLOR_PRIMARIES_BT709" | "COLOR_PRIMARIES_UNSPECIFIED" | "COLOR_PRIMARIES_BT470M" | "COLOR_PRIMARIES_BT470BG" | "COLOR_PRIMARIES_SMPTE170M" | "COLOR_PRIMARIES_SMPTE240M" | "COLOR_PRIMARIES_FILM" | "COLOR_PRIMARIES_BT2020" | "COLOR_PRIMARIES_SMPTEST428_1" | "COLOR_PRIMARIES_SMPTE431" | "COLOR_PRIMARIES_SMPTE432" | "COLOR_PRIMARIES_JEDEC_P22";
  range?:  | "COLOR_RANGE_UNSPECIFIED" | "COLOR_RANGE_MPEG" | "COLOR_RANGE_JPEG";
  transferCharacteristics?:  | "COLOR_TRANSFER_CHARACTERISTICS_BT709" | "COLOR_TRANSFER_CHARACTERISTICS_UNSPECIFIED" | "COLOR_TRANSFER_CHARACTERISTICS_GAMMA22" | "COLOR_TRANSFER_CHARACTERISTICS_GAMMA28" | "COLOR_TRANSFER_CHARACTERISTICS_SMPTE170M" | "COLOR_TRANSFER_CHARACTERISTICS_SMPTE240M" | "COLOR_TRANSFER_CHARACTERISTICS_LINEAR" | "COLOR_TRANSFER_CHARACTERISTICS_LOG" | "COLOR_TRANSFER_CHARACTERISTICS_LOG_SQRT" | "COLOR_TRANSFER_CHARACTERISTICS_IEC61966_2_4" | "COLOR_TRANSFER_CHARACTERISTICS_BT1361_ECG" | "COLOR_TRANSFER_CHARACTERISTICS_IEC61966_2_1" | "COLOR_TRANSFER_CHARACTERISTICS_BT2020_10" | "COLOR_TRANSFER_CHARACTERISTICS_BT2020_12" | "COLOR_TRANSFER_CHARACTERISTICS_SMPTEST2084" | "COLOR_TRANSFER_CHARACTERISTICS_SMPTEST428_1" | "COLOR_TRANSFER_CHARACTERISTICS_ARIB_STD_B67";
}

/**
 * A message holding the equivalent of the content light level information in
 * HEVC or its representation in matroska/webm. This gives coarse stats on the
 * luminance levels in the content and may be used as a hint by algorithms &
 * displays to tone map.
 */
export interface VideoFileContentLightLevel {
  /**
   * Defines the maximum content light level (in cd/m^2) over the entire video.
   */
  maxContentLightLevel?: number;
  /**
   * The maximum (over entire video) of the frame average light level.
   */
  maxFrameAverageLightLevel?: number;
}

/**
 * Information on Frame Packing arrangement
 */
export interface VideoFileFramePackingArrangement {
  /**
   * Grid positions
   */
  gridOffset0Horizontal?: number;
  gridOffset0Vertical?: number;
  gridOffset1Horizontal?: number;
  gridOffset1Vertical?: number;
  /**
   * Content interpretation
   */
  interpretation?:  | "FPA_INTERPRET_UNKNOWN" | "FPA_INTERPRET_LEFT_FIRST" | "FPA_INTERPRET_RIGHT_FIRST";
  /**
   * Quincunx sampling flag indicating if quincunx sampling is used
   */
  quincunxSampling?: boolean;
  /**
   * Arrangement type
   */
  type?:  | "FPA_NONE" | "FPA_CHECKERBOARD" | "FPA_COL_ALTERNATION" | "FPA_ROW_ALTERNATION" | "FPA_SIDE_BY_SIDE" | "FPA_TOP_TO_BOTTOM" | "FPA_FRAME_ALTERNATION";
}

/**
 * Stats on HDR10+ (SMPTE 2094-40:2016 standard) over video frames.
 */
export interface VideoFileHDR10PlusStats {
  /**
   * Application version is set to max version over all frames.
   */
  applicationVersion?: number;
  /**
   * The average of the nominal maximum display luminance of the targeted
   * system display over all frames.
   */
  averageTargetedSystemDisplayMaximumLuminance?: number;
  /**
   * This flag is set if any frame has it.
   */
  masteringDisplayActualPeakLuminanceFlag?: boolean;
  maxNumWindows?: number;
  /**
   * This flag is set if any frame has it.
   */
  targetedSystemDisplayActualPeakLuminanceFlag?: boolean;
}

/**
 * A message holding information about the mastering display color volume. This
 * metadata can be used when tone mapping an HDR signal to a display with a
 * different gamut or brightness characteristics than the mastering display.
 * This message is capable of containing SMPTE 2086 metadata.
 */
export interface VideoFileMasteringDisplayMetadata {
  /**
   * Coordinates of the blue primary of the mastering display.
   */
  blue?: VideoFileMasteringDisplayMetadataCIE1931Coordinate;
  /**
   * Coordinates of the green primary of the mastering display.
   */
  green?: VideoFileMasteringDisplayMetadataCIE1931Coordinate;
  /**
   * Maximum luminance of the display (in cd/m^2).
   */
  maxLuminance?: number;
  /**
   * Minimum luminance of the display (in cd/m^2).
   */
  minLuminance?: number;
  /**
   * Coordinates of the red primary of the mastering display.
   */
  red?: VideoFileMasteringDisplayMetadataCIE1931Coordinate;
  /**
   * Coordinates of the white point of the mastering display.
   */
  whitePoint?: VideoFileMasteringDisplayMetadataCIE1931Coordinate;
}

/**
 * Representation of a color coordinate in CIE1931 color space.
 */
export interface VideoFileMasteringDisplayMetadataCIE1931Coordinate {
  x?: number;
  y?: number;
}

/**
 * Globally allowed spherical meta data.
 */
export interface VideoFileSphericalMetadata {
  /**
   * Like above, but with high-pass motion filtering applied and yaw rotation
   * limited to +/- 15-degrees
   */
  clampedOptimalFovBounds?: VideoFileSphericalMetadataFOVBounds;
  cubemap?: VideoFileSphericalMetadataCubemapProjection;
  deprecatedCroppedArea?: VideoFileSphericalMetadataCroppedArea;
  /**
   * InitialView is from v1 spec, and is more or less equivalent to Pose from
   * v2 spec. Therefore, InitialView found in xml metadata would populate the
   * pose field in this proto.
   */
  deprecatedInitialView?: VideoFileSphericalMetadataViewDirection;
  equirect?: VideoFileSphericalMetadataEquirectProjection;
  fullPanoHeightPixels?: number;
  /**
   * Dimensions of the full video frame.
   */
  fullPanoWidthPixels?: number;
  mesh?: VideoFileSphericalMetadataMeshProjection;
  /**
   * Metadata source v2(svhd)
   */
  metadataSource?: string;
  /**
   * If video contains Wally-sanitized mesh and camera motion metadata (see
   * go/wally-format ), this contains the optimal FOV (smallest FOV that
   * encompass all combinations of input mesh FOV and rotations). This field
   * will only be present if full FfmpegAnalyze is performed.
   */
  optimalFovBounds?: VideoFileSphericalMetadataFOVBounds;
  pose?: VideoFileSphericalMetadataPose;
  /**
   * Mapping type used to map the sphere to the rectangular video E.g.,
   * "equirectangular", http://en.wikipedia.org/wiki/Equirectangular_projection
   * This is kept as string so that we can retain values that are unknown to us.
   */
  projectionType?: string;
  /**
   * The number of camera sources used to generate this video.
   */
  sourceCount?: number;
  /**
   * Whether the video is spherical or not.
   */
  spherical?: boolean;
  /**
   * The stereo mode.
   */
  stereoMode?:  | "STEREO_MODE_UNKNOWN" | "STEREO_MODE_MONO" | "STEREO_MODE_LEFT_RIGHT" | "STEREO_MODE_TOP_BOTTOM";
  /**
   * Whether the video has already been stitched.
   */
  stitched?: boolean;
  /**
   * The stitching software.
   */
  stitchingSoftware?: string;
  /**
   * Epoch Timestamp of when the first frame in the video was recorded
   */
  timestamp?: bigint;
}

function serializeVideoFileSphericalMetadata(data: any): VideoFileSphericalMetadata {
  return {
    ...data,
    mesh: data["mesh"] !== undefined ? serializeVideoFileSphericalMetadataMeshProjection(data["mesh"]) : undefined,
    timestamp: data["timestamp"] !== undefined ? String(data["timestamp"]) : undefined,
  };
}

function deserializeVideoFileSphericalMetadata(data: any): VideoFileSphericalMetadata {
  return {
    ...data,
    mesh: data["mesh"] !== undefined ? deserializeVideoFileSphericalMetadataMeshProjection(data["mesh"]) : undefined,
    timestamp: data["timestamp"] !== undefined ? BigInt(data["timestamp"]) : undefined,
  };
}

/**
 * The cropping coordinates, in pixels.
 */
export interface VideoFileSphericalMetadataCroppedArea {
  height?: number;
  left?: number;
  top?: number;
  width?: number;
}

/**
 * Specifies usage of cubemap projection.
 */
export interface VideoFileSphericalMetadataCubemapProjection {
  /**
   * Values 0 to 255 are reserved for current and future layouts. Value of 0
   * corresponds to a grid with 3 columns and 2 rows as follows: | right face |
   * left face | up face | | down face | front face | back face |
   */
  layout?: number;
  /**
   * Number of pixels to pad from the edge of each cube face
   */
  padding?: number;
}

/**
 * Specifies usage of equirectangular projection. More specifically, these are
 * the proportion of projection cropped from each edge not covered by the video
 * frame. For uncropped frame, all values are 0. For v1 metadata, this contains
 * CroppedArea information (CroppedAreaLeftPixels, CroppedAreaTopPixels,
 * CroppedAreaImageWidthPixels, CroppedAreaImageHeightPixels)
 */
export interface VideoFileSphericalMetadataEquirectProjection {
  projectionBoundsBottom?: number;
  projectionBoundsLeft?: number;
  projectionBoundsRight?: number;
  projectionBoundsTop?: number;
}

export interface VideoFileSphericalMetadataFOVBounds {
  endTiltInDegrees?: number;
  endYawInDegrees?: number;
  startTiltInDegrees?: number;
  startYawInDegrees?: number;
}

/**
 * Specifies usage of mesh projection. "content" contains the mshp atom:
 * version/flags, CRC, compression method, description of the mesh(es)
 * (vertices, coordinates corresponding to each vertex, and vertex lists to
 * describe the projection). See go/pir-spec for mshp atom data layout.
 */
export interface VideoFileSphericalMetadataMeshProjection {
  /**
   * Once mesh is analyzed, this field contains the bounds of the mesh(es) In
   * case of stereo mesh, this will be the aggregate of both eye meshes
   */
  bounds?: VideoFileSphericalMetadataFOVBounds;
  content?: Uint8Array;
  /**
   * The mesh type field will only be populated when we have done analysis on
   * the mesh. If this field is missing, mesh analysis has not been done.
   */
  type?:  | "MESH_TYPE_UNKNOWN" | "MESH_TYPE_WALLY_FISHEYE" | "MESH_TYPE_WALLY_CROPPED_EQUIRECT" | "MESH_TYPE_WALLY_FOVEATED";
}

function serializeVideoFileSphericalMetadataMeshProjection(data: any): VideoFileSphericalMetadataMeshProjection {
  return {
    ...data,
    content: data["content"] !== undefined ? encodeBase64(data["content"]) : undefined,
  };
}

function deserializeVideoFileSphericalMetadataMeshProjection(data: any): VideoFileSphericalMetadataMeshProjection {
  return {
    ...data,
    content: data["content"] !== undefined ? decodeBase64(data["content"] as string) : undefined,
  };
}

/**
 * Specifies the compass heading, pitch & roll for the origin of the
 * projection. The origin for the "equirectangular" projection is the center of
 * the image. The origin for the other projection types is defined as the
 * location in the image that corresponds to the origin of an "equirectangular"
 * projection.
 */
export interface VideoFileSphericalMetadataPose {
  headingDegrees?: number;
  pitchDegrees?: number;
  rollDegrees?: number;
}

export interface VideoFileSphericalMetadataViewDirection {
  headingDegrees?: number;
  pitchDegrees?: number;
  rollDegrees?: number;
}

export interface VideoLegosLegosAnnotationsSet {
  featureSetName?: string;
  legosAnnotations?: YoutubeDiscoveryLegosLegosAnnotations;
}

export interface VideoLegosLegosAnnotationsSets {
  annotationsSet?: VideoLegosLegosAnnotationsSet[];
}

/**
 * Feel free to ignore this lint warning if only the trivia (e.g., comments) is
 * is changed. LINT.IfChange
 */
export interface VideoMediaInfo {
  /**
   * Each entry corresponds to one audio stream in the original media file.
   */
  audioStream?: VideoAudioStream[];
  /**
   * Container type of the file, e.g. FLV, H264, MP3. Uses the numeric value
   * corresponding to the ContainerId enum objects, in order to avoid the
   * dependency on vsi/videostreaminfo.proto.
   * http://cs/symbol:ContainerId%20f:google3/video/vidproc/vsi/videostreaminfo.proto
   */
  containerId?: number;
  /**
   * Media file size in bytes.
   */
  fileSize?: bigint;
  /**
   * This is a high-level description of the media. It does not contain PII.
   */
  overview?: VideoMediaOverview;
  /**
   * Each entry corresponds to one video stream (usually just one) in the
   * original media file.
   */
  videoStream?: VideoVideoStream[];
}

function serializeVideoMediaInfo(data: any): VideoMediaInfo {
  return {
    ...data,
    audioStream: data["audioStream"] !== undefined ? data["audioStream"].map((item: any) => (serializeVideoAudioStream(item))) : undefined,
    fileSize: data["fileSize"] !== undefined ? String(data["fileSize"]) : undefined,
    overview: data["overview"] !== undefined ? serializeVideoMediaOverview(data["overview"]) : undefined,
    videoStream: data["videoStream"] !== undefined ? data["videoStream"].map((item: any) => (serializeVideoVideoStream(item))) : undefined,
  };
}

function deserializeVideoMediaInfo(data: any): VideoMediaInfo {
  return {
    ...data,
    audioStream: data["audioStream"] !== undefined ? data["audioStream"].map((item: any) => (deserializeVideoAudioStream(item))) : undefined,
    fileSize: data["fileSize"] !== undefined ? BigInt(data["fileSize"]) : undefined,
    overview: data["overview"] !== undefined ? deserializeVideoMediaOverview(data["overview"]) : undefined,
    videoStream: data["videoStream"] !== undefined ? data["videoStream"].map((item: any) => (deserializeVideoVideoStream(item))) : undefined,
  };
}

/**
 * Next ID: 19 IMPORTANT: This file is used in scattered directories, such that
 * it is risky to add values to any enumerated type. (First of all, compilation
 * breaks on switch statements without default clauses.) Run a global tap
 * presubmit: tap_presubmit -p all --train -c before submitting. Also check out
 * the blame layer of previous updates for hints on what other files to changes.
 */
export interface VideoMediaOverview {
  aspectRatio?:  | "ASPECT_RATIO_UNKNOWN" | "ASPECT_RATIO_1_1" | "ASPECT_RATIO_3_2" | "ASPECT_RATIO_4_3" | "ASPECT_RATIO_16_9";
  audioOverview?: VideoMediaOverviewAudioOverview[];
  authoringTool?:  | "AUTHORING_TOOL_UNKNOWN" | "AUTHORING_TOOL_GWD";
  colorDynamicRange?:  | "COLOR_DYNAMIC_RANGE_UNKNOWN" | "COLOR_DYNAMIC_RANGE_STANDARD" | "COLOR_DYNAMIC_RANGE_HIGH";
  /**
   * Creation timestamp of this media_info, in Unix timestamp since epoch.
   */
  creationTimeStampUsec?: bigint;
  dataOverview?: VideoMediaOverviewDataOverview[];
  frameRate?:  | "FRAME_RATE_UNKNOWN" | "FRAME_RATE_STANDARD" | "FRAME_RATE_HIGH" | "FRAME_RATE_ULTRA_HIGH";
  /**
   * Currently used by originals replacement pipeline to exclude all videos
   * containing chapter info.
   */
  hasChapters?: boolean;
  mediaClipInfoOverview?: VideoMediaOverviewMediaClipInfoOverview;
  orientation?:  | "ORIENTATION_UNKNOWN" | "ORIENTATION_PORTRAIT" | "ORIENTATION_LANDSCAPE";
  origin?:  | "ORIGIN_UNKNOWN" | "ORIGIN_CLIENT" | "ORIGIN_UPLOAD" | "ORIGIN_PROCESSING";
  projection?:  | "PROJECTION_UNKNOWN" | "PROJECTION_RECTANGULAR" | "PROJECTION_SPHERICAL" | "PROJECTION_PARTIALLY_SPHERICAL";
  resolution?:  | "RESOLUTION_UNKNOWN" | "RESOLUTION_ULTRA_LOW" | "RESOLUTION_LOW" | "RESOLUTION_SD" | "RESOLUTION_720P" | "RESOLUTION_1080P" | "RESOLUTION_2K" | "RESOLUTION_4K" | "RESOLUTION_8K";
  spatialAudioMode?:  | "SPATIAL_AUDIO_MODE_UNKNOWN" | "SPATIAL_AUDIO_MODE_NON_SPATIAL" | "SPATIAL_AUDIO_MODE_SPATIAL";
  stereoMode?:  | "STEREO_MODE_UNKNOWN" | "STEREO_MODE_TWO_D" | "STEREO_MODE_SIDE_BY_SIDE" | "STEREO_MODE_TOP_BOTTOM";
  timedtextOverview?: VideoMediaOverviewTimedTextOverview[];
  videoOverview?: VideoMediaOverviewVideoOverview[];
  /**
   * This only applies when: projection = PROJECTION_PARTIALLY_SPHERICAL
   */
  wallyMeshType?:  | "MESH_TYPE_UNKNOWN" | "MESH_TYPE_WALLY_FISHEYE" | "MESH_TYPE_WALLY_CROPPED_EQUIRECT";
}

function serializeVideoMediaOverview(data: any): VideoMediaOverview {
  return {
    ...data,
    creationTimeStampUsec: data["creationTimeStampUsec"] !== undefined ? String(data["creationTimeStampUsec"]) : undefined,
  };
}

function deserializeVideoMediaOverview(data: any): VideoMediaOverview {
  return {
    ...data,
    creationTimeStampUsec: data["creationTimeStampUsec"] !== undefined ? BigInt(data["creationTimeStampUsec"]) : undefined,
  };
}

/**
 * Audio stream description with no PII.
 */
export interface VideoMediaOverviewAudioOverview {
  /**
   * Number of audio channels.
   */
  channels?: number;
  /**
   * Content type of the audio track extracted from VSI. This is only populated
   * with valid "acont" xtag values at the moment, i.e., if VSI reports an
   * invalid string, we ignore it. Supported acont xtag values can be found in
   * google3/video/storage/common/xtag_validation.cc. Examples: "original",
   * "dubbed", "descriptive", "commentary", etc.
   */
  contentType?: string;
  /**
   * Language of the audio track extracted from VSI. Populated if it's deemed a
   * valid code by ISO639-2b, ISO639-2t or III library.
   */
  language?: string;
  loudness1770Lkfs?: number;
  /**
   * Approximate audio length, has the same caveats as its video equivalent.
   */
  roundedUpOriginalDurationSec?: number;
  spatialAudioMode?:  | "SPATIAL_AUDIO_MODE_UNKNOWN" | "SPATIAL_AUDIO_MODE_NON_SPATIAL" | "SPATIAL_AUDIO_MODE_SPATIAL";
}

/**
 * Data stream description with no PII. Currently used by originals replacement
 * pipeline to exclude all clips that have data streams. Fields in proto are
 * used to exclude clips with certain types of data streams.
 */
export interface VideoMediaOverviewDataOverview {
  /**
   * Whether the data stream has camera motion metadata (dynamic) or not
   * (static). Some Wally/VR180 videos do.
   */
  hasCameraMotionMetadata?: boolean;
  /**
   * If true, source contains metadata for OZO spatial audio support. See
   * b/62393568 for more information about the OZO spatial audio format. Note
   * that SpatialAudioMode is independent of this format.
   */
  hasOzoAudio?: boolean;
}

/**
 * Video clip info description with no PII.
 */
export interface VideoMediaOverviewMediaClipInfoOverview {
  /**
   * Corresponds to vsi.video_clip_info().has_geolocation()
   */
  hasGeolocation?: boolean;
}

/**
 * Timed text stream description with no PII. Currently used by originals
 * replacement pipeline to exclude all clips that have timed text streams. Add
 * fields to proto if we want to only exclude clips with certain types of timed
 * text streams in the future.
 */
export interface VideoMediaOverviewTimedTextOverview {
}

/**
 * Video stream description with no PII.
 */
export interface VideoMediaOverviewVideoOverview {
  aspectRatio?:  | "ASPECT_RATIO_UNKNOWN" | "ASPECT_RATIO_1_1" | "ASPECT_RATIO_3_2" | "ASPECT_RATIO_4_3" | "ASPECT_RATIO_16_9";
  /**
   * Prefer average_fps to match the logic used in transcoder for format
   * profile frame rate checks. First added for Photos, see b/165839654.
   */
  averageFps?: number;
  codecId?: number;
  colorDynamicRange?:  | "COLOR_DYNAMIC_RANGE_UNKNOWN" | "COLOR_DYNAMIC_RANGE_STANDARD" | "COLOR_DYNAMIC_RANGE_HIGH";
  fps?: number;
  height?: number;
  resolution?:  | "RESOLUTION_UNKNOWN" | "RESOLUTION_ULTRA_LOW" | "RESOLUTION_LOW" | "RESOLUTION_SD" | "RESOLUTION_720P" | "RESOLUTION_1080P" | "RESOLUTION_2K" | "RESOLUTION_4K" | "RESOLUTION_8K";
  /**
   * Approximate video length. Data is rounded up to the next second, to avoid
   * being PII. (Long ago, YTFE set a precedent of rounding up durations, rather
   * than rounding to the closest second.) This value is derived from metadata
   * in the source video, and often differs from the actual duration of any
   * given transcode. In videos without valid timestamps, this value is not
   * calculable, and is reported as zero. Prefer the value from
   * MediaInfo::VideoStream over this value, which was added to resolve
   * b/202864365.
   */
  roundedUpOriginalDurationSec?: number;
  videoHasClosedCaptions?: boolean;
  width?: number;
}

export interface VideoPerDocData {
  coreSignals?: MediaIndexVideoCoreSignals;
  frames?: MediaIndexVideoFrames;
}

function serializeVideoPerDocData(data: any): VideoPerDocData {
  return {
    ...data,
    coreSignals: data["coreSignals"] !== undefined ? serializeMediaIndexVideoCoreSignals(data["coreSignals"]) : undefined,
    frames: data["frames"] !== undefined ? serializeMediaIndexVideoFrames(data["frames"]) : undefined,
  };
}

function deserializeVideoPerDocData(data: any): VideoPerDocData {
  return {
    ...data,
    coreSignals: data["coreSignals"] !== undefined ? deserializeMediaIndexVideoCoreSignals(data["coreSignals"]) : undefined,
    frames: data["frames"] !== undefined ? deserializeMediaIndexVideoFrames(data["frames"]) : undefined,
  };
}

export interface VideoPipelineViperThumbnailerColumnData {
  /**
   * The blobRef where the representative frame is stored. This is repeated in
   * order to support multiple thumbnails in the future.
   */
  frameBlobRefs?: BlobstoreBlobRef[];
  /**
   * Video frame files (based on file_dir_to_save_frames parameter)
   */
  frameFileList?: VideoThumbnailsFrameFileList;
  /**
   * Frame type generated (VR/360/3D/default).
   */
  frameTypeGenerated?:  | "FRAME_TYPE_DEFAULT" | "FRAME_TYPE_VR" | "FRAME_TYPE_360" | "FRAME_TYPE_3D" | "FRAME_TYPE_VR180_LEFT_RIGHT" | "FRAME_TYPE_VR180_TOP_BOTTOM";
  /**
   * True if the thumbnails are generated from drishti_thumbnailer.
   */
  generatedFromDrishtiThumbnailer?: boolean;
  highResPreviewThumbnailGenerated?: boolean;
  /**
   * hq720.jpg is a 1280x720 pixel image generated only when the input video
   * resolution is 1280x720 or higher.
   */
  hq720Generated?: boolean;
  /**
   * The flags below indicate whether certain optional thumbnail images were
   * generated. hqdefault.jpg is a 480x360 pixel high quality image which should
   * normally be always generated.
   */
  hqdefaultGenerated?: boolean;
  /**
   * True if a set of backup HVC thumbnails is generated.
   */
  hvcBackupGenerated?: boolean;
  /**
   * True if the thumbnails are generated with background crop and scrim.
   */
  improvedVerticalGenerated?: boolean;
  /**
   * maxresdefault.jpg is an image of the same resolution as the input video.
   * It is generated only when the input video is significantly
   * higher-resolution than 640x480.
   */
  maxresdefaultGenerated?: boolean;
  /**
   * Height of the generated maxresdefault thumbnail.
   */
  maxresdefaultHeight?: number;
  /**
   * Width of the generated maxresdefault thumbnail.
   */
  maxresdefaultWidth?: number;
  /**
   * True if moving thumbnails are generated.
   */
  movingThumbnailGenerated?: boolean;
  /**
   * True if private thumbnails were generated and stored in the thumbnail
   * database.
   */
  privateThumbnailsGenerated?: boolean;
  /**
   * True if public thumbnails were generated and stored in the thumbnail
   * database.
   */
  publicThumbnailsGenerated?: boolean;
  /**
   * Analysis result of running the rerun thumbnailer
   */
  rerunStatus?:  | "RERUN_FAILED" | "RERUN_NO_ACTION_CUSTOM_THUMB" | "RERUN_NO_ACTION_ALREADY_EXISTS" | "RERUN_NO_ACTION_RECOMPUTE_DISABLED" | "RERUN_NO_ACTION_DEFAULT_THUMBNAILS_MISSING" | "RERUN_NO_ACTION_DEFAULT_THUMBNAILS_TIMESTAMP_MISSING" | "RERUN_NO_ACTION_THUMBNAIL_SERVICE_FAILURE" | "RERUN_NO_ACTION_UNUSUAL_THUMBNAIL_DATA" | "RERUN_PERFORM_EXTRACTION";
  /**
   * sddefault.jpg is a 640x480 pixel image generated only when the input video
   * resolution is 640x480 or higher.
   */
  sddefaultGenerated?: boolean;
  /**
   * This flag indicates if storyboard mosaic images were generated and stored
   * in the thumbnail database.
   */
  storyboardGenerated?: boolean;
  /**
   * Number of levels of storyboard generated (0 if policy default).
   */
  storyboardNumLevels?: number;
  /**
   * Policy number that governed the storyboard generation. If zero, no policy
   * was used and the storyboard format is not fully specified by the parameters
   * contained in this message.
   */
  storyboardPolicy?: number;
  /**
   * Version of the storyboard.
   */
  storyboardVersion?: number;
  /**
   * Video duration of the video.
   */
  storyboardVideoDurationMs?: number;
  /**
   * Height of the video that was storyboarded.
   */
  storyboardVideoHeight?: number;
  /**
   * Width of the video that was storyboarded.
   */
  storyboardVideoWidth?: number;
  /**
   * This flag indicates if images in WebP format were created and stored in
   * the thumbnail database.
   */
  webpGenerated?: boolean;
}

function serializeVideoPipelineViperThumbnailerColumnData(data: any): VideoPipelineViperThumbnailerColumnData {
  return {
    ...data,
    frameBlobRefs: data["frameBlobRefs"] !== undefined ? data["frameBlobRefs"].map((item: any) => (serializeBlobstoreBlobRef(item))) : undefined,
  };
}

function deserializeVideoPipelineViperThumbnailerColumnData(data: any): VideoPipelineViperThumbnailerColumnData {
  return {
    ...data,
    frameBlobRefs: data["frameBlobRefs"] !== undefined ? data["frameBlobRefs"].map((item: any) => (deserializeBlobstoreBlobRef(item))) : undefined,
  };
}

export interface VideoPipelineViperVSIColumnData {
  info?: VideoVideoStreamInfo;
  /**
   * Total time taken in seconds to read the input
   */
  inputReadTime?: number;
  /**
   * Was the VSI computed on a partial file ?
   */
  partialFile?: boolean;
  /**
   * Total time (of all attempts) taken in seconds to compute VSI
   */
  totalVsiTime?: number;
  vsiStats?: VideoPipelineViperVSIColumnDataVsiStats[];
}

function serializeVideoPipelineViperVSIColumnData(data: any): VideoPipelineViperVSIColumnData {
  return {
    ...data,
    info: data["info"] !== undefined ? serializeVideoVideoStreamInfo(data["info"]) : undefined,
  };
}

function deserializeVideoPipelineViperVSIColumnData(data: any): VideoPipelineViperVSIColumnData {
  return {
    ...data,
    info: data["info"] !== undefined ? deserializeVideoVideoStreamInfo(data["info"]) : undefined,
  };
}

/**
 * The stats of each output vsi.
 */
export interface VideoPipelineViperVSIColumnDataVsiStats {
  /**
   * True if the output vsi is a partial vsi.
   */
  partialVsi?: boolean;
  /**
   * The time (in secondes) from vsi_engine init to vsi written to output
   * buffer.
   */
  vsiTime?: number;
}

export interface VideoRational32 {
  denominator?: number;
  numerator?: number;
}

/**
 * This SEI message only takes the payload type and the sum of the payload
 * sizes for all SEI messages of this type. More informations, such as
 * timestamp, payload, may be added in the future.
 */
export interface VideoSEIMessage {
  /**
   * message count of each payloadtype
   */
  count?: number;
  /**
   * If the video stream has multiple SEI messages with the same payload type,
   * this is the sum of all these payloads' sizes.
   */
  cumulativeSize?: bigint;
  /**
   * use int type in case there are payload types that are not included in the
   * SEIPayloadType enum below. The enum can be used for lookup
   */
  payloadtype?: number;
}

function serializeVideoSEIMessage(data: any): VideoSEIMessage {
  return {
    ...data,
    cumulativeSize: data["cumulativeSize"] !== undefined ? String(data["cumulativeSize"]) : undefined,
  };
}

function deserializeVideoSEIMessage(data: any): VideoSEIMessage {
  return {
    ...data,
    cumulativeSize: data["cumulativeSize"] !== undefined ? BigInt(data["cumulativeSize"]) : undefined,
  };
}

/**
 * Measurement of loudness. Next tag = 3
 */
export interface VideoStorageLoudnessData {
  /**
   * Loudness measured using ITU-R BS. 1770
   */
  itu1770LoudnessDb?: number;
  /**
   * Perceived loudness of audio measured using replaygain.
   */
  perceptualLoudnessDb?: number;
}

/**
 * Individual video frame saved in an image file.
 */
export interface VideoThumbnailsFrameFile {
  filename?: string;
  height?: number;
  msOffset?: number;
  width?: number;
}

/**
 * List of individual video frames, each saved as an image file
 */
export interface VideoThumbnailsFrameFileList {
  frameFiles?: VideoThumbnailsFrameFile[];
}

/**
 * LINT.IfChange Score calculated from a thumbnail. NextID: 15
 */
export interface VideoThumbnailsThumbnailScore {
  /**
   * Checksum of the thumbnail bytes used to identify which image the score
   * belongs to. Only filled when thumbnail version is 0.
   */
  checksum?: bigint;
  /**
   * Color sampling score encoded as uint32. Encode/Decode using
   * youtube::color::RgbToUint / UIntToRgb. Field is only relevant for
   * TYPE_COLOR_SAMPLING.
   */
  colorSampling?: number;
  /**
   * Thumbnail dense features.
   */
  denseFeatures?: number[];
  /**
   * FeatureExtra extension for dense features.
   */
  denseGeneralExtraFeatures?: DrishtiFeatureExtra;
  /**
   * If true, score is manually assigned.
   */
  isAssigned?: boolean;
  /**
   * If true, score will be instantly indexed by YouTube search indexer.
   */
  isInstant?: boolean;
  modelVersion?:  | "MODEL_VERSION_UNKNOWN" | "MODEL_VERSION_ONE" | "MODEL_VERSION_TWO" | "MODEL_VERSION_THREE" | "MODEL_VERSION_FOUR" | "MODEL_RACY_WATCHPAGE_2018_01_15" | "MODEL_RACY_WATCHPAGE_2020_04_20" | "MODEL_RACY_WATCHPAGE_2020_04_20A" | "MODEL_RACY_WATCHPAGE_2020_04_20_FLAGGED" | "MODEL_RACY_WATCHPAGE_2021_05_04" | "MODEL_RACY_WATCHPAGE_2021_05_04_FLAGGED" | "MODEL_RACY_WATCHPAGE_2021_05_04_FLAGGED_SHORTS" | "MODEL_RACY_WATCHPAGE_2021_05_04_FLAGGED_HOME" | "MODEL_RACY_WATCHPAGE_2021_05_04_FLAGGED_WATCHNEXT" | "MODEL_RACY_WATCHPAGE_V4" | "MODEL_RACY_WATCHPAGE_RELEASE" | "MODEL_RACY_SHORTS_WATCHPAGE_V1" | "MODEL_RACY_SHORTS_WATCHPAGE_V1_FLAGGED" | "MODEL_RACY_SHORTS_WATCHPAGE_V2" | "MODEL_RACY_SHORTS_WATCHPAGE_V2_FLAGGED" | "MODEL_RACY_SHORTS_WATCHPAGE_RELEASE" | "MODEL_RACY_THUMB_2019_04_02" | "MODEL_RACY_THUMB_2019_08_12" | "MODEL_RACY_THUMB_2019_08_12A" | "MODEL_RACY_THUMB_2019_08_12B" | "MODEL_RACY_THUMB_2019_08_12C" | "MODEL_RACY_THUMB_2019_08_12D" | "MODEL_RACY_THUMB_2019_08_12E" | "MODEL_RACY_THUMB_2019_08_12_CALIBRATED" | "MODEL_RACY_THUMB_2019_08_12_FLAGGED" | "MODEL_RACY_THUMB_RELEASE" | "MODEL_QUALITY_2019_09_24" | "MODEL_QUALITY_2019_11_11" | "MODEL_QUALITY_2020_11_12" | "MODEL_RACY_THUMB_2019_08_12_4A" | "MODEL_RACY_THUMB_2019_08_12_4B" | "MODEL_RACY_THUMB_2019_08_12_4C" | "MODEL_RACY_THUMB_2019_08_12_UPDATEDSS" | "MODEL_RACY_THUMB_2019_04_02_ABLATE_ALL" | "MODEL_RACY_THUMB_2019_04_02_ABLATE_V3" | "MODEL_RACY_THUMB_2019_08_12_ABLATE_HUMAN_RATING" | "MODEL_RACY_THUMB_2019_08_12_ABLATE_USER_FLAGGING" | "MODEL_RACY_THUMB_2020_02_24" | "MODEL_RACY_THUMB_2020_02_24_CALIBRATED" | "MODEL_RACY_THUMB_2020_02_24_FLAGGED" | "MODEL_RACY_THUMB_2020_02_24_EFF" | "MODEL_RACY_THUMB_V5" | "MODEL_THUMB_EMBEDDING_20201201" | "MODEL_PQC_20210816_0" | "MODEL_VERSION_TEST";
  overwriteReason?:  | "REASON_NO_OVERWRITE" | "REASON_UNKNOWN" | "REASON_RACY_WARTCHPAGE_RATING" | "REASON_RACY_THUMBNAIL_RATING" | "REASON_THUMBNAIL_REPORT" | "REASON_VIDEO_REPORT" | "REASON_CLUSTER_HEURISTIC";
  /**
   * Thumbnail quantized dense features, available in TYPE_STARBURST_COMPRESSED
   */
  quantizedFeatures?: Uint8Array;
  score?: number;
  /**
   * Thumbnail sparse features, available in TYPE_STARBURST
   */
  sparseFeatures?: DrishtiSparseFeatureData;
  thumbnailSet?:  | "SET_UNKNOWN" | "SET_ONE" | "SET_TWO" | "SET_THREE" | "SET_DEFAULT";
  /**
   * Version number of the thumbnail. Should be consistent with the version
   * number in the ytimg_content column family.
   */
  thumbnailVersion?: bigint;
  type?:  | "TYPE_UNKNOWN" | "TYPE_RACY" | "TYPE_QUALITY" | "TYPE_JOY_FACE" | "TYPE_EYE_OPEN" | "TYPE_FACE_RATIO" | "TYPE_SHARPNESS" | "TYPE_COLORFULNESS" | "TYPE_NIMA" | "TYPE_STARBURST" | "TYPE_RACY_RATING" | "TYPE_RACY_WATCHPAGE" | "TYPE_RACY_LOCKUP" | "TYPE_RACY_WATCHPAGE_FLAGGED" | "TYPE_STARBURST_EMBEDDING" | "TYPE_FACE" | "TYPE_FDENSE_PCA" | "TYPE_FDENSE_PCA_MOE" | "TYPE_FNET_LOGREG" | "TYPE_FNET_TOPICALITY" | "TYPE_LOGO" | "TYPE_NEAR_DUP" | "TYPE_OCR" | "TYPE_OCR_UNIGRAMS" | "TYPE_OCR_UNIGRAMS_NON_TRIVIAL" | "TYPE_PINKY_FRAMING" | "TYPE_PQC_PORN_CHANNEL_DISPLAY_NAME" | "TYPE_PQC_PORN_DESCRIPTION" | "TYPE_PQC_PORN_TITLE" | "TYPE_PQC_VIOLENCE_CHANNEL_DISPLAY_NAME" | "TYPE_PQC_VIOLENCE_DESCRIPTION" | "TYPE_PQC_VIOLENCE_TITLE" | "TYPE_SAFESEARCH" | "TYPE_SAFESEARCH_PINKY" | "TYPE_STARBURST_COMPRESSED" | "TYPE_STARBURST_TOKENS" | "TYPE_MACRO_MARKERS" | "TYPE_THUMB_QUERY_EMBEDDING" | "TYPE_COLOR_SAMPLING" | "TYPE_ENGAGINESS";
}

function serializeVideoThumbnailsThumbnailScore(data: any): VideoThumbnailsThumbnailScore {
  return {
    ...data,
    checksum: data["checksum"] !== undefined ? String(data["checksum"]) : undefined,
    quantizedFeatures: data["quantizedFeatures"] !== undefined ? encodeBase64(data["quantizedFeatures"]) : undefined,
    thumbnailVersion: data["thumbnailVersion"] !== undefined ? String(data["thumbnailVersion"]) : undefined,
  };
}

function deserializeVideoThumbnailsThumbnailScore(data: any): VideoThumbnailsThumbnailScore {
  return {
    ...data,
    checksum: data["checksum"] !== undefined ? BigInt(data["checksum"]) : undefined,
    quantizedFeatures: data["quantizedFeatures"] !== undefined ? decodeBase64(data["quantizedFeatures"] as string) : undefined,
    thumbnailVersion: data["thumbnailVersion"] !== undefined ? BigInt(data["thumbnailVersion"]) : undefined,
  };
}

export interface VideoTimedtextS4ALIResults {
  /**
   * The complete list of language scores, sorted from high score to low.
   */
  langResults?: VideoTimedtextS4LangScore[];
  /**
   * What kind of speech (if any) was detected.
   */
  speechClass?:  | "UNKNOWN" | "NO_SPEECH" | "HAS_SPEECH_FOR_ASR";
}

export interface VideoTimedtextS4LangScore {
  /**
   * A score between 0.0 and 1.0; the relative probability that this is the
   * language of the video. This should not be interpreted as an absolute
   * probability. For instance, scores may be calculated for all languages even
   * for videos for which no speech was detected.
   */
  confidence?: number;
  /**
   * The language code for one of the languages supported by automatic language
   * identification.
   */
  langCode?: string;
}

/**
 * This message contains user data registered itu-t t.35 data
 */
export interface VideoUserDataRegisteredItuTT35 {
  /**
   * Counts itu-t t.35 message with the same country code and provider code
   */
  count?: number;
  countryCode?: number;
  providerCode?: number;
}

/**
 * This message contains unregistered user data identified by a UUID
 */
export interface VideoUserDataUnregistered {
  /**
   * Counts user data with the same uuid and payload If payload size is larger
   * than limit, the payload will be 'Payload size is larger than limit: ' +
   * limit size Count will be for user data with same uuid and payload exceeds
   * limit in this case
   */
  count?: number;
  /**
   * Payload may not be filled in Payload may contain user data
   */
  payload?: Uint8Array;
  uuid?: string;
}

function serializeVideoUserDataUnregistered(data: any): VideoUserDataUnregistered {
  return {
    ...data,
    payload: data["payload"] !== undefined ? encodeBase64(data["payload"]) : undefined,
  };
}

function deserializeVideoUserDataUnregistered(data: any): VideoUserDataUnregistered {
  return {
    ...data,
    payload: data["payload"] !== undefined ? decodeBase64(data["payload"] as string) : undefined,
  };
}

/**
 * VideoClipInfo : meta information extracted from video file Next id: 26
 */
export interface VideoVideoClipInfo {
  /**
   * Lists the artist of the original subject of the file.
   */
  artist?: Uint8Array;
  /**
   * Audio vendor ID
   */
  audioVendorId?: Uint8Array;
  /**
   * Different containers use different video clip info. The following fields
   * include info from popular formats: AVI, MOV, and WMV.
   */
  author?: Uint8Array;
  comment?: Uint8Array;
  /**
   * Lists the name of the person or organization that commissioned the subject
   * of the file.
   */
  commissioned?: Uint8Array;
  /**
   * Records the copyright information for the file.
   */
  copyright?: Uint8Array;
  digitizationTime?: Uint8Array;
  director?: Uint8Array;
  /**
   * The engineer who worked on the file.
   */
  engineer?: Uint8Array;
  /**
   * Optional geo-location information in WGS 84.
   */
  geolocation?: VideoVideoGeoLocation;
  info?: Uint8Array;
  /**
   * Provides a list of keywords that refer to the file or subject of the file.
   */
  keywords?: Uint8Array;
  /**
   * The camera make such as Apple, Samsung etc.
   */
  make?: Uint8Array;
  /**
   * Describes the original subject of the file.
   */
  medium?: Uint8Array;
  /**
   * Container level metadata
   */
  metadata?: VideoClipInfo[];
  /**
   * The camera model such as iPhone7 or Pixel, etc.
   */
  model?: Uint8Array;
  performer?: Uint8Array;
  producer?: Uint8Array;
  requirements?: Uint8Array;
  /**
   * Identifies the name of the software packages used to create the file.
   */
  software?: Uint8Array;
  /**
   * Identifies the name of the person or organization who supplied the
   * original subject of the file.
   */
  sourceProvider?: Uint8Array;
  /**
   * Describes the contents of the file.
   */
  subject?: Uint8Array;
  /**
   * Identifies the technician who digitized the subject file.
   */
  technician?: Uint8Array;
  title?: Uint8Array;
  /**
   * Video vendor ID
   */
  videoVendorId?: Uint8Array;
}

function serializeVideoVideoClipInfo(data: any): VideoVideoClipInfo {
  return {
    ...data,
    artist: data["artist"] !== undefined ? encodeBase64(data["artist"]) : undefined,
    audioVendorId: data["audioVendorId"] !== undefined ? encodeBase64(data["audioVendorId"]) : undefined,
    author: data["author"] !== undefined ? encodeBase64(data["author"]) : undefined,
    comment: data["comment"] !== undefined ? encodeBase64(data["comment"]) : undefined,
    commissioned: data["commissioned"] !== undefined ? encodeBase64(data["commissioned"]) : undefined,
    copyright: data["copyright"] !== undefined ? encodeBase64(data["copyright"]) : undefined,
    digitizationTime: data["digitizationTime"] !== undefined ? encodeBase64(data["digitizationTime"]) : undefined,
    director: data["director"] !== undefined ? encodeBase64(data["director"]) : undefined,
    engineer: data["engineer"] !== undefined ? encodeBase64(data["engineer"]) : undefined,
    info: data["info"] !== undefined ? encodeBase64(data["info"]) : undefined,
    keywords: data["keywords"] !== undefined ? encodeBase64(data["keywords"]) : undefined,
    make: data["make"] !== undefined ? encodeBase64(data["make"]) : undefined,
    medium: data["medium"] !== undefined ? encodeBase64(data["medium"]) : undefined,
    metadata: data["metadata"] !== undefined ? data["metadata"].map((item: any) => (serializeVideoClipInfo(item))) : undefined,
    model: data["model"] !== undefined ? encodeBase64(data["model"]) : undefined,
    performer: data["performer"] !== undefined ? encodeBase64(data["performer"]) : undefined,
    producer: data["producer"] !== undefined ? encodeBase64(data["producer"]) : undefined,
    requirements: data["requirements"] !== undefined ? encodeBase64(data["requirements"]) : undefined,
    software: data["software"] !== undefined ? encodeBase64(data["software"]) : undefined,
    sourceProvider: data["sourceProvider"] !== undefined ? encodeBase64(data["sourceProvider"]) : undefined,
    subject: data["subject"] !== undefined ? encodeBase64(data["subject"]) : undefined,
    technician: data["technician"] !== undefined ? encodeBase64(data["technician"]) : undefined,
    title: data["title"] !== undefined ? encodeBase64(data["title"]) : undefined,
    videoVendorId: data["videoVendorId"] !== undefined ? encodeBase64(data["videoVendorId"]) : undefined,
  };
}

function deserializeVideoVideoClipInfo(data: any): VideoVideoClipInfo {
  return {
    ...data,
    artist: data["artist"] !== undefined ? decodeBase64(data["artist"] as string) : undefined,
    audioVendorId: data["audioVendorId"] !== undefined ? decodeBase64(data["audioVendorId"] as string) : undefined,
    author: data["author"] !== undefined ? decodeBase64(data["author"] as string) : undefined,
    comment: data["comment"] !== undefined ? decodeBase64(data["comment"] as string) : undefined,
    commissioned: data["commissioned"] !== undefined ? decodeBase64(data["commissioned"] as string) : undefined,
    copyright: data["copyright"] !== undefined ? decodeBase64(data["copyright"] as string) : undefined,
    digitizationTime: data["digitizationTime"] !== undefined ? decodeBase64(data["digitizationTime"] as string) : undefined,
    director: data["director"] !== undefined ? decodeBase64(data["director"] as string) : undefined,
    engineer: data["engineer"] !== undefined ? decodeBase64(data["engineer"] as string) : undefined,
    info: data["info"] !== undefined ? decodeBase64(data["info"] as string) : undefined,
    keywords: data["keywords"] !== undefined ? decodeBase64(data["keywords"] as string) : undefined,
    make: data["make"] !== undefined ? decodeBase64(data["make"] as string) : undefined,
    medium: data["medium"] !== undefined ? decodeBase64(data["medium"] as string) : undefined,
    metadata: data["metadata"] !== undefined ? data["metadata"].map((item: any) => (deserializeVideoClipInfo(item))) : undefined,
    model: data["model"] !== undefined ? decodeBase64(data["model"] as string) : undefined,
    performer: data["performer"] !== undefined ? decodeBase64(data["performer"] as string) : undefined,
    producer: data["producer"] !== undefined ? decodeBase64(data["producer"] as string) : undefined,
    requirements: data["requirements"] !== undefined ? decodeBase64(data["requirements"] as string) : undefined,
    software: data["software"] !== undefined ? decodeBase64(data["software"] as string) : undefined,
    sourceProvider: data["sourceProvider"] !== undefined ? decodeBase64(data["sourceProvider"] as string) : undefined,
    subject: data["subject"] !== undefined ? decodeBase64(data["subject"] as string) : undefined,
    technician: data["technician"] !== undefined ? decodeBase64(data["technician"] as string) : undefined,
    title: data["title"] !== undefined ? decodeBase64(data["title"] as string) : undefined,
    videoVendorId: data["videoVendorId"] !== undefined ? decodeBase64(data["videoVendorId"] as string) : undefined,
  };
}

/**
 * Generic geo-location information. This is error-prone due to the fact that
 * is uses signed integer fields, which are not supported by proto1 API and are
 * cast to unsigned integers. Consider using the metadata_util function
 * directly, which fills out a version 2 API proto.
 */
export interface VideoVideoGeoLocation {
  /**
   * Altitude is in meters and multiplied by 100 (i.e., in centimeters). Up
   * till 10 km this fits in 3 bytes.
   */
  altitudeE2?: number;
  /**
   * Latitude and longitude are in degrees and multiplied by 10^7. This gives
   * the worst precision of about 1 cm at the equator.
   */
  latitudeE7?: number;
  longitudeE7?: number;
}

export interface VideoVideoStream {
  /**
   * Video bitrate in bits/s.
   */
  bitrate?: bigint;
  /**
   * Video codec ID. Uses the numeric value corresponding to the CodecId enum
   * object, in order to avoid the dependency on vsi/videostreaminfo.proto.
   * http://cs/symbol:CodecId%20f:google3/video/vidproc/vsi/videostreaminfo.proto
   */
  codecId?: number;
  /**
   * Video frame per second, obtained by parsing video header information. The
   * value can be inaccurate for some types of codecs. See comments at
   * http://cs/symbol:video_fps%20f:google3/video/vidproc/vsi/videostreaminfo.proto
   */
  fps?: number;
  height?: number;
  /**
   * Video length, in seconds. This value is derived from metadata in the
   * source video, and often differs from the actual duration of any given
   * transcode. In videos without valid timestamps, this value is not
   * calculable, and is reported as zero.
   */
  lengthSec?: number;
  /**
   * Index of the stream in the file, 0-based.
   */
  streamIndex?: bigint;
  /**
   * video width and height.
   */
  width?: number;
}

function serializeVideoVideoStream(data: any): VideoVideoStream {
  return {
    ...data,
    bitrate: data["bitrate"] !== undefined ? String(data["bitrate"]) : undefined,
    streamIndex: data["streamIndex"] !== undefined ? String(data["streamIndex"]) : undefined,
  };
}

function deserializeVideoVideoStream(data: any): VideoVideoStream {
  return {
    ...data,
    bitrate: data["bitrate"] !== undefined ? BigInt(data["bitrate"]) : undefined,
    streamIndex: data["streamIndex"] !== undefined ? BigInt(data["streamIndex"]) : undefined,
  };
}

/**
 * Note that when a VSI is from a user video, the information reflects the info
 * in that source. Fields like lengths, fps, etc. are not guaranteed to be the
 * same as those of transcodes. If the relevant info in source is too broken,
 * the corresponding fields (e.g., lengths) could be unset or with the default
 * value, meaning VSI cannot compute them from the given info. Next id: 82
 */
export interface VideoVideoStreamInfo {
  /**
   * audio bitrate in bits/s
   */
  audioBitrate?: number;
  /**
   * audio channels
   */
  audioChannels?: number;
  /**
   * Primary audio codec information Fields 15-20, 41-42, 48, 52-53 for audio
   * will be obsolete soon. Please start using the new repeated audio_stream and
   * video_stream. For now, audio_stream(0) will match these fields. Primary
   * audio codec information starts:
   */
  audioCodecId?:  | "CODEC_ID_NONE" | "CODEC_ID_MPEG1VIDEO" | "CODEC_ID_MPEG2VIDEO" | "CODEC_ID_MPEG2VIDEO_XVMC" | "CODEC_ID_H261" | "CODEC_ID_H263" | "CODEC_ID_RV10" | "CODEC_ID_RV20" | "CODEC_ID_MJPEG" | "CODEC_ID_MJPEGB" | "CODEC_ID_LJPEG" | "CODEC_ID_SP5X" | "CODEC_ID_JPEGLS" | "CODEC_ID_MPEG4" | "CODEC_ID_RAWVIDEO" | "CODEC_ID_MSMPEG4V1" | "CODEC_ID_MSMPEG4V2" | "CODEC_ID_MSMPEG4V3" | "CODEC_ID_WMV1" | "CODEC_ID_WMV2" | "CODEC_ID_H263P" | "CODEC_ID_H263I" | "CODEC_ID_FLV1" | "CODEC_ID_SVQ1" | "CODEC_ID_SVQ3" | "CODEC_ID_DVVIDEO" | "CODEC_ID_HUFFYUV" | "CODEC_ID_CYUV" | "CODEC_ID_H264" | "CODEC_ID_INDEO3" | "CODEC_ID_VP3" | "CODEC_ID_THEORA" | "CODEC_ID_ASV1" | "CODEC_ID_ASV2" | "CODEC_ID_FFV1" | "CODEC_ID_4XM" | "CODEC_ID_VCR1" | "CODEC_ID_CLJR" | "CODEC_ID_MDEC" | "CODEC_ID_ROQ" | "CODEC_ID_INTERPLAY_VIDEO" | "CODEC_ID_XAN_WC3" | "CODEC_ID_XAN_WC4" | "CODEC_ID_RPZA" | "CODEC_ID_CINEPAK" | "CODEC_ID_WS_VQA" | "CODEC_ID_MSRLE" | "CODEC_ID_MSVIDEO1" | "CODEC_ID_IDCIN" | "CODEC_ID_8BPS" | "CODEC_ID_SMC" | "CODEC_ID_FLIC" | "CODEC_ID_TRUEMOTION1" | "CODEC_ID_VMDVIDEO" | "CODEC_ID_MSZH" | "CODEC_ID_ZLIB" | "CODEC_ID_QTRLE" | "CODEC_ID_SNOW" | "CODEC_ID_TSCC" | "CODEC_ID_ULTI" | "CODEC_ID_QDRAW" | "CODEC_ID_VIXL" | "CODEC_ID_QPEG" | "CODEC_ID_XVID" | "CODEC_ID_PNG" | "CODEC_ID_PPM" | "CODEC_ID_PBM" | "CODEC_ID_PGM" | "CODEC_ID_PGMYUV" | "CODEC_ID_PAM" | "CODEC_ID_FFVHUFF" | "CODEC_ID_RV30" | "CODEC_ID_RV40" | "CODEC_ID_VC1" | "CODEC_ID_WMV3" | "CODEC_ID_LOCO" | "CODEC_ID_WNV1" | "CODEC_ID_AASC" | "CODEC_ID_INDEO2" | "CODEC_ID_FRAPS" | "CODEC_ID_TRUEMOTION2" | "CODEC_ID_BMP" | "CODEC_ID_CSCD" | "CODEC_ID_MMVIDEO" | "CODEC_ID_ZMBV" | "CODEC_ID_AVS" | "CODEC_ID_SMACKVIDEO" | "CODEC_ID_NUV" | "CODEC_ID_KMVC" | "CODEC_ID_FLASHSV" | "CODEC_ID_CAVS" | "CODEC_ID_JPEG2000" | "CODEC_ID_VMNC" | "CODEC_ID_VP5" | "CODEC_ID_VP6" | "CODEC_ID_VP6F" | "CODEC_ID_TARGA" | "CODEC_ID_DSICINVIDEO" | "CODEC_ID_TIERTEXSEQVIDEO" | "CODEC_ID_TIFF" | "CODEC_ID_GIF" | "CODEC_ID_FFH264" | "CODEC_ID_DXA" | "CODEC_ID_DNXHD" | "CODEC_ID_THP" | "CODEC_ID_SGI" | "CODEC_ID_C93" | "CODEC_ID_BETHSOFTVID" | "CODEC_ID_PTX" | "CODEC_ID_TXD" | "CODEC_ID_VP6A" | "CODEC_ID_AMV" | "CODEC_ID_VB" | "CODEC_ID_PCX" | "CODEC_ID_SUNRAST" | "CODEC_ID_INDEO4" | "CODEC_ID_INDEO5" | "CODEC_ID_MIMIC" | "CODEC_ID_RL2" | "CODEC_ID_8SVX_EXP" | "CODEC_ID_8SVX_FIB" | "CODEC_ID_ESCAPE124" | "CODEC_ID_DIRAC" | "CODEC_ID_BFI" | "CODEC_ID_CMV" | "CODEC_ID_MOTIONPIXELS" | "CODEC_ID_TGV" | "CODEC_ID_TGQ" | "CODEC_ID_TQI" | "CODEC_ID_AURA" | "CODEC_ID_AURA2" | "CODEC_ID_V210X" | "CODEC_ID_TMV" | "CODEC_ID_V210" | "CODEC_ID_DPX" | "CODEC_ID_MAD" | "CODEC_ID_FRWU" | "CODEC_ID_VP8" | "CODEC_ID_APPLE_PRORES_NQ" | "CODEC_ID_APPLE_PRORES_HQ" | "CODEC_ID_FLASHSV2" | "CODEC_ID_CDGRAPHICS" | "CODEC_ID_R210" | "CODEC_ID_ANM" | "CODEC_ID_BINKVIDEO" | "CODEC_ID_IFF_ILBM" | "CODEC_ID_IFF_BYTERUN1" | "CODEC_ID_KGV1" | "CODEC_ID_YOP" | "CODEC_ID_PICTOR" | "CODEC_ID_APPLE_PRORES_LT" | "CODEC_ID_APPLE_PRORES_PROXY" | "CODEC_ID_APPLE_PRORES_4444" | "CODEC_ID_APPLE_PIXLET" | "CODEC_ID_G2M" | "CODEC_ID_PRORES" | "CODEC_ID_ANSI" | "CODEC_ID_A64_MULTI" | "CODEC_ID_A64_MULTI5" | "CODEC_ID_R10K" | "CODEC_ID_MXPEG" | "CODEC_ID_LAGARITH" | "CODEC_ID_JV" | "CODEC_ID_DFA" | "CODEC_ID_WMV3IMAGE" | "CODEC_ID_VC1IMAGE" | "CODEC_ID_UTVIDEO" | "CODEC_ID_BMV_VIDEO" | "CODEC_ID_VBLE" | "CODEC_ID_DXTORY" | "CODEC_ID_V410" | "CODEC_ID_XWD" | "CODEC_ID_CDXL" | "CODEC_ID_XBM" | "CODEC_ID_ZEROCODEC" | "CODEC_ID_MSS1" | "CODEC_ID_MSA1" | "CODEC_ID_TSCC2" | "CODEC_ID_MTS2" | "CODEC_ID_CLLC" | "CODEC_ID_MSS2" | "CODEC_ID_Y41P" | "CODEC_ID_ESCAPE130" | "CODEC_ID_EXR" | "CODEC_ID_AVRP" | "CODEC_ID_AVUI" | "CODEC_ID_AYUV" | "CODEC_ID_V308" | "CODEC_ID_V408" | "CODEC_ID_YUV4" | "CODEC_ID_SANM" | "CODEC_ID_PAF_VIDEO" | "CODEC_ID_AVRN" | "CODEC_ID_CPIA" | "CODEC_ID_VP9" | "CODEC_ID_H265" | "CODEC_ID_CFHD" | "CODEC_ID_AV1" | "CODEC_ID_AIC" | "CODEC_ID_ALIAS_PIX" | "CODEC_ID_APNG" | "CODEC_ID_BRENDER_PIX" | "CODEC_ID_CLEARVIDEO" | "CODEC_ID_DDS" | "CODEC_ID_DXV" | "CODEC_ID_FIC" | "CODEC_ID_FITS" | "CODEC_ID_FMVC" | "CODEC_ID_GDV" | "CODEC_ID_HAP" | "CODEC_ID_HNM4_VIDEO" | "CODEC_ID_HQ_HQA" | "CODEC_ID_HQX" | "CODEC_ID_M101" | "CODEC_ID_MAGICYUV" | "CODEC_ID_MSCC" | "CODEC_ID_MVC1" | "CODEC_ID_MVC2" | "CODEC_ID_PIXLET" | "CODEC_ID_PSD" | "CODEC_ID_RSCC" | "CODEC_ID_SCPR" | "CODEC_ID_SCREENPRESSO" | "CODEC_ID_SGIRLE" | "CODEC_ID_SHEERVIDEO" | "CODEC_ID_SMVJPEG" | "CODEC_ID_SPEEDHQ" | "CODEC_ID_SRGC" | "CODEC_ID_TARGA_Y216" | "CODEC_ID_TDSC" | "CODEC_ID_TRUEMOTION2RT" | "CODEC_ID_VP7" | "CODEC_ID_BITPACKED" | "CODEC_ID_WEBP" | "CODEC_ID_XFACE" | "CODEC_ID_XPM" | "CODEC_ID_YLC" | "CODEC_ID_012V" | "CODEC_ID_AVS2" | "CODEC_ID_IMM4" | "CODEC_ID_MWSC" | "CODEC_ID_PROSUMER" | "CODEC_ID_RASC" | "CODEC_ID_WCMV" | "CODEC_ID_UNKNOWN" | "CODEC_ID_PCM_S16LE" | "CODEC_ID_PCM_S16BE" | "CODEC_ID_PCM_U16LE" | "CODEC_ID_PCM_U16BE" | "CODEC_ID_PCM_S8" | "CODEC_ID_PCM_U8" | "CODEC_ID_PCM_MULAW" | "CODEC_ID_PCM_ALAW" | "CODEC_ID_PCM_S32LE" | "CODEC_ID_PCM_S32BE" | "CODEC_ID_PCM_U32LE" | "CODEC_ID_PCM_U32BE" | "CODEC_ID_PCM_S24LE" | "CODEC_ID_PCM_S24BE" | "CODEC_ID_PCM_U24LE" | "CODEC_ID_PCM_U24BE" | "CODEC_ID_PCM_S24DAUD" | "CODEC_ID_PCM_ZORK" | "CODEC_ID_PCM_S16LE_PLANAR" | "CODEC_ID_PCM_DVD" | "CODEC_ID_PCM_F32BE" | "CODEC_ID_PCM_F32LE" | "CODEC_ID_PCM_F64BE" | "CODEC_ID_PCM_F64LE" | "CODEC_ID_PCM_BLURAY" | "CODEC_ID_PCM_LXF" | "CODEC_ID_S302M" | "CODEC_ID_PCM_S8_PLANAR" | "CODEC_ID_PCM_S24LE_PLANAR" | "CODEC_ID_PCM_S32LE_PLANAR" | "CODEC_ID_PCM_S16BE_PLANAR" | "CODEC_ID_PCM_S64LE" | "CODEC_ID_PCM_S64BE" | "CODEC_ID_PCM_F16LE" | "CODEC_ID_PCM_F24LE" | "CODEC_ID_ADPCM_IMA_QT" | "CODEC_ID_ADPCM_IMA_WAV" | "CODEC_ID_ADPCM_IMA_DK3" | "CODEC_ID_ADPCM_IMA_DK4" | "CODEC_ID_ADPCM_IMA_WS" | "CODEC_ID_ADPCM_IMA_SMJPEG" | "CODEC_ID_ADPCM_MS" | "CODEC_ID_ADPCM_4XM" | "CODEC_ID_ADPCM_XA" | "CODEC_ID_ADPCM_ADX" | "CODEC_ID_ADPCM_EA" | "CODEC_ID_ADPCM_G726" | "CODEC_ID_ADPCM_CT" | "CODEC_ID_ADPCM_SWF" | "CODEC_ID_ADPCM_YAMAHA" | "CODEC_ID_ADPCM_SBPRO_4" | "CODEC_ID_ADPCM_SBPRO_3" | "CODEC_ID_ADPCM_SBPRO_2" | "CODEC_ID_ADPCM_THP" | "CODEC_ID_ADPCM_IMA_AMV" | "CODEC_ID_ADPCM_EA_R1" | "CODEC_ID_ADPCM_EA_R3" | "CODEC_ID_ADPCM_EA_R2" | "CODEC_ID_ADPCM_IMA_EA_SEAD" | "CODEC_ID_ADPCM_IMA_EA_EACS" | "CODEC_ID_ADPCM_EA_XAS" | "CODEC_ID_ADPCM_EA_MAXIS_XA" | "CODEC_ID_ADPCM_IMA_ISS" | "CODEC_ID_ADPCM_G722" | "CODEC_ID_ADPCM_IMA_APC" | "CODEC_ID_VIMA" | "CODEC_ID_ADPCM_AFC" | "CODEC_ID_ADPCM_IMA_OKI" | "CODEC_ID_ADPCM_DTK" | "CODEC_ID_ADPCM_IMA_RAD" | "CODEC_ID_ADPCM_G726LE" | "CODEC_ID_ADPCM_THP_LE" | "CODEC_ID_ADPCM_PSX" | "CODEC_ID_ADPCM_AICA" | "CODEC_ID_ADPCM_IMA_DAT4" | "CODEC_ID_ADPCM_MTAF" | "CODEC_ID_ADPCM_VIMA" | "CODEC_ID_AMR_NB" | "CODEC_ID_AMR_WB" | "CODEC_ID_RA_144" | "CODEC_ID_RA_288" | "CODEC_ID_ROQ_DPCM" | "CODEC_ID_INTERPLAY_DPCM" | "CODEC_ID_XAN_DPCM" | "CODEC_ID_SOL_DPCM" | "CODEC_ID_GREMLIN_DPCM" | "CODEC_ID_SDX2_DPCM" | "CODEC_ID_MP2" | "CODEC_ID_MP3" | "CODEC_ID_AAC" | "CODEC_ID_MPEG4AAC_DEPRECATED" | "CODEC_ID_AC3" | "CODEC_ID_DTS" | "CODEC_ID_VORBIS" | "CODEC_ID_DVAUDIO" | "CODEC_ID_WMAV1" | "CODEC_ID_WMAV2" | "CODEC_ID_MACE3" | "CODEC_ID_MACE6" | "CODEC_ID_VMDAUDIO" | "CODEC_ID_SONIC" | "CODEC_ID_SONIC_LS" | "CODEC_ID_FLAC" | "CODEC_ID_MP3ADU" | "CODEC_ID_MP3ON4" | "CODEC_ID_SHORTEN" | "CODEC_ID_ALAC" | "CODEC_ID_WESTWOOD_SND1" | "CODEC_ID_GSM" | "CODEC_ID_QDM2" | "CODEC_ID_COOK" | "CODEC_ID_TRUESPEECH" | "CODEC_ID_TTA" | "CODEC_ID_SMACKAUDIO" | "CODEC_ID_QCELP" | "CODEC_ID_WAVPACK" | "CODEC_ID_DSICINAUDIO" | "CODEC_ID_ASAO" | "CODEC_ID_NELLYMOSER" | "CODEC_ID_WMAVOICE" | "CODEC_ID_WMAPRO" | "CODEC_ID_WMALOSSLESS" | "CODEC_ID_IMC" | "CODEC_ID_MUSEPACK7" | "CODEC_ID_MLP" | "CODEC_ID_GSM_MS" | "CODEC_ID_ATRAC3" | "CODEC_ID_VOXWARE" | "CODEC_ID_APE" | "CODEC_ID_MUSEPACK8" | "CODEC_ID_SPEEX" | "CODEC_ID_ATRAC3P" | "CODEC_ID_EAC3" | "CODEC_ID_SIPR" | "CODEC_ID_MP1" | "CODEC_ID_TWINVQ" | "CODEC_ID_TRUEHD" | "CODEC_ID_MP4ALS" | "CODEC_ID_ATRAC1" | "CODEC_ID_BINKAUDIO_RDFT" | "CODEC_ID_BINKAUDIO_DCT" | "CODEC_ID_AAC_LATM" | "CODEC_ID_QDMC" | "CODEC_ID_CELT" | "CODEC_ID_G723_1" | "CODEC_ID_G729" | "CODEC_ID_BMV_AUDIO" | "CODEC_ID_RALF" | "CODEC_ID_IAC" | "CODEC_ID_ILBC" | "CODEC_ID_FFWAVESYNTH" | "CODEC_ID_8SVX_RAW" | "CODEC_ID_PAF_AUDIO" | "CODEC_ID_OPUS" | "CODEC_ID_ATRAC3AL" | "CODEC_ID_ATRAC3PAL" | "CODEC_ID_DOLBY_E" | "CODEC_ID_DSD_LSBF" | "CODEC_ID_DSD_MSBF" | "CODEC_ID_DSD_LSBF_PLANAR" | "CODEC_ID_DSD_MSBF_PLANAR" | "CODEC_ID_DSS_SP" | "CODEC_ID_DST" | "CODEC_ID_EVRC" | "CODEC_ID_INTERPLAY_ACM" | "CODEC_ID_METASOUND" | "CODEC_ID_ON2AVC" | "CODEC_ID_TAK" | "CODEC_ID_XMA1" | "CODEC_ID_XMA2" | "CODEC_ID_COMFORT_NOISE" | "CODEC_ID_APTX" | "CODEC_ID_APTX_HD" | "CODEC_ID_SBC" | "CODEC_ID_ATRAC9" | "CODEC_ID_CODEC2" | "CODEC_ID_OGGTHEORA_DEPRECATED" | "CODEC_ID_DVD_SUBTITLE" | "CODEC_ID_DVB_SUBTITLE" | "CODEC_ID_TEXT" | "CODEC_ID_XSUB" | "CODEC_ID_SSA" | "CODEC_ID_MOV_TEXT" | "CODEC_ID_HDMV_PGS_SUBTITLE" | "CODEC_ID_DVB_TELETEXT" | "CODEC_ID_SRT" | "CODEC_ID_MICRODVD" | "CODEC_ID_EIA_608" | "CODEC_ID_JACOSUB" | "CODEC_ID_SAMI" | "CODEC_ID_REALTEXT" | "CODEC_ID_SUBVIEWER" | "CODEC_ID_SUBRIP" | "CODEC_ID_WEBVTT" | "CODEC_ID_ASS" | "CODEC_ID_MPL2" | "CODEC_ID_PJS" | "CODEC_ID_STL" | "CODEC_ID_SUBVIEWER1" | "CODEC_ID_VPLAYER" | "CODEC_ID_TTML" | "CODEC_ID_TTF" | "CODEC_ID_BINTEXT" | "CODEC_ID_XBIN" | "CODEC_ID_IDF" | "CODEC_ID_OTF" | "CODEC_ID_PROBE" | "CODEC_ID_MPEG2TS" | "CODEC_ID_MPEG4SYSTEMS" | "CODEC_ID_FFMETADATA" | "CODEC_ID_FFMPEG_OUT_OF_SYNC" | "CODEC_ID_WRAPPED_AVFRAME" | "CODEC_ID_CAMM";
  audioEndTimestamp?: bigint;
  /**
   * audio frame size
   */
  audioFrameSize?: bigint;
  /**
   * audio length in seconds Note that when the VSI is from users videos, it is
   * not guaranteed to be the same as transcode lengths and it could be 0 when
   * the full VSI cannot compute the length from the source header and
   * timestamps (for example when header and timestamps are too broken).
   */
  audioLength?: number;
  /**
   * Number of audio frames. Ffmpeg does not report the number of frames
   * accurately. video::TranscodedVideoFileInformation calls Google's analyzer
   * to get information of both audio and video frame numbers.
   */
  audioNumberOfFrames?: bigint;
  /**
   * audio sample rate
   */
  audioSampleRate?: bigint;
  /**
   * Number of meaningful bits per decoded audio sample. This is an implicit
   * conceptual meaning. This is *NOT* the same as ffmpeg's internal sample
   * format that is used when actually decoding with ffmpeg.
   */
  audioSampleSize?: number;
  audioStartTimestamp?: bigint;
  audioStream?: VideoVideoStreamInfoAudioStream[];
  audioStreamCodecTag?: bigint;
  /**
   * Audio-Video interleaving distance between packets (in bytes)
   */
  avDistance?: number;
  /**
   * Average video fps from analyzing entire file.
   */
  averageVideoFps?: number;
  /**
   * Audio and video length in seconds. It's the max of the audio and video
   * length. Note that when the VSI is from users videos, it is not guaranteed
   * to be the same as transcode lengths and it could be 0 when the full VSI
   * cannot compute the length from the source header and timestamps (for
   * example when header and timestamps are too broken).
   */
  avLength?: number;
  /**
   * Build label of the VSI mpm.
   */
  buildLabel?: string;
  /**
   * Container Id.
   */
  containerId?:  | "CONTAINER_ID_NONE" | "CONTAINER_ID_FOURXM" | "CONTAINER_ID_AIFF" | "CONTAINER_ID_AMR" | "CONTAINER_ID_ASF" | "CONTAINER_ID_AU" | "CONTAINER_ID_AUDIO" | "CONTAINER_ID_AVI" | "CONTAINER_ID_AVISYNTH" | "CONTAINER_ID_AVS" | "CONTAINER_ID_DAUD" | "CONTAINER_ID_DC1394" | "CONTAINER_ID_DSICIN" | "CONTAINER_ID_DV1394" | "CONTAINER_ID_DV" | "CONTAINER_ID_EA" | "CONTAINER_ID_FFM" | "CONTAINER_ID_FLIC" | "CONTAINER_ID_FLV" | "CONTAINER_ID_GIF" | "CONTAINER_ID_VIDEO_GRAB_DEVICE" | "CONTAINER_ID_GXF" | "CONTAINER_ID_IDCIN" | "CONTAINER_ID_ROQ" | "CONTAINER_ID_IMAGE2" | "CONTAINER_ID_IMAGE2PIPE" | "CONTAINER_ID_IMAGE" | "CONTAINER_ID_IMAGEPIPE" | "CONTAINER_ID_IPMOVIE" | "CONTAINER_ID_MATROSKA" | "CONTAINER_ID_MM" | "CONTAINER_ID_MMF" | "CONTAINER_ID_MOV" | "CONTAINER_ID_MP3" | "CONTAINER_ID_MPEGPS" | "CONTAINER_ID_MPEGTS" | "CONTAINER_ID_MTV" | "CONTAINER_ID_MXF" | "CONTAINER_ID_NSV" | "CONTAINER_ID_NUT" | "CONTAINER_ID_NUV" | "CONTAINER_ID_OGG" | "CONTAINER_ID_STR" | "CONTAINER_ID_SHORTEN" | "CONTAINER_ID_FLAC" | "CONTAINER_ID_AC3" | "CONTAINER_ID_DTS" | "CONTAINER_ID_AAC" | "CONTAINER_ID_H261" | "CONTAINER_ID_H263" | "CONTAINER_ID_M4V" | "CONTAINER_ID_H264" | "CONTAINER_ID_MPEGVIDEO" | "CONTAINER_ID_MJPEG" | "CONTAINER_ID_INGENIENT" | "CONTAINER_ID_PCM_S16LE" | "CONTAINER_ID_PCM_S16BE" | "CONTAINER_ID_PCM_U16LE" | "CONTAINER_ID_PCM_U16BE" | "CONTAINER_ID_PCM_S8" | "CONTAINER_ID_PCM_U8" | "CONTAINER_ID_PCM_MULAW" | "CONTAINER_ID_PCM_ALAW" | "CONTAINER_ID_RAWVIDEO" | "CONTAINER_ID_RM" | "CONTAINER_ID_SDP" | "CONTAINER_ID_REDIR" | "CONTAINER_ID_SEGAFILM" | "CONTAINER_ID_VMD" | "CONTAINER_ID_SMACKER" | "CONTAINER_ID_SOL" | "CONTAINER_ID_SWF" | "CONTAINER_ID_TTA" | "CONTAINER_ID_V4L2" | "CONTAINER_ID_VOC" | "CONTAINER_ID_WAV" | "CONTAINER_ID_WC3" | "CONTAINER_ID_WSAUD" | "CONTAINER_ID_WSVQA" | "CONTAINER_ID_WV" | "CONTAINER_ID_YUV4MPEGPIPE" | "CONTAINER_ID_TIERTEXSEQ" | "CONTAINER_ID_WEBM" | "CONTAINER_ID_EAC3" | "CONTAINER_ID_AA" | "CONTAINER_ID_ACM" | "CONTAINER_ID_ACT" | "CONTAINER_ID_ADF" | "CONTAINER_ID_ADP" | "CONTAINER_ID_ADS" | "CONTAINER_ID_ADX" | "CONTAINER_ID_AEA" | "CONTAINER_ID_AFC" | "CONTAINER_ID_AIX" | "CONTAINER_ID_ANM" | "CONTAINER_ID_APC" | "CONTAINER_ID_APE" | "CONTAINER_ID_APNG" | "CONTAINER_ID_AQTITLE" | "CONTAINER_ID_ASF_O" | "CONTAINER_ID_ASS" | "CONTAINER_ID_AST" | "CONTAINER_ID_AVR" | "CONTAINER_ID_BETHSOFTVID" | "CONTAINER_ID_BFI" | "CONTAINER_ID_BIN" | "CONTAINER_ID_BINK" | "CONTAINER_ID_BIT" | "CONTAINER_ID_BMV" | "CONTAINER_ID_BFSTM" | "CONTAINER_ID_BRSTM" | "CONTAINER_ID_BOA" | "CONTAINER_ID_C93" | "CONTAINER_ID_CAF" | "CONTAINER_ID_CAVSVIDEO" | "CONTAINER_ID_CDG" | "CONTAINER_ID_CDXL" | "CONTAINER_ID_CINE" | "CONTAINER_ID_CONCAT" | "CONTAINER_ID_DATA" | "CONTAINER_ID_DCSTR" | "CONTAINER_ID_DFA" | "CONTAINER_ID_DIRAC" | "CONTAINER_ID_DNXHD" | "CONTAINER_ID_DSF" | "CONTAINER_ID_DSS" | "CONTAINER_ID_DTSHD" | "CONTAINER_ID_DVBSUB" | "CONTAINER_ID_DVBTXT" | "CONTAINER_ID_DXA" | "CONTAINER_ID_EA_CDATA" | "CONTAINER_ID_EPAF" | "CONTAINER_ID_FFMETADATA" | "CONTAINER_ID_FILMSTRIP" | "CONTAINER_ID_FITS" | "CONTAINER_ID_FRM" | "CONTAINER_ID_FSB" | "CONTAINER_ID_G722" | "CONTAINER_ID_G723_1" | "CONTAINER_ID_G726" | "CONTAINER_ID_G726LE" | "CONTAINER_ID_G729" | "CONTAINER_ID_GDV" | "CONTAINER_ID_GENH" | "CONTAINER_ID_GSM" | "CONTAINER_ID_HEVC" | "CONTAINER_ID_HNM" | "CONTAINER_ID_ICO" | "CONTAINER_ID_IDF" | "CONTAINER_ID_IFF" | "CONTAINER_ID_ILBC" | "CONTAINER_ID_ALIAS_PIX" | "CONTAINER_ID_BRENDER_PIX" | "CONTAINER_ID_IRCAM" | "CONTAINER_ID_ISS" | "CONTAINER_ID_IV8" | "CONTAINER_ID_IVF" | "CONTAINER_ID_IVR" | "CONTAINER_ID_JACOSUB" | "CONTAINER_ID_JV" | "CONTAINER_ID_LMLM4" | "CONTAINER_ID_LOAS" | "CONTAINER_ID_LRC" | "CONTAINER_ID_LVF" | "CONTAINER_ID_LXF" | "CONTAINER_ID_MGSTS" | "CONTAINER_ID_MICRODVD" | "CONTAINER_ID_MJPEG_2000" | "CONTAINER_ID_MLP" | "CONTAINER_ID_MLV" | "CONTAINER_ID_MPC" | "CONTAINER_ID_MPC8" | "CONTAINER_ID_MPEGTSRAW" | "CONTAINER_ID_MPJPEG" | "CONTAINER_ID_MPL2" | "CONTAINER_ID_MPSUB" | "CONTAINER_ID_MSF" | "CONTAINER_ID_MSNWCTCP" | "CONTAINER_ID_MTAF" | "CONTAINER_ID_MUSX" | "CONTAINER_ID_MV" | "CONTAINER_ID_MVI" | "CONTAINER_ID_MXG" | "CONTAINER_ID_NC" | "CONTAINER_ID_NISTSPHERE" | "CONTAINER_ID_OMA" | "CONTAINER_ID_PAF" | "CONTAINER_ID_ALAW" | "CONTAINER_ID_MULAW" | "CONTAINER_ID_F64BE" | "CONTAINER_ID_F64LE" | "CONTAINER_ID_F32BE" | "CONTAINER_ID_F32LE" | "CONTAINER_ID_S32BE" | "CONTAINER_ID_S32LE" | "CONTAINER_ID_S24BE" | "CONTAINER_ID_S24LE" | "CONTAINER_ID_S16BE" | "CONTAINER_ID_S16LE" | "CONTAINER_ID_S8" | "CONTAINER_ID_U32BE" | "CONTAINER_ID_U32LE" | "CONTAINER_ID_U24BE" | "CONTAINER_ID_U24LE" | "CONTAINER_ID_U16BE" | "CONTAINER_ID_U16LE" | "CONTAINER_ID_U8" | "CONTAINER_ID_PJS" | "CONTAINER_ID_PMP" | "CONTAINER_ID_PVA" | "CONTAINER_ID_PVF" | "CONTAINER_ID_QCP" | "CONTAINER_ID_R3D" | "CONTAINER_ID_REALTEXT" | "CONTAINER_ID_REDSPARK" | "CONTAINER_ID_RL2" | "CONTAINER_ID_RPL" | "CONTAINER_ID_RSD" | "CONTAINER_ID_RSO" | "CONTAINER_ID_RTP" | "CONTAINER_ID_RTSP" | "CONTAINER_ID_S337M" | "CONTAINER_ID_SAMI" | "CONTAINER_ID_SAP" | "CONTAINER_ID_SBG" | "CONTAINER_ID_SCC" | "CONTAINER_ID_SDR2" | "CONTAINER_ID_SDS" | "CONTAINER_ID_SDX" | "CONTAINER_ID_FILM_CPK" | "CONTAINER_ID_SHN" | "CONTAINER_ID_SIFF" | "CONTAINER_ID_SLN" | "CONTAINER_ID_SMJPEG" | "CONTAINER_ID_SMUSH" | "CONTAINER_ID_SOX" | "CONTAINER_ID_SPDIF" | "CONTAINER_ID_SRT" | "CONTAINER_ID_STL" | "CONTAINER_ID_SUBVIEWER1" | "CONTAINER_ID_SUBVIEWER" | "CONTAINER_ID_SUP" | "CONTAINER_ID_SVAG" | "CONTAINER_ID_TAK" | "CONTAINER_ID_TEDCAPTIONS" | "CONTAINER_ID_THP" | "CONTAINER_ID_3DOSTR" | "CONTAINER_ID_TMV" | "CONTAINER_ID_TRUEHD" | "CONTAINER_ID_TXD" | "CONTAINER_ID_V210" | "CONTAINER_ID_V210X" | "CONTAINER_ID_VAG" | "CONTAINER_ID_VC1" | "CONTAINER_ID_VC1TEST" | "CONTAINER_ID_VIVO" | "CONTAINER_ID_VOBSUB" | "CONTAINER_ID_VPK" | "CONTAINER_ID_VPLAYER" | "CONTAINER_ID_VQF" | "CONTAINER_ID_W64" | "CONTAINER_ID_WC3MOVIE" | "CONTAINER_ID_WEBM_DASH_MANIFEST" | "CONTAINER_ID_WEBVTT" | "CONTAINER_ID_WSD" | "CONTAINER_ID_WTV" | "CONTAINER_ID_WVE" | "CONTAINER_ID_XA" | "CONTAINER_ID_XBIN" | "CONTAINER_ID_XMV" | "CONTAINER_ID_XVAG" | "CONTAINER_ID_XWMA" | "CONTAINER_ID_YOP" | "CONTAINER_ID_AMRNB" | "CONTAINER_ID_AMRWB" | "CONTAINER_ID_APTX" | "CONTAINER_ID_NSP" | "CONTAINER_ID_TY" | "CONTAINER_ID_APTX_HD" | "CONTAINER_ID_AVS2" | "CONTAINER_ID_CODEC2" | "CONTAINER_ID_CODEC2RAW" | "CONTAINER_ID_SBC" | "CONTAINER_ID_SER" | "CONTAINER_ID_GOOGLE_INDEX" | "CONTAINER_ID_MEDIASAMPLE" | "CONTAINER_ID_TOOTHLESS" | "CONTAINER_ID_MEDIASAMPLE_DEPRECATED";
  /**
   * Name of the container format guessed by ffmpeg.
   */
  containerType?: string;
  /**
   * If the video contains chapters info.
   */
  containsChapters?: boolean;
  dataStream?: VideoVideoStreamInfoDataStream[];
  displayHeight?: number;
  /**
   * final display video width and height if explicitly set in the video
   * otherwise this can be calculated from source width/height and
   * video_pixel_aspect_ratio
   */
  displayWidth?: number;
  /**
   * Input file header fingerprint
   */
  fileHeaderFingerprint?: bigint;
  /**
   * The file type string returned by libmagic, a third party library. It might
   * accidentally include some user content. Some normal file_magic examples: --
   * RIFF (little-endian) data, AVI, 1016 x 696, 30.00 fps, video: XviD, audio:
   * (stereo, 48000 Hz) -- MPEG sequence, v2, program multiplex -- ISO Media,
   * MPEG v4 system, iTunes AVC-LC -- Microsoft Windows Movie Maker project file
   */
  fileMagic?: string;
  /**
   * Input file modification time
   */
  fileModifiedTime?: bigint;
  /**
   * Input file name. DEPRECATED; don't expect the file name to be correct.
   */
  fileName?: string;
  /**
   * Input file size in bytes
   */
  fileSize?: bigint;
  /**
   * High-level file type guessed by looking at the file headers and libmagic.
   */
  fileType?: number;
  imageStream?: VideoVideoStreamInfoVideoStream[];
  /**
   * True if the video is likely to be an ASF file.
   */
  isAsf?: boolean;
  /**
   * True if the video is actually an image file (JPEG, PNG, GIF, etc) and not
   * a video file.
   */
  isImageFile?: boolean;
  /**
   * Check if a video size insane or not. It is set if the input file is an MOV
   * file.
   */
  isVideoInsaneSize?: boolean;
  level?: number;
  metadata?: VideoVideoStreamInfoMetadata;
  /**
   * Total number of audio streams in the file
   */
  numAudioStreams?: number;
  /**
   * Total number of data streams in the file
   */
  numDataStreams?: number;
  /**
   * Total number of image streams in the file
   */
  numImageStreams?: number;
  /**
   * Total number of timedtext streams in the file
   */
  numTimedtextStreams?: number;
  /**
   * Total number of video streams in the file
   */
  numVideoStreams?: number;
  /**
   * If this field is not set, then only base video file information has been
   * generated (and ffmpeg parsing hasn't yet been done). If this is set to
   * 'false', then ffmpeg failed to parse the file - otherwise it will set to
   * 'true'
   */
  parsedByFfmpeg?: boolean;
  /**
   * By default we assume that the entire file was given computing the VSI - if
   * that is not true this flag should be set to true.
   */
  partialFile?: boolean;
  /**
   * Pixel format for the video stream.
   */
  pixFmt?:  | "PIX_FMT_NONE" | "PIX_FMT_YUV420P" | "PIX_FMT_YUYV422" | "PIX_FMT_RGB24" | "PIX_FMT_BGR24" | "PIX_FMT_YUV422P" | "PIX_FMT_YUV444P" | "PIX_FMT_RGB32" | "PIX_FMT_YUV410P" | "PIX_FMT_YUV411P" | "PIX_FMT_RGB565" | "PIX_FMT_RGB555" | "PIX_FMT_GRAY8" | "PIX_FMT_MONOWHITE" | "PIX_FMT_MONOBLACK" | "PIX_FMT_PAL8" | "PIX_FMT_YUVJ420P" | "PIX_FMT_YUVJ422P" | "PIX_FMT_YUVJ444P" | "PIX_FMT_XVMC_MPEG2_MC" | "PIX_FMT_XVMC_MPEG2_IDCT" | "PIX_FMT_UYVY422" | "PIX_FMT_UYYVYY411" | "PIX_FMT_BGR32" | "PIX_FMT_BGR565" | "PIX_FMT_BGR555" | "PIX_FMT_BGR8" | "PIX_FMT_BGR4" | "PIX_FMT_BGR4_BYTE" | "PIX_FMT_RGB8" | "PIX_FMT_RGB4" | "PIX_FMT_RGB4_BYTE" | "PIX_FMT_NV12" | "PIX_FMT_NV21" | "PIX_FMT_RGB32_1" | "PIX_FMT_BGR32_1" | "PIX_FMT_GRAY16BE" | "PIX_FMT_GRAY16LE" | "PIX_FMT_YUV440P" | "PIX_FMT_YUVJ440P" | "PIX_FMT_YUVA420P" | "PIX_FMT_VDPAU_H264" | "PIX_FMT_VDPAU_MPEG1" | "PIX_FMT_VDPAU_MPEG2" | "PIX_FMT_VDPAU_WMV3" | "PIX_FMT_VDPAU_VC1" | "PIX_FMT_RGB48BE" | "PIX_FMT_RGB48LE" | "PIX_FMT_RGB565BE" | "PIX_FMT_RGB555BE" | "PIX_FMT_BGR565BE" | "PIX_FMT_BGR555BE" | "PIX_FMT_VAAPI_MOCO" | "PIX_FMT_VAAPI_IDCT" | "PIX_FMT_VAAPI_VLD" | "PIX_FMT_YUV420P16LE" | "PIX_FMT_YUV420P16BE" | "PIX_FMT_YUV422P16LE" | "PIX_FMT_YUV422P16BE" | "PIX_FMT_YUV444P16LE" | "PIX_FMT_YUV444P16BE" | "PIX_FMT_VDPAU_MPEG4" | "PIX_FMT_DXVA2_VLD" | "PIX_FMT_RGB444LE" | "PIX_FMT_RGB444BE" | "PIX_FMT_BGR444LE" | "PIX_FMT_BGR444BE" | "PIX_FMT_GRAY8A" | "PIX_FMT_BGR48BE" | "PIX_FMT_BGR48LE" | "PIX_FMT_YUV420P9BE" | "PIX_FMT_YUV420P9LE" | "PIX_FMT_YUV420P10BE" | "PIX_FMT_YUV420P10LE" | "PIX_FMT_YUV422P10BE" | "PIX_FMT_YUV422P10LE" | "PIX_FMT_YUV444P9BE" | "PIX_FMT_YUV444P9LE" | "PIX_FMT_YUV444P10BE" | "PIX_FMT_YUV444P10LE" | "PIX_FMT_YUV422P9BE" | "PIX_FMT_YUV422P9LE" | "PIX_FMT_VDA_VLD" | "PIX_FMT_RGBA64BE" | "PIX_FMT_RGBA64LE" | "PIX_FMT_BGRA64BE" | "PIX_FMT_BGRA64LE" | "PIX_FMT_GBRP" | "PIX_FMT_GBRP9BE" | "PIX_FMT_GBRP9LE" | "PIX_FMT_GBRP10BE" | "PIX_FMT_GBRP10LE" | "PIX_FMT_GBRP16BE" | "PIX_FMT_GBRP16LE" | "PIX_FMT_0RGB" | "PIX_FMT_RGB0" | "PIX_FMT_0BGR" | "PIX_FMT_BGR0" | "PIX_FMT_YUVA444P" | "PIX_FMT_YUVA422P" | "PIX_FMT_YUV420P12BE" | "PIX_FMT_YUV420P12LE" | "PIX_FMT_YUV420P14BE" | "PIX_FMT_YUV420P14LE" | "PIX_FMT_YUV422P12BE" | "PIX_FMT_YUV422P12LE" | "PIX_FMT_YUV422P14BE" | "PIX_FMT_YUV422P14LE" | "PIX_FMT_YUV444P12BE" | "PIX_FMT_YUV444P12LE" | "PIX_FMT_YUV444P14BE" | "PIX_FMT_YUV444P14LE" | "PIX_FMT_GBRP12BE" | "PIX_FMT_GBRP12LE" | "PIX_FMT_GBRP14BE" | "PIX_FMT_GBRP14LE" | "PIX_FMT_ARGB" | "PIX_FMT_RGBA" | "PIX_FMT_ABGR" | "PIX_FMT_BGRA" | "PIX_FMT_RGB565LE" | "PIX_FMT_RGB555LE" | "PIX_FMT_BGR565LE" | "PIX_FMT_BGR555LE" | "PIX_FMT_VAAPI" | "PIX_FMT_YA8" | "PIX_FMT_Y400A" | "PIX_FMT_YUVA420P9BE" | "PIX_FMT_YUVA420P9LE" | "PIX_FMT_YUVA422P9BE" | "PIX_FMT_YUVA422P9LE" | "PIX_FMT_YUVA444P9BE" | "PIX_FMT_YUVA444P9LE" | "PIX_FMT_YUVA420P10BE" | "PIX_FMT_YUVA420P10LE" | "PIX_FMT_YUVA422P10BE" | "PIX_FMT_YUVA422P10LE" | "PIX_FMT_YUVA444P10BE" | "PIX_FMT_YUVA444P10LE" | "PIX_FMT_YUVA420P16BE" | "PIX_FMT_YUVA420P16LE" | "PIX_FMT_YUVA422P16BE" | "PIX_FMT_YUVA422P16LE" | "PIX_FMT_YUVA444P16BE" | "PIX_FMT_YUVA444P16LE" | "PIX_FMT_VDPAU" | "PIX_FMT_XYZ12LE" | "PIX_FMT_XYZ12BE" | "PIX_FMT_NV16" | "PIX_FMT_NV20LE" | "PIX_FMT_NV20BE" | "PIX_FMT_YVYU422" | "PIX_FMT_VDA" | "PIX_FMT_YA16BE" | "PIX_FMT_YA16LE" | "PIX_FMT_GBRAP" | "PIX_FMT_GBRAP16BE" | "PIX_FMT_GBRAP16LE" | "PIX_FMT_QSV" | "PIX_FMT_MMAL" | "PIX_FMT_D3D11VA_VLD" | "PIX_FMT_CUDA" | "PIX_FMT_YUVJ411P" | "PIX_FMT_BAYER_BGGR8" | "PIX_FMT_BAYER_RGGB8" | "PIX_FMT_BAYER_GBRG8" | "PIX_FMT_BAYER_GRBG8" | "PIX_FMT_BAYER_BGGR16LE" | "PIX_FMT_BAYER_BGGR16BE" | "PIX_FMT_BAYER_RGGB16LE" | "PIX_FMT_BAYER_RGGB16BE" | "PIX_FMT_BAYER_GBRG16LE" | "PIX_FMT_BAYER_GBRG16BE" | "PIX_FMT_BAYER_GRBG16LE" | "PIX_FMT_BAYER_GRBG16BE" | "PIX_FMT_XVMC" | "PIX_FMT_YUV440P10LE" | "PIX_FMT_YUV440P10BE" | "PIX_FMT_YUV440P12LE" | "PIX_FMT_YUV440P12BE" | "PIX_FMT_AYUV64LE" | "PIX_FMT_AYUV64BE" | "PIX_FMT_VIDEOTOOLBOX" | "PIX_FMT_P010LE" | "PIX_FMT_P010BE" | "PIX_FMT_GBRAP12BE" | "PIX_FMT_GBRAP12LE" | "PIX_FMT_GBRAP10BE" | "PIX_FMT_GBRAP10LE" | "PIX_FMT_MEDIACODEC" | "PIX_FMT_GRAY12BE" | "PIX_FMT_GRAY12LE" | "PIX_FMT_GRAY10BE" | "PIX_FMT_GRAY10LE" | "PIX_FMT_P016LE" | "PIX_FMT_P016BE" | "PIX_FMT_D3D11" | "PIX_FMT_GRAY9BE" | "PIX_FMT_GRAY9LE" | "PIX_FMT_GBRPF32BE" | "PIX_FMT_GBRPF32LE" | "PIX_FMT_GBRAPF32BE" | "PIX_FMT_GBRAPF32LE" | "PIX_FMT_DRM_PRIME" | "PIX_FMT_GACCEL" | "PIX_FMT_OPENCL" | "PIX_FMT_GRAY14BE" | "PIX_FMT_GRAY14LE" | "PIX_FMT_GRAYF32BE" | "PIX_FMT_GRAYF32LE" | "PIX_FMT_VULKAN" | "PIX_FMT_ID_FFMPEG_OUT_OF_SYNC";
  /**
   * video profile
   */
  profile?:  | "PROFILE_UNKNOWN" | "PROFILE_AAC_MAIN" | "PROFILE_AAC_LOW" | "PROFILE_AAC_SSR" | "PROFILE_AAC_LTP" | "PROFILE_AAC_HE" | "PROFILE_AAC_HE_V2" | "PROFILE_AAC_LD" | "PROFILE_AAC_ELD" | "PROFILE_AVC_CONSTRAINED" | "PROFILE_AVC_INTRA" | "PROFILE_AVC_BASELINE" | "PROFILE_AVC_CONSTRAINED_BASELINE" | "PROFILE_AVC_MAIN" | "PROFILE_AVC_EXTENDED" | "PROFILE_AVC_HIGH" | "PROFILE_AVC_HIGH10" | "PROFILE_AVC_HIGH10_INTRA" | "PROFILE_AVC_HIGH422" | "PROFILE_AVC_HIGH422_INTRA" | "PROFILE_AVC_HIGH444" | "PROFILE_HIGH444_PREDICTIVE" | "PROFILE_AVC_HIGH444_INTRA" | "PROFILE_AVC_CAVLC444" | "PROFILE_VP9_0" | "PROFILE_VP9_1" | "PROFILE_VP9_2" | "PROFILE_VP9_3" | "PROFILE_HEVC_MAIN" | "PROFILE_HEVC_MAIN_10" | "PROFILE_HEVC_MAIN_STILL_PICTURE" | "PROFILE_HEVC_REXT" | "PROFILE_DOVI_5";
  timedtextStream?: VideoVideoStreamInfoTimedTextStream[];
  /**
   * video bitrate in bits/s
   */
  videoBitrate?: number;
  /**
   * Video clip information, such as copyright, title, and author.
   */
  videoClipInfo?: VideoVideoClipInfo;
  /**
   * Primary video codec information Fields 1-2, 4-10, 28, 37, 44, 49, 51,
   * 54-55, 57-62, 69 will be obsolete soon. Please start using the new repeated
   * video_stream. For now, video_stream(0) will match these fields. Note
   * however that some of the fields in VideoStream are not populated correctly
   * yet in videostreaminfo.cc, but that will be handled gradually.
   */
  videoCodecId?:  | "CODEC_ID_NONE" | "CODEC_ID_MPEG1VIDEO" | "CODEC_ID_MPEG2VIDEO" | "CODEC_ID_MPEG2VIDEO_XVMC" | "CODEC_ID_H261" | "CODEC_ID_H263" | "CODEC_ID_RV10" | "CODEC_ID_RV20" | "CODEC_ID_MJPEG" | "CODEC_ID_MJPEGB" | "CODEC_ID_LJPEG" | "CODEC_ID_SP5X" | "CODEC_ID_JPEGLS" | "CODEC_ID_MPEG4" | "CODEC_ID_RAWVIDEO" | "CODEC_ID_MSMPEG4V1" | "CODEC_ID_MSMPEG4V2" | "CODEC_ID_MSMPEG4V3" | "CODEC_ID_WMV1" | "CODEC_ID_WMV2" | "CODEC_ID_H263P" | "CODEC_ID_H263I" | "CODEC_ID_FLV1" | "CODEC_ID_SVQ1" | "CODEC_ID_SVQ3" | "CODEC_ID_DVVIDEO" | "CODEC_ID_HUFFYUV" | "CODEC_ID_CYUV" | "CODEC_ID_H264" | "CODEC_ID_INDEO3" | "CODEC_ID_VP3" | "CODEC_ID_THEORA" | "CODEC_ID_ASV1" | "CODEC_ID_ASV2" | "CODEC_ID_FFV1" | "CODEC_ID_4XM" | "CODEC_ID_VCR1" | "CODEC_ID_CLJR" | "CODEC_ID_MDEC" | "CODEC_ID_ROQ" | "CODEC_ID_INTERPLAY_VIDEO" | "CODEC_ID_XAN_WC3" | "CODEC_ID_XAN_WC4" | "CODEC_ID_RPZA" | "CODEC_ID_CINEPAK" | "CODEC_ID_WS_VQA" | "CODEC_ID_MSRLE" | "CODEC_ID_MSVIDEO1" | "CODEC_ID_IDCIN" | "CODEC_ID_8BPS" | "CODEC_ID_SMC" | "CODEC_ID_FLIC" | "CODEC_ID_TRUEMOTION1" | "CODEC_ID_VMDVIDEO" | "CODEC_ID_MSZH" | "CODEC_ID_ZLIB" | "CODEC_ID_QTRLE" | "CODEC_ID_SNOW" | "CODEC_ID_TSCC" | "CODEC_ID_ULTI" | "CODEC_ID_QDRAW" | "CODEC_ID_VIXL" | "CODEC_ID_QPEG" | "CODEC_ID_XVID" | "CODEC_ID_PNG" | "CODEC_ID_PPM" | "CODEC_ID_PBM" | "CODEC_ID_PGM" | "CODEC_ID_PGMYUV" | "CODEC_ID_PAM" | "CODEC_ID_FFVHUFF" | "CODEC_ID_RV30" | "CODEC_ID_RV40" | "CODEC_ID_VC1" | "CODEC_ID_WMV3" | "CODEC_ID_LOCO" | "CODEC_ID_WNV1" | "CODEC_ID_AASC" | "CODEC_ID_INDEO2" | "CODEC_ID_FRAPS" | "CODEC_ID_TRUEMOTION2" | "CODEC_ID_BMP" | "CODEC_ID_CSCD" | "CODEC_ID_MMVIDEO" | "CODEC_ID_ZMBV" | "CODEC_ID_AVS" | "CODEC_ID_SMACKVIDEO" | "CODEC_ID_NUV" | "CODEC_ID_KMVC" | "CODEC_ID_FLASHSV" | "CODEC_ID_CAVS" | "CODEC_ID_JPEG2000" | "CODEC_ID_VMNC" | "CODEC_ID_VP5" | "CODEC_ID_VP6" | "CODEC_ID_VP6F" | "CODEC_ID_TARGA" | "CODEC_ID_DSICINVIDEO" | "CODEC_ID_TIERTEXSEQVIDEO" | "CODEC_ID_TIFF" | "CODEC_ID_GIF" | "CODEC_ID_FFH264" | "CODEC_ID_DXA" | "CODEC_ID_DNXHD" | "CODEC_ID_THP" | "CODEC_ID_SGI" | "CODEC_ID_C93" | "CODEC_ID_BETHSOFTVID" | "CODEC_ID_PTX" | "CODEC_ID_TXD" | "CODEC_ID_VP6A" | "CODEC_ID_AMV" | "CODEC_ID_VB" | "CODEC_ID_PCX" | "CODEC_ID_SUNRAST" | "CODEC_ID_INDEO4" | "CODEC_ID_INDEO5" | "CODEC_ID_MIMIC" | "CODEC_ID_RL2" | "CODEC_ID_8SVX_EXP" | "CODEC_ID_8SVX_FIB" | "CODEC_ID_ESCAPE124" | "CODEC_ID_DIRAC" | "CODEC_ID_BFI" | "CODEC_ID_CMV" | "CODEC_ID_MOTIONPIXELS" | "CODEC_ID_TGV" | "CODEC_ID_TGQ" | "CODEC_ID_TQI" | "CODEC_ID_AURA" | "CODEC_ID_AURA2" | "CODEC_ID_V210X" | "CODEC_ID_TMV" | "CODEC_ID_V210" | "CODEC_ID_DPX" | "CODEC_ID_MAD" | "CODEC_ID_FRWU" | "CODEC_ID_VP8" | "CODEC_ID_APPLE_PRORES_NQ" | "CODEC_ID_APPLE_PRORES_HQ" | "CODEC_ID_FLASHSV2" | "CODEC_ID_CDGRAPHICS" | "CODEC_ID_R210" | "CODEC_ID_ANM" | "CODEC_ID_BINKVIDEO" | "CODEC_ID_IFF_ILBM" | "CODEC_ID_IFF_BYTERUN1" | "CODEC_ID_KGV1" | "CODEC_ID_YOP" | "CODEC_ID_PICTOR" | "CODEC_ID_APPLE_PRORES_LT" | "CODEC_ID_APPLE_PRORES_PROXY" | "CODEC_ID_APPLE_PRORES_4444" | "CODEC_ID_APPLE_PIXLET" | "CODEC_ID_G2M" | "CODEC_ID_PRORES" | "CODEC_ID_ANSI" | "CODEC_ID_A64_MULTI" | "CODEC_ID_A64_MULTI5" | "CODEC_ID_R10K" | "CODEC_ID_MXPEG" | "CODEC_ID_LAGARITH" | "CODEC_ID_JV" | "CODEC_ID_DFA" | "CODEC_ID_WMV3IMAGE" | "CODEC_ID_VC1IMAGE" | "CODEC_ID_UTVIDEO" | "CODEC_ID_BMV_VIDEO" | "CODEC_ID_VBLE" | "CODEC_ID_DXTORY" | "CODEC_ID_V410" | "CODEC_ID_XWD" | "CODEC_ID_CDXL" | "CODEC_ID_XBM" | "CODEC_ID_ZEROCODEC" | "CODEC_ID_MSS1" | "CODEC_ID_MSA1" | "CODEC_ID_TSCC2" | "CODEC_ID_MTS2" | "CODEC_ID_CLLC" | "CODEC_ID_MSS2" | "CODEC_ID_Y41P" | "CODEC_ID_ESCAPE130" | "CODEC_ID_EXR" | "CODEC_ID_AVRP" | "CODEC_ID_AVUI" | "CODEC_ID_AYUV" | "CODEC_ID_V308" | "CODEC_ID_V408" | "CODEC_ID_YUV4" | "CODEC_ID_SANM" | "CODEC_ID_PAF_VIDEO" | "CODEC_ID_AVRN" | "CODEC_ID_CPIA" | "CODEC_ID_VP9" | "CODEC_ID_H265" | "CODEC_ID_CFHD" | "CODEC_ID_AV1" | "CODEC_ID_AIC" | "CODEC_ID_ALIAS_PIX" | "CODEC_ID_APNG" | "CODEC_ID_BRENDER_PIX" | "CODEC_ID_CLEARVIDEO" | "CODEC_ID_DDS" | "CODEC_ID_DXV" | "CODEC_ID_FIC" | "CODEC_ID_FITS" | "CODEC_ID_FMVC" | "CODEC_ID_GDV" | "CODEC_ID_HAP" | "CODEC_ID_HNM4_VIDEO" | "CODEC_ID_HQ_HQA" | "CODEC_ID_HQX" | "CODEC_ID_M101" | "CODEC_ID_MAGICYUV" | "CODEC_ID_MSCC" | "CODEC_ID_MVC1" | "CODEC_ID_MVC2" | "CODEC_ID_PIXLET" | "CODEC_ID_PSD" | "CODEC_ID_RSCC" | "CODEC_ID_SCPR" | "CODEC_ID_SCREENPRESSO" | "CODEC_ID_SGIRLE" | "CODEC_ID_SHEERVIDEO" | "CODEC_ID_SMVJPEG" | "CODEC_ID_SPEEDHQ" | "CODEC_ID_SRGC" | "CODEC_ID_TARGA_Y216" | "CODEC_ID_TDSC" | "CODEC_ID_TRUEMOTION2RT" | "CODEC_ID_VP7" | "CODEC_ID_BITPACKED" | "CODEC_ID_WEBP" | "CODEC_ID_XFACE" | "CODEC_ID_XPM" | "CODEC_ID_YLC" | "CODEC_ID_012V" | "CODEC_ID_AVS2" | "CODEC_ID_IMM4" | "CODEC_ID_MWSC" | "CODEC_ID_PROSUMER" | "CODEC_ID_RASC" | "CODEC_ID_WCMV" | "CODEC_ID_UNKNOWN" | "CODEC_ID_PCM_S16LE" | "CODEC_ID_PCM_S16BE" | "CODEC_ID_PCM_U16LE" | "CODEC_ID_PCM_U16BE" | "CODEC_ID_PCM_S8" | "CODEC_ID_PCM_U8" | "CODEC_ID_PCM_MULAW" | "CODEC_ID_PCM_ALAW" | "CODEC_ID_PCM_S32LE" | "CODEC_ID_PCM_S32BE" | "CODEC_ID_PCM_U32LE" | "CODEC_ID_PCM_U32BE" | "CODEC_ID_PCM_S24LE" | "CODEC_ID_PCM_S24BE" | "CODEC_ID_PCM_U24LE" | "CODEC_ID_PCM_U24BE" | "CODEC_ID_PCM_S24DAUD" | "CODEC_ID_PCM_ZORK" | "CODEC_ID_PCM_S16LE_PLANAR" | "CODEC_ID_PCM_DVD" | "CODEC_ID_PCM_F32BE" | "CODEC_ID_PCM_F32LE" | "CODEC_ID_PCM_F64BE" | "CODEC_ID_PCM_F64LE" | "CODEC_ID_PCM_BLURAY" | "CODEC_ID_PCM_LXF" | "CODEC_ID_S302M" | "CODEC_ID_PCM_S8_PLANAR" | "CODEC_ID_PCM_S24LE_PLANAR" | "CODEC_ID_PCM_S32LE_PLANAR" | "CODEC_ID_PCM_S16BE_PLANAR" | "CODEC_ID_PCM_S64LE" | "CODEC_ID_PCM_S64BE" | "CODEC_ID_PCM_F16LE" | "CODEC_ID_PCM_F24LE" | "CODEC_ID_ADPCM_IMA_QT" | "CODEC_ID_ADPCM_IMA_WAV" | "CODEC_ID_ADPCM_IMA_DK3" | "CODEC_ID_ADPCM_IMA_DK4" | "CODEC_ID_ADPCM_IMA_WS" | "CODEC_ID_ADPCM_IMA_SMJPEG" | "CODEC_ID_ADPCM_MS" | "CODEC_ID_ADPCM_4XM" | "CODEC_ID_ADPCM_XA" | "CODEC_ID_ADPCM_ADX" | "CODEC_ID_ADPCM_EA" | "CODEC_ID_ADPCM_G726" | "CODEC_ID_ADPCM_CT" | "CODEC_ID_ADPCM_SWF" | "CODEC_ID_ADPCM_YAMAHA" | "CODEC_ID_ADPCM_SBPRO_4" | "CODEC_ID_ADPCM_SBPRO_3" | "CODEC_ID_ADPCM_SBPRO_2" | "CODEC_ID_ADPCM_THP" | "CODEC_ID_ADPCM_IMA_AMV" | "CODEC_ID_ADPCM_EA_R1" | "CODEC_ID_ADPCM_EA_R3" | "CODEC_ID_ADPCM_EA_R2" | "CODEC_ID_ADPCM_IMA_EA_SEAD" | "CODEC_ID_ADPCM_IMA_EA_EACS" | "CODEC_ID_ADPCM_EA_XAS" | "CODEC_ID_ADPCM_EA_MAXIS_XA" | "CODEC_ID_ADPCM_IMA_ISS" | "CODEC_ID_ADPCM_G722" | "CODEC_ID_ADPCM_IMA_APC" | "CODEC_ID_VIMA" | "CODEC_ID_ADPCM_AFC" | "CODEC_ID_ADPCM_IMA_OKI" | "CODEC_ID_ADPCM_DTK" | "CODEC_ID_ADPCM_IMA_RAD" | "CODEC_ID_ADPCM_G726LE" | "CODEC_ID_ADPCM_THP_LE" | "CODEC_ID_ADPCM_PSX" | "CODEC_ID_ADPCM_AICA" | "CODEC_ID_ADPCM_IMA_DAT4" | "CODEC_ID_ADPCM_MTAF" | "CODEC_ID_ADPCM_VIMA" | "CODEC_ID_AMR_NB" | "CODEC_ID_AMR_WB" | "CODEC_ID_RA_144" | "CODEC_ID_RA_288" | "CODEC_ID_ROQ_DPCM" | "CODEC_ID_INTERPLAY_DPCM" | "CODEC_ID_XAN_DPCM" | "CODEC_ID_SOL_DPCM" | "CODEC_ID_GREMLIN_DPCM" | "CODEC_ID_SDX2_DPCM" | "CODEC_ID_MP2" | "CODEC_ID_MP3" | "CODEC_ID_AAC" | "CODEC_ID_MPEG4AAC_DEPRECATED" | "CODEC_ID_AC3" | "CODEC_ID_DTS" | "CODEC_ID_VORBIS" | "CODEC_ID_DVAUDIO" | "CODEC_ID_WMAV1" | "CODEC_ID_WMAV2" | "CODEC_ID_MACE3" | "CODEC_ID_MACE6" | "CODEC_ID_VMDAUDIO" | "CODEC_ID_SONIC" | "CODEC_ID_SONIC_LS" | "CODEC_ID_FLAC" | "CODEC_ID_MP3ADU" | "CODEC_ID_MP3ON4" | "CODEC_ID_SHORTEN" | "CODEC_ID_ALAC" | "CODEC_ID_WESTWOOD_SND1" | "CODEC_ID_GSM" | "CODEC_ID_QDM2" | "CODEC_ID_COOK" | "CODEC_ID_TRUESPEECH" | "CODEC_ID_TTA" | "CODEC_ID_SMACKAUDIO" | "CODEC_ID_QCELP" | "CODEC_ID_WAVPACK" | "CODEC_ID_DSICINAUDIO" | "CODEC_ID_ASAO" | "CODEC_ID_NELLYMOSER" | "CODEC_ID_WMAVOICE" | "CODEC_ID_WMAPRO" | "CODEC_ID_WMALOSSLESS" | "CODEC_ID_IMC" | "CODEC_ID_MUSEPACK7" | "CODEC_ID_MLP" | "CODEC_ID_GSM_MS" | "CODEC_ID_ATRAC3" | "CODEC_ID_VOXWARE" | "CODEC_ID_APE" | "CODEC_ID_MUSEPACK8" | "CODEC_ID_SPEEX" | "CODEC_ID_ATRAC3P" | "CODEC_ID_EAC3" | "CODEC_ID_SIPR" | "CODEC_ID_MP1" | "CODEC_ID_TWINVQ" | "CODEC_ID_TRUEHD" | "CODEC_ID_MP4ALS" | "CODEC_ID_ATRAC1" | "CODEC_ID_BINKAUDIO_RDFT" | "CODEC_ID_BINKAUDIO_DCT" | "CODEC_ID_AAC_LATM" | "CODEC_ID_QDMC" | "CODEC_ID_CELT" | "CODEC_ID_G723_1" | "CODEC_ID_G729" | "CODEC_ID_BMV_AUDIO" | "CODEC_ID_RALF" | "CODEC_ID_IAC" | "CODEC_ID_ILBC" | "CODEC_ID_FFWAVESYNTH" | "CODEC_ID_8SVX_RAW" | "CODEC_ID_PAF_AUDIO" | "CODEC_ID_OPUS" | "CODEC_ID_ATRAC3AL" | "CODEC_ID_ATRAC3PAL" | "CODEC_ID_DOLBY_E" | "CODEC_ID_DSD_LSBF" | "CODEC_ID_DSD_MSBF" | "CODEC_ID_DSD_LSBF_PLANAR" | "CODEC_ID_DSD_MSBF_PLANAR" | "CODEC_ID_DSS_SP" | "CODEC_ID_DST" | "CODEC_ID_EVRC" | "CODEC_ID_INTERPLAY_ACM" | "CODEC_ID_METASOUND" | "CODEC_ID_ON2AVC" | "CODEC_ID_TAK" | "CODEC_ID_XMA1" | "CODEC_ID_XMA2" | "CODEC_ID_COMFORT_NOISE" | "CODEC_ID_APTX" | "CODEC_ID_APTX_HD" | "CODEC_ID_SBC" | "CODEC_ID_ATRAC9" | "CODEC_ID_CODEC2" | "CODEC_ID_OGGTHEORA_DEPRECATED" | "CODEC_ID_DVD_SUBTITLE" | "CODEC_ID_DVB_SUBTITLE" | "CODEC_ID_TEXT" | "CODEC_ID_XSUB" | "CODEC_ID_SSA" | "CODEC_ID_MOV_TEXT" | "CODEC_ID_HDMV_PGS_SUBTITLE" | "CODEC_ID_DVB_TELETEXT" | "CODEC_ID_SRT" | "CODEC_ID_MICRODVD" | "CODEC_ID_EIA_608" | "CODEC_ID_JACOSUB" | "CODEC_ID_SAMI" | "CODEC_ID_REALTEXT" | "CODEC_ID_SUBVIEWER" | "CODEC_ID_SUBRIP" | "CODEC_ID_WEBVTT" | "CODEC_ID_ASS" | "CODEC_ID_MPL2" | "CODEC_ID_PJS" | "CODEC_ID_STL" | "CODEC_ID_SUBVIEWER1" | "CODEC_ID_VPLAYER" | "CODEC_ID_TTML" | "CODEC_ID_TTF" | "CODEC_ID_BINTEXT" | "CODEC_ID_XBIN" | "CODEC_ID_IDF" | "CODEC_ID_OTF" | "CODEC_ID_PROBE" | "CODEC_ID_MPEG2TS" | "CODEC_ID_MPEG4SYSTEMS" | "CODEC_ID_FFMETADATA" | "CODEC_ID_FFMPEG_OUT_OF_SYNC" | "CODEC_ID_WRAPPED_AVFRAME" | "CODEC_ID_CAMM";
  videoEndTimestamp?: bigint;
  /**
   * video frame per second, obtained by parsing video header information. It
   * could be inaccurate for some types of codecs, notably, WMV, ASF, and FLV.
   * It will be inaccurate for videos that does not have constant frame rate
   * since it is the smallest framerate that can accurately represent all
   * timestamps (see ffmpeg doc for AVStream.r_frame_rate). Also frame rate can
   * be parsed from headers and can be wrong if it is not available there since
   * ffmpeg uses a heuristic for determining it.
   */
  videoFps?: number;
  /**
   * video frame size
   */
  videoFrameSize?: bigint;
  /**
   * video has b frames
   */
  videoHasBFrames?: boolean;
  /**
   * video (MOV) has fragments
   */
  videoHasFragments?: boolean;
  /**
   * video (MOV) has moov atom before mdat atom allowing streaming transcoding
   */
  videoHasLeadingMoovAtom?: boolean;
  /**
   * video has non-monotonic DTS (potential problem)
   */
  videoHasNonMonotonicDts?: boolean;
  /**
   * video has non-monotonic PTS.
   */
  videoHasNonMonotonicPts?: boolean;
  /**
   * video (MOV) has a possibly av desync issue due to edit lists not starting
   * at 0
   */
  videoHasNonZeroStartEditList?: boolean;
  /**
   * video has possible open GOP
   */
  videoHasPossibleOpenGop?: boolean;
  /**
   * video has frames with different aspect ratios.
   */
  videoHasVariableAspectRatio?: boolean;
  videoHeight?: number;
  /**
   * Information on interlaced video.
   */
  videoInterlace?:  | "INTERLACE_NONE" | "INTERLACE_PIC_AFF" | "INTERLACE_MB_AFF";
  /**
   * video length in seconds Note that when the VSI is from users videos, it is
   * not guaranteed to be the same as transcode lengths and it could be 0 when
   * the full VSI cannot compute the length from the source header and
   * timestamps (for example when header and timestamps are too broken).
   */
  videoLength?: number;
  /**
   * Number of Video frames Warning: running
   * video::FfmpegVideoFileInformation() won't set this info Ffmpeg tool does
   * not report the number of frames accurately. We can't rely on fps and video
   * length. So we will set this after we processed every frame using the filter
   * framework
   */
  videoNumberOfFrames?: bigint;
  /**
   * Invisible frame count Keep a count of frames that are not displayed should
   * the full frame count be needed for the video stream. The only codec
   * currently reporting this value is VP8 with alternate reference frames
   * enabled
   */
  videoNumberOfInvisibleFrames?: number;
  /**
   * video pixel aspect ratio
   */
  videoPixelAspectRatio?: number;
  /**
   * Is the video rotated ?
   */
  videoRotation?:  | "ROTATION_NONE" | "ROTATION_OTHER" | "ROTATION_CW_90" | "ROTATION_CCW_90" | "ROTATION_180";
  /**
   * Start/end timestamps of audio/video in ms.
   */
  videoStartTimestamp?: bigint;
  videoStream?: VideoVideoStreamInfoVideoStream[];
  videoStreamCodecTag?: number;
  /**
   * Version number of the videostreaminfo application that generated this
   * protobuf.
   */
  videostreaminfoVersion?: number;
  /**
   * source video width and height
   */
  videoWidth?: number;
  /**
   * Luma PSNR of the transcoded file.
   */
  yPsnr?: number;
}

function serializeVideoVideoStreamInfo(data: any): VideoVideoStreamInfo {
  return {
    ...data,
    audioEndTimestamp: data["audioEndTimestamp"] !== undefined ? String(data["audioEndTimestamp"]) : undefined,
    audioFrameSize: data["audioFrameSize"] !== undefined ? String(data["audioFrameSize"]) : undefined,
    audioNumberOfFrames: data["audioNumberOfFrames"] !== undefined ? String(data["audioNumberOfFrames"]) : undefined,
    audioSampleRate: data["audioSampleRate"] !== undefined ? String(data["audioSampleRate"]) : undefined,
    audioStartTimestamp: data["audioStartTimestamp"] !== undefined ? String(data["audioStartTimestamp"]) : undefined,
    audioStream: data["audioStream"] !== undefined ? data["audioStream"].map((item: any) => (serializeVideoVideoStreamInfoAudioStream(item))) : undefined,
    audioStreamCodecTag: data["audioStreamCodecTag"] !== undefined ? String(data["audioStreamCodecTag"]) : undefined,
    dataStream: data["dataStream"] !== undefined ? data["dataStream"].map((item: any) => (serializeVideoVideoStreamInfoDataStream(item))) : undefined,
    fileHeaderFingerprint: data["fileHeaderFingerprint"] !== undefined ? String(data["fileHeaderFingerprint"]) : undefined,
    fileModifiedTime: data["fileModifiedTime"] !== undefined ? String(data["fileModifiedTime"]) : undefined,
    fileSize: data["fileSize"] !== undefined ? String(data["fileSize"]) : undefined,
    imageStream: data["imageStream"] !== undefined ? data["imageStream"].map((item: any) => (serializeVideoVideoStreamInfoVideoStream(item))) : undefined,
    metadata: data["metadata"] !== undefined ? serializeVideoVideoStreamInfoMetadata(data["metadata"]) : undefined,
    timedtextStream: data["timedtextStream"] !== undefined ? data["timedtextStream"].map((item: any) => (serializeVideoVideoStreamInfoTimedTextStream(item))) : undefined,
    videoClipInfo: data["videoClipInfo"] !== undefined ? serializeVideoVideoClipInfo(data["videoClipInfo"]) : undefined,
    videoEndTimestamp: data["videoEndTimestamp"] !== undefined ? String(data["videoEndTimestamp"]) : undefined,
    videoFrameSize: data["videoFrameSize"] !== undefined ? String(data["videoFrameSize"]) : undefined,
    videoNumberOfFrames: data["videoNumberOfFrames"] !== undefined ? String(data["videoNumberOfFrames"]) : undefined,
    videoStartTimestamp: data["videoStartTimestamp"] !== undefined ? String(data["videoStartTimestamp"]) : undefined,
    videoStream: data["videoStream"] !== undefined ? data["videoStream"].map((item: any) => (serializeVideoVideoStreamInfoVideoStream(item))) : undefined,
  };
}

function deserializeVideoVideoStreamInfo(data: any): VideoVideoStreamInfo {
  return {
    ...data,
    audioEndTimestamp: data["audioEndTimestamp"] !== undefined ? BigInt(data["audioEndTimestamp"]) : undefined,
    audioFrameSize: data["audioFrameSize"] !== undefined ? BigInt(data["audioFrameSize"]) : undefined,
    audioNumberOfFrames: data["audioNumberOfFrames"] !== undefined ? BigInt(data["audioNumberOfFrames"]) : undefined,
    audioSampleRate: data["audioSampleRate"] !== undefined ? BigInt(data["audioSampleRate"]) : undefined,
    audioStartTimestamp: data["audioStartTimestamp"] !== undefined ? BigInt(data["audioStartTimestamp"]) : undefined,
    audioStream: data["audioStream"] !== undefined ? data["audioStream"].map((item: any) => (deserializeVideoVideoStreamInfoAudioStream(item))) : undefined,
    audioStreamCodecTag: data["audioStreamCodecTag"] !== undefined ? BigInt(data["audioStreamCodecTag"]) : undefined,
    dataStream: data["dataStream"] !== undefined ? data["dataStream"].map((item: any) => (deserializeVideoVideoStreamInfoDataStream(item))) : undefined,
    fileHeaderFingerprint: data["fileHeaderFingerprint"] !== undefined ? BigInt(data["fileHeaderFingerprint"]) : undefined,
    fileModifiedTime: data["fileModifiedTime"] !== undefined ? BigInt(data["fileModifiedTime"]) : undefined,
    fileSize: data["fileSize"] !== undefined ? BigInt(data["fileSize"]) : undefined,
    imageStream: data["imageStream"] !== undefined ? data["imageStream"].map((item: any) => (deserializeVideoVideoStreamInfoVideoStream(item))) : undefined,
    metadata: data["metadata"] !== undefined ? deserializeVideoVideoStreamInfoMetadata(data["metadata"]) : undefined,
    timedtextStream: data["timedtextStream"] !== undefined ? data["timedtextStream"].map((item: any) => (deserializeVideoVideoStreamInfoTimedTextStream(item))) : undefined,
    videoClipInfo: data["videoClipInfo"] !== undefined ? deserializeVideoVideoClipInfo(data["videoClipInfo"]) : undefined,
    videoEndTimestamp: data["videoEndTimestamp"] !== undefined ? BigInt(data["videoEndTimestamp"]) : undefined,
    videoFrameSize: data["videoFrameSize"] !== undefined ? BigInt(data["videoFrameSize"]) : undefined,
    videoNumberOfFrames: data["videoNumberOfFrames"] !== undefined ? BigInt(data["videoNumberOfFrames"]) : undefined,
    videoStartTimestamp: data["videoStartTimestamp"] !== undefined ? BigInt(data["videoStartTimestamp"]) : undefined,
    videoStream: data["videoStream"] !== undefined ? data["videoStream"].map((item: any) => (deserializeVideoVideoStreamInfoVideoStream(item))) : undefined,
  };
}

/**
 * Next id: 25
 */
export interface VideoVideoStreamInfoAudioStream {
  /**
   * Optional ambisonics metadata.
   */
  ambisonics?: VideoAmbisonicsAmbisonicsMetadata;
  /**
   * audio bitrate in bits/s
   */
  bitrate?: bigint;
  channelPosition?:  | "CHANNEL_UNKNOWN" | "CHANNEL_FRONT_LEFT" | "CHANNEL_FRONT_RIGHT" | "CHANNEL_FRONT_CENTER" | "CHANNEL_LOW_FREQUENCY" | "CHANNEL_BACK_LEFT" | "CHANNEL_BACK_RIGHT" | "CHANNEL_FRONT_LEFT_OF_CENTER" | "CHANNEL_FRONT_RIGHT_OF_CENTER" | "CHANNEL_BACK_CENTER" | "CHANNEL_SIDE_LEFT" | "CHANNEL_SIDE_RIGHT" | "CHANNEL_TOP_CENTER" | "CHANNEL_TOP_FRONT_LEFT" | "CHANNEL_TOP_FRONT_CENTER" | "CHANNEL_TOP_FRONT_RIGHT" | "CHANNEL_TOP_BACK_LEFT" | "CHANNEL_TOP_BACK_CENTER" | "CHANNEL_TOP_BACK_RIGHT" | "CHANNEL_STEREO_LEFT" | "CHANNEL_STEREO_RIGHT" | "CHANNEL_WIDE_LEFT" | "CHANNEL_WIDE_RIGHT" | "CHANNEL_SURROUND_DIRECT_LEFT" | "CHANNEL_SURROUND_DIRECT_RIGHT" | "CHANNEL_LOW_FREQUENCY_2"[];
  /**
   * number of audio channels
   */
  channels?: number;
  /**
   * some container allows for a clock discontinuity. In this case, the
   * end_timestamp may not be the correct DTS of the stream.
   */
  clockDiscontinuityUs?: bigint;
  codecFourcc?: string;
  /**
   * Primary audio codec information
   */
  codecId?:  | "CODEC_ID_NONE" | "CODEC_ID_MPEG1VIDEO" | "CODEC_ID_MPEG2VIDEO" | "CODEC_ID_MPEG2VIDEO_XVMC" | "CODEC_ID_H261" | "CODEC_ID_H263" | "CODEC_ID_RV10" | "CODEC_ID_RV20" | "CODEC_ID_MJPEG" | "CODEC_ID_MJPEGB" | "CODEC_ID_LJPEG" | "CODEC_ID_SP5X" | "CODEC_ID_JPEGLS" | "CODEC_ID_MPEG4" | "CODEC_ID_RAWVIDEO" | "CODEC_ID_MSMPEG4V1" | "CODEC_ID_MSMPEG4V2" | "CODEC_ID_MSMPEG4V3" | "CODEC_ID_WMV1" | "CODEC_ID_WMV2" | "CODEC_ID_H263P" | "CODEC_ID_H263I" | "CODEC_ID_FLV1" | "CODEC_ID_SVQ1" | "CODEC_ID_SVQ3" | "CODEC_ID_DVVIDEO" | "CODEC_ID_HUFFYUV" | "CODEC_ID_CYUV" | "CODEC_ID_H264" | "CODEC_ID_INDEO3" | "CODEC_ID_VP3" | "CODEC_ID_THEORA" | "CODEC_ID_ASV1" | "CODEC_ID_ASV2" | "CODEC_ID_FFV1" | "CODEC_ID_4XM" | "CODEC_ID_VCR1" | "CODEC_ID_CLJR" | "CODEC_ID_MDEC" | "CODEC_ID_ROQ" | "CODEC_ID_INTERPLAY_VIDEO" | "CODEC_ID_XAN_WC3" | "CODEC_ID_XAN_WC4" | "CODEC_ID_RPZA" | "CODEC_ID_CINEPAK" | "CODEC_ID_WS_VQA" | "CODEC_ID_MSRLE" | "CODEC_ID_MSVIDEO1" | "CODEC_ID_IDCIN" | "CODEC_ID_8BPS" | "CODEC_ID_SMC" | "CODEC_ID_FLIC" | "CODEC_ID_TRUEMOTION1" | "CODEC_ID_VMDVIDEO" | "CODEC_ID_MSZH" | "CODEC_ID_ZLIB" | "CODEC_ID_QTRLE" | "CODEC_ID_SNOW" | "CODEC_ID_TSCC" | "CODEC_ID_ULTI" | "CODEC_ID_QDRAW" | "CODEC_ID_VIXL" | "CODEC_ID_QPEG" | "CODEC_ID_XVID" | "CODEC_ID_PNG" | "CODEC_ID_PPM" | "CODEC_ID_PBM" | "CODEC_ID_PGM" | "CODEC_ID_PGMYUV" | "CODEC_ID_PAM" | "CODEC_ID_FFVHUFF" | "CODEC_ID_RV30" | "CODEC_ID_RV40" | "CODEC_ID_VC1" | "CODEC_ID_WMV3" | "CODEC_ID_LOCO" | "CODEC_ID_WNV1" | "CODEC_ID_AASC" | "CODEC_ID_INDEO2" | "CODEC_ID_FRAPS" | "CODEC_ID_TRUEMOTION2" | "CODEC_ID_BMP" | "CODEC_ID_CSCD" | "CODEC_ID_MMVIDEO" | "CODEC_ID_ZMBV" | "CODEC_ID_AVS" | "CODEC_ID_SMACKVIDEO" | "CODEC_ID_NUV" | "CODEC_ID_KMVC" | "CODEC_ID_FLASHSV" | "CODEC_ID_CAVS" | "CODEC_ID_JPEG2000" | "CODEC_ID_VMNC" | "CODEC_ID_VP5" | "CODEC_ID_VP6" | "CODEC_ID_VP6F" | "CODEC_ID_TARGA" | "CODEC_ID_DSICINVIDEO" | "CODEC_ID_TIERTEXSEQVIDEO" | "CODEC_ID_TIFF" | "CODEC_ID_GIF" | "CODEC_ID_FFH264" | "CODEC_ID_DXA" | "CODEC_ID_DNXHD" | "CODEC_ID_THP" | "CODEC_ID_SGI" | "CODEC_ID_C93" | "CODEC_ID_BETHSOFTVID" | "CODEC_ID_PTX" | "CODEC_ID_TXD" | "CODEC_ID_VP6A" | "CODEC_ID_AMV" | "CODEC_ID_VB" | "CODEC_ID_PCX" | "CODEC_ID_SUNRAST" | "CODEC_ID_INDEO4" | "CODEC_ID_INDEO5" | "CODEC_ID_MIMIC" | "CODEC_ID_RL2" | "CODEC_ID_8SVX_EXP" | "CODEC_ID_8SVX_FIB" | "CODEC_ID_ESCAPE124" | "CODEC_ID_DIRAC" | "CODEC_ID_BFI" | "CODEC_ID_CMV" | "CODEC_ID_MOTIONPIXELS" | "CODEC_ID_TGV" | "CODEC_ID_TGQ" | "CODEC_ID_TQI" | "CODEC_ID_AURA" | "CODEC_ID_AURA2" | "CODEC_ID_V210X" | "CODEC_ID_TMV" | "CODEC_ID_V210" | "CODEC_ID_DPX" | "CODEC_ID_MAD" | "CODEC_ID_FRWU" | "CODEC_ID_VP8" | "CODEC_ID_APPLE_PRORES_NQ" | "CODEC_ID_APPLE_PRORES_HQ" | "CODEC_ID_FLASHSV2" | "CODEC_ID_CDGRAPHICS" | "CODEC_ID_R210" | "CODEC_ID_ANM" | "CODEC_ID_BINKVIDEO" | "CODEC_ID_IFF_ILBM" | "CODEC_ID_IFF_BYTERUN1" | "CODEC_ID_KGV1" | "CODEC_ID_YOP" | "CODEC_ID_PICTOR" | "CODEC_ID_APPLE_PRORES_LT" | "CODEC_ID_APPLE_PRORES_PROXY" | "CODEC_ID_APPLE_PRORES_4444" | "CODEC_ID_APPLE_PIXLET" | "CODEC_ID_G2M" | "CODEC_ID_PRORES" | "CODEC_ID_ANSI" | "CODEC_ID_A64_MULTI" | "CODEC_ID_A64_MULTI5" | "CODEC_ID_R10K" | "CODEC_ID_MXPEG" | "CODEC_ID_LAGARITH" | "CODEC_ID_JV" | "CODEC_ID_DFA" | "CODEC_ID_WMV3IMAGE" | "CODEC_ID_VC1IMAGE" | "CODEC_ID_UTVIDEO" | "CODEC_ID_BMV_VIDEO" | "CODEC_ID_VBLE" | "CODEC_ID_DXTORY" | "CODEC_ID_V410" | "CODEC_ID_XWD" | "CODEC_ID_CDXL" | "CODEC_ID_XBM" | "CODEC_ID_ZEROCODEC" | "CODEC_ID_MSS1" | "CODEC_ID_MSA1" | "CODEC_ID_TSCC2" | "CODEC_ID_MTS2" | "CODEC_ID_CLLC" | "CODEC_ID_MSS2" | "CODEC_ID_Y41P" | "CODEC_ID_ESCAPE130" | "CODEC_ID_EXR" | "CODEC_ID_AVRP" | "CODEC_ID_AVUI" | "CODEC_ID_AYUV" | "CODEC_ID_V308" | "CODEC_ID_V408" | "CODEC_ID_YUV4" | "CODEC_ID_SANM" | "CODEC_ID_PAF_VIDEO" | "CODEC_ID_AVRN" | "CODEC_ID_CPIA" | "CODEC_ID_VP9" | "CODEC_ID_H265" | "CODEC_ID_CFHD" | "CODEC_ID_AV1" | "CODEC_ID_AIC" | "CODEC_ID_ALIAS_PIX" | "CODEC_ID_APNG" | "CODEC_ID_BRENDER_PIX" | "CODEC_ID_CLEARVIDEO" | "CODEC_ID_DDS" | "CODEC_ID_DXV" | "CODEC_ID_FIC" | "CODEC_ID_FITS" | "CODEC_ID_FMVC" | "CODEC_ID_GDV" | "CODEC_ID_HAP" | "CODEC_ID_HNM4_VIDEO" | "CODEC_ID_HQ_HQA" | "CODEC_ID_HQX" | "CODEC_ID_M101" | "CODEC_ID_MAGICYUV" | "CODEC_ID_MSCC" | "CODEC_ID_MVC1" | "CODEC_ID_MVC2" | "CODEC_ID_PIXLET" | "CODEC_ID_PSD" | "CODEC_ID_RSCC" | "CODEC_ID_SCPR" | "CODEC_ID_SCREENPRESSO" | "CODEC_ID_SGIRLE" | "CODEC_ID_SHEERVIDEO" | "CODEC_ID_SMVJPEG" | "CODEC_ID_SPEEDHQ" | "CODEC_ID_SRGC" | "CODEC_ID_TARGA_Y216" | "CODEC_ID_TDSC" | "CODEC_ID_TRUEMOTION2RT" | "CODEC_ID_VP7" | "CODEC_ID_BITPACKED" | "CODEC_ID_WEBP" | "CODEC_ID_XFACE" | "CODEC_ID_XPM" | "CODEC_ID_YLC" | "CODEC_ID_012V" | "CODEC_ID_AVS2" | "CODEC_ID_IMM4" | "CODEC_ID_MWSC" | "CODEC_ID_PROSUMER" | "CODEC_ID_RASC" | "CODEC_ID_WCMV" | "CODEC_ID_UNKNOWN" | "CODEC_ID_PCM_S16LE" | "CODEC_ID_PCM_S16BE" | "CODEC_ID_PCM_U16LE" | "CODEC_ID_PCM_U16BE" | "CODEC_ID_PCM_S8" | "CODEC_ID_PCM_U8" | "CODEC_ID_PCM_MULAW" | "CODEC_ID_PCM_ALAW" | "CODEC_ID_PCM_S32LE" | "CODEC_ID_PCM_S32BE" | "CODEC_ID_PCM_U32LE" | "CODEC_ID_PCM_U32BE" | "CODEC_ID_PCM_S24LE" | "CODEC_ID_PCM_S24BE" | "CODEC_ID_PCM_U24LE" | "CODEC_ID_PCM_U24BE" | "CODEC_ID_PCM_S24DAUD" | "CODEC_ID_PCM_ZORK" | "CODEC_ID_PCM_S16LE_PLANAR" | "CODEC_ID_PCM_DVD" | "CODEC_ID_PCM_F32BE" | "CODEC_ID_PCM_F32LE" | "CODEC_ID_PCM_F64BE" | "CODEC_ID_PCM_F64LE" | "CODEC_ID_PCM_BLURAY" | "CODEC_ID_PCM_LXF" | "CODEC_ID_S302M" | "CODEC_ID_PCM_S8_PLANAR" | "CODEC_ID_PCM_S24LE_PLANAR" | "CODEC_ID_PCM_S32LE_PLANAR" | "CODEC_ID_PCM_S16BE_PLANAR" | "CODEC_ID_PCM_S64LE" | "CODEC_ID_PCM_S64BE" | "CODEC_ID_PCM_F16LE" | "CODEC_ID_PCM_F24LE" | "CODEC_ID_ADPCM_IMA_QT" | "CODEC_ID_ADPCM_IMA_WAV" | "CODEC_ID_ADPCM_IMA_DK3" | "CODEC_ID_ADPCM_IMA_DK4" | "CODEC_ID_ADPCM_IMA_WS" | "CODEC_ID_ADPCM_IMA_SMJPEG" | "CODEC_ID_ADPCM_MS" | "CODEC_ID_ADPCM_4XM" | "CODEC_ID_ADPCM_XA" | "CODEC_ID_ADPCM_ADX" | "CODEC_ID_ADPCM_EA" | "CODEC_ID_ADPCM_G726" | "CODEC_ID_ADPCM_CT" | "CODEC_ID_ADPCM_SWF" | "CODEC_ID_ADPCM_YAMAHA" | "CODEC_ID_ADPCM_SBPRO_4" | "CODEC_ID_ADPCM_SBPRO_3" | "CODEC_ID_ADPCM_SBPRO_2" | "CODEC_ID_ADPCM_THP" | "CODEC_ID_ADPCM_IMA_AMV" | "CODEC_ID_ADPCM_EA_R1" | "CODEC_ID_ADPCM_EA_R3" | "CODEC_ID_ADPCM_EA_R2" | "CODEC_ID_ADPCM_IMA_EA_SEAD" | "CODEC_ID_ADPCM_IMA_EA_EACS" | "CODEC_ID_ADPCM_EA_XAS" | "CODEC_ID_ADPCM_EA_MAXIS_XA" | "CODEC_ID_ADPCM_IMA_ISS" | "CODEC_ID_ADPCM_G722" | "CODEC_ID_ADPCM_IMA_APC" | "CODEC_ID_VIMA" | "CODEC_ID_ADPCM_AFC" | "CODEC_ID_ADPCM_IMA_OKI" | "CODEC_ID_ADPCM_DTK" | "CODEC_ID_ADPCM_IMA_RAD" | "CODEC_ID_ADPCM_G726LE" | "CODEC_ID_ADPCM_THP_LE" | "CODEC_ID_ADPCM_PSX" | "CODEC_ID_ADPCM_AICA" | "CODEC_ID_ADPCM_IMA_DAT4" | "CODEC_ID_ADPCM_MTAF" | "CODEC_ID_ADPCM_VIMA" | "CODEC_ID_AMR_NB" | "CODEC_ID_AMR_WB" | "CODEC_ID_RA_144" | "CODEC_ID_RA_288" | "CODEC_ID_ROQ_DPCM" | "CODEC_ID_INTERPLAY_DPCM" | "CODEC_ID_XAN_DPCM" | "CODEC_ID_SOL_DPCM" | "CODEC_ID_GREMLIN_DPCM" | "CODEC_ID_SDX2_DPCM" | "CODEC_ID_MP2" | "CODEC_ID_MP3" | "CODEC_ID_AAC" | "CODEC_ID_MPEG4AAC_DEPRECATED" | "CODEC_ID_AC3" | "CODEC_ID_DTS" | "CODEC_ID_VORBIS" | "CODEC_ID_DVAUDIO" | "CODEC_ID_WMAV1" | "CODEC_ID_WMAV2" | "CODEC_ID_MACE3" | "CODEC_ID_MACE6" | "CODEC_ID_VMDAUDIO" | "CODEC_ID_SONIC" | "CODEC_ID_SONIC_LS" | "CODEC_ID_FLAC" | "CODEC_ID_MP3ADU" | "CODEC_ID_MP3ON4" | "CODEC_ID_SHORTEN" | "CODEC_ID_ALAC" | "CODEC_ID_WESTWOOD_SND1" | "CODEC_ID_GSM" | "CODEC_ID_QDM2" | "CODEC_ID_COOK" | "CODEC_ID_TRUESPEECH" | "CODEC_ID_TTA" | "CODEC_ID_SMACKAUDIO" | "CODEC_ID_QCELP" | "CODEC_ID_WAVPACK" | "CODEC_ID_DSICINAUDIO" | "CODEC_ID_ASAO" | "CODEC_ID_NELLYMOSER" | "CODEC_ID_WMAVOICE" | "CODEC_ID_WMAPRO" | "CODEC_ID_WMALOSSLESS" | "CODEC_ID_IMC" | "CODEC_ID_MUSEPACK7" | "CODEC_ID_MLP" | "CODEC_ID_GSM_MS" | "CODEC_ID_ATRAC3" | "CODEC_ID_VOXWARE" | "CODEC_ID_APE" | "CODEC_ID_MUSEPACK8" | "CODEC_ID_SPEEX" | "CODEC_ID_ATRAC3P" | "CODEC_ID_EAC3" | "CODEC_ID_SIPR" | "CODEC_ID_MP1" | "CODEC_ID_TWINVQ" | "CODEC_ID_TRUEHD" | "CODEC_ID_MP4ALS" | "CODEC_ID_ATRAC1" | "CODEC_ID_BINKAUDIO_RDFT" | "CODEC_ID_BINKAUDIO_DCT" | "CODEC_ID_AAC_LATM" | "CODEC_ID_QDMC" | "CODEC_ID_CELT" | "CODEC_ID_G723_1" | "CODEC_ID_G729" | "CODEC_ID_BMV_AUDIO" | "CODEC_ID_RALF" | "CODEC_ID_IAC" | "CODEC_ID_ILBC" | "CODEC_ID_FFWAVESYNTH" | "CODEC_ID_8SVX_RAW" | "CODEC_ID_PAF_AUDIO" | "CODEC_ID_OPUS" | "CODEC_ID_ATRAC3AL" | "CODEC_ID_ATRAC3PAL" | "CODEC_ID_DOLBY_E" | "CODEC_ID_DSD_LSBF" | "CODEC_ID_DSD_MSBF" | "CODEC_ID_DSD_LSBF_PLANAR" | "CODEC_ID_DSD_MSBF_PLANAR" | "CODEC_ID_DSS_SP" | "CODEC_ID_DST" | "CODEC_ID_EVRC" | "CODEC_ID_INTERPLAY_ACM" | "CODEC_ID_METASOUND" | "CODEC_ID_ON2AVC" | "CODEC_ID_TAK" | "CODEC_ID_XMA1" | "CODEC_ID_XMA2" | "CODEC_ID_COMFORT_NOISE" | "CODEC_ID_APTX" | "CODEC_ID_APTX_HD" | "CODEC_ID_SBC" | "CODEC_ID_ATRAC9" | "CODEC_ID_CODEC2" | "CODEC_ID_OGGTHEORA_DEPRECATED" | "CODEC_ID_DVD_SUBTITLE" | "CODEC_ID_DVB_SUBTITLE" | "CODEC_ID_TEXT" | "CODEC_ID_XSUB" | "CODEC_ID_SSA" | "CODEC_ID_MOV_TEXT" | "CODEC_ID_HDMV_PGS_SUBTITLE" | "CODEC_ID_DVB_TELETEXT" | "CODEC_ID_SRT" | "CODEC_ID_MICRODVD" | "CODEC_ID_EIA_608" | "CODEC_ID_JACOSUB" | "CODEC_ID_SAMI" | "CODEC_ID_REALTEXT" | "CODEC_ID_SUBVIEWER" | "CODEC_ID_SUBRIP" | "CODEC_ID_WEBVTT" | "CODEC_ID_ASS" | "CODEC_ID_MPL2" | "CODEC_ID_PJS" | "CODEC_ID_STL" | "CODEC_ID_SUBVIEWER1" | "CODEC_ID_VPLAYER" | "CODEC_ID_TTML" | "CODEC_ID_TTF" | "CODEC_ID_BINTEXT" | "CODEC_ID_XBIN" | "CODEC_ID_IDF" | "CODEC_ID_OTF" | "CODEC_ID_PROBE" | "CODEC_ID_MPEG2TS" | "CODEC_ID_MPEG4SYSTEMS" | "CODEC_ID_FFMETADATA" | "CODEC_ID_FFMPEG_OUT_OF_SYNC" | "CODEC_ID_WRAPPED_AVFRAME" | "CODEC_ID_CAMM";
  /**
   * RFC6381 Codec string.
   */
  codecString?: string;
  /**
   * Specifies the content_type of the audio stream as given in the metadata.
   */
  contentType?: string;
  /**
   * The bytes offset of the end of the first decodable packet.
   */
  decodeOffset?: bigint;
  endTimestamp?: bigint;
  /**
   * audio frame size
   */
  frameSize?: bigint;
  /**
   * Specifies the language of the audio stream as given in the metadata.
   */
  language?: string;
  /**
   * audio length in seconds Note that when the VSI is from users videos, it is
   * not guaranteed to be the same as transcode lengths and it could be 0 when
   * the full VSI cannot compute the length from the source header and
   * timestamps (for example when header and timestamps are too broken).
   */
  length?: number;
  /**
   * Metadata for audio elementary stream;
   */
  metadata?: VideoClipInfo[];
  /**
   * Number of audio frames.
   */
  numberOfFrames?: bigint;
  profile?:  | "PROFILE_UNKNOWN" | "PROFILE_AAC_MAIN" | "PROFILE_AAC_LOW" | "PROFILE_AAC_SSR" | "PROFILE_AAC_LTP" | "PROFILE_AAC_HE" | "PROFILE_AAC_HE_V2" | "PROFILE_AAC_LD" | "PROFILE_AAC_ELD" | "PROFILE_AVC_CONSTRAINED" | "PROFILE_AVC_INTRA" | "PROFILE_AVC_BASELINE" | "PROFILE_AVC_CONSTRAINED_BASELINE" | "PROFILE_AVC_MAIN" | "PROFILE_AVC_EXTENDED" | "PROFILE_AVC_HIGH" | "PROFILE_AVC_HIGH10" | "PROFILE_AVC_HIGH10_INTRA" | "PROFILE_AVC_HIGH422" | "PROFILE_AVC_HIGH422_INTRA" | "PROFILE_AVC_HIGH444" | "PROFILE_HIGH444_PREDICTIVE" | "PROFILE_AVC_HIGH444_INTRA" | "PROFILE_AVC_CAVLC444" | "PROFILE_VP9_0" | "PROFILE_VP9_1" | "PROFILE_VP9_2" | "PROFILE_VP9_3" | "PROFILE_HEVC_MAIN" | "PROFILE_HEVC_MAIN_10" | "PROFILE_HEVC_MAIN_STILL_PICTURE" | "PROFILE_HEVC_REXT" | "PROFILE_DOVI_5";
  /**
   * audio sample rate
   */
  sampleRate?: bigint;
  /**
   * Number of meaningful bits per decoded audio sample. This is an implicit
   * conceptual meaning. This is *NOT* the same as ffmpeg's internal sample
   * format that is used when actually decoding with ffmpeg.
   */
  sampleSize?: number;
  /**
   * Start/end timestamps of audio in ms.
   */
  startTimestamp?: bigint;
  streamCodecTag?: bigint;
  /**
   * Index of the stream in the file. it is 0 based.
   */
  streamIndex?: bigint;
}

function serializeVideoVideoStreamInfoAudioStream(data: any): VideoVideoStreamInfoAudioStream {
  return {
    ...data,
    bitrate: data["bitrate"] !== undefined ? String(data["bitrate"]) : undefined,
    clockDiscontinuityUs: data["clockDiscontinuityUs"] !== undefined ? String(data["clockDiscontinuityUs"]) : undefined,
    decodeOffset: data["decodeOffset"] !== undefined ? String(data["decodeOffset"]) : undefined,
    endTimestamp: data["endTimestamp"] !== undefined ? String(data["endTimestamp"]) : undefined,
    frameSize: data["frameSize"] !== undefined ? String(data["frameSize"]) : undefined,
    metadata: data["metadata"] !== undefined ? data["metadata"].map((item: any) => (serializeVideoClipInfo(item))) : undefined,
    numberOfFrames: data["numberOfFrames"] !== undefined ? String(data["numberOfFrames"]) : undefined,
    sampleRate: data["sampleRate"] !== undefined ? String(data["sampleRate"]) : undefined,
    startTimestamp: data["startTimestamp"] !== undefined ? String(data["startTimestamp"]) : undefined,
    streamCodecTag: data["streamCodecTag"] !== undefined ? String(data["streamCodecTag"]) : undefined,
    streamIndex: data["streamIndex"] !== undefined ? String(data["streamIndex"]) : undefined,
  };
}

function deserializeVideoVideoStreamInfoAudioStream(data: any): VideoVideoStreamInfoAudioStream {
  return {
    ...data,
    bitrate: data["bitrate"] !== undefined ? BigInt(data["bitrate"]) : undefined,
    clockDiscontinuityUs: data["clockDiscontinuityUs"] !== undefined ? BigInt(data["clockDiscontinuityUs"]) : undefined,
    decodeOffset: data["decodeOffset"] !== undefined ? BigInt(data["decodeOffset"]) : undefined,
    endTimestamp: data["endTimestamp"] !== undefined ? BigInt(data["endTimestamp"]) : undefined,
    frameSize: data["frameSize"] !== undefined ? BigInt(data["frameSize"]) : undefined,
    metadata: data["metadata"] !== undefined ? data["metadata"].map((item: any) => (deserializeVideoClipInfo(item))) : undefined,
    numberOfFrames: data["numberOfFrames"] !== undefined ? BigInt(data["numberOfFrames"]) : undefined,
    sampleRate: data["sampleRate"] !== undefined ? BigInt(data["sampleRate"]) : undefined,
    startTimestamp: data["startTimestamp"] !== undefined ? BigInt(data["startTimestamp"]) : undefined,
    streamCodecTag: data["streamCodecTag"] !== undefined ? BigInt(data["streamCodecTag"]) : undefined,
    streamIndex: data["streamIndex"] !== undefined ? BigInt(data["streamIndex"]) : undefined,
  };
}

/**
 * Data streams refer to additional data separate from audio and video streams
 * For example: camera motion metadata (see http://go/wally-format) Available
 * tags: 4+
 */
export interface VideoVideoStreamInfoDataStream {
  codecFourcc?: string;
  /**
   * Codec information
   */
  codecId?:  | "CODEC_ID_NONE" | "CODEC_ID_MPEG1VIDEO" | "CODEC_ID_MPEG2VIDEO" | "CODEC_ID_MPEG2VIDEO_XVMC" | "CODEC_ID_H261" | "CODEC_ID_H263" | "CODEC_ID_RV10" | "CODEC_ID_RV20" | "CODEC_ID_MJPEG" | "CODEC_ID_MJPEGB" | "CODEC_ID_LJPEG" | "CODEC_ID_SP5X" | "CODEC_ID_JPEGLS" | "CODEC_ID_MPEG4" | "CODEC_ID_RAWVIDEO" | "CODEC_ID_MSMPEG4V1" | "CODEC_ID_MSMPEG4V2" | "CODEC_ID_MSMPEG4V3" | "CODEC_ID_WMV1" | "CODEC_ID_WMV2" | "CODEC_ID_H263P" | "CODEC_ID_H263I" | "CODEC_ID_FLV1" | "CODEC_ID_SVQ1" | "CODEC_ID_SVQ3" | "CODEC_ID_DVVIDEO" | "CODEC_ID_HUFFYUV" | "CODEC_ID_CYUV" | "CODEC_ID_H264" | "CODEC_ID_INDEO3" | "CODEC_ID_VP3" | "CODEC_ID_THEORA" | "CODEC_ID_ASV1" | "CODEC_ID_ASV2" | "CODEC_ID_FFV1" | "CODEC_ID_4XM" | "CODEC_ID_VCR1" | "CODEC_ID_CLJR" | "CODEC_ID_MDEC" | "CODEC_ID_ROQ" | "CODEC_ID_INTERPLAY_VIDEO" | "CODEC_ID_XAN_WC3" | "CODEC_ID_XAN_WC4" | "CODEC_ID_RPZA" | "CODEC_ID_CINEPAK" | "CODEC_ID_WS_VQA" | "CODEC_ID_MSRLE" | "CODEC_ID_MSVIDEO1" | "CODEC_ID_IDCIN" | "CODEC_ID_8BPS" | "CODEC_ID_SMC" | "CODEC_ID_FLIC" | "CODEC_ID_TRUEMOTION1" | "CODEC_ID_VMDVIDEO" | "CODEC_ID_MSZH" | "CODEC_ID_ZLIB" | "CODEC_ID_QTRLE" | "CODEC_ID_SNOW" | "CODEC_ID_TSCC" | "CODEC_ID_ULTI" | "CODEC_ID_QDRAW" | "CODEC_ID_VIXL" | "CODEC_ID_QPEG" | "CODEC_ID_XVID" | "CODEC_ID_PNG" | "CODEC_ID_PPM" | "CODEC_ID_PBM" | "CODEC_ID_PGM" | "CODEC_ID_PGMYUV" | "CODEC_ID_PAM" | "CODEC_ID_FFVHUFF" | "CODEC_ID_RV30" | "CODEC_ID_RV40" | "CODEC_ID_VC1" | "CODEC_ID_WMV3" | "CODEC_ID_LOCO" | "CODEC_ID_WNV1" | "CODEC_ID_AASC" | "CODEC_ID_INDEO2" | "CODEC_ID_FRAPS" | "CODEC_ID_TRUEMOTION2" | "CODEC_ID_BMP" | "CODEC_ID_CSCD" | "CODEC_ID_MMVIDEO" | "CODEC_ID_ZMBV" | "CODEC_ID_AVS" | "CODEC_ID_SMACKVIDEO" | "CODEC_ID_NUV" | "CODEC_ID_KMVC" | "CODEC_ID_FLASHSV" | "CODEC_ID_CAVS" | "CODEC_ID_JPEG2000" | "CODEC_ID_VMNC" | "CODEC_ID_VP5" | "CODEC_ID_VP6" | "CODEC_ID_VP6F" | "CODEC_ID_TARGA" | "CODEC_ID_DSICINVIDEO" | "CODEC_ID_TIERTEXSEQVIDEO" | "CODEC_ID_TIFF" | "CODEC_ID_GIF" | "CODEC_ID_FFH264" | "CODEC_ID_DXA" | "CODEC_ID_DNXHD" | "CODEC_ID_THP" | "CODEC_ID_SGI" | "CODEC_ID_C93" | "CODEC_ID_BETHSOFTVID" | "CODEC_ID_PTX" | "CODEC_ID_TXD" | "CODEC_ID_VP6A" | "CODEC_ID_AMV" | "CODEC_ID_VB" | "CODEC_ID_PCX" | "CODEC_ID_SUNRAST" | "CODEC_ID_INDEO4" | "CODEC_ID_INDEO5" | "CODEC_ID_MIMIC" | "CODEC_ID_RL2" | "CODEC_ID_8SVX_EXP" | "CODEC_ID_8SVX_FIB" | "CODEC_ID_ESCAPE124" | "CODEC_ID_DIRAC" | "CODEC_ID_BFI" | "CODEC_ID_CMV" | "CODEC_ID_MOTIONPIXELS" | "CODEC_ID_TGV" | "CODEC_ID_TGQ" | "CODEC_ID_TQI" | "CODEC_ID_AURA" | "CODEC_ID_AURA2" | "CODEC_ID_V210X" | "CODEC_ID_TMV" | "CODEC_ID_V210" | "CODEC_ID_DPX" | "CODEC_ID_MAD" | "CODEC_ID_FRWU" | "CODEC_ID_VP8" | "CODEC_ID_APPLE_PRORES_NQ" | "CODEC_ID_APPLE_PRORES_HQ" | "CODEC_ID_FLASHSV2" | "CODEC_ID_CDGRAPHICS" | "CODEC_ID_R210" | "CODEC_ID_ANM" | "CODEC_ID_BINKVIDEO" | "CODEC_ID_IFF_ILBM" | "CODEC_ID_IFF_BYTERUN1" | "CODEC_ID_KGV1" | "CODEC_ID_YOP" | "CODEC_ID_PICTOR" | "CODEC_ID_APPLE_PRORES_LT" | "CODEC_ID_APPLE_PRORES_PROXY" | "CODEC_ID_APPLE_PRORES_4444" | "CODEC_ID_APPLE_PIXLET" | "CODEC_ID_G2M" | "CODEC_ID_PRORES" | "CODEC_ID_ANSI" | "CODEC_ID_A64_MULTI" | "CODEC_ID_A64_MULTI5" | "CODEC_ID_R10K" | "CODEC_ID_MXPEG" | "CODEC_ID_LAGARITH" | "CODEC_ID_JV" | "CODEC_ID_DFA" | "CODEC_ID_WMV3IMAGE" | "CODEC_ID_VC1IMAGE" | "CODEC_ID_UTVIDEO" | "CODEC_ID_BMV_VIDEO" | "CODEC_ID_VBLE" | "CODEC_ID_DXTORY" | "CODEC_ID_V410" | "CODEC_ID_XWD" | "CODEC_ID_CDXL" | "CODEC_ID_XBM" | "CODEC_ID_ZEROCODEC" | "CODEC_ID_MSS1" | "CODEC_ID_MSA1" | "CODEC_ID_TSCC2" | "CODEC_ID_MTS2" | "CODEC_ID_CLLC" | "CODEC_ID_MSS2" | "CODEC_ID_Y41P" | "CODEC_ID_ESCAPE130" | "CODEC_ID_EXR" | "CODEC_ID_AVRP" | "CODEC_ID_AVUI" | "CODEC_ID_AYUV" | "CODEC_ID_V308" | "CODEC_ID_V408" | "CODEC_ID_YUV4" | "CODEC_ID_SANM" | "CODEC_ID_PAF_VIDEO" | "CODEC_ID_AVRN" | "CODEC_ID_CPIA" | "CODEC_ID_VP9" | "CODEC_ID_H265" | "CODEC_ID_CFHD" | "CODEC_ID_AV1" | "CODEC_ID_AIC" | "CODEC_ID_ALIAS_PIX" | "CODEC_ID_APNG" | "CODEC_ID_BRENDER_PIX" | "CODEC_ID_CLEARVIDEO" | "CODEC_ID_DDS" | "CODEC_ID_DXV" | "CODEC_ID_FIC" | "CODEC_ID_FITS" | "CODEC_ID_FMVC" | "CODEC_ID_GDV" | "CODEC_ID_HAP" | "CODEC_ID_HNM4_VIDEO" | "CODEC_ID_HQ_HQA" | "CODEC_ID_HQX" | "CODEC_ID_M101" | "CODEC_ID_MAGICYUV" | "CODEC_ID_MSCC" | "CODEC_ID_MVC1" | "CODEC_ID_MVC2" | "CODEC_ID_PIXLET" | "CODEC_ID_PSD" | "CODEC_ID_RSCC" | "CODEC_ID_SCPR" | "CODEC_ID_SCREENPRESSO" | "CODEC_ID_SGIRLE" | "CODEC_ID_SHEERVIDEO" | "CODEC_ID_SMVJPEG" | "CODEC_ID_SPEEDHQ" | "CODEC_ID_SRGC" | "CODEC_ID_TARGA_Y216" | "CODEC_ID_TDSC" | "CODEC_ID_TRUEMOTION2RT" | "CODEC_ID_VP7" | "CODEC_ID_BITPACKED" | "CODEC_ID_WEBP" | "CODEC_ID_XFACE" | "CODEC_ID_XPM" | "CODEC_ID_YLC" | "CODEC_ID_012V" | "CODEC_ID_AVS2" | "CODEC_ID_IMM4" | "CODEC_ID_MWSC" | "CODEC_ID_PROSUMER" | "CODEC_ID_RASC" | "CODEC_ID_WCMV" | "CODEC_ID_UNKNOWN" | "CODEC_ID_PCM_S16LE" | "CODEC_ID_PCM_S16BE" | "CODEC_ID_PCM_U16LE" | "CODEC_ID_PCM_U16BE" | "CODEC_ID_PCM_S8" | "CODEC_ID_PCM_U8" | "CODEC_ID_PCM_MULAW" | "CODEC_ID_PCM_ALAW" | "CODEC_ID_PCM_S32LE" | "CODEC_ID_PCM_S32BE" | "CODEC_ID_PCM_U32LE" | "CODEC_ID_PCM_U32BE" | "CODEC_ID_PCM_S24LE" | "CODEC_ID_PCM_S24BE" | "CODEC_ID_PCM_U24LE" | "CODEC_ID_PCM_U24BE" | "CODEC_ID_PCM_S24DAUD" | "CODEC_ID_PCM_ZORK" | "CODEC_ID_PCM_S16LE_PLANAR" | "CODEC_ID_PCM_DVD" | "CODEC_ID_PCM_F32BE" | "CODEC_ID_PCM_F32LE" | "CODEC_ID_PCM_F64BE" | "CODEC_ID_PCM_F64LE" | "CODEC_ID_PCM_BLURAY" | "CODEC_ID_PCM_LXF" | "CODEC_ID_S302M" | "CODEC_ID_PCM_S8_PLANAR" | "CODEC_ID_PCM_S24LE_PLANAR" | "CODEC_ID_PCM_S32LE_PLANAR" | "CODEC_ID_PCM_S16BE_PLANAR" | "CODEC_ID_PCM_S64LE" | "CODEC_ID_PCM_S64BE" | "CODEC_ID_PCM_F16LE" | "CODEC_ID_PCM_F24LE" | "CODEC_ID_ADPCM_IMA_QT" | "CODEC_ID_ADPCM_IMA_WAV" | "CODEC_ID_ADPCM_IMA_DK3" | "CODEC_ID_ADPCM_IMA_DK4" | "CODEC_ID_ADPCM_IMA_WS" | "CODEC_ID_ADPCM_IMA_SMJPEG" | "CODEC_ID_ADPCM_MS" | "CODEC_ID_ADPCM_4XM" | "CODEC_ID_ADPCM_XA" | "CODEC_ID_ADPCM_ADX" | "CODEC_ID_ADPCM_EA" | "CODEC_ID_ADPCM_G726" | "CODEC_ID_ADPCM_CT" | "CODEC_ID_ADPCM_SWF" | "CODEC_ID_ADPCM_YAMAHA" | "CODEC_ID_ADPCM_SBPRO_4" | "CODEC_ID_ADPCM_SBPRO_3" | "CODEC_ID_ADPCM_SBPRO_2" | "CODEC_ID_ADPCM_THP" | "CODEC_ID_ADPCM_IMA_AMV" | "CODEC_ID_ADPCM_EA_R1" | "CODEC_ID_ADPCM_EA_R3" | "CODEC_ID_ADPCM_EA_R2" | "CODEC_ID_ADPCM_IMA_EA_SEAD" | "CODEC_ID_ADPCM_IMA_EA_EACS" | "CODEC_ID_ADPCM_EA_XAS" | "CODEC_ID_ADPCM_EA_MAXIS_XA" | "CODEC_ID_ADPCM_IMA_ISS" | "CODEC_ID_ADPCM_G722" | "CODEC_ID_ADPCM_IMA_APC" | "CODEC_ID_VIMA" | "CODEC_ID_ADPCM_AFC" | "CODEC_ID_ADPCM_IMA_OKI" | "CODEC_ID_ADPCM_DTK" | "CODEC_ID_ADPCM_IMA_RAD" | "CODEC_ID_ADPCM_G726LE" | "CODEC_ID_ADPCM_THP_LE" | "CODEC_ID_ADPCM_PSX" | "CODEC_ID_ADPCM_AICA" | "CODEC_ID_ADPCM_IMA_DAT4" | "CODEC_ID_ADPCM_MTAF" | "CODEC_ID_ADPCM_VIMA" | "CODEC_ID_AMR_NB" | "CODEC_ID_AMR_WB" | "CODEC_ID_RA_144" | "CODEC_ID_RA_288" | "CODEC_ID_ROQ_DPCM" | "CODEC_ID_INTERPLAY_DPCM" | "CODEC_ID_XAN_DPCM" | "CODEC_ID_SOL_DPCM" | "CODEC_ID_GREMLIN_DPCM" | "CODEC_ID_SDX2_DPCM" | "CODEC_ID_MP2" | "CODEC_ID_MP3" | "CODEC_ID_AAC" | "CODEC_ID_MPEG4AAC_DEPRECATED" | "CODEC_ID_AC3" | "CODEC_ID_DTS" | "CODEC_ID_VORBIS" | "CODEC_ID_DVAUDIO" | "CODEC_ID_WMAV1" | "CODEC_ID_WMAV2" | "CODEC_ID_MACE3" | "CODEC_ID_MACE6" | "CODEC_ID_VMDAUDIO" | "CODEC_ID_SONIC" | "CODEC_ID_SONIC_LS" | "CODEC_ID_FLAC" | "CODEC_ID_MP3ADU" | "CODEC_ID_MP3ON4" | "CODEC_ID_SHORTEN" | "CODEC_ID_ALAC" | "CODEC_ID_WESTWOOD_SND1" | "CODEC_ID_GSM" | "CODEC_ID_QDM2" | "CODEC_ID_COOK" | "CODEC_ID_TRUESPEECH" | "CODEC_ID_TTA" | "CODEC_ID_SMACKAUDIO" | "CODEC_ID_QCELP" | "CODEC_ID_WAVPACK" | "CODEC_ID_DSICINAUDIO" | "CODEC_ID_ASAO" | "CODEC_ID_NELLYMOSER" | "CODEC_ID_WMAVOICE" | "CODEC_ID_WMAPRO" | "CODEC_ID_WMALOSSLESS" | "CODEC_ID_IMC" | "CODEC_ID_MUSEPACK7" | "CODEC_ID_MLP" | "CODEC_ID_GSM_MS" | "CODEC_ID_ATRAC3" | "CODEC_ID_VOXWARE" | "CODEC_ID_APE" | "CODEC_ID_MUSEPACK8" | "CODEC_ID_SPEEX" | "CODEC_ID_ATRAC3P" | "CODEC_ID_EAC3" | "CODEC_ID_SIPR" | "CODEC_ID_MP1" | "CODEC_ID_TWINVQ" | "CODEC_ID_TRUEHD" | "CODEC_ID_MP4ALS" | "CODEC_ID_ATRAC1" | "CODEC_ID_BINKAUDIO_RDFT" | "CODEC_ID_BINKAUDIO_DCT" | "CODEC_ID_AAC_LATM" | "CODEC_ID_QDMC" | "CODEC_ID_CELT" | "CODEC_ID_G723_1" | "CODEC_ID_G729" | "CODEC_ID_BMV_AUDIO" | "CODEC_ID_RALF" | "CODEC_ID_IAC" | "CODEC_ID_ILBC" | "CODEC_ID_FFWAVESYNTH" | "CODEC_ID_8SVX_RAW" | "CODEC_ID_PAF_AUDIO" | "CODEC_ID_OPUS" | "CODEC_ID_ATRAC3AL" | "CODEC_ID_ATRAC3PAL" | "CODEC_ID_DOLBY_E" | "CODEC_ID_DSD_LSBF" | "CODEC_ID_DSD_MSBF" | "CODEC_ID_DSD_LSBF_PLANAR" | "CODEC_ID_DSD_MSBF_PLANAR" | "CODEC_ID_DSS_SP" | "CODEC_ID_DST" | "CODEC_ID_EVRC" | "CODEC_ID_INTERPLAY_ACM" | "CODEC_ID_METASOUND" | "CODEC_ID_ON2AVC" | "CODEC_ID_TAK" | "CODEC_ID_XMA1" | "CODEC_ID_XMA2" | "CODEC_ID_COMFORT_NOISE" | "CODEC_ID_APTX" | "CODEC_ID_APTX_HD" | "CODEC_ID_SBC" | "CODEC_ID_ATRAC9" | "CODEC_ID_CODEC2" | "CODEC_ID_OGGTHEORA_DEPRECATED" | "CODEC_ID_DVD_SUBTITLE" | "CODEC_ID_DVB_SUBTITLE" | "CODEC_ID_TEXT" | "CODEC_ID_XSUB" | "CODEC_ID_SSA" | "CODEC_ID_MOV_TEXT" | "CODEC_ID_HDMV_PGS_SUBTITLE" | "CODEC_ID_DVB_TELETEXT" | "CODEC_ID_SRT" | "CODEC_ID_MICRODVD" | "CODEC_ID_EIA_608" | "CODEC_ID_JACOSUB" | "CODEC_ID_SAMI" | "CODEC_ID_REALTEXT" | "CODEC_ID_SUBVIEWER" | "CODEC_ID_SUBRIP" | "CODEC_ID_WEBVTT" | "CODEC_ID_ASS" | "CODEC_ID_MPL2" | "CODEC_ID_PJS" | "CODEC_ID_STL" | "CODEC_ID_SUBVIEWER1" | "CODEC_ID_VPLAYER" | "CODEC_ID_TTML" | "CODEC_ID_TTF" | "CODEC_ID_BINTEXT" | "CODEC_ID_XBIN" | "CODEC_ID_IDF" | "CODEC_ID_OTF" | "CODEC_ID_PROBE" | "CODEC_ID_MPEG2TS" | "CODEC_ID_MPEG4SYSTEMS" | "CODEC_ID_FFMETADATA" | "CODEC_ID_FFMPEG_OUT_OF_SYNC" | "CODEC_ID_WRAPPED_AVFRAME" | "CODEC_ID_CAMM";
  streamCodecTag?: bigint;
  /**
   * Index of the stream in the file
   */
  streamIndex?: bigint;
}

function serializeVideoVideoStreamInfoDataStream(data: any): VideoVideoStreamInfoDataStream {
  return {
    ...data,
    streamCodecTag: data["streamCodecTag"] !== undefined ? String(data["streamCodecTag"]) : undefined,
    streamIndex: data["streamIndex"] !== undefined ? String(data["streamIndex"]) : undefined,
  };
}

function deserializeVideoVideoStreamInfoDataStream(data: any): VideoVideoStreamInfoDataStream {
  return {
    ...data,
    streamCodecTag: data["streamCodecTag"] !== undefined ? BigInt(data["streamCodecTag"]) : undefined,
    streamIndex: data["streamIndex"] !== undefined ? BigInt(data["streamIndex"]) : undefined,
  };
}

export interface VideoVideoStreamInfoMetadata {
  luts?: VideoVideoStreamInfoMetadataLutAttachments;
  /**
   * Information on Frame Packing arrangement
   */
  videoFpa?: VideoFileFramePackingArrangement;
}

function serializeVideoVideoStreamInfoMetadata(data: any): VideoVideoStreamInfoMetadata {
  return {
    ...data,
    luts: data["luts"] !== undefined ? serializeVideoVideoStreamInfoMetadataLutAttachments(data["luts"]) : undefined,
  };
}

function deserializeVideoVideoStreamInfoMetadata(data: any): VideoVideoStreamInfoMetadata {
  return {
    ...data,
    luts: data["luts"] !== undefined ? deserializeVideoVideoStreamInfoMetadataLutAttachments(data["luts"]) : undefined,
  };
}

/**
 * An attached 3D look up table
 */
export interface VideoVideoStreamInfoMetadataLutAttachments {
  lut?: VideoVideoStreamInfoMetadataLutAttachmentsLut3D[];
}

function serializeVideoVideoStreamInfoMetadataLutAttachments(data: any): VideoVideoStreamInfoMetadataLutAttachments {
  return {
    ...data,
    lut: data["lut"] !== undefined ? data["lut"].map((item: any) => (serializeVideoVideoStreamInfoMetadataLutAttachmentsLut3D(item))) : undefined,
  };
}

function deserializeVideoVideoStreamInfoMetadataLutAttachments(data: any): VideoVideoStreamInfoMetadataLutAttachments {
  return {
    ...data,
    lut: data["lut"] !== undefined ? data["lut"].map((item: any) => (deserializeVideoVideoStreamInfoMetadataLutAttachmentsLut3D(item))) : undefined,
  };
}

/**
 * Description and encoding of a 3d lut.
 */
export interface VideoVideoStreamInfoMetadataLutAttachmentsLut3D {
  /**
   * Lut data, sanitized and encoded in google's binary coded form of 3D
   * look-up tables.
   */
  data?: Uint8Array;
  /**
   * Original file name of the lut (present in the original file)
   */
  fileName?: string;
  /**
   * The size (in each dimension) of the lut. For a 3D cube of size NxNxN, this
   * will be N. If the value is -1, then the file was determined to be invalid.
   * This is useful for logging files where the input could not be parsed, and
   * is useful for to indicate info of the 3D lut without having to
   * decode/inspect the binary data.
   */
  size?: number;
}

function serializeVideoVideoStreamInfoMetadataLutAttachmentsLut3D(data: any): VideoVideoStreamInfoMetadataLutAttachmentsLut3D {
  return {
    ...data,
    data: data["data"] !== undefined ? encodeBase64(data["data"]) : undefined,
  };
}

function deserializeVideoVideoStreamInfoMetadataLutAttachmentsLut3D(data: any): VideoVideoStreamInfoMetadataLutAttachmentsLut3D {
  return {
    ...data,
    data: data["data"] !== undefined ? decodeBase64(data["data"] as string) : undefined,
  };
}

/**
 * Timed text streams refer to the streams that are separated from audio and
 * video streams. Closed caption streams embedded in video streams (e.g. MPEG-2
 * - Line 21) do not belong here.
 */
export interface VideoVideoStreamInfoTimedTextStream {
  /**
   * Codec information.
   */
  codecId?:  | "CODEC_ID_NONE" | "CODEC_ID_MPEG1VIDEO" | "CODEC_ID_MPEG2VIDEO" | "CODEC_ID_MPEG2VIDEO_XVMC" | "CODEC_ID_H261" | "CODEC_ID_H263" | "CODEC_ID_RV10" | "CODEC_ID_RV20" | "CODEC_ID_MJPEG" | "CODEC_ID_MJPEGB" | "CODEC_ID_LJPEG" | "CODEC_ID_SP5X" | "CODEC_ID_JPEGLS" | "CODEC_ID_MPEG4" | "CODEC_ID_RAWVIDEO" | "CODEC_ID_MSMPEG4V1" | "CODEC_ID_MSMPEG4V2" | "CODEC_ID_MSMPEG4V3" | "CODEC_ID_WMV1" | "CODEC_ID_WMV2" | "CODEC_ID_H263P" | "CODEC_ID_H263I" | "CODEC_ID_FLV1" | "CODEC_ID_SVQ1" | "CODEC_ID_SVQ3" | "CODEC_ID_DVVIDEO" | "CODEC_ID_HUFFYUV" | "CODEC_ID_CYUV" | "CODEC_ID_H264" | "CODEC_ID_INDEO3" | "CODEC_ID_VP3" | "CODEC_ID_THEORA" | "CODEC_ID_ASV1" | "CODEC_ID_ASV2" | "CODEC_ID_FFV1" | "CODEC_ID_4XM" | "CODEC_ID_VCR1" | "CODEC_ID_CLJR" | "CODEC_ID_MDEC" | "CODEC_ID_ROQ" | "CODEC_ID_INTERPLAY_VIDEO" | "CODEC_ID_XAN_WC3" | "CODEC_ID_XAN_WC4" | "CODEC_ID_RPZA" | "CODEC_ID_CINEPAK" | "CODEC_ID_WS_VQA" | "CODEC_ID_MSRLE" | "CODEC_ID_MSVIDEO1" | "CODEC_ID_IDCIN" | "CODEC_ID_8BPS" | "CODEC_ID_SMC" | "CODEC_ID_FLIC" | "CODEC_ID_TRUEMOTION1" | "CODEC_ID_VMDVIDEO" | "CODEC_ID_MSZH" | "CODEC_ID_ZLIB" | "CODEC_ID_QTRLE" | "CODEC_ID_SNOW" | "CODEC_ID_TSCC" | "CODEC_ID_ULTI" | "CODEC_ID_QDRAW" | "CODEC_ID_VIXL" | "CODEC_ID_QPEG" | "CODEC_ID_XVID" | "CODEC_ID_PNG" | "CODEC_ID_PPM" | "CODEC_ID_PBM" | "CODEC_ID_PGM" | "CODEC_ID_PGMYUV" | "CODEC_ID_PAM" | "CODEC_ID_FFVHUFF" | "CODEC_ID_RV30" | "CODEC_ID_RV40" | "CODEC_ID_VC1" | "CODEC_ID_WMV3" | "CODEC_ID_LOCO" | "CODEC_ID_WNV1" | "CODEC_ID_AASC" | "CODEC_ID_INDEO2" | "CODEC_ID_FRAPS" | "CODEC_ID_TRUEMOTION2" | "CODEC_ID_BMP" | "CODEC_ID_CSCD" | "CODEC_ID_MMVIDEO" | "CODEC_ID_ZMBV" | "CODEC_ID_AVS" | "CODEC_ID_SMACKVIDEO" | "CODEC_ID_NUV" | "CODEC_ID_KMVC" | "CODEC_ID_FLASHSV" | "CODEC_ID_CAVS" | "CODEC_ID_JPEG2000" | "CODEC_ID_VMNC" | "CODEC_ID_VP5" | "CODEC_ID_VP6" | "CODEC_ID_VP6F" | "CODEC_ID_TARGA" | "CODEC_ID_DSICINVIDEO" | "CODEC_ID_TIERTEXSEQVIDEO" | "CODEC_ID_TIFF" | "CODEC_ID_GIF" | "CODEC_ID_FFH264" | "CODEC_ID_DXA" | "CODEC_ID_DNXHD" | "CODEC_ID_THP" | "CODEC_ID_SGI" | "CODEC_ID_C93" | "CODEC_ID_BETHSOFTVID" | "CODEC_ID_PTX" | "CODEC_ID_TXD" | "CODEC_ID_VP6A" | "CODEC_ID_AMV" | "CODEC_ID_VB" | "CODEC_ID_PCX" | "CODEC_ID_SUNRAST" | "CODEC_ID_INDEO4" | "CODEC_ID_INDEO5" | "CODEC_ID_MIMIC" | "CODEC_ID_RL2" | "CODEC_ID_8SVX_EXP" | "CODEC_ID_8SVX_FIB" | "CODEC_ID_ESCAPE124" | "CODEC_ID_DIRAC" | "CODEC_ID_BFI" | "CODEC_ID_CMV" | "CODEC_ID_MOTIONPIXELS" | "CODEC_ID_TGV" | "CODEC_ID_TGQ" | "CODEC_ID_TQI" | "CODEC_ID_AURA" | "CODEC_ID_AURA2" | "CODEC_ID_V210X" | "CODEC_ID_TMV" | "CODEC_ID_V210" | "CODEC_ID_DPX" | "CODEC_ID_MAD" | "CODEC_ID_FRWU" | "CODEC_ID_VP8" | "CODEC_ID_APPLE_PRORES_NQ" | "CODEC_ID_APPLE_PRORES_HQ" | "CODEC_ID_FLASHSV2" | "CODEC_ID_CDGRAPHICS" | "CODEC_ID_R210" | "CODEC_ID_ANM" | "CODEC_ID_BINKVIDEO" | "CODEC_ID_IFF_ILBM" | "CODEC_ID_IFF_BYTERUN1" | "CODEC_ID_KGV1" | "CODEC_ID_YOP" | "CODEC_ID_PICTOR" | "CODEC_ID_APPLE_PRORES_LT" | "CODEC_ID_APPLE_PRORES_PROXY" | "CODEC_ID_APPLE_PRORES_4444" | "CODEC_ID_APPLE_PIXLET" | "CODEC_ID_G2M" | "CODEC_ID_PRORES" | "CODEC_ID_ANSI" | "CODEC_ID_A64_MULTI" | "CODEC_ID_A64_MULTI5" | "CODEC_ID_R10K" | "CODEC_ID_MXPEG" | "CODEC_ID_LAGARITH" | "CODEC_ID_JV" | "CODEC_ID_DFA" | "CODEC_ID_WMV3IMAGE" | "CODEC_ID_VC1IMAGE" | "CODEC_ID_UTVIDEO" | "CODEC_ID_BMV_VIDEO" | "CODEC_ID_VBLE" | "CODEC_ID_DXTORY" | "CODEC_ID_V410" | "CODEC_ID_XWD" | "CODEC_ID_CDXL" | "CODEC_ID_XBM" | "CODEC_ID_ZEROCODEC" | "CODEC_ID_MSS1" | "CODEC_ID_MSA1" | "CODEC_ID_TSCC2" | "CODEC_ID_MTS2" | "CODEC_ID_CLLC" | "CODEC_ID_MSS2" | "CODEC_ID_Y41P" | "CODEC_ID_ESCAPE130" | "CODEC_ID_EXR" | "CODEC_ID_AVRP" | "CODEC_ID_AVUI" | "CODEC_ID_AYUV" | "CODEC_ID_V308" | "CODEC_ID_V408" | "CODEC_ID_YUV4" | "CODEC_ID_SANM" | "CODEC_ID_PAF_VIDEO" | "CODEC_ID_AVRN" | "CODEC_ID_CPIA" | "CODEC_ID_VP9" | "CODEC_ID_H265" | "CODEC_ID_CFHD" | "CODEC_ID_AV1" | "CODEC_ID_AIC" | "CODEC_ID_ALIAS_PIX" | "CODEC_ID_APNG" | "CODEC_ID_BRENDER_PIX" | "CODEC_ID_CLEARVIDEO" | "CODEC_ID_DDS" | "CODEC_ID_DXV" | "CODEC_ID_FIC" | "CODEC_ID_FITS" | "CODEC_ID_FMVC" | "CODEC_ID_GDV" | "CODEC_ID_HAP" | "CODEC_ID_HNM4_VIDEO" | "CODEC_ID_HQ_HQA" | "CODEC_ID_HQX" | "CODEC_ID_M101" | "CODEC_ID_MAGICYUV" | "CODEC_ID_MSCC" | "CODEC_ID_MVC1" | "CODEC_ID_MVC2" | "CODEC_ID_PIXLET" | "CODEC_ID_PSD" | "CODEC_ID_RSCC" | "CODEC_ID_SCPR" | "CODEC_ID_SCREENPRESSO" | "CODEC_ID_SGIRLE" | "CODEC_ID_SHEERVIDEO" | "CODEC_ID_SMVJPEG" | "CODEC_ID_SPEEDHQ" | "CODEC_ID_SRGC" | "CODEC_ID_TARGA_Y216" | "CODEC_ID_TDSC" | "CODEC_ID_TRUEMOTION2RT" | "CODEC_ID_VP7" | "CODEC_ID_BITPACKED" | "CODEC_ID_WEBP" | "CODEC_ID_XFACE" | "CODEC_ID_XPM" | "CODEC_ID_YLC" | "CODEC_ID_012V" | "CODEC_ID_AVS2" | "CODEC_ID_IMM4" | "CODEC_ID_MWSC" | "CODEC_ID_PROSUMER" | "CODEC_ID_RASC" | "CODEC_ID_WCMV" | "CODEC_ID_UNKNOWN" | "CODEC_ID_PCM_S16LE" | "CODEC_ID_PCM_S16BE" | "CODEC_ID_PCM_U16LE" | "CODEC_ID_PCM_U16BE" | "CODEC_ID_PCM_S8" | "CODEC_ID_PCM_U8" | "CODEC_ID_PCM_MULAW" | "CODEC_ID_PCM_ALAW" | "CODEC_ID_PCM_S32LE" | "CODEC_ID_PCM_S32BE" | "CODEC_ID_PCM_U32LE" | "CODEC_ID_PCM_U32BE" | "CODEC_ID_PCM_S24LE" | "CODEC_ID_PCM_S24BE" | "CODEC_ID_PCM_U24LE" | "CODEC_ID_PCM_U24BE" | "CODEC_ID_PCM_S24DAUD" | "CODEC_ID_PCM_ZORK" | "CODEC_ID_PCM_S16LE_PLANAR" | "CODEC_ID_PCM_DVD" | "CODEC_ID_PCM_F32BE" | "CODEC_ID_PCM_F32LE" | "CODEC_ID_PCM_F64BE" | "CODEC_ID_PCM_F64LE" | "CODEC_ID_PCM_BLURAY" | "CODEC_ID_PCM_LXF" | "CODEC_ID_S302M" | "CODEC_ID_PCM_S8_PLANAR" | "CODEC_ID_PCM_S24LE_PLANAR" | "CODEC_ID_PCM_S32LE_PLANAR" | "CODEC_ID_PCM_S16BE_PLANAR" | "CODEC_ID_PCM_S64LE" | "CODEC_ID_PCM_S64BE" | "CODEC_ID_PCM_F16LE" | "CODEC_ID_PCM_F24LE" | "CODEC_ID_ADPCM_IMA_QT" | "CODEC_ID_ADPCM_IMA_WAV" | "CODEC_ID_ADPCM_IMA_DK3" | "CODEC_ID_ADPCM_IMA_DK4" | "CODEC_ID_ADPCM_IMA_WS" | "CODEC_ID_ADPCM_IMA_SMJPEG" | "CODEC_ID_ADPCM_MS" | "CODEC_ID_ADPCM_4XM" | "CODEC_ID_ADPCM_XA" | "CODEC_ID_ADPCM_ADX" | "CODEC_ID_ADPCM_EA" | "CODEC_ID_ADPCM_G726" | "CODEC_ID_ADPCM_CT" | "CODEC_ID_ADPCM_SWF" | "CODEC_ID_ADPCM_YAMAHA" | "CODEC_ID_ADPCM_SBPRO_4" | "CODEC_ID_ADPCM_SBPRO_3" | "CODEC_ID_ADPCM_SBPRO_2" | "CODEC_ID_ADPCM_THP" | "CODEC_ID_ADPCM_IMA_AMV" | "CODEC_ID_ADPCM_EA_R1" | "CODEC_ID_ADPCM_EA_R3" | "CODEC_ID_ADPCM_EA_R2" | "CODEC_ID_ADPCM_IMA_EA_SEAD" | "CODEC_ID_ADPCM_IMA_EA_EACS" | "CODEC_ID_ADPCM_EA_XAS" | "CODEC_ID_ADPCM_EA_MAXIS_XA" | "CODEC_ID_ADPCM_IMA_ISS" | "CODEC_ID_ADPCM_G722" | "CODEC_ID_ADPCM_IMA_APC" | "CODEC_ID_VIMA" | "CODEC_ID_ADPCM_AFC" | "CODEC_ID_ADPCM_IMA_OKI" | "CODEC_ID_ADPCM_DTK" | "CODEC_ID_ADPCM_IMA_RAD" | "CODEC_ID_ADPCM_G726LE" | "CODEC_ID_ADPCM_THP_LE" | "CODEC_ID_ADPCM_PSX" | "CODEC_ID_ADPCM_AICA" | "CODEC_ID_ADPCM_IMA_DAT4" | "CODEC_ID_ADPCM_MTAF" | "CODEC_ID_ADPCM_VIMA" | "CODEC_ID_AMR_NB" | "CODEC_ID_AMR_WB" | "CODEC_ID_RA_144" | "CODEC_ID_RA_288" | "CODEC_ID_ROQ_DPCM" | "CODEC_ID_INTERPLAY_DPCM" | "CODEC_ID_XAN_DPCM" | "CODEC_ID_SOL_DPCM" | "CODEC_ID_GREMLIN_DPCM" | "CODEC_ID_SDX2_DPCM" | "CODEC_ID_MP2" | "CODEC_ID_MP3" | "CODEC_ID_AAC" | "CODEC_ID_MPEG4AAC_DEPRECATED" | "CODEC_ID_AC3" | "CODEC_ID_DTS" | "CODEC_ID_VORBIS" | "CODEC_ID_DVAUDIO" | "CODEC_ID_WMAV1" | "CODEC_ID_WMAV2" | "CODEC_ID_MACE3" | "CODEC_ID_MACE6" | "CODEC_ID_VMDAUDIO" | "CODEC_ID_SONIC" | "CODEC_ID_SONIC_LS" | "CODEC_ID_FLAC" | "CODEC_ID_MP3ADU" | "CODEC_ID_MP3ON4" | "CODEC_ID_SHORTEN" | "CODEC_ID_ALAC" | "CODEC_ID_WESTWOOD_SND1" | "CODEC_ID_GSM" | "CODEC_ID_QDM2" | "CODEC_ID_COOK" | "CODEC_ID_TRUESPEECH" | "CODEC_ID_TTA" | "CODEC_ID_SMACKAUDIO" | "CODEC_ID_QCELP" | "CODEC_ID_WAVPACK" | "CODEC_ID_DSICINAUDIO" | "CODEC_ID_ASAO" | "CODEC_ID_NELLYMOSER" | "CODEC_ID_WMAVOICE" | "CODEC_ID_WMAPRO" | "CODEC_ID_WMALOSSLESS" | "CODEC_ID_IMC" | "CODEC_ID_MUSEPACK7" | "CODEC_ID_MLP" | "CODEC_ID_GSM_MS" | "CODEC_ID_ATRAC3" | "CODEC_ID_VOXWARE" | "CODEC_ID_APE" | "CODEC_ID_MUSEPACK8" | "CODEC_ID_SPEEX" | "CODEC_ID_ATRAC3P" | "CODEC_ID_EAC3" | "CODEC_ID_SIPR" | "CODEC_ID_MP1" | "CODEC_ID_TWINVQ" | "CODEC_ID_TRUEHD" | "CODEC_ID_MP4ALS" | "CODEC_ID_ATRAC1" | "CODEC_ID_BINKAUDIO_RDFT" | "CODEC_ID_BINKAUDIO_DCT" | "CODEC_ID_AAC_LATM" | "CODEC_ID_QDMC" | "CODEC_ID_CELT" | "CODEC_ID_G723_1" | "CODEC_ID_G729" | "CODEC_ID_BMV_AUDIO" | "CODEC_ID_RALF" | "CODEC_ID_IAC" | "CODEC_ID_ILBC" | "CODEC_ID_FFWAVESYNTH" | "CODEC_ID_8SVX_RAW" | "CODEC_ID_PAF_AUDIO" | "CODEC_ID_OPUS" | "CODEC_ID_ATRAC3AL" | "CODEC_ID_ATRAC3PAL" | "CODEC_ID_DOLBY_E" | "CODEC_ID_DSD_LSBF" | "CODEC_ID_DSD_MSBF" | "CODEC_ID_DSD_LSBF_PLANAR" | "CODEC_ID_DSD_MSBF_PLANAR" | "CODEC_ID_DSS_SP" | "CODEC_ID_DST" | "CODEC_ID_EVRC" | "CODEC_ID_INTERPLAY_ACM" | "CODEC_ID_METASOUND" | "CODEC_ID_ON2AVC" | "CODEC_ID_TAK" | "CODEC_ID_XMA1" | "CODEC_ID_XMA2" | "CODEC_ID_COMFORT_NOISE" | "CODEC_ID_APTX" | "CODEC_ID_APTX_HD" | "CODEC_ID_SBC" | "CODEC_ID_ATRAC9" | "CODEC_ID_CODEC2" | "CODEC_ID_OGGTHEORA_DEPRECATED" | "CODEC_ID_DVD_SUBTITLE" | "CODEC_ID_DVB_SUBTITLE" | "CODEC_ID_TEXT" | "CODEC_ID_XSUB" | "CODEC_ID_SSA" | "CODEC_ID_MOV_TEXT" | "CODEC_ID_HDMV_PGS_SUBTITLE" | "CODEC_ID_DVB_TELETEXT" | "CODEC_ID_SRT" | "CODEC_ID_MICRODVD" | "CODEC_ID_EIA_608" | "CODEC_ID_JACOSUB" | "CODEC_ID_SAMI" | "CODEC_ID_REALTEXT" | "CODEC_ID_SUBVIEWER" | "CODEC_ID_SUBRIP" | "CODEC_ID_WEBVTT" | "CODEC_ID_ASS" | "CODEC_ID_MPL2" | "CODEC_ID_PJS" | "CODEC_ID_STL" | "CODEC_ID_SUBVIEWER1" | "CODEC_ID_VPLAYER" | "CODEC_ID_TTML" | "CODEC_ID_TTF" | "CODEC_ID_BINTEXT" | "CODEC_ID_XBIN" | "CODEC_ID_IDF" | "CODEC_ID_OTF" | "CODEC_ID_PROBE" | "CODEC_ID_MPEG2TS" | "CODEC_ID_MPEG4SYSTEMS" | "CODEC_ID_FFMETADATA" | "CODEC_ID_FFMPEG_OUT_OF_SYNC" | "CODEC_ID_WRAPPED_AVFRAME" | "CODEC_ID_CAMM";
  /**
   * Metadata for the stream.
   */
  metadata?: VideoClipInfo[];
  streamCodecTag?: bigint;
  /**
   * Index of the stream in the file. it is 0 based.
   */
  streamIndex?: bigint;
}

function serializeVideoVideoStreamInfoTimedTextStream(data: any): VideoVideoStreamInfoTimedTextStream {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? data["metadata"].map((item: any) => (serializeVideoClipInfo(item))) : undefined,
    streamCodecTag: data["streamCodecTag"] !== undefined ? String(data["streamCodecTag"]) : undefined,
    streamIndex: data["streamIndex"] !== undefined ? String(data["streamIndex"]) : undefined,
  };
}

function deserializeVideoVideoStreamInfoTimedTextStream(data: any): VideoVideoStreamInfoTimedTextStream {
  return {
    ...data,
    metadata: data["metadata"] !== undefined ? data["metadata"].map((item: any) => (deserializeVideoClipInfo(item))) : undefined,
    streamCodecTag: data["streamCodecTag"] !== undefined ? BigInt(data["streamCodecTag"]) : undefined,
    streamIndex: data["streamIndex"] !== undefined ? BigInt(data["streamIndex"]) : undefined,
  };
}

/**
 * TODO(yanghu) add 25/50/75 percentiles of FPS to have a 5 number summary.
 * Next id: 48
 */
export interface VideoVideoStreamInfoVideoStream {
  /**
   * This represents the canonical frame rate of the video. This is named
   * average_fps for historical reasons, and may not actually be the arithmetic
   * mean. For variable frame rate videos, the algorithm may change again in
   * future. Currently, full vsi set it with arithmetic mean, and partial vsi
   * set it with median.
   */
  averageFps?: number;
  /**
   * video bitrate in bits/s
   */
  bitrate?: bigint;
  /**
   * Contains the color information obtained after inspection of the bitstream
   * in cases where there may be inconsistencies between container and coded
   * bitstream that are resolved in favor of the container.
   */
  bitstreamColorInfo?: VideoFileColorInfo;
  cleanAperture?: VideoVideoStreamInfoVideoStreamCleanAperture;
  /**
   * some container allows for a clock discontinuity. In this case, the
   * end_timestamp may not be the correct DTS of the stream.
   */
  clockDiscontinuityUs?: bigint;
  closedCaptions?: VideoClosedCaptions;
  /**
   * closed_gop_size refers to chunkable boundaries for each specified codec
   * and may actually contain one or more GOPs, e.g. for H.264, closed_gop_size
   * will denote the distance (frame count) between two IDR frames.
   */
  closedGopSize?: VideoVideoStreamInfoVideoStreamStatistics;
  codecFourcc?: string;
  /**
   * Primary video codec information
   */
  codecId?:  | "CODEC_ID_NONE" | "CODEC_ID_MPEG1VIDEO" | "CODEC_ID_MPEG2VIDEO" | "CODEC_ID_MPEG2VIDEO_XVMC" | "CODEC_ID_H261" | "CODEC_ID_H263" | "CODEC_ID_RV10" | "CODEC_ID_RV20" | "CODEC_ID_MJPEG" | "CODEC_ID_MJPEGB" | "CODEC_ID_LJPEG" | "CODEC_ID_SP5X" | "CODEC_ID_JPEGLS" | "CODEC_ID_MPEG4" | "CODEC_ID_RAWVIDEO" | "CODEC_ID_MSMPEG4V1" | "CODEC_ID_MSMPEG4V2" | "CODEC_ID_MSMPEG4V3" | "CODEC_ID_WMV1" | "CODEC_ID_WMV2" | "CODEC_ID_H263P" | "CODEC_ID_H263I" | "CODEC_ID_FLV1" | "CODEC_ID_SVQ1" | "CODEC_ID_SVQ3" | "CODEC_ID_DVVIDEO" | "CODEC_ID_HUFFYUV" | "CODEC_ID_CYUV" | "CODEC_ID_H264" | "CODEC_ID_INDEO3" | "CODEC_ID_VP3" | "CODEC_ID_THEORA" | "CODEC_ID_ASV1" | "CODEC_ID_ASV2" | "CODEC_ID_FFV1" | "CODEC_ID_4XM" | "CODEC_ID_VCR1" | "CODEC_ID_CLJR" | "CODEC_ID_MDEC" | "CODEC_ID_ROQ" | "CODEC_ID_INTERPLAY_VIDEO" | "CODEC_ID_XAN_WC3" | "CODEC_ID_XAN_WC4" | "CODEC_ID_RPZA" | "CODEC_ID_CINEPAK" | "CODEC_ID_WS_VQA" | "CODEC_ID_MSRLE" | "CODEC_ID_MSVIDEO1" | "CODEC_ID_IDCIN" | "CODEC_ID_8BPS" | "CODEC_ID_SMC" | "CODEC_ID_FLIC" | "CODEC_ID_TRUEMOTION1" | "CODEC_ID_VMDVIDEO" | "CODEC_ID_MSZH" | "CODEC_ID_ZLIB" | "CODEC_ID_QTRLE" | "CODEC_ID_SNOW" | "CODEC_ID_TSCC" | "CODEC_ID_ULTI" | "CODEC_ID_QDRAW" | "CODEC_ID_VIXL" | "CODEC_ID_QPEG" | "CODEC_ID_XVID" | "CODEC_ID_PNG" | "CODEC_ID_PPM" | "CODEC_ID_PBM" | "CODEC_ID_PGM" | "CODEC_ID_PGMYUV" | "CODEC_ID_PAM" | "CODEC_ID_FFVHUFF" | "CODEC_ID_RV30" | "CODEC_ID_RV40" | "CODEC_ID_VC1" | "CODEC_ID_WMV3" | "CODEC_ID_LOCO" | "CODEC_ID_WNV1" | "CODEC_ID_AASC" | "CODEC_ID_INDEO2" | "CODEC_ID_FRAPS" | "CODEC_ID_TRUEMOTION2" | "CODEC_ID_BMP" | "CODEC_ID_CSCD" | "CODEC_ID_MMVIDEO" | "CODEC_ID_ZMBV" | "CODEC_ID_AVS" | "CODEC_ID_SMACKVIDEO" | "CODEC_ID_NUV" | "CODEC_ID_KMVC" | "CODEC_ID_FLASHSV" | "CODEC_ID_CAVS" | "CODEC_ID_JPEG2000" | "CODEC_ID_VMNC" | "CODEC_ID_VP5" | "CODEC_ID_VP6" | "CODEC_ID_VP6F" | "CODEC_ID_TARGA" | "CODEC_ID_DSICINVIDEO" | "CODEC_ID_TIERTEXSEQVIDEO" | "CODEC_ID_TIFF" | "CODEC_ID_GIF" | "CODEC_ID_FFH264" | "CODEC_ID_DXA" | "CODEC_ID_DNXHD" | "CODEC_ID_THP" | "CODEC_ID_SGI" | "CODEC_ID_C93" | "CODEC_ID_BETHSOFTVID" | "CODEC_ID_PTX" | "CODEC_ID_TXD" | "CODEC_ID_VP6A" | "CODEC_ID_AMV" | "CODEC_ID_VB" | "CODEC_ID_PCX" | "CODEC_ID_SUNRAST" | "CODEC_ID_INDEO4" | "CODEC_ID_INDEO5" | "CODEC_ID_MIMIC" | "CODEC_ID_RL2" | "CODEC_ID_8SVX_EXP" | "CODEC_ID_8SVX_FIB" | "CODEC_ID_ESCAPE124" | "CODEC_ID_DIRAC" | "CODEC_ID_BFI" | "CODEC_ID_CMV" | "CODEC_ID_MOTIONPIXELS" | "CODEC_ID_TGV" | "CODEC_ID_TGQ" | "CODEC_ID_TQI" | "CODEC_ID_AURA" | "CODEC_ID_AURA2" | "CODEC_ID_V210X" | "CODEC_ID_TMV" | "CODEC_ID_V210" | "CODEC_ID_DPX" | "CODEC_ID_MAD" | "CODEC_ID_FRWU" | "CODEC_ID_VP8" | "CODEC_ID_APPLE_PRORES_NQ" | "CODEC_ID_APPLE_PRORES_HQ" | "CODEC_ID_FLASHSV2" | "CODEC_ID_CDGRAPHICS" | "CODEC_ID_R210" | "CODEC_ID_ANM" | "CODEC_ID_BINKVIDEO" | "CODEC_ID_IFF_ILBM" | "CODEC_ID_IFF_BYTERUN1" | "CODEC_ID_KGV1" | "CODEC_ID_YOP" | "CODEC_ID_PICTOR" | "CODEC_ID_APPLE_PRORES_LT" | "CODEC_ID_APPLE_PRORES_PROXY" | "CODEC_ID_APPLE_PRORES_4444" | "CODEC_ID_APPLE_PIXLET" | "CODEC_ID_G2M" | "CODEC_ID_PRORES" | "CODEC_ID_ANSI" | "CODEC_ID_A64_MULTI" | "CODEC_ID_A64_MULTI5" | "CODEC_ID_R10K" | "CODEC_ID_MXPEG" | "CODEC_ID_LAGARITH" | "CODEC_ID_JV" | "CODEC_ID_DFA" | "CODEC_ID_WMV3IMAGE" | "CODEC_ID_VC1IMAGE" | "CODEC_ID_UTVIDEO" | "CODEC_ID_BMV_VIDEO" | "CODEC_ID_VBLE" | "CODEC_ID_DXTORY" | "CODEC_ID_V410" | "CODEC_ID_XWD" | "CODEC_ID_CDXL" | "CODEC_ID_XBM" | "CODEC_ID_ZEROCODEC" | "CODEC_ID_MSS1" | "CODEC_ID_MSA1" | "CODEC_ID_TSCC2" | "CODEC_ID_MTS2" | "CODEC_ID_CLLC" | "CODEC_ID_MSS2" | "CODEC_ID_Y41P" | "CODEC_ID_ESCAPE130" | "CODEC_ID_EXR" | "CODEC_ID_AVRP" | "CODEC_ID_AVUI" | "CODEC_ID_AYUV" | "CODEC_ID_V308" | "CODEC_ID_V408" | "CODEC_ID_YUV4" | "CODEC_ID_SANM" | "CODEC_ID_PAF_VIDEO" | "CODEC_ID_AVRN" | "CODEC_ID_CPIA" | "CODEC_ID_VP9" | "CODEC_ID_H265" | "CODEC_ID_CFHD" | "CODEC_ID_AV1" | "CODEC_ID_AIC" | "CODEC_ID_ALIAS_PIX" | "CODEC_ID_APNG" | "CODEC_ID_BRENDER_PIX" | "CODEC_ID_CLEARVIDEO" | "CODEC_ID_DDS" | "CODEC_ID_DXV" | "CODEC_ID_FIC" | "CODEC_ID_FITS" | "CODEC_ID_FMVC" | "CODEC_ID_GDV" | "CODEC_ID_HAP" | "CODEC_ID_HNM4_VIDEO" | "CODEC_ID_HQ_HQA" | "CODEC_ID_HQX" | "CODEC_ID_M101" | "CODEC_ID_MAGICYUV" | "CODEC_ID_MSCC" | "CODEC_ID_MVC1" | "CODEC_ID_MVC2" | "CODEC_ID_PIXLET" | "CODEC_ID_PSD" | "CODEC_ID_RSCC" | "CODEC_ID_SCPR" | "CODEC_ID_SCREENPRESSO" | "CODEC_ID_SGIRLE" | "CODEC_ID_SHEERVIDEO" | "CODEC_ID_SMVJPEG" | "CODEC_ID_SPEEDHQ" | "CODEC_ID_SRGC" | "CODEC_ID_TARGA_Y216" | "CODEC_ID_TDSC" | "CODEC_ID_TRUEMOTION2RT" | "CODEC_ID_VP7" | "CODEC_ID_BITPACKED" | "CODEC_ID_WEBP" | "CODEC_ID_XFACE" | "CODEC_ID_XPM" | "CODEC_ID_YLC" | "CODEC_ID_012V" | "CODEC_ID_AVS2" | "CODEC_ID_IMM4" | "CODEC_ID_MWSC" | "CODEC_ID_PROSUMER" | "CODEC_ID_RASC" | "CODEC_ID_WCMV" | "CODEC_ID_UNKNOWN" | "CODEC_ID_PCM_S16LE" | "CODEC_ID_PCM_S16BE" | "CODEC_ID_PCM_U16LE" | "CODEC_ID_PCM_U16BE" | "CODEC_ID_PCM_S8" | "CODEC_ID_PCM_U8" | "CODEC_ID_PCM_MULAW" | "CODEC_ID_PCM_ALAW" | "CODEC_ID_PCM_S32LE" | "CODEC_ID_PCM_S32BE" | "CODEC_ID_PCM_U32LE" | "CODEC_ID_PCM_U32BE" | "CODEC_ID_PCM_S24LE" | "CODEC_ID_PCM_S24BE" | "CODEC_ID_PCM_U24LE" | "CODEC_ID_PCM_U24BE" | "CODEC_ID_PCM_S24DAUD" | "CODEC_ID_PCM_ZORK" | "CODEC_ID_PCM_S16LE_PLANAR" | "CODEC_ID_PCM_DVD" | "CODEC_ID_PCM_F32BE" | "CODEC_ID_PCM_F32LE" | "CODEC_ID_PCM_F64BE" | "CODEC_ID_PCM_F64LE" | "CODEC_ID_PCM_BLURAY" | "CODEC_ID_PCM_LXF" | "CODEC_ID_S302M" | "CODEC_ID_PCM_S8_PLANAR" | "CODEC_ID_PCM_S24LE_PLANAR" | "CODEC_ID_PCM_S32LE_PLANAR" | "CODEC_ID_PCM_S16BE_PLANAR" | "CODEC_ID_PCM_S64LE" | "CODEC_ID_PCM_S64BE" | "CODEC_ID_PCM_F16LE" | "CODEC_ID_PCM_F24LE" | "CODEC_ID_ADPCM_IMA_QT" | "CODEC_ID_ADPCM_IMA_WAV" | "CODEC_ID_ADPCM_IMA_DK3" | "CODEC_ID_ADPCM_IMA_DK4" | "CODEC_ID_ADPCM_IMA_WS" | "CODEC_ID_ADPCM_IMA_SMJPEG" | "CODEC_ID_ADPCM_MS" | "CODEC_ID_ADPCM_4XM" | "CODEC_ID_ADPCM_XA" | "CODEC_ID_ADPCM_ADX" | "CODEC_ID_ADPCM_EA" | "CODEC_ID_ADPCM_G726" | "CODEC_ID_ADPCM_CT" | "CODEC_ID_ADPCM_SWF" | "CODEC_ID_ADPCM_YAMAHA" | "CODEC_ID_ADPCM_SBPRO_4" | "CODEC_ID_ADPCM_SBPRO_3" | "CODEC_ID_ADPCM_SBPRO_2" | "CODEC_ID_ADPCM_THP" | "CODEC_ID_ADPCM_IMA_AMV" | "CODEC_ID_ADPCM_EA_R1" | "CODEC_ID_ADPCM_EA_R3" | "CODEC_ID_ADPCM_EA_R2" | "CODEC_ID_ADPCM_IMA_EA_SEAD" | "CODEC_ID_ADPCM_IMA_EA_EACS" | "CODEC_ID_ADPCM_EA_XAS" | "CODEC_ID_ADPCM_EA_MAXIS_XA" | "CODEC_ID_ADPCM_IMA_ISS" | "CODEC_ID_ADPCM_G722" | "CODEC_ID_ADPCM_IMA_APC" | "CODEC_ID_VIMA" | "CODEC_ID_ADPCM_AFC" | "CODEC_ID_ADPCM_IMA_OKI" | "CODEC_ID_ADPCM_DTK" | "CODEC_ID_ADPCM_IMA_RAD" | "CODEC_ID_ADPCM_G726LE" | "CODEC_ID_ADPCM_THP_LE" | "CODEC_ID_ADPCM_PSX" | "CODEC_ID_ADPCM_AICA" | "CODEC_ID_ADPCM_IMA_DAT4" | "CODEC_ID_ADPCM_MTAF" | "CODEC_ID_ADPCM_VIMA" | "CODEC_ID_AMR_NB" | "CODEC_ID_AMR_WB" | "CODEC_ID_RA_144" | "CODEC_ID_RA_288" | "CODEC_ID_ROQ_DPCM" | "CODEC_ID_INTERPLAY_DPCM" | "CODEC_ID_XAN_DPCM" | "CODEC_ID_SOL_DPCM" | "CODEC_ID_GREMLIN_DPCM" | "CODEC_ID_SDX2_DPCM" | "CODEC_ID_MP2" | "CODEC_ID_MP3" | "CODEC_ID_AAC" | "CODEC_ID_MPEG4AAC_DEPRECATED" | "CODEC_ID_AC3" | "CODEC_ID_DTS" | "CODEC_ID_VORBIS" | "CODEC_ID_DVAUDIO" | "CODEC_ID_WMAV1" | "CODEC_ID_WMAV2" | "CODEC_ID_MACE3" | "CODEC_ID_MACE6" | "CODEC_ID_VMDAUDIO" | "CODEC_ID_SONIC" | "CODEC_ID_SONIC_LS" | "CODEC_ID_FLAC" | "CODEC_ID_MP3ADU" | "CODEC_ID_MP3ON4" | "CODEC_ID_SHORTEN" | "CODEC_ID_ALAC" | "CODEC_ID_WESTWOOD_SND1" | "CODEC_ID_GSM" | "CODEC_ID_QDM2" | "CODEC_ID_COOK" | "CODEC_ID_TRUESPEECH" | "CODEC_ID_TTA" | "CODEC_ID_SMACKAUDIO" | "CODEC_ID_QCELP" | "CODEC_ID_WAVPACK" | "CODEC_ID_DSICINAUDIO" | "CODEC_ID_ASAO" | "CODEC_ID_NELLYMOSER" | "CODEC_ID_WMAVOICE" | "CODEC_ID_WMAPRO" | "CODEC_ID_WMALOSSLESS" | "CODEC_ID_IMC" | "CODEC_ID_MUSEPACK7" | "CODEC_ID_MLP" | "CODEC_ID_GSM_MS" | "CODEC_ID_ATRAC3" | "CODEC_ID_VOXWARE" | "CODEC_ID_APE" | "CODEC_ID_MUSEPACK8" | "CODEC_ID_SPEEX" | "CODEC_ID_ATRAC3P" | "CODEC_ID_EAC3" | "CODEC_ID_SIPR" | "CODEC_ID_MP1" | "CODEC_ID_TWINVQ" | "CODEC_ID_TRUEHD" | "CODEC_ID_MP4ALS" | "CODEC_ID_ATRAC1" | "CODEC_ID_BINKAUDIO_RDFT" | "CODEC_ID_BINKAUDIO_DCT" | "CODEC_ID_AAC_LATM" | "CODEC_ID_QDMC" | "CODEC_ID_CELT" | "CODEC_ID_G723_1" | "CODEC_ID_G729" | "CODEC_ID_BMV_AUDIO" | "CODEC_ID_RALF" | "CODEC_ID_IAC" | "CODEC_ID_ILBC" | "CODEC_ID_FFWAVESYNTH" | "CODEC_ID_8SVX_RAW" | "CODEC_ID_PAF_AUDIO" | "CODEC_ID_OPUS" | "CODEC_ID_ATRAC3AL" | "CODEC_ID_ATRAC3PAL" | "CODEC_ID_DOLBY_E" | "CODEC_ID_DSD_LSBF" | "CODEC_ID_DSD_MSBF" | "CODEC_ID_DSD_LSBF_PLANAR" | "CODEC_ID_DSD_MSBF_PLANAR" | "CODEC_ID_DSS_SP" | "CODEC_ID_DST" | "CODEC_ID_EVRC" | "CODEC_ID_INTERPLAY_ACM" | "CODEC_ID_METASOUND" | "CODEC_ID_ON2AVC" | "CODEC_ID_TAK" | "CODEC_ID_XMA1" | "CODEC_ID_XMA2" | "CODEC_ID_COMFORT_NOISE" | "CODEC_ID_APTX" | "CODEC_ID_APTX_HD" | "CODEC_ID_SBC" | "CODEC_ID_ATRAC9" | "CODEC_ID_CODEC2" | "CODEC_ID_OGGTHEORA_DEPRECATED" | "CODEC_ID_DVD_SUBTITLE" | "CODEC_ID_DVB_SUBTITLE" | "CODEC_ID_TEXT" | "CODEC_ID_XSUB" | "CODEC_ID_SSA" | "CODEC_ID_MOV_TEXT" | "CODEC_ID_HDMV_PGS_SUBTITLE" | "CODEC_ID_DVB_TELETEXT" | "CODEC_ID_SRT" | "CODEC_ID_MICRODVD" | "CODEC_ID_EIA_608" | "CODEC_ID_JACOSUB" | "CODEC_ID_SAMI" | "CODEC_ID_REALTEXT" | "CODEC_ID_SUBVIEWER" | "CODEC_ID_SUBRIP" | "CODEC_ID_WEBVTT" | "CODEC_ID_ASS" | "CODEC_ID_MPL2" | "CODEC_ID_PJS" | "CODEC_ID_STL" | "CODEC_ID_SUBVIEWER1" | "CODEC_ID_VPLAYER" | "CODEC_ID_TTML" | "CODEC_ID_TTF" | "CODEC_ID_BINTEXT" | "CODEC_ID_XBIN" | "CODEC_ID_IDF" | "CODEC_ID_OTF" | "CODEC_ID_PROBE" | "CODEC_ID_MPEG2TS" | "CODEC_ID_MPEG4SYSTEMS" | "CODEC_ID_FFMETADATA" | "CODEC_ID_FFMPEG_OUT_OF_SYNC" | "CODEC_ID_WRAPPED_AVFRAME" | "CODEC_ID_CAMM";
  /**
   * RFC6381 Codec string.
   */
  codecString?: string;
  colorInfo?: VideoFileColorInfo;
  contentLightLevel?: VideoFileContentLightLevel;
  /**
   * The bytes offset of the end of the first decodable packet.
   */
  decodeOffset?: bigint;
  displayHeight?: number;
  /**
   * final display video width and height if explicitly set in the video
   * otherwise this can be calculated from source width/height and
   * video_pixel_aspect_ratio
   */
  displayWidth?: number;
  /**
   * Dolby Vision configuration if stream is compatible.
   */
  doviConfiguration?: VideoDoViDecoderConfiguration;
  endTimestamp?: bigint;
  /**
   * Should the video be mirrored horizontally / vertically? When rotation and
   * flip both are present for a video, it is assumed that the flip is applied
   * first, and then the rotation.
   */
  flip?:  | "FLIP_NONE" | "FLIP_HORIZONTAL" | "FLIP_VERTICAL";
  /**
   * video frame per second, obtained by parsing video header information. It
   * could be inaccurate for some types of codecs, notably, WMV, ASF, and FLV.
   * It will be inaccurate for videos that does not have constant frame rate
   * since it is the smallest framerate that can accurately represent all
   * timestamps (see ffmpeg doc for AVStream.r_frame_rate). Also frame rate can
   * be parsed from headers and can be wrong if it is not available there since
   * ffmpeg uses a heuristic for determining it.
   */
  fps?: number;
  /**
   * video frame size
   */
  frameSize?: bigint;
  /**
   * Statistics about gop sizes of the video.
   */
  gopSize?: VideoVideoStreamInfoVideoStreamStatistics;
  /**
   * video has b frames
   */
  hasBFrames?: boolean;
  /**
   * Stats on HDR10+ over video frames.
   */
  hdr10PlusStats?: VideoFileHDR10PlusStats;
  height?: number;
  /**
   * Information on interlaced video.
   */
  interlace?:  | "INTERLACE_NONE" | "INTERLACE_PIC_AFF" | "INTERLACE_MB_AFF";
  /**
   * Check if a video size insane or not. It is set if the input file is an MOV
   * file.
   */
  isInsaneSize?: boolean;
  /**
   * User data registered Itu-T T.35 SEI message
   */
  ituTT35?: VideoUserDataRegisteredItuTT35[];
  /**
   * video length in seconds Note that when the VSI is from users videos, it is
   * not guaranteed to be the same as transcode lengths and it could be 0 when
   * the full VSI cannot compute the length from the source header and
   * timestamps (for example when header and timestamps are too broken).
   */
  length?: number;
  level?: number;
  masteringDisplayMetadata?: VideoFileMasteringDisplayMetadata;
  /**
   * Maximum instantaneous frame rate seen from analyzing the entire stream.
   */
  maxFps?: number;
  /**
   * Metadata for video elementary stream;
   */
  metadata?: VideoClipInfo[];
  /**
   * Minimum instantaneous frame rate seen from analyzing the entire stream.
   */
  minFps?: number;
  /**
   * Number of video frames.
   */
  numberOfFrames?: bigint;
  /**
   * Invisible frame count Keep a count of frames that are not displayed should
   * the full frame count be needed for the video stream. The only codec
   * currently reporting this value is VP8 with alternate reference frames
   * enabled
   */
  numberOfInvisibleFrames?: number;
  /**
   * video pixel aspect ratio
   */
  pixelAspectRatio?: number;
  /**
   * Pixel format for the video stream.
   */
  pixFmt?:  | "PIX_FMT_NONE" | "PIX_FMT_YUV420P" | "PIX_FMT_YUYV422" | "PIX_FMT_RGB24" | "PIX_FMT_BGR24" | "PIX_FMT_YUV422P" | "PIX_FMT_YUV444P" | "PIX_FMT_RGB32" | "PIX_FMT_YUV410P" | "PIX_FMT_YUV411P" | "PIX_FMT_RGB565" | "PIX_FMT_RGB555" | "PIX_FMT_GRAY8" | "PIX_FMT_MONOWHITE" | "PIX_FMT_MONOBLACK" | "PIX_FMT_PAL8" | "PIX_FMT_YUVJ420P" | "PIX_FMT_YUVJ422P" | "PIX_FMT_YUVJ444P" | "PIX_FMT_XVMC_MPEG2_MC" | "PIX_FMT_XVMC_MPEG2_IDCT" | "PIX_FMT_UYVY422" | "PIX_FMT_UYYVYY411" | "PIX_FMT_BGR32" | "PIX_FMT_BGR565" | "PIX_FMT_BGR555" | "PIX_FMT_BGR8" | "PIX_FMT_BGR4" | "PIX_FMT_BGR4_BYTE" | "PIX_FMT_RGB8" | "PIX_FMT_RGB4" | "PIX_FMT_RGB4_BYTE" | "PIX_FMT_NV12" | "PIX_FMT_NV21" | "PIX_FMT_RGB32_1" | "PIX_FMT_BGR32_1" | "PIX_FMT_GRAY16BE" | "PIX_FMT_GRAY16LE" | "PIX_FMT_YUV440P" | "PIX_FMT_YUVJ440P" | "PIX_FMT_YUVA420P" | "PIX_FMT_VDPAU_H264" | "PIX_FMT_VDPAU_MPEG1" | "PIX_FMT_VDPAU_MPEG2" | "PIX_FMT_VDPAU_WMV3" | "PIX_FMT_VDPAU_VC1" | "PIX_FMT_RGB48BE" | "PIX_FMT_RGB48LE" | "PIX_FMT_RGB565BE" | "PIX_FMT_RGB555BE" | "PIX_FMT_BGR565BE" | "PIX_FMT_BGR555BE" | "PIX_FMT_VAAPI_MOCO" | "PIX_FMT_VAAPI_IDCT" | "PIX_FMT_VAAPI_VLD" | "PIX_FMT_YUV420P16LE" | "PIX_FMT_YUV420P16BE" | "PIX_FMT_YUV422P16LE" | "PIX_FMT_YUV422P16BE" | "PIX_FMT_YUV444P16LE" | "PIX_FMT_YUV444P16BE" | "PIX_FMT_VDPAU_MPEG4" | "PIX_FMT_DXVA2_VLD" | "PIX_FMT_RGB444LE" | "PIX_FMT_RGB444BE" | "PIX_FMT_BGR444LE" | "PIX_FMT_BGR444BE" | "PIX_FMT_GRAY8A" | "PIX_FMT_BGR48BE" | "PIX_FMT_BGR48LE" | "PIX_FMT_YUV420P9BE" | "PIX_FMT_YUV420P9LE" | "PIX_FMT_YUV420P10BE" | "PIX_FMT_YUV420P10LE" | "PIX_FMT_YUV422P10BE" | "PIX_FMT_YUV422P10LE" | "PIX_FMT_YUV444P9BE" | "PIX_FMT_YUV444P9LE" | "PIX_FMT_YUV444P10BE" | "PIX_FMT_YUV444P10LE" | "PIX_FMT_YUV422P9BE" | "PIX_FMT_YUV422P9LE" | "PIX_FMT_VDA_VLD" | "PIX_FMT_RGBA64BE" | "PIX_FMT_RGBA64LE" | "PIX_FMT_BGRA64BE" | "PIX_FMT_BGRA64LE" | "PIX_FMT_GBRP" | "PIX_FMT_GBRP9BE" | "PIX_FMT_GBRP9LE" | "PIX_FMT_GBRP10BE" | "PIX_FMT_GBRP10LE" | "PIX_FMT_GBRP16BE" | "PIX_FMT_GBRP16LE" | "PIX_FMT_0RGB" | "PIX_FMT_RGB0" | "PIX_FMT_0BGR" | "PIX_FMT_BGR0" | "PIX_FMT_YUVA444P" | "PIX_FMT_YUVA422P" | "PIX_FMT_YUV420P12BE" | "PIX_FMT_YUV420P12LE" | "PIX_FMT_YUV420P14BE" | "PIX_FMT_YUV420P14LE" | "PIX_FMT_YUV422P12BE" | "PIX_FMT_YUV422P12LE" | "PIX_FMT_YUV422P14BE" | "PIX_FMT_YUV422P14LE" | "PIX_FMT_YUV444P12BE" | "PIX_FMT_YUV444P12LE" | "PIX_FMT_YUV444P14BE" | "PIX_FMT_YUV444P14LE" | "PIX_FMT_GBRP12BE" | "PIX_FMT_GBRP12LE" | "PIX_FMT_GBRP14BE" | "PIX_FMT_GBRP14LE" | "PIX_FMT_ARGB" | "PIX_FMT_RGBA" | "PIX_FMT_ABGR" | "PIX_FMT_BGRA" | "PIX_FMT_RGB565LE" | "PIX_FMT_RGB555LE" | "PIX_FMT_BGR565LE" | "PIX_FMT_BGR555LE" | "PIX_FMT_VAAPI" | "PIX_FMT_YA8" | "PIX_FMT_Y400A" | "PIX_FMT_YUVA420P9BE" | "PIX_FMT_YUVA420P9LE" | "PIX_FMT_YUVA422P9BE" | "PIX_FMT_YUVA422P9LE" | "PIX_FMT_YUVA444P9BE" | "PIX_FMT_YUVA444P9LE" | "PIX_FMT_YUVA420P10BE" | "PIX_FMT_YUVA420P10LE" | "PIX_FMT_YUVA422P10BE" | "PIX_FMT_YUVA422P10LE" | "PIX_FMT_YUVA444P10BE" | "PIX_FMT_YUVA444P10LE" | "PIX_FMT_YUVA420P16BE" | "PIX_FMT_YUVA420P16LE" | "PIX_FMT_YUVA422P16BE" | "PIX_FMT_YUVA422P16LE" | "PIX_FMT_YUVA444P16BE" | "PIX_FMT_YUVA444P16LE" | "PIX_FMT_VDPAU" | "PIX_FMT_XYZ12LE" | "PIX_FMT_XYZ12BE" | "PIX_FMT_NV16" | "PIX_FMT_NV20LE" | "PIX_FMT_NV20BE" | "PIX_FMT_YVYU422" | "PIX_FMT_VDA" | "PIX_FMT_YA16BE" | "PIX_FMT_YA16LE" | "PIX_FMT_GBRAP" | "PIX_FMT_GBRAP16BE" | "PIX_FMT_GBRAP16LE" | "PIX_FMT_QSV" | "PIX_FMT_MMAL" | "PIX_FMT_D3D11VA_VLD" | "PIX_FMT_CUDA" | "PIX_FMT_YUVJ411P" | "PIX_FMT_BAYER_BGGR8" | "PIX_FMT_BAYER_RGGB8" | "PIX_FMT_BAYER_GBRG8" | "PIX_FMT_BAYER_GRBG8" | "PIX_FMT_BAYER_BGGR16LE" | "PIX_FMT_BAYER_BGGR16BE" | "PIX_FMT_BAYER_RGGB16LE" | "PIX_FMT_BAYER_RGGB16BE" | "PIX_FMT_BAYER_GBRG16LE" | "PIX_FMT_BAYER_GBRG16BE" | "PIX_FMT_BAYER_GRBG16LE" | "PIX_FMT_BAYER_GRBG16BE" | "PIX_FMT_XVMC" | "PIX_FMT_YUV440P10LE" | "PIX_FMT_YUV440P10BE" | "PIX_FMT_YUV440P12LE" | "PIX_FMT_YUV440P12BE" | "PIX_FMT_AYUV64LE" | "PIX_FMT_AYUV64BE" | "PIX_FMT_VIDEOTOOLBOX" | "PIX_FMT_P010LE" | "PIX_FMT_P010BE" | "PIX_FMT_GBRAP12BE" | "PIX_FMT_GBRAP12LE" | "PIX_FMT_GBRAP10BE" | "PIX_FMT_GBRAP10LE" | "PIX_FMT_MEDIACODEC" | "PIX_FMT_GRAY12BE" | "PIX_FMT_GRAY12LE" | "PIX_FMT_GRAY10BE" | "PIX_FMT_GRAY10LE" | "PIX_FMT_P016LE" | "PIX_FMT_P016BE" | "PIX_FMT_D3D11" | "PIX_FMT_GRAY9BE" | "PIX_FMT_GRAY9LE" | "PIX_FMT_GBRPF32BE" | "PIX_FMT_GBRPF32LE" | "PIX_FMT_GBRAPF32BE" | "PIX_FMT_GBRAPF32LE" | "PIX_FMT_DRM_PRIME" | "PIX_FMT_GACCEL" | "PIX_FMT_OPENCL" | "PIX_FMT_GRAY14BE" | "PIX_FMT_GRAY14LE" | "PIX_FMT_GRAYF32BE" | "PIX_FMT_GRAYF32LE" | "PIX_FMT_VULKAN" | "PIX_FMT_ID_FFMPEG_OUT_OF_SYNC";
  profile?:  | "PROFILE_UNKNOWN" | "PROFILE_AAC_MAIN" | "PROFILE_AAC_LOW" | "PROFILE_AAC_SSR" | "PROFILE_AAC_LTP" | "PROFILE_AAC_HE" | "PROFILE_AAC_HE_V2" | "PROFILE_AAC_LD" | "PROFILE_AAC_ELD" | "PROFILE_AVC_CONSTRAINED" | "PROFILE_AVC_INTRA" | "PROFILE_AVC_BASELINE" | "PROFILE_AVC_CONSTRAINED_BASELINE" | "PROFILE_AVC_MAIN" | "PROFILE_AVC_EXTENDED" | "PROFILE_AVC_HIGH" | "PROFILE_AVC_HIGH10" | "PROFILE_AVC_HIGH10_INTRA" | "PROFILE_AVC_HIGH422" | "PROFILE_AVC_HIGH422_INTRA" | "PROFILE_AVC_HIGH444" | "PROFILE_HIGH444_PREDICTIVE" | "PROFILE_AVC_HIGH444_INTRA" | "PROFILE_AVC_CAVLC444" | "PROFILE_VP9_0" | "PROFILE_VP9_1" | "PROFILE_VP9_2" | "PROFILE_VP9_3" | "PROFILE_HEVC_MAIN" | "PROFILE_HEVC_MAIN_10" | "PROFILE_HEVC_MAIN_STILL_PICTURE" | "PROFILE_HEVC_REXT" | "PROFILE_DOVI_5";
  /**
   * The nominal frame rate ('fps' field) represented as a fraction.
   */
  rationalFps?: VideoRational32;
  /**
   * Is the video rotated ?
   */
  rotation?:  | "ROTATION_NONE" | "ROTATION_OTHER" | "ROTATION_CW_90" | "ROTATION_CCW_90" | "ROTATION_180";
  /**
   * video SEI payload types and total payload size of a type this is only for
   * H.264 and H.265
   */
  seiMessage?: VideoSEIMessage[];
  /**
   * Optional spherical video information.
   */
  spherical?: VideoFileSphericalMetadata;
  /**
   * Start/end timestamps of audio/video in ms.
   */
  startTimestamp?: bigint;
  streamCodecTag?: bigint;
  /**
   * Index of the stream in the file. it is 0 based.
   */
  streamIndex?: bigint;
  /**
   * User data unregistered SEI message
   */
  userDataUnregistered?: VideoUserDataUnregistered[];
  /**
   * source video width and height
   */
  width?: number;
}

function serializeVideoVideoStreamInfoVideoStream(data: any): VideoVideoStreamInfoVideoStream {
  return {
    ...data,
    bitrate: data["bitrate"] !== undefined ? String(data["bitrate"]) : undefined,
    clockDiscontinuityUs: data["clockDiscontinuityUs"] !== undefined ? String(data["clockDiscontinuityUs"]) : undefined,
    closedGopSize: data["closedGopSize"] !== undefined ? serializeVideoVideoStreamInfoVideoStreamStatistics(data["closedGopSize"]) : undefined,
    decodeOffset: data["decodeOffset"] !== undefined ? String(data["decodeOffset"]) : undefined,
    endTimestamp: data["endTimestamp"] !== undefined ? String(data["endTimestamp"]) : undefined,
    frameSize: data["frameSize"] !== undefined ? String(data["frameSize"]) : undefined,
    gopSize: data["gopSize"] !== undefined ? serializeVideoVideoStreamInfoVideoStreamStatistics(data["gopSize"]) : undefined,
    metadata: data["metadata"] !== undefined ? data["metadata"].map((item: any) => (serializeVideoClipInfo(item))) : undefined,
    numberOfFrames: data["numberOfFrames"] !== undefined ? String(data["numberOfFrames"]) : undefined,
    seiMessage: data["seiMessage"] !== undefined ? data["seiMessage"].map((item: any) => (serializeVideoSEIMessage(item))) : undefined,
    spherical: data["spherical"] !== undefined ? serializeVideoFileSphericalMetadata(data["spherical"]) : undefined,
    startTimestamp: data["startTimestamp"] !== undefined ? String(data["startTimestamp"]) : undefined,
    streamCodecTag: data["streamCodecTag"] !== undefined ? String(data["streamCodecTag"]) : undefined,
    streamIndex: data["streamIndex"] !== undefined ? String(data["streamIndex"]) : undefined,
    userDataUnregistered: data["userDataUnregistered"] !== undefined ? data["userDataUnregistered"].map((item: any) => (serializeVideoUserDataUnregistered(item))) : undefined,
  };
}

function deserializeVideoVideoStreamInfoVideoStream(data: any): VideoVideoStreamInfoVideoStream {
  return {
    ...data,
    bitrate: data["bitrate"] !== undefined ? BigInt(data["bitrate"]) : undefined,
    clockDiscontinuityUs: data["clockDiscontinuityUs"] !== undefined ? BigInt(data["clockDiscontinuityUs"]) : undefined,
    closedGopSize: data["closedGopSize"] !== undefined ? deserializeVideoVideoStreamInfoVideoStreamStatistics(data["closedGopSize"]) : undefined,
    decodeOffset: data["decodeOffset"] !== undefined ? BigInt(data["decodeOffset"]) : undefined,
    endTimestamp: data["endTimestamp"] !== undefined ? BigInt(data["endTimestamp"]) : undefined,
    frameSize: data["frameSize"] !== undefined ? BigInt(data["frameSize"]) : undefined,
    gopSize: data["gopSize"] !== undefined ? deserializeVideoVideoStreamInfoVideoStreamStatistics(data["gopSize"]) : undefined,
    metadata: data["metadata"] !== undefined ? data["metadata"].map((item: any) => (deserializeVideoClipInfo(item))) : undefined,
    numberOfFrames: data["numberOfFrames"] !== undefined ? BigInt(data["numberOfFrames"]) : undefined,
    seiMessage: data["seiMessage"] !== undefined ? data["seiMessage"].map((item: any) => (deserializeVideoSEIMessage(item))) : undefined,
    spherical: data["spherical"] !== undefined ? deserializeVideoFileSphericalMetadata(data["spherical"]) : undefined,
    startTimestamp: data["startTimestamp"] !== undefined ? BigInt(data["startTimestamp"]) : undefined,
    streamCodecTag: data["streamCodecTag"] !== undefined ? BigInt(data["streamCodecTag"]) : undefined,
    streamIndex: data["streamIndex"] !== undefined ? BigInt(data["streamIndex"]) : undefined,
    userDataUnregistered: data["userDataUnregistered"] !== undefined ? data["userDataUnregistered"].map((item: any) => (deserializeVideoUserDataUnregistered(item))) : undefined,
  };
}

export interface VideoVideoStreamInfoVideoStreamCleanAperture {
  height?: number;
  horizontalOffset?: number;
  verticalOffset?: number;
  width?: number;
}

export interface VideoVideoStreamInfoVideoStreamStatistics {
  max?: bigint;
  mean?: number;
  min?: bigint;
}

function serializeVideoVideoStreamInfoVideoStreamStatistics(data: any): VideoVideoStreamInfoVideoStreamStatistics {
  return {
    ...data,
    max: data["max"] !== undefined ? String(data["max"]) : undefined,
    min: data["min"] !== undefined ? String(data["min"]) : undefined,
  };
}

function deserializeVideoVideoStreamInfoVideoStreamStatistics(data: any): VideoVideoStreamInfoVideoStreamStatistics {
  return {
    ...data,
    max: data["max"] !== undefined ? BigInt(data["max"]) : undefined,
    min: data["min"] !== undefined ? BigInt(data["min"]) : undefined,
  };
}

export interface VideoYoutubeCommentsClassificationProtoSmartSuggestion {
  /**
   * Diversification threshold used in prediction. Additional responses which
   * are closer than the threshold to the already selected responses will be
   * skipped.
   */
  diversificationThreshold?: number;
  /**
   * Bias weight used in prediction.
   */
  likelihoodBiasWeight?: number;
  /**
   * Content of the reply snippet (could include emoji as well as text).
   */
  replyContent?: string;
  /**
   * Model score for the predicted reply snippet.
   */
  score?: number;
}

/**
 * Smart reply suggestions for comment.
 */
export interface VideoYoutubeCommentsClassificationProtoYouTubeCommentSmartReply {
  /**
   * The order of the reply snippets in the list determines how they should be
   * displayed in the UI and the client is not supposed to re-order the list
   * using the scores.
   */
  smartSuggestions?: VideoYoutubeCommentsClassificationProtoSmartSuggestion[];
  /**
   * Identifier (language_code, channel_id, etc) for the suggestion list from
   * which the top k suggestions are selected.
   */
  suggestionListIdentifier?: string;
}

/**
 * Used for stanza KV pair. Next tag: 7.
 */
export interface VideoYoutubeCommentsRankingCTRMetrics {
  downvotes?: bigint;
  impressions?: bigint;
  measureWindow?:  | "UNKNOWN" | "THREE_DAYS" | "SEVEN_DAYS" | "FULL_HISTORY";
  teaserClicks?: bigint;
  teaserImpressions?: bigint;
  upvotes?: bigint;
}

function serializeVideoYoutubeCommentsRankingCTRMetrics(data: any): VideoYoutubeCommentsRankingCTRMetrics {
  return {
    ...data,
    downvotes: data["downvotes"] !== undefined ? String(data["downvotes"]) : undefined,
    impressions: data["impressions"] !== undefined ? String(data["impressions"]) : undefined,
    teaserClicks: data["teaserClicks"] !== undefined ? String(data["teaserClicks"]) : undefined,
    teaserImpressions: data["teaserImpressions"] !== undefined ? String(data["teaserImpressions"]) : undefined,
    upvotes: data["upvotes"] !== undefined ? String(data["upvotes"]) : undefined,
  };
}

function deserializeVideoYoutubeCommentsRankingCTRMetrics(data: any): VideoYoutubeCommentsRankingCTRMetrics {
  return {
    ...data,
    downvotes: data["downvotes"] !== undefined ? BigInt(data["downvotes"]) : undefined,
    impressions: data["impressions"] !== undefined ? BigInt(data["impressions"]) : undefined,
    teaserClicks: data["teaserClicks"] !== undefined ? BigInt(data["teaserClicks"]) : undefined,
    teaserImpressions: data["teaserImpressions"] !== undefined ? BigInt(data["teaserImpressions"]) : undefined,
    upvotes: data["upvotes"] !== undefined ? BigInt(data["upvotes"]) : undefined,
  };
}

export interface WatchpageLanguageWatchPageLanguageResult {
  /**
   * The language predicted by the WatchPage Language model.
   */
  watchpageLanguage?:  | "ENGLISH" | "DANISH" | "DUTCH" | "FINNISH" | "FRENCH" | "GERMAN" | "HEBREW" | "ITALIAN" | "JAPANESE" | "KOREAN" | "NORWEGIAN" | "POLISH" | "PORTUGUESE" | "RUSSIAN" | "SPANISH" | "SWEDISH" | "CHINESE" | "CZECH" | "GREEK" | "ICELANDIC" | "LATVIAN" | "LITHUANIAN" | "ROMANIAN" | "HUNGARIAN" | "ESTONIAN" | "TG_UNKNOWN_LANGUAGE" | "UNKNOWN_LANGUAGE" | "BULGARIAN" | "CROATIAN" | "SERBIAN" | "IRISH" | "GALICIAN" | "TAGALOG" | "TURKISH" | "UKRAINIAN" | "HINDI" | "MACEDONIAN" | "BENGALI" | "INDONESIAN" | "LATIN" | "MALAY" | "MALAYALAM" | "WELSH" | "NEPALI" | "TELUGU" | "ALBANIAN" | "TAMIL" | "BELARUSIAN" | "JAVANESE" | "OCCITAN" | "URDU" | "BIHARI" | "GUJARATI" | "THAI" | "ARABIC" | "CATALAN" | "ESPERANTO" | "BASQUE" | "INTERLINGUA" | "KANNADA" | "PUNJABI" | "SCOTS_GAELIC" | "SWAHILI" | "SLOVENIAN" | "MARATHI" | "MALTESE" | "VIETNAMESE" | "FRISIAN" | "SLOVAK" | "CHINESE_T" | "FAROESE" | "SUNDANESE" | "UZBEK" | "AMHARIC" | "AZERBAIJANI" | "GEORGIAN" | "TIGRINYA" | "PERSIAN" | "BOSNIAN" | "SINHALESE" | "NORWEGIAN_N" | "PORTUGUESE_P" | "PORTUGUESE_B" | "XHOSA" | "ZULU" | "GUARANI" | "SESOTHO" | "TURKMEN" | "KYRGYZ" | "BRETON" | "TWI" | "YIDDISH" | "SERBO_CROATIAN" | "SOMALI" | "UIGHUR" | "KURDISH" | "MONGOLIAN" | "ARMENIAN" | "LAOTHIAN" | "SINDHI" | "RHAETO_ROMANCE" | "AFRIKAANS" | "LUXEMBOURGISH" | "BURMESE" | "KHMER" | "TIBETAN" | "DHIVEHI" | "CHEROKEE" | "SYRIAC" | "LIMBU" | "ORIYA" | "ASSAMESE" | "CORSICAN" | "INTERLINGUE" | "KAZAKH" | "LINGALA" | "MOLDAVIAN" | "PASHTO" | "QUECHUA" | "SHONA" | "TAJIK" | "TATAR" | "TONGA" | "YORUBA" | "CREOLES_AND_PIDGINS_ENGLISH_BASED" | "CREOLES_AND_PIDGINS_FRENCH_BASED" | "CREOLES_AND_PIDGINS_PORTUGUESE_BASED" | "CREOLES_AND_PIDGINS_OTHER" | "MAORI" | "WOLOF" | "ABKHAZIAN" | "AFAR" | "AYMARA" | "BASHKIR" | "BISLAMA" | "DZONGKHA" | "FIJIAN" | "GREENLANDIC" | "HAUSA" | "HAITIAN_CREOLE" | "INUPIAK" | "INUKTITUT" | "KASHMIRI" | "KINYARWANDA" | "MALAGASY" | "NAURU" | "OROMO" | "RUNDI" | "SAMOAN" | "SANGO" | "SANSKRIT" | "SISWANT" | "TSONGA" | "TSWANA" | "VOLAPUK" | "ZHUANG" | "KHASI" | "SCOTS" | "GANDA" | "MANX" | "MONTENEGRIN" | "AKAN" | "IGBO" | "MAURITIAN_CREOLE" | "HAWAIIAN" | "CEBUANO" | "EWE" | "GA" | "HMONG" | "KRIO" | "LOZI" | "LUBA_LULUA" | "LUO_KENYA_AND_TANZANIA" | "NEWARI" | "NYANJA" | "OSSETIAN" | "PAMPANGA" | "PEDI" | "RAJASTHANI" | "SESELWA_CREOLE_FRENCH" | "TUMBUKA" | "VENDA" | "WARAY_PHILIPPINES" | "NUM_LANGUAGES";
}

/**
 * Page boosting using Live Results data. Attaching this proto to a document
 * indicates that a Live Result feed exists for that document, and that this
 * feed has sufficient reliability to warrant potential boosting of the document
 * rank. Next ID: 3
 */
export interface WeboftrustLiveResultDocBoostData {
  /**
   * Identifies the degree to which the existence of this LiveResult should
   * boost a query's score (when the query is performed within the hot_times
   * range). This field is always in the range [0,1]. A missing field, a value
   * of 0, or a value outside the legal range indicates that no boosting is
   * performed. A value of 1 indicates that the maximum level of boosting will
   * be applied. This field will be updated from time to time based on CTR and
   * other signals.
   */
  boostLevel?: number;
  /**
   * Specifies the time range within which this LiveResult is relevant. Used
   * for deciding whether the rank of the corresponding page should be boosted.
   * For example, this range can be set to encompass a few days before and after
   * a sports game to which the page refers. If this field is missing, no
   * boosting is performed. Specifying that a page should always be boosted is
   * not recommended, but can be accomplished by setting
   * hot_times.start_unix_time=0 and hot_time.end_unix_time=0x7fffffff. Note
   * that multiple time ranges can be implemented by adding several
   * LiveResultDocBoostData messages to the LiveResultsDocAttachments proto. If
   * overlapping time ranges are used, the proto containing the highest boost
   * level will be used.
   */
  hotTimes?: WeboftrustTimeRange;
}

function serializeWeboftrustLiveResultDocBoostData(data: any): WeboftrustLiveResultDocBoostData {
  return {
    ...data,
    hotTimes: data["hotTimes"] !== undefined ? serializeWeboftrustTimeRange(data["hotTimes"]) : undefined,
  };
}

function deserializeWeboftrustLiveResultDocBoostData(data: any): WeboftrustLiveResultDocBoostData {
  return {
    ...data,
    hotTimes: data["hotTimes"] !== undefined ? deserializeWeboftrustTimeRange(data["hotTimes"]) : undefined,
  };
}

/**
 * Per-provider attachment of a LiveResult. Used to identify pages for which
 * result-based triggering of Live Results should appear. Theoretically there
 * can be more than one attachment per web document, so we keep them as a
 * repeated field of the LiveResultsDocAttachment. Next ID: 4
 */
export interface WeboftrustLiveResultProviderDocAttachment {
  providerId?: bigint;
  /**
   * Tag that specifies the use-case within provider's data. It appears as a
   * string in Alexandria signal and in the DocJoins. During the indexing stage
   * this field will be converted to a 64-bit fingerprint to save space. See the
   * "tag_fp" field, below.
   */
  tag?: string;
  /**
   * A fingerprint of the "tag" field, automatically calculated during the
   * indexing stage. Will be used as a key for fetching the data.
   */
  tagFp?: bigint;
}

function serializeWeboftrustLiveResultProviderDocAttachment(data: any): WeboftrustLiveResultProviderDocAttachment {
  return {
    ...data,
    providerId: data["providerId"] !== undefined ? String(data["providerId"]) : undefined,
    tagFp: data["tagFp"] !== undefined ? String(data["tagFp"]) : undefined,
  };
}

function deserializeWeboftrustLiveResultProviderDocAttachment(data: any): WeboftrustLiveResultProviderDocAttachment {
  return {
    ...data,
    providerId: data["providerId"] !== undefined ? BigInt(data["providerId"]) : undefined,
    tagFp: data["tagFp"] !== undefined ? BigInt(data["tagFp"]) : undefined,
  };
}

/**
 * Message to which we attach to web documents in order to decide which
 * LiveResult to trigger. Next ID: 3
 */
export interface WeboftrustLiveResultsDocAttachments {
  /**
   * Information about potential rank boosting for the document by virtue of
   * its Live Result feed.
   */
  docBoost?: WeboftrustLiveResultDocBoostData[];
  /**
   * Identifies a Live Result which is to be attached to the document.
   */
  providerAttachment?: WeboftrustLiveResultProviderDocAttachment[];
}

function serializeWeboftrustLiveResultsDocAttachments(data: any): WeboftrustLiveResultsDocAttachments {
  return {
    ...data,
    docBoost: data["docBoost"] !== undefined ? data["docBoost"].map((item: any) => (serializeWeboftrustLiveResultDocBoostData(item))) : undefined,
    providerAttachment: data["providerAttachment"] !== undefined ? data["providerAttachment"].map((item: any) => (serializeWeboftrustLiveResultProviderDocAttachment(item))) : undefined,
  };
}

function deserializeWeboftrustLiveResultsDocAttachments(data: any): WeboftrustLiveResultsDocAttachments {
  return {
    ...data,
    docBoost: data["docBoost"] !== undefined ? data["docBoost"].map((item: any) => (deserializeWeboftrustLiveResultDocBoostData(item))) : undefined,
    providerAttachment: data["providerAttachment"] !== undefined ? data["providerAttachment"].map((item: any) => (deserializeWeboftrustLiveResultProviderDocAttachment(item))) : undefined,
  };
}

/**
 * Time range (start time and end time). Used to indicate the times in which a
 * LiveResult is considered "hot" and thus a potential for boosting. Specified
 * as Unix time (seconds since midnight, January 1, 1970). Time zone is same as
 * that for query_start_time (i.e., GMT). Next ID: 3
 */
export interface WeboftrustTimeRange {
  endUnixTime?: bigint;
  /**
   * Start and end times should always appear. Marked as optional to avoid
   * breaking code.
   */
  startUnixTime?: bigint;
}

function serializeWeboftrustTimeRange(data: any): WeboftrustTimeRange {
  return {
    ...data,
    endUnixTime: data["endUnixTime"] !== undefined ? String(data["endUnixTime"]) : undefined,
    startUnixTime: data["startUnixTime"] !== undefined ? String(data["startUnixTime"]) : undefined,
  };
}

function deserializeWeboftrustTimeRange(data: any): WeboftrustTimeRange {
  return {
    ...data,
    endUnixTime: data["endUnixTime"] !== undefined ? BigInt(data["endUnixTime"]) : undefined,
    startUnixTime: data["startUnixTime"] !== undefined ? BigInt(data["startUnixTime"]) : undefined,
  };
}

/**
 * IMPORTANT: It is unsafe to accept this message from an untrusted source,
 * since it's trivial for an attacker to forge serialized messages that don't
 * fulfill the type's safety contract -- for example, it could contain attacker
 * controlled script. A system which receives a SafeHtmlProto implicitly trusts
 * the producer of the SafeHtmlProto. So, it's generally safe to return this
 * message in RPC responses, but generally unsafe to accept it in RPC requests.
 */
export interface WebutilHtmlTypesSafeHtmlProto {
  /**
   * IMPORTANT: Never set or read this field, even from tests, it is private.
   * See documentation at the top of .proto file for programming language
   * packages with which to create or read this message.
   */
  privateDoNotAccessOrElseSafeHtmlWrappedValue?: string;
}

export interface WirelessTranscoderFetchFetchMetadata {
  name?: string;
  value?: Uint8Array;
}

function serializeWirelessTranscoderFetchFetchMetadata(data: any): WirelessTranscoderFetchFetchMetadata {
  return {
    ...data,
    value: data["value"] !== undefined ? encodeBase64(data["value"]) : undefined,
  };
}

function deserializeWirelessTranscoderFetchFetchMetadata(data: any): WirelessTranscoderFetchFetchMetadata {
  return {
    ...data,
    value: data["value"] !== undefined ? decodeBase64(data["value"] as string) : undefined,
  };
}

/**
 * To tag which fetcher satisfied this fetch request with optional detail.
 */
export interface WirelessTranscoderFetchFetchSourceInfo {
  /**
   * Provides fetcher-specific detail about how source satisfied the request.
   */
  detail?: string;
  /**
   * The fetcher that ultimately satisfied this fetch request.
   */
  source?: string;
}

/**
 * Some per-doc info is returned for all www DocInfo requests. Next id: 94
 */
export interface WWWDocInfo {
  /**
   * Additional stats output by SafeSearch. See
   * classifier/porn/public/porn-attachments.h.
   */
  additionalSafesearchStats?: number[];
  /**
   * Sometimes called secureid
   */
  authMethod?: number;
  /**
   * Bad meta flag
   */
  badMetadescription?: boolean;
  /**
   * Size of document
   */
  bodySize?: number;
  bodyTitleLanguages?: string[];
  boilerplateMetadescription?: boolean;
  /**
   * Detected color in the image in RGB565 format in the lower 16 bits.
   */
  colorDetectionResult?: number;
  /**
   * If not present, then the type
   */
  contentType?: bigint;
  /**
   * Url of coupled doc (e.g. image)
   */
  coupledUrl?: string;
  coupledUrlEncoding?: number;
  /**
   * Last time this doc crawled
   */
  crawlTime?: bigint;
  /**
   * Thumbnail cropping information.
   */
  cropData?: number;
  dataVersion?: string;
  /**
   * Fields generated by the docserver, but whose meaning is unclear. Sometimes
   * last crawl time
   */
  docVersionId?: bigint;
  encoding?: bigint;
  /**
   * fails_safe_search is never filled in production.
   */
  failsSafeSearch?: bigint;
  /**
   * If converted to TEXT or HTML
   */
  fileTypeId?: bigint;
  /**
   * Indicate if the meta description in a different language than its page.
   */
  foreignMetadescription?: boolean;
  fuzzyMetadescription?: boolean;
  /**
   * Addition to support google label per-search-result annotation.
   */
  googleLabelData?: Uint8Array;
  /**
   * If true, the original document has a bad SSL certificate.
   */
  hasBadSslCertificate?: boolean;
  /**
   * image height
   */
  imageHeight?: number;
  /**
   * Image license info such as license url and how to acquire the license.
   */
  imageLicenseInfo?: ImageSearchImageLicenseInfo;
  imagePublisher?: string;
  /**
   * size in bytes;
   */
  imageSize?: number;
  /**
   * image width
   */
  imageWidth?: number;
  /**
   * The timestamp (the time since the Epoch, in microseconds) when the docjoin
   * is exported from indexing. This is mainly exported and used by Youtube
   * Search. See MustangBasicInfo.indexing_ts for more details.
   */
  indexingTs?: bigint;
  /**
   * If ipaddr is set, ip should be ignored (it should not be set). Ipaddr
   * should be either 4- or 16-byte string for IPv4 or IPv6 addresses. If ipaddr
   * is not set, ip is set to the IPv4 address for the host.
   */
  ip?: number;
  ipaddr?: Uint8Array;
  /**
   * Is this image animated?
   */
  isAnimated?: boolean;
  /**
   * Hosted Images related fields.
   */
  isHostedImage?: boolean;
  /**
   * Doc porn classification.
   */
  isPorn?: boolean;
  /**
   * Is disallowed for crawling according to host's robots.txt.
   */
  isRoboted?: boolean;
  /**
   * Consider the page classification is_porn as an alternative for
   * is_site_porn, and talk to safesearch@google.com for additional information
   * if needed.
   */
  isSitePorn?: boolean;
  /**
   * Doc softporn classification.
   */
  isSoftporn?: boolean;
  /**
   * go/iii-td b/130371355
   */
  language?: bigint;
  /**
   * This returns the most probable language for the document. The complete set
   * of languages is in the GenericSearchResponse. (If some future use requires
   * all languages from the doc request, note that fetching that will require
   * decoding the entire per-doc data attachment, which is a performance hit)
   * Use docinfo-util.h to set & read language fields. Language tag as defined
   * by http://www.unicode.org/reports/tr35/#Identifiers and
   * https://tools.ietf.org/html/bcp47 If not present, then use language.
   */
  languageTag?: string;
  /**
   * Unused by gws
   */
  lastModTime?: bigint;
  /**
   * Indicates the web-master opt-in state of this image. This project is still
   * in MVP stage, please contact us licensed-media-team@ before use.
   */
  licensedWebImagesOptInState?:  | "IMAGES_OPTIN_NONE" | "IMAGES_OPTIN_FULL" | "PAGE_SNIPPET_CONTROL_SIZE_NONE" | "PAGE_SNIPPET_CONTROL_SIZE_STANDARD" | "PAGE_SNIPPET_CONTROL_SIZE_LARGE" | "IMAGE_TAG_SNIPPET_CONTROL_SIZE_NONE" | "IMAGE_TAG_SNIPPET_CONTROL_SIZE_STANDARD" | "IMAGE_TAG_SNIPPET_CONTROL_SIZE_LARGE";
  lowQualityMetadescription?: boolean;
  /**
   * If meta description/body title were detected to be in a different language
   * from the document language (the 'language' field above) in
   * RosettaLanguageAnnotator, the detected languages are populated here. Note:
   * as of ariane/154728, no more than one language is populated for each field.
   */
  metaDescriptionLanguages?: string[];
  /**
   * Nearby text of the image on landing page. Used to construct Scroll to
   * Image urls.
   */
  nearbyText?: string;
  /**
   * If not 0, we should not show the image in overlay mode in image snippets.
   */
  noimageframeoverlayreason?: number;
  /**
   * Sitechunk used by NSR. For most pages this is equivalent HOST_LEVEL_V3
   * sitechunk. Main difference is that, for sites like youtube.com and
   * vimeo.com, nsr_sitechunks are channel level (based on schema.org markup,
   * not url alone). See go/nsr-chunks for more details.
   */
  nsrSitechunk?: string;
  partialBoilerplateMetadescription?: boolean;
  /**
   * 'porn_stats' is used in porn demotion and filtering. See
   * classifier/porn/public/porn-attachments.h.
   */
  pornStats?: number;
  /**
   * Quality score (also known as QScore, see go/qscore-faq).
   */
  qualityWithoutAdjustment?: number;
  /**
   * Url of referring doc
   */
  referrerUrl?: string;
  relatedimages?: WWWDocInfoRelatedImages[];
  /**
   * True if the meta-description is duplicated on many other pages and this
   * page is the rootpage of such pages which have the same meta-description.
   */
  rootpageDuplicateMetadescription?: boolean;
  /**
   * Has noarchive meta robots flag
   */
  seenNoarchive?: boolean;
  /**
   * Has noindex meta robots flag
   */
  seenNoindex?: boolean;
  /**
   * NOTE(kinoue): ODP/GWD snippet is unlaunched as of June 2017. This is no
   * longer used.
   */
  seenNoodp?: boolean;
  /**
   * Has nopreview meta robots flag
   */
  seenNopreview?: boolean;
  /**
   * Has nosnippet meta robots flag
   */
  seenNosnippet?: boolean;
  /**
   * Has notranslate meta robots flag
   */
  seenNotranslate?: boolean;
  shoppingAttachment?: QualityShoppingShoppingAttachment;
  /**
   * Shopping offer info from Inventory & Policy Service.
   */
  shoppingOffers?: ImageMustangShoppingOffer[];
  /**
   * Subindex id of the document should be one of the values defined by enum
   * CompositeDoc::SubIndexType. Used for superroot/gws logging if a shard has
   * documents from multiple indices.
   */
  subindex?: number;
  /**
   * thumbnail height
   */
  thumbHeight?: number;
  thumbnail?: WWWDocInfoThumbnail[];
  /**
   * Additions for image search.
   */
  thumbWidth?: number;
  /**
   * Landing page title.
   */
  title?: string;
  unionBuildTime?: bigint;
  /**
   * Url
   */
  url?: string;
  /**
   * empty => same as url
   */
  urlAfterRedirects?: string;
  /**
   * See webutil/urlencoding
   */
  urlEncoding?: number;
  /**
   * If an image request, was the coupled image visible on the page?
   */
  visibleImage?: boolean;
  /**
   * Is this doc visual RTL? See enum VisualType in visualtype.h. Default is
   * NOT_VISUAL_DOCUMENT.
   */
  visualType?: bigint;
}

function serializeWWWDocInfo(data: any): WWWDocInfo {
  return {
    ...data,
    contentType: data["contentType"] !== undefined ? String(data["contentType"]) : undefined,
    crawlTime: data["crawlTime"] !== undefined ? String(data["crawlTime"]) : undefined,
    docVersionId: data["docVersionId"] !== undefined ? String(data["docVersionId"]) : undefined,
    encoding: data["encoding"] !== undefined ? String(data["encoding"]) : undefined,
    failsSafeSearch: data["failsSafeSearch"] !== undefined ? String(data["failsSafeSearch"]) : undefined,
    fileTypeId: data["fileTypeId"] !== undefined ? String(data["fileTypeId"]) : undefined,
    googleLabelData: data["googleLabelData"] !== undefined ? encodeBase64(data["googleLabelData"]) : undefined,
    indexingTs: data["indexingTs"] !== undefined ? String(data["indexingTs"]) : undefined,
    ipaddr: data["ipaddr"] !== undefined ? encodeBase64(data["ipaddr"]) : undefined,
    language: data["language"] !== undefined ? String(data["language"]) : undefined,
    lastModTime: data["lastModTime"] !== undefined ? String(data["lastModTime"]) : undefined,
    relatedimages: data["relatedimages"] !== undefined ? data["relatedimages"].map((item: any) => (serializeWWWDocInfoRelatedImages(item))) : undefined,
    shoppingAttachment: data["shoppingAttachment"] !== undefined ? serializeQualityShoppingShoppingAttachment(data["shoppingAttachment"]) : undefined,
    shoppingOffers: data["shoppingOffers"] !== undefined ? data["shoppingOffers"].map((item: any) => (serializeImageMustangShoppingOffer(item))) : undefined,
    thumbnail: data["thumbnail"] !== undefined ? data["thumbnail"].map((item: any) => (serializeWWWDocInfoThumbnail(item))) : undefined,
    unionBuildTime: data["unionBuildTime"] !== undefined ? String(data["unionBuildTime"]) : undefined,
    visualType: data["visualType"] !== undefined ? String(data["visualType"]) : undefined,
  };
}

function deserializeWWWDocInfo(data: any): WWWDocInfo {
  return {
    ...data,
    contentType: data["contentType"] !== undefined ? BigInt(data["contentType"]) : undefined,
    crawlTime: data["crawlTime"] !== undefined ? BigInt(data["crawlTime"]) : undefined,
    docVersionId: data["docVersionId"] !== undefined ? BigInt(data["docVersionId"]) : undefined,
    encoding: data["encoding"] !== undefined ? BigInt(data["encoding"]) : undefined,
    failsSafeSearch: data["failsSafeSearch"] !== undefined ? BigInt(data["failsSafeSearch"]) : undefined,
    fileTypeId: data["fileTypeId"] !== undefined ? BigInt(data["fileTypeId"]) : undefined,
    googleLabelData: data["googleLabelData"] !== undefined ? decodeBase64(data["googleLabelData"] as string) : undefined,
    indexingTs: data["indexingTs"] !== undefined ? BigInt(data["indexingTs"]) : undefined,
    ipaddr: data["ipaddr"] !== undefined ? decodeBase64(data["ipaddr"] as string) : undefined,
    language: data["language"] !== undefined ? BigInt(data["language"]) : undefined,
    lastModTime: data["lastModTime"] !== undefined ? BigInt(data["lastModTime"]) : undefined,
    relatedimages: data["relatedimages"] !== undefined ? data["relatedimages"].map((item: any) => (deserializeWWWDocInfoRelatedImages(item))) : undefined,
    shoppingAttachment: data["shoppingAttachment"] !== undefined ? deserializeQualityShoppingShoppingAttachment(data["shoppingAttachment"]) : undefined,
    shoppingOffers: data["shoppingOffers"] !== undefined ? data["shoppingOffers"].map((item: any) => (deserializeImageMustangShoppingOffer(item))) : undefined,
    thumbnail: data["thumbnail"] !== undefined ? data["thumbnail"].map((item: any) => (deserializeWWWDocInfoThumbnail(item))) : undefined,
    unionBuildTime: data["unionBuildTime"] !== undefined ? BigInt(data["unionBuildTime"]) : undefined,
    visualType: data["visualType"] !== undefined ? BigInt(data["visualType"]) : undefined,
  };
}

/**
 * Return related images.
 */
export interface WWWDocInfoRelatedImages {
  imageDocid?: bigint;
  thumbHeight?: number;
  thumbType?:  | "THUMBNAIL_TYPE_DEFAULT" | "THUMBNAIL_TYPE_AREA_50K" | "THUMBNAIL_TYPE_400" | "THUMBNAIL_TYPE_800" | "THUMBNAIL_TYPE_ORIGINAL" | "THUMBNAIL_TYPE_ORIGINAL_HQ" | "THUMBNAIL_TYPE_FAVICON_16" | "THUMBNAIL_TYPE_FAVICON_28" | "THUMBNAIL_TYPE_FAVICON_32" | "THUMBNAIL_TYPE_FAVICON_64" | "THUMBNAIL_TYPE_FAVICON_ORIGINAL" | "THUMBNAIL_TYPE_FAVICON_16_DARK" | "THUMBNAIL_TYPE_FAVICON_28_DARK" | "THUMBNAIL_TYPE_FAVICON_32_DARK" | "THUMBNAIL_TYPE_FAVICON_64_DARK" | "THUMBNAIL_TYPE_FAVICON_ORIGINAL_DARK" | "THUMBNAIL_TYPE_1080" | "THUMBNAIL_TYPE_1600_HQ" | "THUMBNAIL_TYPE_AREA_300K" | "THUMBNAIL_TYPE_AREA_50K_ALPHA" | "THUMBNAIL_TYPE_AREA_50K_SYNTHETIC_ALPHA" | "THUMBNAIL_TYPE_AREA_2M" | "THUMBNAIL_TYPE_AREA_2M_METADATA" | "THUMBNAIL_TYPE_800_ALPHA_WHITE" | "THUMBNAIL_TYPE_ORIGINAL_ALPHA_WHITE" | "THUMBNAIL_TYPE_ANIMATED_H144" | "THUMBNAIL_TYPE_ORIGINAL_HQ_LICENSED" | "THUMBNAIL_TYPE_TENOR_250K_GIF" | "THUMBNAIL_TYPE_TENOR_100K_OPTIMIZED_GIF" | "THUMBNAIL_TYPE_TENOR_30K_OPTIMIZED_THUMBNAIL_GIF" | "THUMBNAIL_TYPE_TENOR_45K_OPTIMIZED_90P_GIF" | "THUMBNAIL_TYPE_TENOR_50K_OPTIMIZED_100P_GIF" | "THUMBNAIL_TYPE_TENOR_100K_OPTIMIZED_200P_GIF" | "THUMBNAIL_TYPE_TENOR_50K_OPTIMIZED_100W_GIF" | "THUMBNAIL_TYPE_TENOR_100K_OPTIMIZED_200W_GIF" | "THUMBNAIL_TYPE_TENOR_45K_PREVIEW_GIF" | "THUMBNAIL_TYPE_TENOR_250K_MEDIUM_GIF" | "THUMBNAIL_TYPE_AREA_2M_WEBP" | "THUMBNAIL_TYPE_AREA_2M_WEBP_METADATA" | "THUMBNAIL_TYPE_AREA_2M_AVIF" | "THUMBNAIL_TYPE_AREA_2M_AVIF_METADATA" | "THUMBNAIL_TYPE_AREA_50K_WEBP" | "THUMBNAIL_TYPE_AREA_50K_AVIF" | "THUMBNAIL_TYPE_ORIGINAL_HQ_KG";
  thumbWidth?: number;
}

function serializeWWWDocInfoRelatedImages(data: any): WWWDocInfoRelatedImages {
  return {
    ...data,
    imageDocid: data["imageDocid"] !== undefined ? String(data["imageDocid"]) : undefined,
  };
}

function deserializeWWWDocInfoRelatedImages(data: any): WWWDocInfoRelatedImages {
  return {
    ...data,
    imageDocid: data["imageDocid"] !== undefined ? BigInt(data["imageDocid"]) : undefined,
  };
}

export interface WWWDocInfoThumbnail {
  expirationTimestampMicros?: bigint;
  height?: number;
  /**
   * The type here corresponds to image_base::ThumbnailType defined in
   * image/base/thumbnail-type.proto.
   */
  type?: number;
  width?: number;
}

function serializeWWWDocInfoThumbnail(data: any): WWWDocInfoThumbnail {
  return {
    ...data,
    expirationTimestampMicros: data["expirationTimestampMicros"] !== undefined ? String(data["expirationTimestampMicros"]) : undefined,
  };
}

function deserializeWWWDocInfoThumbnail(data: any): WWWDocInfoThumbnail {
  return {
    ...data,
    expirationTimestampMicros: data["expirationTimestampMicros"] !== undefined ? BigInt(data["expirationTimestampMicros"]) : undefined,
  };
}

/**
 * We can return the content attribute for some or all meta tags.
 */
export interface WWWMetaTag {
  content?: string;
  name?: string;
}

/**
 * The following message contains info of sub image docs, it is populated in
 * query_state and consumed in web image boost twiddler:
 * (go/WebImageBoostTwiddler).
 */
export interface WWWResultInfoSubImageDocInfo {
  additionalSafesearchSignals?: number[];
  /**
   * The best thumbnail type is either 300K or 50K.
   */
  bestThumbnailType?:  | "THUMBNAIL_TYPE_DEFAULT" | "THUMBNAIL_TYPE_AREA_50K" | "THUMBNAIL_TYPE_400" | "THUMBNAIL_TYPE_800" | "THUMBNAIL_TYPE_ORIGINAL" | "THUMBNAIL_TYPE_ORIGINAL_HQ" | "THUMBNAIL_TYPE_FAVICON_16" | "THUMBNAIL_TYPE_FAVICON_28" | "THUMBNAIL_TYPE_FAVICON_32" | "THUMBNAIL_TYPE_FAVICON_64" | "THUMBNAIL_TYPE_FAVICON_ORIGINAL" | "THUMBNAIL_TYPE_FAVICON_16_DARK" | "THUMBNAIL_TYPE_FAVICON_28_DARK" | "THUMBNAIL_TYPE_FAVICON_32_DARK" | "THUMBNAIL_TYPE_FAVICON_64_DARK" | "THUMBNAIL_TYPE_FAVICON_ORIGINAL_DARK" | "THUMBNAIL_TYPE_1080" | "THUMBNAIL_TYPE_1600_HQ" | "THUMBNAIL_TYPE_AREA_300K" | "THUMBNAIL_TYPE_AREA_50K_ALPHA" | "THUMBNAIL_TYPE_AREA_50K_SYNTHETIC_ALPHA" | "THUMBNAIL_TYPE_AREA_2M" | "THUMBNAIL_TYPE_AREA_2M_METADATA" | "THUMBNAIL_TYPE_800_ALPHA_WHITE" | "THUMBNAIL_TYPE_ORIGINAL_ALPHA_WHITE" | "THUMBNAIL_TYPE_ANIMATED_H144" | "THUMBNAIL_TYPE_ORIGINAL_HQ_LICENSED" | "THUMBNAIL_TYPE_TENOR_250K_GIF" | "THUMBNAIL_TYPE_TENOR_100K_OPTIMIZED_GIF" | "THUMBNAIL_TYPE_TENOR_30K_OPTIMIZED_THUMBNAIL_GIF" | "THUMBNAIL_TYPE_TENOR_45K_OPTIMIZED_90P_GIF" | "THUMBNAIL_TYPE_TENOR_50K_OPTIMIZED_100P_GIF" | "THUMBNAIL_TYPE_TENOR_100K_OPTIMIZED_200P_GIF" | "THUMBNAIL_TYPE_TENOR_50K_OPTIMIZED_100W_GIF" | "THUMBNAIL_TYPE_TENOR_100K_OPTIMIZED_200W_GIF" | "THUMBNAIL_TYPE_TENOR_45K_PREVIEW_GIF" | "THUMBNAIL_TYPE_TENOR_250K_MEDIUM_GIF" | "THUMBNAIL_TYPE_AREA_2M_WEBP" | "THUMBNAIL_TYPE_AREA_2M_WEBP_METADATA" | "THUMBNAIL_TYPE_AREA_2M_AVIF" | "THUMBNAIL_TYPE_AREA_2M_AVIF_METADATA" | "THUMBNAIL_TYPE_AREA_50K_WEBP" | "THUMBNAIL_TYPE_AREA_50K_AVIF" | "THUMBNAIL_TYPE_ORIGINAL_HQ_KG";
  crops?: number;
  /**
   * Deepcrop thumbnail cropping hints.
   */
  deepCropBytes?: Uint8Array;
  docid?: bigint;
  documentTrust?: number;
  /**
   * EQ* is a unified signal to capture the emotional quality (e.g.
   * inspiration, lifestyle, context, etc.) of an image. For more information,
   * please refer to go/image-inspiration-ranking-framework.
   */
  eqStar?: number;
  /**
   * Estimated Image Relevance ranging between 0.0 (Off-Topic) to 1.0 (Very
   * Useful).
   */
  estRelevance?: number;
  flowOutput?: ImageContentFlowProtoProd;
  height?: number;
  height50k?: number;
  /**
   * DeepTags human model score. go/VisualShoppingImageAttributes
   */
  humanModelScore?: number;
  imageUrl?: string;
  pamirNormalizedScore?: number;
  /**
   * Encoded Safe Search annotations of the image. See
   * image/safesearch/overall/public/image_porn_attachments.h for decoding
   * functions.
   */
  pornSignals?: number;
  /**
   * Result is not on the Images Universal blacklist. For more comprehensive
   * filtering of IU images, including this bit, see
   * superroot/impls/images/quality/safesearch/iu_inappropriate_filter_lib.h
   */
  safeForUniversal?: boolean;
  /**
   * Salient score, indicating how important an image is to the page it's on.
   * Check go/salient-images-design-doc for details.
   */
  salience?: number;
  /**
   * 4-bytes: (low order on the left) RRRRRRRR GGGGGGGG BBBBBBBB SS where R:
   * 8-bits encoding color 'r' G: 8-bits encoding color 'g' B: 8-bits encoding
   * color 'b' S: 2-bits encoding the color source - 00 = from color detection
   * result - 01 = from cairo This field has the salient color information.
   */
  salientColorInfo?: number;
  score?: number;
  /**
   * TQ* is a signal to capture the technical quality (e.g. exposure,
   * sharpness, composition, etc.) of an image. For more information, please
   * refer to go/tqstar.
   */
  tqStar?: number;
  tradFrac?: number;
  width?: number;
  /**
   * Width and height of the AREA_50K thumbnail for this image.
   */
  width50k?: number;
}

function serializeWWWResultInfoSubImageDocInfo(data: any): WWWResultInfoSubImageDocInfo {
  return {
    ...data,
    deepCropBytes: data["deepCropBytes"] !== undefined ? encodeBase64(data["deepCropBytes"]) : undefined,
    docid: data["docid"] !== undefined ? String(data["docid"]) : undefined,
    flowOutput: data["flowOutput"] !== undefined ? serializeImageContentFlowProtoProd(data["flowOutput"]) : undefined,
  };
}

function deserializeWWWResultInfoSubImageDocInfo(data: any): WWWResultInfoSubImageDocInfo {
  return {
    ...data,
    deepCropBytes: data["deepCropBytes"] !== undefined ? decodeBase64(data["deepCropBytes"] as string) : undefined,
    docid: data["docid"] !== undefined ? BigInt(data["docid"]) : undefined,
    flowOutput: data["flowOutput"] !== undefined ? deserializeImageContentFlowProtoProd(data["flowOutput"]) : undefined,
  };
}

/**
 * Per-document response for a www DocInfo request. Next field position: 55
 */
export interface WWWSnippetResponse {
  /**
   * A list of answers that had at least one hit in the document. Answers are
   * identified by their index into the QRewriteQueryParams_AnswerSnippetInfo
   * array (see //query/proto/query-params.proto).
   */
  answerDocMatches?: number[];
  /**
   * Tidbits chosen from the document body. Consists of repeated [begin, end)
   * half-open ranges in token offsets from the beginning of the document.
   */
  chosenBodyTidbits?: number[];
  docInfo?: WWWDocInfo;
  /**
   * DocPreviewRestrictions for canonical url.
   */
  docPreviewRestrictions?: QualityDniDocPreviewRestrictions;
  /**
   * DocPreviewRestrictions for amp result.
   */
  docPreviewRestrictionsForAmp?: QualityDniDocPreviewRestrictions;
  /**
   * Bitfield of snippet events and the various events. See SnippetEvents in
   * ./snippets/defines.h for details on the contents.
   */
  events?: bigint;
  /**
   * If requested, the extra snippet info
   */
  extraInfo?: ExtraSnippetInfoResponse;
  /**
   * A bitvector of the tidbits in the snippet that are appropriate for the
   * Quick Scroll (Findy) Chrome extension. Typically these contain "extra body
   * matches", i.e., important query items not in the title.
   */
  findyTidbits?: number;
  /**
   * Additional available data (message type ids)
   */
  hasMessageType?: number[];
  /**
   * Additional data. Currently, this is used for sitelinks, localinfo,
   * manybox, discussion metadata, richsnippets, similarpages and breadcrumbs.
   */
  info?: Proto2BridgeMessageSet;
  /**
   * True if the document represents a login page.
   */
  isLoginPage?: boolean;
  /**
   * Assume this is true unless we discover that the result doesn't match the
   * the query, in which case this result is invalid despite having returned
   * docinfo.
   */
  isValidResult?: boolean;
  /**
   * Document keywords
   */
  keyword?: string[];
  /**
   * List snippet data.
   */
  listSnippet?: ListSnippetResponse;
  /**
   * List summary phrase for list pages.
   */
  listSummary?: string;
  /**
   * Returned if want_long_structured_snippets. If present, caller should
   * ignore the normal snippet.
   */
  longStructuredSnippet?: LongStructuredSnippet;
  /**
   * Bitmap representing matches to leaf query terms within document (body
   * section and url). It gets populated if query_matches_info = true.
   */
  matchesBitmapEncoded?: Uint8Array;
  matchesBitmapSize?: number;
  /**
   * Meta tags
   */
  metaTags?: WWWMetaTag[];
  numberOfPages?: number;
  /**
   * Similar to num_tokens_skipped_by_in_doc_restrictions_in_scoring, but this
   * number is for tokens skipped during printing, since printer owns its own
   * token info manager which populates tokens.
   */
  numTokensSkippedByInDocRestrictionsInPrinting?: number;
  /**
   * Number of tokens that is skipped because of in doc restrictions during
   * scoring. This is an estimate, as the list of tokens is cached in
   * TokenInfoManager. We should only monitor the cases where this number is too
   * big or non-zero.
   */
  numTokensSkippedByInDocRestrictionsInScoring?: number;
  /**
   * LocalWWWInfo
   */
  obsoleteLocalinfo?: string;
  /**
   * ManyboxData
   */
  obsoleteManybox?: string;
  /**
   * These fields were previously optional messages, but CL 2388905 moved them
   * into the MessageSet. However, at this time, old Mustang binaries are still
   * deployed in production and probably will be around for awhile. So, servers
   * which need to talk to old binaries and need to use these fields need to
   * check both the obsolete versions and the MessageSet version. Sitemap
   */
  obsoleteSitemap?: string;
  /**
   * Was odp used in the snippets? DEPRECATED - this is no longer populated as
   * of June 2017.
   */
  odp?: boolean;
  /**
   * DEPRECATED If requested, the orion entities
   */
  orionEntities?: OrionDocEntitiesProto;
  /**
   * Abbreviated bibliographic data from Google Scholar.
   */
  scienceInfo?: ScienceIndexSignal;
  sectionHeadingAnchorName?: string;
  /**
   * If requested, the snippet generator may take note of query items present
   * in an entry in an on-page table-of-contents (i.e. a series of on-page links
   * to named anchors.) If so, these two fields contain the formatted and
   * highlighted entry and the name of the on-page anchor it links to,
   * respectively. This may be used by GWS to show a direct link to that named
   * anchor on the page.
   */
  sectionHeadingText?: string;
  /**
   * Did a negative query term match the meta description?
   */
  seenNotTerm?: boolean;
  /**
   * DEPRECATED Sentiment snippets
   */
  sentimentSnippets?: RepositoryAnnotationsMustangSentimentSnippetAnnotations[];
  /**
   * The display name of the document's domain used as the first part of
   * VisUrl, e.g, "Google > play > store" is the VisUrl of
   * "https://play.google.com/store/". Wherein, "Google" is site_display_name of
   * the domain "google.com". See go/site-display-name for more details.
   */
  siteDisplayName?: string;
  /**
   * Byline date for time sensitive snippets. Most of the time it originates
   * from quality_timebased::SyntacticDate and it is floored to PT midnight.
   */
  snippetBylineDate?: bigint;
  snippetExtraInfo?: SnippetExtraInfo;
  /**
   * A hash for duplicate detection. Two results with the same content can
   * return different snippets if, for example, one has an ODP entry and the
   * other does not. Gws can use this value reliably to filter duplicates. It is
   * a hash of body only tidbits.
   */
  snippethash?: bigint;
  /**
   * List of bitmaps representing matches to leaf query terms within each of
   * the highlighted snippet text fragments. Consecutive bitmaps correspond to
   * consecutive text fragments. It gets populated iff
   * return_query_snippet_highlight_matches = true. Example: document body
   * section: "This cafe has pet friendly patio." squery: (a (o dog :o pet
   * :syn:general) friendly :o (o restaurant :o cafe :syn:general)) Let's assume
   * the returned snippet text contains the whole document body section where
   * two fragments get highlighted as follows: "This *cafe* has *pet friendly*
   * patio." Then, the returned snippet_highlight_matches_bitmap[] list will
   * have two bitmaps: bitmap[0] = <"cafe" -> leaf term with index 4> =
   * {encoded: DenseEncode("00001"), size: 5} bitmap[1] = <"pet" and "friendly"
   * -> leaf terms with indexes 1 and 2> = {encoded: DenseEncode("011"), size:
   * 3}
   */
  snippetHighlightMatchesBitmap?: WWWSnippetResponseBitmapPB[];
  /**
   * If requested the page number on which the snippet begins. (Only for
   * documents such as PDFs where page numbers are well-defined.)
   */
  snippetPageNumber?: number;
  /**
   * Character counts of snippet prefix, if any. E.g. section heading, list
   * summary, byline date.
   */
  snippetPrefixCharCount?: number;
  /**
   * How tokens are rendered in generating snippet.
   */
  snippetRenderedToken?: MustangSnippetsRenderedToken[];
  /**
   * Records features to analyze titles/snippets in ranklab.
   */
  snippetsRanklabFeatures?: MustangReposWwwSnippetsSnippetsRanklabFeatures;
  /**
   * This field is never set.
   */
  squeryFingerprint?: bigint;
  /**
   * True if the title length is already adjusted for the browser width. If it
   * is true, GWS needs not truncate the title.
   */
  titleLengthAdjustedForBrowserWidth?: boolean;
  /**
   * How tokens are rendered in generating title. Note: In rendering a title,
   * the page title part and the site/host/domain title part can be flipped
   * after initial rendering. The flip, if happend, may not be reflected in this
   * field. That is, this field may contain the tokens in the original,
   * pre-flip, order.
   */
  titleRenderedToken?: MustangSnippetsRenderedToken[];
  /**
   * Will only be set when `title_use_num_of_chars` is false.
   */
  titleSizeParams?: TitleSizeParams;
  /**
   * Only for desktop web search. Please refer to
   * Title.keep_original_title_and_populate_truncated_one for more details.
   */
  truncatedTitle?: string;
}

function serializeWWWSnippetResponse(data: any): WWWSnippetResponse {
  return {
    ...data,
    docInfo: data["docInfo"] !== undefined ? serializeWWWDocInfo(data["docInfo"]) : undefined,
    docPreviewRestrictions: data["docPreviewRestrictions"] !== undefined ? serializeQualityDniDocPreviewRestrictions(data["docPreviewRestrictions"]) : undefined,
    docPreviewRestrictionsForAmp: data["docPreviewRestrictionsForAmp"] !== undefined ? serializeQualityDniDocPreviewRestrictions(data["docPreviewRestrictionsForAmp"]) : undefined,
    events: data["events"] !== undefined ? String(data["events"]) : undefined,
    extraInfo: data["extraInfo"] !== undefined ? serializeExtraSnippetInfoResponse(data["extraInfo"]) : undefined,
    matchesBitmapEncoded: data["matchesBitmapEncoded"] !== undefined ? encodeBase64(data["matchesBitmapEncoded"]) : undefined,
    orionEntities: data["orionEntities"] !== undefined ? serializeOrionDocEntitiesProto(data["orionEntities"]) : undefined,
    scienceInfo: data["scienceInfo"] !== undefined ? serializeScienceIndexSignal(data["scienceInfo"]) : undefined,
    snippetBylineDate: data["snippetBylineDate"] !== undefined ? String(data["snippetBylineDate"]) : undefined,
    snippetExtraInfo: data["snippetExtraInfo"] !== undefined ? serializeSnippetExtraInfo(data["snippetExtraInfo"]) : undefined,
    snippethash: data["snippethash"] !== undefined ? String(data["snippethash"]) : undefined,
    snippetHighlightMatchesBitmap: data["snippetHighlightMatchesBitmap"] !== undefined ? data["snippetHighlightMatchesBitmap"].map((item: any) => (serializeWWWSnippetResponseBitmapPB(item))) : undefined,
    snippetRenderedToken: data["snippetRenderedToken"] !== undefined ? data["snippetRenderedToken"].map((item: any) => (serializeMustangSnippetsRenderedToken(item))) : undefined,
    snippetsRanklabFeatures: data["snippetsRanklabFeatures"] !== undefined ? serializeMustangReposWwwSnippetsSnippetsRanklabFeatures(data["snippetsRanklabFeatures"]) : undefined,
    squeryFingerprint: data["squeryFingerprint"] !== undefined ? String(data["squeryFingerprint"]) : undefined,
    titleRenderedToken: data["titleRenderedToken"] !== undefined ? data["titleRenderedToken"].map((item: any) => (serializeMustangSnippetsRenderedToken(item))) : undefined,
  };
}

function deserializeWWWSnippetResponse(data: any): WWWSnippetResponse {
  return {
    ...data,
    docInfo: data["docInfo"] !== undefined ? deserializeWWWDocInfo(data["docInfo"]) : undefined,
    docPreviewRestrictions: data["docPreviewRestrictions"] !== undefined ? deserializeQualityDniDocPreviewRestrictions(data["docPreviewRestrictions"]) : undefined,
    docPreviewRestrictionsForAmp: data["docPreviewRestrictionsForAmp"] !== undefined ? deserializeQualityDniDocPreviewRestrictions(data["docPreviewRestrictionsForAmp"]) : undefined,
    events: data["events"] !== undefined ? BigInt(data["events"]) : undefined,
    extraInfo: data["extraInfo"] !== undefined ? deserializeExtraSnippetInfoResponse(data["extraInfo"]) : undefined,
    matchesBitmapEncoded: data["matchesBitmapEncoded"] !== undefined ? decodeBase64(data["matchesBitmapEncoded"] as string) : undefined,
    orionEntities: data["orionEntities"] !== undefined ? deserializeOrionDocEntitiesProto(data["orionEntities"]) : undefined,
    scienceInfo: data["scienceInfo"] !== undefined ? deserializeScienceIndexSignal(data["scienceInfo"]) : undefined,
    snippetBylineDate: data["snippetBylineDate"] !== undefined ? BigInt(data["snippetBylineDate"]) : undefined,
    snippetExtraInfo: data["snippetExtraInfo"] !== undefined ? deserializeSnippetExtraInfo(data["snippetExtraInfo"]) : undefined,
    snippethash: data["snippethash"] !== undefined ? BigInt(data["snippethash"]) : undefined,
    snippetHighlightMatchesBitmap: data["snippetHighlightMatchesBitmap"] !== undefined ? data["snippetHighlightMatchesBitmap"].map((item: any) => (deserializeWWWSnippetResponseBitmapPB(item))) : undefined,
    snippetRenderedToken: data["snippetRenderedToken"] !== undefined ? data["snippetRenderedToken"].map((item: any) => (deserializeMustangSnippetsRenderedToken(item))) : undefined,
    snippetsRanklabFeatures: data["snippetsRanklabFeatures"] !== undefined ? deserializeMustangReposWwwSnippetsSnippetsRanklabFeatures(data["snippetsRanklabFeatures"]) : undefined,
    squeryFingerprint: data["squeryFingerprint"] !== undefined ? BigInt(data["squeryFingerprint"]) : undefined,
    titleRenderedToken: data["titleRenderedToken"] !== undefined ? data["titleRenderedToken"].map((item: any) => (deserializeMustangSnippetsRenderedToken(item))) : undefined,
  };
}

/**
 * Encoded bitmap.
 */
export interface WWWSnippetResponseBitmapPB {
  encoded?: Uint8Array;
  size?: number;
}

function serializeWWWSnippetResponseBitmapPB(data: any): WWWSnippetResponseBitmapPB {
  return {
    ...data,
    encoded: data["encoded"] !== undefined ? encodeBase64(data["encoded"]) : undefined,
  };
}

function deserializeWWWSnippetResponseBitmapPB(data: any): WWWSnippetResponseBitmapPB {
  return {
    ...data,
    encoded: data["encoded"] !== undefined ? decodeBase64(data["encoded"] as string) : undefined,
  };
}

/**
 * Contains information about comment that is posted through a Super VOD
 * purchase. Next ID: 6
 */
export interface YoutubeBackstageSuperVodCommentInfo {
  /**
   * Currency code the user uses to purchase this Super VOD item.
   */
  currencyCode?: string;
  /**
   * The ID of the Super VOD entitlement. It uniquely identifies a Super VOD
   * purchase.
   */
  entitlementId?: string;
  /**
   * Price of Super VOD item the user purchases in micros.
   */
  priceInMicros?: bigint;
  /**
   * The Super VOD item the user purchases, it represents price tier.
   */
  superVodItemId?: string;
  /**
   * Which version of experiment this Super VOD comment is posted in.
   */
  version?:  | "UNSPECIFIED_VERSION" | "V1_DEFAULT_MESSAGE" | "V2_DECORATED_DEFAULT_MESSAGE" | "V3_USER_GENERATED_MESSAGE";
}

function serializeYoutubeBackstageSuperVodCommentInfo(data: any): YoutubeBackstageSuperVodCommentInfo {
  return {
    ...data,
    priceInMicros: data["priceInMicros"] !== undefined ? String(data["priceInMicros"]) : undefined,
  };
}

function deserializeYoutubeBackstageSuperVodCommentInfo(data: any): YoutubeBackstageSuperVodCommentInfo {
  return {
    ...data,
    priceInMicros: data["priceInMicros"] !== undefined ? BigInt(data["priceInMicros"]) : undefined,
  };
}

/**
 * Intended to be simpler to work with than the ExportedStanza it's derived
 * from See documentation:
 * https://g3doc.corp.google.com/company/teams/youtube/community_intelligence/eng_resources/data_sources.md#ministanza
 * Next available: 77
 */
export interface YoutubeCommentsClusteringMiniStanza {
  /**
   * TnS Ansible scores map. Keyed by various model names.
   */
  ansibleScores?: {
    [key: string]: number
  };
  /**
   * Automod scores map. Keyed by various model names.
   */
  automodScores?: {
    [key: string]: number
  };
  /**
   * The blarney stone score.
   */
  blarneyStoneScore?: YoutubeDistillerBlarneyStoneScores;
  /**
   * The channel this channel discussion comment belongs to. Note that this
   * will match channel_id for such comments.
   */
  channelDiscussionId?: string;
  /**
   * The channel of the video this comment belongs to.
   */
  channelId?: string;
  /**
   * Channel profile quality scores map. Keyed by various model names.
   */
  channelProfileQualityScores?: {
    [key: string]: number
  };
  /**
   * Char entropy of the comment.
   */
  charEntropy?: number;
  /**
   * Comment classification mapping all secondary keys to values. E.g.
   * {"joke_v1":0.8, "joke_v2":0.7, "question_v1":0.3}.
   */
  commentClassification?: {
    [key: string]: number
  };
  /**
   * List of pre-defined classification score buckets to which the comment
   * belongs. E.g. satisfaction_v1_percentile_80.
   */
  commentClassificationBuckets?: string[];
  /**
   * Comment classification for ranking mapping all secondary keys to values.
   * E.g. {"joke_v1":0.8, "joke_v2":0.7, "question_v1":0.3}.
   */
  commentClassificationRanking?: {
    [key: string]: number
  };
  /**
   * Whether the comment is on a video, post, or other product.
   */
  commentType?:  | "UNKNOWN_PRODUCT_TYPE" | "UNSUPPORTED_PRODUCT_TYPE" | "YT_VIDEO_COMMENT" | "YT_CHANNEL_DISCUSSION" | "YT_BACKSTAGE_COMMENT" | "YT_LIVE_CHAT" | "YT_LIVE_CHAT_CONFIG" | "YT_CHANNEL_CONFIG" | "YT_POST_COMMENT";
  /**
   * The text content of the comment.
   */
  content?: string;
  /**
   * The stanza content last update timestamp, as observed by the server. Note
   * that for many comments older than Nov. 2014 this is unset in the original
   * stanza. MiniStanza tries to be consistent with the original so for such
   * comments it remains unset in MiniStanza. If you use this field you should
   * check has_content_update_timestamp().
   */
  contentUpdateTimestamp?: Date;
  /**
   * Whether or not this comment is eligible for comment classifier coverage
   * sampling (in Kapla). Refer to
   * go/coverage-monitoring-for-kapla-comment-classifiers for more information.
   */
  coverageSamplingEligible?: boolean;
  /**
   * The creation device. Derived from shares:yt_creation_device
   */
  creationDevice?:  | "UNKNOWN_INTERFACE" | "WEB" | "WEB_GAMING" | "WEB_MUSIC" | "WEB_MUSIC_EMBEDDED_PLAYER" | "WEB_REMIX" | "WEB_EXPERIMENTS" | "WEB_MOVIES" | "WEB_HEROES" | "WEB_CREATOR" | "WEB_LIVE_STREAMING" | "WEB_KIDS" | "WEB_INTERNAL_ANALYTICS" | "WEB_PARENT_TOOLS" | "WEB_PHONE_VERIFICATION" | "WEB_EMBEDDED_PLAYER" | "WEB_UNPLUGGED" | "WEB_UNPLUGGED_ONBOARDING" | "WEB_UNPLUGGED_OPS" | "WEB_UNPLUGGED_PUBLIC" | "MWEB" | "MWEB_TIER_2" | "ANDROID" | "ANDROID_CASUAL" | "ANDROID_CREATOR" | "ANDROID_GAMING" | "ANDROID_KIDS" | "ANDROID_INSTANT" | "ANDROID_MUSIC" | "ANDROID_TESTSUITE" | "ANDROID_UNPLUGGED" | "ANDROID_VR" | "ANDROID_WITNESS" | "ANDROID_SPORTS" | "ANDROID_LITE" | "ANDROID_MOVIES" | "ANDROID_EMBEDDED_PLAYER" | "ANDROID_PRODUCER" | "IOSAPPLE" | "IOS" | "IOS_CREATOR" | "IOS_DIRECTOR" | "IOS_GAMING" | "IOS_INSTANT" | "IOS_KIDS" | "IOS_LIVE_CREATION_EXTENSION" | "IOS_MESSAGES_EXTENSION" | "IOS_MUSIC" | "IOS_TABLOID" | "IOS_UNPLUGGED" | "IOS_WITNESS" | "IOS_SPORTS" | "IOS_EMBEDDED_PLAYER" | "IOS_MOVIES" | "IOS_PILOT_STUDIO" | "IOS_UPTIME" | "IOS_PRODUCER" | "OTHERAPP" | "TVHTML5" | "TVHTML5_AUDIO" | "TVHTML5_CAST" | "TVHTML5_KIDS" | "TVHTML5_FOR_KIDS" | "TVHTML5_MOVIES" | "TVHTML5_SIMPLY" | "TVHTML5_SIMPLY_EMBEDDED_PLAYER" | "TVHTML5_UNPLUGGED" | "TVHTML5_VR" | "TVHTML5_YONGLE" | "TVLITE" | "TV_UNPLUGGED_CAST" | "TV_UNPLUGGED_ANDROID" | "XL" | "ROKU_MOVIES" | "CC_MOVIES" | "TVANDROID" | "ANDROID_TV" | "ANDROID_TV_KIDS" | "ANDROID_TV_MOVIES" | "XBOX" | "XBOXONEGUIDE" | "CLIENTX" | "TVAPPLE" | "TVAPPLE_MOVIES" | "AIRPLAY_MOVIES" | "WEB_MUSIC_ANALYTICS" | "MUSIC_INTEGRATIONS" | "WEB_HANGOUTS_MEET" | "KAIOS_LAUNCHER" | "WEB_GVP_ADS" | "ANDROID_GVP_ADS" | "IOS_GVP_ADS" | "VAST_GVP_ADS" | "GOOGLE_ASSISTANT" | "GOOGLE_LIST_RECS" | "GOOGLE_MEDIA_ACTIONS" | "MEDIA_CONNECT_FRONTEND" | "GOOGLE_TV";
  /**
   * The time when the comment is created.
   */
  creationTimeInSeconds?: bigint;
  /**
   * The language code with extra script details. This is derived from
   * detailed_language_code if it's populated, otherwise the same as
   * language_code. E.g. mr-Latn
   */
  detailedLanguageCode?: string;
  /**
   * All distiller engagements like reports and downvotes.
   */
  distillerEngagements?: AppsPeopleActivityStreamqualityDistillerEngagements;
  /**
   * The qualified comment teaser filters that this comment is eligible for.
   * Refer to go/comment-teaser-design for more information.
   */
  eligibleQualifiedTeaserFilters?: string[];
  /**
   * Comments empirical CTRs.
   */
  empiricalCtrs?: VideoYoutubeCommentsRankingCTRMetrics;
  /**
   * Fountain Discovery Score, which represents the reputation of the author.
   */
  fds?: number;
  /**
   * Indicator for whether there is creator heart on this comment.
   */
  hasCreatorHeart?: boolean;
  /**
   * If the comment has a creator reply.
   */
  hasCreatorReply?: boolean;
  /**
   * If the author is a channel member (sponsor).
   */
  isAuthorSponsor?: boolean;
  /**
   * Whether a comment is from deleted shares. See stanza_restrictions for more
   * specific information and is_publicly_visible for comments which are allowed
   * to be seen by everyone.
   */
  isDeleted?: boolean;
  /**
   * Whether the comment is pinned. This is derived from the
   * DestinationStreamDump.
   */
  isPinned?: boolean;
  /**
   * If the post is publicly visible.
   */
  isPubliclyVisible?: boolean;
  /**
   * Whether the comment is a reply.
   */
  isReply?: boolean;
  /**
   * If the comment author is publicly subscribed to the channel.
   */
  isSubscriber?: boolean;
  /**
   * Unicode CLDR language code of the segments, as implemented by
   * //depot/google3/java/com/google/i18n/identifiers/LanguageCode.java This is
   * derived from user_content and should be considered the canonical language
   * code of the comment.
   */
  languageCode?: string;
  /**
   * The time when last reply is created.
   */
  lastReplyTimestampUsec?: bigint;
  /**
   * Low quality decisions. Keyed by decision types corresponding to secondary
   * keys.
   */
  lowQualityDecisions?: {
    [key: string]: boolean
  };
  /**
   * Timed comments for the "mentioned" secondary key.
   */
  mentionedTimestampCommentSecond?: number;
  /**
   * Misinfo scores map. Keyed by various model names.
   */
  misinfoScores?: {
    [key: string]: number
  };
  /**
   * Number of dislikes the comment has.
   */
  numDislikes?: number;
  /**
   * Number of likes the comment has.
   */
  numLikes?: number;
  /**
   * Number of different repliers the comment has.
   */
  numRepliers?: number;
  /**
   * Number of non-abusive replies the comment has.
   */
  numReplies?: number;
  /**
   * Bucketed number of subscribers held by comment author.
   */
  numSubscribersBucket?: number;
  /**
   * Offline engagement scores map. Keyed by various model names.
   */
  offlineEngagementScores?: {
    [key: string]: number
  };
  /**
   * The parent stanza's stanza_id, empty for top-level posts (non-replies).
   * Prefer is_reply field for checking if a comment is a reply since that is
   * unaffected by surrogatization. For replies to replies, this is the root
   * stanza_id (not guaranteed AFAIK).
   */
  parentId?: string;
  /**
   * The post this comment belongs to.
   */
  postId?: string;
  /**
   * The language code stored in the KV pair ranking:post_language. This should
   * usually be the same as language_code but is not guaranteed to be identical.
   * The KV pair is needed because ranking can't consume user_content.
   */
  rankingPostLanguage?: string;
  /**
   * A textual content for the context.
   */
  segments?: SocialCommonSegments;
  /**
   * Sensitivity scores map for smart reply sensitivity scores. Keyed by model
   * names. See
   * (g3doc/company/teams/expander/research/conversation/sensitive.md) for more
   * information on sensitivity scores.
   */
  sensitivityScores?: {
    [key: string]: number
  };
  /**
   * Sentiment. This omits entity_sentiment and keeps only the polarity,
   * magnitude, and score. Sentiment as currently implemented is not debiased
   * and has limited language coverage. Please read go/comments-sentiment-access
   * before using.
   */
  sentiment?: YoutubeCommentsSentimentSentiment;
  /**
   * Associated Short Reply video ID if the comment represents a Short Reply.
   * See go/yt-comment-sticker-m2.
   */
  shortReplyVideoId?: string;
  /**
   * Smart replies for this comment. Keyed by model names.
   */
  smartReplies?: {
    [key: string]: VideoYoutubeCommentsClassificationProtoYouTubeCommentSmartReply
  };
  /**
   * Refers to the stanza this data is derived from.
   */
  stanzaId?: string;
  /**
   * Contains various restriction information about a stanza.
   */
  stanzaRestrictions?: SocialStanzaStanzaRestriction[];
  /**
   * The author of the comment
   */
  subject?: SecurityCredentialsPrincipalProto;
  /**
   * Whether the comment is authored by the creator.
   */
  subjectIsVideoOwner?: boolean;
  /**
   * The timestamp (in seconds) when the author subscribed to the channel.
   */
  subscriptionTimestamp?: bigint;
  /**
   * Super Thanks related info if a comment is posted through a Super Thanks
   * purchase.
   */
  superThanksInfo?: YoutubeBackstageSuperVodCommentInfo;
  /**
   * Comment text embedding.
   */
  textEmbedding?: {
    [key: string]: YoutubeCommentsRankingYouTubeCommentTextEmbedding
  };
  /**
   * Text length of the comment.
   */
  textLength?: number;
  /**
   * Predicted probability of the comment being flagged based on the text.
   */
  textQualityScores?: YoutubeCommentsRankingYouTubeCommentTextQualityAnnotation;
  /**
   * Predicted probability of the comment being flagged based on the text. For
   * testing the new annotation process only.
   */
  textQualityScores2?: YoutubeCommentsRankingYouTubeCommentTextQualityAnnotation;
  /**
   * The video this comment belongs to.
   */
  videoId?: string;
  /**
   * Unique video timestamps in seconds sorted by timestamp. This is derived
   * from text Segments, not from a KV. These may exceed the length of the video
   * since that isn't checked at segmentation time. The segmentation rules have
   * changed over time e.g. in the past "10:00 PM" was treated as a timestamp.
   */
  videoTimestamps?: number[];
  /**
   * Word entropy of the comment.
   */
  wordEntropy?: number;
  /**
   * The youtube channel id of the comment author.
   */
  ytAuthorChannelId?: string;
  /**
   * Existing quality corpus scores.
   */
  ytCommentQualityScore?: number;
  ytCommentQualityScore2?: number;
  ytCommentQualityScore3?: number;
  /**
   * For replies to replies, this contains the parent reply's id. The parent_id
   * field is actually the root stanza_id (not guaranteed AFAIK).
   */
  ytReplyToItemId?: string;
}

function serializeYoutubeCommentsClusteringMiniStanza(data: any): YoutubeCommentsClusteringMiniStanza {
  return {
    ...data,
    contentUpdateTimestamp: data["contentUpdateTimestamp"] !== undefined ? data["contentUpdateTimestamp"].toISOString() : undefined,
    creationTimeInSeconds: data["creationTimeInSeconds"] !== undefined ? String(data["creationTimeInSeconds"]) : undefined,
    distillerEngagements: data["distillerEngagements"] !== undefined ? serializeAppsPeopleActivityStreamqualityDistillerEngagements(data["distillerEngagements"]) : undefined,
    empiricalCtrs: data["empiricalCtrs"] !== undefined ? serializeVideoYoutubeCommentsRankingCTRMetrics(data["empiricalCtrs"]) : undefined,
    lastReplyTimestampUsec: data["lastReplyTimestampUsec"] !== undefined ? String(data["lastReplyTimestampUsec"]) : undefined,
    segments: data["segments"] !== undefined ? serializeSocialCommonSegments(data["segments"]) : undefined,
    sentiment: data["sentiment"] !== undefined ? serializeYoutubeCommentsSentimentSentiment(data["sentiment"]) : undefined,
    stanzaRestrictions: data["stanzaRestrictions"] !== undefined ? data["stanzaRestrictions"].map((item: any) => (serializeSocialStanzaStanzaRestriction(item))) : undefined,
    subject: data["subject"] !== undefined ? serializeSecurityCredentialsPrincipalProto(data["subject"]) : undefined,
    subscriptionTimestamp: data["subscriptionTimestamp"] !== undefined ? String(data["subscriptionTimestamp"]) : undefined,
    superThanksInfo: data["superThanksInfo"] !== undefined ? serializeYoutubeBackstageSuperVodCommentInfo(data["superThanksInfo"]) : undefined,
  };
}

function deserializeYoutubeCommentsClusteringMiniStanza(data: any): YoutubeCommentsClusteringMiniStanza {
  return {
    ...data,
    contentUpdateTimestamp: data["contentUpdateTimestamp"] !== undefined ? new Date(data["contentUpdateTimestamp"]) : undefined,
    creationTimeInSeconds: data["creationTimeInSeconds"] !== undefined ? BigInt(data["creationTimeInSeconds"]) : undefined,
    distillerEngagements: data["distillerEngagements"] !== undefined ? deserializeAppsPeopleActivityStreamqualityDistillerEngagements(data["distillerEngagements"]) : undefined,
    empiricalCtrs: data["empiricalCtrs"] !== undefined ? deserializeVideoYoutubeCommentsRankingCTRMetrics(data["empiricalCtrs"]) : undefined,
    lastReplyTimestampUsec: data["lastReplyTimestampUsec"] !== undefined ? BigInt(data["lastReplyTimestampUsec"]) : undefined,
    segments: data["segments"] !== undefined ? deserializeSocialCommonSegments(data["segments"]) : undefined,
    sentiment: data["sentiment"] !== undefined ? deserializeYoutubeCommentsSentimentSentiment(data["sentiment"]) : undefined,
    stanzaRestrictions: data["stanzaRestrictions"] !== undefined ? data["stanzaRestrictions"].map((item: any) => (deserializeSocialStanzaStanzaRestriction(item))) : undefined,
    subject: data["subject"] !== undefined ? deserializeSecurityCredentialsPrincipalProto(data["subject"]) : undefined,
    subscriptionTimestamp: data["subscriptionTimestamp"] !== undefined ? BigInt(data["subscriptionTimestamp"]) : undefined,
    superThanksInfo: data["superThanksInfo"] !== undefined ? deserializeYoutubeBackstageSuperVodCommentInfo(data["superThanksInfo"]) : undefined,
  };
}

/**
 * Comment text embedding.
 */
export interface YoutubeCommentsRankingYouTubeCommentTextEmbedding {
  /**
   * Comment text embedding.
   */
  textEmbedding?: number[];
}

/**
 * Text quality scores for a single comment.
 */
export interface YoutubeCommentsRankingYouTubeCommentTextQualityAnnotation {
  /**
   * Score produced by the user flag prediction model.
   */
  flagPredictionScore?: number;
  /**
   * Version identifier of the flag prediction model.
   */
  flagPredictionVersion?: string;
}

/**
 * Sentiment information extracted from the annotated content by Goldmine. This
 * mirrors nlp_sentiment.SentimentAnnotation. Next tag: 5.
 */
export interface YoutubeCommentsSentimentSentiment {
  entitySentiment?: YoutubeCommentsSentimentSentimentEntitySentimentAnnotation[];
  /**
   * Total magnitude of the sentiment. A positive number representing the total
   * intensity of sentiment regardless of positive vs negative polarity.
   */
  magnitude?: number;
  /**
   * Polarity of the sentiment. Value is between -1.0 and 1.0 inclusive, with
   * larger numbers representing more positive sentiment and negative numbers
   * representing negative sentiment.
   */
  polarity?: number;
  /**
   * The average score over sentences. This combines the polarity and magnitude
   * signals into one value. Bounded between -1.0 and 1.0.
   */
  score?: number;
}

function serializeYoutubeCommentsSentimentSentiment(data: any): YoutubeCommentsSentimentSentiment {
  return {
    ...data,
    entitySentiment: data["entitySentiment"] !== undefined ? data["entitySentiment"].map((item: any) => (serializeYoutubeCommentsSentimentSentimentEntitySentimentAnnotation(item))) : undefined,
  };
}

function deserializeYoutubeCommentsSentimentSentiment(data: any): YoutubeCommentsSentimentSentiment {
  return {
    ...data,
    entitySentiment: data["entitySentiment"] !== undefined ? data["entitySentiment"].map((item: any) => (deserializeYoutubeCommentsSentimentSentimentEntitySentimentAnnotation(item))) : undefined,
  };
}

/**
 * An entity level sentiment annotation containing the sentiment values
 * aggregated over all mentions of an entity. Next tag: 7.
 */
export interface YoutubeCommentsSentimentSentimentEntitySentimentAnnotation {
  /**
   * The representative entity name. This can be blank for cases when there is
   * no explicit name like "I" or "it". The mentions' tokens can be used to get
   * more details about each entity.
   */
  entityName?: string;
  /**
   * Total magnitude of the sentiment.
   */
  magnitude?: number;
  mentionSentiment?: YoutubeCommentsSentimentSentimentEntitySentimentAnnotationMentionSentimentAnnotation[];
  /**
   * MID for this entity, if available.
   */
  mid?: string;
  /**
   * Polarity of the sentiment. See above for detail.
   */
  polarity?: number;
  /**
   * The per entity score between -1.0 and 1.0. Combines the signal from
   * polarity and magnitude values.
   */
  score?: number;
}

function serializeYoutubeCommentsSentimentSentimentEntitySentimentAnnotation(data: any): YoutubeCommentsSentimentSentimentEntitySentimentAnnotation {
  return {
    ...data,
    mentionSentiment: data["mentionSentiment"] !== undefined ? data["mentionSentiment"].map((item: any) => (serializeYoutubeCommentsSentimentSentimentEntitySentimentAnnotationMentionSentimentAnnotation(item))) : undefined,
  };
}

function deserializeYoutubeCommentsSentimentSentimentEntitySentimentAnnotation(data: any): YoutubeCommentsSentimentSentimentEntitySentimentAnnotation {
  return {
    ...data,
    mentionSentiment: data["mentionSentiment"] !== undefined ? data["mentionSentiment"].map((item: any) => (deserializeYoutubeCommentsSentimentSentimentEntitySentimentAnnotationMentionSentimentAnnotation(item))) : undefined,
  };
}

/**
 * A mention level sentiment annotation containing the sentiment values for a
 * single entity mention. // Next tag: 6.
 */
export interface YoutubeCommentsSentimentSentimentEntitySentimentAnnotationMentionSentimentAnnotation {
  /**
   * Token end index in corresponding SAFT document (inclusive).
   */
  endToken?: bigint;
  /**
   * Total magnitude of the sentiment.
   */
  magnitude?: number;
  /**
   * Polarity of the sentiment. See above for detail.
   */
  polarity?: number;
  /**
   * The per mention score between -1.0 and 1.0. Combines the signal from
   * polarity and magnitude values.
   */
  score?: number;
  /**
   * Token start index in corresponding SAFT document.
   */
  startToken?: bigint;
}

function serializeYoutubeCommentsSentimentSentimentEntitySentimentAnnotationMentionSentimentAnnotation(data: any): YoutubeCommentsSentimentSentimentEntitySentimentAnnotationMentionSentimentAnnotation {
  return {
    ...data,
    endToken: data["endToken"] !== undefined ? String(data["endToken"]) : undefined,
    startToken: data["startToken"] !== undefined ? String(data["startToken"]) : undefined,
  };
}

function deserializeYoutubeCommentsSentimentSentimentEntitySentimentAnnotationMentionSentimentAnnotation(data: any): YoutubeCommentsSentimentSentimentEntitySentimentAnnotationMentionSentimentAnnotation {
  return {
    ...data,
    endToken: data["endToken"] !== undefined ? BigInt(data["endToken"]) : undefined,
    startToken: data["startToken"] !== undefined ? BigInt(data["startToken"]) : undefined,
  };
}

/**
 * The annotation of a document by a given entity, for a given type of
 * relationship.
 */
export interface YoutubeDiscoveryLegosLegosAnnotation {
  /**
   * The entity annotating the document.
   */
  entity?: YoutubeDiscoveryLegosLegosEntity;
  /**
   * The annotation is a format annotation, i.e. it tells the format of the
   * video.
   */
  format?: YoutubeDiscoveryLegosLegosFormatRelationship;
  /**
   * The annotation is present in the video. Semantic Legos and Presence Legos
   * naturally overlap and can contain the same entities. However, we do not
   * enforce a strict subset relation.
   */
  present?: YoutubeDiscoveryLegosLegosPresentRelationship;
  /**
   * The annotation is a semantic annotation, i.e. it tells what the document
   * is about and what the reasons to watch the video are. The annotation should
   * be valid for the complete annotated document, not simply a part of the
   * document such as a video segment.
   */
  semantic?: YoutubeDiscoveryLegosLegosSemanticRelationship;
  /**
   * The annotation is a taxonomic annotation, i.e. it tells to which class of
   * the Legos taxonomy the document belongs to.
   */
  taxonomic?: YoutubeDiscoveryLegosLegosTaxonomicRelationship;
}

/**
 * A collection of annotations returned by Legos for a document.
 */
export interface YoutubeDiscoveryLegosLegosAnnotations {
  /**
   * The annotations for this document. For a given (entity, relationship type)
   * pair, there will be at most one annotation. The list has no particular
   * order.
   */
  annotations?: YoutubeDiscoveryLegosLegosAnnotation[];
}

/**
 * The identification of a Knowledge Graph (KG) entity in Legos.
 */
export interface YoutubeDiscoveryLegosLegosEntity {
  /**
   * DO NOT USE THIS FIELD. The entity name here can be random garbage and when
   * it's actually a name it will be in a random language (most of the time
   * English but not always). This field is going away soon. For a replacement
   * you should probably use the following RPC: cs/symbol:Ytpedia.GetNames
   * please read go/ytks-calling details on how to call it and don't hesitate to
   * write to us for help with this (or in any case before starting to send real
   * traffic to us) at: g/yt-knowledge-service
   */
  debugName?: string;
  /**
   * The ID of the Knowledge Graph entity. Note: this is the primary ID at
   * generation time. See
   * https://sites.google.com/a/google.com/knowledge-graph/data/primary_ids
   */
  kgId?: string;
}

/**
 * Description of a format Legos annotation. http://go/legos/formats.md
 */
export interface YoutubeDiscoveryLegosLegosFormatRelationship {
  /**
   * Format classification confidence score, in the 0-1 range. A score of XX%
   * means that we expect at least XX% of the documents annotated with this
   * format to be correctly annotated; i.e. thresholding at XX% yields a
   * precision of at least XX%.
   */
  confidence?: number;
}

/**
 * Description of a present Legos annotation.
 */
export interface YoutubeDiscoveryLegosLegosPresentRelationship {
  /**
   * Confidence score. Thresholding at the confidence score at 0.XX yields
   * annotations of precision of at least XX%.
   */
  confidence?: number;
  /**
   * Extra context about how the entity relates to the document. Typically
   * vertical-specific. Please refrain from populating this field as we're
   * working on migrating most of the use cases to the LegosEntity proto so
   * clients don't have to scan all relationships to know which annotations they
   * may be interested in.
   */
  contexts?: YoutubeDiscoveryLegosLegosSemanticRelationshipContext[];
}

/**
 * Description of a semantic Legos annotation.
 * http://go/legos/project.md#semantic-intent-annotations
 */
export interface YoutubeDiscoveryLegosLegosSemanticRelationship {
  /**
   * Confidence score. Thresholding at the confidence score at 0.XX yields
   * annotations of precision of at least XX%. Only filled in the intent
   * definition Legos. Please use IsSemanticAnnotationAtConfidenceThreshold()
   * from
   * video/youtube/discovery/legos/annotations/public/legos_annotations_util.h
   * to obtain only intent definition Legos. For more information on the
   * migration please look at go/legos-intent-migration.
   */
  confidence?: number;
  contexts?: YoutubeDiscoveryLegosLegosSemanticRelationshipContext[];
  /**
   * DEPRECATED. Please use confidence instead. Will be set to the same value
   * as confidence in early January 2019. See go/legos-intent-migration for more
   * information.
   */
  topicalityScore?: number;
}

/**
 * Extra context about how the entity relates to the document. Typically
 * vertical-specific.
 */
export interface YoutubeDiscoveryLegosLegosSemanticRelationshipContext {
  /**
   * The subject of the semantic relationship. This is set when the
   * relationship is derived from some other entity. The exact meaning of this
   * field depends on the ContextType.
   */
  subject?: YoutubeDiscoveryLegosLegosEntity;
  /**
   * The type of semantic relationship between the document and the entity.
   * This allows one to retrieve vertical-specific fine-grained information
   * about the document.
   */
  type?:  | "UNKNOWN_CONTEXT_TYPE" | "MUSIC_RECORDING_CLUSTER" | "MUSIC_EXACT_RECORDING" | "MUSIC_PRIMARY_RECORDING" | "MUSIC_RECORDING_ARTIST" | "MUSIC_FEATURED_ARTIST" | "MUSIC_COMPOSITION" | "MUSIC_ORIGINAL_ARTIST_OF_COVER" | "MUSIC_ORIGINAL_RECORDING_CLUSTER_OF_COVER" | "MUSIC_OFFICIAL_VIDEO" | "MUSIC_OFFICIAL_AUDIO" | "MUSIC_OFFICIAL_EXACT_RECORDING_WITHOUT_CLUSTER" | "MUSIC_LYRICS_VIDEO" | "MUSIC_LIVE_RECORDING" | "MUSIC_REMIX_RECORDING" | "MUSIC_KARAOKE_VERSION" | "MUSIC_INSTRUMENTAL_RECORDING" | "MUSIC_REMIX_ARTIST" | "MUSIC_BOLLYWOOD_ACTOR" | "MUSIC_UGC_SONG" | "MUSIC_ART_TRACK_OR_PREMIUM_CLAIM" | "SHORT_VIDEO_BACKGROUND_MUSIC" | "SHORT_VIDEO_BACKGROUND_MUSIC_COMPOSITION" | "SHORT_VIDEO_BACKGROUND_MUSIC_EXACT_RECORDING" | "MUSIC_BASS_TOP_LEVEL_GENRE" | "MUSIC_BASS_SUBGENRE" | "CREATOR_OFFICIAL_CHANNEL" | "CREATOR_VEVO_SINGLE_CHANNEL" | "CREATOR_OTHER_SINGLE_CHANNEL" | "CREATOR_MULTIPLE_CHANNEL" | "TV_SHOW_FOOTAGE" | "TV_SHOW_GENRE" | "MOVIE_GENRE" | "GAMING_TOP_VIDEO_GAME" | "GAMING_IS_ITEM_EQUIPPED_BY" | "GAMING_IS_ITEM_USED_BY" | "GAMING_IS_ALLIED_CHARACTER_OF" | "GAMING_IS_CHARACTER_CONTROLLED_BY" | "LEGOS_OVERRIDE_LIVE_SPORTS" | "KG_SOCIAL_MEDIA_PROFILE" | "PERSON_CREATOR" | "PREMIUM_TVOD_MOVIE" | "PREMIUM_AVOD_MOVIE" | "PREMIUM_TVOD_SHOW" | "PREMIUM_MOVIE_ACTOR" | "PREMIUM_MOVIE_DIRECTOR" | "PREMIUM_MOVIE_GENRE" | "PUBLIC_FIGURE_UPLOADER" | "PUBLIC_FIGURE_ABOUT" | "RESPONSIBILITY_CLARIFICATION_NEEDED" | "CLARIFY_TFX_MODEL" | "DENORM_VIDEO_GAME_TO_VIDEO_GAME_GENRES" | "DENORM_VIDEO_GAME_TO_VIDEO_GAME_SERIES" | "DENORM_PRODUCT_LINE_TO_BRAND" | "DENORM_ORGANIZATION_TO_BRAND" | "DENORM_PODCAST_SERIES_TO_PODCAST" | "DENORM_COVID_VACCINE" | "DENORM_PRODUCT_TO_DOMINANT_PRODUCT_CATEGORY" | "DENORM_PRODUCT_TO_PRODUCT_CATEGORY" | "DENORMALIZATIONS" | "SHOPPING_PRODUCT" | "SHOPPING_PRODUCT_LINE" | "SHOPPING_BRAND" | "SHOPPING_CATEGORY" | "CREATOR_SHOPPING_PRODUCT" | "VSU_SHOPPING_PRODUCT" | "GEO_TYPE_RESTAURANT_OR_CAFE" | "GEO_TYPE_ESTABLISHMENT_POI" | "GEO_TYPES_COLLECTION_TRAVEL_AND_TOURISM" | "GEO_TYPE_ENTERTAINMENT_AND_RECREATION" | "GEO_TYPES_COLLECTION_BUSINESSES" | "GEO_TYPES_COLLECTION_POTENTIALLY_SENSITIVE" | "GEO_TYPE" | "GEO_TYPES_COLLECTION_SMALL_POLITICALS" | "ADDED_DURING_GEO_ENTITIES_PROMOTION" | "DENORM_LOCATION_TO_CONTAINING_COUNTRY" | "DENORM_LOCATION_TO_CONTAINING_REGION" | "DENORM_LOCATION_TO_CONTAINING_CITY" | "MOVIE" | "TV_SHOW" | "SPORT_TEAM" | "SPORT_LEAGUE" | "ELECTIONS_ANNOTATION_PRE_RULES" | "HAS_A_VOTING_MID" | "GEO_LEGOS_TEST_SET_V2_POLITICAL" | "GEO_LEGOS_TEST_SET_V2_TRAVEL_DESTINATIONS" | "GEO_LEGOS_TEST_SET_V2_DINING" | "GEO_LEGOS_TEST_SET_V2_HOTEL";
}

/**
 * Description of a taxonomic Legos annotation.
 * http://go/legos/project.md#taxonomy-annotations
 */
export interface YoutubeDiscoveryLegosLegosTaxonomicRelationship {
  /**
   * Set to true if the taxonomy annotation is redundant amongst the set of
   * other taxonomy annotations for the same document, i.e. if there is at least
   * one other taxonomy annotation that is a child node of this one.
   */
  isRedundant?: boolean;
  /**
   * A score, in the 0-1 range, used to rank taxonomy annotations.
   */
  score?: number;
}

/**
 * Blarney Stone classification scores: go/blarneystone Next available ID: 6
 */
export interface YoutubeDistillerBlarneyStoneScores {
  familySafeV1Score?: number;
  mildHateHarassV1Score?: number;
  mildHateHarassV2Score?: number;
  /**
   * The scores corresponds to each of the abe_models in
   * /cns/yk-d/home/blarneystone/model0/config-2015-11-20.pbtxt
   */
  modelScores?: YoutubeDistillerModelScore[];
  severeHateHarassV1Score?: number;
}

/**
 * Next available ID: 4
 */
export interface YoutubeDistillerModelScore {
  /**
   * The classifier trained with tensor flow.
   */
  classifier?:  | "UNKNOWN" | "OFFENSIVE_NON_POLICY" | "OFFENSIVE_YT_POLICY" | "COMMERCIAL_INTENT";
  /**
   * The model trained with dist belief [going to be deprecated].
   */
  model?:  | "UNKNOWN" | "HATE" | "HARASSMENT" | "HATE_OR_HARASSMENT" | "COMMERCIAL_INTENT" | "SEVERE_HATE_HARASSMENT" | "MILD_HATE_HARASSMENT" | "MILD_HATE_HARASSMENT_V2";
  score?: number;
}

function decodeBase64(b64: string): Uint8Array {
  const binString = atob(b64);
  const size = binString.length;
  const bytes = new Uint8Array(size);
  for (let i = 0; i < size; i++) {
    bytes[i] = binString.charCodeAt(i);
  }
  return bytes;
}

const base64abc = ["A","B","C","D","E","F","G","H","I","J","K","L","M","N","O","P","Q","R","S","T","U","V","W","X","Y","Z","a","b","c","d","e","f","g","h","i","j","k","l","m","n","o","p","q","r","s","t","u","v","w","x","y","z","0","1","2","3","4","5","6","7","8","9","+","/"];
/**
 * CREDIT: https://gist.github.com/enepomnyaschih/72c423f727d395eeaa09697058238727
 * Encodes a given Uint8Array, ArrayBuffer or string into RFC4648 base64 representation
 * @param data
 */
function encodeBase64(uint8: Uint8Array): string {
  let result = "", i;
  const l = uint8.length;
  for (i = 2; i < l; i += 3) {
    result += base64abc[uint8[i - 2] >> 2];
    result += base64abc[((uint8[i - 2] & 0x03) << 4) | (uint8[i - 1] >> 4)];
    result += base64abc[((uint8[i - 1] & 0x0f) << 2) | (uint8[i] >> 6)];
    result += base64abc[uint8[i] & 0x3f];
  }
  if (i === l + 1) {
    // 1 octet yet to write
    result += base64abc[uint8[i - 2] >> 2];
    result += base64abc[(uint8[i - 2] & 0x03) << 4];
    result += "==";
  }
  if (i === l) {
    // 2 octets yet to write
    result += base64abc[uint8[i - 2] >> 2];
    result += base64abc[((uint8[i - 2] & 0x03) << 4) | (uint8[i - 1] >> 4)];
    result += base64abc[(uint8[i - 1] & 0x0f) << 2];
    result += "=";
  }
  return result;
}
